{"id": "14194", "url": "https://en.wikipedia.org/wiki?curid=14194", "title": "History of medicine", "text": "History of medicine\n\nThe history of medicine shows how societies have changed in their approach to illness and disease from ancient times to the present. Early medical traditions include those of Babylon, China, Egypt and India. The Indians introduced the concepts of medical diagnosis, prognosis, and advanced medical ethics. The Hippocratic Oath was written in ancient Greece in the 5th century BCE, and is a direct inspiration for oaths of office that physicians swear upon entry into the profession today. In the Middle Ages, surgical practices inherited from the ancient masters were improved and then systematized in Rogerius's \"The Practice of Surgery\". Universities began systematic training of physicians around 1220 CE in Italy.\n\nDuring the Renaissance, understanding of anatomy improved, and the microscope was invented. Prior to the 19th century, humorism (also known as humoralism) was thought to explain the cause of disease but it was gradually replaced by the germ theory of disease, leading to effective treatments and even cures for many infectious diseases. Military doctors advanced the methods of trauma treatment and surgery. Public health measures were developed especially in the 19th century as the rapid growth of cities required systematic sanitary measures. Advanced research centers opened in the early 20th century, often connected with major hospitals. The mid-20th century was characterized by new biological treatments, such as antibiotics. These advancements, along with developments in chemistry, genetics, and radiography led to modern medicine. Medicine was heavily professionalized in the 20th century, and new careers opened to women as nurses (from the 1870s) and as physicians (especially after 1970).\n\nAlthough there is no record to establish when plants were first used for medicinal purposes (herbalism), the use of plants as healing agents, as well as clays and soils is ancient. Over time through emulation of the behavior of fauna a medicinal knowledge base developed and passed between generations. As tribal culture specialized specific castes, shamans and apothecaries fulfilled the role of healer.\nThe first known dentistry dates to c. 7000 BC in Baluchistan where Neolithic dentists used flint-tipped drills and bowstrings. The first known trepanning operation was carried out c. 5000 BC in Ensisheim, France. A possible amputation was carried out c. 4,900 BC in Buthiers-Bulancourt, France.\n\nEven earlier, Neanderthals may have engaged in medical practices.\n\nThe ancient Mesopotamians had no distinction between \"rational science\" and magic. When a person became ill, doctors would prescribe both magical formulas to be recited as well as medicinal treatments. The earliest medical prescriptions appear in Sumerian during the Third Dynasty of Ur ( 2112 BC – 2004 BC). The oldest Babylonian texts on medicine date back to the Old Babylonian period in the first half of the 2nd millennium BCE. The most extensive Babylonian medical text, however, is the \"Diagnostic Handbook\" written by the \"ummânū\", or chief scholar, Esagil-kin-apli of Borsippa, during the reign of the Babylonian king Adad-apla-iddina (1069–1046 BCE). Along with the Egyptians, the Babylonians introduced the practice of diagnosis, prognosis, physical examination, and remedies. In addition, the \"Diagnostic Handbook\" introduced the methods of therapy and cause. The text contains a list of medical symptoms and often detailed empirical observations along with logical rules used in combining observed symptoms on the body of a patient with its diagnosis and prognosis. The \"Diagnostic Handbook\" was based on a logical set of axioms and assumptions, including the modern view that through the examination and inspection of the symptoms of a patient, it is possible to determine the patient's disease, its cause and future development, and the chances of the patient's recovery. The symptoms and diseases of a patient were treated through therapeutic means such as bandages, herbs and creams.\n\nIn East Semitic cultures, the main medicinal authority was a kind of exorcist-healer known as an \"āšipu\". The profession was generally passed down from father to son and was held in extremely high regard. Of less frequent recourse was another kind of healer known as an \"asu\", who corresponds more closely to a modern physician and treated physical symptoms using primarily folk remedies composed of various herbs, animal products, and minerals, as well as potions, enemas, and ointments or poultices. These physicians, who could be either male or female, also dressed wounds, set limbs, and performed simple surgeries. The ancient Mesopotamians also practiced prophylaxis and took measures to prevent the spread of disease.\n\nMental illnesses were well known in ancient Mesopotamia, where diseases and mental disorders were believed to be caused by specific deities. Because hands symbolized control over a person, mental illnesses were known as \"hands\" of certain deities. One psychological illness was known as \"Qāt Ištar\", meaning \"Hand of Ishtar\". Others were known as \"Hand of Shamash\", \"Hand of the Ghost\", and \"Hand of the God\". Descriptions of these illnesses, however, are so vague that it is usually impossible to determine which illnesses they correspond to in modern terminology. Mesopotamian doctors kept detailed record of their patients' hallucinations and assigned spiritual meanings to them. A patient who hallucinated that he was seeing a dog was predicted to die; whereas, if he saw a gazelle, he would recover. The royal family of Elam was notorious for its members frequently suffering from insanity. Erectile dysfunction was recognized as being rooted in psychological problems.\n\nAncient Egypt developed a large, varied and fruitful medical tradition. Herodotus described the Egyptians as \"the healthiest of all men, next to the Libyans\", because of the dry climate and the notable public health system that they possessed. According to him, \"the practice of medicine is so specialized among them that each physician is a healer of one disease and no more.\" Although Egyptian medicine, to a considerable extent, dealt with the supernatural, it eventually developed a practical use in the fields of anatomy, public health, and clinical diagnostics.\n\nMedical information in the Edwin Smith Papyrus may date to a time as early as 3000 BC. Imhotep in the 3rd dynasty is sometimes credited with being the founder of ancient Egyptian medicine and with being the original author of the \"Edwin Smith Papyrus\", detailing cures, ailments and anatomical observations. The \"Edwin Smith Papyrus\" is regarded as a copy of several earlier works and was written c. 1600 BC. It is an ancient textbook on surgery almost completely devoid of magical thinking and describes in exquisite detail the \"examination, diagnosis, treatment,\" and \"prognosis\" of numerous ailments.\n\nThe Kahun Gynaecological Papyrus treats women's complaints, including problems with conception. Thirty four cases detailing diagnosis and treatment survive, some of them fragmentarily. Dating to 1800 BCE, it is the oldest surviving medical text of any kind.\n\nMedical institutions, referred to as \"Houses of Life\" are known to have been established in ancient Egypt as early as 2200 BC.\n\nThe earliest known physician is also credited to ancient Egypt: Hesy-Ra, \"Chief of Dentists and Physicians\" for King Djoser in the 27th century BCE. Also, the earliest known woman physician, Peseshet, practiced in Ancient Egypt at the time of the 4th dynasty. Her title was \"Lady Overseer of the Lady Physicians.\" In addition to her supervisory role, Peseshet trained midwives at an ancient Egyptian medical school in Sais.\n\nThe Atharvaveda, a sacred text of Hinduism dating from the Early Iron Age, is one of the first Indian text dealing with medicine. The Atharvaveda also contain prescriptions of herbs for various ailments. The use of herbs to treat ailments would later form a large part of Ayurveda.\n\nAyurveda, meaning the \"complete knowledge for long life\" is another medical system of India. Its two most famous texts belong to the schools of Charaka and Sushruta. The earliest foundations of Ayurveda were built on a synthesis of traditional herbal practices together with a massive addition of theoretical conceptualizations, new nosologies and new therapies dating from about 600 BCE onwards, and coming out of the communities of thinkers who included the Buddha and others.\n\nAccording to the compendium of Charaka, the Charakasamhitā, health and disease are not predetermined and life may be prolonged by human effort. The compendium of Suśruta, the Suśrutasamhitā defines the purpose of medicine to cure the diseases of the sick, protect the healthy, and to prolong life. Both these ancient compendia include details of the examination, diagnosis, treatment, and prognosis of numerous ailments. The Suśrutasamhitā is notable for describing procedures on various forms of surgery, including rhinoplasty, the repair of torn ear lobes, perineal lithotomy, cataract surgery, and several other excisions and other surgical procedures. Most remarkable is Sushruta's penchant for scientific classification:\nHis medical treatise consists of 184 chapters, 1,120 conditions are listed, including injuries and illnesses relating to aging and mental illness.\n\nThe Ayurvedic classics mention eight branches of medicine: kāyācikitsā (internal medicine), śalyacikitsā (surgery including anatomy), śālākyacikitsā (eye, ear, nose, and throat diseases), kaumārabhṛtya (pediatrics with obstetrics and gynaecology), bhūtavidyā (spirit and psychiatric medicine), agada tantra (toxicology with treatments of stings and bites), rasāyana (science of rejuvenation), and vājīkaraṇa (aphrodisiac and fertility). Apart from learning these, the student of Āyurveda was expected to know ten arts that were indispensable in the preparation and application of his medicines: distillation, operative skills, cooking, horticulture, metallurgy, sugar manufacture, pharmacy, analysis and separation of minerals, compounding of metals, and preparation of alkalis. The teaching of various subjects was done during the instruction of relevant clinical subjects. For example, teaching of anatomy was a part of the teaching of surgery, embryology was a part of training in pediatrics and obstetrics, and the knowledge of physiology and pathology was interwoven in the teaching of all the clinical disciplines.\nThe normal length of the student's training appears to have been seven years. But the physician was to continue to learn.\n\nAs an alternative form of medicine in India, Unani medicine got deep roots and royal patronage during medieval times. It progressed during Indian sultanate and mughal periods. Unani medicine is very close to Ayurveda. Both are based on theory of the presence of the elements (in Unani, they are considered to be fire, water, earth and air) in the human body. According to followers of Unani medicine, these elements are present in different fluids and their balance leads to health and their imbalance leads to illness.\n\nBy the 18th century CE, Sanskrit medical wisdom still dominated. Muslim rulers built large hospitals in 1595 in Hyderabad, and in Delhi in 1719, and numerous commentaries on ancient texts were written.\n\nChina also developed a large body of traditional medicine. Much of the philosophy of traditional Chinese medicine derived from empirical observations of disease and illness by Taoist physicians and reflects the classical Chinese belief that individual human experiences express causative principles effective in the environment at all scales. These causative principles, whether material, essential, or mystical, correlate as the expression of the natural order of the universe.\n\nThe foundational text of Chinese medicine is the Huangdi neijing, (or \"Yellow Emperor's Inner Canon\"), written 5th century to 3rd century BCE. Near the end of the 2nd century CE, during the Han dynasty, Zhang Zhongjing, wrote a \"Treatise on Cold Damage\", which contains the earliest known reference to the \"Neijing Suwen\". The Jin Dynasty practitioner and advocate of acupuncture and moxibustion, Huangfu Mi (215–282), also quotes the Yellow Emperor in his \"Jiayi jing\", c. 265. During the Tang Dynasty, the \"Suwen\" was expanded and revised, and is now the best extant representation of the foundational roots of traditional Chinese medicine. Traditional Chinese Medicine that is based on the use of herbal medicine, acupuncture, massage and other forms of therapy has been practiced in China for thousands of years.\n\nIn the 18th century, during the Qing dynasty, there was a proliferation of popular books as well as more advanced encyclopedias on traditional medicine. Jesuit missionaries introduced Western science and medicine to the royal court, the Chinese physicians ignored them.\n\nFinally in the 19th century, Western medicine was introduced at the local level by Christian medical missionaries from the London Missionary Society (Britain), the Methodist Church (Britain) and the Presbyterian Church (US). Benjamin Hobson (1816–1873) in 1839, set up a highly successful Wai Ai Clinic in Guangzhou, China. The Hong Kong College of Medicine for Chinese was founded in 1887 by the London Missionary Society, with its first graduate (in 1892) being Sun Yat-sen, who later led the Chinese Revolution (1911). The Hong Kong College of Medicine for Chinese was the forerunner of the School of Medicine of the University of Hong Kong, which started in 1911.\n\nBecause of the social custom that men and women should not be near to one another, the women of China were reluctant to be treated by male doctors. The missionaries sent women doctors such as Dr. Mary Hannah Fulton (1854–1927). Supported by the Foreign Missions Board of the Presbyterian Church (US) she in 1902 founded the first medical college for women in China, the Hackett Medical College for Women, in Guangzhou.\n\nAround 800 BCE Homer in The Iliad gives descriptions of wound treatment by the two sons of Asklepios, the admirable physicians Podaleirius and Machaon and one acting doctor, Patroclus. Because Machaon is wounded and Podaleirius is in combat Eurypylus asks Patroclus to \"cut out this arrow from my thigh, wash off the blood with warm water and spread soothing ointment on the wound\". Asklepios like Imhotep becomes god of healing over time.\n\nTemples dedicated to the healer-god Asclepius, known as \"Asclepieia\" (, sing. , \"'Asclepieion\"), functioned as centers of medical advice, prognosis, and healing. At these shrines, patients would enter a dream-like state of induced sleep known as \"enkoimesis\" () not unlike anesthesia, in which they either received guidance from the deity in a dream or were cured by surgery. Asclepeia provided carefully controlled spaces conducive to healing and fulfilled several of the requirements of institutions created for healing. In the Asclepeion of Epidaurus, three large marble boards dated to 350 BCE preserve the names, case histories, complaints, and cures of about 70 patients who came to the temple with a problem and shed it there. Some of the surgical cures listed, such as the opening of an abdominal abscess or the removal of traumatic foreign material, are realistic enough to have taken place, but with the patient in a state of enkoimesis induced with the help of soporific substances such as opium. Alcmaeon of Croton wrote on medicine between 500 and 450 BCE. He argued that channels linked the sensory organs to the brain, and it is possible that he discovered one type of channel, the optic nerves, by dissection.\n\nA towering figure in the history of medicine was the physician Hippocrates of Kos (c. 460c. 370 BCE), considered the \"father of modern medicine.\" The Hippocratic Corpus is a collection of around seventy early medical works from ancient Greece strongly associated with Hippocrates and his students. Most famously, the Hippocratics invented the Hippocratic Oath for physicians. Contemporary physicians swear an oath of office which includes aspects found in early editions of the Hippocratic Oath.\n\nHippocrates and his followers were first to describe many diseases and medical conditions. Though humorism (humoralism) as a medical system predates 5th-century Greek medicine, Hippocrates and his students systemetized the thinking that illness can be explained by an imbalance of blood, phlegm, black bile, and yellow bile. Hippocrates is given credit for the first description of clubbing of the fingers, an important diagnostic sign in chronic suppurative lung disease, lung cancer and cyanotic heart disease. For this reason, clubbed fingers are sometimes referred to as \"Hippocratic fingers\". Hippocrates was also the first physician to describe the Hippocratic face in \"Prognosis\". Shakespeare famously alludes to this description when writing of Falstaff's death in Act II, Scene iii. of \"Henry V\".\n\nHippocrates began to categorize illnesses as acute, chronic, endemic and epidemic, and use terms such as, \"exacerbation, relapse, resolution, crisis, paroxysm, peak, and convalescence.\"\n\nAnother of Hippocrates's major contributions may be found in his descriptions of the symptomatology, physical findings, surgical treatment and prognosis of thoracic empyema, i.e. suppuration of the lining of the chest cavity. His teachings remain relevant to present-day students of pulmonary medicine and surgery. Hippocrates was the first documented person to practise cardiothoracic surgery, and his findings are still valid.\n\nSome of the techniques and theories developed by Hippocrates are now put into practice by the fields of Environmental and Integrative Medicine. These include recognizing the importance of taking a complete history which includes environmental exposures as well as foods eaten by the patient which might play a role in his or her illness.\n\nTwo great Alexandrians laid the foundations for the scientific study of anatomy and physiology, Herophilus of Chalcedon and Erasistratus of Ceos. Other Alexandrian surgeons gave us ligature (hemostasis), lithotomy, hernia operations, ophthalmic surgery, plastic surgery, methods of reduction of dislocations and fractures, tracheotomy, and mandrake as an anaesthetic. Some of what we know of them comes from Celsus and Galen of Pergamum.\n\nHerophilus of Chalcedon, working at the medical school of Alexandria placed intelligence in the brain, and connected the nervous system to motion and sensation. Herophilus also distinguished between veins and arteries, noting that the latter pulse while the former do not. He and his contemporary, Erasistratus of Chios, researched the role of veins and nerves, mapping their courses across the body. Erasistratus connected the increased complexity of the surface of the human brain compared to other animals to its superior intelligence. He sometimes employed experiments to further his research, at one time repeatedly weighing a caged bird, and noting its weight loss between feeding times. In Erasistratus' physiology, air enters the body, is then drawn by the lungs into the heart, where it is transformed into vital spirit, and is then pumped by the arteries throughout the body. Some of this vital spirit reaches the brain, where it is transformed into animal spirit, which is then distributed by the nerves.\n\nThe Greek Galen (c. 129–216 CE) was one of the greatest physicians of the ancient world, studying and traveling widely in ancient Rome. He dissected animals to learn about the body, and performed many audacious operations—including brain and eye surgeries—that were not tried again for almost two millennia. In \"Ars medica\" (\"Arts of Medicine\"), he explained mental properties in terms of specific mixtures of the bodily parts.\n\nGalen's medical works were regarded as authoritative until well into the Middle Ages. Galen left a physiological model of the human body that became the mainstay of the medieval physician's university anatomy curriculum, but it suffered greatly from stasis and intellectual stagnation because some of Galen's ideas were incorrect; he did not dissect a human body. Greek and Roman taboos had meant that dissection was usually banned in ancient times, but in the Middle Ages it changed.\n\nIn 1523 Galen's \"On the Natural Faculties\" was published in London. In the 1530s Belgian anatomist and physician Andreas Vesalius launched a project to translate many of Galen's Greek texts into Latin. Vesalius's most famous work, \"De humani corporis fabrica\" was greatly influenced by Galenic writing and form.\n\nThe Romans invented numerous surgical instruments, including the first instruments unique to women, as well as the surgical uses of forceps, scalpels, cautery, cross-bladed scissors, the surgical needle, the sound, and speculas. Romans also performed cataract surgery.\n\nThe Roman army physician Dioscorides (c. 40–90 CE), was a Greek botanist and pharmacologist. He wrote the encyclopedia \"De Materia Medica\" describing over 600 herbal cures, forming an influential pharmacopoeia which was used extensively for the following 1,500 years.\n\nByzantine medicine encompasses the common medical practices of the Byzantine Empire from about 400 AD to 1453 AD. Byzantine medicine was notable for building upon the knowledge base developed by its Greco-Roman predecessors. In preserving medical practices from antiquity, Byzantine medicine influenced Islamic medicine as well as fostering the Western rebirth of medicine during the Renaissance.\n\nByzantine physicians often compiled and standardized medical knowledge into textbooks. Their records tended to include both diagnostic explanations and technical drawings. The Medical Compendium in Seven Books, written by the leading physician Paul of Aegina, survived as a particularly thorough source of medical knowledge. This compendium, written in the late seventh century, remained in use as a standard textbook for the following 800 years.\n\nLate antiquity ushered in a revolution in medical science, and historical records often mention civilian hospitals (although battlefield medicine and wartime triage were recorded well before Imperial Rome). Constantinople stood out as a center of medicine during the Middle Ages, which was aided by its crossroads location, wealth, and accumulated knowledge.\ncopied content from Byzantine medicine; see that page's history for attribution\n\nThe first ever known example of separating conjoined twins occurred in the Byzantine Empire in the 10th century. The next example of separating conjoined twins will be first recorded many centuries later in Germany in 1689.\n\nThe Byzantine Empire's neighbors, the Persian Sassanid Empire, also made their noteworthy contributions mainly with the establishment of the Academy of Gondeshapur, which was \"the most important medical center of the ancient world during the 6th and 7th centuries.\" In addition, Cyril Elgood, British physician and a historian of medicine in Persia, commented that thanks to medical centers like the Academy of Gondeshapur, \"to a very large extent, the credit for the whole hospital system must be given to Persia.\"\n\nThe Islamic civilization rose to primacy in medical science as its physicians contributed significantly to the field of medicine, including anatomy, ophthalmology, pharmacology, pharmacy, physiology, surgery, and the pharmaceutical sciences. The Arabs were influenced by ancient Indian, Persian, Greek, Roman and Byzantine medical practices, and helped them develop further. Galen & Hippocrates were pre-eminent authorities. The translation of 129 of Galen's works into Arabic by the Nestorian Christian Hunayn ibn Ishaq and his assistants, and in particular Galen's insistence on a rational systematic approach to medicine, set the template for Islamic medicine, which rapidly spread throughout the Arab Empire. while Europe was in its Dark Ages, Islam expanded in West\nAsia and enjoyed a golden age. Its most famous\nphysicians included the Persian polymaths Muhammad ibn Zakariya al-Razi and Avicenna, who\nwrote more than 40 works on health, medicine, and well-being.\nTaking leads from Greece and Rome, Islamic scholars kept both\nthe art and science of medicine alive and moving forward.\n\nAfter AD 400, the study and practice of medicine in the Western Roman Empire went into deep decline. Medical services were provided, especially for the poor, in the thousands of monastic hospitals that sprang up across Europe, but the care was rudimentary and mainly palliative. Most of the writings of Galen and Hippocrates were lost to the West, with the summaries and compendia of St. Isidore of Seville being the primary channel for transmitting Greek medical ideas. The Carolingian renaissance brought increased contact with Byzantium and a greater awareness of ancient medicine, but only with the twelfth-century renaissance and the new translations coming from Muslim and Jewish sources in Spain, and the fifteenth-century flood of resources after the fall of Constantinople did the West fully recover its acquaintance with classical antiquity.\n\nGreek and Roman taboos had meant that dissection was usually banned in ancient times, but in the Middle Ages it changed: medical teachers and students at Bologna began to open human bodies, and Mondino de Luzzi (c. 1275–1326) produced the first known anatomy textbook based on human dissection.\n\nWallis identifies a prestige hierarchy with university educated physicians on top, followed by learned surgeons; craft-trained surgeons; barber surgeons; itinerant specialists such as dentist and oculists; empirics; and midwives.\n\nThe first medical schools were opened in the 9th century, most notably the Schola Medica Salernitana at Salerno in southern Italy. The cosmopolitan influences from Greek, Latin, Arabic, and Hebrew sources gave it an international reputation as the Hippocratic City. Students from wealthy families came for three years of preliminary studies and five of medical studies. The medicine, following the laws of Federico II, that he founded in 1224 the University ad improved the Schola Salernitana, in the period between 1200 and 1400, it had in Sicily (so-called Sicilian Middle Ages) a particular development so much to create a true school of Jewish medicine.\n\nAs a result of which, after a legal examination, was conferred to a Jewish Sicilian woman, Virdimura, wife of another physician Pasquale of Catania, the hystorical record of before woman officially trained to exercise of the medical profession.\n\nBy the thirteenth century, the medical school at Montpellier began to eclipse the Salernitan school. In the 12th century, universities were founded in Italy, France, and England, which soon developed schools of medicine. The University of Montpellier in France and Italy's University of Padua and University of Bologna were leading schools. Nearly all the learning was from lectures and readings in Hippocrates, Galen, Avicenna, and Aristotle.\n\nThe underlying principle of most medieval medicine was Galen's theory of humours. This was derived from the ancient medical works, and dominated all western medicine until the 19th century. The theory stated that within every individual there were four humours, or principal fluids—black bile, yellow bile, phlegm, and blood, these were produced by various organs in the body, and they had to be in balance for a person to remain healthy. Too much phlegm in the body, for example, caused lung problems; and the body tried to cough up the phlegm to restore a balance. The balance of humours in humans could be achieved by diet, medicines, and by blood-letting, using leeches. The four humours were also associated with the four seasons, black bile-autumn, yellow bile-summer, phlegm-winter and blood-spring.\n\nHealing included both physical and spiritual therapeutics, such as the right herbs, a suitable diet, clean bedding, and the sense that care was always at hand. Other procedures used to help patients included the Mass, prayers, relics of saints, and music used to calm a troubled mind or quickened pulse.\n\nIn 1376, in Sicily, it was historically given, in relationship to the laws of Federico II that they foresaw an examination with a regal errand of physicists, the first qualification to the exercise of the medicine to a woman, Virdimura a Jewess of Catania, whose document is preserved in Palermo to the Italian national archives.\n\nThe Renaissance brought an intense focus on scholarship to Christian Europe. A major effort to translate the Arabic and Greek scientific works into Latin emerged. Europeans gradually became experts not only in the ancient writings of the Romans and Greeks, but in the contemporary writings of Islamic scientists. During the later centuries of the Renaissance came an increase in experimental investigation, particularly in the field of dissection and body examination, thus advancing our knowledge of human anatomy.\n\nThe development of modern neurology began in the 16th century in Italy and France with Niccolò Massa, Jean Fernel, Jacques Dubois and Andreas Vesalius. Vesalius described in detail the anatomy of the brain and other organs; he had little knowledge of the brain's function, thinking that it resided mainly in the ventricles. Over his lifetime he corrected over 200 of Galen's mistakes. Understanding of medical sciences and diagnosis improved, but with little direct benefit to health care. Few effective drugs existed, beyond opium and quinine. Folklore cures and potentially poisonous metal-based compounds were popular treatments.\nIndependently from Ibn al-Nafis, Michael Servetus rediscovered the pulmonary circulation, but this discovery did not reach the public because it was written down for the first time in the \"Manuscript of Paris\" in 1546, and later published in the theological work which he paid with his life in 1553. Later this was perfected by Renaldus Columbus and Andrea Cesalpino. Later William Harvey correctly described the circulatory system. The most useful tomes in medicine used both by students and expert physicians were \"De Materia Medica\" and Pharmacopoeia.\nBacteria and protists were first observed with a microscope by Antonie van Leeuwenhoek in 1676, initiating the scientific field of microbiology.\n\nParacelsus (1493–1541), was an erratic and abusive innovator who rejected Galen and bookish knowledge, calling for experimental research, with heavy doses of mysticism, alchemy and magic mixed in. He rejected sacred magic (miracles) under Church auspisces and looked for cures in nature. He preached but he also pioneered the use of chemicals and minerals in medicine. His hermetical views were that sickness and health in the body relied on the harmony of man (microcosm) and Nature (macrocosm). He took an approach different from those before him, using this analogy not in the manner of soul-purification but in the manner that humans must have certain balances of minerals in their bodies, and that certain illnesses of the body had chemical remedies that could cure them. Most of his influence came after his death. Paracelsus is a highly controversial figure in the history of medicine, with most experts hailing him as a Father of Modern Medicine for shaking off religious orthodoxy and inspiring many researchers; others say he was a mystic more than a scientist and downplay his importance.\n\nUniversity training of physicians began in the 13th century.\n\nThe University of Padua was founded about 1220 by walkouts from the University of Bologna, and began teaching medicine in 1222. It played a leading role in the identification and treatment of diseases and ailments, specializing in autopsies and the inner workings of the body. Starting in 1595, Padua's famous anatomical theatre drew artists and scientists studying the human body during public dissections. The intensive study of Galen led to critiques of Galen modeled on his own writing, as in the first book of Vesalius's \"De humani corporis fabrica.\" Andreas Vesalius held the chair of Surgery and Anatomy (\"explicator chirurgiae\") and in 1543 published his anatomical discoveries in De Humani Corporis Fabrica. He portrayed the human body as an interdependent system of organ groupings. The book triggered great public interest in dissections and caused many other European cities to establish anatomical theatres.\n\nAt the University of Bologna the training of physicians began in 1219. The Italian city attracted students from across Europe. Taddeo Alderotti built a tradition of medical education that established the characteristic features of Italian learned medicine and was copied by medical schools elsewhere. Turisanus (d. 1320) was his student. The curriculum was revised and strengthened in 1560–1590. A representative professor was Julius Caesar Aranzi (Arantius) (1530–89). He became Professor of Anatomy and Surgery at the University of Bologna in 1556, where he established anatomy as a major branch of medicine for the first time. Aranzi combined anatomy with a description of pathological processes, based largely on his own research, Galen, and the work of his contemporary Italians. Aranzi discovered the 'Nodules of Aranzio' in the semilunar valves of the heart and wrote the first description of the superior levator palpebral and the coracobrachialis muscles. His books (in Latin) covered surgical techniques for many conditions, including hydrocephalus, nasal polyp, goitre and tumours to phimosis, ascites, haemorrhoids, anal abscess and fistulae.\n\nCatholic women played large roles in health and healing in medieval and early modern Europe. A life as a nun was a prestigious role; wealthy families provided dowries for their daughters, and these funded the convents, while the nuns provided free nursing care for the poor.\n\nThe Catholic elites provided hospital services because of their theology of salvation that good works were the route to heaven. The Protestant reformers rejected the notion that rich men could gain God's grace through good works—and thereby escape purgatory—by providing cash endowments to charitable institutions. They also rejected the Catholic idea that the poor patients earned grace and salvation through their suffering. Protestants generally closed all the convents and most of the hospitals, sending women home to become housewives, often against their will. On the other hand, local officials recognized the public value of hospitals, and some were continued in Protestant lands, but without monks or nuns and in the control of local governments.\n\nIn London, the crown allowed two hospitals to continue their charitable work, under nonreligious control of city officials. The convents were all shut down but Harkness finds that women—some of them former nuns—were part of a new system that delivered essential medical services to people outside their family. They were employed by parishes and hospitals, as well as by private families, and provided nursing care as well as some medical, pharmaceutical, and surgical services.\n\nMeanwhile, in Catholic lands such as France, rich families continued to fund convents and monasteries, and enrolled their daughters as nuns who provided free health services to the poor. Nursing was a religious role for the nurse, and there was little call for science.\n\nDuring the Age of Enlightenment, the 18th century, science was held in high esteem and physicians upgraded their social status by becoming more scientific. The health field was crowded with self-trained barber-surgeons, apothecaries, midwives, drug peddlers, and charlatans.\n\nAcross Europe medical schools relied primarily on lectures and readings. The final year student would have limited clinical experience by trailing the professor through the wards. Laboratory work was uncommon, and dissections were rarely done because of legal restrictions on cadavers. Most schools were small, and only Edinburgh, Scotland, with 11,000 alumni, produced large numbers of graduates.\n\nIn Britain, there were but three small hospitals after 1550. Pelling and Webster estimate that in London in the 1580 to 1600 period, out of a population of nearly 200,000 people, there were about 500 medical practitioners. Nurses and midwives are not included. There were about 50 physicians, 100 licensed surgeons, 100 apothecaries, and 250 additional unlicensed practitioners. In the last category about 25% were women. All across Britain—and indeed all of the world—the vast majority of the people in city, town or countryside depended for medical care on local amateurs with no professional training but with a reputation as wise healers who could diagnose problems and advise sick people what to do—and perhaps set broken bones, pull a tooth, give some traditional herbs or brews or perform a little magic to cure what ailed them.\n\nThe London Dispensary opened in 1696, the first clinic in the British Empire to dispense medicines to poor sick people. The innovation was slow to catch on, but new dispensaries were open in the 1770s. In the colonies, small hospitals opened in Philadelphia in 1752, New York in 1771, and Boston (Massachusetts General Hospital) in 1811.\n\nGuy's Hospital, the first great British hospital opened in 1721 in London, with funding from businessman Thomas Guy. In 1821 a bequest of £200,000 by William Hunt in 1829 funded expansion for an additional hundred beds. Samuel Sharp (1709–78), a surgeon at Guy's Hospital, from 1733 to 1757, was internationally famous; his \"A Treatise on the Operations of Surgery\" (1st ed., 1739), was the first British study focused exclusively on operative technique.\n\nEnglish physician Thomas Percival (1740–1804) wrote a comprehensive system of medical conduct, \"Medical Ethics; or, a Code of Institutes and Precepts, Adapted to the Professional Conduct of Physicians and Surgeons\" (1803) that set the standard for many textbooks.\n\nIn the Spanish Empire, the viceregal capital of Mexico City was a site of medical training for physicians and the creation of hospitals. Epidemic disease had decimated indigenous populations starting with the early sixteenth-century Spanish conquest of the Aztec empire, when a black auxiliary in the armed forces of conqueror Hernán Cortés, with an active case of smallpox, set off a virgin land epidemic among indigenous peoples, Spanish allies and enemies alike. Aztec emperor Cuitlahuac died of smallpox. Disease was a significant factor in the Spanish conquest elsewhere as well.\n\nMedical education instituted at the Royal and Pontifical University of Mexico chiefly served the needs of urban elites. Male and female \"curanderos\" or lay practitioners, attended to the ills of the popular classes. The Spanish crown began regulating the medical profession just a few years after the conquest, setting up the Royal Tribunal of the Protomedicato, a board for licensing medical personnel in 1527. Licensing became more systematic after 1646 with physicians, druggists, surgeons, and bleeders requiring a license before they could publicly practice. Crown regulation of medical practice became more general in the Spanish empire.\n\nElites and the popular classes alike called on divine intervention in personal and society-wide health crises, such as the epidemic of 1737. The intervention of the Virgin of Guadalupe was depicted in a scene of dead and dying Indians, with elites on their knees praying for her aid. In the late eighteenth century, the crown began implementing secularizing policies on the Iberian peninsula and its overseas empire to control disease more systematically and scientifically.\n\nThe practice of medicine changed in the face of rapid advances in science, as well as new approaches by physicians. Hospital doctors began much more systematic analysis of patients' symptoms in diagnosis. Among the more powerful new techniques were anaesthesia, and the development of both antiseptic and aseptic operating theatres. Effective cures were developed for certain endemic infectious diseases. However the decline in many of the most lethal diseases was due more to improvements in public health and nutrition than to advances in medicine.\n\nMedicine was revolutionized in the 19th century and beyond by advances in chemistry, laboratory techniques, and equipment. Old ideas of infectious disease epidemiology were gradually replaced by advances in bacteriology and virology.\n\nIn the 1830s in Italy, Agostino Bassi traced the silkworm disease muscardine to microorganisms. Meanwhile, in Germany, Theodor Schwann led research on alcoholic fermentation by yeast, proposing that living microorganisms were responsible.\nLeading chemists, such as Justus von Liebig, seeking solely physicochemical explanations, derided this claim and alleged that Schwann was regressing to vitalism.\n\nIn 1847 in Vienna, Ignaz Semmelweis (1818–1865), dramatically reduced the death rate of new mothers (due to childbed fever) by requiring physicians to clean their hands before attending childbirth, yet his principles were marginalized and attacked by professional peers. At that time most people still believed that infections were caused by foul odors called miasmas.\n\nEminent French scientist Louis Pasteur confirmed Schwann's fermentation experiments in 1857 and afterwards supported the hypothesis that yeast were microorganisms. Moreover, he suggested that such a process might also explain contagious disease. In 1860, Pasteur's report on bacterial fermentation of butyric acid motivated fellow Frenchman Casimir Davaine to identify a similar species (which he called \"bacteridia\") as the pathogen of the deadly disease anthrax. Others dismissed \"bacteridia\" as a mere byproduct of the disease. British surgeon Joseph Lister, however, took these findings seriously and subsequently introduced antisepsis to wound treatment in 1865.\n\nGerman physician Robert Koch, noting fellow German Ferdinand Cohn's report of a spore stage of a certain bacterial species, traced the life cycle of Davaine's \"bacteridia\", identified spores, inoculated laboratory animals with them, and reproduced anthrax—a breakthrough for experimental pathology and germ theory of disease. Pasteur's group added ecological investigations confirming spores' role in the natural setting, while Koch published a landmark treatise in 1878 on the bacterial pathology of wounds. In 1881, Koch reported discovery of the \"tubercle bacillus\", cementing germ theory and Koch's acclaim.\n\nUpon the outbreak of a cholera epidemic in Alexandria, Egypt, two medical missions went to investigate and attend the sick, one was sent out by Pasteur and the other led by Koch. Koch's group returned in 1883, having successfully discovered the cholera pathogen. In Germany, however, Koch's bacteriologists had to vie against Max von Pettenkofer, Germany's leading proponent of miasmatic theory. Pettenkofer conceded bacteria's casual involvement, but maintained that other, environmental factors were required to turn it pathogenic, and opposed water treatment as a misdirected effort amid more important ways to improve public health. The massive cholera epidemic in Hamburg in 1892 devastasted Pettenkoffer's position, and yielded German public health to \"Koch's bacteriology\".\n\nOn losing the 1883 rivalry in Alexandria, Pasteur switched research direction, and introduced his third vaccine—rabies vaccine—the first vaccine for humans since Jenner's for smallpox. From across the globe, donations poured in, funding the founding of Pasteur Institute, the globe's first biomedical institute, which opened in 1888. Along with Koch's bacteriologists, Pasteur's group—which preferred the term \"microbiology\"—led medicine into the new era of \"scientific medicine\" upon bacteriology and germ theory. Accepted from Jakob Henle, Koch's steps to confirm a species' pathogenicity became famed as \"Koch's postulates\". Although his proposed tuberculosis treatment, tuberculin, seemingly failed, it soon was used to test for infection with the involved species. In 1905, Koch was awarded the Nobel Prize in Physiology or Medicine, and remains renowned as the founder of medical microbiology.\n\nWomen had always served in ancillary roles, and as midwives and healers. The professionalization of medicine forced them increasingly to the sidelines. As hospitals multiplied they relied in Europe on orders of Roman Catholic nun-nurses, and German Protestant and Anglican deaconesses in the early 19th century. They were trained in traditional methods of physical care that involved little knowledge of medicine. The breakthrough to professionalization based on knowledge of advanced medicine was led by Florence Nightingale in England. She resolved to provide more advanced training than she saw on the Continent. At Kaiserswerth, where the first German nursing schools were founded in 1836 by Theodor Fliedner, she said, \"The nursing was nil and the hygiene horrible.\") Britain's male doctors preferred the old system, but Nightingale won out and her Nightingale Training School opened in 1860 and became a model. The Nightingale solution depended on the patronage of upper class women, and they proved eager to serve. Royalty became involved. In 1902 the wife of the British king took control of the nursing unit of the British army, became its president, and renamed it after herself as the Queen Alexandra's Royal Army Nursing Corps; when she died the next queen became president. Today its Colonel In Chief is Sophie, Countess of Wessex, the daughter-in-law of Queen Elizabeth II. In the United States, upper middle class women who already supported hospitals promoted nursing. The new profession proved highly attractive to women of all backgrounds, and schools of nursing opened in the late 19th century. They soon a function of large hospitals, where they provided a steady stream of low-paid idealistic workers. The International Red Cross began operations in numerous countries in the late 19th century, promoting nursing as an ideal profession for middle class women.\n\nThe Nightingale model was widely copied. Linda Richards (1841–1930) studied in London and became the first professionally trained American nurse. She established nursing training programs in the United States and Japan, and created the first system for keeping individual medical records for hospitalized patients. The Russian Orthodox Church sponsored seven orders of nursing sisters in the late 19th century. They ran hospitals, clinics, almshouses, pharmacies, and shelters as well as training schools for nurses. In the Soviet era (1917–1991), with the aristocratic sponsors gone, nursing became a low-prestige occupation based in poorly maintained hospitals.\n\nIt was very difficult for women to become doctors in any field before the 1970s. Elizabeth Blackwell (1821–1910) became the first woman to formally study and practice medicine in the United States. She was a leader in women's medical education. While Blackwell viewed medicine as a means for social and moral reform, her student Mary Putnam Jacobi (1842–1906) focused on curing disease. At a deeper level of disagreement, Blackwell felt that women would succeed in medicine because of their humane female values, but Jacobi believed that women should participate as the equals of men in all medical specialties using identical methods, values and insights. In the Soviet Union although the majority of medical doctors were women, they were paid less than the mostly male factory workers.\n\nParis (France) and Vienna were the two leading medical centers on the Continent in the era 1750–1914.\n\nIn the 1770s–1850s Paris became a world center of medical research and teaching. The \"Paris School\" emphasized that teaching and research should be based in large hospitals and promoted the professionalization of the medical profession and the emphasis on sanitation and public health. A major reformer was Jean-Antoine Chaptal (1756–1832), a physician who was Minister of Internal Affairs. He created the Paris Hospital, health councils, and other bodies.\nLouis Pasteur (1822–1895) was one of the most important founders of medical microbiology. He is remembered for his remarkable breakthroughs in the causes and preventions of diseases. His discoveries reduced mortality from puerperal fever, and he created the first vaccines for rabies and anthrax. His experiments supported the germ theory of disease. He was best known to the general public for inventing a method to treat milk and wine in order to prevent it from causing sickness, a process that came to be called pasteurization. He is regarded as one of the three main founders of microbiology, together with Ferdinand Cohn and Robert Koch. He worked chiefly in Paris and in 1887 founded the Pasteur Institute there to perpetuate his commitment to basic research and its practical applications. As soon as his institute was created, Pasteur brought together scientists with various specialties. The first five departments were directed by Emile Duclaux (general microbiology research) and Charles Chamberland (microbe research applied to hygiene), as well as a biologist, Ilya Ilyich Mechnikov (morphological microbe research) and two physicians, Jacques-Joseph Grancher (rabies) and Emile Roux (technical microbe research). One year after the inauguration of the Institut Pasteur, Roux set up the first course of microbiology ever taught in the world, then entitled \"Cours de Microbie Technique\" (Course of microbe research techniques). It became the model for numerous research centers around the world named \"Pasteur Institutes.\"\n\nThe First Viennese School of Medicine, 1750–1800, was led by the Dutchman Gerard van Swieten (1700–1772), who aimed to put medicine on new scientific foundations—promoting unprejudiced clinical observation, botanical and chemical research, and introducing simple but powerful remedies. When the Vienna General Hospital opened in 1784, it at once became the world's largest hospital and physicians acquired a facility that gradually developed into the most important research centre. Progress ended with the Napoleonic wars and the government shutdown in 1819 of all liberal journals and schools; this caused a general return to traditionalism and eclecticism in medicine.\n\nVienna was the capital of a diverse empire and attracted not just Germans but Czechs, Hungarians, Jews, Poles and others to its world-class medical facilities. After 1820 the Second Viennese School of Medicine emerged with the contributions of physicians such as Carl Freiherr von Rokitansky, Josef Škoda, Ferdinand Ritter von Hebra, and Ignaz Philipp Semmelweis. Basic medical science expanded and specialization advanced. Furthermore, the first dermatology, eye, as well as ear, nose, and throat clinics in the world were founded in Vienna. The textbook of ophthalmologist Georg Joseph Beer (1763–1821) \"Lehre von den Augenkrankheiten\" combined practical research and philosophical speculations, and became the standard reference work for decades.\n\nAfter 1871 Berlin, the capital of the new German Empire, became a leading center for medical research. Robert Koch (1843–1910) was a representative leader. He became famous for isolating \"Bacillus anthracis\" (1877), the \"Tuberculosis bacillus\" (1882) and \"Vibrio cholerae\" (1883) and for his development of Koch's postulates. He was awarded the Nobel Prize in Physiology or Medicine in 1905 for his tuberculosis findings. Koch is one of the founders of microbiology, inspiring such major figures as Paul Ehrlich and Gerhard Domagk.\n\nIn the American Civil War (1861–65), as was typical of the 19th century, more soldiers died of disease than in battle, and even larger numbers were temporarily incapacitated by wounds, disease and accidents. Conditions were poor in the Confederacy, where doctors and medical supplies were in short supply. The war had a dramatic long-term impact on medicine in the U.S., from surgical technique to hospitals to nursing and to research facilities. Weapon development -particularly the appearance of Springfield Model 1861, mass-produced and much more accurate than muskets led to generals underestimating the risks of long range rifle fire; risks exemplified in the death of John Sedgwick and the disastrous Pickett's Charge. The rifles could shatter bone forcing amputation and longer ranges meant casualties were sometimes not quickly found. Evacuation of the wounded from Second Battle of Bull Run took a week. As in earlier wars, untreated casualties sometimes survived unexpectedly due to maggots debriding the wound -an observation which led to the surgical use of maggots -still a useful method in the absence of effective antibiotics.\n\nThe hygiene of the training and field camps was poor, especially at the beginning of the war when men who had seldom been far from home were brought together for training with thousands of strangers. First came epidemics of the childhood diseases of chicken pox, mumps, whooping cough, and, especially, measles. Operations in the South meant a dangerous and new disease environment, bringing diarrhea, dysentery, typhoid fever, and malaria. There were no antibiotics, so the surgeons prescribed coffee, whiskey, and quinine. Harsh weather, bad water, inadequate shelter in winter quarters, poor policing of camps, and dirty camp hospitals took their toll.\n\nThis was a common scenario in wars from time immemorial, and conditions faced by the Confederate army were even worse. The Union responded by building army hospitals in every state. What was different in the Union was the emergence of skilled, well-funded medical organizers who took proactive action, especially in the much enlarged United States Army Medical Department, and the United States Sanitary Commission, a new private agency. Numerous other new agencies also targeted the medical and morale needs of soldiers, including the United States Christian Commission as well as smaller private agencies.\n\nThe U.S. Army learned many lessons and in August 1886, it established the Hospital Corps.\n\nA major breakthrough in epidemiology came with the introduction of statistical maps and graphs. They allowed careful analysis of seasonality issues in disease incidents, and the maps allowed public health officials to identify critical loci for the dissemination of disease. John Snow in London developed the methods. In 1849, he observed that the symptoms of cholera, which had already claimed around 500 lives within a month, were vomiting and diarrhoea. He concluded that the source of contamination must be through ingestion, rather than inhalation as was previously thought. It was this insight that resulted in the removal of The Pump On Broad Street, after which deaths from cholera plummeted afterwards. English nurse Florence Nightingale pioneered analysis of large amounts of statistical data, using graphs and tables, regarding the condition of thousands of patients in the Crimean War to evaluate the efficacy of hospital services. Her methods proved convincing and led to reforms in military and civilian hospitals, usually with the full support of the government.\n\nBy the late 19th and early 20th century English statisticians led by Francis Galton, Karl Pearson and Ronald Fisher developed the mathematical tools such as correlations and hypothesis tests that made possible much more sophisticated analysis of statistical data.\n\nDuring the U.S. Civil War the Sanitary Commission collected enormous amounts of statistical data, and opened up the problems of storing information for fast access and mechanically searching for data patterns. The pioneer was John Shaw Billings (1838–1913). A senior surgeon in the war, Billings built the Library of the Surgeon General's Office (now the National Library of Medicine), the centerpiece of modern medical information systems. Billings figured out how to mechanically analyze medical and demographic data by turning facts into numbers and punching the numbers onto cardboard cards that could be sorted and counted by machine. The applications were developed by his assistant Herman Hollerith; Hollerith invented the punch card and counter-sorter system that dominated statistical data manipulation until the 1970s. Hollerith's company became International Business Machines (IBM) in 1911.\n\nJohns Hopkins Hospital, founded in 1889, originated several modern medical practices, including residency and rounds.\n\nEuropean ideas of modern medicine were spread widely through the world by medical missionaries, and the dissemination of textbooks. Japanese elites enthusiastically embraced Western medicine after the Meiji Restoration of the 1860s. However they had been prepared by their knowledge of the Dutch and German medicine, for they had some contact with Europe through the Dutch. Highly influential was the 1765 edition of Hendrik van Deventer's pioneer work \"Nieuw Ligt\" (\"A New Light\") on Japanese obstetrics, especially on Katakura Kakuryo's publication in 1799 of \"Sanka Hatsumo\" (\"Enlightenment of Obstetrics\"). A cadre of Japanese physicians began to interact with Dutch doctors, who introduced smallpox vaccinations. By 1820 Japanese ranpô medical practitioners not only translated Dutch medical texts, they integrated their readings with clinical diagnoses. These men became leaders of the modernization of medicine in their country. They broke from Japanese traditions of closed medical fraternities and adopted the European approach of an open community of collaboration based on expertise in the latest scientific methods.\n\nKitasato Shibasaburō (1853–1931) studied bacteriology in Germany under Robert Koch. In 1891 he founded the Institute of Infectious Diseases in Tokyo, which introduced the study of bacteriology to Japan. He and French researcher Alexandre Yersin went to Hong Kong in 1894, where; Kitasato confirmed Yersin's discovery that the bacterium \"Yersinia pestis\" is the agent of the plague. In 1897 he isolates and described the organism that caused dysentery. He became the first dean of medicine at Keio University, and the first president of the Japan Medical Association.\n\nJapanese physicians immediately recognized the values of X-Rays. They were able to purchase the equipment locally from the Shimadzu Company, which developed, manufactured, marketed, and distributed X-Ray machines after 1900. Japan not only adopted German methods of public health in the home islands, but implemented them in its colonies, especially Korea and Taiwan, and after 1931 in Manchuria. A heavy investment in sanitation resulted in a dramatic increase of life expectancy.\n\nUntil the nineteenth century, the care of the insane was largely a communal and family responsibility rather than a medical one. The vast majority of the mentally ill were treated in domestic contexts with only the most unmanageable or burdensome likely to be institutionally confined. This situation was transformed radically from the late eighteenth century as, amid changing cultural conceptions of madness, a new-found optimism in the curability of insanity within the asylum setting emerged. Increasingly, lunacy was perceived less as a physiological condition than as a mental and moral one to which the correct response was persuasion, aimed at inculcating internal restraint, rather than external coercion. This new therapeutic sensibility, referred to as moral treatment, was epitomised in French physician Philippe Pinel's quasi-mythological unchaining of the lunatics of the Bicêtre Hospital in Paris and realised in an institutional setting with the foundation in 1796 of the Quaker-run York Retreat in England.\n\nFrom the early nineteenth century, as lay-led lunacy reform movements gained in influence, ever more state governments in the West extended their authority and responsibility over the mentally ill. Small-scale asylums, conceived as instruments to reshape both the mind and behaviour of the disturbed, proliferated across these regions. By the 1830s, moral treatment, together with the asylum itself, became increasingly medicalised and asylum doctors began to establish a distinct medical identity with the establishment in the 1840s of associations for their members in France, Germany, the United Kingdom and America, together with the founding of medico-psychological journals. Medical optimism in the capacity of the asylum to cure insanity soured by the close of the nineteenth century as the growth of the asylum population far outstripped that of the general population. Processes of long-term institutional segregation, allowing for the psychiatric conceptualisation of the natural course of mental illness, supported the perspective that the insane were a distinct population, subject to mental pathologies stemming from specific medical causes. As degeneration theory grew in influence from the mid-nineteenth century, heredity was seen as the central causal element in chronic mental illness, and, with national asylum systems overcrowded and insanity apparently undergoing an inexorable rise, the focus of psychiatric therapeutics shifted from a concern with treating the individual to maintaining the racial and biological health of national populations.\n\nEmil Kraepelin (1856–1926) introduced new medical categories of mental illness, which eventually came into psychiatric usage despite their basis in behavior rather than pathology or underlying cause. Shell shock among frontline soldiers exposed to heavy artillery bombardment was first diagnosed by British Army doctors in 1915. By 1916, similar symptoms were also noted in soldiers not exposed to explosive shocks, leading to questions as to whether the disorder was physical or psychiatric. In the 1920s surrealist opposition to psychiatry was expressed in a number of surrealist publications. In the 1930s several controversial medical practices were introduced including inducing seizures (by electroshock, insulin or other drugs) or cutting parts of the brain apart (leucotomy or lobotomy). Both came into widespread use by psychiatry, but there were grave concerns and much opposition on grounds of basic morality, harmful effects, or misuse.\n\nIn the 1950s new psychiatric drugs, notably the antipsychotic chlorpromazine, were designed in laboratories and slowly came into preferred use. Although often accepted as an advance in some ways, there was some opposition, due to serious adverse effects such as tardive dyskinesia. Patients often opposed psychiatry and refused or stopped taking the drugs when not subject to psychiatric control. There was also increasing opposition to the use of psychiatric hospitals, and attempts to move people back into the community on a collaborative user-led group approach (\"therapeutic communities\") not controlled by psychiatry. Campaigns against masturbation were done in the Victorian era and elsewhere. Lobotomy was used until the 1970s to treat schizophrenia. This was denounced by the anti-psychiatric movement in the 1960s and later.\n\nThe ABO blood group system was discovered in 1901, and the Rhesus blood group system in 1937, facilitating blood transfusion.\n\nDuring the 20th century, large-scale wars were attended with medics and mobile hospital units which developed advanced techniques for healing massive injuries and controlling infections rampant in battlefield conditions. During the Mexican Revolution (1910–1920), General Pancho Villa organized hospital trains for wounded soldiers. Boxcars marked \"Servicio Sanitario\" (\"sanitary service\") were re-purposed as surgical operating theaters and areas for recuperation, and staffed by up to 40 Mexican and U.S. physicians. Severely wounded soldiers were shuttled back to base hospitals. Canadian physician Norman Bethune, M.D. developed a mobile blood-transfusion service for frontline operations in the Spanish Civil War (1936–1939), but ironically, he himself died of blood poisoning.\nThousands of scarred troops provided the need for improved prosthetic limbs and expanded techniques in plastic surgery or reconstructive surgery. Those practices were combined to broaden cosmetic surgery and other forms of elective surgery.\n\nDuring the First World War, Alexis Carrel and Henry Dakin developed the Carrel-Dakin method of treating wounds with an irrigation, Dakin's solution, a germicide which helped prevent gangrene.\n\nThe Great War spurred the usage of Roentgen's X-ray, and the electrocardiograph, for the monitoring of internal bodily functions. This was followed in the inter-war period by the development of the first anti-bacterial agents such as the sulpha antibiotics.\n\nPublic health measures became particular important during the 1918 flu pandemic, which killed at least 50 million people around the world. It became an important case study in epidemiology. Bristow shows there was a gendered response of health caregivers to the pandemic in the United States. Male doctors were unable to cure the patients, and they felt like failures. Women nurses also saw their patients die, but they took pride in their success in fulfilling their professional role of caring for, ministering, comforting, and easing the last hours of their patients, and helping the families of the patients cope as well.\n\nFrom 1917 to 1923, the American Red Cross moved into Europe with a battery of long-term child health projects. It built and operated hospitals and clinics, and organized antituberculosis and antityphus campaigns. A high priority involved child health programs such as clinics, better baby shows, playgrounds, fresh air camps, and courses for women on infant hygiene. Hundreds of U.S. doctors, nurses, and welfare professionals administered these programs, which aimed to reform the health of European youth and to reshape European public health and welfare along American lines.\n\nThe advances in medicine made a dramatic difference for Allied troops, while the Germans and especially the Japanese and Chinese suffered from a severe lack of newer medicines, techniques and facilities. Harrison finds that the chances of recovery for a badly wounded British infantryman were as much as 25 times better than in the First World War. The reason was that:\n\nUnethical human subject research, and killing of patients with disabilities, peaked during the Nazi era, with Nazi human experimentation and Aktion T4 during the Holocaust as the most significant examples. Many of the details of these and related events were the focus of the Doctors' Trial. Subsequently, principles of medical ethics, such as the Nuremberg Code, were introduced to prevent a recurrence of such atrocities. After 1937, the Japanese Army established programs of biological warfare in China. In Unit 731, Japanese doctors and research scientists conducted large numbers of vivisections and experiments on human beings, mostly Chinese victims.\n\nStarting in World War II, DDT was used as insecticide to combat insect vectors carrying malaria, which was endemic in most tropical regions of the world. The first goal was to protect soldiers, but it was widely adopted as a public health device. In Liberia, for example, the United States had large military operations during the war and the U.S. Public Health Service began the use of DDT for indoor residual spraying (IRS) and as a larvicide, with the goal of controlling malaria in Monrovia, the Liberian capital. In the early 1950s, the project was expanded to nearby villages. In 1953, the World Health Organization (WHO) launched an antimalaria program in parts of Liberia as a pilot project to determine the feasibility of malaria eradication in tropical Africa. However these projects encountered a spate of difficulties that foreshadowed the general retreat from malaria eradication efforts across tropical Africa by the mid-1960s.\n\nThe World Health Organization was founded in 1948 as a United Nations agency to improve global health. In most of the world, life expectancy has improved since then, and was about 67 years , and well above 80 years in some countries. Eradication of infectious diseases is an international effort, and several new vaccines have been developed during the post-war years, against infections such as measles, mumps, several strains of influenza and human papilloma virus. The long-known vaccine against Smallpox finally eradicated the disease in the 1970s, and Rinderpest was wiped out in 2011. Eradication of polio is underway. Tissue culture is important for development of vaccines. Though the early success of antiviral vaccines and antibacterial drugs, antiviral drugs were not introduced until the 1970s. Through the WHO, the international community has developed a response protocol against epidemics, displayed during the SARS epidemic in 2003, the Influenza A virus subtype H5N1 from 2004, the Ebola virus epidemic in West Africa and onwards.\n\nAs infectious diseases have become less lethal, and the most common causes of death in developed countries are now tumors and cardiovascular diseases, these conditions have received increased attention in medical research. Tobacco smoking as a cause of lung cancer was first researched in the 1920s, but was not widely supported by publications until the 1950s. Cancer treatment has been developed with radiotherapy, chemotherapy and surgical oncology.\n\nOral rehydration therapy has been extensively used since the 1970s to treat cholera and other diarrhea-inducing infections.\n\nThe sexual revolution included taboo-breaking research in human sexuality such as the 1948 and 1953 Kinsey reports, invention of hormonal contraception, and the normalization of abortion and homosexuality in many countries. Family planning has promoted a demographic transition in most of the world. With threatening sexually transmitted infections, not least HIV, use of barrier contraception has become imperative. The struggle against HIV has improved antiretroviral treatments.\n\nX-ray imaging was the first kind of medical imaging, and later ultrasonic imaging, CT scanning, MR scanning and other imaging methods became available.\n\nGenetics have advanced with the discovery of the DNA molecule, genetic mapping and gene therapy. Stem cell research took off in the 2000s (decade), with stem cell therapy as a promising method.\n\nEvidence-based medicine is a modern concept, not introduced to literature until the 1990s.\n\nProsthetics have improved. In 1958, Arne Larsson in Sweden became the first patient to depend on an artificial cardiac pacemaker. He died in 2001 at age 86, having outlived its inventor, the surgeon, and 26 pacemakers. Lightweight materials as well as neural prosthetics emerged in the end of the 20th century.\n\nCardiac surgery was revolutionized in 1948 as open-heart surgery was introduced for the first time since 1925.\n\nIn 1954 Joseph Murray, J. Hartwell Harrison and others accomplished the first kidney transplantation. Transplantations of other organs, such as heart, liver and pancreas, were also introduced during the later 20th century. The first partial face transplant was performed in 2005, and the first full one in 2010. By the end of the 20th century, microtechnology had been used to create tiny robotic devices to assist microsurgery using micro-video and fiber-optic cameras to view internal tissues during surgery with minimally invasive practices.\n\nLaparoscopic surgery was broadly introduced in the 1990s. Natural orifice surgery has followed. Remote surgery is another recent development, with the Lindbergh operation in 2001 as a groundbreaking example.\n\n\n\n\n\n\n"}
{"id": "14196", "url": "https://en.wikipedia.org/wiki?curid=14196", "title": "Hamoaze", "text": "Hamoaze\n\nThe Hamoaze (; ) is an estuarine stretch of the tidal River Tamar, between its confluence with the River Lynher and Plymouth Sound, England.\n\nThe name first appears as \"ryver of Hamose\" in 1588 and it originally most likely applied just to a creek of the estuary that led up to the manor of Ham, north of the present-day Devonport Dockyard. The name evidently later came to be used for the estuary's main channel. The \"ose\" element possibly derives from Old English \"wāse\" meaning 'mud' (as in 'ooze') – the creek consisting of mud-banks at low tide.\n\nThe Hamoaze flows past Devonport Dockyard, which is one of three major bases of the Royal Navy today. The presence of large numbers of small watercraft are a challenge and hazard to the warships using the naval base and dockyard. Navigation on the waterway is controlled by the Queen's Harbour Master for Plymouth.\n\nSettlements on the banks of the Hamoaze are Saltash, Wilcove, Torpoint and Cremyll in Cornwall, as well as Devonport and Plymouth in Devon.\n\nTwo regular ferry services crossing the Hamoaze exist: the Torpoint Ferry (a chain ferry that takes vehicles) and the Cremyll Ferry (passengers and cyclists only).\n"}
{"id": "14197", "url": "https://en.wikipedia.org/wiki?curid=14197", "title": "Hanover", "text": "Hanover\n\nHanover or Hannover (; ; ) is the capital and largest city of the German state of Lower Saxony. Its 535,061 (2017) inhabitants make it the thirteenth-largest city of Germany, as well as the third-largest city of Northern Germany after Hamburg and Bremen. The city lies at the confluence of the River Leine (progression: ) and its tributary Ihme, in the south of the North German Plain, and is the largest city of the Hannover–Braunschweig–Göttingen–Wolfsburg Metropolitan Region. It is the fifth-largest city in the Low German dialect area after Hamburg, Dortmund, Essen, and Bremen.\n\nBefore it became the capital of Lower Saxony in 1946, Hanover was the capital of the Principality of Calenberg (1636–1692), the Electorate of Brunswick-Lüneburg (1692–1814), the Kingdom of Hanover (1814–1866), the Province of Hanover of the Kingdom of Prussia (1868–1918), the Province of Hanover of the Free State of Prussia (1918–1946), and of the State of Hanover (1946). From 1714 to 1837, Hanover was by personal union the family seat of the Hanoverian Kings of the United Kingdom of Great Britain and Ireland, under their title of the dukes of Brunswick-Lüneburg (later described as the Elector of Hanover).\n\nThe city is a major crossing point of railway lines and highways (Autobahnen), connecting European main lines in both the east-west (Berlin–Ruhr area/Düsseldorf/Cologne) and north-south (Hamburg–Frankfurt/Stuttgart/Munich) directions. Hannover Airport lies north of the city, in Langenhagen, and is Germany's ninth-busiest airport. The city's most notable institutions of higher education are the Hannover Medical School with its university hospital (Klinikum der Medizinischen Hochschule Hannover), and the University of Hanover.\n\nThe Hanover fairground, due to numerous extensions, especially for the Expo 2000, is the largest in the world. Hanover hosts annual commercial trade fairs such as the Hanover Fair and up to 2018 the CeBIT. The IAA Commercial Vehicles show takes place every two years. It is the world's leading trade show for transport, logistics and mobility. Every year Hanover hosts the Schützenfest Hannover, the world's largest marksmen's festival, and the Oktoberfest Hannover.\n\n\"Hanover\" is the traditional English spelling. The German spelling (with a double n) is becoming more popular in English; recent editions of encyclopedias prefer the German spelling, and the local government uses the German spelling on English websites. The English pronunciation, with stress on the first syllable, is applied to both the German and English spellings, which is different from German pronunciation, with stress on the second syllable and a long second vowel. The traditional English spelling is still used in historical contexts, especially when referring to the British House of Hanover.\n\nHanover was founded in medieval times on the east bank of the River Leine. Its original name \"Honovere\" may mean \"high (river)bank\", though this is debated (cf. \"das Hohe Ufer\"). Hanover was a small village of ferrymen and fishermen that became a comparatively large town in the 13th century, receiving town privileges in 1241, due to its position at a natural crossroads. As overland travel was relatively difficult, its position on the upper navigable reaches of the river helped it to grow by increasing trade. It was connected to the Hanseatic League city of Bremen by the Leine, and was situated near the southern edge of the wide North German Plain and north-west of the Harz mountains, so that east-west traffic such as mule trains passed through it. Hanover was thus a gateway to the Rhine, Ruhr and Saar river valleys, their industrial areas which grew up to the southwest and the plains regions to the east and north, for overland traffic skirting the Harz between the Low Countries and Saxony or Thuringia.\n\nIn the 14th century the main churches of Hanover were built, as well as a city wall with three city gates. The beginning of industrialization in Germany led to trade in iron and silver from the northern Harz Mountains, which increased the city's importance.\n\nIn 1636 George, Duke of Brunswick-Lüneburg, ruler of the Brunswick-Lüneburg principality of Calenberg, moved his residence to Hanover. The Dukes of Brunswick-Lüneburg was elevated by the Holy Roman Emperor to the rank of Prince-Elector in 1692, and this elevation was confirmed by the Imperial Diet in 1708. Thus the principality was upgraded to the Electorate of Brunswick-Lüneburg, colloquially known as the Electorate of Hanover after Calenberg's capital (see also: House of Hanover). Its Electors later become monarchs of Great Britain (and from 1801, of the United Kingdom of Great Britain and Ireland). The first of these was George I Louis, who acceded to the British throne in 1714. The last British monarch who reigned in Hanover was William IV. Semi-Salic law, which required succession by the male line if possible, forbade the accession of Queen Victoria in Hanover. As a male-line descendant of George I, Queen Victoria was herself a member of the House of Hanover. Her descendants, however, bore her husband's titular name of Saxe-Coburg-Gotha. Three kings of Great Britain, or the United Kingdom, were concurrently also Electoral Princes of Hanover.\n\nDuring the time of the personal union of the crowns of the United Kingdom and Hanover (1714–1837), the monarchs rarely visited the city. In fact, during the reigns of the final three joint rulers (1760–1837), there was only one short visit, by George IV in 1821. From 1816 to 1837 Viceroy Adolphus represented the monarch in Hanover.\n\nDuring the Seven Years' War, the Battle of Hastenbeck was fought near the city on 26 July 1757. The French army defeated the Hanoverian Army of Observation, leading to the city's occupation as part of the Invasion of Hanover. It was recaptured by Anglo-German forces led by Ferdinand of Brunswick the following year.\n\nAfter Napoleon imposed the Convention of Artlenburg (Convention of the Elbe) on July 5, 1803, about 35,000 French soldiers occupied Hanover. The Convention also required disbanding the army of Hanover. However, George III did not recognize the Convention of the Elbe. This resulted in a great number of soldiers from Hanover eventually emigrating to Great Britain, where the King's German Legion was formed. It was only troops from Hanover and Brunswick that consistently opposed France throughout the entire Napoleonic wars. The Legion later played an important role in the Battle of Waterloo in 1815. The Congress of Vienna in 1815 elevated the electorate to the Kingdom of Hanover. The capital town Hanover expanded to the western bank of the Leine and since then has grown considerably.\n\nIn 1837, the personal union of the United Kingdom and Hanover ended because William IV's heir in the United Kingdom was female (Queen Victoria). Hanover could be inherited only by male heirs. Thus, Hanover passed to William IV's brother, Ernest Augustus, and remained a kingdom until 1866, when it was annexed by Prussia during the Austro-Prussian war. Despite Hanover being expected to defeat Prussia at the Battle of Langensalza, Prussia employed Moltke the Elder's Kesselschlacht order of battle to instead destroy the Hanoverian army. The city of Hanover became the capital of the Prussian Province of Hanover. After the annexation, the people of Hanover generally opposed the Prussian government.\n\nTo Hanover's industry, however, the new connection with Prussia meant an improvement in business. The introduction of free trade promoted economic growth and led to the recovery of the Gründerzeit (the founders' era). Between 1879 and 1902 Hanover's population grew from 87,600 to 313,940. \n\nIn 1842 the first horse railway was inaugurated, and from 1893 an electric tram was installed. In 1887 Hanover's Emile Berliner invented the record and the gramophone.\n\nAfter 1937 the Lord Mayor and the state commissioners of Hanover were members of the NSDAP (Nazi party). A large Jewish population then existed in Hanover. In October 1938, 484 Hanoverian Jews of Polish origin were expelled to Poland, including the Grynszpan family. However, Poland refused to accept them, leaving them stranded at the border with thousands of other Polish-Jewish deportees, fed only intermittently by the Polish Red Cross and Jewish welfare organisations. The Grynszpans' son Herschel Grynszpan was in Paris at the time. When he learned of what was happening, he drove to the German embassy in Paris and shot the German diplomat Eduard Ernst vom Rath, who died shortly afterwards.\n\nThe Nazis took this act as a pretext to stage a nationwide pogrom known as Kristallnacht (9 November 1938). On that day, the synagogue of Hanover, designed in 1870 by Edwin Oppler in neo-romantic style, was burnt by the Nazis.\n\nIn September 1941, through the \"Action Lauterbacher\" plan, a ghettoisation of the remaining Hanoverian Jewish families began. Even before the Wannsee Conference, on 15 December 1941, the first Jews from Hanover were deported to Riga. A total of 2,400 people were deported, and very few survived. During the war seven concentration camps were constructed in Hanover, in which many Jews were confined. Of the approximately 4,800 Jews who had lived in Hannover in 1938, fewer than 100 were still in the city when troops of the United States Army arrived on 10 April 1945 to occupy Hanover at the end of the war. Today, a memorial at the Opera Square is a reminder of the persecution of the Jews in Hanover. \nAfter the war a large group of Orthodox Jewish survivors of the nearby Bergen-Belsen concentration camp settled in Hanover.\nAs an important railroad and road junction and production centre, Hanover was a major target for strategic bombing during World War II, including the Oil Campaign. Targets included the AFA (Stöcken), the Deurag-Nerag refinery (Misburg), the Continental plants (Vahrenwald and Limmer), the United light metal works (VLW) in Ricklingen and Laatzen (today Hanover fairground), the Hanover/Limmer rubber reclamation plant, the Hanomag factory (Linden) and the tank factory \"M.N.H. Maschinenfabrik Niedersachsen\" (Badenstedt). Residential areas were also targeted, and more than 6,000 civilians were killed by the Allied bombing raids. More than 90% of the city centre was destroyed in a total of 88 bombing raids. After the war, the Aegidienkirche was not rebuilt and its ruins were left as a war memorial.\n\nThe Allied ground advance into Germany reached Hanover in April 1945. The US 84th Infantry Division captured the city on 10 April 1945.\n\nHanover was in the British zone of occupation of Germany and became part of the new state (Land) of Lower Saxony in 1946.\n\nToday Hanover is a Vice-President City of Mayors for Peace, an international mayoral organisation mobilising cities and citizens worldwide to abolish and eliminate nuclear weapons by the year 2020.\n\nHannover has an oceanic climate (Köppen: \"Cfb\") independent of the isotherm. Although the city is not on a coastal location, the predominant air masses are still from the ocean, unlike other places further east or south-central Germany.\n\n\n\nOne of Hanover's most famous sights is the \"Royal Gardens of Herrenhausen\". Its \"Great Garden\" is an important European baroque garden. The palace itself was largely destroyed by Allied bombing but has been reconstructed and reopened in 2013. Among the points of interest is the \"Grotto\". Its interior was designed by the French artist Niki de Saint Phalle). The Great Garden consists of several parts and contains Europe's highest garden fountain. The historic \"Garden Theatre\" hosted the musicals of the German rock musician Heinz Rudolf Kunze.\n\nAlso at Herrenhausen, the \"Berggarten\" is a botanical garden with the most varied collection of orchids in Europe. Some points of interest are the \"Tropical House\", the \"Cactus House\", the \"Canary House\" and the \"Orchid House\", and free-flying birds and butterflies. Near the entrance to the Berggarten is the historic \"Library Pavillon\". The \"Mausoleum\" of the Guelphs is also located in the Berggarten. Like the Great Garden, the Berggarten also consists of several parts, for example the \"Paradies\" and the \"Prairie Garden\". The \"Georgengarten\" is an English landscape garden. The \"Leibniz Temple\" and the \"Georgen Palace\" are two points of interest there.\n\nThe landmark of Hanover is the New Town Hall (\"Neues Rathaus\"). Inside the building are four scale models of the city. A worldwide unique diagonal/arch elevator goes up the large dome at a 17 degree angle to an observation deck.\n\nThe \"Hanover Zoo\" received the Park Scout Award for the fourth year running in 2009/10, placing it among the best zoos in Germany. The zoo consists of several theme areas: Sambesi, Meyers Farm, Gorilla-Mountain, Jungle-Palace, and Mullewapp. Some smaller areas are Australia, the wooded area for wolves, and the so-called swimming area with many seabirds. There is also a tropical house, a jungle house, and a show arena. The new Canadian-themed area, Yukon Bay, opened in 2010. In 2010 the Hanover Zoo had over 1.6 million visitors. There is also the \"Sea Life Centre Hanover\", which is the first tropical aquarium in Germany.\n\nAnother point of interest is the \"Old Town\". In the centre are the large Marktkirche (Church St. Georgii et Jacobi, preaching venue of the bishop of the Lutheran Landeskirche Hannovers) and the \"Old Town Hall\". Nearby are the \"Leibniz House\", the \"Nolte House\", and the \"Beguine Tower\". The \"Kreuz-Church-Quarter\" around the \"Kreuz Church\" contains many little lanes. Nearby is the old royal sports hall, now called the \"Ballhof\" theatre. On the edge of the Old Town are the \"Market Hall\", the \"Leine Palace\", and the ruin of the \"Aegidien Church\" which is now a monument to the victims of war and violence. Through the \"Marstall Gate\" the bank of the river \"Leine\" can be reached; the \"Nanas\" of Niki de Saint Phalle are located here. They are part of the \"Mile of Sculptures\", which starts from Trammplatz, leads along the river bank, crosses Königsworther Square, and ends at the entrance of the Georgengarten. Near the Old Town is the district of Calenberger Neustadt where the Catholic Basilica Minor of \"St. Clemens\", the \"Reformed Church\" and the Lutheran Neustädter Hof- und Stadtkirche St. Johannis are located.\n\nSome other popular sights are the \"Waterloo Column\", the \"Laves House\", the \"Wangenheim Palace\", the \"Lower Saxony State Archives\", the \"Hanover Playhouse\", the \"Kröpcke Clock\", the \"Anzeiger Tower Block\", the \"Administration Building of the NORD/LB\", the \"Cupola Hall\" of the Congress Centre, the \"Lower Saxony Stock\", the \"Ministry of Finance\", the \"Garten Church\", the \"Luther Church\", the \"Gehry Tower\" (designed by the American architect Frank O. Gehry), the specially designed \"Bus Stops\", the \"Opera House\", \"the Central Station\", the \"Maschsee\" lake and the city forest \"Eilenriede\", which is one of the largest of its kind in Europe. With around 40 parks, forests and gardens, a couple of lakes, two rivers and one canal, Hanover offers a large variety of leisure activities.\n\nSince 2007 the historic \"Leibniz Letters\", which can be viewed in the \"Gottfried Wilhelm Leibniz Library\", are on UNESCO's Memory of the World Register.\n\nOutside the city centre is the \"EXPO-Park\", the former site of EXPO 2000. Some points of interest are the \"Planet M.\", the former \"German Pavillon\", some nations' vacant pavilions, the \"Expowale\", the \"EXPO-Plaza\" and the \"EXPO-Gardens\" (Parc Agricole, EXPO-Park South and the Gardens of change). The fairground can be reached by the \"Exponale\", one of the largest pedestrian bridges in Europe.\n\nThe \"Hanover fairground\" is the largest exhibition centre in the world.\nIt provides 496,000 square metres of covered indoor space, 58,000 square metres of open-air space, 27 halls and pavilions. Many of the Exhibition Centre's halls are architectural highlights. Furthermore, it offers the Convention Center with its 35 function rooms, glassed-in areas between halls, grassy park-like recreation zones and its own heliport. Two important sights on the fairground are the \"Hermes Tower\" (88.8 metres high) and the \"EXPO Roof\", the largest wooden roof in the world.\n\nIn the district of Anderten is the \"European Cheese Centre\", the only Cheese Experience Centre in Europe. Another tourist sight in Anderten is the \"Hindenburg Lock\", which was the biggest lock in Europe at the time of its construction in 1928. The \"Tiergarten\" (literally the \"animals' garden\") in the district of Kirchrode is a large forest originally used for deer and other game for the king's table.\n\nIn the district of Groß-Buchholz the 282-metre-high \"Telemax\" is located, which is the tallest building in Lower Saxony and the highest television tower in Northern Germany. Some other notable towers are the \"VW-Tower\" in the city centre and the old towers of the former middle-age defence belt: \"Döhrener Tower\", \"Lister Tower\" and the \"Horse Tower\".\n\nThe 36 most important sights of the city centre are connected with a -long red line, which is painted on the pavement. This so-called \"Red Thread\" marks out a walk that starts at the Tourist Information Office and ends on the Ernst-August-Square in front of the central station. There is also a guided sightseeing-bus tour through the city.\n\nHanover is headquarters for several Protestant organizations, including the World Communion of Reformed Churches, the Evangelical Church in Germany, the Reformed Alliance, the United Evangelical Lutheran Church of Germany, and the Independent Evangelical-Lutheran Church.\n\nIn 2015, 31.1% of the population were Protestant and 13.4% were Roman Catholic. The majority 55.5% were irreligious or other faith.\n\nThe \"Historic Museum\" describes the history of Hanover, from the medieval settlement \"Honovere\" to the world-famous Exhibition City of today. The museum focuses on the period from 1714 to 1834 when Hanover had a strong relationship with the British royal house.\n\nWith more than 4,000 members, the \"Kestnergesellschaft\" is the largest art society in Germany. The museum hosts exhibitions from classical modernist art to contemporary art. One big focus is put on film, video, contemporary music and architecture, room installments and big presentations of contemporary paintings, sculptures and video art.\n\nThe \"Kestner-Museum\" is located in the \"House of 5.000 windows\". The museum is named after August Kestner and exhibits 6,000 years of applied art in four areas: Ancient cultures, ancient Egypt, applied art and a valuable collection of historic coins.\n\nThe \"KUBUS\" is a forum for contemporary art. It features mostly exhibitions and projects of famous and important artists from Hanover.\n\nThe \"Kunstverein Hannover\" (Art Society Hanover) shows contemporary art and was established in 1832 as one of the first art societies in Germany. It is located in the \"Künstlerhaus\" (House of artists). There are around 7 international monografic and thematic Exhibitions in one year.\n\nThe \"Lower Saxony State Museum\" is the largest museum in Hanover. The \"State Gallery\" shows the European Art from the 11th to the 20th century, the \"Nature Department\" shows the zoology, geology, botanic, geology and a \"Vivarium\" with fishes, insects, reptiles and amphibians. The \"Primeval Department\" shows the primeval history of Lower Saxony and the \"Folklore Department\" shows the cultures from all over the world.\n\nThe \"Sprengel Museum\" shows the art of the 20th century. It is one of the most notable art museums in Germany. The focus is put on the classical modernist art with the collection of \"Kurt Schwitters\", works of German expressionism, and French cubism, the cabinet of abstracts, the graphics and the department of photography and media. Furthermore, the museum shows the famous works of the French artist Niki de Saint-Phalle.\n\nThe \"Theatre Museum\" shows an exhibition of the history of the theatre in Hanover from the 17th century up to now: opera, concert, drama and ballet. The museum also hosts several touring exhibitions during the year.\n\nThe \"Wilhelm Busch Museum\" is the \"German Museum of Caricature and Critical Graphic Arts\". The collection of the works of Wilhelm Busch and the extensive collection of cartoons and critical graphics is this museum unique in Germany. Furthermore, the museum hosts several exhibitions of national and international artists during the year.\n\nA cabinet of coins is the \"Münzkabinett der TUI-AG\". The \"Polizeigeschichtliche Sammlung Niedersachsen\" is the largest police museum in Germany. Textiles from all over the world can be visited in the \"Museum for textile art\". The \"EXPOseeum\" is the museum of the world-exhibition \"EXPO 2000 Hannover\". Carpets and objects from the orient can be visited in the \"Oriental Carpet Museum\". The \"Blind Man Museum\" is a rarity in Germany, another one is only in Berlin. The \"Museum of veterinary medicine\" is unique in Germany. The \"Museum for Energy History\" describes the 150 years old history of the application of energy. The \"Home Museum Ahlem\" shows the history of the district of Ahlem. The \"Mahn- und Gedenkstätte Ahlem\" describes the history of the Jewish people in Hanover and the \"Stiftung Ahlers Pro Arte / Kestner Pro Arte\" shows modern art. Modern art is also the main topic of the \"Kunsthalle Faust\", the \"Nord/LB Art Gellery\" and of the \"Foro Artistico / Eisfabrik\".\n\nSome leading art events in Hanover are the \"Long Night of the museums\" and the \"Zinnober Kunstvolkslauf\" which features all the galleries in Hanover.\n\nPeople who are interested in astronomy should visit the \"Observatory Geschwister Herschel\" on the Lindener Mountain or the small planetarium inside of the Bismarck School.\n\nAround 40 theatres are located in Hanover. The \"Opera House\", the \"Schauspielhaus\" (Play House), the \"Ballhof eins\", the \"Ballhof zwei\" and the \"Cumberlandsche Galerie\" belong to the \"Lower Saxony State Theatre\". The \"Theater am Aegi\" is Hanover's big theatre for musicals, shows and guest performances. The \"Neues Theater\" (New Theatre) is the boulevard theatre of Hanover. The \"Theater für Niedersachsen\" is another big theatre in Hanover, which also has an own musical company. Some of the most important musical productions are the rock musicals of the German rock musician Heinz Rudolph Kunze, which take place at the \"Garden-Theatre\" in the Great Garden.\n\nSome important theatre-events are the \"Tanztheater International\", the \"Long Night of the Theatres\", the \"Festival Theaterformen\" and the \"International Competition for Choreographs\".\n\nHanover's leading cabaret-stage is the \"GOP Variety theatre\" which is located in the \"Georgs Palace\". Some other famous cabaret-stages are the \"Variety Marlene\", the \"Uhu-Theatre\". the theatre \"Die Hinterbühne\", the \"Rampenlich Variety\" and the revue-stage \"TAK\". The most important cabaret event is the \"Kleines Fest im Großen Garten\" (Little Festival in the Great Garden) which is the most successful cabaret festival in Germany. It features artists from around the world. Some other important events are the \"Calenberger Cabaret Weeks\", the \"Hanover Cabaret Festival\" and the \"Wintervariety\".\n\nHanover has two symphony orchestras: The Lower Saxon State Orchestra Hanover and the NDR Radiophilharmonie (North German Radio Philharmonic Orchestra). Two notable choirs have their homes in Hanover: the Girls Choir Hanover (Mädchenchor Hannover) and the Knabenchor Hannover (Boys Choir Hanover).\n\nThere are/were two big international competitions for classical music in Hanover:\n\nThe rock bands Scorpions and Fury in the Slaughterhouse are originally from Hanover. Acclaimed DJ Mousse T also has his main recording studio in the area. Rick J. Jordan, member of the band Scooter was born here in 1968. Eurovision Song Contest winner of 2010, Lena, is also from Hanover.\n\nHannover 96 (nickname \"Die Roten\" or 'The Reds') is the top local football team that is again playing in the Bundesliga top division after being relegated to the 2. Bundesliga after the 2015–16 season. Home games are played at the HDI-Arena, which hosted matches in the 1974 and 2006 World Cups and the Euro 1988. Their reserve team Hannover 96 II plays in the fourth league. Their home games were played in the traditional Eilenriedestadium till they moved to the HDI Arena due to DFL directives. Arminia Hannover is another traditional soccer team in Hanover that has played in the first league for years and plays now in the Niedersachsen-West Liga (Lower Saxony League West). Home matches are played in the Rudolf-Kalweit-Stadium.\n\nThe Hannover Indians are the local ice hockey team. They play in the third tier. Their home games are played at the traditional Eisstadion am Pferdeturm. The Hannover Scorpions played in Hanover in Germany's top league until 2013 when they sold their license and moved to Langenhagen.\n\nHanover was one of the rugby union capitals in Germany. The first German rugby team was founded in Hanover in 1878. Hanover-based teams dominated the German rugby scene for a long time. DRC Hannover plays in the first division, and \"SV Odin von 1905\" as well as SG 78/08 Hannover play in the second division.\n\nThe first German fencing club was founded in Hanover in 1862. Today there are three additional fencing clubs in Hanover.\n\nThe Hannover Korbjäger are the city's top basketball team. They play their home games at the IGS Linden.\n\nHanover is a centre for water sports. Thanks to the Maschsee lake, the rivers Ihme and Leine and to the Mittellandkanal channel, Hanover hosts sailing schools, yacht schools, waterski clubs, rowing clubs, canoe clubs and paddle clubs. The water polo team WASPO W98 plays in the first division.\n\nThe Hannover Regents play in the third Bundesliga (baseball) division. The Hannover Grizzlies, Armina Spartans and Hannover Stampeders are the local American football teams.\n\nThe Hannover Marathon is the biggest running event in Hanover with more than 11,000 participants and usually around 200.000 spectators. Some other important running events are the Gilde Stadtstaffel (relay), the Sport-Check Nachtlauf (night-running), the Herrenhäuser Team-Challenge, the Hannoversche Firmenlauf (company running) and the Silvesterlauf (sylvester running).\n\nHanover also hosts an important international cycle race: The \"Nacht von Hannover\" (night of Hanover). The race takes place around the Market Hall.\n\nThe lake Maschsee hosts the International Dragon Boat Races and the Canoe Polo-Tournament. Many regattas take place during the year. \"Head of the river Leine\" on the river Leine is one of the biggest rowing regattas in Hanover. One of Germany's most successful dragon boat teams, the All Sports Team Hannover, which has won since its foundation in year 2000 more than 100 medals on national and international competitions, is doing practising on the Maschsee in the heart of Hannover. The All Sports Team has received the award \"Team of the Year 2013\" in Lower Saxony.\n\nSome other important sport events are the Lower Saxony Beach Volleyball Tournament, the international horse show \"German Classics\" and the international ice hockey tournament Nations Cup.\n\nHanover is one of the leading exhibition cities in the world. It hosts more than 60 international and national exhibitions every year. The most popular ones are the \"CeBIT\", the \"Hanover Fair\", the \"Domotex\", the \"Ligna\", the \"IAA Nutzfahrzeuge\" and the \"Agritechnica\". Hanover also hosts a huge number of congresses and symposiums like the \"International Symposium on Society and Resource Management.\"\n\nHanover is also host to the \"Schützenfest Hannover,\" the largest marksmen's fun fair in the world which takes place once a year (late June to early July) (2014 − July 4th to the 13th). Founded in 1529, it consists of more than 260 rides and inns, five large beer tents and a big entertainment programme. The highlight of this fun fair is the long \"Parade of the Marksmen\" with more than 12,000 participants from all over the world, including around 5,000 marksmen, 128 bands, and more than 70 wagons, carriages, and other festival vehicles. This makes it the longest procession in Europe. Around 2 million people visit this fun fair every year. The landmark of this fun fair is the biggest transportable Ferris wheel in the world, about ( high). \n\nHanover also hosts one of the two largest spring festivals in Europe, with around 180 rides and inns, 2 large beer tents, and around 1.5 million visitors each year. The Oktoberfest Hannover is the second largest Oktoberfest in the world with around 160 rides and inns, two large beer tents and around 1 million visitors each year.\n\nThe \"Maschsee Festival\" takes place around the Maschsee Lake. Each year around 2 million visitors come to enjoy live music, comedy, cabaret, and much more. It is the largest Volksfest of its kind in Northern Germany. The Great Garden hosts every year the \"International Fireworks Competition\", and the \"International Festival Weeks Herrenhausen,\" with music and cabaret performances. The \"Carnival Procession\" is around long and consists of 3.000 participants, around 30 festival vehicles and around 20 bands and takes place every year.\n\nOther festivals include the Festival \"Feuer und Flamme\" (Fire and Flames), the \"Gartenfestival\" (Garden Festival), the \"Herbstfestival\" (Autumn Festival), the \"Harley Days\", the \"Steintor Festival\" (Steintor is a party area in the city centre) and the \"Lister-Meile-Festival\" (Lister Meile is a large pedestrian area).\n\nHanover also hosts food-oriented festivals including the \"Wine Festival\" and the \"Gourmet Festival\". It also hosts some special markets. The \"Old Town Flea Market\" is the oldest flea market in Germany and the \"Market for Art and Trade\" has a high reputation. Some other major markets include the \"Christmas Markets of the City of Hanover\" in the Old Town and city centre, and the Lister Meile.\n\nThe city's central station, Hannover Hauptbahnhof, is a hub of the German high-speed ICE network. It is the starting point of the Hanover-Würzburg high-speed rail line and also the central hub for the Hanover S-Bahn. It offers many international and national connections.\n\nHanover and its area is served by Hanover/Langenhagen International Airport (IATA code: HAJ; ICAO code: EDDV)\n\nHanover is also an important hub of Germany's Autobahn network; the junction of two major autobahns, the A2 and A7 is at \"Kreuz Hannover-Ost\", at the northeastern edge of the city.\n\nLocal autobahns are A 352 (a short cut between A7 [north] and A2 [west], also known as the \"airport autobahn\" because it passes \"Hanover Airport\") and the A 37.\n\nThe Schnellweg \"(en: expressway)\" system, a number of Bundesstraße roads, forms a structure loosely resembling a large ring road together with A2 and A7. The roads are B 3, B 6 and Bundesstraße 65|B 65, called Westschnellweg (B6 on the northern part, B3 on the southern part), Messeschnellweg (B3, becomes A37 near Burgdorf, crosses A2, becomes B3 again, changes to B6 at \"Seelhorster Kreuz\", then passes the Hanover fairground as B6 and becomes A37 again before merging into A7) and Südschnellweg (starts out as B65, becomes B3/B6/B65 upon crossing \"Westschnellweg\", then becomes B65 again at \"Seelhorster Kreuz\").\n\nHanover has an extensive Stadtbahn and bus system, operated by üstra. The city is famous for its designer buses and tramways, the TW 6000 and TW 2000 trams being the most well-known examples.\n\nCycle paths are very common in the city centre. At off-peak hours you are allowed to take your bike on a tram or bus.\n\nVarious industrial businesses are located in Hannover. The Volkswagen Commercial Vehicles Transporter (VWN) factory at Hannover-Stöcken is the biggest employer in the region and operates a huge plant at the northern edge of town adjoining the Mittellandkanal and Motorway A2. Volkswagen shares a coal-burning power plant with a factory of German tire and automobile parts manufacturer Continental AG. Continental AG, founded in Hanover in 1871, is one of the city's major companies. Since 2008 a take-over has been in progress: the Schaeffler Group from Herzogenaurach (Bavaria) holds the majority of Continental's stock but were required due to the financial crisis to deposit the options as securities at banks.\n\nThe audio equipment company Sennheiser and the travel group TUI AG are both based in Hanover. Hanover is home to many insurance companies including Talanx, VHV Group, and Concordia Insurance. The major global reinsurance company is Hannover Re also has its headquarters east of the city centre.\n\nIn 2012, the city generated a GDP of €29.5 billion, which is equivalent to €74,822 per employee. The gross value of production in 2012 was €26.4 billion, which is equivalent to €66,822 per employee.\nAround 300,000 employees were counted in 2014. Of these, 189,000 had their primary residence in Hanover, while 164,892 commute into the city every day.\n\nIn 2014 the city was home to 34,198 businesses, of which 9,342 were registered in the German Trade Register and 24,856 counted as small businesses. Hence, more than half of the metropolitan area's businesses in the German Trade Register are located in Hanover (17,485 total).\nHannoverimpuls GMBH is a joint business development company from the city and region of Hannover. The company was founded in 2003 and supports the start-up, growth and relocation of businesses in the Hannover Region. The focus is on seven sectors, which stand for sustainable economic growth: Automotive, Energy Solutions, Information and Communications Technology, Life Sciences, Optical Technologies, Creative Industries and Production Engineering.\n\nA range of programmes supports companies from the key industries in their expansion plans in Hannover or abroad. Three regional centres specifically promote international economic relations with Russia, India and Turkey.\n\nThe Leibniz University Hannover is the largest funded institution in Hanover for providing higher education to the students from around the world. Below are the names of the universities and some of the important schools, including newly opened Hannover Medical Research School in 2003 for attracting the students from biology background from around the world.\n\nThere are several universities in Hanover:\nThere is one University of Applied Science and Arts in Hanover:\n\nThe \"Schulbiologiezentrum Hannover\" maintains practical biology schools in four locations (Botanischer Schulgarten Burg, Freiluftschule Burg, Zooschule Hannover, and Botanischer Schulgarten Linden). The University of Veterinary Medicine Hanover also maintains its own botanical garden specializing in medicinal and poisonous plants, the Heil- und Giftpflanzengarten der Tierärztlichen Hochschule Hannover.\n\nThe following is a selection of famous Hanover-natives, personalities connected with the city and honorary citizens:\n\nHanover is twinned with:\n\n\n"}
{"id": "14199", "url": "https://en.wikipedia.org/wiki?curid=14199", "title": "Handheld game console", "text": "Handheld game console\n\nA handheld game console, or simply handheld console, is a small, portable self-contained video game console with a built-in screen, game controls, and speakers. Handheld game consoles are smaller than home video game consoles and contain the console, screen, speakers, and controls in one unit, allowing people to carry them and play them at any time or place.\n\nIn 1976, Mattel introduced the first handheld electronic game with the release of \"Auto Race\". Later, several companies—including Coleco and Milton Bradley—made their own single-game, lightweight table-top or handheld electronic game devices. The oldest true handheld game console with interchangeable cartridges is the Milton Bradley Microvision in 1979.\n\nNintendo is credited with popularizing the handheld console concept with the release of the Game Boy in 1989 and continues to dominate the handheld console market.\n\nThe origins of handheld game consoles are found in handheld and tabletop electronic game devices of the 1970s and early 1980s. These electronic devices are capable of playing only a single game, they fit in the palm of the hand or on a tabletop, and they may make use of a variety of video displays such as LED, VFD, or LCD. In 1978, handheld electronic games were described by \"Popular Electronics\" magazine as \"nonvideo electronic games\" and \"non-TV games\" as distinct from devices that required use of a television screen. Handheld electronic games, in turn, find their origins in the synthesis of previous handheld and tabletop electro-mechanical devices such as Waco's \"Electronic Tic-Tac-Toe\" (1972) Cragstan's \"Periscope-Firing Range\" (1951), and the emerging optoelectronic-display-driven calculator market of the early 1970s. This synthesis happened in 1976, when \"Mattel began work on a line of calculator-sized sports games that became the world's first handheld electronic games. The project began when Michael Katz, Mattel's new product category marketing director, told the engineers in the electronics group to design a game the size of a calculator, using LED (light-emitting diode) technology.\"\n\nThe result was the 1976 release of \"Auto Race\". Followed by \"Football\" later in 1977, the two games were so successful that according to Katz, \"these simple electronic handheld games turned into a '$400 million category.'\" Mattel would later win the honor of being recognized by the industry for innovation in handheld game device displays. Soon, other manufacturers including Coleco, Parker Brothers, Milton Bradley, Entex, and Bandai began following up with their own tabletop and handheld electronic games.\n\nIn 1979 the LCD-based Microvision, designed by Smith Engineering and distributed by Milton-Bradley, became the first handheld game console and the first to use interchangeable game cartridges. The Microvision game \"Cosmic Hunter\" (1981) also introduced the concept of a directional pad on handheld gaming devices, and is operated by using the thumb to manipulate the on-screen character in any of four directions.\n\nIn 1979, Gunpei Yokoi, traveling on a bullet train, saw a bored businessman playing with an LCD calculator by pressing the buttons. Yokoi then thought of an idea for a watch that doubled as a miniature game machine for killing time. Starting in 1980, Nintendo began to release a series of electronic games designed by Yokoi called the Game & Watch games. Taking advantage of the technology used in the credit-card-sized calculators that had appeared on the market, Yokoi designed the series of LCD-based games to include a digital time display in the corner of the screen. For later, more complicated Game & Watch games, Yokoi invented a cross shaped directional pad or \"D-pad\" for control of on-screen characters. Yokoi also included his directional pad on the NES controllers, and the cross-shaped thumb controller soon became standard on game console controllers and ubiquitous across the video game industry since. When Yokoi began designing Nintendo's first handheld game console, he came up with a device that married the elements of his Game & Watch devices and the Famicom console, including both items' D-pad controller. The result was the Nintendo Game Boy.\n\nIn 1982, the Bandai LCD Solarpower was the first solar-powered gaming device. Some of its games, such as the horror-themed game \"Terror House\", features two LCD panels, one stacked on the other, for an early 3D effect. In 1983, Takara Tomy's Tomytronic 3D simulates 3D by having two LCD panels that were lit by external light through a window on top of the device, making it the first dedicated home video 3D hardware.\n\nThe late 1980s and early 1990s saw the beginnings of the handheld game console industry as we know it, after the demise of the Microvision. As backlit LCD game consoles with color graphics consume a lot of power, they were not battery-friendly like the non-backlit original Game Boy whose monochrome graphics allowed longer battery life. By this point, rechargeable battery technology had not yet matured and so the more advanced game consoles of the time such as the Sega Game Gear and Atari Lynx did not have nearly as much success as the Game Boy.\n\nEven though third-party rechargeable batteries were available for the battery-hungry alternatives to the Game Boy, these batteries employed a nickel-cadmium process and had to be completely discharged before being recharged to ensure maximum efficiency; lead-acid batteries could be used with automobile circuit limiters (cigarette lighter plug devices); but the batteries had mediocre portability. The later NiMH batteries, which do not share this requirement for maximum efficiency, were not released until the late 1990s, years after the Game Gear, Atari Lynx, and original Game Boy had been discontinued. During the time when technologically superior handhelds had strict technical limitations, batteries had a very low mAh rating since batteries with heavy power density were not yet available.\n\nModern game systems such as the Nintendo DS and PlayStation Portable have rechargeable Lithium-Ion batteries with proprietary shapes. Other seventh-generation consoles such as the GP2X use standard alkaline batteries. Because the mAh rating of alkaline batteries has increased since the 1990s, the power needed for handhelds like the GP2X may be supplied by relatively few batteries.\n\nNintendo released the Game Boy on April 21, 1989 (September 1990 for the UK). The design team headed by Gunpei Yokoi had also been responsible for the Game & Watch system, as well as the Nintendo Entertainment System games \"Metroid\" and \"Kid Icarus\". The Game Boy came under scrutiny by some industry critics, saying that the monochrome screen was too small, and the processing power was inadequate. The design team had felt that low initial cost and battery economy were more important concerns, and when compared to the Microvision, the Game Boy was a huge leap forward.\n\nYokoi recognized that the Game Boy needed a killer app—at least one game that would define the console, and persuade customers to buy it. In June 1988, Minoru Arakawa, then-CEO of Nintendo of America saw a demonstration of the game \"Tetris\" at a trade show. Nintendo purchased the rights for the game, and packaged it with the Game Boy system as a launch title. It was almost an immediate hit. By the end of the year more than a million units were sold in the US. As of March 31, 2005, the Game Boy and Game Boy Color combined to sell over 118 million units worldwide.\n\nIn 1987, Epyx created the Handy Game; a device that would turn into the Atari Lynx in 1989. It is the first color handheld console ever made, as well as the first with a backlit screen. It also features networking support with up to 17 other players, and advanced hardware that allows the zooming and scaling of sprites. The Lynx can also be turned upside down to accommodate left-handed players. However, all these features came at a very high price point, which drove consumers to seek cheaper alternatives. The Lynx is also very unwieldy, consumes batteries very quickly, and lacked the third-party support enjoyed by its competitors. Due to its high price, short battery life, production shortages, a dearth of compelling games, and Nintendo's aggressive marketing campaign, and despite a redesign in 1991, the Lynx became a commercial failure. Despite this, companies like Telegames helped to keep the system alive long past its commercial relevance, and when new owner Hasbro released the rights to develop for the public domain, independent developers like Songbird have managed to release new commercial games for the system every year until 2004's \"Winter Games\".\n\nThe TurboExpress is a portable version of the TurboGrafx, released in 1990 for $249.99 (the price was briefly raised to $299.99, soon dropped back to $249.99, and by 1992 it was $199.99). Its Japanese equivalent is the PC Engine GT.\n\nIt is the most advanced handheld of its time and can play all the TurboGrafx-16's games (which are on a small, credit-card sized media called HuCards). It has a 66 mm (2.6 in.) screen, the same as the original Game Boy, but in a much higher resolution, and can display 64 sprites at once, 16 per scanline, in 512 colors. Although the hardware can only handle 481 simultaneous colors. It has 8 kilobytes of RAM. The Turbo runs the HuC6820 CPU at 1.79 or 7.16 MHz.\n\nThe optional \"TurboVision\" TV tuner includes RCA audio/video input, allowing users to use TurboExpress as a video monitor. The \"TurboLink\" allowed two-player play. \"Falcon\", a flight simulator, included a \"head-to-head\" dogfight mode that can only be accessed via TurboLink. However, very few TG-16 games offered co-op play modes especially designed with the TurboExpress in mind.\n\nThe Bitcorp Gamate is the one of the first handheld game systems created in response to the Nintendo Game Boy. It was released in Asia in 1990 and distributed worldwide by 1991.\n\nLike the Sega Game Gear, it was horizontal in orientation and like the Game Boy, required 4 AA batteries. Unlike many later Game Boy clones, its internal components were professionally assembled (no \"glop-top\" chips). Unfortunately the system's fatal flaw is its screen. Even by the standards of the day, its screen is rather difficult to use, suffering from similar motion blur problems that were common complaints with the first generation Game Boys. Likely because of this fact sales were quite poor, and Bitcorp closed by 1992. However, new games continued to be published for the Asian market, possibly as late as 1994. The total number of games released for the system remains unknown.\n\nGamate games were designed for stereo sound, but the console is only equipped with a mono speaker. \n\nThe Game Gear is the third color handheld console, after the Lynx and the TurboExpress; produced by Sega. Released in Japan in 1990 and in North America and Europe in 1991, it is based on the Master System, which gave Sega the ability to quickly create Game Gear games from its large library of games for the Master System. While never reaching the level of success enjoyed by Nintendo, the Game Gear proved to be a fairly durable competitor, lasting longer than any other Game Boy rivals.\n\nWhile the Game Gear is most frequently seen in black or navy blue, it was also released in a variety of additional colors: red, light blue, yellow, clear, and violet. All of these variations were released in small quantities and frequently only in the Asian market.\n\nFollowing Sega's success with the Game Gear, they began development on a successor during the early 1990s, which was intended to feature a touchscreen interface, many years before the Nintendo DS. However, such a technology was very expensive at the time, and the handheld itself was estimated to have cost around $289 were it to be released. Sega eventually chose to shelve the idea and instead release the Genesis Nomad, a handheld version of the Genesis, as the successor.\n\nThe Watara Supervision was released in 1992 in an attempt to compete with the Nintendo Game Boy. The first model was designed very much like a Game Boy, but it is grey in color and has a slightly larger screen. The second model was made with a hinge across the center and can be bent slightly to provide greater comfort for the user. While the system did enjoy a modest degree of success, it never impacted the sales of Nintendo or Sega. The Supervision was redesigned a final time as \"The Magnum\". Released in limited quantities it was roughly equivalent to the Game Boy Pocket. It was available in three colors: yellow, green and grey. Watara designed many of the games themselves, but did receive some third party support, most notably from Sachen.\n\nA TV adapter was available in both PAL and NTSC formats that could transfer the Supervision's black-and-white palette to 4 colors, similar in some regards to the Super Game Boy from Nintendo.\n\nThe Hartung Game Master is an obscure handheld released at an unknown point in the early 1990s. Its graphics were much lower than most of its contemporaries, similar in complexity to the Atari 2600. It was available in black, white, and purple, and was frequently rebranded by its distributors, such as Delplay, Videojet and Virella.\nThe exact number of games released is not known, but is likely around 20. The system most frequently turns up in Europe and Australia.\n\nBy this time, the lack of significant development in Nintendo's product line began allowing more advanced systems such as the Neo Geo Pocket Color and the WonderSwan Color to be developed.\n\nThe Nomad was released in October 1995 in North America only. The release was five years into the market span of the Genesis, with an existing library of more than 500 Genesis games. According to former Sega of America research and development head Joe Miller, the Nomad was not intended to be the Game Gear's replacement and believes that there was little planning from Sega of Japan for the new handheld. Sega was supporting five different consoles: Saturn, Genesis, Game Gear, Pico, and the Master System, as well as the Sega CD and 32X add-ons. In Japan, the Mega Drive had never been successful and the Saturn was more successful than Sony's PlayStation, so Sega Enterprises CEO Hayao Nakayama decided to focus on the Saturn. By 1999, the Nomad was being sold at less than a third of its original price.\n\nThe Game Boy Pocket is a redesigned version of the original Game Boy having the same features. It was released in 1996. Notably, this variation is smaller and lighter. It comes in seven different colors; red, yellow, green, black, clear, silver, blue, and pink. It has space for two AAA batteries, which provide approximately 10 hours of game play. The screen was changed to a true black-and-white display, rather than the \"pea soup\" monochromatic display of the original Game Boy. Although, like its predecessor, the Game Boy Pocket has no backlight to allow play in a darkened area, it did notably improve visibility and pixel response-time (mostly eliminating ghosting).\n\nAnother notable improvement over the original Game Boy is a black-and-white display screen, rather than the green-tinted display of the original Game Boy, that also featured improved response time for less blurring during motion. The Game Boy Pocket takes two AAA batteries as opposed to four AA batteries for roughly ten hours of gameplay. The first model of the Game Boy Pocket did not have an LED to show battery levels, but the feature was added due to public demand. The Game Boy Pocket was not a new software platform and played the same software as the original Game Boy model.\n\nThe Game.com (pronounced in TV commercials as \"game com\", not \"game dot com\", and not capitalized in marketing material) is a handheld game console released by Tiger Electronics in September 1997. It featured many new ideas for handheld consoles and was aimed at an older target audience, sporting PDA-style features and functions such as a touch screen and stylus. However, Tiger hoped it would also challenge Nintendo's Game Boy and gain a following among younger gamers too. Unlike other handheld game consoles, the first game.com consoles included two slots for game cartridges, which would not happen again until the Tapwave Zodiac, the DS and DS Lite, and could be connected to a 14.4 kbit/s modem. Later models had only a single cartridge slot.\n\nThe Game Boy Color (also referred to as GBC or CGB) is Nintendo's successor to the Game Boy and was released on October 21, 1998, in Japan and in November of the same year in the United States. It features a color screen, and is slightly bigger than the Game Boy Pocket. The processor is twice as fast as a Game Boy's and has twice as much memory. It also had an infrared communications port for wireless linking which did not appear in later versions of the Game Boy, such as the Game Boy Advance.\n\nThe Game Boy Color was a response to pressure from game developers for a new system, as they felt that the Game Boy, even in its latest incarnation, the Game Boy Pocket, was insufficient. The resulting product was backward compatible, a first for a handheld console system, and leveraged the large library of games and great installed base of the predecessor system. This became a major feature of the Game Boy line, since it allowed each new launch to begin with a significantly larger library than any of its competitors. As of March 31, 2005, the Game Boy and Game Boy Color combined to sell 118.69 million units worldwide.\n\nThe console is capable of displaying up to 56 different colors simultaneously on screen from its palette of 32,768, and can add basic four-color shading to games that had been developed for the original Game Boy. It can also give the sprites and backgrounds separate colors, for a total of more than four colors.\n\nThe Neo Geo Pocket Color (or NGPC) was released in 1999 in Japan, and later that year in the United States and Europe. It is a 16-bit color handheld game console designed by SNK, the maker of the Neo Geo home console and arcade machine. It came after SNK's original Neo Geo Pocket monochrome handheld, which debuted in 1998 in Japan.\n\nIn 2000 following SNK's purchase by Japanese Pachinko manufacturer Aruze, the Neo Geo Pocket Color was dropped from both the US and European markets, purportedly due to commercial failure.\n\nThe system seemed well on its way to being a success in the U.S. It was more successful than any Game Boy competitor since Sega's Game Gear, but was hurt by several factors, such as SNK's infamous lack of communication with third-party developers, and anticipation of the Game Boy Advance. The decision to ship U.S. games in cardboard boxes in a cost-cutting move rather than hard plastic cases that Japanese and European releases were shipped in may have also hurt US sales.\n\nThe WonderSwan Color is a handheld game console designed by Bandai. It was released on December 9, 2000, in Japan, Although the WonderSwan Color was slightly larger and heavier (7 mm and 2 g) compared to the original WonderSwan, the color version featured 512 kB of RAM and a larger color LCD screen. In addition, the WonderSwan Color is compatible with the original WonderSwan library of games.\n\nPrior to WonderSwan's release, Nintendo had virtually a monopoly in the Japanese video game handheld market. After the release of the WonderSwan Color, Bandai took approximately 8% of the market share in Japan partly due to its low price of 6800 yen (approximately US$65). Another reason for the WonderSwan's success in Japan was the fact that Bandai managed to get a deal with Square to port over the original Famicom \"Final Fantasy\" games with improved graphics and controls. However, with the popularity of the Game Boy Advance and the reconciliation between Square and Nintendo, the WonderSwan Color and its successor, the SwanCrystal quickly lost its competitive advantage.\n\nThe 2000s saw a major leap in innovation, particularly in the second half with the release of the DS and PSP.\n\nIn 2001, Nintendo released the Game Boy Advance (GBA or AGB), which added two shoulder buttons, a larger screen, and more computing power than the Game Boy Color.\n\nThe design was revised two years later when the Game Boy Advance SP (GBA SP), a more compact version, was released. The SP features a \"clamshell\" design (folding open and closed, like a laptop computer), as well as a frontlit color display and rechargeable battery. Despite the smaller form factor, the screen remained the same size as that of the original. In 2005, the Game Boy Micro was released. This revision sacrifices screen size and backwards compatibility with previous Game Boys for a dramatic reduction in total size and a brighter backlit screen. A new SP model with a backlit screen was released in some regions around the same time.\n\nAlong with the Nintendo GameCube, the GBA also introduced the concept of \"connectivity\": using a handheld system as a console controller. A handful of games use this feature, most notably \"Animal Crossing\", \"Pac-Man Vs.\", \"Final Fantasy Crystal Chronicles\", \"\", \"\", \"Metroid Prime\", and \"\".\n\nAs of December 31, 2007, the GBA, GBA SP, and the Game Boy Micro combined have sold 80.72 million units worldwide.\n\nThe original GP32 was released in 2001 by the South Korean company Game Park a few months after the launch of the Game Boy Advance. It featured a 32-bit CPU, 133 MHz processor, MP3 and Divx player, and e-book reader. SmartMedia cards were used for storage, and could hold up to 128mb of anything downloaded through a USB cable from a PC. The GP32 was redesigned in 2003. A front-lit screen was added and the new version was called GP32 FLU (Front Light Unit). In summer 2004, another redesign, the GP32 BLU, was made, and added a backlit screen. This version of the handheld was planned for release outside South Korea; in Europe, and it was released for example in Spain (VirginPlay was the distributor). While not a commercial success on a level with mainstream handhelds (only 30,000 units were sold), it ended up being used mainly as a platform for user-made applications and emulators of other systems, being popular with developers and more technically adept users.\n\nNokia released the N-Gage in 2003. It was designed as a combination MP3 player, cellphone, PDA, radio, and gaming device. The system received much criticism alleging defects in its physical design and layout, including its vertically oriented screen and requirement of removing the battery to change game cartridges. The most well known of these was \"sidetalking\", or the act of placing the phone speaker and receiver on an edge of the device instead of one of the flat sides, causing the user to appear as if they are speaking into a taco.\n\nThe N-Gage QD was later released to address the design flaws of the original. However, certain features available in the original N-Gage, including MP3 playback, FM radio reception, and USB connectivity were removed.\n\nSecond generation of N-Gage launched on April 3, 2008 in the form of a service for selected Nokia Smartphones.\n\nThe Cybiko is a Russian hand-held computer introduced in May 2000 by David Yang's company and designed for teenage audiences, featuring its own two-way radio text messaging system. It has over 430 \"official\" freeware games and applications. Because of the text messaging system, it features a QWERTY keyboard that was used with a stylus. An MP3 player add-on was made for the unit as well as a SmartMedia card reader. The company stopped manufacturing the units after two product versions and only a few years on the market. Cybikos can communicate with each other up to a maximum range of 300 metres (0.19 miles). Several Cybikos can chat with each other in a wireless chatroom.\n\nCybiko Classic:\n\nThere were two models of the Classic Cybiko. Visually, the only difference was that the original version had a power switch on the side, whilst the updated version used the \"escape\" key for power management. Internally, the differences between the two models were in the internal memory, and the location of the firmware.\n\nCybiko Xtreme:\n\nThe Cybiko Xtreme was the second-generation Cybiko handheld. It featured various improvements over the original Cybiko, such as a faster processor, more RAM, more ROM, a new operating system, a new keyboard layout and case design, greater wireless range, a microphone, improved audio output, and smaller size.\n\nIn 2003, Tapwave released the Zodiac. It was designed to be a PDA-handheld game console hybrid. It supported photos, movies, music, Internet, and documents. The Zodiac used a special version Palm OS 5, 5.2T, that supported the special gaming buttons and graphics chip. Two versions were available, Zodiac 1 and 2, differing in memory and looks. The Zodiac line ended in July 2005 when Tapwave declared bankruptcy.\n\nThe Nintendo DS was released in November 2004. Among its new features were the incorporation of two screens, a touchscreen, wireless connectivity, and a microphone port. As with the Game Boy Advance SP, the DS features a clamshell design, with the two screens aligned vertically on either side of the hinge.\n\nThe DS's lower screen is touch sensitive, designed to be pressed with a stylus, a user's finger or a special \"thumb pad\" (a small plastic pad attached to the console's wrist strap, which can be affixed to the thumb to simulate an analog stick). More traditional controls include four face buttons, two shoulder buttons, a D-pad, and \"Start\" and \"Select\" buttons. The console also features online capabilities via the Nintendo Wi-Fi Connection and ad-hoc wireless networking for multiplayer games with up to sixteen players. It is backwards-compatible with all Game Boy Advance games, but not games designed for the Game Boy or Game Boy Color.\n\nIn January 2006, Nintendo revealed an updated version of the DS: the Nintendo DS Lite (released on March 2, 2006, in Japan) with an updated, smaller form factor (42% smaller and 21% lighter than the original Nintendo DS), a cleaner design, longer battery life, and brighter, higher-quality displays, with adjustable brightness. It is also able to connect wirelessly with Nintendo's Wii console.\n\nIn October 2008, Nintendo announced the Nintendo DSi, with larger, 3.25-inch screens and two integrated cameras. It has an SD card storage slot in place of the Game Boy Advance slot, plus internal flash memory for storing downloaded games. It was released on November 1, 2008, in Japan, and was released in North America April 5, 2009, and April 3, 2009, in Europe.\n\nAs of December 31, 2009, the Nintendo DS, Nintendo DS Lite and Nintendo DSi combined have sold 125.13 million units worldwide. In 2010 Nintendo released a larger version of the DSi, called the DSi XL.\n\nThe GameKing is a handheld game console released by the Chinese company TimeTop in 2004. The first model while original in design owes a large debt to Nintendo's Game Boy Advance. The second model, the GameKing 2, is believed to be inspired by Sony's PSP. This model also was upgraded with a backlit screen, with a distracting background transparency (which can be removed by opening up the console). A color model, the GameKing 3 apparently exists, but was only made for a brief time and was difficult to purchase outside of Asia. Whether intentionally or not, the GameKing has the most primitive graphics of any handheld released since the Game Boy of 1989. \n\nAs many of the games have an \"old school\" simplicity, the device has developed a small cult following. The Gameking's speaker is quite loud and the cartridges' sophisticated looping soundtracks (sampled from other sources) are seemingly at odds with its primitive graphics.\n\nTimeTop made at least one additional device sometimes labeled as \"GameKing\", but while it seems to possess more advanced graphics, is essentially an emulator that plays a handful of multi-carts (like the GB Station Light II). Outside of Asia (especially China) however the Gameking remains relatively unheard of due to the enduring popularity of Japanese handhelds such as those manufactured by Nintendo and Sony.\n\nThe PlayStation Portable (officially abbreviated PSP) is a handheld game console manufactured and marketed by Sony Computer Entertainment. Development of the console was first announced during E3 2003, and it was unveiled on May 11, 2004, at a Sony press conference before E3 2004. The system was released in Japan on December 12, 2004, in North America on March 24, 2005, and in the PAL region on September 1, 2005.\n\nThe PlayStation Portable is the first handheld video game console to use an optical disc format, Universal Media Disc (UMD), for distribution of its games. UMD Video discs with movies and television shows were also released. The PSP utilized the Sony/SanDisk Memory Stick Pro Duo format as its primary storage medium. Other distinguishing features of the console include its large viewing screen, multi-media capabilities, and connectivity with the PlayStation 3, other PSPs, and the Internet.\n\nTiger's Gizmondo came out in the UK during March 2005 and it was released in the U.S. during October 2005. It is designed to play music, movies, and games, have a camera for taking and storing photos, and have GPS functions. It also has Internet capabilities. It has a phone for sending text and multimedia messages. Email was promised at launch, but was never released before Gizmondo, and ultimately Tiger Telematics', downfall in early 2006. Users obtained a second service pack, unreleased, hoping to find such functionality. However, Service Pack B did not activate the e-mail functionality.\n\nThe GP2X is an open-source, Linux-based handheld video game console and media player created by GamePark Holdings of South Korea, designed for homebrew developers as well as commercial developers. It is commonly used to run emulators for game consoles such as Neo-Geo, Genesis, Master System, Game Gear, Amstrad CPC, Commodore 64, Nintendo Entertainment System, TurboGrafx-16, MAME and others.\n\nA new version called the \"F200\" was released October 30, 2007, and features a touchscreen, among other changes. Followed by GP2X Wiz (2009) and GP2X Caanoo (2010).\n\nThe Dingoo A-320 is a micro-sized gaming handheld that resembles the Game Boy Micro and is open to game development. It also supports music, radio, emulators (8 bit and 16 bit) and video playing capabilities with its own interface much like the PSP. There is also an onboard radio and recording program. It is currently available in two colors — white and black. Other similar products from the same manufacturer are the Dingoo A-330 (also known as Geimi), Dingoo A-360, Dingoo A-380 (available in pink, white and black) and the recently released Dingoo A-320E.\n\nThe PSP Go is a version of the PlayStation Portable handheld game console manufactured by Sony. It was released on October 1, 2009, in American and European territories, and on November 1 in Japan. It was revealed prior to E3 2009 through Sony's Qore VOD service. Although its design is significantly different from other PSPs, it is not intended to replace the PSP 3000, which Sony continued to manufacture, sell, and support. On April 20, 2011, the manufacturer announced that the PSP Go would be discontinued so that they may concentrate on the PlayStation Vita. Sony later said that only the European and Japanese versions were being cut, and that the console would still be available in the US.\nUnlike previous PSP models, the PSP Go does not feature a UMD drive, but instead has 16 GB of internal flash memory to store games, video, pictures, and other media. This can be extended by up to 32 GB with the use of a Memory Stick Micro (M2) flash card. Also unlike previous PSP models, the PSP Go's rechargeable battery is not removable or replaceable by the user. The unit is 43% lighter and 56% smaller than the original PSP-1000, and 16% lighter and 35% smaller than the PSP-3000. It has a 3.8\" 480 × 272 LCD (compared to the larger 4.3\" 480 × 272 pixel LCD on previous PSP models). The screen slides up to reveal the main controls. The overall shape and sliding mechanism are similar to that of Sony's mylo COM-2 internet device.\n\nThe Pandora is a handheld game console/UMPC/PDA hybrid designed to take advantage of existing open source software and to be a target for home-brew development. It runs a full distribution of Linux, and in functionality is like a small PC with gaming controls. It is developed by OpenPandora, which is made up of former distributors and community members of the GP32 and GP2X handhelds.\n\nOpenPandora began taking pre-orders for one batch of 4000 devices in November 2008 and after manufacturing delays, began shipping to customers on May 21, 2010.\nThe FC-16 Go is a portable Super NES hardware clone manufactured by Yobo Gameware in 2009. It features a 3.5-inch display, two wireless controllers, and CRT cables that allow cartridges to be played on a television screen. Unlike other Super NES clone consoles, it has region tabs that only allow NTSC North American cartridges to be played. Later revisions feature stereo sound output, larger shoulder buttons, and a slightly re-arranged button, power, and A/V output layout.\n\nThe Nintendo 3DS is the successor to Nintendo's DS handheld. The autostereoscopic device is able to project stereoscopic three-dimensional effects without requirement of active shutter or passive polarized glasses, which are required by most current 3D televisions to display the 3D effect. The 3DS was released in Japan on February 26, 2011; in Europe on March 25, 2011; in North America on March 27, 2011, and in Australia on March 31, 2011. The system features backward compatibility with Nintendo DS series software, including Nintendo DSi software. It also features an online service called the Nintendo eShop, launched on June 6, 2011, in North America and June 7, 2011, in Europe and Japan, which allows owners to download games, demos, applications and information on upcoming film and game releases. On November 24, 2011, a limited edition Legend of Zelda 25th Anniversary 3DS was released that contained a unique Cosmo Black unit decorated with gold Legend of Zelda related imagery, along with a copy of The Legend of Zelda: Ocarina of Time 3D.\n\nThere are also other models including the Nintendo 2DS and the New Nintendo 3DS, the latter with a larger (XL/LL) variant, like the original Nintendo 3DS. The 2DS also has a successor, the New Nintendo 2DS XL.\nThe Sony Ericsson Xperia PLAY is a handheld game console smartphone produced by Sony Ericsson under the Xperia smartphone brand. The device runs Android 2.3 Gingerbread, and is the first to be part of the PlayStation Certified program which means that it can play PlayStation Suite games. The device is a horizontally sliding phone with its original form resembling the Xperia X10 while the slider below resembles the slider of the PSP Go. The slider features a D-pad on the left side, a set of standard PlayStation buttons (, , and ) on the right, a long rectangular touchpad in the middle, start and select buttons on the bottom right corner, a menu button on the bottom left corner, and two shoulder buttons (L and R) on the back of the device. It is powered by a 1 GHz Qualcomm Snapdragon processor, a Qualcomm Adreno 205 GPU, and features a display measuring 4.0 inches (100 mm) (854 × 480), an 8-megapixel camera, 512 MB RAM, 8 GB internal storage, and a micro-USB connector. It supports microSD cards, versus the Memory Stick variants used in PSP consoles. The device was revealed officially for the first time in a Super Bowl ad on Sunday, February 6, 2011. On February 13, 2011, at Mobile World Congress (MWC) 2011, it was announced that the device would be shipping globally in March 2011, with a launch lineup of around 50 software titles.\nThe PlayStation Vita is the successor to Sony's PlayStation Portable (PSP) Handheld series. It was released in Japan on December 17, 2011 and in Europe, Australia, North and South America on February 22, 2012.\n\nThe handheld includes two analog sticks, a 5-inch (130 mm) OLED/LCD multi-touch capacitive touchscreen, and supports Bluetooth, Wi-Fi and optional 3G. Internally, the PS Vita features a 4 core ARM Cortex-A9 MPCore processor and a 4 core SGX543MP4+ graphics processing unit, as well as LiveArea software as its main user interface, which succeeds the XrossMediaBar.\n\nThe device is fully backwards-compatible with PlayStation Portable games digitally released on the PlayStation Network via the PlayStation Store. However, PSone Classics and PS2 titles were not compatible at the time of the primary public release in Japan. The Vita's dual analog sticks will be supported on selected PSP games. The graphics for PSP releases will be up-scaled, with a smoothing filter to reduce pixelation.\nThe Razer Switchblade was a prototype pocket-sized like a Nintendo DSi XL designed to run Windows 7, featured a multi-touch LCD screen and an adaptive keyboard that changed keys depending on the game you play. It also was to feature a full mouse.\n\nIt was first unveiled on January 5, 2011, on the Consumer Electronics Show (CES). The Switchblade won The Best of CES 2011 People's Voice award. It has since been in development and the release date is still unknown. The device has likely been suspended indefinitely.\nProject Shield is a handheld system developed by Nvidia announced at CES 2013. It runs on Android 4.2 and uses Nvidia Tegra 4 SoC. The hardware includes a 5-inches multitouch screen with support for HD graphics (720p). The console allows for the streaming of games running on a compatible desktop PC, or laptop.\nThe Nintendo Switch is a hybrid console that can either be used in a handheld form, or inserted into a docking station attached to a television to play on a bigger screen. The Switch features two detachable wireless controllers, called Joy-Con, which can be used individually or attached to a grip to provide a traditional gamepad form.\n\n\n\n\n\n\n\n\n\n"}
{"id": "14200", "url": "https://en.wikipedia.org/wiki?curid=14200", "title": "Heinrich Abeken", "text": "Heinrich Abeken\n\nHeinrich Abeken (August 19, 1809August 8, 1872) was a German theologian and Prussian Privy Legation Councillor in the Ministry of Foreign Affairs in Berlin.\n\nAbeken was born and raised in the city of Osnabrück as a son of a merchant, he was incited to a higher education by the example of his uncle Bernhard Rudolf Abeken. After finishing the college in Osnabrück, he moved in 1827 to visit the University of Berlin to study theology. He soon combined philosophical and philological studies and was interested in art and modern literature.\n\nIn 1831, Abeken acquired a licenciate of theology. At the end of the year he visited Rome, and was welcomed in the house of Christian Karl Josias, Freiherr von Bunsen. Abeken participated in Bunsen's works, namely an evangelic prayer and hymn-book. In 1834 became chaplain to the Prussian embassy in Rome. He married his first wife, who died soon thereafter.\nBunsen left Rome in 1838 and Abeken followed soon thereafter to Germany. In 1841, he was sent to England to help founding a German-English evangelic episcopacy in Jerusalem. In the same year, he was sent by Frederick William IV of Prussia to Egypt and Ethiopia, where he joined an expedition led by professor Karl Richard Lepsius. In 1845 and 1846 he returned via Jerusalem and Rome to Germany. He became Legation Councillor in Berlin, later Council Referee at the Ministry of Foreign Affairs.\n\nIn 1848 he received an appointment in the Prussian ministry for foreign affairs, and in 1853 was promoted to be privy councillor of legation (\"Geheimer Legationsrath\"). Abeken remained in charge for more than twenty years of Prussian politics, assisting Otto Theodor Freiherr von Manteuffel and Chancellor Otto von Bismarck. The latter was so much pleased with Abeken's work that officials started to call Abeken \"the quill [i.e., the scribe] of Bismarck.\" Abeken married in 1866 Hedwig von Olfers, daughter of the general director of the royal museums, Privy Council von Olfers.\n\nHe was much employed by Bismarck in the writing of official despatches, and stood high in the favour of King William, whom he often accompanied on his journeys as representative of the foreign office. He was present with the king during the campaigns of 1866 and 1870-71. In 1851 he published anonymously \"Babylon und Jerusalem,\" a slashing criticism of the views of the Countess von Hahn-Hahn.\n\nDuring the war against Austria in 1866 as well as in the wars against France in 1870 and 1871, Abeken stayed in the Prussian headquarters. A major part of the dispatches of the time have been written by him. Unfortunately his health was damaged by the endeavours of these travels, and he died after an illness of several months. Emperor Wilhelm I described Abeken in a condolence letter to his widow: \"One of my most reliable advisors, standing on my side in the most decisive moments; His loss is irreplaceable to me; In him his fatherland has lost one of the most noble and most loyal men and officials.\"\n\nDespite his engagement in politics, Abeken never lost his interest in theology and continued to publish and speak in this sector during all of his life. He was interested in art and archeology, and was sponsor of the Archeological Institute of Rome and member of the Archeological Society of Rome. He founded a Circle of Friends of the Greek Literature in Berlin and was member of the prize commission for the royal Schiller-Prize.\n\nSee \"Heinrich Abeken, ein schlichtes Leben in bewegter Zeit\" (Berlin, 1898), by his widow. This is valuable by reason of the letters written from the Prussian headquarters.\n\n\n"}
{"id": "14201", "url": "https://en.wikipedia.org/wiki?curid=14201", "title": "Henry Bruce, 1st Baron Aberdare", "text": "Henry Bruce, 1st Baron Aberdare\n\nHenry Austin Bruce, 1st Baron Aberdare, (16 April 181525 February 1895) was a British Liberal Party politician, who served in government most notably as Home Secretary (1868–1873) and as Lord President of the Council.\n\nHenry Bruce was born at Duffryn, Aberdare, Glamorganshire, the son of John Bruce, a Glamorganshire landowner, and his first wife Sarah, daughter of Reverend Hugh Williams Austin. John Bruce's original family name was Knight, but on coming of age in 1805 he assumed the name of Bruce: his mother, through whom he inherited the Duffryn estate, was the daughter of William Bruce, high sheriff of Glamorganshire.\n\nHenry was educated from the age of twelve at the Bishop Gore School, Swansea (Swansea Grammar School). In 1837 he was called to the bar from Lincoln's Inn. Shortly after he had begun to practice, the discovery of coal beneath the Duffryn and other Aberdare Valley estates brought his family great wealth. From 1847 to 1854 Bruce was stipendiary magistrate for Merthyr Tydfil and Aberdare, resigning the position in the latter year, after entering parliament as Liberal member for Merthyr Tydfil.\n\nBruce was returned unopposed as MP for Merthyr Tydfil in December 1852, following the death of Sir John Guest. He did so with the enthusiastic support of the late member's political allies, notably the iron masters of Dowlais, and he was thereafter regarded by his political opponents, most notably in the Aberdare Valley, as their nominee. Even so, Bruce's parliamentary record demonstrated support for liberal policies, with the exception of the ballot. The electorate in the constituency at this time remained relatively small, excluding the vast majority of the working classes.\n\nSignificantly, however, Bruce's relationship with the miners of the Aberdare Valley, in particular, deteriorated as a result of the Aberdare Strike of 1857-8. In a speech to a large audience of miners at the Aberdare Market Hall, Bruce sought to strike a conciliatory tone in persuading the miners to return to work. In a second speech, however, he delivered a broadside against the trade union movement generally, referring to the violence engendered elsewhere as a result of strikes and to alleged examples of intimidation and violence in the immediate locality. The strike damaged his reputation and may well have contributed to his eventual election defeat ten years later. In 1855, Bruce was appointed a trustee of the Dowlais Iron Company and played a role in the further development of the iron industry.\n\nIn November 1862, after nearly ten years in Parliament, he became Under-Secretary of State for the Home Department, and held that office until April 1864. He became a Privy Councillor and a Charity Commissioner for England and Wales in 1864, when he was moved to be Vice-President of the Council of Education.\n\nAt the 1868 General Election, Merthyr Tydfil became a two-member constituency with a much-increased electorate as a result of the Second Reform Act of 1867. Since the formation of the constituency, Merthyr Tydfil had dominated representation as the vast majority of the electorate lived in the town and its vicinity, whereas there was a much lower number of electors in the neighbouring Aberdare Valley. During the 1850s and 1860s, however, the population of Aberdare grew rapidly, and the franchise changes in 1867 gave the vote to large numbers of miners in that valley. Amongst these new electors, Bruce, as noted above, remained unpopular as a result of his actions during the 1857 -8 dispute. Initially, it appeared that the Aberdare iron master, Richard Fothergill, would be elected to the second seat alongside Bruce. However, the appearance of a third Liberal candidate, Henry Richard, a nonconformist radical popular in both Merthyr and Aberdare, left Bruce on the defensive and he was ultimately defeated, finishing in third place behind both Richard and Fothergill.\n\nAfter losing his seat, Bruce was elected for Renfrewshire on 25 January 1869, he was made Home Secretary by William Ewart Gladstone. His tenure of this office was conspicuous for a reform of the licensing laws, and he was responsible for the Licensing Act 1872, which made the magistrates the licensing authority, increased the penalties for misconduct in public-houses and shortened the number of hours for the sale of drink. In 1873 Bruce relinquished the home secretaryship, at Gladstone's request, to become Lord President of the Council, and was elevated to the peerage as Baron Aberdare, of Duffryn in the County of Glamorgan, on 23 August that year. Being a Gladstonian Liberal, Aberdare had hoped for a much more radical proposal to keep existing licensee holders for a further ten years, and to prevent any new applicants. Its unpopularity pricked his nonconformist's conscience, when like Gladstone himself he had a strong leaning towards Temperance. He had already pursued 'moral improvement' on miners in the regulations attempting to further ban boys from the pits. The Trades Union Act 1871 was another more liberal regime giving further rights to unions, and protection from malicious prosecutions.\nThe defeat of the Liberal government in the following year terminated Lord Aberdare's official political life, and he subsequently devoted himself to social, educational and economic questions. Education became one of Lord Aberdare's main interests in later life. His interest had been shown by the speech on Welsh education which he had made on 5 May 1862. In 1880, he was appointed to chair the Departmental Committee on Intermediate and Higher Education in Wales and Monmouthshire, whose report ultimately led to the Welsh Intermediate Education Act of 1889. The report also stimulated the campaign for the provision of university education in Wales. In 1883, Lord Aberdare was elected the first president of the University College of South Wales and Monmouthshire. In his inaugural address he declared that the framework of Welsh education would not be complete until there was a University of Wales. The University was eventually founded in 1893 and Aberdare became its first chancellor.\n\nIn 1876 he was elected a Fellow of the Royal Society; from 1878 to 1891 he was president of the Royal Historical Society. and in 1881 he became president of both the Royal Geographical Society and the Girls' Day School Trust. In 1888 he headed the commission that established the Official Table of Drops, listing how far a person of a particular weight should be dropped when hanged for a capital offence (the only method of 'judicial execution' in the United Kingdom at that time), to ensure an instant and painless death, by cleanly breaking the neck between the 2nd and 3rd vertebrae, an 'exacting science', eventually brought to perfection by Chief Executioner Albert Pierrepoint. Prisoners health, clothing and discipline was a particular concern even at the end of his career. In the Lords he spoke at some length to the Home Affairs Committee chaired by Arthur Balfour about the prison rules system. Aberdare had always maintained a healthy skepticism about intemperate working-classes; in 1878 urging greater vigilance against the vice of excessive drinking, he took evidence on miners and railway colliers habitual imbibing. The committee tried racinate special legislation based on a link between Sunday Opening and absenteeism established in 1868. Aberdare had been interested in the plight of working class drinkers since Gladstone had appointed him Home Secretary. The defeat of the Licensing Bill by the Tory 'beerage' and publicans was drafted to limit hours and protect the public, but it persuaded a convinced Anglican forever more of the iniquities.\n\nIn 1882 he began a connection with West Africa which lasted the rest of his life, by accepting the chairmanship of the National African Company, formed by Sir George Goldie, which in 1886 received a charter under the title of the Royal Niger Company and in 1899 was taken over by the British government, its territories being constituted the protectorate of Nigeria. West African affairs, however, by no means exhausted Lord Aberdare's energies, and it was principally through his efforts that a charter was in 1894 obtained for the University College of South Wales and Monmouthshire,a constituent institution of the University of Wales. This is now Cardiff University. Lord Aberdare, who in 1885 was made a Knight Grand Cross of the Order of the Bath, presided over several Royal Commissions at different times.\n\nHenry Bruce married firstly Annabella, daughter of Richard Beadon, of Clifton by Annabella A'Court, sister of 1st Baron Heytesbury, on 6 January 1846. They had one son and three daughters. \n\nAfter her death on 28 July 1852 he married secondly on 17 August 1854 Norah Creina Blanche, youngest daughter of Lt-Gen Sir William Napier, KCB the historian of the Peninsular War, whose biography he edited, by Caroline Amelia, second daughter of Gen. Hon Henry Edward Fox, son of the Earl of Ilchester. They had seven daughters and two sons, of whom:\n\nLord Aberdare died at his London home, 39 Princes Gardens, W, on 25 February 1895, aged 79, and was succeeded in the barony by his only son by his first marriage, Henry. He was survived by his wife, Lady Aberdare, born 1827, who died on 27 April 1897. She was a proponent of women's education and active in the establishment of Aberdare Hall in Cardiff.\n\nHenry Austin Bruce is buried at Aberffrwd Cemetery in Mountain Ash, Wales. His large family plot is surrounded by a chain, and his grave is a simple Celtic cross with double plinth and kerb. In place is written \"To God the Judge of all and to the spirits of just men more perfect.\"\n\n\n"}
{"id": "14203", "url": "https://en.wikipedia.org/wiki?curid=14203", "title": "Harpers Ferry (disambiguation)", "text": "Harpers Ferry (disambiguation)\n\nHarpers Ferry is the name of several places in the United States of America:\n\nHarpers Ferry may also refer to:\n\n"}
{"id": "14204", "url": "https://en.wikipedia.org/wiki?curid=14204", "title": "Halophile", "text": "Halophile\n\nHalophiles are organisms that thrive in high salt concentrations. They are a type of extremophile organism. The name comes from the Greek word for \"salt-loving\". While most halophiles are classified into the Archaea domain, there are also bacterial halophiles and some eukaryota, such as the alga \"Dunaliella salina\" or fungus \"Wallemia ichthyophaga\". Some well-known species give off a red color from carotenoid compounds, notably bacteriorhodopsin. Halophiles can be found anywhere with a concentration of salt five times greater than the salt concentration of the ocean, such as the Great Salt Lake in Utah, Owens Lake in California, the Dead Sea, and in evaporation ponds.\n\nHalophiles are categorized as slight, moderate, or extreme, by the extent of their halotolerance. Slight halophiles prefer 0.3 to 0.8 M (1.7 to 4.8%—seawater is 0.6 M or 3.5%), moderate halophiles 0.8 to 3.4 M (4.7 to 20%), and extreme halophiles 3.4 to 5.1 M (20 to 30%) salt content. Halophiles require sodium chloride (salt) for growth, in contrast to halotolerant organisms, which do not require salt but can grow under saline conditions.\n\nHigh salinity represents an extreme environment to which relatively few organisms have been able to adapt and occupy. Most halophilic and all halotolerant organisms expend energy to exclude salt from their cytoplasm to avoid protein aggregation ('salting out'). To survive the high salinities, halophiles employ two differing strategies to prevent desiccation through osmotic movement of water out of their cytoplasm. Both strategies work by increasing the internal osmolarity of the cell. In the first (which is employed by the majority of halophilic bacteria, some archaea, yeasts, algae and fungi), organic compounds are accumulated in the cytoplasm—osmoprotectants which are known as compatible solutes. These can be either synthesised or accumulated from the environment. The most common compatible solutes are neutral or zwitterionic, and include amino acids, sugars, polyols, betaines, and ectoines, as well as derivatives of some of these compounds.\n\nThe second, more radical, adaptation involves the selective influx of potassium (K) ions into the cytoplasm. This adaptation is restricted to the moderately halophilic bacterial order Halanaerobiales, the extremely halophilic archaeal family Halobacteriaceae, and the extremely halophilic bacterium \"Salinibacter ruber\". The presence of this adaptation in three distinct evolutionary lineages suggests convergent evolution of this strategy, it being unlikely to be an ancient characteristic retained in only scattered groups or passed on through massive lateral gene transfer. The primary reason for this is the entire intracellular machinery (enzymes, structural proteins, etc.) must be adapted to high salt levels, whereas in the compatible solute adaptation, little or no adjustment is required to intracellular macromolecules; in fact, the compatible solutes often act as more general stress protectants, as well as just osmoprotectants.\n\nOf particular note are the extreme halophiles or haloarchaea (often known as halobacteria), a group of archaea, which require at least a 2 M salt concentration and are usually found in saturated solutions (about 36% w/v salts). These are the primary inhabitants of salt lakes, inland seas, and evaporating ponds of seawater, such as the deep salterns, where they tint the water column and sediments bright colors. These species most likely perish if they are exposed to anything other than a very high-concentration, salt-conditioned environment. These prokaryotes require salt for growth. The high concentration of sodium chloride in their environment limits the availability of oxygen for respiration. Their cellular machinery is adapted to high salt concentrations by having charged amino acids on their surfaces, allowing the retention of water molecules around these components. They are heterotrophs that normally respire by aerobic means. Most halophiles are unable to survive outside their high-salt native environments. Indeed, many cells are so fragile that when placed in distilled water, they immediately lyse from the change in osmotic conditions.\n\nHalophiles may use a variety of energy sources. They can be aerobic or anaerobic. Anaerobic halophiles include phototrophic, fermentative, sulfate-reducing, homoacetogenic, and methanogenic species.\n\nThe Haloarchaea, and particularly the family Halobacteriaceae, are members of the domain Archaea, and comprise the majority of the prokaryotic population in hypersaline environments. Currently, 15 recognised genera are in the family. The domain Bacteria (mainly \"Salinibacter ruber\") can comprise up to 25% of the prokaryotic community, but is more commonly a much lower percentage of the overall population. At times, the alga \"Dunaliella salina\" can also proliferate in this environment.\n\nA comparatively wide range of taxa has been isolated from saltern crystalliser ponds, including members of these genera: \"Haloferax, Halogeometricum, Halococcus, Haloterrigena, Halorubrum, Haloarcula\", and \"Halobacterium\". However, the viable counts in these cultivation studies have been small when compared to total counts, and the numerical significance of these isolates has been unclear. Only recently has it become possible to determine the identities and relative abundances of organisms in natural populations, typically using PCR-based strategies that target 16S small subunit ribosomal ribonucleic acid (16S rRNA) genes. While comparatively few studies of this type have been performed, results from these suggest that some of the most readily isolated and studied genera may not in fact be significant in the \"in situ\" community. This is seen in cases such as the genus \"Haloarcula\", which is estimated to make up less than 0.1% of the\" in situ\" community, but commonly appears in isolation studies.\n\nThe comparative genomic and proteomic analysis showed distinct molecular signatures exist for environmental adaptation of halophiles. At the protein level, the halophilic species are characterized by low hydrophobicity, overrepresentation of acidic residues, underrepresentation of Cys, lower propensities for helix formation, and higher propensities for coil structure. The core of these proteins is less hydrophobic, such as DHFR, that was found to have narrower β-strands.\nAt the DNA level, the halophiles exhibit distinct dinucleotide and codon usage.\n\n\"Halobacterium\" is a genus of the Archaea that has a high tolerance for elevated levels of salinity. Some species of halobacteria have acidic proteins that resist the denaturing effects of salts. \"Halococcus\" is a specific genus of the family Halobacteriaceae.\n\nSome hypersaline lakes are a habitat to numerous families of halophiles. For example, the Makgadikgadi Pans in Botswana form a vast, seasonal, high-salinity water body that manifests halophilic species within the diatom genus \"Nitzschia\" in the family Bacillariaceae, as well as species within the genus \"Lovenula\" in the family Diaptomidae. Owens Lake in California also contains a large population of the halophilic bacterium \"Halobacterium halobium\".\n\n\"Wallemia ichthyophaga\" is a basidiomycetous fungus, which requires at least 1.5 M sodium chloride for \"in vitro\" growth, and it thrives even in media saturated with salt. Obligate requirement for salt is an exception in fungi. Even species that can tolerate salt concentrations close to saturation (for example \"Hortaea werneckii\") in almost all cases grow well in standard microbiological media without the addition of salt.\n\nThe fermentation of salty foods (such as soy sauce, Chinese fermented beans, salted cod, salted anchovies, sauerkraut, etc.) often involves halobacteria, as either essential ingredients or accidental contaminants. One example is \"Chromohalobacter beijerinckii\", found in salted beans preserved in brine and in salted herring. \"Tetragenococcus halophilus\" is found in salted anchovies and soy sauce.\n\nNorth Ronaldsay sheep are a breed of sheep originating from Orkney, Scotland. They have limited access to fresh water sources on the island and to their only food source is seaweed. They have adapted to handle salt concentrations that would kill other breeds of sheep.\n\n\n\n"}
{"id": "14205", "url": "https://en.wikipedia.org/wiki?curid=14205", "title": "Herbert A. Simon", "text": "Herbert A. Simon\n\nHerbert Alexander Simon (June 15, 1916 – February 9, 2001) was an American economist and political scientist whose primary interest was decision-making within organizations and is best known for the theories of \"bounded rationality\" and \"satisficing\". He received the Nobel Prize in Economics in 1978 and the Turing Award in 1975. His research was noted for its interdisciplinary nature and spanned across the fields of cognitive science, computer science, public administration, management, and political science. He was at Carnegie Mellon University for most of his career, from 1949 to 2001.\n\nNotably, Simon was among the pioneers of several modern-day scientific domains such as artificial intelligence, information processing, decision-making, problem-solving, organization theory, and complex systems. He was among the earliest to analyze the architecture of complexity and to propose a preferential attachment mechanism to explain power law distributions.\n\nHerbert Alexander Simon was born in Milwaukee, Wisconsin, on June 15, 1916. His father, Arthur Simon (1881–1948), was a Jewish electrical engineer who had come to the United States from Germany in 1903 after earning his engineering degree from the Technische Hochschule of Darmstadt. An inventor who was granted \"several dozen patents\", his father also was an independent patent attorney. His mother, Edna Marguerite Merkel, was an accomplished pianist whose ancestors had come from Prague and Cologne. His European ancestors had been piano makers, goldsmiths, and vintners. Simon's father was Jewish and his mother came from a family with Jewish, Lutheran, and Catholic backgrounds. Simon called himself an atheist.\n\nSimon was educated in the Milwaukee public school system, where he developed an interest in science. He found schoolwork to be interesting, but rather easy. Unlike many children, Simon was exposed to the idea that human behavior could be studied scientifically at a relatively young age due to the influence of his mother's younger brother, Harold Merkel, who had studied economics at the University of Wisconsin–Madison under John R. Commons. Through his uncle's books on economics and psychology, Simon discovered the social sciences. Among his earliest influences, Simon has cited Richard Ely's economics textbook, Norman Angell's \"The Great Illusion\", and Henry George's \"Progress and Poverty\". At that time, Simon argued \"from conviction, rather than cussedness\" in favor of George's controversial \"single tax\" on land rents.\n\nIn 1933, Simon entered the University of Chicago, and following those early influences, he studied the social sciences and mathematics. He was interested in biology, but chose not to study it because of his \"color-blindness and awkwardness in the laboratory\". He chose instead to focus on political science and economics. His most important mentor was Henry Schultz, an econometrician and mathematical economist. Simon received both his B.A. (1936) and his Ph.D. (1943) in political science, from the University of Chicago, where he studied under Harold Lasswell, Nicholas Rashevsky, Rudolf Carnap, Henry Schultz, and Charles Edward Merriam.\n\nAfter enrolling in a course on \"Measuring Municipal Governments\", Simon was invited to be a research assistant for Clarence Ridley, with whom he coauthored \"Measuring Municipal Activities\" in 1938. Eventually his studies led him to the field of organizational decision-making, which would become the subject of his doctoral dissertation.\n\nAfter graduating with his undergraduate degree, Simon obtained a research assistantship in municipal administration which turned into a directorship at the University of California, Berkeley.\n\nFrom 1942 to 1949, Simon was a professor of political science and also served as department chairman at Illinois Institute of Technology in Chicago. There, he began participating in the seminars held by the staff of the Cowles Commission who at that time included Trygve Haavelmo, Jacob Marschak, and Tjalling Koopmans. He thus began an in-depth study of economics in the area of institutionalism. Marschak brought Simon in to assist in the study he was currently undertaking with Sam Schurr of the \"prospective economic effects of atomic energy\".\n\nFrom 1949 to 2001, Simon was a faculty at Carnegie Mellon. In 1949, Simon became a professor of administration and chairman of the Department of Industrial Management at Carnegie Tech (later to become Carnegie Mellon University). Simon later also taught psychology and computer science in the same university, (occasionally visiting other universities.).\n\nSimon married Dorothea Pye in 1938. Their marriage lasted 63 years until his death from a cancerous tumor. In January 2001, Simon underwent surgery at UPMC Presbyterian to remove a cancerous tumor in his abdomen. Although the surgery was successful, Simon later succumbed to the complications that followed. They had three children, Katherine, Peter, and Barbara. His wife died in 2002.\n\nFrom 1950 to 1955, Simon studied mathematical economics and during this time, together with David Hawkins, discovered and proved the Hawkins–Simon theorem on the \"conditions for the existence of positive solution vectors for input-output matrices\". He also developed theorems on near-decomposability and aggregation. Having begun to apply these theorems to organizations, by 1954 Simon determined that the best way to study problem-solving was to simulate it with computer programs, which led to his interest in computer simulation of human cognition. Founded during the 1950s, he was among the first members of the Society for General Systems Research.\n\nSimon had a keen interest in the arts, as he was a pianist. He was a friend of Robert Lepper and Richard Rappaport. Rappaport also painted Simon's commissioned portrait at Carnegie Mellon University. He was also a keen mountain climber. As a testament to his wide interests, he at one point taught an undergraduate course on the French Revolution.\n\nSeeking to replace the highly simplified classical approach to economic modeling, Simon became best known for his theory of corporate decision in his book \"Administrative Behavior\". In this book he based his concepts with an approach that recognized multiple factors that contribute to decision making. His organization and administration interest allowed him to not only serve three times as a university department chairman, but he also played a big part in the creation of the Economic Cooperation Administration in 1948; administrative team that administered aid to the Marshall Plan for the U.S. government, serving on President Lyndon Johnson's Science Advisory Committee, and also the National Academy of Science. Simon has made a great number of contributions to both economic analysis and applications. Because of this, his work can be found in a number of economic literary works, making contributions to areas such as mathematical economics including theorem, human rationality, behavioral study of firms, theory of casual ordering, and the analysis of the parameter identification problem in econometrics.\n\n\"Administrative Behavior\", first published in 1947, and updated across the years was based on Simon's doctoral dissertation. It served as the foundation for his life's work. The centerpiece of this book is the behavioral and cognitive processes of humans making rational choices, that is, decisions. By his definition, an operational administrative decision should be correct and efficient, and it must be practical to implement with a set of coordinated means.\nSimon recognized that a theory of administration is largely a theory of human decision making, and as such must be based on both economics and on psychology. He states:\n\nContrary to the \"homo economicus\" stereotype, Simon argued that alternatives and consequences may be partly known, and means and ends imperfectly differentiated, incompletely related, or poorly detailed.\n\nSimons defined the task of rational decision making is to select the alternative that results in the more preferred set of all the possible consequences. Correctness of administrative decisions was thus measured by:\n\nThe task of choice was divided into three required steps:\n\n\nAny given individual or organization attempting to implement this model in a real situation would be unable to comply with the three requirements. Simon argued that knowledge of all alternatives, or all consequences that follow from each alternative is impossible in many realistic cases.\n\nSimon attempted to determine the techniques and/or behavioral processes that a person or organization could bring to bear to achieve approximately the best result given limits on rational decision making. Simon writes:\n\nSimon therefore, describes work in terms of an economic framework, conditioned on human cognitive limitations: Economic man and Administrative man.\n\n\"Administrative Behavior\" addresses a wide range of human behaviors, cognitive abilities, management techniques, personnel policies, training goals and procedures, specialized roles, criteria for evaluation of accuracy and efficiency, and all of the ramifications of communication processes. Simon is particularly interested in how these factors influence the making of decisions, both directly and indirectly.\n\nSimons argued that the two outcomes of a choice require monitoring and that many members of the organization would be expected to focus on adequacy, but that administrative management must pay particular attention to the efficiency with which the desired result was obtained.\n\nSimon followed Chester Barnard who pointed out that \"the decisions that an individual makes as a member of an organization are quite distinct from his personal decisions\". Personal choices may be determined whether an individual joins a particular organization, and continue to be made in his or her extra–organizational private life. As a member of an organization, however, that individual makes decisions not in relationship to personal needs and results, but in an impersonal sense as part of the organizational intent, purpose, and effect. Organizational inducements, rewards, and sanctions are all designed to form, strengthen, and maintain this identification.\n\nSimon saw two universal elements of human social behavior as key to creating the possibility of organizational behavior in human individuals: Authority (addressed in Chapter VII—The Role of Authority) and in Loyalties and Identification (Addressed in Chapter X: Loyalties, and Organizational Identification).\n\nAuthority is a well-studied, primary mark of organizational behavior, straightforwardly defined in the organizational context as the ability and right of an individual of higher rank to guide the decisions of an individual of lower rank. The actions, attitudes, and relationships of the dominant and subordinate individuals constitute components of role behavior that may vary widely in form, style, and content, but do not vary in the expectation of obedience by the one of superior status, and willingness to obey from the subordinate.\n\nLoyalty was defined by Simon as the \"process whereby the individual substitutes organizational objectives (service objectives or conservation objectives) for his own aims as the value-indices which determine his organizational decisions\". This entailed evaluating alternative choices in terms of their consequences for the group rather than only for onself or ones family.\n\nDecisions can be complex admixtures of facts and values. Information about facts, especially empirically-proven facts or facts derived from specialized experience, are more easily transmitted in the exercise of authority than are the expressions of values. Simon is primarily interested in seeking identification of the individual employee with the organizational goals and values. Following Lasswell, he states that \"a person identifies himself with a group when, in making a decision, he evaluates the several alternatives of choice in terms of their consequences for the specified group\". A person may identify himself with any number of social, geographic, economic, racial, religious, familial, educational, gender, political, and sports groups. Indeed, the number and variety are unlimited. The fundamental problem for organizations is to recognize that personal and group identifications may either facilitate or obstruct correct decision making for the organization. A specific organization has to determine deliberately, and specify in appropriate detail and clear language, its own goals, objectives, means, ends, and values.\n\nSimon has been critical of traditional economics' elementary understanding of decision-making, and argues it \"is too quick to build an idealistic, unrealistic picture of the decision-making process and then prescribe on the basis of such unrealistic picture\". His contributions to research in the area of administrative decision-making have become increasingly mainstream in the business community.\n\nSimon was a pioneer in the field of artificial intelligence, creating with Allen Newell the Logic Theory Machine (1956) and the General Problem Solver (GPS) (1957) programs. GPS may possibly be the first method developed for separating problem solving strategy from information about particular problems. Both programs were developed using the Information Processing Language (IPL) (1956) developed by Newell, Cliff Shaw, and Simon. Donald Knuth mentions the development of list processing in IPL, with the linked list originally called \"NSS memory\" for its inventors. In 1957, Simon predicted that computer chess would surpass human chess abilities within \"ten years\" when, in reality, that transition took about forty years.\n\nIn the early 1960s psychologist Ulric Neisser asserted that while machines are capable of replicating \"cold cognition\" behaviors such as reasoning, planning, perceiving, and deciding, they would never be able to replicate \"hot cognition\" behaviors such as pain, pleasure, desire, and other emotions. Simon responded to Neisser's views in 1963 by writing a paper on emotional cognition, which he updated in 1967 and published in \"Psychological Review\". Simon's work on emotional cognition was largely ignored by the artificial intelligence research community for several years, but subsequent work on emotions by Sloman and Picard helped refocus attention on Simon's paper and eventually, made it highly influential on the topic.\n\nSimon also collaborated with James G. March on several works in organization theory.\n\nWith Allen Newell, Simon developed a theory for the simulation of human problem solving behavior using production rules. The study of human problem solving required new kinds of human measurements and, with Anders Ericsson, Simon developed the experimental technique of verbal protocol analysis. Simon was interested in the role of knowledge in expertise. He said that to become an expert on a topic required about ten years of experience and he and colleagues estimated that expertise was the result of learning roughly 50,000 chunks of information. A chess expert was said to have learned about 50,000 chunks or chess position patterns.\n\nHe was awarded the ACM Turing Award, along with Allen Newell, in 1975. \"In joint scientific efforts extending over twenty years, initially in collaboration with J. C. (Cliff) Shaw at the RAND Corporation, and with numerous faculty and student colleagues at Carnegie Mellon University, they have made basic contributions to artificial intelligence, the psychology of human cognition, and list processing.\"\n\nSimon was interested in how humans learn and, with Edward Feigenbaum, he developed the EPAM (Elementary Perceiver and Memorizer) theory, one of the first theories of learning to be implemented as a computer program. EPAM was able to explain a large number of phenomena in the field of verbal learning. Later versions of the model were applied to concept formation and the acquisition of expertise. With Fernand Gobet, he has expanded the EPAM theory into the CHREST computational model. The theory explains how simple chunks of information form the building blocks of schemata, which are more complex structures. CHREST has been used predominantly, to simulate aspects of chess expertise.\n\nSimon has been credited for revolutionary changes in microeconomics. He is responsible for the concept of organizational decision-making as it is known today. He also was the first to discuss this concept in terms of uncertainty; i.e., it is impossible to have perfect and complete information at any given time to make a decision. While this notion was not entirely new, Simon is best known for its origination. It was in this area that he was awarded the Nobel Prize in 1978.\n\nAt the Cowles Commission, Simon's main goal was to link economic theory to mathematics and statistics. His main contributions were to the fields of general equilibrium and econometrics. He was greatly influenced by the marginalist debate that began in the 1930s. The popular work of the time argued that it was not apparent empirically that entrepreneurs needed to follow the marginalist principles of profit-maximization/cost-minimization in running organizations. The argument went on to note that profit maximization was not accomplished, in part, because of the lack of complete information. In decision-making, Simon believed that agents face uncertainty about the future and costs in acquiring information in the present. These factors limit the extent to which agents may make a fully rational decision, thus they possess only \"bounded rationality\" and must make decisions by \"satisficing\", or choosing that which might not be optimal, but which will make them happy enough. Bounded rationality is a central theme in behavioral economics. It is concerned with the ways in which the actual decision making process influences decision. Theories of bounded rationality relax one or more assumptions of standard expected utility theory.\n\nFurther, Simon emphasized that psychologists invoke a \"procedural\" definition of rationality, whereas economists employ a \"substantive\" definition. Gustavos Barros argued that the procedural rationality concept does not have a significant presence in the economics field and has never had nearly as much weight as the concept of bounded rationality. However, in an earlier article, Bhargava (1997) noted the importance of Simon's arguments and emphasized that there are several applications of the \"procedural\" definition of rationality in econometric analyses of data on health. In particular, economists should employ \"auxiliary assumptions\" that reflect the knowledge in the relevant biomedical fields, and guide the specification of econometric models for health outcomes.\n\nSimon was also known for his research on industrial organization. He determined that the internal organization of firms and the external business decisions thereof, did not conform to the neoclassical theories of \"rational\" decision-making. Simon wrote many articles on the topic over the course of his life, mainly focusing on the issue of decision-making within the behavior of what he termed \"bounded rationality\". \"Rational behavior, in economics, means that individuals maximize their utility function under the constraints they face (e.g., their budget constraint, limited choices, ...) in pursuit of their self-interest. This is reflected in the theory of subjective expected utility. The term, bounded rationality, is used to designate rational choice that takes into account the cognitive limitations of both knowledge and cognitive capacity. Bounded rationality is a central theme in behavioral economics. It is concerned with the ways in which the actual decision-making process influences decisions. Theories of bounded rationality relax one or more assumptions of standard expected utility theory\".\n\nSimon determined that the best way to study these areas was through computer simulations. As such, he developed an interest in computer science. Simon's main interests in computer science were in artificial intelligence, human–computer interaction, principles of the organization of humans and machines as information processing systems, the use of computers to study (by modeling) philosophical problems of the nature of intelligence and of epistemology, and the social implications of computer technology.\n\nIn his youth, Simon took an interest in land economics and Georgism, an idea known at the time as \"single tax\". The system is meant to redistribute unearned economic rent to the public and improve land use. In 1979, Simon still maintained these ideas and argued that land value tax should replace taxes on wages.\n\nSome of Simon's economic research was directed toward understanding technological change in general and the information processing revolution in particular.\n\nSimon's work has strongly influenced John Mighton, developer of a program that has achieved significant success in improving mathematics performance among elementary and high school students. Mighton cites a 2000 paper by Simon and two coauthors that counters arguments by French mathematics educator, Guy Brousseau, and others suggesting that excessive practice hampers children's understanding:\n\nHe received many top-level honors in life, including becoming a fellow of the American Academy of Arts and Sciences in 1959; election to the National Academy of Sciences in 1967; APA Award for Distinguished Scientific Contributions to Psychology (1969); the ACM's Turing Award for making \"basic contributions to artificial intelligence, the psychology of human cognition, and list processing\" (1975); the Nobel Memorial Prize in Economics \"for his pioneering research into the decision-making process within economic organizations\" (1978); the National Medal of Science (1986); the APA's Award for Outstanding Lifetime Contributions to Psychology (1993); ACM fellow (1994); and IJCAI Award for Research Excellence (1995).\n\n\nSimon was a prolific writer and authored 27 books and almost a thousand papers. As of 2016, Simon was the most cited person in artificial intelligence and cognitive psychology on Google Scholar. With almost a thousand highly cited publications, he was one of the most influential social scientists of the twentieth century.\n\n\n\n\n\n\n"}
{"id": "14207", "url": "https://en.wikipedia.org/wiki?curid=14207", "title": "Hematite", "text": "Hematite\n\nHematite, also spelled as haematite, is the mineral form of iron(III) oxide (FeO), one of several iron oxides. It is the oldest known iron oxide mineral that has ever formed on earth, and is widespread in rocks and soils. Hematite crystallizes in the rhombohedral lattice system, and it has the same crystal structure as ilmenite and corundum. Hematite and ilmenite form a complete solid solution at temperatures above .\n\nHematite is colored black to steel or silver-gray, brown to reddish brown, or red. It is mined as the main ore of iron. Varieties include \"kidney ore\", \"martite\" (pseudomorphs after magnetite), \"iron rose\" and \"specularite\" (specular hematite). While the forms of hematite vary, they all have a rust-red streak. Hematite is harder than pure iron, but much more brittle. Maghemite is a hematite- and magnetite-related oxide mineral.\nHuge deposits of hematite are found in banded iron formations. Gray hematite is typically found in places that can have still standing water or mineral hot springs, such as those in Yellowstone National Park in North America. The mineral can precipitate out of water and collect in layers at the bottom of a lake, spring, or other standing water. Hematite can also occur without water, however, usually as the result of volcanic activity.\n\nClay-sized hematite crystals can also occur as a secondary mineral formed by weathering processes in soil, and along with other iron oxides or oxyhydroxides such as goethite, is responsible for the red color of many tropical, ancient, or otherwise highly weathered soils.\n\nThe name hematite is derived from the Greek word for blood αἷμα \"haima,\" due to the red coloration found in some varieties of hematite. The color of hematite lends itself to use as a pigment. The English name of the stone is derived from Middle French: Hématite Pierre, which was imported from Latin: Lapis Hæmatites around the 15th century, which originated from Ancient Greek: αἱματίτης λίθος (\"haimatitēs\" lithos, \"blood-red stone\").\n\nOchre is a clay that is colored by varying amounts of hematite, varying between 20% and 70%. Red ochre contains unhydrated hematite, whereas yellow ochre contains hydrated hematite (FeO • HO). The principal use of ochre is for tinting with a permanent color.\n\nThe red chalk writing of this mineral was one of the earliest in the history of humans. The powdery mineral was first used 164,000 years ago by the Pinnacle-Point man possibly for social purposes. Hematite residues are also found in graves from 80,000 years ago. Near Rydno in Poland and Lovas in Hungary red chalk mines have been found that are from 5000 BC, belonging to the Linear Pottery culture at the Upper Rhine.\n\nRich deposits of hematite have been found on the island of Elba that have been mined since the time of the Etruscans.\n\nHematite is an antiferromagnetic material below the Morin transition at , and a canted antiferromagnet or weakly ferromagnetic above the Morin transition and below its Néel temperature at 948 K, above which it is paramagnetic.\n\nThe magnetic structure of a-hematite was the subject of considerable discussion and debate in the 1950s because it appeared to be ferromagnetic with a Curie temperature of around 1000 K, but with an extremely tiny magnetic moment (0.002 µ). Adding to the surprise was a transition with a decrease in temperature at around 260 K to a phase with no net magnetic moment. It was shown that the system is essentially antiferromagnetic, but that the low symmetry of the cation sites allows spin–orbit coupling to cause canting of the moments when they are in the plane perpendicular to the c axis. The disappearance of the moment with a decrease in temperature at 260 K is caused by a change in the anisotropy which causes the moments to align along the c axis. In this configuration, spin canting does not reduce the energy. The magnetic properties of bulk hematite differ from their nanoscale counterparts. For example, the Morin transition temperature of hematite decreases with a decrease in the particle size. The suppression of this transition has also been observed in some of the hematite nanoparticles, and the presence of impurities, water molecules and defects in the crystals were attributed to the absence of a Morin transition. Hematite is part of a complex solid solution oxyhydroxide system having various contents of water, hydroxyl groups and vacancy substitutions that affect the mineral's magnetic and crystal chemical properties. Two other end-members are referred to as protohematite and hydrohematite.\n\nEnhanced magnetic coercivities for hematite have been achieved by dry-heating a 2-line ferrihydrite precursor prepared from solution. Hematite exhibited temperature-dependent magnetic coercivity values ranging from 289 to 5,027 Oe. The origin of these high coercivity values has been interpreted as a consequence of the subparticle structure induced by the different particle and crystallite size growth rates at increasing annealing temperature. These differences in the growth rates are translated into a progressive development of a subparticle structure at the nanoscale. At lower temperatures (350–600 °C), single particles crystallize however; at higher temperatures (600–1000 °C), the growth of crystalline aggregates with a subparticle structure is favored.\n\nHematite is present in the waste tailings of iron mines. A recently developed process, magnetation, uses magnets to glean waste hematite from old mine tailings in Minnesota's vast Mesabi Range iron district. Falu red is a pigment used in traditional Swedish house paints. Originally, it was made from tailings of the Falu mine.\n\nThe spectral signature of hematite was seen on the planet Mars by the infrared spectrometer on the NASA Mars Global Surveyor (\"MGS\") and 2001 Mars Odyssey spacecraft in orbit around Mars. The mineral was seen in abundance at two sites on the planet, the Terra Meridiani site, near the Martian equator at 0° longitude, and the Aram Chaos site near the Valles Marineris. Several other sites also showed hematite, e.g., Aureum Chaos. Because terrestrial hematite is typically a mineral formed in aqueous environments or by aqueous alteration, this detection was scientifically interesting enough that the second of the two Mars Exploration Rovers was sent to a site in the Terra Meridiani region designated Meridiani Planum. In-situ investigations by the Opportunity rover showed a significant amount of hematite, much of it in the form of small spherules that were informally named \"blueberries\" by the science team. Analysis indicates that these spherules are apparently concretions formed from a water solution.\n\"Knowing just how the hematite on Mars was formed will help us characterize the past environment and determine whether that environment was favorable for life\".\n\nHematite's popularity in jewelry rose in England during the Victorian era, due to its use in mourning jewelry. Certain types of hematite or iron oxide-rich clay, especially Armenian bole, have been used in gilding. Hematite is also used in art such as in the creation of intaglio engraved gems. Hematine is a synthetic material sold as \"magnetic hematite\".\n\n\n"}
{"id": "14208", "url": "https://en.wikipedia.org/wiki?curid=14208", "title": "Holocene extinction", "text": "Holocene extinction\n\nThe Holocene extinction, otherwise referred to as the Sixth extinction or Anthropocene extinction, is the ongoing extinction event of species during the present Holocene epoch, mainly as a result of human activity. The large number of extinctions spans numerous families of plants and animals, including mammals, birds, amphibians, reptiles and arthropods. With widespread degradation of highly biodiverse habitats such as coral reefs and rainforests, as well as other areas, the vast majority of these extinctions are thought to be \"undocumented\", as no one is even aware of the existence of the species before they go extinct, or no one has yet discovered their extinction. The current rate of extinction of species is estimated at 100 to 1,000 times higher than natural background rates.\n\nThe Holocene extinction includes the disappearance of large land animals known as megafauna, starting at the end of the last Ice Age. Megafauna outside of the African continent, which did not evolve alongside humans, proved highly sensitive to the introduction of new predation, and many died out shortly after early humans began spreading and hunting across the Earth (additionally, many African species have also gone extinct in the Holocene). These extinctions, occurring near the Pleistocene–Holocene boundary, are sometimes referred to as the Quaternary extinction event.\n\nThe arrival of humans on different continents coincides with megafaunal extinction. The most popular theory is that human overhunting of species added to existing stress conditions. Although there is debate regarding how much human predation affected their decline, certain population declines have been directly correlated with human activity, such as the extinction events of New Zealand and Hawaii. Aside from humans, climate change may have been a driving factor in the megafaunal extinctions, especially at the end of the Pleistocene.\n\nEcologically, humanity has been noted as an unprecedented \"global superpredator\" that consistently preys on the adults of other apex predators, and has worldwide effects on food webs. There have been extinctions of species on every land mass and in every ocean: there are many famous examples within Africa, Asia, Europe, Australia, North and South America, and on smaller islands. Overall, the Holocene extinction can be linked to the human impact on the environment. The Holocene extinction continues into the 21st century, with meat consumption, overfishing, ocean acidification and the decline in amphibian populations being a few broader examples of an almost universal, cosmopolitan decline in biodiversity. Human overpopulation (and continued population growth) along with profligate consumption are considered to be the primary drivers of this rapid decline.\n\nThe Holocene extinction is also known as the \"sixth extinction\", as it is possibly the sixth mass extinct event, after the Ordovician–Silurian extinction events, the Late Devonian extinction, the Permian–Triassic extinction event, the Triassic–Jurassic extinction event, and the Cretaceous–Paleogene extinction event. Mass extinctions are characterized by the loss of at least 75% of species within a geologically short period of time. There is no general agreement on where the Holocene, or anthropogenic, extinction begins, and the Quaternary extinction event, which includes climate change resulting in the end of the last ice age, ends, or if they should be considered separate events at all. Some have suggested that anthropogenic extinctions may have begun as early as when the first modern humans spread out of Africa between 200,000 and 100,000 years ago; this is supported by rapid megafaunal extinction following recent human colonisation in Australia, New Zealand and Madagascar, as might be expected when any large, adaptable predator (invasive species) moves into a new ecosystem. In many cases, it is suggested that even minimal hunting pressure was enough to wipe out large fauna, particularly on geographically isolated islands. Only during the most recent parts of the extinction have plants also suffered large losses.\n\nIn \"The Future of Life\" (2002), Edward Osborne Wilson of Harvard calculated that, if the current rate of human disruption of the biosphere continues, one-half of Earth's higher lifeforms will be extinct by 2100. A 1998 poll conducted by the American Museum of Natural History found that 70% of biologists acknowledge an ongoing anthropogenic extinction event. At present, the rate of extinction of species is estimated at 100 to 1,000 times higher than the background extinction rate, the historically typical rate of extinction (in terms of the natural evolution of the planet); also, the current rate of extinction is 10 to 100 times higher than in any of the previous mass extinctions in the history of Earth. One scientist estimates the current extinction rate may be 10,000 times the background extinction rate, although most scientists predict a much lower extinction rate than this outlying estimate. Theoretical ecologist Stuart Pimm stated that the extinction rate for plants is 100 times higher than normal.\n\nIn a pair of studies published in 2015, extrapolation from observed extinction of Hawaiian snails led to the conclusion that 7% of all species on Earth may have been lost already.\n\nThere is widespread consensus among scientists that human activity is accelerating the extinction of many animal species through the destruction of habitats, the consumption of animals as resources, and the elimination of species that humans view as threats or competitors. But some contend that this biotic destruction has yet to reach the level of the previous five mass extinctions. Stuart Pimm, for example, asserts that the sixth mass extinction \"is something that hasn't happened yet – we are on the edge of it.\" In November 2017, a statement, titled \"World Scientists’ Warning to Humanity: A Second Notice\", led by eight authors and signed by 15,364 scientists from 184 countries asserted that, among other things, \"we have unleashed a mass extinction event, the sixth in roughly 540 million years, wherein many current life forms could be annihilated or at least committed to extinction by the end of this century.\"\n\nThe abundance of species extinctions considered anthropogenic, or due to human activity, have sometimes (especially when referring to hypothesized future events) been collectively called the \"Anthropocene extinction\". \"Anthropocene\" is a term introduced in 2000. Some now postulate that a new geological epoch has begun, with the most abrupt and widespread extinction of species since the Cretaceous–Paleogene extinction event 66 million years ago.\n\nThe term \"anthropocene\" is being used more frequently by scientists, and some commentators may refer to the current and projected future extinctions as part of a longer Holocene extinction. The Holocene–Anthropocene boundary is contested, with some commentators asserting significant human influence on climate for much of what is normally regarded as the Holocene Epoch. Other commentators place the Holocene–Anthropocene boundary at the industrial revolution and also say that \"[f]ormal adoption of this term in the near future will largely depend on its utility, particularly to earth scientists working on late Holocene successions.\"\n\nIt has been suggested that human activity has made the period starting from the mid-20th century different enough from the rest of the Holocene to consider it a new geological epoch, known as the Anthropocene, a term which was considered for inclusion in the timeline of Earth's history by the International Commission on Stratigraphy in 2016. In order to constitute the Holocene as an extinction event, scientists must determine exactly when anthropogenic greenhouse gas emissions began to measurably alter natural atmospheric levels on a global scale, and when these alterations caused changes to global climate. Using chemical proxies from Antarctic ice cores, researchers have estimated the fluctuations of carbon dioxide (CO) and methane (CH) gases in the Earth's atmosphere during the late Pleistocene and Holocene epochs. Estimates of the fluctuations of these two gases in the atmosphere, using chemical proxies from Antarctic ice cores, generally indicate that the peak of the Anthropocene occurred within the previous two centuries: typically beginning with the Industrial Revolution, when the highest greenhouse gas levels were recorded.\n\nThe Holocene extinction is mainly caused by human activity. Extinction of animals, plants, and other organisms caused by human actions may go as far back as the late Pleistocene, over 12,000 years ago. There is a correlation between megafaunal extinction and the arrival of humans, and human overpopulation and human population growth, along with overconsumption and consumption growth, most prominently in the past two centuries, are regarded as one of the underlying causes of extinction.\n\nMegafauna were once found on every continent of the world and large islands such as New Zealand and Madagascar, but are now almost exclusively found on the continent of Africa, with notable comparisons on Australia and the islands previously mentioned experiencing population crashes and trophic cascades shortly after the earliest human settlers. It has been suggested that the African megafauna survived because they evolved alongside humans. The timing of South American megafaunal extinction appears to precede human arrival, although the possibility that human activity at the time impacted the global climate enough to cause such an extinction has been suggested.\n\nIt has been noted, in the face of such evidence, that humans are unique in ecology as an unprecedented 'global superpredator', regularly preying on large numbers of fully grown terrestrial and marine apex predators, and with a great deal of influence over food webs and climatic systems worldwide. Although significant debate exists as to how much human predation and indirect effects contributed to prehistoric extinctions, certain population crashes have been directly correlated with human arrival. A 2018 study published in \"PNAS\" found that since the dawn of human civilization, 83% of wild mammals, 80% of marine mammals, 50% of plants and 15% of fish have vanished. Currently, livestock make up 60% of the biomass of all mammals on earth, followed by humans (36%) and wild mammals (4%). As for birds, 70% are domesticated, such as poultry, whereas only 30% are wild.\n\nMore recently, some scholars assert that the emergence of capitalism as the dominant economic system has accelerated ecological exploitation and destruction, and has also exacerbated mass species extinction. CUNY professor David Harvey, for example, posits that the neoliberal era \"happens to be the era of the fastest mass extinction of species in the Earth's recent history\".\n\nHuman civilization was founded on and grew from agriculture. The more land used for farming, the greater the population a civilization could sustain, and subsequent popularization of farming led to increasing ecological disasters.\n\nHabitat destruction by humans, including oceanic devastation, such as through overfishing and contamination; and the modification and destruction of vast tracts of land and river systems around the world to meet solely human-centered ends (with 13 percent of Earth's ice-free land surface now used as row-crop agricultural sites, 26 percent used as pastures, and 4 percent urban-industrial areas.), thus replacing the original local ecosystems. The sustained conversion of forestland to less-productive pastureland over the last 9,000 years has considerably reduced the Earth’s carrying capacity for wild birds, among other organisms, in both population size and species count.\n\nOther, related human causes of the extinction event include deforestation, hunting, pollution, the introduction in various regions of non-native species, and the widespread transmission of infectious diseases spread through livestock and crops.\n\nRecent investigations about hunter-gatherer landscape burning has a major implication for the current debate about the timing of the Anthropocene and the role that humans may have played in the production of greenhouse gases prior to the Industrial Revolution. Studies on early hunter-gatherers raises questions about the current use of population size or density as a proxy for the amount of land clearance and anthropogenic burning that took place in pre-industrial times. Scientists have questioned the correlation between population size and early territorial alterations. Ruddiman and Ellis' research paper in 2009 makes the case that early farmers involved in systems of agriculture used more land per capita than growers later in the Holocene, who intensified their labor to produce more food per unit of area (thus, per laborer); arguing that agricultural involvement in rice production implemented thousands of years ago by relatively small populations have created significant environmental impacts through large-scale means of deforestation.\n\nWhile a number of human-derived factors are recognized as potentially contributing to rising atmospheric concentrations of CH (methane) and CO (carbon dioxide), deforestation and territorial clearance practices associated with agricultural development may be contributing most to these concentrations globally. Scientists that are employing a variance of archaeological and paleoecological data argue that the processes contributing to substantial human modification of the environment spanned many thousands of years ago on a global scale and thus, not originating as early as the Industrial Revolution. Gaining popularity on his uncommon hypothesis, palaeoclimatologist William Ruddiman in 2003, stipulated that in the early Holocene 11,000 years ago, atmospheric carbon dioxide and methane levels fluctuated in a pattern which was different from the Pleistocene epoch before it. He argued that the patterns of the significant decline of CO levels during the last ice age of the Pleistocene inversely correlates to the Holocene where there have been dramatic increases of CO around 8000 years ago and CH levels 3000 years after that. The correlation between the decrease of CO in the Pleistocene and the increase of it during the Holocene implies that the causation of this spark of greenhouse gases into the atmosphere was the growth of human agriculture during the Holocene such as the anthropogenic expansion of (human) land use and irrigation.\n\nHuman arrival in the Caribbean around 6,000 years ago is correlated with the extinction of many species. Examples include many different genera of ground and arboreal sloths across all islands. These sloths were generally smaller than those found on the South American continent. \"Megalocnus\" were the largest genus at up to , \"Acratocnus\" were medium-sized relatives of modern two-toed sloths endemic to Cuba, \"Imagocnus\" also of Cuba, \"Neocnus\" and many others.\n\nRecent research, based on archaeological and paleontological digs on 70 different Pacific islands has shown that numerous species became extinct as people moved across the Pacific, starting 30,000 years ago in the Bismarck Archipelago and Solomon Islands. It is currently estimated that among the bird species of the Pacific, some 2000 species have gone extinct since the arrival of humans, representing a 20% drop in the biodiversity of birds worldwide.\n\nThe first settlers are thought to have arrived in the islands between 300 and 800 CE, with European arrival in the 16th century. Hawaii is notable for its endemism of plants, birds, insects, mollusks and fish; 30% of its organisms are endemic. Many of its species are endangered or have gone extinct, primarily due to accidentally introduced species and livestock grazing. Over 40% of its bird species have gone extinct, and it is the location of 75% of extinctions in the United States. Extinction has increased in Hawaii over the last 200 years and is relatively well documented, with extinctions among native snails used as estimates for global extinction rates.\n\nAustralia was once home to a large assemblage of megafauna, with many parallels to those found on the African continent today. Australia's fauna is characterised by primarily marsupial mammals, and many reptiles and birds, all existing as giant forms until recently. Humans arrived on the continent very early, about 50,000 years ago. The extent human arrival contributed is controversial; climatic drying of Australia 40,000–60,000 years ago was an unlikely cause, as it was less severe in speed or magnitude than previous regional climate change which failed to kill off megafauna. Extinctions in Australia continued from original settlement until today in both plants and animals, whilst many more animals and plants have declined or are endangered.\n\nDue to the older timeframe and the soil chemistry on the continent, very little subfossil preservation evidence exists relative to elsewhere. However, continent-wide extinction of all genera weighing over 100 kilograms, and six of seven genera weighing between 45 and 100 kilograms occurred around 46,400 years ago (4,000 years after human arrival) and the fact that megafauna survived until a later date on the island of Tasmania following the establishment of a land bridge suggest direct hunting or anthropogenic ecosystem disruption such as fire-stick farming as likely causes. The first evidence of direct human predation leading to extinction in Australia was published in 2016.\nWithin 500 years of the arrival of humans between 2,500–2,000 years ago, nearly all of Madagascar's distinct, endemic and geographically isolated megafauna became extinct. The largest animals, of more than , were extinct very shortly after the first human arrival, with large and medium-sized species dying out after prolonged hunting pressure from an expanding human population moving into more remote regions of the island around 1000 years ago. Smaller fauna experienced initial increases due to decreased competition, and then subsequent declines over the last 500 years. All fauna weighing over died out. The primary reasons for this are human hunting and habitat loss from early aridification, both of which persist and threaten Madagascar's remaining taxa today.\n\nThe eight or more species of elephant birds, giant flightless ratites in the genera \"Aepyornis\" and \"Mullerornis\", are extinct from over-hunting, as well as 17 species of lemur, known as giant, subfossil lemurs. Some of these lemurs typically weighed over , and fossils have provided evidence of human butchery on many species.\n\nNew Zealand is characterised by its geographic isolation and island biogeography, and had been isolated from mainland Australia for 80 million years. It was the last large land mass to be colonised by humans. The arrival of Polynesian settlers circa 12th century resulted in the extinction of all of the islands' megafaunal birds within several hundred years. The last moa, large flightless ratites, became extinct within 200 years of the arrival of human settlers. The Polynesians also introduced the Polynesian rat. This may have put some pressure on other birds but at the time of early European contact (18th Century) and colonisation (19th Century) the bird life was prolific. With them, the Europeans brought ship rats, possums, cats and mustelids which decimated native bird life, some of which had adapted flightlessness and ground nesting habits and others had no defensive behavior as a result of having no extant endemic mammalian predators. The kakapo, the world's biggest parrot, which is flightless, now only exists in managed breeding sanctuaries. New Zealand's national emblem, the kiwi, is on the endangered bird list.\n\nThere has been a debate as to the extent to which the disappearance of megafauna at the end of the last glacial period can be attributed to human activities by hunting, or even by slaughter of prey populations. Discoveries at Monte Verde in South America and at Meadowcroft Rock Shelter in Pennsylvania have caused a controversy regarding the Clovis culture. There likely would have been human settlements prior to the Clovis Culture, and the history of humans in the Americas may extend back many thousands of years before the Clovis culture. The amount of correlation between human arrival and megafauna extinction is still being debated: for example, in Wrangel Island in Siberia the extinction of dwarf woolly mammoths (approximately 2000 BCE) did not coincide with the arrival of humans, nor did megafaunal mass extinction on the South American continent, although it has been suggested climate changes induced by anthropogenic effects elsewhere in the world may have contributed.\n\nComparisons are sometimes made between recent extinctions (approximately since the industrial revolution) and the Pleistocene extinction near the end of the last glacial period. The latter is exemplified by the extinction of large herbivores such as the woolly mammoth and the carnivores that preyed on them. Humans of this era actively hunted the mammoth and the mastodon, but it is not known if this hunting was the cause of the subsequent massive ecological changes, widespread extinctions and climate changes.\n\nThe ecosystems encountered by the first Americans had not been exposed to human interaction, and may have been far less resilient to human made changes than the ecosystems encountered by industrial era humans. Therefore, the actions of the Clovis people, despite seeming insignificant by today's standards could indeed have had a profound effect on the ecosystems and wild life which was entirely unused to human influence.\n\nAfrica experienced the smallest decline in megafauna compared to the other continents. This is presumably due to the idea that Afroeurasian megafauna evolved alongside humans, and thus developed a healthy fear of them, unlike the comparatively tame animals of other continents. Unlike other continents, the megafauna of Eurasia went extinct over a relatively long period of time, possibly due to climate fluctuations fragmenting and decreasing populations, leaving them vulnerable to over-exploitation, as with the steppe bison (\"Bison priscus\"). The warming of the arctic region caused the rapid decline of grasslands, which had a negative effect on the grazing megafauna of Eurasia. Most of what once was mammoth steppe has been converted to mire, rendering the environment incapable of supporting them, notably the woolly mammoth.\n\nOne of the main theories to the extinction is climate change. The climate change theory has suggested that a change in climate near the end of the late Pleistocene stressed the megafauna to the point of extinction. Some scientists favor abrupt climate change as the catalyst for the extinction of the mega-fauna at the end of the Pleistocene, but there are many who believe increased hunting from early modern humans also played a part, with others even suggesting that the two interacted. However, the annual mean temperature of the current interglacial period for the last 10,000 years is no higher than that of previous interglacial periods, yet some of the same megafauna survived similar temperature increases. In the Americas, a controversial explanation for the shift in climate is presented under the Younger Dryas impact hypothesis, which states that the impact of comets cooled global temperatures.\n\nMegafauna play a significant role in the lateral transport of mineral nutrients in an ecosystem, tending to translocate them from areas of high to those of lower abundance. They do so by their movement between the time they consume the nutrient and the time they release it through elimination (or, to a much lesser extent, through decomposition after death). In South America's Amazon Basin, it is estimated that such lateral diffusion was reduced over 98% following the megafaunal extinctions that occurred roughly 12,500 years ago. Given that phosphorus availability is thought to limit productivity in much of the region, the decrease in its transport from the western part of the basin and from floodplains (both of which derive their supply from the uplift of the Andes) to other areas is thought to have significantly impacted the region's ecology, and the effects may not yet have reached their limits. The extinction of the mammoths allowed grasslands they had maintained through grazing habits to become birch forests. The new forest and the resulting forest fires may have induced climate change. Such disappearances might be the result of the proliferation of modern humans; some recent studies favor this theory.\n\nLarge populations of megaherbivores have the potential to contribute greatly to the atmospheric concentration of methane, which is an important greenhouse gas. Modern ruminant herbivores produce methane as a byproduct of foregut fermentation in digestion, and release it through belching or flatulence. Today, around 20% of annual methane emissions come from livestock methane release. In the Mesozoic, it has been estimated that sauropods could have emitted 520 million tons of methane to the atmosphere annually, contributing to the warmer climate of the time (up to 10 °C warmer than at present). This large emission follows from the enormous estimated biomass of sauropods, and because methane production of individual herbivores is believed to be almost proportional to their mass.\n\nRecent studies have indicated that the extinction of megafaunal herbivores may have caused a reduction in atmospheric methane. This hypothesis is relatively new. One study examined the methane emissions from the bison that occupied the Great Plains of North America before contact with European settlers. The study estimated that the removal of the bison caused a decrease of as much as 2.2 million tons per year. Another study examined the change in the methane concentration in the atmosphere at the end of the Pleistocene epoch after the extinction of megafauna in the Americas. After early humans migrated to the Americas about 13,000 BP, their hunting and other associated ecological impacts led to the extinction of many megafaunal species there. Calculations suggest that this extinction decreased methane production by about 9.6 million tons per year. This suggests that the absence of megafaunal methane emissions may have contributed to the abrupt climatic cooling at the onset of the Younger Dryas. The decrease in atmospheric methane that occurred at that time, as recorded in ice cores, was 2–4 times more rapid than any other decrease in the last half million years, suggesting that an unusual mechanism was at work.\n\nThe hyperdisease hypothesis, proposed by Ross MacPhee in 1997, states that the megafaunal die-off was due to an indirect transmission of diseases by newly arriving aboriginal humans. According to MacPhee, aboriginals or animals travelling with them, such as domestic dogs or livestock, introduced one or more highly virulent diseases into new environments whose native population had no immunity to them, eventually leading to their extinction. K-selection animals, such as the now-extinct megafauna, are especially vulnerable to diseases, as opposed to r-selection animals who have a shorter gestation period and a higher population size. Humans are thought to be the sole cause as other earlier migrations of animals into North America from Eurasia did not cause extinctions.\n\nThere are many problems with this theory, as this disease would have to meet several criteria: it has to be able to sustain itself in an environment with no hosts; it has to have a high infection rate; and be extremely lethal, with a mortality rate of 50–75%. Disease has to be very virulent to kill off all the individuals in a genus or species, and even such a virulent disease as West Nile Virus is unlikely to have caused extinction.\n\nHowever, diseases have been the cause for some extinctions. The introduction of avian malaria and avipoxvirus, for example, have had a negative impact on the endemic birds of Hawaii.\n\nThe loss of species from ecological communities, defaunation, is primarily driven by human activity. This has resulted in empty forests, ecological communities depleted of large vertebrates. This is not to be confused with extinction, as it includes both the disappearance of species and declines in abundance. Defaunation effects were first implied at the Symposium of Plant-Animal Interactions at the University of Campinas, Brazil in 1988 in the context of neotropical forests. Since then, the term has gained broader usage in conservation biology as a global phenomenon.\n\nBig cat populations have severely declined over the last half-century and could face extinction in the following decades. According to IUCN estimates: lions are down to 25,000, from 450,000; leopards are down to 50,000, from 750,000; cheetahs are down to 12,000, from 45,000; tigers are down to 3,000 in the wild, from 50,000. A December 2016 study by the Zoological Society of London, Panthera Corporation and Wildlife Conservation Society showed that cheetahs are far closer to extinction than previously thought, with only 7,100 remaining in the wild, and crammed within only 9% of their historic range. Human pressures are to blame for the cheetah population crash, including prey loss due to overhunting by people, retaliatory killing from farmers, habitat loss and the illegal wildlife trade.\n\nThe term pollinator decline refers to the reduction in abundance of insect and other animal pollinators in many ecosystems worldwide beginning at the end of the twentieth century, and continuing into the present day. Pollinators, which are necessary for 75% of food crops, are declining globally in both abundance and diversity. A 2017 study led by Radboud University's Hans de Kroon indicated that the biomass of insect life in Germany had declined by three-quarters in the previous 25 years. Participating researcher Dave Goulson of Sussex University stated that their study suggested that humans are making large parts of the planet uninhabitable for wildlife. Goulson characterized the situation as an approaching \"ecological Armageddon\", adding that \"if we lose the insects then everything is going to collapse.\"\n\nVarious species are predicted to become extinct in the near future, among them the rhinoceros, nonhuman primates, pangolins, and giraffes. Hunting alone threatens bird and mammalian populations around the world. Mammals in particular have suffered such severe losses as the result of human activity that it could take several million years for them to recover. According to the WWF's 2016 \"Living Planet Report\", global wildlife populations have declined 58% since 1970, primarily due to habitat destruction, over-hunting and pollution. They project that if current trends continue, 67% of wildlife could disappear by 2020. In their 2018 report, the WWF found that overconsumption of resources by the global population has destroyed 60% of animal populations since 1970, and this continued destruction of wildlife is an emergency which threatens the survival of human civilization. 189 countries, which are signatory to the Convention on Biological Diversity (Rio Accord), have committed to preparing a Biodiversity Action Plan, a first step at identifying specific endangered species and habitats, country by country.\n\nRecent extinctions are more directly attributable to human influences, whereas prehistoric extinctions can be attributed to other factors, such as global climate change. The International Union for Conservation of Nature (IUCN) characterises 'recent' extinction as those that have occurred past the cut-off point of 1500, and at least 875 species have gone extinct since that time and 2012. Some species, such as the Père David's deer and the Hawaiian crow, are extinct in the wild, and survive solely in captive populations. Other species, such as the Florida panther, are ecologically extinct, surviving in such low numbers that they essentially have no impact on the ecosystem. Other populations are only locally extinct (extirpated), still existence elsewhere, but reduced in distribution, as with the extinction of gray whales in the Atlantic, and of the leatherback sea turtle in Malaysia.\n\nGlobal warming is widely accepted as being a contributor to extinction worldwide, in a similar way that previous extinction events have generally included a rapid change in global climate and meteorology. It is also expected to disrupt sex ratios in many reptiles which have temperature-dependent sex determination.\n\nThe removal of land to clear way for palm oil plantations releases carbon emissions held in the peatlands of Indonesia. Palm oil mainly serves as a cheap cooking oil, and also as a (controversial) biofuel. However, damage to peatland contributes to 4% of global greenhouse gas emissions, and 8% of those caused by burning fossil fuels. Palm oil cultivation has also been criticized for other impacts to the environment, including deforestation, which has threatened critically endangered species such as the orangutan and the tree-kangaroo. The IUCN stated in 2016 that the species could go extinct within a decade if measures are not taken to preserve the rainforests in which they live.\n\nSome scientists and academics assert that industrial agriculture and the growing demand for meat is contributing to significant global biodiversity loss as this is a significant driver of deforestation and habitat destruction; species-rich habitats, such as significant portions of the Amazon region, are being converted to agriculture for meat production. A 2017 study by the World Wildlife Fund (WWF) found that 60% of biodiversity loss can be attributed to the vast scale of feed crop cultivation required to rear tens of billions of farm animals. Moreover, a 2006 report by the Food and Agriculture Organization (FAO) of the United Nations, \"Livestock's Long Shadow\", also found that the livestock sector is a \"leading player\" in biodiversity loss.\n\nRising levels of carbon dioxide are resulting in influx of this gas into the ocean, increasing its acidity. Marine organisms which possess calcium carbonate shells or exoskeletons experience physiological pressure as the carbonate reacts with acid. For example, this is already resulting in coral bleaching on various coral reefs worldwide, which provide valuable habitat and maintain a high biodiversity. Marine gastropods, bivalves and other invertebrates are also affected, as are the organisms that feed on them. According to a 2018 study published in \"Science\", global Orca populations are poised to collapse due to toxic chemical and PCB pollution. PCBs are still leaking into the sea in spite of being banned for decades.\n\nSome researchers suggest that by 2050 there could be more plastic than fish in the oceans by weight, with about of plastic being discharged into the oceans annually. Single-use plastics, such as plastic shopping bags, make up the bulk of this, and can often be ingested by marine life, such as with sea turtles. These plastics can degrade into microplastics, smaller particles that can affect a larger array of species. Microplastics make up the bulk of the Great Pacific Garbage Patch, and their smaller size is detrimental to cleanup efforts.\n\nOverhunting can reduce the local population of game animals by more than half, as well as reducing population density, and may lead to extinction for some species. Populations located nearer to villages are significantly more at risk of depletion. Several conservationist organizations, among them IFAW and HSUS, assert that trophy hunters, particularly from the United States, are playing a significant role in the decline of giraffes, which they refer to as a \"silent extinction\".\n\nThe surge in the mass killings by poachers involved in the illegal ivory trade along with habitat loss is threatening African elephant populations. In 1979, their populations stood at 1.7 million; at present there are fewer than 400,000 remaining. Prior to European colonization, scientists believe Africa was home to roughly 20 million elephants. According to the Great Elephant Census, 30% of African elephants (or 144,000 individuals) disappeared over a seven-year period, 2007 to 2014. African elephants could become extinct by 2035 if poaching rates continue.\n\nFishing has had a devastating effect on marine organism populations for several centuries even before the explosion of destructive and highly effective fishing practices like trawling. Humans are unique among predators in that they regularly prey on other adult apex predators, particularly in marine environments; bluefin tuna, blue whales, North Atlantic right whales and over fifty species of sharks and rays are vulnerable to predation pressure from human fishing, in particular commercial fishing. A 2016 study published in \"Science\" concludes that humans tend to hunt larger species, and this could disrupt ocean ecosystems for millions of years.\n\nThe decline of amphibian populations has also been identified as an indicator of environmental degradation. As well as habitat loss, introduced predators and pollution, Chytridiomycosis, a fungal infection thought to have been accidentally spread by human travel, has caused severe population drops of several species of frogs, including (among many others) the extinction of the golden toad in Costa Rica and the Gastric-brooding frog in Australia. Many other amphibian species now face extinction, including the reduction of Rabb's fringe-limbed treefrog to an endling, and the extinction of the Panamanian golden frog in the wild. Chytrid fungus has spread across Australia, New Zealand, Central America and Africa, including countries with high amphibian diversity such as cloud forests in Honduras and Madagascar. \"Batrachochytrium salamandrivorans\" is a similar infection currently threatening salamanders. Amphibians are now the most endangered vertebrate group, having existed for more than 300 million years through three other mass extinctions.\n\nMillions of bats in the US have been dying off since 2012 due to a fungal infection spread from European bats, which appear to be immune. Population drops have been as great as 90% within five years, and extinction of at least one bat species is predicted. There is currently no form of treatment, and such declines have been described as \"unprecedented\" in bat evolutionary history by Alan Hicks of the New York State Department of Environmental Conservation.\n\nBetween 2007 and 2013, over ten million beehives were abandoned due to colony collapse disorder, which causes worker bees to abandon the queen. This disorder has been attributed to - amongst other things - neonicotinoids consumed by worker bees from the extensive use of pesticides in human farming methods.\n\nSome leading scientists have advocated for the global community to designate as protected areas 30 percent of the planet by 2030, and 50 percent by 2050, in order to mitigate the contemporary extinction crisis as the human population is projected to grow to 10 billion by the middle of the century. Human consumption of food and water resources is also projected to double by this time.\n\nIn November 2018, the UN's biodiversity chief Cristiana Pașca Palmer urged people around the world to put pressure on governments to implement significant protections for wildlife by 2020, as rampant biodiversity loss is a \"silent killer\" as dangerous as global warming, but has received little attention by comparison. She says that \"It’s different from climate change, where people feel the impact in everyday life. With biodiversity, it is not so clear but by the time you feel what is happening, it may be too late.\"\n\n\n"}
{"id": "14209", "url": "https://en.wikipedia.org/wiki?curid=14209", "title": "Hollywood-style Lindy Hop", "text": "Hollywood-style Lindy Hop\n\nHollywood-style Lindy Hop is a variety of Lindy Hop, an American vernacular dance. It is also sometimes referred to as Dean Collins or Smooth-style, but these terms also sometimes refer to different styles of Lindy Hop.\n\nHollywood is the style reconstructed by Erik Robison and Sylvia Skylar based on movies from 1930s and 1940s featuring dancers like Dean Collins, Jewel McGowan, Jean Veloz and others. They were the first to call it \"Hollywood Style\".\n\nThe swingout (the basic step of Lindy) is danced in a position often described as someone about to sit on a stool, thereby bringing their center point of balance closer to the ground. This piked position is the classic look of Hollywood with the back straight and a slight forward tilt. The Hollywood style is also a slotted dance, meaning the follower travels in a straight line instead of the more elliptical or circular Savoy-style Lindy Hop.\n\nA popular variation of Hollywood-Style Lindy Hop called LA-style Lindy Hop has a few technical changes in the footwork and fewer steps. The steps are shortened or \"cheated\" to create this look. The style is geared towards performance and is heavily based on short choreographies. Originating in Los Angeles, LA-style is a favorite on the west coast of the United States.\n"}
{"id": "14210", "url": "https://en.wikipedia.org/wiki?curid=14210", "title": "Harrison Narcotics Tax Act", "text": "Harrison Narcotics Tax Act\n\nThe Harrison Narcotics Tax Act (Ch. 1, ) was a United States federal law that regulated and taxed the production, importation, and distribution of opiates and coca products. The act was proposed by Representative Francis Burton Harrison of New York and was approved on December 17, 1914.\n\n\"An Act To provide for the registration of, with collectors of internal revenue, and to impose a special tax on all persons who produce, import, manufacture, compound, deal in, dispense, sell, distribute, or give away opium or coca leaves, their salts, derivatives, or preparations, and for other purposes.\" The courts interpreted this to mean that physicians could prescribe narcotics to patients in the course of normal treatment, but not for the treatment of addiction.\n\nThe Harrison Anti-Narcotic legislation consisted of three U.S. House bills imposing restrictions on the availability and consumption of the psychoactive drug opium. U.S. House bills and passed conjointly with House bill or the Opium and Coca Leaves Trade Restrictions Act.\n\nAlthough technically illegal for purposes of distribution and use, the distribution, sale and use of cocaine was still legal for registered companies and individuals.\n\nFollowing the Spanish–American War the U.S. acquired the Philippines from Spain. At that time, opium addiction constituted a significant problem in the civilian population of the Philippines.\n\nCharles Henry Brent was an American Episcopal bishop who served as Missionary Bishop of the Philippines beginning in 1901. He convened a Commission of Inquiry, known as the Brent Commission, for the purpose of examining alternatives to a licensing system for opium addicts. The Commission recommended that narcotics should be subject to international control. The recommendations of the Brent Commission were endorsed by the United States Department of State and in 1906 President Theodore Roosevelt called for an international conference, the International Opium Commission, which was held in Shanghai in February 1909. A second conference was held at The Hague in May 1911, and out of it came the first international drug control treaty, the International Opium Convention of 1912.\n\nIn the 1800s opiates and cocaine were mostly unregulated drugs. In the 1890s the Sears & Roebuck catalogue, which was distributed to millions of Americans homes, offered a syringe and a small amount of cocaine for $1.50. On the other hand, as early as 1880 some states and localities had already passed laws against smoking opium, at least in public.\n\nAt the beginning of the 20th century, cocaine began to be linked to crime. In 1900, the \"Journal of the American Medical Association\" published an editorial stating, \"Negroes in the South are reported as being addicted to a new form of vice – that of 'cocaine sniffing' or the 'coke habit.'\" Some newspapers later claimed cocaine use caused blacks to rape white women and was improving their pistol marksmanship. Chinese immigrants were blamed for importing the opium-smoking habit to the U.S. The 1903 blue-ribbon citizens' panel, the Committee on the Acquirement of the Drug Habit, concluded, \"If the Chinaman cannot get along without his dope we can get along without him.\"\n\nTheodore Roosevelt appointed Dr. Hamilton Wright as the first Opium Commissioner of the United States in 1908. In 1909, Wright attended the International Opium Commission in Shanghai as the American delegate. He was accompanied by Charles Henry Brent, the Episcopal Bishop. On March 12, 1911, Dr. Wright was quoted as follows in an article in \"The New York Times\": \"Of all the nations of the world, the United States consumes most habit-forming drugs per capita. Opium, the most pernicious drug known to humanity, is surrounded, in this country, with far fewer safeguards than any other nation in Europe fences it with.\" Wright further claimed that \"it has been authoritatively stated that cocaine is often the direct incentive to the crime of rape by the negroes of the South and other sections of the country,\" though he failed to mention specifically \"which\" authorities had stated that, and did not provide any evidence for his claim. Wright also stated that \"one of the most unfortunate phases of smoking opium in this country is the large number of women who have become involved and were living as common-law wives or cohabitating with Chinese in the Chinatowns of our various cities\".\n\nOpium usage had begun to decline by 1914 after rising dramatically in the post Civil War Era, peaking at around one-half million pounds per year in 1896. Demand gradually declined thereafter in response to mounting public concern, local and state regulations, and the Pure Food and Drugs Act of 1906, which required labeling of patent medicines that contained opiates, cocaine, alcohol, cannabis and other intoxicants. As of 1911, an estimated one U.S. citizen in 400 (0.25%) was addicted to some form of opium. The opium addicts were mostly women who were prescribed and dispensed legal opiates by physicians and pharmacist for \"female problems\" (probably pain at menstruation) or white men and Chinese at the Opium dens. Between two-thirds and three-quarters of these addicts were women. By 1914, forty-six states had regulations on cocaine and twenty-nine states had laws against opium, morphine, and heroin.\n\nSeveral authors have argued that the debate was merely to regulate trade and collect a tax. However, the committee report prior to the debate on the house floor and the debate itself, discussed the rise of opiate use in the United States. Harrison stated that \"The purpose of this Bill can hardly be said to raise revenue, because it prohibits the importation of something upon which we have hitherto collected revenue.\" Later Harrison stated, \"We are not attempting to collect revenue, but regulate commerce.\" House representative Thomas Sisson stated, \"The purpose of this bill—and we are all in sympathy with it—is to prevent the use of opium in the United States, destructive as it is to human happiness and human life.\"\n\nThe drafters played on fears of \"drug-crazed, sex-mad negroes\" and made references to Negroes under the influence of drugs murdering whites, degenerate Mexicans smoking marijuana, and \"Chinamen\" seducing white women with drugs. Dr. Hamilton Wright, testified at a hearing for the Harrison Act. Wright alleged that drugs made blacks uncontrollable, gave them superhuman powers and caused them to rebel against white authority. Dr. Christopher Koch of the State Pharmacy Board of Pennsylvania testified that \"Most of the attacks upon the white women of the South are the direct result of a cocaine-crazed Negro brain\".\n\nBefore the Act was passed, on February 8, 1914, \"The New York Times\" published an article entitled \"Negro Cocaine 'Fiends' Are New Southern Menace: Murder and Insanity Increasing Among Lower-Class Blacks\" by Edward Huntington Williams, which reported that Southern sheriffs had increased the caliber of their weapons from .32 to .38 to bring down Negroes under the effect of cocaine.\n\nDespite the extreme racialization of the issue that took place in the buildup to the Act's passage, the contemporary research on the subject indicated that black Americans were in fact using cocaine and opium at much \"lower\" rates than white Americans.\n\nEnforcement began in 1915.\n\nThe act appears to be concerned about the marketing of opiates. However a clause applying to doctors allowed distribution \"in the course of his professional practice only.\" This clause was interpreted after 1917 to mean that a doctor could not prescribe opiates to an addict, since addiction was not considered a disease. A number of doctors were arrested and some were imprisoned. The medical profession quickly learned not to supply opiates to addicts. In \"United States v. Doremus\", 249 U.S. 86 (1919), the Supreme Court ruled that the Harrison Act was constitutional, and in \"Webb v. United States\", 249 U.S. 96, 99 (1919) that physicians could not prescribe narcotics solely for maintenance.\n\nThe impact of diminished supply was obvious by mid-1915. A 1918 commission called for sterner law enforcement, while newspapers published sensational articles about addiction-related crime waves. Congress responded by tightening up the Harrison Act—the importation of heroin for any purpose was banned in 1924.\n\nAfter other complementary laws (for example implementing the Uniform State Narcotic Act in 1932), and other actions by the government the number of addicts of opium started to decrease fast from 1925 to a level that in 1945 that was about one tenth of the level in 1914.\n\nThe use of the term 'narcotics' in the title of the act to describe not just opiates but also cocaine—which is a central nervous system stimulant, not a narcotic—initiated a precedent of frequent legislative and judicial misclassification of various substances as 'narcotics'. Today, law enforcement agencies, popular media, the United Nations, other nations and even some medical practitioners can be observed applying the term very broadly and often pejoratively in reference to a wide range of illicit substances, regardless of the more precise definition existing in medical contexts. For this reason, however, 'narcotic' has come to mean any illegally used drug, but it is useful as a shorthand for referring to a controlled drug in a context where its legal status is more important than its physiological effects.\n\nThe remaining effect of this act, which has largely been superseded by the Controlled Substances Act of 1970, is the warning \"*Warning: May be habit forming\" on labels, package inserts, and other places where ingredients are listed in the case of many opioids, barbiturates, medicinal formulations of cocaine, and chloral hydrate.\n\nThe act also marks the beginning of the creation of the modern, criminal drug addict and the American black market for drugs. Within five years the Rainey Committee, a Special Committee on Investigation appointed by Secretary of the Treasury William Gibbs McAdoo and led by Congressman T. Rainey, reported in June, 1919 that drugs were being smuggled into the country by sea, and across the Mexican and Canadian borders by nationally established organisations and that the United States consumed 470,000 pounds of opium annually, compared to 17,000 pounds in both France and Germany. The Monthly Summary of Foreign Commerce of the United States recorded that in the 7 months to January 1920, 528,635 pounds of opium was imported, compared to 74,650 pounds in the same period in 1919.\n\nThe Act's applicability in prosecuting doctors who prescribe narcotics to addicts was successfully challenged in \"Linder v. United States\" in 1925, as Justice McReynolds ruled that the federal government has no power to regulate medical practice.\n\n"}
{"id": "14215", "url": "https://en.wikipedia.org/wiki?curid=14215", "title": "Horse tack", "text": "Horse tack\n\nTack refers to equipment or accessories equipped on horses and other equines in the course of their use as domesticated animals. Saddles, stirrups, bridles, halters, reins, bits, harnesses, martingales, and breastplates are all forms of horse tack. Equipping a horse is often referred to as tacking up. A room to store such equipment, usually near or in a stable, is a tack room.\n\nSaddles are seats for the rider, fastened to the horse's back by means of a \"girth\" (English-style riding), known as a \"cinch\" in the Western US, a wide strap that goes around the horse at a point about four inches behind the forelegs. Some western saddles will also have a second strap known as a \"flank\" or \"back cinch\" that fastens at the rear of the saddle and goes around the widest part of the horse's belly.\n\nIt is important that the saddle be comfortable for both the rider and the horse as an improperly fitting saddle may create pressure points on the horse's back muscle (Latissimus dorsi) and cause the horse pain and can lead to the horse, rider, or both getting injured.\n\nThere are many types of saddle, each specially designed for its given task.\nSaddles are usually divided into two major categories: \"English saddles\" and \"Western saddles\" according to the riding discipline they are used in. Other types of saddles, such as racing saddles, Australian saddles, sidesaddles and endurance saddles do not necessarily fit neatly in either category.\n\n\nStirrups are supports for the rider's feet that hang down on either side of the saddle. They provide greater stability for the rider but can have safety concerns due to the potential for a rider's feet to get stuck in them. If a rider is thrown from a horse but has a foot caught in the stirrup, they could be dragged if the horse runs away. To minimize this risk, a number of safety precautions are taken. First, most riders wear riding boots with a heel and a smooth sole. Next, some saddles, particularly English saddles, have safety bars that allow a stirrup leather to fall off the saddle if pulled backwards by a falling rider. Other precautions are done with stirrup design itself. Western saddles have wide stirrup treads that make it more difficult for the foot to become trapped. A number of saddle styles incorporate a tapedero, which is covering over the front of the stirrup that keeps the foot from sliding all the way through the stirrup. The English stirrup (or \"iron\") has several design variations which are either shaped to allow the rider's foot to slip out easily or are closed with a very heavy rubber band. The invention of stirrups was of great historic significance in mounted combat, giving the rider secure foot support while on horseback.\n\n\"Bridles\", hackamores, \"halters\" or \"headcollars\", and similar equipment consist of various arrangements of straps around the horse's head, and are used for control and communication with the animal.\n\nA \"halter\" (US) or \"headcollar\" (UK) (occasionally \"headstall\") consists of a noseband and headstall that buckles around the horse's head and allows the horse to be led or tied. The lead rope is separate, and it may be short (from six to ten feet, two to three meters) for everyday leading and tying, or much longer (up to , eight meters) for tasks such as for leading packhorses or for picketing a horse out to graze.\n\nSome horses, particularly stallions, may have a chain attached to the lead rope and placed over the nose or under the jaw to increase the control provided by a halter while being led. Most of the time, horses are not ridden with a halter, as it offers insufficient precision and control. Halters have no bit.\n\nIn Australian and British English, a \"halter\" is a rope with a spliced running loop around the nose and another over the poll, used mainly for unbroken horses or for cattle. The lead rope cannot be removed from the halter. A show halter is made from rolled leather and the lead attaches to form the chinpiece of the noseband. These halters are not suitable for paddock usage or in loose stalls. An \"underhalter\" is a lightweight halter or headcollar which is made with only one small buckle, and can be worn under a bridle for tethering a horse without untacking.\n\nBridles usually have a \"bit\" attached to \"reins\" and are used for riding and driving horses.\n\n\"English Bridles\" have a \"cavesson\" style noseband and are seen in English riding. Their reins are buckled to one another, and they have little adornment or flashy hardware.\n\n\"Western Bridles\" used in Western riding usually have no noseband, are made of thin bridle leather. They may have long, separated \"Split\" reins or shorter closed reins, which sometimes include an attached \"Romal\". Western bridles are often adorned with silver or other decorative features.\n\n\"Double bridles\" are a type of English bridle that use two bits in the mouth at once, a snaffle and a curb. The two bits allow the rider to have very precise control of the horse. As a rule, only very advanced horses and riders use double bridles. Double bridles are usually seen in the top levels of dressage, but also are seen in certain types of show hack and Saddle seat competition.\n\nA \"hackamore\" is a headgear that utilizes a heavy noseband of some sort, rather than a bit, most often used to train young horses or to go easy on an older horse's mouth. Hackamores are more often seen in western riding. Some related styles of headgear that control a horse with a noseband rather than a bit are known as bitless bridles.\n\nThe word \"hackamore\" is derived from the Spanish word \"jáquima.\" Hackamores are seen in western riding disciplines, as well as in endurance riding and English riding disciplines such as show jumping and the stadium phase of eventing. While the classic bosal-style hackamore is usually used to start young horses, other designs, such as various bitless bridles and the mechanical hackamore are often seen on mature horses with dental issues that make bit use painful, horses with certain training problems, and on horses with mouth or tongue injuries. Some riders also like to use them in the winter to avoid putting a frozen metal bit into a horse's mouth.\n\nLike bitted bridles, noseband-based designs can be gentle or harsh, depending on the hands of the rider. It is a myth that a bit is cruel and a hackamore is gentler. The horse's face is very soft and sensitive with many nerve endings. Misuse of a hackamore can cause swelling on the nose, scraping on the nose and jawbone, and extreme misuse may cause damage to the bones and cartilage of the horse's head.\n\nA \"longeing cavesson\" (UK: \"lungeing\") is a special type of halter or noseband used for longeing a horse. Longeing is the activity of having a horse walk, trot and/or canter in a large circle around the handler at the end of a rope that is 25 to long. It is used for training and exercise.\n\nReins consist of leather straps or rope attached to the outer ends of a \"bit\" and extend to the rider's or driver's hands. Reins are the means by which a horse rider or driver communicates directional commands to the horse's head. Pulling on the reins can be used to steer or stop the horse. The sides of a horse's mouth are sensitive, so pulling on the reins pulls the bit, which then pulls the horse's head from side to side, which is how the horse is controlled.\n\nOn some types of harnesses there might be supporting rings to carry the reins over the horse's back. When pairs of horses are used in drawing a wagon or coach it is usual for the outer side of each pair to be connected to reins and the inside of the bits connected by a short bridging strap or rope. The driver carries \"four-in-hand\" or \"six-in-hand\" being the number of reins connecting to the pairs of horses.\n\nA rein may be attached to a halter to lead or guide the horse in a circle for training purposes or to lead a packhorse, but a simple lead rope is more often used for these purposes. A longe line is sometimes called a \"longe rein,\" but it is actually a flat line about long, usually made of nylon or cotton web, about one inch wide, thus longer and wider than even a driving rein.\n\nHorses should never be tied by the reins. Not only do they break easily, but, being attached to a bit in the horse's sensitive mouth, a great deal of pain can be inflicted if a bridled horse sets back against being tied.\n\nA bit is a device placed in a horse's mouth, kept on a horse's head by means of a headstall. There are many types, each useful for specific types of riding and training.\n\nThe mouthpiece of the bit does not rest on the teeth of the horse, but rather rests on the gums or \"bars\" of the horse's mouth in an interdental space behind the front incisors and in front of the back molars. It is important that the style of bit is appropriate to the horse's needs and is fitted properly for it to function properly and be as comfortable as possible for the horse.\n\nThe basic \"classic\" styles of bits are:\n\nWhile there are literally hundreds of types of bit mouthpieces, bit rings and bit shanks, essentially there are really only two broad categories: direct pressure bits, broadly termed snaffle bits; and leverage bits, usually termed curbs.\n\nBits that act with direct pressure on the tongue and lips of the bit are in the general category of \"snaffle\" bits. Snaffle bits commonly have a single jointed mouthpiece and act with a nutcracker effect on the bars, tongue and occasionally roof of the mouth. However, regardless of mouthpiece, any bit that operates only on direct pressure is a \"snaffle\" bit.\n\nLeverage bits have shanks coming off the mouthpiece to create leverage that applies pressure to the poll, chin groove and mouth of the horse are in the category of \"curb\" bits. Any bit with shanks that works off of leverage is a \"curb\" bit, regardless of whether the mouthpiece is solid or jointed.\n\nSome combination or hybrid bits combine direct pressure and leverage, such as the Kimblewick or Kimberwicke, which adds slight leverage to a two-rein design that resembles a snaffle; and the four rein designs such as the single mouthpiece Pelham bit and the double bridle, which places a curb and a snaffle bit simultaneously in the horse's mouth.\n\nIn the wrong hands even the mildest bit can hurt the horse. Conversely, a very severe bit, in the right hands, can transmit subtle commands that cause no pain to the horse. Bit commands should be given with only the quietest movements of the hands, and much steering and stopping should be done with the legs and seat.\n\nA horse harness is a set of devices and straps that attaches a horse to a cart, carriage, sledge or any other load. There are two main styles of harnesses - breaststrap and collar and hames style. These differ in how the weight of the load is attached. Most Harnesses are made from leather, which is the traditional material for harnesses, though some designs are now made of nylon webbing or synthetic biothane.\n\nA breaststrap harness has a wide leather strap going horizontally across the horses' breast, attached to the traces and then to the load. This is used only for lighter loads. A collar and hames harness has a collar around the horses' neck with wood or metal hames in the collar. The traces attach from the hames to the load. This type of harness is needed for heavy draft work.\n\nBoth types will also have a bridle and reins. A harness that is used to support shafts, such as on a cart pulled by a single horse, will also have a \"saddle\" attached to the harness to help the horse support the shafts and \"breeching\" to brake the forward motion of the vehicle, especially when stopping or moving downhill. Horses guiding vehicles by means of a pole, such as two-horse teams pulling a wagon, a hay-mower, or a dray, will have \"pole-straps\" attached to the lower part of the horse collar.\n\nBreastplates, breastcollars or breastgirths attach to the front of the saddle, cross the horse's chest, and usually have a strap that runs between the horse's front legs and attaches to the girth. They keep the saddle from sliding back or sideways. They are usually seen in demanding, fast-paced sports. They are crucial pieces of safety equipment for English riding activities requiring jumping, such as eventing, show jumping, polo, and fox hunting. They are also seen in Western riding events, particularly in rodeo, reining and cutting, where it is particularly important to prevent a saddle from shifting. They may also be worn in other horse show classes for decorative purposes.\n\nA martingale is a piece of equipment that keeps a horse from raising its head too high. Various styles can be used as a control measure, to prevent the horse from avoiding rider commands by raising its head out of position; or as a safety measure to keep the horse from tossing its head high or hard enough to smack its rider in the face.\n\nThey are allowed in many types of competition, especially those where speed or jumping may be required, but are not allowed in most \"flat\" classes at horse shows, though an exception is made in a few classes limited exclusively to young or \"green\" horses who may not yet be fully trained.\n\nMartingales are usually attached to the horse one of two ways. They are either attached to the center chest ring of a breastplate or, if no breastplate is worn, they are attached by two straps, one that goes around the horse's neck, and the other that attaches to the girth, with the martingale itself beginning at the point in the center of the chest where the neck and girth straps intersect.\n\nMartingale types include:\n\n\n\nThere are other training devices that fall loosely in the martingale category, in that they use straps attached to the reins or bit which limit the movement of the horse's head or add leverage to the rider's hands in order to control the horse's head. Common devices of this nature include the overcheck, the chambon, de Gogue, grazing reins, draw reins and the \"bitting harness\" or \"bitting rig\". However, most of this equipment is used for training purposes and is not legal in any competition. In some disciplines, use of leverage devices, even in training, is controversial.\n\n"}
{"id": "14216", "url": "https://en.wikipedia.org/wiki?curid=14216", "title": "Hausa language", "text": "Hausa language\n\nHausa (; \"Yaren Hausa\" or \"Harshen Hausa\") is the Chadic language (a branch of the Afroasiatic language family) with the largest number of speakers, spoken as a first language by some 44 million people, and as a second language by another 20 million. The total number of Hausa speakers is estimated at 63 million, according to Ethnologue.\nThe ancestral language of the Hausa people, one of the largest ethnic groups in Central Africa, Hausa is mostly spoken throughout southern Niger and northern Nigeria. It has developed into a lingua franca across much of Western Africa for purposes of trade.\n\nHausa belongs to the West Chadic languages subgroup of the Chadic languages group, which in turn is part of the Afroasiatic language family.\n\nNative speakers of Hausa, the Hausa people, are mostly found in Niger, in Northern Nigeria, and in Chad. Furthermore, the language is used as a \"lingua franca\" by non-native speakers in most of Northern Nigeria and Southern Niger, and as a trade language across a much larger swathe of West Africa (Benin, Ghana, Cameroon, Togo, Ivory Coast) and parts of Sudan).\n\nEastern Hausa dialects include \"Dauranci\" in Daura, \"Kananci\" in Kano, \"Bausanci\" in Bauchi, \"Gudduranci\" in Katagum Misau and part of Borno, and \"Hadejanci\" in Hadejiya.\n\nWestern Hausa dialects include \"Sakkwatanci\" in Sokoto, \"Katsinanci\" in Katsina, \"Arewanci\" in Gobir, Adar, Kebbi, and Zamfara, and \"Kurhwayanci\" in Kurfey in Niger. Katsina is transitional between Eastern and Western dialects.\n\nNorthern Hausa dialects include \"Arewa\" and \"Arewaci\".\n\n\"Zazzaganci\" in Zazzau is the major Southern dialect.\n\nThe Daura (\"Dauranchi\") and Kano (\"Kananci\") dialect are the standard. The BBC, Deutsche Welle, Radio France Internationale and Voice of America offer Hausa services on their international news web sites using Dauranci and Kananci. In recent language development Zazzaganci took over the innovation of writing and speaking the current Hausa language use.\n\nThe western to eastern Hausa dialects of \"Kurhwayanci\", \"Daragaram\" and \"Aderawa\", represent the traditional northernmost limit of native Hausa communities. These are spoken in the northernmost sahel and mid-Saharan regions in west and central Niger in the Tillaberi, Tahoua, Dosso, Maradi, Agadez and Zinder regions. While mutually comprehensible with other dialects (especially \"Sakkwatanci\", and to a lesser extent \"Gaananci\"), the northernmost dialects have slight grammatical and lexical differences owing to frequent contact with the Zarma and Tuareg groups and cultural changes owing to the geographical differences between the grassland and desert zones. These dialects also have the quality of being non-tonal or pitch accent dialects.\n\nThis link between non-tonality and geographic location is not limited to Hausa alone, but is exhibited in other northern dialects of neighbouring languages; such as the difference within Songhay language (between the non-tonal northernmost dialects of Koyra Chiini in Timbuktu and Koyraboro Senni in Gao; and the tonal southern Zarma dialect, spoken from western Niger to northern Ghana), and within the Soninke language (between the non-tonal northernmost dialects of Imraguen and Nemadi spoken in east-central Mauritania; and the tonal southern dialects of Senegal, Mali and the sahel).\n\nThe Ghanaian Hausa dialect (\"Gaananci\"), spoken in Ghana, Togo, and western Ivory Coast, is a distinct western native Hausa dialect-bloc with adequate linguistic and media resources available. Separate smaller Hausa dialects are spoken by an unknown number of Hausa further west in parts of Burkina Faso, and in the Haoussa Foulane, Badji Haoussa, Guezou Haoussa, and Ansongo districts of northeastern Mali (where it is designated as a minority language by the Malian government), but there are very little linguistic resources and research done on these particular dialects at this time.\n\nGaananci forms a separate group from other Western Hausa dialects, as it now falls outside the contiguous Hausa-dominant area, and is usually identified by the use of \"c\" for \"ky\", and \"j\" for \"gy\". This is attributed to the fact that Ghana's Hausa population descend from Hausa-Fulani traders settled in the zongo districts of major trade-towns up and down the previous Asante, Gonja and Dagomba kingdoms stretching from the sahel to coastal regions, in particular the cities of Tamale, Salaga, Bawku, Bolgatanga, Achimota, Nima and Kumasi.\n\nGaananci exhibits noted inflected influences from Zarma, Gur, Dyula and Soninke, as Ghana is the westernmost area in which the Hausa language is a major lingua-franca; as well as it being the westernmost area both the Hausa and Djerma ethnic groups inhabit in large numbers. Immediately west from Ghana (in Ivory Coast, Togo, and Burkina Faso), Hausa is abruptly replaced with Dioula–Bambara as the main lingua-franca of what become predominantly Mandinka areas, and native Hausa populations plummet to a very small urban minority.\n\nBecause of this, and the presence of surrounding Akan, Gur and Mande languages, Gaananci was historically isolated from the other Hausa dialects. Despite this difference, grammatical similarities between \"Sakkwatanci\" and Ghanaian Hausa determine that the dialect, and the origin of the Ghanaian Hausa people themselves, are derived from the northwestern Hausa area surrounding Sokoto.\n\nHausa is also widely spoken by non-native Gur and Mande Ghanaian Muslims, but differs from Gaananci, and rather has features consistent with non-native Hausa dialects.\n\nHausa is also spoken in various parts of Cameroon and Chad, which combined the mixed dialects of northern Nigeria and Niger. In addition, Arabic has had a great influence in the way Hausa is spoken by the native Hausa speakers in these areas.\n\nIn West Africa, Hausa's use as a lingua franca has given rise to a non-native pronunciation that differs vastly from native pronunciation by way of key omissions of implosive and ejective consonants present in native Hausa dialects, such as \"ɗ\", \"ɓ\" and \"kʼ/ƙ\", which are pronounced by non-native speakers as \"d\", \"b\" and \"k\" respectively. This creates confusion among non-native and native Hausa speakers, as non-native pronunciation does not distinguish words like ' (\"correct\") and ' (\"one-by-one\"). Another difference between native and non-native Hausa is the omission of vowel length in words and change in the standard tone of native Hausa dialects (ranging from native Fulani and Tuareg Hausa-speakers omitting tone altogether, to Hausa speakers with Gur or Yoruba mother tongues using additional tonal structures similar to those used in their native languages). Use of masculine and feminine gender nouns and sentence structure are usually omitted or interchanged, and many native Hausa nouns and verbs are substituted with non-native terms from local languages.\n\nNon-native speakers of Hausa numbered more than 25 million and, in some areas, live close to native Hausa. It has replaced many other languages especially in the north-central and north-eastern part of Nigeria and continues to gain popularity in other parts of Africa as a result of Hausa movies and music which spread out throughout the region.\n\nThere are several pidgin forms of Hausa. Barikanchi was formerly used in the colonial army of Nigeria. Gibanawa is currently in widespread use in Jega in northwestern Nigeria, south of the native Hausa area.\n\nHausa has between 23 and 25 consonant phonemes depending on the speaker.\n\nThe three-way contrast between palatalized velars , plain velars , and labialized velars is found only before long and short , e.g. ('grass'), ('to increase'), ('shea-nuts'). Before front vowels, only palatalized and labialized velars occur, e.g. ('jealousy') vs. ('side of body'). Before rounded vowels, only labialized velars occur, e.g. ('ringworm').\n\nHausa has glottalic consonants (implosives and ejectives) at four or five places of articulation (depending on the dialect). They require movement of the glottis during pronunciation and have a staccato sound.\n\nThey are written with modified versions of Latin letters. They can also be denoted with an apostrophe, either before or after depending on the letter, as shown below.\n\n\nHausa has five phonetic vowel sounds, which can be either short or long, giving a total of 10 monophthongs. In addition, there are four joint vowels (diphthongs), giving a total number of 14 vowel phonemes.\n\n\nIn comparison with the long vowels, the short can be similar in quality to the long vowels, mid-centralized to or centralized to .\n\nMedial can be neutralized to , with the rounding depending on the environment.\n\nMedial are neutralized with .\n\nThe short can be either similar in quality to the long , or it can be as high as , with possible intermediate pronunciations ().\n\n\nHausa is a tonal language. Each of its five vowels may have low tone, high tone or falling tone. In standard written Hausa, tone is not marked. In recent linguistic and pedagogical materials, tone is marked by means of diacritics.\n\nAn acute accent () may be used for high tone, but the usual practice is to leave high tone unmarked.\n\nHausa's modern official orthography is a Latin-based alphabet called \"boko\", which was introduced in the 1930s by the British colonial administration.\nThe letter \"ƴ\" (y with a right hook) is used only in Niger; in Nigeria it is written \"ʼy\".\n\nTone, vowel length, and the distinction between and (which does not exist for all speakers) are not marked in writing. So, for example, \"from\" and \"battle\" are both written \"daga\".\n\nHausa has also been written in \"ajami\", an Arabic alphabet, since the early 17th century. The first known work to be written in Hausa is Riwayar Nabi Musa by Abdullahi Suka in the 17th century. There is no standard system of using \"ajami\", and different writers may use letters with different values. Short vowels are written regularly with the help of vowel marks, which are seldom used in Arabic texts other than the Quran. Many medieval Hausa manuscripts in \"ajami\", similar to the Timbuktu Manuscripts, have been discovered recently; some of them even describe constellations and calendars.\n\nIn the following table, vowels are shown with the Arabic letter for \"t\" () as an example.\n\nHausa is one of three indigenous languages of Nigeria which has been rendered in braille.\n\nAt least three other writing systems for Hausa have been proposed or \"discovered\". None of these are in active use beyond perhaps some individuals.\n\n\n\n17. \n\n"}
{"id": "14220", "url": "https://en.wikipedia.org/wiki?curid=14220", "title": "History of mathematics", "text": "History of mathematics\n\nThe area of study known as the history of mathematics is primarily an investigation into the origin of discoveries in mathematics and, to a lesser extent, an investigation into the mathematical methods and notation of the past. Before the modern age and the worldwide spread of knowledge, written examples of new mathematical developments have come to light only in a few locales. From 3000 BC the Mesopotamian states of Sumer, Akkad and Assyria, together with Ancient Egypt and Ebla began using arithmetic, algebra and geometry for purposes of taxation, commerce, trade and also in the field of astronomy and to formulate calendars and record time.\n\nThe most ancient mathematical texts available are from Mesopotamia and Egypt - \"Plimpton 322\" (Babylonian c. 1900 BC), the \"Rhind Mathematical Papyrus\" (Egyptian c. 2000–1800 BC) and the \"Moscow Mathematical Papyrus\" (Egyptian c. 1890 BC). All of these texts mention the so-called Pythagorean triples and so, by inference, the Pythagorean theorem, seems to be the most ancient and widespread mathematical development after basic arithmetic and geometry.\n\nThe study of mathematics as a \"demonstrative discipline\" begins in the 6th century BC with the Pythagoreans, who coined the term \"mathematics\" from the ancient Greek \"μάθημα\" (\"mathema\"), meaning \"subject of instruction\". Greek mathematics greatly refined the methods (especially through the introduction of deductive reasoning and mathematical rigor in proofs) and expanded the subject matter of mathematics. Although they made virtually no contributions to theoretical mathematics, the ancient Romans used applied mathematics in surveying, structural engineering, mechanical engineering, bookkeeping, creation of lunar and solar calendars, and even arts and crafts. Chinese mathematics made early contributions, including a place value system and the first use of negative numbers. The Hindu–Arabic numeral system and the rules for the use of its operations, in use throughout the world today evolved over the course of the first millennium AD in India and were transmitted to the Western world via Islamic mathematics through the work of Muḥammad ibn Mūsā al-Khwārizmī. Islamic mathematics, in turn, developed and expanded the mathematics known to these civilizations. Contemporaneous with but independent of these traditions were the mathematics developed by the Maya civilization of Mexico and Central America, where the concept of zero was given a standard symbol in Maya numerals.\n\nMany Greek and Arabic texts on mathematics were translated into Latin from the 12th century onward, leading to further development of mathematics in Medieval Europe. From ancient times through the Middle Ages, periods of mathematical discovery were often followed by centuries of stagnation. Beginning in Renaissance Italy in the 15th century, new mathematical developments, interacting with new scientific discoveries, were made at an increasing pace that continues through the present day. This includes the groundbreaking work of both Isaac Newton and Gottfried Wilhelm Leibniz in the development of infinitesimal calculus during the course of the 17th century. At the end of the 19th century the International Congress of Mathematicians was founded and continues to spearhead advances in the field.\n\nThe origins of mathematical thought lie in the concepts of number, magnitude, and form. Modern studies of animal cognition have shown that these concepts are not unique to humans. Such concepts would have been part of everyday life in hunter-gatherer societies. The idea of the \"number\" concept evolving gradually over time is supported by the existence of languages which preserve the distinction between \"one\", \"two\", and \"many\", but not of numbers larger than two.\n\nPrehistoric artifacts discovered in Africa, dated 20,000 years old or more suggest early attempts to quantify time. The Ishango bone, found near the headwaters of the Nile river (northeastern Congo), may be more than 20,000 years old and consists of a series of marks carved in three columns running the length of the bone. Common interpretations are that the Ishango bone shows either a \"tally\" of the earliest known demonstration of sequences of prime numbers or a six-month lunar calendar. Peter Rudman argues that the development of the concept of prime numbers could only have come about after the concept of division, which he dates to after 10,000 BC, with prime numbers probably not being understood until about 500 BC. He also writes that \"no attempt has been made to explain why a tally of something should exhibit multiples of two, prime numbers between 10 and 20, and some numbers that are almost multiples of 10.\" The Ishango bone, according to scholar Alexander Marshack, may have influenced the later development of mathematics in Egypt as, like some entries on the Ishango bone, Egyptian arithmetic also made use of multiplication by 2; this however, is disputed.\n\nPredynastic Egyptians of the 5th millennium BC pictorially represented geometric designs. It has been claimed that megalithic monuments in England and Scotland, dating from the 3rd millennium BC, incorporate geometric ideas such as circles, ellipses, and Pythagorean triples in their design. All of the above are disputed however, and the currently oldest undisputed mathematical documents are from Babylonian and dynastic Egyptian sources.\n\nBabylonian mathematics refers to any mathematics of the peoples of Mesopotamia (modern Iraq) from the days of the early Sumerians through the Hellenistic period almost to the dawn of Christianity. The majority of Babylonian mathematical work comes from two widely separated periods: The first few hundred years of the second millennium BC (Old Babylonian period), and the last few centuries of the first millennium BC (Seleucid period). It is named Babylonian mathematics due to the central role of Babylon as a place of study. Later under the Arab Empire, Mesopotamia, especially Baghdad, once again became an important center of study for Islamic mathematics.\nIn contrast to the sparsity of sources in Egyptian mathematics, our knowledge of Babylonian mathematics is derived from more than 400 clay tablets unearthed since the 1850s. Written in Cuneiform script, tablets were inscribed whilst the clay was moist, and baked hard in an oven or by the heat of the sun. Some of these appear to be graded homework.\n\nThe earliest evidence of written mathematics dates back to the ancient Sumerians, who built the earliest civilization in Mesopotamia. They developed a complex system of metrology from 3000 BC. From around 2500 BC onwards, the Sumerians wrote multiplication tables on clay tablets and dealt with geometrical exercises and division problems. The earliest traces of the Babylonian numerals also date back to this period.\nBabylonian mathematics were written using a sexagesimal (base-60) numeral system. From this derives the modern day usage of 60 seconds in a minute, 60 minutes in an hour, and 360 (60 x 6) degrees in a circle, as well as the use of seconds and minutes of arc to denote fractions of a degree. It is likely the sexagesimal system was chosen because 60 can be evenly divided by 2, 3, 4, 5, 6, 10, 12, 15, 20 and 30. Also, unlike the Egyptians, Greeks, and Romans, the Babylonians had a true place-value system, where digits written in the left column represented larger values, much as in the decimal system. The power of the Babylonian notational system lay in that it could be used to represent fractions as easily as whole numbers; thus multiplying two numbers that contained fractions was no different than multiplying integers, similar to our modern notation. The notational system of the Babylonians was the best of any civilization until the Renaissance, and its power allowed it to achieve remarkable computation accuracy and power; for example, the Babylonian tablet YBC 7289 gives an approximation of accurate to five decimal places. The Babylonians lacked, however, an equivalent of the decimal point, and so the place value of a symbol often had to be inferred from the context. By the Seleucid period, the Babylonians had developed a zero symbol as a placeholder for empty positions; however it was only used for intermediate positions. This zero sign does not appear in terminal positions, thus the Babylonians came close but did not develop a true place value system.\n\nOther topics covered by Babylonian mathematics include fractions, algebra, quadratic and cubic equations, and the calculation of regular reciprocal pairs. The tablets also include multiplication tables and methods for solving linear, quadratic equations and cubic equations, a remarkable achievement for the time. Tablets from the Old Babylonian period also contain the earliest known statement of the Pythagorean theorem. However, as with Egyptian mathematics, Babylonian mathematics shows no awareness of the difference between exact and approximate solutions, or the solvability of a problem, and most importantly, no explicit statement of the need for proofs or logical principles.\n\nEgyptian mathematics refers to mathematics written in the Egyptian language. From the Hellenistic period, Greek replaced Egyptian as the written language of Egyptian scholars. Mathematical study in Egypt later continued under the Arab Empire as part of Islamic mathematics, when Arabic became the written language of Egyptian scholars.\n\nThe most extensive Egyptian mathematical text is the Rhind papyrus (sometimes also called the Ahmes Papyrus after its author), dated to c. 1650 BC but likely a copy of an older document from the Middle Kingdom of about 2000–1800 BC. It is an instruction manual for students in arithmetic and geometry. In addition to giving area formulas and methods for multiplication, division and working with unit fractions, it also contains evidence of other mathematical knowledge, including composite and prime numbers; arithmetic, geometric and harmonic means; and simplistic understandings of both the Sieve of Eratosthenes and perfect number theory (namely, that of the number 6). It also shows how to solve first order linear equations as well as arithmetic and geometric series.\n\nAnother significant Egyptian mathematical text is the Moscow papyrus, also from the Middle Kingdom period, dated to c. 1890 BC. It consists of what are today called \"word problems\" or \"story problems\", which were apparently intended as entertainment. One problem is considered to be of particular importance because it gives a method for finding the volume of a frustum (truncated pyramid).\n\nFinally, the Berlin Papyrus 6619 (c. 1800 BC) shows that ancient Egyptians could solve a second-order algebraic equation.\n\nGreek mathematics refers to the mathematics written in the Greek language from the time of Thales of Miletus (~600 BC) to the closure of the Academy of Athens in 529 AD. Greek mathematicians lived in cities spread over the entire Eastern Mediterranean, from Italy to North Africa, but were united by culture and language. Greek mathematics of the period following Alexander the Great is sometimes called Hellenistic mathematics.\n\nGreek mathematics was much more sophisticated than the mathematics that had been developed by earlier cultures. All surviving records of pre-Greek mathematics show the use of inductive reasoning, that is, repeated observations used to establish rules of thumb. Greek mathematicians, by contrast, used deductive reasoning. The Greeks used logic to derive conclusions from definitions and axioms, and used mathematical rigor to prove them.\n\nGreek mathematics is thought to have begun with Thales of Miletus (c. 624–c.546 BC) and Pythagoras of Samos (c. 582–c. 507 BC). Although the extent of the influence is disputed, they were probably inspired by Egyptian and Babylonian mathematics. According to legend, Pythagoras traveled to Egypt to learn mathematics, geometry, and astronomy from Egyptian priests.\n\nThales used geometry to solve problems such as calculating the height of pyramids and the distance of ships from the shore. He is credited with the first use of deductive reasoning applied to geometry, by deriving four corollaries to Thales' Theorem. As a result, he has been hailed as the first true mathematician and the first known individual to whom a mathematical discovery has been attributed. Pythagoras established the Pythagorean School, whose doctrine it was that mathematics ruled the universe and whose motto was \"All is number\". It was the Pythagoreans who coined the term \"mathematics\", and with whom the study of mathematics for its own sake begins. The Pythagoreans are credited with the first proof of the Pythagorean theorem, though the statement of the theorem has a long history, and with the proof of the existence of irrational numbers. Although he was preceded by the Babylonians and the Chinese, the Neopythagorean mathematician Nicomachus (60–120 AD) provided one of the earliest Greco-Roman multiplication tables, whereas the oldest extant Greek multiplication table is found on a wax tablet dated to the 1st century AD (now found in the British Museum). The association of the Neopythagoreans with the Western invention of the multiplication table is evident in its later Medieval name: the \"mensa Pythagorica\".\n\nPlato (428/427 BC – 348/347 BC) is important in the history of mathematics for inspiring and guiding others. His Platonic Academy, in Athens, became the mathematical center of the world in the 4th century BC, and it was from this school that the leading mathematicians of the day, such as Eudoxus of Cnidus, came. Plato also discussed the foundations of mathematics, clarified some of the definitions (e.g. that of a line as \"breadthless length\"), and reorganized the assumptions. The analytic method is ascribed to Plato, while a formula for obtaining Pythagorean triples bears his name.\n\nEudoxus (408–c. 355 BC) developed the method of exhaustion, a precursor of modern integration and a theory of ratios that avoided the problem of incommensurable magnitudes. The former allowed the calculations of areas and volumes of curvilinear figures, while the latter enabled subsequent geometers to make significant advances in geometry. Though he made no specific technical mathematical discoveries, Aristotle (384–c. 322 BC) contributed significantly to the development of mathematics by laying the foundations of logic.\nIn the 3rd century BC, the premier center of mathematical education and research was the Musaeum of Alexandria. It was there that Euclid (c. 300 BC) taught, and wrote the \"Elements\", widely considered the most successful and influential textbook of all time. The \"Elements\" introduced mathematical rigor through the axiomatic method and is the earliest example of the format still used in mathematics today, that of definition, axiom, theorem, and proof. Although most of the contents of the \"Elements\" were already known, Euclid arranged them into a single, coherent logical framework. The \"Elements\" was known to all educated people in the West up through the middle of the 20th century and its contents are still taught in geometry classes today. In addition to the familiar theorems of Euclidean geometry, the \"Elements\" was meant as an introductory textbook to all mathematical subjects of the time, such as number theory, algebra and solid geometry, including proofs that the square root of two is irrational and that there are infinitely many prime numbers. Euclid also wrote extensively on other subjects, such as conic sections, optics, spherical geometry, and mechanics, but only half of his writings survive.\nArchimedes (c. 287–212 BC) of Syracuse, widely considered the greatest mathematician of antiquity, used the method of exhaustion to calculate the area under the arc of a parabola with the summation of an infinite series, in a manner not too dissimilar from modern calculus. He also showed one could use the method of exhaustion to calculate the value of π with as much precision as desired, and obtained the most accurate value of π then known, . He also studied the spiral bearing his name, obtained formulas for the volumes of surfaces of revolution (paraboloid, ellipsoid, hyperboloid), and an ingenious method of exponentiation for expressing very large numbers. While he is also known for his contributions to physics and several advanced mechanical devices, Archimedes himself placed far greater value on the products of his thought and general mathematical principles. He regarded as his greatest achievement his finding of the surface area and volume of a sphere, which he obtained by proving these are 2/3 the surface area and volume of a cylinder circumscribing the sphere.\nApollonius of Perga (c. 262–190 BC) made significant advances to the study of conic sections, showing that one can obtain all three varieties of conic section by varying the angle of the plane that cuts a double-napped cone. He also coined the terminology in use today for conic sections, namely parabola (\"place beside\" or \"comparison\"), \"ellipse\" (\"deficiency\"), and \"hyperbola\" (\"a throw beyond\"). His work \"Conics\" is one of the best known and preserved mathematical works from antiquity, and in it he derives many theorems concerning conic sections that would prove invaluable to later mathematicians and astronomers studying planetary motion, such as Isaac Newton. While neither Apollonius nor any other Greek mathematicians made the leap to coordinate geometry, Apollonius' treatment of curves is in some ways similar to the modern treatment, and some of his work seems to anticipate the development of analytical geometry by Descartes some 1800 years later.\n\nAround the same time, Eratosthenes of Cyrene (c. 276–194 BC) devised the Sieve of Eratosthenes for finding prime numbers. The 3rd century BC is generally regarded as the \"Golden Age\" of Greek mathematics, with advances in pure mathematics henceforth in relative decline. Nevertheless, in the centuries that followed significant advances were made in applied mathematics, most notably trigonometry, largely to address the needs of astronomers. Hipparchus of Nicaea (c. 190–120 BC) is considered the founder of trigonometry for compiling the first known trigonometric table, and to him is also due the systematic use of the 360 degree circle. Heron of Alexandria (c. 10–70 AD) is credited with Heron's formula for finding the area of a scalene triangle and with being the first to recognize the possibility of negative numbers possessing square roots. Menelaus of Alexandria (c. 100 AD) pioneered spherical trigonometry through Menelaus' theorem. The most complete and influential trigonometric work of antiquity is the \"Almagest\" of Ptolemy (c. AD 90–168), a landmark astronomical treatise whose trigonometric tables would be used by astronomers for the next thousand years. Ptolemy is also credited with Ptolemy's theorem for deriving trigonometric quantities, and the most accurate value of π outside of China until the medieval period, 3.1416.\nFollowing a period of stagnation after Ptolemy, the period between 250 and 350 AD is sometimes referred to as the \"Silver Age\" of Greek mathematics. During this period, Diophantus made significant advances in algebra, particularly indeterminate analysis, which is also known as \"Diophantine analysis\". The study of Diophantine equations and Diophantine approximations is a significant area of research to this day. His main work was the \"Arithmetica\", a collection of 150 algebraic problems dealing with exact solutions to determinate and indeterminate equations. The \"Arithmetica\" had a significant influence on later mathematicians, such as Pierre de Fermat, who arrived at his famous Last Theorem after trying to generalize a problem he had read in the \"Arithmetica\" (that of dividing a square into two squares). Diophantus also made significant advances in notation, the \"Arithmetica\" being the first instance of algebraic symbolism and syncopation.\nAmong the last great Greek mathematicians is Pappus of Alexandria (4th century AD). He is known for his hexagon theorem and centroid theorem, as well as the Pappus configuration and Pappus graph. His \"Collection\" is a major source of knowledge on Greek mathematics as most of it has survived. Pappus is considered the last major innovator in Greek mathematics, with subsequent work consisting mostly of commentaries on earlier work.\n\nThe first woman mathematician recorded by history was Hypatia of Alexandria (AD 350–415). She succeeded her father (Theon of Alexandria) as Librarian at the Great Library and wrote many works on applied mathematics. Because of a political dispute, the Christian community in Alexandria had her stripped publicly and executed. Her death is sometimes taken as the end of the era of the Alexandrian Greek mathematics, although work did continue in Athens for another century with figures such as Proclus, Simplicius and Eutocius. Although Proclus and Simplicius were more philosophers than mathematicians, their commentaries on earlier works are valuable sources on Greek mathematics. The closure of the neo-Platonic Academy of Athens by the emperor Justinian in 529 AD is traditionally held as marking the end of the era of Greek mathematics, although the Greek tradition continued unbroken in the Byzantine empire with mathematicians such as Anthemius of Tralles and Isidore of Miletus, the architects of the Hagia Sophia. Nevertheless, Byzantine mathematics consisted mostly of commentaries, with little in the way of innovation, and the centers of mathematical innovation were to be found elsewhere by this time.\n\nAlthough ethnic Greek mathematicians continued under the rule of the late Roman Republic and subsequent Roman Empire, there were no noteworthy native Latin mathematicians in comparison. Ancient Romans such as Cicero (106–43 BC), an influential Roman statesman who studied mathematics in Greece, believed that Roman surveyors and calculators were far more interested in applied mathematics than the theoretical mathematics and geometry that were prized by the Greeks. It is unclear if the Romans first derived their numerical system directly from the Greek precedent or from Etruscan numerals used by the Etruscan civilization centered in what is now Tuscany, central Italy.\n\nUsing calculation, Romans were adept at both instigating and detecting financial fraud, as well as managing taxes for the treasury. Siculus Flaccus, one of the Roman \"gromatici\" (i.e. land surveyor), wrote the \"Categories of Fields\", which aided Roman surveyors in measuring the surface areas of allotted lands and territories. Aside from managing trade and taxes, the Romans also regularly applied mathematics to solve problems in engineering, including the erection of architecture such as bridges, road-building, and preparation for military campaigns. Arts and crafts such as Roman mosaics, inspired by previous Greek designs, created illusionist geometric patterns and rich, detailed scenes that required precise measurements for each tessera tile, the opus tessellatum pieces on average measuring eight millimeters square and the finer opus vermiculatum pieces having an average surface of four millimeters square.\n\nThe creation of the Roman calendar also necessitated basic mathematics. The first calendar allegedly dates back to 8th century BC during the Roman Kingdom and included 356 days plus a leap year every other year. In contrast, the lunar calendar of the Republican era contained 355 days, roughly ten-and-one-fourth days shorter than the solar year, a discrepancy that was solved by adding an extra month into the calendar after the 23rd of February. This calendar was supplanted by the Julian calendar, a solar calendar organized by Julius Caesar (100–44 BC) and devised by Sosigenes of Alexandria to include a leap day every four years in a 365-day cycle. This calendar, which contained an error of 11 minutes and 14 seconds, was later corrected by the Gregorian calendar organized by Pope Gregory XIII (), virtually the same solar calendar used in modern times as the international standard calendar.\n\nAt roughly the same time, the Han Chinese and the Romans both invented the wheeled odometer device for measuring distances traveled, the Roman model first described by the Roman civil engineer and architect Vitruvius (c. 80 BC - c. 15 BC). The device was used at least until the reign of emperor Commodus (), but its design seems to have been lost until experiments were made during the 15th century in Western Europe. Perhaps relying on similar gear-work and technology found in the Antikythera mechanism, the odometer of Vitruvius featured chariot wheels measuring 4 feet (1.2 m) in diameter turning four-hundred times in one Roman mile (roughly 4590 ft/1400 m). With each revolution, a pin-and-axle device engaged a 400-tooth cogwheel that turned a second gear responsible for dropping pebbles into a box, each pebble representing one mile traversed.\n\nAn analysis of early Chinese mathematics has demonstrated its unique development compared to other parts of the world, leading scholars to assume an entirely independent development. The oldest extant mathematical text from China is the \"Zhoubi Suanjing\", variously dated to between 1200 BC and 100 BC, though a date of about 300 BC during the Warring States Period appears reasonable. However, the Tsinghua Bamboo Slips, containing the earliest known decimal multiplication table (although ancient Babylonians had ones with a base of 60), is dated around 305 BC and is perhaps the oldest surviving mathematical text of China.\nOf particular note is the use in Chinese mathematics of a decimal positional notation system, the so-called \"rod numerals\" in which distinct ciphers were used for numbers between 1 and 10, and additional ciphers for powers of ten. Thus, the number 123 would be written using the symbol for \"1\", followed by the symbol for \"100\", then the symbol for \"2\" followed by the symbol for \"10\", followed by the symbol for \"3\". This was the most advanced number system in the world at the time, apparently in use several centuries before the common era and well before the development of the Indian numeral system. Rod numerals allowed the representation of numbers as large as desired and allowed calculations to be carried out on the \"suan pan\", or Chinese abacus. The date of the invention of the \"suan pan\" is not certain, but the earliest written mention dates from AD 190, in Xu Yue's \"Supplementary Notes on the Art of Figures\".\n\nThe oldest existent work on geometry in China comes from the philosophical Mohist canon c. 330 BC, compiled by the followers of Mozi (470–390 BC). The \"Mo Jing\" described various aspects of many fields associated with physical science, and provided a small number of geometrical theorems as well. It also defined the concepts of circumference, diameter, radius, and volume.\nIn 212 BC, the Emperor Qin Shi Huang commanded all books in the Qin Empire other than officially sanctioned ones be burned. This decree was not universally obeyed, but as a consequence of this order little is known about ancient Chinese mathematics before this date. After the book burning of 212 BC, the Han dynasty (202 BC–220 AD) produced works of mathematics which presumably expanded on works that are now lost. The most important of these is \"The Nine Chapters on the Mathematical Art\", the full title of which appeared by AD 179, but existed in part under other titles beforehand. It consists of 246 word problems involving agriculture, business, employment of geometry to figure height spans and dimension ratios for Chinese pagoda towers, engineering, surveying, and includes material on right triangles. It created mathematical proof for the Pythagorean theorem, and a mathematical formula for Gaussian elimination. The treatise also provides values of π, which Chinese mathematicians originally approximated as 3 until Liu Xin (d. 23 AD) provided a figure of 3.1457 and subsequently Zhang Heng (78–139) approximated pi as 3.1724, as well as 3.162 by taking the square root of 10. Liu Hui commented on the \"Nine Chapters\" in the 3rd century AD and gave a value of π accurate to 5 decimal places (i.e. 3.14159). Though more of a matter of computational stamina than theoretical insight, in the 5th century AD Zu Chongzhi computed the value of π to seven decimal places (i.e. 3.141592), which remained the most accurate value of π for almost the next 1000 years. He also established a method which would later be called Cavalieri's principle to find the volume of a sphere.\n\nThe high-water mark of Chinese mathematics occurred in the 13th century during the latter half of the Song dynasty (960–1279), with the development of Chinese algebra. The most important text from that period is the \"Precious Mirror of the Four Elements\" by Zhu Shijie (1249–1314), dealing with the solution of simultaneous higher order algebraic equations using a method similar to Horner's method. The \"Precious Mirror\" also contains a diagram of Pascal's triangle with coefficients of binomial expansions through the eighth power, though both appear in Chinese works as early as 1100. The Chinese also made use of the complex combinatorial diagram known as the magic square and magic circles, described in ancient times and perfected by Yang Hui (AD 1238–1298).\n\nEven after European mathematics began to flourish during the Renaissance, European and Chinese mathematics were separate traditions, with significant Chinese mathematical output in decline from the 13th century onwards. Jesuit missionaries such as Matteo Ricci carried mathematical ideas back and forth between the two cultures from the 16th to 18th centuries, though at this point far more mathematical ideas were entering China than leaving.\n\nJapanese mathematics, Korean mathematics, and Vietnamese mathematics are traditionally viewed as stemming from Chinese mathematics and belonging to the Confucian-based East Asian cultural sphere. Korean and Japanese mathematics were heavily influenced by the algebraic works produced during China's Song dynasty, whereas Vietnamese mathematics was heavily indebted to popular works of China's Ming dynasty (1368–1644). For instance, although Vietnamese mathematical treatises were written in either Chinese or the native Vietnamese Chữ Nôm script, all of them followed the Chinese format of presenting a collection of problems with algorithms for solving them, followed by numerical answers. Mathematics in Vietnam and Korea were mostly associated with the professional court bureaucracy of mathematicians and astronomers, whereas in Japan it was more prevalent in the realm of private schools.\n\nThe earliest civilization on the Indian subcontinent is the Indus Valley Civilization (mature phase: 2600 to 1900 BC) that flourished in the Indus river basin. Their cities were laid out with geometric regularity, but no known mathematical documents survive from this civilization.\n\nThe oldest extant mathematical records from India are the Sulba Sutras (dated variously between the 8th century BC and the 2nd century AD), appendices to religious texts which give simple rules for constructing altars of various shapes, such as squares, rectangles, parallelograms, and others. As with Egypt, the preoccupation with temple functions points to an origin of mathematics in religious ritual. The Sulba Sutras give methods for constructing a circle with approximately the same area as a given square, which imply several different approximations of the value of π. In addition, they compute the square root of 2 to several decimal places, list Pythagorean triples, and give a statement of the Pythagorean theorem. All of these results are present in Babylonian mathematics, indicating Mesopotamian influence. It is not known to what extent the Sulba Sutras influenced later Indian mathematicians. As in China, there is a lack of continuity in Indian mathematics; significant advances are separated by long periods of inactivity.\n\nPāṇini (c. 5th century BC) formulated the rules for Sanskrit grammar. His notation was similar to modern mathematical notation, and used metarules, transformations, and recursion. Pingala (roughly 3rd–1st centuries BC) in his treatise of prosody uses a device corresponding to a binary numeral system. His discussion of the combinatorics of meters corresponds to an elementary version of the binomial theorem. Pingala's work also contains the basic ideas of Fibonacci numbers (called \"mātrāmeru\").\n\nThe next significant mathematical documents from India after the \"Sulba Sutras\" are the \"Siddhantas\", astronomical treatises from the 4th and 5th centuries AD (Gupta period) showing strong Hellenistic influence. They are significant in that they contain the first instance of trigonometric relations based on the half-chord, as is the case in modern trigonometry, rather than the full chord, as was the case in Ptolemaic trigonometry. Through a series of translation errors, the words \"sine\" and \"cosine\" derive from the Sanskrit \"jiya\" and \"kojiya\".\nAround 500 AD, Aryabhata wrote the \"Aryabhatiya\", a slim volume, written in verse, intended to supplement the rules of calculation used in astronomy and mathematical mensuration, though with no feeling for logic or deductive methodology. Though about half of the entries are wrong, it is in the \"Aryabhatiya\" that the decimal place-value system first appears. Several centuries later, the Muslim mathematician Abu Rayhan Biruni described the \"Aryabhatiya\" as a \"mix of common pebbles and costly crystals\".\n\nIn the 7th century, Brahmagupta identified the Brahmagupta theorem, Brahmagupta's identity and Brahmagupta's formula, and for the first time, in \"Brahma-sphuta-siddhanta\", he lucidly explained the use of zero as both a placeholder and decimal digit, and explained the Hindu–Arabic numeral system. It was from a translation of this Indian text on mathematics (c. 770) that Islamic mathematicians were introduced to this numeral system, which they adapted as Arabic numerals. Islamic scholars carried knowledge of this number system to Europe by the 12th century, and it has now displaced all older number systems throughout the world. Various symbol sets are used to represent numbers in the Hindu–Arabic numeral system, all of which evolved from the Brahmi numerals. Each of the roughly dozen major scripts of India has its own numeral glyphs. In the 10th century, Halayudha's commentary on Pingala's work contains a study of the Fibonacci sequence and Pascal's triangle, and describes the formation of a matrix.\n\nIn the 12th century, Bhāskara II lived in southern India and wrote extensively on all then known branches of mathematics. His work contains mathematical objects equivalent or approximately equivalent to infinitesimals, derivatives, the mean value theorem and the derivative of the sine function. To what extent he anticipated the invention of calculus is a controversial subject among historians of mathematics.\n\nIn the 14th century, Madhava of Sangamagrama, the founder of the so-called Kerala School of Mathematics, found the Madhava–Leibniz series, and, using 21 terms, computed the value of π as 3.14159265359. Madhava also found the Madhava-Gregory series to determine the arctangent, the Madhava-Newton power series to determine sine and cosine and the Taylor approximation for sine and cosine functions. In the 16th century, Jyesthadeva consolidated many of the Kerala School's developments and theorems in the \"Yukti-bhāṣā\". However, the Kerala School did not formulate a systematic theory of differentiation and integration, nor is there any direct evidence of their results being transmitted outside Kerala.\n\nThe Islamic Empire established across Persia, the Middle East, Central Asia, North Africa, Iberia, and in parts of India in the 8th century made significant contributions towards mathematics. Although most Islamic texts on mathematics were written in Arabic, most of them were not written by Arabs, since much like the status of Greek in the Hellenistic world, Arabic was used as the written language of non-Arab scholars throughout the Islamic world at the time. Persians contributed to the world of Mathematics alongside Arabs.\n\nIn the 9th century, the Persian mathematician Muḥammad ibn Mūsā al-Khwārizmī wrote several important books on the Hindu–Arabic numerals and on methods for solving equations. His book \"On the Calculation with Hindu Numerals\", written about 825, along with the work of Al-Kindi, were instrumental in spreading Indian mathematics and Indian numerals to the West. The word \"algorithm\" is derived from the Latinization of his name, Algoritmi, and the word \"algebra\" from the title of one of his works, \"Al-Kitāb al-mukhtaṣar fī hīsāb al-ğabr wa’l-muqābala\" (\"The Compendious Book on Calculation by Completion and Balancing\"). He gave an exhaustive explanation for the algebraic solution of quadratic equations with positive roots, and he was the first to teach algebra in an elementary form and for its own sake. He also discussed the fundamental method of \"reduction\" and \"balancing\", referring to the transposition of subtracted terms to the other side of an equation, that is, the cancellation of like terms on opposite sides of the equation. This is the operation which al-Khwārizmī originally described as \"al-jabr\". His algebra was also no longer concerned \"with a series of problems to be resolved, but an exposition which starts with primitive terms in which the combinations must give all possible prototypes for equations, which henceforward explicitly constitute the true object of study.\" He also studied an equation for its own sake and \"in a generic manner, insofar as it does not simply emerge in the course of solving a problem, but is specifically called on to define an infinite class of problems.\"\n\nIn Egypt, Abu Kamil extended algebra to the set of irrational numbers, accepting square roots and fourth roots as solutions and coefficients to quadratic equations. He also developed techniques used to solve three non-linear simultaneous equations with three unknown variables. One unique feature of his works was trying to find all the possible solutions to some of his problems, including one where he found 2676 solutions. His works formed an important foundation for the development of algebra and influenced later mathematicians, such as al-Karaji and Fibonacci.\n\nFurther developments in algebra were made by Al-Karaji in his treatise \"al-Fakhri\", where he extends the methodology to incorporate integer powers and integer roots of unknown quantities. Something close to a proof by mathematical induction appears in a book written by Al-Karaji around 1000 AD, who used it to prove the binomial theorem, Pascal's triangle, and the sum of integral cubes. The historian of mathematics, F. Woepcke, praised Al-Karaji for being \"the first who introduced the theory of algebraic calculus.\" Also in the 10th century, Abul Wafa translated the works of Diophantus into Arabic. Ibn al-Haytham was the first mathematician to derive the formula for the sum of the fourth powers, using a method that is readily generalizable for determining the general formula for the sum of any integral powers. He performed an integration in order to find the volume of a paraboloid, and was able to generalize his result for the integrals of polynomials up to the fourth degree. He thus came close to finding a general formula for the integrals of polynomials, but he was not concerned with any polynomials higher than the fourth degree.\n\nIn the late 11th century, Omar Khayyam wrote \"Discussions of the Difficulties in Euclid\", a book about what he perceived as flaws in Euclid's \"Elements\", especially the parallel postulate. He was also the first to find the general geometric solution to cubic equations. He was also very influential in calendar reform.\n\nIn the 13th century, Nasir al-Din Tusi (Nasireddin) made advances in spherical trigonometry. He also wrote influential work on Euclid's parallel postulate. In the 15th century, Ghiyath al-Kashi computed the value of π to the 16th decimal place. Kashi also had an algorithm for calculating \"n\"th roots, which was a special case of the methods given many centuries later by Ruffini and Horner.\n\nOther achievements of Muslim mathematicians during this period include the addition of the decimal point notation to the Arabic numerals, the discovery of all the modern trigonometric functions besides the sine, al-Kindi's introduction of cryptanalysis and frequency analysis, the development of analytic geometry by Ibn al-Haytham, the beginning of algebraic geometry by Omar Khayyam and the development of an algebraic notation by al-Qalasādī.\n\nDuring the time of the Ottoman Empire and Safavid Empire from the 15th century, the development of Islamic mathematics became stagnant.\n\nIn the Pre-Columbian Americas, the Maya civilization that flourished in Mexico and Central America during the 1st millennium AD developed a unique tradition of mathematics that, due to its geographic isolation, was entirely independent of existing European, Egyptian, and Asian mathematics. Maya numerals utilized a base of 20, the vigesimal system, instead of a base of ten that forms the basis of the decimal system used by most modern cultures. The Mayas used mathematics to create the Maya calendar as well as to predict astronomical phenomena in their native Maya astronomy. While the concept of zero had to be inferred in the mathematics of many contemporary cultures, the Mayas developed a standard symbol for it.\n\nMedieval European interest in mathematics was driven by concerns quite different from those of modern mathematicians. One driving element was the belief that mathematics provided the key to understanding the created order of nature, frequently justified by Plato's \"Timaeus\" and the biblical passage (in the \"Book of Wisdom\") that God had \"ordered all things in measure, and number, and weight\".\n\nBoethius provided a place for mathematics in the curriculum in the 6th century when he coined the term \"quadrivium\" to describe the study of arithmetic, geometry, astronomy, and music. He wrote \"De institutione arithmetica\", a free translation from the Greek of Nicomachus's \"Introduction to Arithmetic\"; \"De institutione musica\", also derived from Greek sources; and a series of excerpts from Euclid's \"Elements\". His works were theoretical, rather than practical, and were the basis of mathematical study until the recovery of Greek and Arabic mathematical works.\n\nIn the 12th century, European scholars traveled to Spain and Sicily seeking scientific Arabic texts, including al-Khwārizmī's \"The Compendious Book on Calculation by Completion and Balancing\", translated into Latin by Robert of Chester, and the complete text of Euclid's \"Elements\", translated in various versions by Adelard of Bath, Herman of Carinthia, and Gerard of Cremona. These and other new sources sparked a renewal of mathematics.\n\nLeonardo of Pisa, now known as Fibonacci, serendipitously learned about the Hindu–Arabic numerals on a trip to what is now Béjaïa, Algeria with his merchant father. (Europe was still using Roman numerals.) There, he observed a system of arithmetic (specifically algorism) which due to the positional notation of Hindu–Arabic numerals was much more efficient and greatly facilitated commerce. Leonardo wrote \"Liber Abaci\" in 1202 (updated in 1254) introducing the technique to Europe and beginning a long period of popularizing it. The book also brought to Europe what is now known as the Fibonacci sequence (known to Indian mathematicians for hundreds of years before that) which was used as an unremarkable example within the text.\n\nThe 14th century saw the development of new mathematical concepts to investigate a wide range of problems. One important contribution was development of mathematics of local motion.\n\nThomas Bradwardine proposed that speed (V) increases in arithmetic proportion as the ratio of force (F) to resistance (R) increases in geometric proportion. Bradwardine expressed this by a series of specific examples, but although the logarithm had not yet been conceived, we can express his conclusion anachronistically by writing:\nV = log (F/R). Bradwardine's analysis is an example of transferring a mathematical technique used by al-Kindi and Arnald of Villanova to quantify the nature of compound medicines to a different physical problem.\nOne of the 14th-century Oxford Calculators, William Heytesbury, lacking differential calculus and the concept of limits, proposed to measure instantaneous speed \"by the path that would be described by [a body] if... it were moved uniformly at the same degree of speed with which it is moved in that given instant\".\n\nHeytesbury and others mathematically determined the distance covered by a body undergoing uniformly accelerated motion (today solved by integration), stating that \"a moving body uniformly acquiring or losing that increment [of speed] will traverse in some given time a [distance] completely equal to that which it would traverse if it were moving continuously through the same time with the mean degree [of speed]\".\n\nNicole Oresme at the University of Paris and the Italian Giovanni di Casali independently provided graphical demonstrations of this relationship, asserting that the area under the line depicting the constant acceleration, represented the total distance traveled. In a later mathematical commentary on Euclid's \"Elements\", Oresme made a more detailed general analysis in which he demonstrated that a body will acquire in each successive increment of time an increment of any quality that increases as the odd numbers. Since Euclid had demonstrated the sum of the odd numbers are the square numbers, the total quality acquired by the body increases as the square of the time.\n\nDuring the Renaissance, the development of mathematics and of accounting were intertwined. While there is no direct relationship between algebra and accounting, the teaching of the subjects and the books published often intended for the children of merchants who were sent to reckoning schools (in Flanders and Germany) or abacus schools (known as \"abbaco\" in Italy), where they learned the skills useful for trade and commerce. There is probably no need for algebra in performing bookkeeping operations, but for complex bartering operations or the calculation of compound interest, a basic knowledge of arithmetic was mandatory and knowledge of algebra was very useful.\n\nPiero della Francesca (c. 1415–1492) wrote books on solid geometry and linear perspective, including \"De Prospectiva Pingendi (On Perspective for Painting)\", \"Trattato d’Abaco (Abacus Treatise)\", and \"De corporibus regularibus (Regular Solids)\".\nLuca Pacioli's \"Summa de Arithmetica, Geometria, Proportioni et Proportionalità\" (Italian: \"Review of Arithmetic, Geometry, Ratio and Proportion\") was first printed and published in Venice in 1494. It included a 27-page treatise on bookkeeping, \"\"Particularis de Computis et Scripturis\"\" (Italian: \"Details of Calculation and Recording\"). It was written primarily for, and sold mainly to, merchants who used the book as a reference text, as a source of pleasure from the mathematical puzzles it contained, and to aid the education of their sons. In \"Summa Arithmetica\", Pacioli introduced symbols for plus and minus for the first time in a printed book, symbols that became standard notation in Italian Renaissance mathematics. \"Summa Arithmetica\" was also the first known book printed in Italy to contain algebra. Pacioli obtained many of his ideas from Piero Della Francesca whom he plagiarized.\n\nIn Italy, during the first half of the 16th century, Scipione del Ferro and Niccolò Fontana Tartaglia discovered solutions for cubic equations. Gerolamo Cardano published them in his 1545 book \"Ars Magna\", together with a solution for the quartic equations, discovered by his student Lodovico Ferrari. In 1572 Rafael Bombelli published his \"L'Algebra\" in which he showed how to deal with the imaginary quantities that could appear in Cardano's formula for solving cubic equations.\n\nSimon Stevin's book \"De Thiende\" ('the art of tenths'), first published in Dutch in 1585, contained the first systematic treatment of decimal notation, which influenced all later work on the real number system.\n\nDriven by the demands of navigation and the growing need for accurate maps of large areas, trigonometry grew to be a major branch of mathematics. Bartholomaeus Pitiscus was the first to use the word, publishing his \"Trigonometria\" in 1595. Regiomontanus's table of sines and cosines was published in 1533.\n\nDuring the Renaissance the desire of artists to represent the natural world realistically, together with the rediscovered philosophy of the Greeks, led artists to study mathematics. They were also the engineers and architects of that time, and so had need of mathematics in any case. The art of painting in perspective, and the developments in geometry that involved, were studied intensely.\n\nThe 17th century saw an unprecedented increase of mathematical and scientific ideas across Europe. Galileo observed the moons of Jupiter in orbit about that planet, using a telescope based on a toy imported from Holland. Tycho Brahe had gathered an enormous quantity of mathematical data describing the positions of the planets in the sky. By his position as Brahe's assistant, Johannes Kepler was first exposed to and seriously interacted with the topic of planetary motion. Kepler's calculations were made simpler by the contemporaneous invention of logarithms by John Napier and Jost Bürgi. Kepler succeeded in formulating mathematical laws of planetary motion.\nThe analytic geometry developed by René Descartes (1596–1650) allowed those orbits to be plotted on a graph, in Cartesian coordinates.\n\nBuilding on earlier work by many predecessors, Isaac Newton discovered the laws of physics explaining Kepler's Laws, and brought together the concepts now known as calculus. Independently, Gottfried Wilhelm Leibniz, who is arguably one of the most important mathematicians of the 17th century, developed calculus and much of the calculus notation still in use today. Science and mathematics had become an international endeavor, which would soon spread over the entire world.\n\nIn addition to the application of mathematics to the studies of the heavens, applied mathematics began to expand into new areas, with the correspondence of Pierre de Fermat and Blaise Pascal. Pascal and Fermat set the groundwork for the investigations of probability theory and the corresponding rules of combinatorics in their discussions over a game of gambling. Pascal, with his wager, attempted to use the newly developing probability theory to argue for a life devoted to religion, on the grounds that even if the probability of success was small, the rewards were infinite. In some sense, this foreshadowed the development of utility theory in the 18th–19th century.\n\nThe most influential mathematician of the 18th century was arguably Leonhard Euler. His contributions range from founding the study of graph theory with the Seven Bridges of Königsberg problem to standardizing many modern mathematical terms and notations. For example, he named the square root of minus 1 with the symbol \"i\", and he popularized the use of the Greek letter formula_1 to stand for the ratio of a circle's circumference to its diameter. He made numerous contributions to the study of topology, graph theory, calculus, combinatorics, and complex analysis, as evidenced by the multitude of theorems and notations named for him.\n\nOther important European mathematicians of the 18th century included Joseph Louis Lagrange, who did pioneering work in number theory, algebra, differential calculus, and the calculus of variations, and Laplace who, in the age of Napoleon, did important work on the foundations of celestial mechanics and on statistics.\n\nThroughout the 19th century mathematics became increasingly abstract. Carl Friedrich Gauss (1777–1855) epitomizes this trend. He did revolutionary work on functions of complex variables, in geometry, and on the convergence of series, leaving aside his many contributions to science. He also gave the first satisfactory proofs of the fundamental theorem of algebra and of the quadratic reciprocity law.\nThis century saw the development of the two forms of non-Euclidean geometry, where the parallel postulate of Euclidean geometry no longer holds.\nThe Russian mathematician Nikolai Ivanovich Lobachevsky and his rival, the Hungarian mathematician János Bolyai, independently defined and studied hyperbolic geometry, where uniqueness of parallels no longer holds. In this geometry the sum of angles in a triangle add up to less than 180°. Elliptic geometry was developed later in the 19th century by the German mathematician Bernhard Riemann; here no parallel can be found and the angles in a triangle add up to more than 180°. Riemann also developed Riemannian geometry, which unifies and vastly generalizes the three types of geometry, and he defined the concept of a manifold, which generalizes the ideas of curves and surfaces.\n\nThe 19th century saw the beginning of a great deal of abstract algebra. Hermann Grassmann in Germany gave a first version of vector spaces, William Rowan Hamilton in Ireland developed noncommutative algebra. The British mathematician George Boole devised an algebra that soon evolved into what is now called Boolean algebra, in which the only numbers were 0 and 1. Boolean algebra is the starting point of mathematical logic and has important applications in computer science.\n\nAugustin-Louis Cauchy, Bernhard Riemann, and Karl Weierstrass reformulated the calculus in a more rigorous fashion.\n\nAlso, for the first time, the limits of mathematics were explored. Niels Henrik Abel, a Norwegian, and Évariste Galois, a Frenchman, proved that there is no general algebraic method for solving polynomial equations of degree greater than four (Abel–Ruffini theorem). Other 19th-century mathematicians utilized this in their proofs that straightedge and compass alone are not sufficient to trisect an arbitrary angle, to construct the side of a cube twice the volume of a given cube, nor to construct a square equal in area to a given circle. Mathematicians had vainly attempted to solve all of these problems since the time of the ancient Greeks. On the other hand, the limitation of three dimensions in geometry was surpassed in the 19th century through considerations of parameter space and hypercomplex numbers.\n\nAbel and Galois's investigations into the solutions of various polynomial equations laid the groundwork for further developments of group theory, and the associated fields of abstract algebra. In the 20th century physicists and other scientists have seen group theory as the ideal way to study symmetry.\n\nIn the later 19th century, Georg Cantor established the first foundations of set theory, which enabled the rigorous treatment of the notion of infinity and has become the common language of nearly all mathematics. Cantor's set theory, and the rise of mathematical logic in the hands of Peano, L.E.J. Brouwer, David Hilbert, Bertrand Russell, and A.N. Whitehead, initiated a long running debate on the foundations of mathematics.\n\nThe 19th century saw the founding of a number of national mathematical societies: the London Mathematical Society in 1865, the Société Mathématique de France in 1872, the Circolo Matematico di Palermo in 1884, the Edinburgh Mathematical Society in 1883, and the American Mathematical Society in 1888. The first international, special-interest society, the Quaternion Society, was formed in 1899, in the context of a vector controversy.\n\nIn 1897, Hensel introduced p-adic numbers.\n\nThe 20th century saw mathematics become a major profession. Every year, thousands of new Ph.D.s in mathematics were awarded, and jobs were available in both teaching and industry. An effort to catalogue the areas and applications of mathematics was undertaken in Klein's encyclopedia.\n\nIn a 1900 speech to the International Congress of Mathematicians, David Hilbert set out a list of 23 unsolved problems in mathematics. These problems, spanning many areas of mathematics, formed a central focus for much of 20th-century mathematics. Today, 10 have been solved, 7 are partially solved, and 2 are still open. The remaining 4 are too loosely formulated to be stated as solved or not.\nNotable historical conjectures were finally proven. In 1976, Wolfgang Haken and Kenneth Appel proved the four color theorem, controversial at the time for the use of a computer to do so. Andrew Wiles, building on the work of others, proved Fermat's Last Theorem in 1995. Paul Cohen and Kurt Gödel proved that the continuum hypothesis is independent of (could neither be proved nor disproved from) the standard axioms of set theory. In 1998 Thomas Callister Hales proved the Kepler conjecture.\n\nMathematical collaborations of unprecedented size and scope took place. An example is the classification of finite simple groups (also called the \"enormous theorem\"), whose proof between 1955 and 1983 required 500-odd journal articles by about 100 authors, and filling tens of thousands of pages. A group of French mathematicians, including Jean Dieudonné and André Weil, publishing under the pseudonym \"Nicolas Bourbaki\", attempted to exposit all of known mathematics as a coherent rigorous whole. The resulting several dozen volumes has had a controversial influence on mathematical education.\nDifferential geometry came into its own when Einstein used it in general relativity. Entirely new areas of mathematics such as mathematical logic, topology, and John von Neumann's game theory changed the kinds of questions that could be answered by mathematical methods. All kinds of structures were abstracted using axioms and given names like metric spaces, topological spaces etc. As mathematicians do, the concept of an abstract structure was itself abstracted and led to category theory. Grothendieck and Serre recast algebraic geometry using sheaf theory. Large advances were made in the qualitative study of dynamical systems that Poincaré had begun in the 1890s.\nMeasure theory was developed in the late 19th and early 20th centuries. Applications of measures include the Lebesgue integral, Kolmogorov's axiomatisation of probability theory, and ergodic theory. Knot theory greatly expanded. Quantum mechanics led to the development of functional analysis. Other new areas include Laurent Schwartz's distribution theory, fixed point theory, singularity theory and René Thom's catastrophe theory, model theory, and Mandelbrot's fractals. Lie theory with its Lie groups and Lie algebras became one of the major areas of study.\n\nNon-standard analysis, introduced by Abraham Robinson, rehabilitated the infinitesimal approach to calculus, which had fallen into disrepute in favour of the theory of limits, by extending the field of real numbers to the Hyperreal numbers which include infinitesimal and infinite quantities. An even larger number system, the surreal numbers were discovered by John Horton Conway in connection with combinatorial games.\n\nThe development and continual improvement of computers, at first mechanical analog machines and then digital electronic machines, allowed industry to deal with larger and larger amounts of data to facilitate mass production and distribution and communication, and new areas of mathematics were developed to deal with this: Alan Turing's computability theory; complexity theory; Derrick Henry Lehmer's use of ENIAC to further number theory and the Lucas-Lehmer test; Rózsa Péter's recursive function theory; Claude Shannon's information theory; signal processing; data analysis; optimization and other areas of operations research. In the preceding centuries much mathematical focus was on calculus and continuous functions, but the rise of computing and communication networks led to an increasing importance of discrete concepts and the expansion of combinatorics including graph theory. The speed and data processing abilities of computers also enabled the handling of mathematical problems that were too time-consuming to deal with by pencil and paper calculations, leading to areas such as numerical analysis and symbolic computation. Some of the most important methods and algorithms of the 20th century are: the simplex algorithm, the Fast Fourier Transform, error-correcting codes, the Kalman filter from control theory and the RSA algorithm of public-key cryptography.\n\nAt the same time, deep insights were made about the limitations to mathematics. In 1929 and 1930, it was proved the truth or falsity of all statements formulated about the natural numbers plus one of addition and multiplication, was decidable, i.e. could be determined by some algorithm. In 1931, Kurt Gödel found that this was not the case for the natural numbers plus both addition and multiplication; this system, known as Peano arithmetic, was in fact incompletable. (Peano arithmetic is adequate for a good deal of number theory, including the notion of prime number.) A consequence of Gödel's two incompleteness theorems is that in any mathematical system that includes Peano arithmetic (including all of analysis and geometry), truth necessarily outruns proof, i.e. there are true statements that cannot be proved within the system. Hence mathematics cannot be reduced to mathematical logic, and David Hilbert's dream of making all of mathematics complete and consistent needed to be reformulated.\nOne of the more colorful figures in 20th-century mathematics was Srinivasa Aiyangar Ramanujan (1887–1920), an Indian autodidact who conjectured or proved over 3000 theorems, including properties of highly composite numbers, the partition function and its asymptotics, and mock theta functions. He also made major investigations in the areas of gamma functions, modular forms, divergent series, hypergeometric series and prime number theory.\n\nPaul Erdős published more papers than any other mathematician in history, working with hundreds of collaborators. Mathematicians have a game equivalent to the Kevin Bacon Game, which leads to the Erdős number of a mathematician. This describes the \"collaborative distance\" between a person and Paul Erdős, as measured by joint authorship of mathematical papers.\n\nEmmy Noether has been described by many as the most important woman in the history of mathematics. She studied the theories of rings, fields, and algebras.\n\nAs in most areas of study, the explosion of knowledge in the scientific age has led to specialization: by the end of the century there were hundreds of specialized areas in mathematics and the Mathematics Subject Classification was dozens of pages long. More and more mathematical journals were published and, by the end of the century, the development of the World Wide Web led to online publishing.\n\nIn 2000, the Clay Mathematics Institute announced the seven Millennium Prize Problems, and in 2003 the Poincaré conjecture was solved by Grigori Perelman (who declined to accept an award, as he was critical of the mathematics establishment).\n\nMost mathematical journals now have online versions as well as print versions, and many online-only journals are launched. There is an increasing drive towards open access publishing, first popularized by the arXiv.\n\nThere are many observable trends in mathematics, the most notable being that the subject is growing ever larger, computers are ever more important and powerful, the application of mathematics to bioinformatics is rapidly expanding, and the volume of data being produced by science and industry, facilitated by computers, is explosively expanding.\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "14223", "url": "https://en.wikipedia.org/wiki?curid=14223", "title": "HSK", "text": "HSK\n\nHSK may refer to:\n\n"}
{"id": "14225", "url": "https://en.wikipedia.org/wiki?curid=14225", "title": "Hydrogen atom", "text": "Hydrogen atom\n\nA hydrogen atom is an atom of the chemical element hydrogen. The electrically neutral atom contains a single positively charged proton and a single negatively charged electron bound to the nucleus by the Coulomb force. Atomic hydrogen constitutes about 75% of the baryonic mass of the universe.\n\nIn everyday life on Earth, isolated hydrogen atoms (called \"atomic hydrogen\") are extremely rare. Instead, hydrogen tends to combine with other atoms in compounds, or with itself to form ordinary (diatomic) hydrogen gas, H. \"Atomic hydrogen\" and \"hydrogen atom\" in ordinary English use have overlapping, yet distinct, meanings. For example, a water molecule contains two hydrogen atoms, but does not contain atomic hydrogen (which would refer to isolated hydrogen atoms).\n\nAtomic spectroscopy shows that there is a discrete infinite set of states in which a hydrogen (or any) atom can exist, contrary to the predictions of classical physics. Attempts to develop a theoretical understanding of the states of the hydrogen atom have been important to the history of quantum mechanics, since all other atoms can be roughly understood by knowing in detail about this simplest atomic structure.\n\nThe most abundant isotope, hydrogen-1, protium, or light hydrogen, contains no neutrons and is simply a proton and an electron. Protium is stable and makes up 99.985% of naturally occurring hydrogen atoms.\n\nDeuterium contains one neutron and one proton. Deuterium is stable and makes up 0.0156% of naturally occurring hydrogen and is used in industrial processes like nuclear reactors and Nuclear Magnetic Resonance.\n\nTritium contains two neutrons and one proton and is not stable, decaying with a half-life of 12.32 years. Because of the short half life, tritium does not exist in nature except in trace amounts.\n\nHigher isotopes of hydrogen are only created in artificial accelerators and reactors and have half lives around the order of 10 seconds.\n\nThe formulas below are valid for all three isotopes of hydrogen, but slightly different values of the Rydberg constant (correction formula given below) must be used for each hydrogen isotope.\n\nHydrogen is not found without its electron in ordinary chemistry (room temperatures and pressures), as ionized hydrogen is highly chemically reactive. When ionized hydrogen is written as \"H\" as in the solvation of classical acids such as hydrochloric acid, the hydronium ion, HO, is meant, not a literal ionized single hydrogen atom. In that case, the acid transfers the proton to HO to form HO.\n\nIonized hydrogen without its electron, or free protons, are common in the interstellar medium, and solar wind.\n\nThe hydrogen atom has special significance in quantum mechanics and quantum field theory as a simple two-body problem physical system which has yielded many simple analytical solutions in closed-form.\n\nExperiments by Ernest Rutherford in 1909 showed the structure of the atom to be a dense, positive nucleus with a tenuous negative charge cloud around it. This immediately caused problems on how such a system could be stable. Classical electromagnetism had shown that any accelerating charge radiates energy described through the Larmor formula. If the electron is assumed to orbit in a perfect circle and radiates energy continuously, the electron would rapidly spiral into the nucleus with a fall time of:\n\nWhere formula_2 is the Bohr radius and formula_3 is the classical electron radius. If this were true, all atoms would instantly collapse, however atoms seem to be stable. Furthermore, the spiral inward would release a smear of electromagnetic frequencies as the orbit got smaller. Instead, atoms were observed to only emit discrete frequencies of radiation. The resolution would lie in the development of quantum mechanics.\n\nIn 1913, Niels Bohr obtained the energy levels and spectral frequencies of the hydrogen atom after making a number of simple assumptions in order to correct the failed classical model. The assumptions included:\nBohr supposed that the electron's angular momentum is quantized with possible values:\n\nformula_4 where formula_5\n\nand formula_6 is Planck constant over formula_7. He also supposed that the centripetal force which keeps the electron in its orbit is provided by the Coulomb force, and that energy is conserved. Bohr derived the energy of each orbit of the hydrogen atom to be:\n\nwhere formula_9 is the electron mass, formula_10 is the electron charge, formula_11 is the vacuum permittivity, and formula_12 is the quantum number (now known as the principal quantum number). Bohr's predictions matched experiments measuring the hydrogen spectral series to the first order, giving more confidence to a theory that used quantized values.\n\nFor formula_13, the value\nis called the Rydberg unit of energy. It is related to the Rydberg constant formula_15 of atomic physics by formula_16\n\nThe exact value of the Rydberg constant assumes that the nucleus is infinitely massive with respect to the electron. For hydrogen-1, hydrogen-2 (deuterium), and hydrogen-3 (tritium) the constant must be slightly modified to use the reduced mass of the system, rather than simply the mass of the electron. However, since the nucleus is much heavier than the electron, the values are nearly the same. The Rydberg constant \"R\" for a hydrogen atom (one electron), \"R\" is given by\n\nformula_17\n\nwhere formula_18 is the mass of the atomic nucleus. For hydrogen-1, the quantity formula_19 is about 1/1836 (i.e. the electron-to-proton mass ratio). For deuterium and tritium, the ratios are about 1/3670 and 1/5497 respectively. These figures, when added to 1 in the denominator, represent very small corrections in the value of \"R\", and thus only small corrections to all energy levels in corresponding hydrogen isotopes.\n\nThere were still problems with Bohr's model: \n\nMost of these shortcomings were resolved by Arnold Sommerfeld's modification of the Bohr model. Sommerfeld introduced two additional degrees of freedom, allowing an electron to move on an elliptical orbit characterized by its eccentricity and declination with respect to a chosen axis. This introduced two additional quantum numbers, which correspond to the orbital angular momentum and its projection on the chosen axis. Thus the correct multiplicity of states (except for the factor 2 accounting for the yet unknown electron spin) was found. Further, by applying special relativity to the elliptic orbits, Sommerfeld succeeded in deriving the correct expression for the fine structure of hydrogen spectra (which happens to be exactly the same as in the most elaborate Dirac theory). However, some observed phenomena, such as the anomalous Zeeman effect, remained unexplained. These issues were resolved with the full development of quantum mechanics and the Dirac equation. It is often alleged that the Schrödinger equation is superior to the Bohr-Sommerfeld theory in describing hydrogen atom. This is not the case, as most of the results of both approaches coincide or are very close (a remarkable exception is the problem of hydrogen atom in crossed electric and magnetic fields, which cannot be self-consistently solved in the framework of the Bohr-Sommerfeld theory), and in both theories the main shortcomings result from the absence of the electron spin. It was the complete failure of the Bohr-Sommerfeld theory to explain many-electron systems (such as helium atom or hydrogen molecule) which demonstrated its inadequacy in describing quantum phenomena.\n\nThe Schrödinger equation allows one to calculate the development of quantum systems with time and can give exact, analytical answers for the non-relativistic hydrogen atom.\n\nThe Hamiltonian of the hydrogen atom is the radial kinetic energy operator and coulomb attraction force between the positive proton and negative electron. Using the time-independent Schrödinger equation, ignoring all spin-coupling interactions and using the reduced mass formula_22, the equation is written as:\n\nformula_23\n\nExpanding the Laplacian in spherical coordinates:\n\nformula_24\n\nThis is a separable, partial differential equation which can be solved in terms of special functions. The normalized position wavefunctions, given in spherical coordinates are:\n\nwhere:\n\nThe quantum numbers can take the following values: \n\nAdditionally, these wavefunctions are \"normalized\" (i.e., the integral of their modulus square equals 1) and orthogonal:\nwhere formula_37 is the state represented by the wavefunction formula_38 in Dirac notation, and formula_39 is the Kronecker delta function.\n\nThe wavefunctions in momentum space are related to the wavefunctions in position space through a Fourier transform\n\nwhich, for the bound states, results in \n\nwhere formula_42 denotes a Gegenbauer polynomial and formula_43 is in units of formula_44.\n\nThe solutions to the Schrödinger equation for hydrogen are analytical, giving a simple expression for the hydrogen energy levels and thus the frequencies of the hydrogen spectral lines and fully reproduced the Bohr model and went beyond it. It also yields two other quantum numbers and the shape of the electron's wave function (\"orbital\") for the various possible quantum-mechanical states, thus explaining the anisotropic character of atomic bonds.\n\nThe Schrödinger equation also applies to more complicated atoms and molecules. When there is more than one electron or nucleus the solution is not analytical and either computer calculations are necessary or simplifying assumptions must be made.\n\nSince the Schrödinger equation is only valid for non-relativistic quantum mechanics, the solutions it yields for the hydrogen atom are not entirely correct. The Dirac equation of relativistic quantum theory improves these solutions (see below).\n\nThe solution of the Schrödinger equation (wave equation) for the hydrogen atom uses the fact that the Coulomb potential produced by the nucleus is isotropic (it is radially symmetric in space and only depends on the distance to the nucleus). Although the resulting energy eigenfunctions (the \"orbitals\") are not necessarily isotropic themselves, their dependence on the angular coordinates follows completely generally from this isotropy of the underlying potential: the eigenstates of the Hamiltonian (that is, the energy eigenstates) can be chosen as simultaneous eigenstates of the angular momentum operator. This corresponds to the fact that angular momentum is conserved in the orbital motion of the electron around the nucleus. Therefore, the energy eigenstates may be classified by two angular momentum quantum numbers, \"ℓ\" and \"m\" (both are integers). The angular momentum quantum number determines the magnitude of the angular momentum. The magnetic quantum number determines the projection of the angular momentum on the (arbitrarily chosen) \"z\"-axis.\n\nIn addition to mathematical expressions for total angular momentum and angular momentum projection of wavefunctions, an expression for the radial dependence of the wave functions must be found. It is only here that the details of the 1/\"r\" Coulomb potential enter (leading to Laguerre polynomials in \"r\"). This leads to a third quantum number, the principal quantum number . The principal quantum number in hydrogen is related to the atom's total energy.\n\nNote that the maximum value of the angular momentum quantum number is limited by the principal quantum number: it can run only up to \"n\" − 1, i.e. .\n\nDue to angular momentum conservation, states of the same \"ℓ\" but different \"m\" have the same energy (this holds for all problems with rotational symmetry). In addition, for the hydrogen atom, states of the same \"n\" but different \"ℓ\" are also degenerate (i.e. they have the same energy). However, this is a specific property of hydrogen and is no longer true for more complicated atoms which have an (effective) potential differing from the form 1/\"r\" (due to the presence of the inner electrons shielding the nucleus potential).\n\nTaking into account the spin of the electron adds a last quantum number, the projection of the electron's spin angular momentum along the \"z\"-axis, which can take on two values. Therefore, any eigenstate of the electron in the hydrogen atom is described fully by four quantum numbers. According to the usual rules of quantum mechanics, the actual state of the electron may be any superposition of these states. This explains also why the choice of \"z\"-axis for the directional quantization of the angular momentum vector is immaterial: an orbital of given \"ℓ\" and \"m\"′ obtained for another preferred axis \"z\"′ can always be represented as a suitable superposition of the various states of different \"m\" (but same \"l\") that have been obtained for \"z\".\n\nIn 1928, Paul Dirac found an equation that was fully compatible with Special Relativity, and (as a consequence) made the wave function a 4-component \"Dirac spinor\" including \"up\" and \"down\" spin components, with both positive and \"negative\" energy (or matter and antimatter). The solution to this equation gave the following results, more accurate than the Schrödinger solution.\n\nThe energy levels of hydrogen, including fine structure (excluding Lamb shift and hyperfine structure), are given by the Sommerfeld fine structure expression:\n\nwhere \"α\" is the fine-structure constant and \"j\" is the \"total angular momentum\" quantum number, which is equal to |\"ℓ\" ± | depending on the direction of the electron spin. This formula represents a small correction to the energy obtained by Bohr and Schrödinger as given above. The factor in square brackets in the last expression is nearly one; the extra term arises from relativistic effects (for details, see #Features going beyond the Schrödinger solution). It is worth noting that this expression was first obtained by A. Sommerfeld in 1916 based on the relativistic version of the old Bohr theory. Sommerfeld has however used different notation for the quantum numbers.\n\nThe image to the right shows the first few hydrogen atom orbitals (energy eigenfunctions). These are cross-sections of the probability density that are color-coded (black represents zero density and white represents the highest density). The angular momentum (orbital) quantum number \"ℓ\" is denoted in each column, using the usual spectroscopic letter code (\"s\" means \"ℓ\" = 0, \"p\" means \"ℓ\" = 1, \"d\" means \"ℓ\" = 2). The main (principal) quantum number \"n\" (= 1, 2, 3, ...) is marked to the right of each row. For all pictures the magnetic quantum number \"m\" has been set to 0, and the cross-sectional plane is the \"xz\"-plane (\"z\" is the vertical axis). The probability density in three-dimensional space is obtained by rotating the one shown here around the \"z\"-axis.\n\nThe \"ground state\", i.e. the state of lowest energy, in which the electron is usually found, is the first one, the 1\"s\" state (principal quantum level \"n\" = 1, \"ℓ\" = 0).\n\nBlack lines occur in each but the first orbital: these are the nodes of the wavefunction, i.e. where the probability density is zero. (More precisely, the nodes are spherical harmonics that appear as a result of solving Schrödinger equation in polar coordinates.)\n\nThe quantum numbers determine the layout of these nodes. There are:\n\nThere are several important effects that are neglected by the Schrödinger equation and which are responsible for certain small but measurable deviations of the real spectral lines from the predicted ones:\n\n\nBoth of these features (and more) are incorporated in the relativistic Dirac equation, with predictions that come still closer to experiment. Again the Dirac equation may be solved analytically in the special case of a two-body system, such as the hydrogen atom. The resulting solution quantum states now must be classified by the total angular momentum number \"j\" (arising through the coupling between electron spin and orbital angular momentum). States of the same \"j\" and the same \"n\" are still degenerate. Thus, direct analytical solution of Dirac equation predicts 2S() and 2P() levels of Hydrogen to have exactly the same energy, which is in a contradiction with observations (Lamb-Retherford experiment).\n\n\nFor these developments, it was essential that the solution of the Dirac equation for the hydrogen atom could be worked out exactly, such that any experimentally observed deviation had to be taken seriously as a signal of failure of the theory.\n\nIn the language of Heisenberg's matrix mechanics, the hydrogen atom was first solved by Wolfgang Pauli using a rotational symmetry in four dimensions [O(4)-symmetry] generated by the angular momentum \nand the Laplace–Runge–Lenz vector. By extending the symmetry group O(4) to the dynamical group O(4,2),\nthe entire spectrum and all transitions were embedded in a single irreducible group representation.\n\nIn 1979 the (non relativistic) hydrogen atom was solved for the first time within Feynman's path integral formulation\nof quantum mechanics. This work greatly extended the range of applicability of Feynman's method.\n\n\n\n"}
{"id": "14227", "url": "https://en.wikipedia.org/wiki?curid=14227", "title": "Elagabalus", "text": "Elagabalus\n\nElagabalus (), also known as Heliogabalus (; 204 – 11 March 222), was Roman emperor from 218 to 222. A member of the Severan dynasty, he was Syrian, the second son of Julia Soaemias and Sextus Varius Marcellus. In his early youth he served the god Elagabalus as a priest in Emesa, the hometown of his mother's family. As a private citizen, he was probably named Sextus Varius Avitus Bassianus. Upon becoming emperor he took the name Marcus Aurelius Antoninus Augustus. He was called Elagabalus only after his death.\n\nIn 217, the emperor Caracalla was assassinated and replaced by his Praetorian prefect, Marcus Opellius Macrinus. Caracalla's maternal aunt, Julia Maesa, successfully instigated a revolt among the Third Legion to have her eldest grandson (and Caracalla's cousin), Elagabalus, declared emperor in his place. Macrinus was defeated on 8 June 218 at the Battle of Antioch. Elagabalus, barely 14 years old, became emperor, initiating a reign remembered mainly for sex scandals and religious controversy.\n\nLater historians suggest Elagabalus showed a disregard for Roman religious traditions and sexual taboos. He replaced the traditional head of the Roman pantheon, Jupiter, with the deity Elagabalus, of whom he had been high priest. He forced leading members of Rome's government to participate in religious rites celebrating this deity, over which he personally presided. Elagabalus was supposedly \"married\" as many as five times, lavishing favours on male courtiers popularly thought to have been his lovers, and was reported to have prostituted himself in the imperial palace. His behavior estranged the Praetorian Guard, the Senate, and the common people alike. Amidst growing opposition, Elagabalus, just 18 years old, was assassinated and replaced by his cousin Severus Alexander on 11 March 222, who ruled for 13 years before his own assassination, which marked the epoch event for the Crisis of the Third Century. The assassination plot against Elagabalus was devised by his grandmother, Julia Maesa, and carried out by disaffected members of the Praetorian Guard.\n\nElagabalus developed a reputation among his contemporaries for extreme eccentricity, decadence, and zealotry. This tradition has persisted, and with writers of the early modern age he suffers one of the worst reputations among Roman emperors. Edward Gibbon, for example, wrote that Elagabalus \"abandoned himself to the grossest pleasures and ungoverned fury\". According to Barthold Georg Niebuhr, \"The name Elagabalus is branded in history above all others\" because of his \"unspeakably disgusting life\".\n\nElagabalus was born around the year 204 to Sextus Varius Marcellus and Julia Soaemias Bassiana. His father was initially a member of the Equites class, but was later elevated to the rank of senator. His grandmother, Julia Maesa, was the widow of the consul Julius Avitus, the sister of Julia Domna, and the sister-in-law of the emperor Septimius Severus. He had at least one sibling: an unnamed elder brother. His mother, Julia Soaemias, was a cousin of the emperor Caracalla. His other relatives included his aunt Julia Avita Mamaea and uncle Marcus Julius Gessius Marcianus and among their children, their son Severus Alexander. Elagabalus's family held hereditary rights to the priesthood of the sun god Elagabal, of whom Elagabalus was the high priest at Emesa (modern Homs) in Roman Syria.\n\nThe deity Elagabalus was initially venerated at Emesa. This form of the god's name is a Latinized version of the Syrian \"Ilāh hag-Gabal\", which derives from \"Ilāh\" (a Semitic word for \"god\") and \"gabal\" (an Arabic word for \"mountain\"), resulting in \"the God of the Mountain,\" the Emesene manifestation of the deity. \n\nThe cult of the deity spread to other parts of the Roman Empire in the 2nd century; a dedication has been found as far away as Woerden (Netherlands), near the Roman \"limes\". The god was later imported and assimilated with the Roman sun god known as Sol Indiges in republican times and as Sol Invictus during the second and third centuries CE. In Greek the sun god is Helios, hence \"Heliogabalus\", a hybrid conjunction of \"Helios\" and \"Elagabalus\".\n\nWhen the Emperor Macrinus came to power, he suppressed the threat against his reign from the family of his assassinated predecessor, Caracalla, by exiling them—Julia Maesa, her two daughters, and her eldest grandson Elagabalus—to their estate at Emesa in Syria. Almost upon arrival in Syria, Maesa began a plot with her advisor and Elagabalus' tutor, Gannys, to overthrow Macrinus and elevate the fourteen-year-old Elagabalus to the imperial throne.\n\nHis mother publicly declared that he was the illegitimate son of Caracalla, and therefore deserving the loyalty of Roman soldiers and senators who had sworn allegiance to Caracalla. After Julia Maesa displayed her wealth to the Third Legion at Raphana they swore allegiance to Elagabalus. At sunrise on 16 May 218, Publius Valerius Comazon, commander of the legion, declared him emperor. To strengthen his legitimacy Elagabalus assumed Caracalla's names, \"Marcus Aurelius Antoninus\".\n\nIn response Macrinus dispatched his Praetorian prefect Ulpius Julianus to the region with a contingent of troops he considered strong enough to crush the rebellion. However, this force soon joined the faction of Elagabalus when, during the battle, they turned on their own commanders. The officers were killed and Julianus' head was sent back to the emperor.\n\nMacrinus now sent letters to the Senate denouncing Elagabalus as the \"False Antoninus\" and claiming he was insane. Both consuls and other high-ranking members of Rome's leadership condemned Elagabalus, and the Senate subsequently declared war on both Elagabalus and Julia Maesa.\n\nMacrinus and his son, weakened by the desertion of the Second Legion due to bribes and promises circulated by Julia Maesa, were defeated on 8 June 218 at the Battle of Antioch by troops commanded by Gannys. Macrinus fled to Italy, disguised as a courier, but was intercepted near Chalcedon and executed in Cappadocia. His son Diadumenian, sent as a friendly hostage to the Parthian court as a guarantee of peace between the states, was captured at Zeugma and also put to death.\n\nElagabalus declared the date of the victory at Antioch to be the beginning of his reign and assumed the imperial titles without prior senatorial approval. This violated tradition but was a common practice among 3rd-century emperors nonetheless. Letters of reconciliation were dispatched to Rome extending amnesty to the Senate and recognizing the laws, while also condemning the administration of Macrinus and his son.\n\nThe senators responded by acknowledging Elagabalus as emperor and accepting his claim to be the son of Caracalla. Caracalla and Julia Domna were both deified by the Senate, both Julia Maesa and Julia Soaemias were elevated to the rank of Augustae, and the memory of both Macrinus and Diadumenian was expunged by the Senate. The former commander of the Third Legion, Comazon, was appointed commander of the Praetorian Guard.\n\nElagabalus and his entourage spent the winter of 218 in Bithynia at Nicomedia, where the emperor's religious beliefs first presented themselves as a problem. The contemporary historian Cassius Dio suggests that Gannys was in fact killed by the new emperor because he pressured Elagabalus to live \"temperately and prudently\". To help Romans adjust to having an oriental priest as emperor, Julia Maesa had a painting of Elagabalus in priestly robes sent to Rome and hung over a statue of the goddess Victoria in the Senate House. This placed senators in the awkward position of having to make offerings to Elagabalus whenever they made offerings to Victoria.\n\nThe legions were dismayed by his behaviour and quickly came to regret having supported his accession. While Elagabalus was still on his way to Rome, brief revolts broke out by the Fourth Legion at the instigation of Gellius Maximus, and by the Third Legion, which itself had been responsible for the elevation of Elagabalus to the throne, under the command of Senator Verus. The rebellion was quickly put down, and the Third Legion disbanded.\n\nWhen the entourage reached Rome in the autumn of 219, Comazon and other allies of Julia Maesa and Elagabalus were given powerful and lucrative positions, to the chagrin of many senators who did not consider them worthy of such privileges. After his tenure as Praetorian prefect, Comazon served as the city prefect of Rome three times, and as consul twice. Elagabalus soon devalued the Roman currency. He decreased the silver purity of the \"denarius\" from 58% to 46.5% — the actual silver weight dropping from 1.82 grams to 1.41 grams. He also demonetized the \"antoninianus\" during this period in Rome.\n\nElagabalus tried to have his presumed lover, the charioteer Hierocles, declared Caesar, while another alleged lover, the athlete Aurelius Zoticus, was appointed to the non-administrative but influential position of Master of the Chamber, or \"Cubicularius\". His offer of amnesty for the Roman upper class was largely honoured, though the jurist Ulpian was exiled.\n\nThe relationships between Julia Maesa, Julia Soaemias, and Elagabalus were strong at first. His mother and grandmother became the first women to be allowed into the Senate, and both received senatorial titles: Soaemias the established title of \"Clarissima,\" and Maesa the more unorthodox \"Mater Castrorum et Senatus\" (\"Mother of the army camp and of the Senate\"). They held the title of \"Augusta\" as well, suggesting that they may have been the power behind the throne. Indeed, they exercised great influence over the young emperor throughout his reign, and can be found on many coins and inscriptions—a rare honor for Roman women.\n\nSince the reign of Septimius Severus, sun worship had increased throughout the Empire. Elagabalus saw this as an opportunity to install Elagabal as the chief deity of the Roman pantheon. The god was renamed \"Deus Sol Invictus\", meaning \"God the Undefeated Sun\", and honored above Jupiter.\n\nAs a token of respect for Roman religion, however, Elagabalus joined either Astarte, Minerva, Urania, or some combination of the three to Elagabal as consort. A union between Elagabal and a traditional goddess would have served to strengthen ties between the new religion and the imperial cult. In fact, there may have been an effort to introduce Elagabal, Urania, and Athena as the new Capitoline triad of Rome—replacing Jupiter, Juno, and Minerva.\n\nHe aroused further discontent when he married the Vestal Virgin Aquilia Severa, claiming the marriage would produce \"godlike children\". This was a flagrant breach of Roman law and tradition, which held that any Vestal found to have engaged in sexual intercourse was to be buried alive.\n\nA lavish temple called the Elagabalium was built on the east face of the Palatine Hill to house Elagabal, who was represented by a black conical meteorite from Emesa. Herodian wrote \"this stone is worshipped as though it were sent from heaven; on it there are some small projecting pieces and markings that are pointed out, which the people would like to believe are a rough picture of the sun, because this is how they see them\".\n\nIn order to become the high priest of his new religion, Elagabalus had himself circumcised. He forced senators to watch while he danced around the altar of Deus Sol Invictus to the accompaniment of drums and cymbals. Each summer solstice he held a festival dedicated to the god, which became popular with the masses because of the free food distributed on these occasions. During this festival, Elagabalus placed the Emesa stone on a chariot adorned with gold and jewels, which he paraded through the city:\n\nThe most sacred relics from the Roman religion were transferred from their respective shrines to the Elagabalium, including the emblem of the Great Mother, the fire of Vesta, the Shields of the Salii, and the Palladium, so that no other god could be worshipped except in association with Elagabal.\n\nThe question of Elagabalus' sexual orientation is confused, owing to salacious and unreliable sources. Elagabalus married and divorced five women, three of whom are known. His first wife was Julia Cornelia Paula; the second was the Vestal Virgin Julia Aquilia Severa.\n\nWithin a year, he abandoned her and married Annia Aurelia Faustina, a descendant of Marcus Aurelius and the widow of a man he had recently had executed. He had returned to his second wife Severa by the end of the year. According to Cassius Dio, his most stable relationship seems to have been with his chariot driver, a blond slave from Caria named Hierocles, whom he referred to as his husband.\n\nThe \"Augustan History\" claims that he also married a man named Zoticus, an athlete from Smyrna, in a public ceremony at Rome. Cassius Dio reported that Elagabalus would paint his eyes, depilate his body hair and wear wigs before prostituting himself in taverns, brothels, and even in the imperial palace:\n\nHerodian commented that Elagabalus enhanced his natural good looks by the regular application of cosmetics. He was described as having been \"delighted to be called the mistress, the wife, the queen of Hierocles\" and was reported to have offered vast sums of money to any physician who could equip him with female genitalia. Elagabalus has been characterized by some modern writers as transgender or transsexual.\n\nBy 221 Elagabalus' eccentricities, particularly his relationship with Hierocles, increasingly provoked the soldiers of the Praetorian Guard. When Elagabalus' grandmother Julia Maesa perceived that popular support for the emperor was waning, she decided that he and his mother, who had encouraged his religious practices, had to be replaced. As alternatives, she turned to her other daughter, Julia Avita Mamaea, and her daughter's son, the fifteen-year-old Severus Alexander.\n\nPrevailing on Elagabalus, she arranged that he appoint his cousin Alexander as his heir and that the boy be given the title of \"Caesar\". Alexander shared the consulship with the emperor that year. However, Elagabalus reconsidered this arrangement when he began to suspect that the Praetorian Guard preferred his cousin to himself.\n\nFollowing the failure of various attempts on Alexander's life, Elagabalus stripped his cousin of his titles, revoked his consulship, and invented the rumor that Alexander was near death, in order to see how the Praetorians would react. A riot ensued, and the Guard demanded to see Elagabalus and Alexander in the Praetorian camp.\n\nThe Emperor complied and on 11 March 222 he publicly presented his cousin along with his own mother, Julia Soaemias. On their arrival the soldiers started cheering Alexander while ignoring Elagabalus, who ordered the summary arrest and execution of anyone who had taken part in this display of insubordination. In response, members of the Praetorian Guard attacked Elagabalus and his mother:\n\nFollowing his assassination, many associates of Elagabalus were killed or deposed, including his lover Hierocles. His religious edicts were reversed and the stone of Elagabal was sent back to Emesa. Women were again barred from attending meetings of the Senate. The practice of \"damnatio memoriae\"—erasing from the public record a disgraced personage formerly of note—was systematically applied in his case. Several images, including an over-life-size statue of him as Hercules that is now in Naples, were re-carved with the face of Alexander Severus.\n\nThe source of many of these stories of Elagabalus's depravity is the \"Augustan History\" (\"Historia Augusta\"), which includes controversial claims. It is most likely that the \"Historia Augusta\" was written towards the end of the 4th century, during the reign of Emperor Theodosius I. The life of Elagabalus as described in the \"Augustan History\" is of uncertain historical merit. Sections 13 to 17, relating to the fall of Elagabalus, are less controversial among historians.\n\nSources often considered more credible than the \"Augustan History\" include the contemporary historians Cassius Dio and Herodian. Cassius Dio lived from the second half of the 2nd century until sometime after 229. Born into a patrician family, he spent the greater part of his life in public service. He was a senator under emperor Commodus and governor of Smyrna after the death of Septimius Severus. Afterwards, he served as suffect consul around 205, and as proconsul in Africa and Pannonia.\n\nSeverus Alexander held him in high esteem and made him his consul again. His \"Roman History\" spans nearly a millennium, from the arrival of Aeneas in Italy until the year 229. As a contemporary of Elagabalus, Cassius Dio's account of his reign is generally considered more reliable than the \"Augustan History\", although by his own admission Dio spent the greater part of the relevant period outside of Rome and had to rely on second-hand information.\n\nFurthermore, the political climate in the aftermath of Elagabalus' reign, as well as Dio's own position within the government of Alexander likely influenced the truth of this part of his history for the worse. Dio regularly refers to Elagabalus as Sardanapalus, partly to distinguish him from his divine namesake, but chiefly to do his part in maintaining the \"damnatio memoriae\" and to associate him with another autocrat notorious for a dissolute life.\n\nAnother contemporary of Elagabalus' was Herodian, a minor Roman civil servant who lived from c. 170 until 240. His work, \"History of the Roman Empire since Marcus Aurelius\", commonly abbreviated as \"Roman History\", is an eyewitness account of the reign of Commodus until the beginning of the reign of Gordian III. His work largely overlaps with Dio's own \"Roman History\", but the texts, written independently of each other, agree more often than not about the emperor and his short but eventful reign .\n\nAlthough Herodian is not deemed as reliable as Cassius Dio, his lack of literary and scholarly pretensions make him less biased than senatorial historians. Herodian is considered the most important source for the religious reforms which took place during the reign of Elagabalus, which have been confirmed by numismatic and archaeological evidence.\n\nFor readers of the modern age, \"The History of the Decline and Fall of the Roman Empire\" by Edward Gibbon (1737–94) further cemented the scandalous reputation of Elagabalus. Gibbon not only accepted and expressed outrage at the allegations of the ancient historians, but he might have added some details of his own; he is the first historian known to claim that Gannys was a eunuch, for example. Gibbon wrote:\n\nThe 20th-century anthropologist James George Frazer (famous for \"The Golden Bough\") took seriously the monotheistic aspirations of the emperor, but also ridiculed him: \"The dainty priest of the Sun [was] the most abandoned reprobate who ever sat upon a throne...It was the intention of this eminently religious but crack-brained despot to supersede the worship of all the gods, not only at Rome but throughout the world, by the single worship of Elagabalus or the Sun.\"\n\nThe first book-length biography was \"The Amazing Emperor Heliogabalus\" (1911) by J. Stuart Hay, \"a serious and systematic study\" more sympathetic than that of previous historians, which nonetheless stressed the exoticism of Elagabalus, calling his reign one of \"enormous wealth and excessive prodigality, luxury and aestheticism, carried to their ultimate extreme, and sensuality in all the refinements of its Eastern habit.\"\n\nSome recent historians paint a more favorable picture of the emperor's rule. Martijn Icks, in \"Images of Elagabalus\" (2008; republished as \"The Crimes of Elagabalus\" in 2012), doubts the reliability of the ancient sources and argues that it was the emperor's unorthodox religious policies that alienated the power elite of Rome, to the point that his grandmother saw fit to eliminate him and replace him with his cousin. Leonardo de Arrizabalaga y Prado, in \"The Emperor Elagabalus: Fact or Fiction?\" (2008), is also critical of the ancient historians and speculates that neither religion nor sexuality played a role in the fall of the young emperor. He was simply the loser in a power struggle within the imperial family; the loyalty of the Praetorian Guards was up for sale, and Julia Maesa had the resources to outmaneuver and outbribe her grandson. In this version of events, once Elagabalus, his mother, and his immediate circle had been murdered, a campaign of character assassination began, resulting in a grotesque caricature that has persisted to the present day. Historians have not only kept the tradition alive, but often embellished it, reflecting their own bias against effeminacy, religious zealotry, and other traits with which Elagabalus is commonly identified.\n\nDue to the ancient tradition about him, Elagabalus became something of an (anti-)hero in the Decadent movement of the late 19th century. He often appears in literature and other creative media as the epitome of a young, amoral aesthete. His life and character have informed or at least inspired many famous works of art, by Decadents, even by contemporary artists. The most notable of these works include:\n\n\n\n\n\n\n\n\n\n\n \n"}
{"id": "14229", "url": "https://en.wikipedia.org/wiki?curid=14229", "title": "Homeopathy", "text": "Homeopathy\n\nHomeopathy or homœopathy is a system of alternative medicine created in 1796 by Samuel Hahnemann, based on his doctrine of \"like cures like\" (\"similia similibus curentur\"), a claim that a substance that causes the symptoms of a disease in healthy people would cure similar symptoms in sick people. Homeopathy is a pseudoscience – a belief that is incorrectly presented as scientific. Homeopathic preparations are not effective for treating any condition; large-scale studies have found homeopathy to be no more effective than a placebo, indicating that any positive effects that follow treatment are not due to the treatment itself but instead to factors such as normal recovery from illness, or regression toward the mean.\n\nHahnemann believed the underlying causes of disease were phenomena that he termed \"miasms\", and that homeopathic preparations addressed these. The preparations are manufactured using a process of homeopathic dilution, in which a chosen substance is repeatedly diluted in alcohol or distilled water, each time with the containing vessel being struck against an elastic material, commonly a leather-bound book. Dilution typically continues well past the point where no molecules of the original substance remain. Homeopaths select homeopathics by consulting reference books known as \"repertories\", and by considering the totality of the patient's symptoms, personal traits, physical and psychological state, and life history.\n\nHomeopathy is not a plausible system of treatment, as its dogmas about how drugs, illness, the human body, liquids and solutions operate are contradicted by a wide range of discoveries across biology, psychology, physics and chemistry made in the two centuries since its invention. Although some clinical trials produce positive results, multiple systematic reviews have shown that this is because of chance, flawed research methods, and reporting bias. Homeopathic practice has been criticized as unethical because it discourages the use of effective treatments, with the World Health Organization warning against using homeopathy to try to treat severe diseases such as HIV and malaria. The continued practice of homeopathy, despite a lack of evidence of efficacy, has led to it being characterized within the scientific and medical communities as nonsense, quackery, and a sham.\n\nThere have been four large scale assessments of homeopathy by national or international bodies: the Australian National Health and Medical Research Council; the United Kingdom's House of Commons Science and Technology Committee; the European Academies' Science Advisory Council; and the Swiss Federal Health Office. Each concluded that homeopathy is ineffective, and recommended against the practice receiving any further funding. The National Health Service in England has announced a policy of not funding homeopathic medicine because it is \"a misuse of resources\". They called on the UK Department of Health to add homeopathic remedies to the blacklist of forbidden prescription items, and the NHS ceased funding homeopathic remedies in November 2017.\n\nThe concept of \"like cures like\" may have been suggested by Hippocrates around 400 BC, when he prescribed a small dose of mandrake root to treat mania, knowing it produces mania in much larger doses. Similarly, in the 16th century, Paracelsus wrote \"similia similibus curantur\" (similar to the subjunctive form later used by Hahnemann), often translated as \"what makes a man ill also cures him\".\n\nIn the late 18th and 19th centuries, mainstream medicine used methods like bloodletting and purging, and administered complex mixtures, such as Venice treacle, which was made from 64 substances including opium, myrrh, and viper's flesh. These treatments often worsened symptoms and sometimes proved fatal. Hahnemann rejected these practices – which had been extolled for centuries – as irrational and inadvisable;\ninstead, he advocated the use of single drugs at lower doses and promoted an immaterial, vitalistic view of how living organisms function, believing that diseases have spiritual, as well as physical causes.\n\nThe term \"homeopathy\" was coined by Hahnemann and first appeared in print in 1807.\n\nHahnemann conceived of homeopathy while translating a medical treatise by the Scottish physician and chemist William Cullen into German. Being sceptical of Cullen's theory concerning cinchona's use for curing malaria, Hahnemann ingested some bark specifically to investigate what would happen. He experienced fever, shivering and joint pain: symptoms similar to those of malaria itself. From this, Hahnemann came to believe that all effective drugs produce symptoms in healthy individuals similar to those of the diseases that they treat, in accord with the \"law of similars\" that had been proposed by ancient physicians. An account of the effects of eating cinchona bark noted by Oliver Wendell Holmes, and published in 1861, failed to reproduce the symptoms Hahnemann reported. Hahnemann's law of similars is a postulate rather than a scientific law. This led to the name \"\"homeopathy\"\", which comes from the \"hómoios\", \"-like\" and \"páthos\", \"suffering\".\n\nSubsequent scientific work showed that cinchona cures malaria because it contains quinine, which kills the \"Plasmodium falciparum\" parasite that causes the disease; the mechanism of action is unrelated to Hahnemann's ideas.\n\nHahnemann began to test what effects substances produced in humans, a procedure that would later become known as \"homeopathic proving\". These tests required subjects to test the effects of ingesting substances by clearly recording all of their symptoms as well as the ancillary conditions under which they appeared. He published a collection of provings in 1805, and a second collection of 65 preparations appeared in his book, \"Materia Medica Pura\", in 1810.\n\nBecause Hahnemann believed that large doses of drugs that caused similar symptoms would only aggravate illness, he advocated extreme dilutions of the substances; he devised a technique for making dilutions that he believed would preserve a substance's therapeutic properties while removing its harmful effects. Hahnemann believed that this process aroused and enhanced \"the spirit-like medicinal powers of the crude substances\".\nHe gathered and published a complete overview of his new medical system in his 1810 book, \"The Organon of the Healing Art\", whose 6th edition, published in 1921, is still used by homeopaths today.\n\nIn the \"Organon\", Hahnemann introduced the concept of \"miasms\" as \"infectious principles\" underlying chronic disease. Hahnemann associated each miasm with specific diseases, and thought that initial exposure to miasms causes local symptoms, such as skin or venereal diseases. If, however, these symptoms were suppressed by medication, the cause went deeper and began to manifest itself as diseases of the internal organs. Homeopathy maintains that treating diseases by directly alleviating their symptoms, as is sometimes done in conventional medicine, is ineffective because all \"disease can generally be traced to some latent, deep-seated, underlying chronic, or inherited tendency\". The underlying imputed miasm still remains, and deep-seated ailments can be corrected only by removing the deeper disturbance of the vital force.\n\nHahnemann's hypotheses for the direct or remote cause of all chronic diseases (miasms) originally presented only three, psora (the itch), syphilis (venereal disease) or sycosis (fig-wart disease). Of these three the most important was \"psora\" (Greek for \"itch\"), described as being related to any itching diseases of the skin, supposed to be derived from suppressed scabies, and claimed to be the foundation of many further disease conditions. Hahnemann believed psora to be the cause of such diseases as epilepsy, cancer, jaundice, deafness, and cataracts.\nSince Hahnemann's time, other miasms have been proposed, some replacing one or more of psora's proposed functions, including tuberculosis and cancer miasms.\n\nThe law of susceptibility implies that a negative state of mind can attract hypothetical disease entities called \"miasms\" to invade the body and produce symptoms of diseases. Hahnemann rejected the notion of a disease as a separate thing or invading entity, and insisted it was always part of the \"living whole\". Hahnemann coined the expression \"allopathic medicine\", which was used to pejoratively refer to traditional Western medicine.\n\nHahnemann's miasm theory remains disputed and controversial within homeopathy even in modern times. The theory of miasms has been criticized as an explanation developed by Hahnemann to preserve the system of homeopathy in the face of treatment failures, and for being inadequate to cover the many hundreds of sorts of diseases, as well as for failing to explain disease predispositions, as well as genetics, environmental factors, and the unique disease history of each patient.\n\nHomeopathy achieved its greatest popularity in the 19th century. It was introduced to the United States in 1825 by Hans Birch Gram, a student of Hahnemann. The first homeopathic school in the US opened in 1835, and in 1844, the first US national medical association, the American Institute of Homeopathy, was established. Throughout the 19th century, dozens of homeopathic institutions appeared in Europe and the United States, and by 1900, there were 22 homeopathic colleges and 15,000 practitioners in the United States. Because medical practice of the time relied on ineffective and often dangerous treatments, patients of homeopaths often had better outcomes than those of the doctors of the time. Homeopathic preparations, even if ineffective, would almost surely cause no harm, making the users of homeopathic preparations less likely to be killed by the treatment that was supposed to be helping them. The relative success of homeopathy in the 19th century may have led to the abandonment of the ineffective and harmful treatments of bloodletting and purging and to have begun the move towards more effective, science-based medicine.\nOne reason for the growing popularity of homeopathy was its apparent success in treating people suffering from infectious disease epidemics.\nDuring 19th-century epidemics of diseases such as cholera, death rates in homeopathic hospitals were often lower than in conventional hospitals, where the treatments used at the time were often harmful and did little or nothing to combat the diseases.\n\nFrom its inception, however, homeopathy was criticized by mainstream science. Sir John Forbes, physician to Queen Victoria, said in 1843 that the extremely small doses of homeopathy were regularly derided as useless, \"an outrage to human reason\". James Young Simpson said in 1853 of the highly diluted drugs: \"No poison, however strong or powerful, the billionth or decillionth of which would in the least degree affect a man or harm a fly.\"\n19th-century American physician and author Oliver Wendell Holmes, Sr. was also a vocal critic of homeopathy and published an essay in 1842 entitled \"Homœopathy and Its Kindred Delusions\". The members of the French Homeopathic Society observed in 1867 that some leading homeopathists of Europe not only were abandoning the practice of administering infinitesimal doses but were also no longer defending it. The last school in the US exclusively teaching homeopathy closed in 1920.\n\nAccording to , the Nazi regime in Germany was fascinated by homeopathy, and spent large sums of money on researching its mechanisms, but without gaining a positive result. Unschuld further argues that homeopathy never subsequently took root in the United States, but remained more deeply established in European thinking.\nIn the United States, the \"Food, Drug, and Cosmetic Act\" of 1938 (sponsored by Royal Copeland, a Senator from New York and homeopathic physician) recognized homeopathic preparations as drugs. In the 1950s, there were only 75 pure homeopaths practising in the U.S. However, by the mid to late 1970s, homeopathy made a significant comeback and sales of some homeopathic companies increased tenfold. Some homeopaths give credit for the revival to Greek homeopath George Vithoulkas, who performed a \"great deal of research to update the scenarios and refine the theories and practice of homeopathy\", beginning in the 1970s, but Ernst and Singh consider it to be linked to the rise of the New Age movement. Whichever is correct, mainstream pharmacy chains recognized the business potential of selling homeopathic preparations. The Food and Drug Administration held a hearing April 20 and 21, 2015, requesting public comment on regulation of homeopathic drugs. The FDA cited the growth of sales of over-the-counter homeopathic medicines, which was $2.7 billion for 2007.\n\nBruce Hood has argued that the increased popularity of homeopathy in recent times may be due to the comparatively long consultations practitioners are willing to give their patients, and to an irrational preference for \"natural\" products, which people think are the basis of homeopathic preparations.\n\nSince the beginning of the 21st century a series of meta analysis has further shown that therapeutic claims of Homeopathy lack scientific justification. In a 2010 report, the Science and Technology Committee of the United Kingdom House of Commons recommended that homeopathy should no longer be a beneficiary of NHS funding due its lack of scientific credibility; funding ceased in 2017. In March 2015, the National Health and Medical Research Council of Australia published an information paper on Homeopathy. The main findings of the report were 'there are no health conditions for which there is reliable evidence that homeopathy is effective\". Reactions to the report sparked world headlines which suggested that the NHMRC had found that homeopathy is not effective for all conditions.\n\nIn 2018, Australian pharmacies ignored recommendations for a homeopathic ban in the broader scope of the federal government accepting only three of the 45 recommendations made by the review of Pharmacy Remuneration and Regulation (which were delivered in September 2017 to Health Minister Greg Hunt).\n\nHomeopathic preparations are referred to as \"homeopathics\" or \"remedies\". Practitioners rely on two types of reference when prescribing: \"Materia Medica\" and repertories. A homeopathic \"materia medica\" is a collection of \"drug pictures\", organized alphabetically. These entries describe the symptom patterns associated with individual preparations. A homeopathic repertory is an index of disease symptoms that lists preparations associated with specific symptoms. In both cases different compilers may dispute particular inclusions. The first symptomatic homeopathic \"materia medica\" was arranged by Hahnemann. The first homeopathic repertory was Georg Jahr's \"Symptomenkodex\", published in German in 1835, and translated into English as the \"Repertory to the more Characteristic Symptoms of Materia Medica\" by Constantine Hering in 1838.\nThis version was less focused on disease categories and was the forerunner to later works by James Tyler Kent. Repertories, in particular, may be very large.\n\nHomeopathy uses animal, plant, mineral, and synthetic substances in its preparations, generally referring to them using Latin or faux-Latin names. Examples include \"arsenicum album\" (arsenic oxide), \"natrum muriaticum\" (sodium chloride or table salt), \"Lachesis muta\" (the venom of the bushmaster snake), \"opium\", and \"thyroidinum\" (thyroid hormone).\n\nSome homeopaths use so-called \"nosodes\" (from the Greek \"nosos\", disease) made from diseased or pathological products such as fecal, urinary, and respiratory discharges, blood, and tissue. Conversely, preparations made from \"healthy\" specimens are called \"sarcodes\".\n\nSome modern homeopaths use preparations they call \"imponderables\" because they do not originate from a substance but some other phenomenon presumed to have been \"captured\" by alcohol or lactose. Examples include X-rays\nand sunlight.\n\nOther minority practices include paper preparations, where the substance and dilution are written on pieces of paper and either pinned to the patients' clothing, put in their pockets, or placed under glasses of water that are then given to the patients, and the use of radionics to manufacture preparations. Such practices have been strongly criticized by classical homeopaths as unfounded, speculative, and verging upon magic and superstition.\n\nHahnemann found that undiluted doses caused reactions, sometimes dangerous ones, so specified that preparations be given at the lowest possible dose. He found that this reduced potency as well as side-effects, but formed the view that vigorous shaking and striking on an elastic surface – a process he termed \"Schütteln\", translated as \"succussion\" – nullified this. A common explanation for his settling on this process is said to be that he found preparations subjected to agitation in transit, such as in saddle bags or in a carriage, were more \"potent\". Hahnemann had a saddle-maker construct a special wooden striking board covered in leather on one side and stuffed with horsehair. Insoluble solids, such as granite, diamond, and platinum, are diluted by grinding them with lactose (\"trituration\").\n\nThe process of dilution and succussion is termed \"dynamization\" or \"potentization\" by homeopaths. In industrial manufacture this may be done by machine.\n\nSerial dilution is achieved by taking an amount of the mixture and adding solvent, but the \"Korsakovian\" method may also be used, whereby the vessel in which the preparations are manufactured is emptied, refilled with solvent, and the volume of fluid adhering to the walls of the vessel is deemed sufficient for the new batch. The Korsakovian method is sometimes referred to as K on the label of a homeopathic preparation, e.g. 200CK is a 200C preparation made using the Korsakovian method.\n\nFluxion and radionics methods of preparation do not require succussion. There are differences of opinion on the number and force of strikes, and some practitioners dispute the need for succussion at all while others reject the Korsakovian and other non-classical preparations. There are no laboratory assays and the importance and techniques for succussion cannot be determined with any certainty from the literature.\n\nThree main logarithmic potency scales are in regular use in homeopathy. Hahnemann created the \"centesimal\" or \"C scale\", diluting a substance by a factor of 100 at each stage. The centesimal scale was favoured by Hahnemann for most of his life.\n\nA 2C dilution requires a substance to be diluted to one part in 100, and then some of that diluted solution diluted by a further factor of 100.\n\nThis works out to one part of the original substance in 10,000 parts of the solution. A 6C dilution repeats this process six times, ending up with the original substance diluted by a factor of 100=10 (one part in one trillion or 1/1,000,000,000,000). Higher dilutions follow the same pattern.\n\nIn homeopathy, a solution that is more dilute is described as having a higher \"potency\", and more dilute substances are considered by homeopaths to be stronger and deeper-acting. The end product is often so diluted as to be indistinguishable from the diluent (pure water, sugar or alcohol). There is also a decimal potency scale (notated as \"X\" or \"D\") in which the preparation is diluted by a factor of 10 at each stage.\n\nHahnemann advocated 30C dilutions for most purposes (that is, dilution by a factor of 10). Hahnemann regularly used potencies up to 300C but opined that \"there must be a limit to the matter, it cannot go on indefinitely\".\n\nIn Hahnemann's time, it was reasonable to assume the preparations could be diluted indefinitely, as the concept of the atom or molecule as the smallest possible unit of a chemical substance was just beginning to be recognized.\n\nThe greatest dilution reasonably likely to contain even one molecule of the original substance is 12C.\nCritics and advocates of homeopathy alike commonly attempt to illustrate the dilutions involved in homeopathy with analogies.\nHahnemann is reported to have joked that a suitable procedure to deal with an epidemic would be to empty a bottle of poison into Lake Geneva, if it could be succussed 60 times.\nAnother example given by a critic of homeopathy states that a 12C solution is equivalent to a \"pinch of salt in both the North and South Atlantic Oceans\", which is approximately correct.\nOne-third of a drop of some original substance diluted into all the water on earth would produce a preparation with a concentration of about 13C. A popular homeopathic treatment for the flu is a 200C dilution of duck liver, marketed under the name Oscillococcinum. As there are only about 10 atoms in the entire observable universe, a dilution of one molecule in the observable universe would be about 40C. Oscillococcinum would thus require 10 more universes to simply have one molecule in the final substance.\nThe high dilutions characteristically used are often considered to be the most controversial and implausible aspect of homeopathy.\n\nNot all homeopaths advocate high dilutions. Preparations at concentrations below 4X are considered an important part of homeopathic heritage. Many of the early homeopaths were originally doctors and generally used lower dilutions such as \"3X\" or \"6X\", rarely going beyond \"12X\".\nThe split between lower and higher dilutions followed ideological lines.\nThose favouring low dilutions stressed pathology and a stronger link to conventional medicine, while those favouring high dilutions emphasized vital force, miasms and a spiritual interpretation of disease.\nSome products with such relatively lower dilutions continue to be sold, but like their counterparts, they have not been conclusively demonstrated to have any effect beyond that of a placebo.\n\nA homeopathic \"proving\" is the method by which the profile of a homeopathic preparation is determined.\n\nAt first Hahnemann used undiluted doses for provings, but he later advocated provings with preparations at a 30C dilution, and most modern provings are carried out using ultra-dilute preparations in which it is highly unlikely that any of the original molecules remain. During the proving process, Hahnemann administered preparations to healthy volunteers, and the resulting symptoms were compiled by observers into a \"drug picture\".\n\nThe volunteers were observed for months at a time and made to keep extensive journals detailing all of their symptoms at specific times throughout the day. They were forbidden from consuming coffee, tea, spices, or wine for the duration of the experiment; playing chess was also prohibited because Hahnemann considered it to be \"too exciting\", though they were allowed to drink beer and encouraged to exercise in moderation.\n\nAfter the experiments were over, Hahnemann made the volunteers take an oath swearing that what they reported in their journals was the truth, at which time he would interrogate them extensively concerning their symptoms.\n\nProvings are claimed to have been important in the development of the clinical trial, due to their early use of simple control groups, systematic and quantitative procedures, and some of the first application of statistics in medicine. The lengthy records of self-experimentation by homeopaths have occasionally proven useful in the development of modern drugs: For example, evidence that nitroglycerin might be useful as a treatment for angina was discovered by looking through homeopathic provings, though homeopaths themselves never used it for that purpose at that time.\nThe first recorded provings were published by Hahnemann in his 1796 \"Essay on a New Principle\".\nHis \"Fragmenta de Viribus\" (1805) contained the results of 27 provings, and his 1810 \"Materia Medica Pura\" contained 65.\nFor James Tyler Kent's 1905 \"Lectures on Homoeopathic Materia Medica\", 217 preparations underwent provings and newer substances are continually added to contemporary versions.\n\nThough the proving process has superficial similarities with clinical trials, it is fundamentally different in that the process is subjective, not blinded, and modern provings are unlikely to use pharmacologically active levels of the substance under proving. As early as 1842, Holmes noted the provings were impossibly vague, and the purported effect was not repeatable among different subjects.\n\nHomeopaths generally begin with detailed examinations of their patients' histories, including questions regarding their physical, mental and emotional states, their life circumstances and any physical or emotional illnesses. The homeopath then attempts to translate this information into a complex formula of mental and physical symptoms, including likes, dislikes, innate predispositions and even body type.\n\nFrom these symptoms, the homeopath chooses how to treat the patient using \"materia medica\" and repertories. In classical homeopathy, the practitioner attempts to match a single preparation to the totality of symptoms (the \"simlilum\"), while \"clinical homeopathy\" involves combinations of preparations based on the various symptoms of an illness.\n\nHomeopathic pills are made from an inert substance (often sugars, typically lactose), upon which a drop of liquid homeopathic preparation is placed and allowed to evaporate.\n\nThe process of homeopathic dilution results in no objectively detectable active ingredient in most cases, but some preparations (e.g. calendula and arnica creams) do contain pharmacologically active doses. One product, Zicam Cold Remedy, which was marketed as an \"unapproved homeopathic\" product, contains two ingredients that are only \"slightly\" diluted: zinc acetate (2X = 1/100 dilution) and zinc gluconate (1X = 1/10 dilution), which means both are present in a biologically active concentration strong enough to have caused some people to lose their sense of smell, a condition termed anosmia. Zicam also listed several normal homeopathic potencies as \"inactive ingredients\", including \"galphimia glauca\", histamine dihydrochloride (homeopathic name, \"histaminum hydrochloricum\"), \"luffa operculata\", and sulfur.\n\nIsopathy is a therapy derived from homeopathy, invented by Johann Joseph Wilhelm Lux in the 1830s. Isopathy differs from homeopathy in general in that the preparations, known as \"nosodes\", are made up either from things that cause the disease or from products of the disease, such as pus. Many so-called \"homeopathic vaccines\" are a form of isopathy. Tautopathy is a form of isopathy where the preparations are composed of drugs or vaccines that a person has consumed in the past, in the belief that this can reverse lingering damage caused by the initial use. There is no convincing scientific evidence for isopathy as an effective method of treatment.\n\nFlower preparations can be produced by placing flowers in water and exposing them to sunlight. The most famous of these are the Bach flower remedies, which were developed by the physician and homeopath Edward Bach. Although the proponents of these preparations share homeopathy's vitalist world-view and the preparations are claimed to act through the same hypothetical \"vital force\" as homeopathy, the method of preparation is different. Bach flower preparations are manufactured in allegedly \"gentler\" ways such as placing flowers in bowls of sunlit water, and the preparations are not succussed. There is no convincing scientific or clinical evidence for flower preparations being effective.\n\nThe idea of using homeopathy as a treatment for other animals termed \"veterinary homeopathy\", dates back to the inception of homeopathy; Hahnemann himself wrote and spoke of the use of homeopathy in animals other than humans. The FDA has not approved homeopathic products as veterinary medicine in the U.S. In the UK, veterinary surgeons who use homeopathy may belong to the Faculty of Homeopathy and/or to the British Association of Homeopathic Veterinary Surgeons. Animals may be treated only by qualified veterinary surgeons in the UK and some other countries. Internationally, the body that supports and represents homeopathic veterinarians is the International Association for Veterinary Homeopathy.\n\nThe use of homeopathy in veterinary medicine is controversial; the little existing research on the subject is not of a high enough scientific standard to provide reliable data on efficacy. Given that homeopathy's effects in humans appear to be mainly due to the placebo effect and the counseling aspects of the consultation, it is unlikely that homeopathic treatments would be effective in animals. Other studies have also found that giving animals placebos can play active roles in influencing pet owners to believe in the effectiveness of the treatment when none exists. The British Veterinary Association's position statement on alternative medicines says that it \"cannot endorse\" homeopathy, and the Australian Veterinary Association includes it on its list of \"ineffective therapies\". A 2016 review of peer-reviewed articles from 1981 to 2014 by scientists from the University of Kassel, Germany, concluded that there was insufficient evidence to support the use of homeopathy in livestock as a way to prevent or treat infectious diseases.\n\nThe UK's Department for Environment, Food and Rural Affairs (Defra) has adopted a robust position against use of \"alternative\" pet preparations including homeopathy.\n\nPopular in the late nineteenth century, electrohomeopathy has been described as \"utter idiocy\".\n\nElectrohomeopathy is somewhat associated with an Spagyric medicine in that the disease is usually multi-organic in cause or effect and calls for holistic treatment that is both complex and natural.\n\nThe Allahabad High Court in Kanpur handed down a decree in 2012 which stated that electrohomeopathy was an unrecognized system of medicine which was quackery.\n\nThe use of homeopathy as a preventive for serious infectious diseases is especially controversial, in the context of ill-founded public alarm over the safety of vaccines stoked by the anti-vaccination movement. Promotion of homeopathic alternatives to vaccines has been characterized as dangerous, inappropriate and irresponsible. In December 2014, Australian homeopathy supplier Homeopathy Plus! were found to have acted deceptively in promoting homeopathic alternatives to vaccines.\n\nThe low concentration of homeopathic preparations, which often lack even a single molecule of the diluted substance, has been the basis of questions about the effects of the preparations since the 19th century. Modern advocates of homeopathy have proposed a concept of \"water memory\", according to which water \"remembers\" the substances mixed in it, and transmits the effect of those substances when consumed. This concept is inconsistent with the current understanding of matter, and water memory has never been demonstrated to have any detectable effect, biological or otherwise. Pharmacological research has found instead that stronger effects of an active ingredient come from higher, not lower doses.\n\nJames Randi and the groups have highlighted the lack of active ingredients in most homeopathic products by taking large 'overdoses'. None of the hundreds of demonstrators in the UK, Australia, New Zealand, Canada and the US were injured and \"no one was cured of anything, either\".\n\nOutside of the alternative medicine community, scientists have long considered homeopathy a sham or a pseudoscience, and the mainstream medical community regards it as quackery. There is an overall absence of sound statistical evidence of therapeutic efficacy, which is consistent with the lack of any biologically plausible pharmacological agent or mechanism.\n\nAbstract concepts within theoretical physics have been invoked to suggest explanations of how or why preparations might work, including quantum entanglement, quantum nonlocality, the theory of relativity and chaos theory. Contrariwise, quantum superposition has been invoked to explain why homeopathy does \"not\" work in double-blind trials. However, the explanations are offered by nonspecialists within the field, and often include speculations that are incorrect in their application of the concepts and not supported by actual experiments. Several of the key concepts of homeopathy conflict with fundamental concepts of physics and chemistry. The use of quantum entanglement to explain homeopathy's purported effects is \"patent nonsense\", as entanglement is a delicate state that rarely lasts longer than a fraction of a second. While entanglement may result in certain aspects of individual subatomic particles acquiring linked quantum states, this does not mean the particles will mirror or duplicate each other, nor cause health-improving transformations.\n\nThe proposed mechanisms for homeopathy are precluded from having any effect by the laws of physics and physical chemistry. The extreme dilutions used in homeopathic preparations usually leave not one molecule of the original substance in the final product.\n\nA number of speculative mechanisms have been advanced to counter this, the most widely discussed being water memory, though this is now considered erroneous since short-range order in water only persists for about 1 picosecond. No evidence of stable clusters of water molecules was found when homeopathic preparations were studied using nuclear magnetic resonance, and many other physical experiments in homeopathy have been found to be of low methodological quality, which precludes any meaningful conclusion. Existence of a pharmacological effect in the absence of any true active ingredient is inconsistent with the law of mass action and the observed dose-response relationships characteristic of therapeutic drugs (whereas placebo effects are non-specific and unrelated to pharmacological activity).\n\nHomeopaths contend that their methods produce a therapeutically active preparation, selectively including only the intended substance, though critics note that any water will have been in contact with millions of different substances throughout its history, and homeopaths have not been able to account for a reason why only the selected homeopathic substance would be a special case in their process. For comparison, ISO 3696:1987 defines a standard for water used in laboratory analysis; this allows for a contaminant level of ten parts per billion, 4C in homeopathic notation. This water may not be kept in glass as contaminants will leach out into the water.\n\nPractitioners of homeopathy hold that higher dilutions―described as being of higher \"potency\"―produce stronger medicinal effects. This idea is also inconsistent with observed dose-response relationships, where effects are dependent on the concentration of the active ingredient in the body. This dose-response relationship has been confirmed in myriad experiments on organisms as diverse as nematodes, rats, and humans. Some homeopaths contend that the phenomenon of hormesis may support the idea of dilution increasing potency, but the dose-response relationship outside the zone of hormesis declines with dilution as normal, and nonlinear pharmacological effects do not provide any credible support for homeopathy.\n\nPhysicist Robert L. Park, former executive director of the American Physical Society, is quoted as saying:\n\n\"since the least amount of a substance in a solution is one molecule, a 30C solution would have to have at least one molecule of the original substance dissolved in a minimum of 1,000,000,000,000,000,000,000,000,000,000,<wbr>000,000,000,000,000,000,000,000,000,000 [or 10] molecules of water. This would require a container more than 30,000,000,000 times the size of the Earth.\"\nPark is also quoted as saying that, \"to expect to get even one molecule of the 'medicinal' substance allegedly present in 30X pills, it would be necessary to take some two billion of them, which would total about a thousand tons of lactose plus whatever impurities the lactose contained\".\n\nThe laws of chemistry state that there is a limit to the dilution that can be made without losing the original substance altogether. This limit, which is related to Avogadro's number, is roughly equal to homeopathic dilutions of 12C or 24X (1 part in 10).\n\nScientific tests run by both the BBC's \"Horizon\" and ABC's \"20/20\" programmes were unable to differentiate homeopathic dilutions from water, even when using tests suggested by homeopaths themselves.\n\nIn May 2018, the German skeptical organization GWUP issued an invitation to individuals and groups to respond to its challenge \"to identify homeopathic preparations in high potency and to give a detailed description on how this can be achieved reproducibly.\" The first participant to correctly identify selected homeopathic preparations under an agreed-upon protocol will receive €50,000.\n\nNo individual homeopathic preparation has been unambiguously shown by research to be different from placebo. The methodological quality of the primary research was generally low, with such problems as weaknesses in study design and reporting, small sample size, and selection bias. Since better quality trials have become available, the evidence for efficacy of homeopathy preparations has diminished; the highest-quality trials indicate that the preparations themselves exert no intrinsic effect. A review conducted in 2010 of all the pertinent studies of \"best evidence\" produced by the Cochrane Collaboration concluded that \"the most reliable evidence – that produced by Cochrane reviews – fails to demonstrate that homeopathic medicines have effects beyond placebo.\"\n\nGovernment-level reviews have been conducted in recent years by Switzerland (2005), the United Kingdom (2009), Australia (2015) and the European Academies' Science Advisory Council (2017).\n\nThe Swiss \"programme for the evaluation of complementary medicine\" (PEK) resulted in the peer-reviewed Shang publication (see \"Systematic reviews and meta-analyses of efficacy\") and a controversial competing analysis by homeopaths and advocates led by Gudrun Bornhöft and Peter Matthiessen, which has misleadingly been presented as a Swiss government report by homeopathy proponents, a claim that has been repudiated by the Swiss Federal Office of Public Health. The Swiss Government terminated reimbursement, though it was subsequently reinstated after a political campaign and referendum for a further six-year trial period.\n\nThe United Kingdom's House of Commons Science and Technology Committee sought written evidence and submissions from concerned parties and, following a review of all submissions, concluded that there was no compelling evidence of effect other than placebo and recommended that the Medicines and Healthcare products Regulatory Agency (MHRA) should not allow homeopathic product labels to make medical claims, that homeopathic products should no longer be licensed by the MHRA, as they are not medicines, and that further clinical trials of homeopathy could not be justified. They recommended that funding of homeopathic hospitals should not continue, and NHS doctors should not refer patients to homeopaths. The Secretary of State for Health deferred to local NHS on funding homeopathy, in the name of patient choice. By February 2011 only one-third of primary care trusts still funded homeopathy. By 2012, no British universities offered homeopathy courses. In July 2017, as part of a plan to save £200m a year by preventing the \"misuse of scarce\" funding, the NHS announced that it would no longer provide homeopathic medicines. A legal appeal by the British Homeopathic Association against the decision was rejected in June 2018.\n\nThe Australian National Health and Medical Research Council completed a comprehensive review of the effectiveness of homeopathic preparations in 2015, in which it concluded that \"there were no health conditions for which there was reliable evidence that homeopathy was effective. No good-quality, well-designed studies with enough participants for a meaningful result reported either that homeopathy caused greater health improvements than placebo, or caused health improvements equal to those of another treatment.\"\n\nOn September 20, 2017, the European Academies' Science Advisory Council (EASAC) published its official analysis and conclusion on the use of homeopathic products, finding a lack of evidence that homeopathic products are effective, and raising concerns about quality control.\n\nThe fact that individual randomized controlled trials have given positive results is not in contradiction with an overall lack of statistical evidence of efficacy. A small proportion of randomized controlled trials inevitably provide false-positive outcomes due to the play of chance: a \"statistically significant\" positive outcome is commonly adjudicated when the probability of it being due to chance rather than a real effect is no more than 5%―a level at which about 1 in 20 tests can be expected to show a positive result in the absence of any therapeutic effect. Furthermore, trials of low methodological quality (i.e. ones that have been inappropriately designed, conducted or reported) are prone to give misleading results. In a systematic review of the methodological quality of randomized trials in three branches of alternative medicine, Linde \"et al.\" highlighted major weaknesses in the homeopathy sector, including poor randomization. A separate 2001 systematic review that assessed the quality of clinical trials of homeopathy found that such trials were generally of lower quality than trials of conventional medicine.\n\nA related issue is publication bias: researchers are more likely to submit trials that report a positive finding for publication, and journals prefer to publish positive results. Publication bias has been particularly marked in alternative medicine journals, where few of the published articles (just 5% during the year 2000) tend to report null results. Regarding the way in which homeopathy is represented in the medical literature, a systematic review found signs of bias in the publications of clinical trials (towards negative representation in mainstream medical journals, and \"vice versa\" in alternative medicine journals), but not in reviews.\n\nPositive results are much more likely to be false if the prior probability of the claim under test is low.\n\nBoth meta-analyses, which statistically combine the results of several randomized controlled trials, and other systematic reviews of the literature are essential tools to summarize evidence of therapeutic efficacy. Early systematic reviews and meta-analyses of trials evaluating the efficacy of homeopathic preparations in comparison with placebo more often tended to generate positive results, but appeared unconvincing overall. In particular, reports of three large meta-analyses warned readers that firm conclusions could not be reached, largely due to methodological flaws in the primary studies and the difficulty in controlling for publication bias. The positive finding of one of the most prominent of the early meta-analyses, published in \"The Lancet\" in 1997 by Linde et al., was later reframed by the same research team, who wrote:\n\nThe evidence of bias [in the primary studies] weakens the findings of our original meta-analysis. Since we completed our literature search in 1995, a considerable number of new homeopathy trials have been published. The fact that a number of the new high-quality trials ... have negative results, and a recent update of our review for the most \"original\" subtype of homeopathy (classical or individualized homeopathy), seem to confirm the finding that more rigorous trials have less-promising results. It seems, therefore, likely that our meta-analysis at least overestimated the effects of homeopathic treatments.\n\nSubsequent work by John Ioannidis and others has shown that for treatments with no prior plausibility, the chances of a positive result being a false positive are much higher, and that any result not consistent with the null hypothesis should be assumed to be a false positive.\n\nA systematic review of the available systematic reviews confirmed in 2002 that higher-quality trials tended to have less positive results, and found no convincing evidence that any homeopathic preparation exerts clinical effects different from placebo.\n\nIn 2005, \"The Lancet\" medical journal published a meta-analysis of 110 placebo-controlled homeopathy trials and 110 matched medical trials based upon the Swiss government's Programme for Evaluating Complementary Medicine, or PEK. The study concluded that its findings were \"compatible with the notion that the clinical effects of homeopathy are placebo effects\". This was accompanied by an editorial pronouncing \"The end of homoeopathy\", which was denounced by the homeopath Peter Fisher.\n\nOther meta-analyses include homeopathic treatments to reduce cancer therapy side-effects following radiotherapy and chemotherapy, allergic rhinitis, attention-deficit hyperactivity disorder and childhood diarrhoea, adenoid vegetation, asthma, upper respiratory tract infection in children, insomnia, fibromyalgia, psychiatric conditions and Cochrane Library systematic reviews of homeopathic treatments for asthma, dementia, attention-deficit hyperactivity disorder, induction of labour, upper respiratory tract infections in children, and irritable bowel syndrome. Other reviews covered osteoarthritis, migraines, postoperative ecchymosis and edema, delayed-onset muscle soreness, preventing postpartum haemorrhage, or eczema and other dermatological conditions.\n\nA 2017 systematic review and meta-analysis found that the most reliable evidence did not support the effectiveness of non-individualized homeopathy. The authors noted that \"the quality of the body of evidence is low.\"\n\nThe results of these reviews are generally negative or only weakly positive, and reviewers consistently report the poor quality of trials. The finding of Linde \"et. al.\" that more rigorous studies produce less positive results is supported in several and contradicted by none.\n\nSome clinical trials have tested individualized homeopathy, and there have been reviews of this, specifically. A 1998 review found 32 trials that met their inclusion criteria, 19 of which were placebo-controlled and provided enough data for meta-analysis. These 19 studies showed a pooled odds ratio of 1.17 to 2.23 in favour of individualized homeopathy over the placebo, but no difference was seen when the analysis was restricted to the methodologically best trials. The authors concluded that \"the results of the available randomized trials suggest that individualized homeopathy has an effect over placebo. The evidence, however, is not convincing because of methodological shortcomings and inconsistencies.\" Jay Shelton, author of a book on homeopathy, has stated that the claim assumes without evidence that classical, individualized homeopathy works better than nonclassical variations. A 2014 systematic review and meta-analysis found that individualized homeopathic remedies may be slightly more effective than placebos, though the authors noted that their findings were based on low- or unclear-quality evidence. The same research team later reported that taking into account model validity did not significantly affect this conclusion.\n\nHealth organizations such as the UK's National Health Service, the American Medical Association, the FASEB, and the National Health and Medical Research Council of Australia, have issued statements of their conclusion that there is \"no good-quality evidence that homeopathy is effective as a treatment for any health condition\". In 2009, World Health Organization official Mario Raviglione criticized the use of homeopathy to treat tuberculosis; similarly, another WHO spokesperson argued there was no evidence homeopathy would be an effective treatment for diarrhoea.\n\nThe American College of Medical Toxicology and the American Academy of Clinical Toxicology recommend that no one use homeopathic treatment for disease or as a preventive health measure. These organizations report that no evidence exists that homeopathic treatment is effective, but that there is evidence that using these treatments produces harm and can bring indirect health risks by delaying conventional treatment.\n\nScience offers a variety of explanations for how homeopathy may appear to cure diseases or alleviate symptoms even though the preparations themselves are inert:\n\nWhile some articles have suggested that homeopathic solutions of high dilution can have statistically significant effects on organic processes including the growth of grain, histamine release by leukocytes, and enzyme reactions, such evidence is disputed since attempts to replicate them have failed. A 2007 systematic review of high-dilution experiments found that none of the experiments with positive results could be reproduced by all investigators.\n\nIn 1987, French immunologist Jacques Benveniste submitted a paper to the journal \"Nature\" while working at INSERM. The paper purported to have discovered that basophils, a type of white blood cell, released histamine when exposed to a homeopathic dilution of anti-immunoglobulin E antibody. The journal editors, sceptical of the results, requested that the study be replicated in a separate laboratory. Upon replication in four separate laboratories the study was published. Still sceptical of the findings, \"Nature\" assembled an independent investigative team to determine the accuracy of the research, consisting of \"Nature\" editor and physicist Sir John Maddox, American scientific fraud investigator and chemist Walter Stewart, and sceptic James Randi. After investigating the findings and methodology of the experiment, the team found that the experiments were \"statistically ill-controlled\", \"interpretation has been clouded by the exclusion of measurements in conflict with the claim\", and concluded, \"We believe that experimental data have been uncritically assessed and their imperfections inadequately reported.\" James Randi stated that he doubted that there had been any conscious fraud, but that the researchers had allowed \"wishful thinking\" to influence their interpretation of the data.\n\nIn 2001 and 2004, Madeleine Ennis published a number of studies that reported that homeopathic dilutions of histamine exerted an effect on the activity of basophils. In response to the first of these studies, \"Horizon\" aired a programme in which British scientists attempted to replicate Ennis' results; they were unable to do so.\n\nThe provision of homeopathic preparations has been described as unethical. Michael Baum, Professor Emeritus of Surgery and visiting Professor of Medical Humanities at University College London (UCL), has described homoeopathy as a \"cruel deception\".\n\nEdzard Ernst, the first \"Professor of Complementary Medicine\" in the United Kingdom and a former homeopathic practitioner, has expressed his concerns about pharmacists who violate their ethical code by failing to provide customers with \"necessary and relevant information\" about the true nature of the homeopathic products they advertise and sell:\n\nPatients who choose to use homeopathy rather than evidence-based medicine risk missing timely diagnosis and effective treatment of serious conditions such as cancer.\n\nIn 2013 the UK Advertising Standards Authority concluded that the Society of Homeopaths were targeting vulnerable ill people and discouraging the use of essential medical treatment while making misleading claims of efficacy for homeopathic products.\n\nIn 2015 the Federal Court of Australia imposed penalties on a homeopathic company, Homeopathy Plus! Pty Ltd and its director, for making false or misleading statements about the efficacy of the whooping cough vaccine and homeopathic remedies as an alternative to the whooping cough vaccine, in breach of the Australian Consumer Law.\n\nSome homeopathic preparations involve poisons such as Belladonna, arsenic, and poison ivy, which are highly diluted in the homeopathic preparation. In rare cases, the original ingredients are present at detectable levels. This may be due to improper preparation or intentional low dilution. Serious adverse effects such as seizures and death have been reported or associated with some homeopathic preparations.\n\nOn September 30, 2016 the FDA issued a safety alert to consumers warning against the use of homeopathic teething gels and tablets following reports of adverse events after their use. The agency recommended that parents discard these products and \"seek advice from their health care professional for safe alternatives\" to homeopathy for teething. The pharmacy CVS announced, also on September 30, that it was voluntarily withdrawing the products from sale and on October 11 Hyland's (the manufacturer) announced that it was discontinuing their teething medicine in the United States though the products remain on sale in Canada. On October 12, Buzzfeed reported that the regulator had \"examined more than 400 reports of seizures, fever and vomiting, as well as 10 deaths\" over a six-year period. The investigation (including analyses of the products) is still ongoing and the FDA does not know yet if the deaths and illnesses were caused by the products. However a previous FDA investigation in 2010, following adverse effects reported then, found that these same products were improperly diluted and contained \"unsafe levels of belladonna, also known as deadly nightshade\" and that the reports of serious adverse events in children using this product were \"consistent with belladonna toxicity\".\n\nInstances of arsenic poisoning have occurred after use of arsenic-containing homeopathic preparations. Zicam Cold remedy Nasal Gel, which contains 2X (1:100) zinc gluconate, reportedly caused a small percentage of users to lose their sense of smell; 340 cases were settled out of court in 2006 for . In 2009, the FDA advised consumers to stop using three discontinued cold remedy Zicam products because it could cause permanent damage to users' sense of smell. Zicam was launched without a New Drug Application (NDA) under a provision in the FDA's Compliance Policy Guide called \"Conditions under which homeopathic drugs may be marketed\" (CPG 7132.15), but the FDA warned Matrixx Initiatives, its manufacturer, via a Warning Letter that this policy does not apply when there is a health risk to consumers.\n\nA 2000 review by homeopaths reported that homeopathic preparations are \"unlikely to provoke severe adverse reactions\". In 2012, a systematic review evaluating evidence of homeopathy's possible adverse effects concluded that \"homeopathy has the potential to harm patients and consumers in both direct and indirect ways\". One of the reviewers, Edzard Ernst, supplemented the article on his blog, writing: \"I have said it often and I say it again: if used as an alternative to an effective cure, even the most 'harmless' treatment can become life-threatening.\" A 2016 systematic review and meta-analysis found that, in homeopathic clinical trials, adverse effects were reported among the patients who received homeopathy about as often as they were reported among patients who received placebo or conventional medicine.\n\nThe lack of convincing scientific evidence supporting its efficacy and its use of preparations without active ingredients have led to characterizations as pseudoscience and quackery, or, in the words of a 1998 medical review, \"placebo therapy at best and quackery at worst\". The Russian Academy of Sciences considers homeopathy a \"dangerous 'pseudoscience' that does not work\", and \"urges people to treat homeopathy 'on a par with magic. The Chief Medical Officer for England, Dame Sally Davies, has stated that homeopathic preparations are \"rubbish\" and do not serve as anything more than placebos. Jack Killen, acting deputy director of the National Center for Complementary and Alternative Medicine, says homeopathy \"goes beyond current understanding of chemistry and physics\". He adds: \"There is, to my knowledge, no condition for which homeopathy has been proven to be an effective treatment.\" Ben Goldacre says that homeopaths who misrepresent scientific evidence to a scientifically illiterate public, have \"... walled themselves off from academic medicine, and critique has been all too often met with avoidance rather than argument\". Homeopaths often prefer to ignore meta-analyses in favour of cherry picked positive results, such as by promoting a particular observational study (one which Goldacre describes as \"little more than a customer-satisfaction survey\") as if it were more informative than a series of randomized controlled trials.\n\nReferring specifically to homeopathy, the British House of Commons Science and Technology Committee has stated:\n\nThe National Center for Complementary and Alternative Medicine of the United States' National Institutes of Health states:\n\nBen Goldacre noted that in the early days of homeopathy, when medicine was dogmatic and frequently worse than doing nothing, homeopathy at least failed to make matters worse:\n\nOn clinical grounds, patients who choose to use homeopathy in preference to normal medicine risk missing timely diagnosis and effective treatment, thereby worsening the outcomes of serious conditions. Critics of homeopathy have cited individual cases of patients of homeopathy failing to receive proper treatment for diseases that could have been easily diagnosed and managed with conventional medicine and who have died as a result, and the \"marketing practice\" of criticizing and downplaying the effectiveness of mainstream medicine. Homeopaths claim that use of conventional medicines will \"push the disease deeper\" and cause more serious conditions, a process referred to as \"suppression\". Some homeopaths (particularly those who are non-physicians) advise their patients against immunization. Some homeopaths suggest that vaccines be replaced with homeopathic \"nosodes\", created from biological materials such as pus, diseased tissue, bacilli from sputum or (in the case of \"bowel nosodes\") faeces. While Hahnemann was opposed to such preparations, modern homeopaths often use them although there is no evidence to indicate they have any beneficial effects. Cases of homeopaths advising against the use of anti-malarial drugs have been identified. This puts visitors to the tropics who take this advice in severe danger, since homeopathic preparations are completely ineffective against the malaria parasite. Also, in one case in 2004, a homeopath instructed one of her patients to stop taking conventional medication for a heart condition, advising her on June 22, 2004 to \"Stop ALL medications including homeopathic\", advising her on or around August 20 that she no longer needed to take her heart medication, and adding on August 23, \"She just cannot take ANY drugs – I have suggested some homeopathic remedies ... I feel confident that if she follows the advice she will regain her health.\" The patient was admitted to hospital the next day, and died eight days later, the final diagnosis being \"acute heart failure due to treatment discontinuation\".\n\nIn 1978, Anthony Campbell, then a consultant physician at the Royal London Homeopathic Hospital, criticized statements by George Vithoulkas claiming that syphilis, when treated with antibiotics, would develop into secondary and tertiary syphilis with involvement of the central nervous system, saying that \"The unfortunate layman might well be misled by Vithoulkas' rhetoric into refusing orthodox treatment\".\nVithoulkas' claims echo the idea that treating a disease with external medication used to treat the symptoms would only drive it deeper into the body and conflict with scientific studies, which indicate that penicillin treatment produces a complete cure of syphilis in more than 90% of cases.\n\nA 2006 review by W. Steven Pray of the College of Pharmacy at Southwestern Oklahoma State University recommends that pharmacy colleges include a required course in unproven medications and therapies, that ethical dilemmas inherent in recommending products lacking proven safety and efficacy data be discussed, and that students should be taught where unproven systems such as homeopathy depart from evidence-based medicine.\n\nIn an article entitled \"Should We Maintain an Open Mind about Homeopathy?\" published in the \"American Journal of Medicine\", Michael Baum and Edzard Ernstwriting to other physicianswrote that \"Homeopathy is among the worst examples of faith-based medicine... These axioms [of homeopathy] are not only out of line with scientific facts but also directly opposed to them. If homeopathy is correct, much of physics, chemistry, and pharmacology must be incorrect...\".\n\nIn 2013, Mark Walport, the UK Government Chief Scientific Adviser and head of the Government Office for Science, had this to say: \"My view scientifically is absolutely clear: homoeopathy is nonsense, it is non-science. My advice to ministers is clear: that there is no science in homoeopathy. The most it can have is a placebo effect – it is then a political decision whether they spend money on it or not.\" His predecessor, John Beddington, referring to his views on homeopathy being \"fundamentally ignored\" by the Government, said: \"The only one [view being ignored] I could think of was homoeopathy, which is mad. It has no underpinning of scientific basis. In fact, all the science points to the fact that it is not at all sensible. The clear evidence is saying this is wrong, but homoeopathy is still used on the NHS.\"\n\nHomeopathy is fairly common in some countries while being uncommon in others; is highly regulated in some countries and mostly unregulated in others. It is practised worldwide and professional qualifications and licences are needed in most countries. In some countries, there are no specific legal regulations concerning the use of homeopathy, while in others, licences or degrees in conventional medicine from accredited universities are required. In Germany, to become a homeopathic physician, one must attend a three-year training programme, while France, Austria and Denmark mandate licences to diagnose any illness or dispense of any product whose purpose is to treat any illness.\n\nSome homeopathic treatment is covered by the public health service of several European countries, including France, Scotland, Luxembourg and England (though the latter will cease in February 2019). In other countries, such as Belgium, homeopathy is not covered. In Austria, the public health service requires scientific proof of effectiveness in order to reimburse medical treatments and homeopathy is listed as not reimbursable, but exceptions can be made; private health insurance policies sometimes include homeopathic treatment. The Swiss government, after a 5-year trial, withdrew coverage of homeopathy and four other complementary treatments in 2005, stating that they did not meet efficacy and cost-effectiveness criteria, but following a referendum in 2009 the five therapies have been reinstated for a further 6-year trial period from 2012.\nThe Indian government recognizes homeopathy as one of its national systems of medicine; it has established AYUSH or the Department of Ayurveda, Yoga and Naturopathy, Unani, Siddha and Homoeopathy under the Ministry of Health & Family Welfare. The south Indian state of Kerala also has a cabinet-level AYUSH department. The Central Council of Homoeopathy was established in 1973 to monitor higher education in homeopathy, and National Institute of Homoeopathy in 1975. A minimum of a recognized diploma in homeopathy and registration on a state register or the Central Register of Homoeopathy is required to practise homeopathy in India.\n\nOn September 28, 2016 the UK's Committee of Advertising Practice (CAP) Compliance team wrote to homeopaths in the UK to \"remind them of the rules that govern what they can and can't say in their marketing materials\". The letter highlights that \"homeopaths may not currently make either direct or implied claims to treat medical conditions\" and asks them to review their marketing communications \"including websites and social media pages\" to ensure compliance by November 3, 2016. The letter also includes information on sanctions in the event of non-compliance including, ultimately, \"referral by the ASA to Trading Standards under the Consumer Protection from Unfair Trading Regulations 2008\".\n\nIn February 2017, Russian Academy of Sciences declared homeopathy to be \"dangerous pseudoscience\" and \"on a par with magic\".\n\nIn the April 1997 edition of FDA Consumer, William T. Jarvis, the President of the National Council Against Health Fraud, said \"Homeopathy is a fraud perpetrated on the public with the government's blessing, thanks to the abuse of political power of Sen. Royal S. Copeland [chief sponsor of the 1938 Food, Drug, and Cosmetic Act].\"\n\nMock \"overdosing\" on homeopathic preparations by individuals or groups in \"mass suicides\" have become more popular since James Randi began taking entire bottles of homeopathic sleeping pills before giving lectures. In 2010 The Merseyside Skeptics Society from the United Kingdom launched the , encouraging groups to publicly overdose as groups. In 2011 the 10:23 campaign expanded and saw sixty-nine groups participate; fifty-four submitted videos. In April 2012, at the Berkeley SkeptiCal conference, over 100 people participated in a mass overdose, taking \"coffea cruda\", which is supposed to treat sleeplessness.\n\nIn 2011, the non-profit, educational organizations Center for Inquiry (CFI) and the associated Committee for Skeptical Inquiry (CSI) have petitioned the U.S. Food and Drug Administration (FDA) to initiate \"rulemaking that would require all over-the-counter homeopathic drugs to meet the same standards of effectiveness as non-homeopathic drugs\" and \"to place warning labels on homeopathic drugs until such time as they are shown to be effective\". In a separate petition, CFI and CSI request FDA to issue warning letters to Boiron, maker of Oscillococcinum, regarding their marketing tactic and criticize Boiron for misleading labelling and advertising of Oscillococcinum. In 2015, CFI filed comments urging the Federal Trade Commission to end the false advertising practice of homeopathy. On November 15, 2016, FTC declared that homeopathic products cannot include claims of effectiveness without \"competent and reliable scientific evidence\". If no such evidence exists, they must state this fact clearly on their labeling, and state that the product's claims are based only on 18th-century theories that have been discarded by modern science. Failure to do so will be considered a violation of the FTC Act.\nCFI in Canada is calling for persons that feel they were harmed by homeopathic products to contact them.\n\nIn July 2018 the Center for Inquiry filed a lawsuit against CVS for consumer fraud over its sale of homeopathic medicines. According to Nicholas Little, CFI's Vice President and General Counsel:\n\nThe filing in part contends that apart from being a waste of money, choosing homeopathic treatments to the exclusion of evidence-based medicines can result in worsened or prolonged symptoms, and in some cases, even death. It also claimed that CVS was selling homeopathic products on an easier-to-obtain basis than standard medication; for example on the CVS website Oscillococcinum could be purchased as a \"Flu remedy\", whereas the Tylenol brand could only be purchased by visiting a physical pharmacy.\n\nIn August 2011, a class action lawsuit was filed against Boiron on behalf of \"all California residents who purchased Oscillo at any time within the past four years\". The lawsuit charged that it \"is nothing more than a sugar pill\", \"despite falsely advertising that it contains an active ingredient known to treat flu symptoms\". In March 2012, Boiron agreed to spend up to $12 million to settle the claims of falsely advertising the benefits of its homeopathic preparations.\n\nIn July 2012, CBC News reporter Erica Johnson for \"Marketplace\" conducted an investigation on the homeopathy industry in Canada; her findings were that it is \"based on flawed science and some loopy thinking\". Center for Inquiry (CFI) Vancouver skeptics participated in a mass overdose outside an emergency room in Vancouver, B.C., taking entire bottles of \"medications\" that should have made them sleepy, nauseous or dead; after 45 minutes of observation no ill effects were felt. Johnson asked homeopaths and company representatives about cures for cancer and vaccine claims. All reported positive results but none could offer any science backing up their statements, only that \"it works\". Johnson was unable to find any evidence that homeopathic preparations contain any active ingredient. Analysis performed at the University of Toronto's chemistry department found that the active ingredient is so small \"it is equivalent to 5 billion times less than the amount of aspirin ... in a single pellet\". Belladonna and ipecac \"would be indistinguishable from each other in a blind test\".\n\nHomeopathic services offered at Bristol Homeopathic Hospital in the UK ceased in October 2015, partly in response to increased public awareness as a result of the and a campaign led by the Good Thinking Society. University Hospitals Bristol confirmed that it would cease to offer homeopathic therapies from October 2015, at which point homeopathic therapies would no longer be included in the contract. Homeopathic services in the Bristol area were relocated to \"a new independent social enterprise\" at which Bristol Clinical Commissioning Group revealed \"there are currently no (NHS) contracts for homeopathy in place.\" Following a threat of legal action by the Good Thinking Society campaign group, the British government has stated that the Department of Health will hold a consultation in 2016 regarding whether homeopathic treatments should be added to the NHS treatments blacklist (officially, Schedule 1 of the National Health Service (General Medical Services Contracts) (Prescription of Drugs etc.) Regulations 2004), that specifies a blacklist of medicines not to be prescribed under the NHS.\n\nIn March 2016, the University of Barcelona cancelled its master's degree in Homeopathy citing \"lack of scientific basis\", after advice from the Spanish Ministry of Health stated that \"Homeopathy has not definitely proved its efficacy under any indication or concrete clinical situation\". Shortly afterwards, in April 2016, the University of Valencia announced the elimination of its Masters in Homeopathy for 2017.\n\nIn June 2016, blogger and sceptic Jithin Mohandas launched a petition through Change.org asking the government of Kerala, India, to stop admitting students to homeopathy medical colleges. Mohandas said that government approval of these colleges makes them appear legitimate, leading thousands of talented students to join them and end up with invalid degrees. The petition asks that homeopathy colleges be converted to regular medical colleges and that people with homeopathy degrees be provided with training in scientific medicine.\n\nIn Germany, physician and critic of alternative medicine Irmgard Oepen was a relentless critic of homeopathy.\n\nOn April 20–21, 2015, the FDA held a hearing on homeopathic product regulation. Invitees representing the scientific and medical community, and various pro-homeopathy stakeholders, gave testimonials on homeopathic products and the regulatory role played by the FDA.\nMichael de Dora, a representative from the Center for Inquiry (CFI), on behalf of the organization and dozens of doctors and scientists associated with CFI and the Committee for Skeptical Inquiry (CSI) gave a testimonial which summarized the basis of the organization's objection to homeopathic products, the harm that is done to the general public and proposed regulatory actions:\n\nThe CFI testimonial stated that the principle of homeopathy is at complete odds with the basic principles of modern biology, chemistry and physics and that decades of scientific examination of homeopathic products shows that there is no evidence that it is effective in treating illnesses other than acting as a placebo. Further, it noted a 2012 report by the American Association of Poison Control Centers which listed 10,311 reported cases of poison exposure related to homeopathic agents, among which 8,788 cases were attributed to young children five years of age or younger, as well as examples of harm – including deaths – caused to patients who relied on homeopathics instead of proven medical treatment.\n\nThe CFI urged the FDA to announce and implement strict guidelines that \"require all homeopathic products meet the same standards as non-homeopathic drugs\", arguing that the consumers can only have true freedom of choice (an often used argument from the homeopathy proponents) if they are fully informed of the choices. CFI proposed that the FDA take these three steps:\n\nIn December 2017, the FDA announced it would strengthen regulation of homeopathic products focusing on \"situations where homeopathic treatments are being marketed for serious diseases or conditions but have not been shown to offer clinical benefits\" and where \"products labeled as homeopathic contain potentially harmful ingredients or do not meet current good manufacturing practices.\"\n\nIn March 2015, the National Health and Medical Research Council of Australia issued the following conclusions and recommendations:\n\nIn November 2016, The United States FTC issued an \"Enforcement Policy Statement Regarding Marketing Claims for Over-the-Counter Homeopathic Drugs\" which specified that the FTC will hold efficacy and safety claims for OTC homeopathic drugs to the same standard as other products making similar claims. A November 15, 2016, FTC press release summarized the policy as follows:\n\nIn conjunction with the 2016 FTC Enforcement Policy Statement, the FTC also released its \"Homeopathic Medicine & Advertising Workshop Report\", which summarizes the panel presentations and related public comments in addition to describing consumer research commissioned by the FTC. The report concluded:\n\n\n"}
{"id": "14231", "url": "https://en.wikipedia.org/wiki?curid=14231", "title": "Hairpin", "text": "Hairpin\n\nA hair pin or hairpin is a long device used to hold a person's hair in place. It may be used simply to secure long hair out of the way for convenience or as part of an elaborate hairstyle or coiffure. The earliest evidence for dressing the hair may be seen in carved \"venus figurines\" such as the Venus of Brassempouy and the Venus of Willendorf. The creation of different hairstyles, especially among women, seems to be common to all cultures and all periods and many past, and current, societies use hairpins.\n\nHairpins made of metal, ivory, bronze, carved wood, etc. were used in ancient Assyria and Egypt for securing decorated hairstyles. Such hairpins suggest, as graves show, that many were luxury objects among the Egyptians and later the Greeks, Etruscans, and Romans. Major success came in 1901 with the invention of the spiral hairpin by New Zealand inventor Ernest Godward. This was a predecessor of the hair clip.\n\nThe hairpin may be decorative and encrusted with jewels and ornaments, or it may be utiliarian, and designed to be almost invisible while holding a hairstyle in place.\n\nSome hairpins are a single straight pin, but modern versions are more likely to be constructed from different lengths of wire that are bent in half with a u-shaped end and a few kinks along the two opposite portions. The finished pin may vary from two to six inches in final length. The length of the wires enables placement in several styles of hairdos to hold the style in place. The kinks enable retaining the pin during normal movements.\n\nA hairpin patent was issued to Kelly Chamandy in 1925.\n\nHairpins (generally known as ; ) are an important symbol in Chinese culture. In ancient China, hairpins were worn by all genders, and they were essential items for everyday hairstyling, mainly for securing and decorating a hair bun. Furthermore, hairpins worn by women could also represent their social status.\n\nIn Han Chinese culture, when young girls reached the age of fifteen, they were allowed to take part in a rite of passage known as \"\" (), or “hairpin initiation” . This ceremony marks the coming of age of young women. Particularly, before the age of fifteen, girls did not use hairpins as they wore their hair in braids, and they were considered as children. When they turned fifteen, they could be considered as young women after the ceremony, and they started to style their hair as buns secured and embellished by hairpins. This practice indicated these young women may now enter into marriage. However, if a young woman hadn't been consented to marriage before age twenty, or she hadn't yet participated in a coming of age ceremony, she must attend a ceremony when she turned twenty.\n\nIn comparison with “”, the male equivalent known as “guan li” () or “hat initiation”, usually took place five years later, at the age of twenty. In the 21st century Hanfu Movement, an attempt to revive the traditional Han Chinese coming-of-age ceremonies has been made, and the ideal age to attend the ceremony is twenty years old for all genders.\n\nWhile hairpins can symbolize the transition from childhood to adulthood, they were closely connected to the concept of marriage as well. At the time of an engagement, the fiancée may take a hairpin from her hair and give it to her fiancé as a pledge: this can be seen as a reversal of the Western tradition, in which the future groom presents an engagement ring to his betrothed. After the wedding ceremony, the husband should put the hairpin back into his spouse’s hair.\n\nHair has always carried many psychological, philosophical, romantic, and cultural meanings in Chinese culture. In Han culture, people call the union between two people “” (), literally “tying hair”. During the wedding ceremony, some Chinese couples exchange a lock of hair as a pledge, while others break a hairpin into two parts, and then, each of the betrothed take one part with them for keeping. If this couple were ever to get separated in the future, when they reunite, they can piece the two halves together, and the completed hairpin would serve as a proof of their identities as well as a symbol of their reunion. In addition, a married heterosexual couple is sometimes referred to as “” (), an idiom which implies the relationship between the pair is very intimate and happy, just like how their hair has been tied together.\n\n"}
{"id": "14233", "url": "https://en.wikipedia.org/wiki?curid=14233", "title": "Hate speech", "text": "Hate speech\n\nHate speech is speech that attacks a person or group on the basis of attributes such as race, religion, ethnic origin, national origin, sex, disability, sexual orientation, or gender identity. The laws of some countries describe hate speech as speech, gestures, conduct, writing, or displays that incite violence or prejudicial actions against a protected group or individuals on the basis of their membership in the group, or disparages or intimidates a protected group, or individuals on the basis of their membership in the group. The law may identify a protected group based on certain characteristics. In some countries, hate speech is not a legal term. Additionally in some countries, including the United States, hate speech is constitutionally protected.\n\nIn some countries, a victim of hate speech may seek redress under civil law, criminal law, or both. A website that contains hate speech (online hate speech) may be called a \"hate site\". Many of these sites contain Internet forums and news briefs that emphasize a particular viewpoint.\n\nThere has been much debate over freedom of speech, hate speech and hate speech legislation.\n\nWhile hate speech could be countered under obscenity law (on par with sexual obscenity, for example), as distinct from freedom of speech laws and censorship, little has been done to effectively pursue that direction of justice. Nonetheless, in terms of the adverse health effects hate speech is a matter that concerns Public Health for hate—as a social disease—has the characteristics of a contagious disease where the medical model is used. Hate speech affects the first victim who is the perpetrator and then the second victim upon whom the perpetrator imposes his or her own self hate (Provost, 2013). Habitual hate speech is a form of verbal menacing of which there are two types: actual or vrais menacing and posturing or faux menacing and gesture. \"Vrais\" menacing constitutes intent to enact not just psychological harm but also bodily, psychological, metaphysical, spiritual and social harm. \"Faux\" menacing enacts all but bodily attacks to control and intimidate, being a form posturing and verbal gesture, as in the world of non-sentient animals, and is tolerated—even valorized—in some societies as \"honour crimes\" not so much against the primary victim who suffers the bodily, psychological, metaphysical, spiritual and social harm and attack but in actuality against a relative or member of the victim's family, organization, or community (Provost, 2017). Computer programming software—new machine learning models—are now used to analyze speech and text for evidence of hate speech as overt and covert violence, including cyber-bullying. For example, the Hate Speech Detection Library for Python. The main challenge with detecting hate whether in speech or in text depends on distinguishing profane speech from hate speech (Malmasi and Zampier, 2017). There are more incidents of misogyny (hate of girls and women) which masquerades as pornography, prostitution and trafficking, for example, while incidents of misandry are rare (Dana Daniels, 2016).\n\nThe International Covenant on Civil and Political Rights (ICCPR) states that \"any advocacy of national, racial or religious hatred that constitutes incitement to discrimination, hostility or violence shall be prohibited by law\". The Convention on the Elimination of All Forms of Racial Discrimination (ICERD) prohibits all incitement of racism. Concerning the debate over how freedom of speech applies to the Internet, conferences concerning such sites have been sponsored by the United Nations High Commissioner for Refugees.\n\nThe global capacity of the internet makes it extremely difficult to set limits or boundaries to cyberspace. Additionally, the United States' strong commitment to the First Amendment makes it impossible for worldwide internet policies to be put in place. Seeking other options both legally and technologically (such as monitoring, IPS user agreements, user end software and hotlines) will at least minimize the harm done due to hate speech.\n\nLaws against hate speech can be divided into two types: those intended to preserve public order and those intended to protect human dignity. Those designed to protect public order require a higher threshold be violated, so they are not specifically enforced frequently. For example, in Northern Ireland, as of 1992 only one person was prosecuted for violating the regulation in twenty-one years. Those meant to protect human dignity have a much lower threshold for violation, so those in Canada, Denmark, France, Germany and the Netherlands tend to be more frequently enforced.\n\nAustralia's hate speech laws vary by jurisdiction, and seek especially to prevent victimisation on account of race.\n\nThe Belgian Anti-Racism Law, in full, the \"Law of 30 July 1981 on the Punishment of Certain Acts inspired by Racism or Xenophobia\", is a law against hate speech and discrimination that the Federal Parliament of Belgium passed in 1981. It made certain acts motivated by racism or xenophobia illegal. It is also known as the \"Moureaux Law\".\n\nThe Belgian Holocaust denial law, passed on 23 March 1995, bans public Holocaust denial. Specifically, the law makes it illegal to publicly \"deny, play down, justify or approve of the genocide committed by the Nazi German regime during the Second World War.\" Prosecution is led by the Belgian Centre for Equal Opportunities. The offense is punishable by imprisonment of up to one year and fines of up to €2,500.\n\nIn Brazil, according to the 1988 Brazilian Constitution, racism is an \"Offense with no statute of limitations and no right to bail for the defendant.\"\n\nIn Canada, advocating genocide against any \"identifiable group\" is an indictable offence under the \"Criminal Code\" and it carries a maximum sentence of five years' imprisonment. There is no minimum sentence.\n\nPublicly inciting hatred against any identifiable group is also an offence. It can be prosecuted either as an indictable offence with a maximum sentence of two years' imprisonment, or as a summary conviction offence with a maximum sentence of six months' imprisonment. There are no minimum sentences in either case. The offence of publicly inciting hatred makes exceptions for cases of statements of truth, and subjects of public debate and religious doctrine. The landmark judicial decision on the constitutionality of this law was \"R v Keegstra\" (1990).\n\nAn \"identifiable group\" is defined for both offences as \"any section of the public distinguished by colour, race, religion, national or ethnic origin, age, sex, sexual orientation, gender identity or expression or mental or physical disability\".\n\nArticle 31 of the \"Ley sobre Libertades de Opinión e Información y Ejercicio del Periodismo\" (statute on freedom of opinion and information and the performance of journalism), punishes with a large fine those who “through any means of social communication makes publications or transmissions intended to promote hatred or hostility towards persons or a group of persons due to their race, sex, religion or nationality\". This law has been applied to expressions transmitted via the internet. There is also a rule increasing the penalties for crimes motivated by discriminatory hatred.\n\nThe Croatian Constitution guarantees freedom of speech, but the Croatian penal code prohibits discrimination and punishes anyone \"who based on differences of race, religion, language, political or other belief, wealth, birth, education, social status or other properties, gender, skin color, nationality or ethnicity violates basic human rights and freedoms recognized by the international community.\"\n\nDenmark prohibits hate speech, and defines it as publicly making statements by which a group is threatened ('), insulted (') or degraded (\"\") due to race, skin colour, national or ethnic origin, faith or sexual orientation.\n\nThe Council of Europe sponsored \"No Hate Speech\" movement actively raises awareness about hate speech, in order to help combat the problem. While Article 10 of the European Convention on Human Rights does not prohibit criminal laws against revisionism such as denial or minimization of genocides or crimes against humanity, as interpreted by the European Court of Human Rights (ECtHR), the Committee of Ministers of the Council of Europe went further and recommended in 1997 that member governments \"take appropriate steps to combat hate speech\" under its Recommendation R (97) 20. The ECtHR does not offer an accepted definition for \"hate speech\" but instead offers only parameters by which prosecutors can decide if the \"hate speech\" is entitled to the protection of freedom of speech.\n\nA growing awareness of this topic has resulted from educational programs in schools, which has enhanced reporting of hate speech incidences. The Council of Europe also created the European Commission against Racism and Intolerance, which has produced country reports and several general policy recommendations, for instance against anti-Semitism and intolerance against Muslims.\n\nThere has been considerable debate over the definition of \"hate speech\" (\"vihapuhe\") in the Finnish language.\n\nIf \"hate speech\" is taken to mean ethnic agitation, it is prohibited in Finland and defined in the section 11 of the penal code, \"War crimes and crimes against humanity\", as published information or as an opinion or other statement that threatens or insults a group because of race, nationality, ethnicity, religion or conviction, sexual orientation, disability, or any comparable trait. Ethnic agitation is punishable with a fine or up to 2 years in prison, or 4 months to 4 years if aggravated (such as incitement to genocide).\n\nCritics claim that, in political contexts, labeling certain opinions and statements \"hate speech\" can be used to silence unfavorable or critical opinions and suppress debate. Certain politicians, including Member of Parliament and the leader of the Finns Party Jussi Halla-aho, consider the term \"hate speech\" problematic because of the disagreement over its definition.\n\nFrance's penal code and press laws prohibit public and private communication that is defamatory or insulting, or that incites discrimination, hatred, or violence against a person or group on account of place of origin, ethnicity or lack thereof, nationality, race, specific religion, sex, sexual orientation, or handicap. The law prohibits declarations that justify or deny crimes against humanity—for example, the Holocaust (Gayssot Act).\n\nIn Germany, \"Volksverhetzung\" (\"incitement to hatred\") is a punishable offense under Section 130 of the \"Strafgesetzbuch\" (Germany's criminal code) and can lead to up to five years' imprisonment. Section 130 makes it a crime to publicly incite hatred against parts of the population or to call for violent or arbitrary measures against them or to insult, maliciously slur or defame them in a manner violating their (constitutionally protected) human dignity. Thus for instance it is illegal to publicly call certain ethnic groups \"maggots\" or \"freeloaders\". \"Volksverhetzung\" is punishable in Germany even if committed abroad and even if committed by non-German citizens, if only the incitement of hatred takes effect within German territory, e.g., the seditious sentiment was expressed in German writing or speech and made accessible in Germany (German criminal code's Principle of Ubiquity, Section 9 §1 Alt. 3 and 4 of the Strafgesetzbuch).\n\nOn June 30, 2017, Germany approved a bill criminalizing hate speech on social media sites. Among criminalizing hate speech, the law states that social networking sites may be fined up to €50 million (US$56 million) if they persistently fail to remove illegal content within a week, including defamatory \"fake news\".\n\nIn Iceland, the hate speech law is not confined to inciting hatred, as one can see from Article 233 a. in the Icelandic Penal Code, but includes simply expressing such hatred publicly:\n\nIn this context \"assault\" does not refer to physical violence but only to verbal assault.\n\nFreedom of speech and expression is protected by article 19 (1) of the constitution of India, but under article 19(2) \"reasonable restrictions\" can be imposed on freedom of speech and expression in the interest of \"the sovereignty and integrity of India, the security of the State, friendly relations with foreign States, public order, decency or morality, or in relation to contempt of court, defamation or incitement to an offence\".\n\nIndonesia has been a signatory to the International Covenant on Civil and Political Rights since 2006, but has not promulgated comprehensive legislation against hate-speech crimes. Calls for a comprehensive anti-hate speech law and associated educational program have followed statements by a leader of a hard-line Islamic organization that Balinese Hindus were mustering forces to protect the \"lascivious Miss World pageant\" in “a war against Islam\" and that \"those who fight on the path of Allah are promised heaven\". The statements are said to be an example of similar messages intolerance being preached throughout the country by radical clerics.\n\nThe National Police ordered all of their personnel to anticipate any potential conflicts in society caused by hate speech. The order is stipulated in the circular signed by the National Police chief General Badrodin Haiti on Oct. 8, 2015.\n\nThe Constitution of Ireland guarantees Irish citizens the right \"to express freely their convictions and opinions\"; however, this right is \"subject to public order and morality\", mass media \"shall not be used to undermine public order or morality or the authority of the State\", and \"publication or utterance of blasphemous, seditious, or indecent matter is an offence\". The Prohibition of Incitement to Hatred Act 1989 made it an offence to make, distribute, or broadcast \"threatening, abusive or insulting\" words, images, or sounds with intent or likelihood to \"stir up hatred\", where \"hatred\" is \"against a group of persons in the State or elsewhere on account of their race, colour, nationality, religion, ethnic or national origins, membership of the travelling community or sexual orientation\". The first conviction was in 2000, of a bus driver who told a Gambian passenger \"You should go back to where you came from\". Frustration at the low number of prosecutions (18 by 2011) was attributed to a misconception that the law addressed hate crimes more generally as opposed to incitement in particular. In 2013 the Constitutional Convention considered the constitutional prohibition of blasphemy, and recommended replacing it with a ban on incitement to religious hatred. This was endorsed by the Oireachtas, and in 2017 the Fine Gael-led government planned a referendum for October 2018.\n\nJapanese law covers threats and slander, but it \"does not apply to hate speech against general groups of people\". Japan became a member of the United Nations International Convention on the Elimination of All Forms of Racial Discrimination in 1995. Article 4 of the convention sets forth provisions calling for the criminalization of hate speech. But the Japanese government has suspended the provisions, saying actions to spread or promote the idea of racial discrimination have not been taken in Japan to such an extent that legal action is necessary. The Foreign Ministry says that this assessment remains unchanged.\n\nIn May 2013, the United Nations Committee on Economic, Social and Cultural Rights (CESCR) warned the Japanese government that it needs to take measures to curb hate speech against so-called comfort women. The committee's recommendation called for the Japanese government to better educate Japanese society on the plight of women who were forced into sexual slavery to prevent stigmatization, and to take necessary measures to repair the lasting effects of exploitation, including addressing their right to compensation.\n\nIn 2013, following demonstrations, parades, and comments posted on the Internet threatening violence against foreign residents of Japan, especially Koreans, there are concerns that hate speech is a growing problem in Japan. Prime Minister Shinzō Abe and Justice Minister Sadakazu Tanigaki have expressed concerns about the increase in hate speech, saying that it \"goes completely against the nation's dignity\", but so far have stopped short of proposing any legal action against protesters.\n\nOn 22 September 2013 around 2,000 people participated in the \"March on Tokyo for Freedom\" campaigning against recent hate speech marches. Participants called on the Japanese government to \"sincerely adhere\" to the International Convention on the Elimination of All Forms of Racial Discrimination. Sexual minorities and the disabled also participated in the march.\n\nOn 25 September 2013 a new organization, \"An international network overcoming hate speech and racism\" (Norikoenet), that is opposed to hate speech against ethnic Koreans and other minorities in Japan was launched.\n\nOn 7 October 2013, in a rare ruling on racial discrimination against ethnic Koreans, a Japanese court ordered an anti-Korean group, Zaitokukai, to stop \"hate speech\" protests against a Korean school in Kyoto and pay the school 12.26 million yen ($126,400 U.S.) in compensation for protests that took place in 2009 and 2010.\n\nA United Nations panel urged Japan to ban hate speech.\n\nIn May 2016 Japan passed a law dealing with hate speech. However, it does not ban hate speech and sets no penalty for committing it.\n\nSeveral Jordanian laws seek to prevent the publication or dissemination of material that could provoke strife or hatred:\n\nThe Maltese criminal code through Articles 82A-82D prohibits in substance hate speech comprehensively as follows:\n\nThe Dutch penal code prohibits both insulting a group (article 137c) and inciting hatred, discrimination or violence (article 137d). The definition of the offences as outlined in the penal code is as follows:\n\nIn January 2009, a court in Amsterdam ordered the prosecution of Geert Wilders, a Dutch Member of Parliament, for breaching articles 137c and 137d. On 23 June 2011, Wilders was acquitted of all charges. In 2016, in a separate case, Wilders was found guilty of both insulting a group and inciting discrimination for promising an audience that he would deliver on their demand for \"fewer Moroccans.\"\n\nNew Zealand prohibits hate speech under the Human Rights Act 1993. Section 61 (Racial Disharmony) makes it unlawful to publish or distribute \"threatening, abusive, or insulting ... matter or words likely to excite hostility against or bring into contempt any group of persons ... on the ground of the colour, race, or ethnic or national or ethnic origins of that group of persons\". Section 131 (Inciting Racial Disharmony) lists offences for which \"racial disharmony\" creates liability.\n\nNorway prohibits hate speech, and defines it as publicly making statements that threaten or ridicule someone or that incite hatred, persecution or contempt for someone due to their skin colour, ethnic origin, homosexual orientation, religion or philosophy of life. At the same time, the Norwegian Constitution guarantees the right to free speech, and there has been an ongoing public and judicial debate over where the right balance between the ban against hate speech and the right to free speech lies. Norwegian courts have been restrictive in the use of the hate speech law and only a few persons have been sentenced for violating the law since its implementation in 1970. A public Free Speech committee (1996–1999) recommended to abolish the hate speech law but the Norwegian Parliament instead voted to slightly strengthen it.\n\nThe hate speech laws in Poland punish those who offend the feelings of the religious by e.g. disturbing a religious ceremony or creating public calumny. They also prohibit public expression that insults a person or a group on account of national, ethnic, racial, or religious affiliation or the lack of a religious affiliation.\n\nArticle 369 of the Criminal Code, titled 'Incitement to hatred or discrimination', prohibits hate speech directed against a group of persons. The offense carries a punishment of 6 months to 3 years' imprisonment, or a fine.\n\nAccording to Article 282 of the Criminal Code, 'Raising hates or hostility, or equally humiliation of human dignity':\n\nThe Serbian constitution guarantees freedom of speech, but restricts it in certain cases to protect the rights of others. The criminal charge of \"Provoking ethnic, racial and religion based animosity and intolerance\" carries a minimum six months prison term and a maximum of ten years.\n\nSingapore has passed numerous laws that prohibit speech that causes disharmony among various religious groups. The Maintenance of Religious Harmony Act is an example of such legislation. The Penal Code criminalizes the deliberate promotion by someone of enmity, hatred or ill-will between different racial and religious groups on grounds of race or religion. It also makes it an offence for anyone to deliberately wound the religious or racial feelings of any person.\n\nIn South Africa, hate speech (along with incitement to violence and propaganda for war) is specifically excluded from protection of free speech in the Constitution. The Promotion of Equality and Prevention of Unfair Discrimination Act, 2000 contains the following clause:\n\nThe \"prohibited grounds\" include race, gender, sex, pregnancy, marital status, ethnic or social origin, colour, sexual orientation, age, disability, religion, conscience, belief, culture, language and birth.\n\nThe crime of \"crimen injuria\" (\"unlawfully, intentionally and seriously impairing the dignity of another\") may also be used to prosecute hate speech.\n\nIn 2011, a South African court banned \"Dubula iBhunu (Shoot the Boer)\", a derogatory song that degraded Afrikaners, on the basis that it violated a South African law prohibiting speech that demonstrates a clear intention to be hurtful, to incite harm, or to promote hatred.\n\nIn October 2016, \"the draft Hate Crimes Bill was introduced. It aims to address racism, racial discrimination, xenophobia and discrimination based on gender, sex, sexual orientation and other issues, by providing an offence of hate crime. It includes controversial provisions that criminalize hate speech in ways that could be used to impermissibly restrict the right to freedom of expression\". The Foundation of Economic Education views this bill as a repetition of a mistake during the apartheid era, some maintaining that it constitutes \"the gravest threat to freedom of expression which South Africans have ever faced.\"\n\nThe Spanish \"Código Penal\" has two articles related to hate speech: article 510 about crimes against the Constitution and article 607.2 about genocidal crimes. Both articles forbid any form of ill-intended speech against individuals but have been criticized for their vague interpretation.\n\nThe organisation tasked with enforcing hate speech related crimes is the Committee on the Elimination of Racial Discrimination (\"Comité para la Eliminación de la Discriminación Racial\"). This committee is directed by the (\"Convención Internacional sobre la Eliminación de todas las Formas de Discriminación Racial\"). In an article published in 2011, it showed concerns about the persistence of stereotypical and unhealthy racial attitudes towards maghrebi and latino communities living in Spain.\n\nThe committee has urged the Government to take action by creating a national strategy in order to combat racism, xenophobia and their social consequences.\n\nSweden prohibits hate speech, and defines it as publicly making statements that threaten or express disrespect for an ethnic group or similar group regarding their race, skin colour, national or ethnic origin, faith, or sexual orientation. The crime does not prohibit a pertinent and responsible debate (\"en saklig och vederhäftig diskussion\"), nor statements made in a completely private sphere. There are constitutional restrictions pertaining to which acts are criminalized, as well limits set by the European Convention on Human Rights. The crime is called \"Hets mot folkgrupp\" in Swedish, which directly translates to \"Incitement (of hatred/violence) towards population groups.\"\n\nThe sexual orientation provision, added in 2002, was used to convict Pentecostalist pastor Åke Green of hate speech based on a 2003 sermon. His conviction was later overturned.\n\nIn Switzerland public discrimination or invoking to rancor against persons or a group of people because of their race, ethnicity, is getting penalized with a term of imprisonment until 3 years or a mulct. In 1934, the authorities of the Basel-Stadt canton criminalized anti-Jewish hate speech, e.g., the accusation of ritual murders, mostly in reaction against a pro-Nazi antisemitic group and newspaper, the .\n\nI. \"\"Constitution of Ukraine\"\" :\n\nThe most important law of the Ukraine country : the \"\"Constitution of Ukraine\"\" guarantees protection against Hate crime :\n\n\"\"Constitution of Ukraine\"\" :\n\nArticle 24: \"There can be no privileges or restrictions on the grounds of race, color of the skin, political, religious or other beliefs, sex, ethnic or social origin, property status, place of residence, language or other grounds\".\n\nArticle 37: \"The establishment and activity of political parties and public associations are prohibited if their program goals or actions are aimed at ...the propaganda of war and of violence, the incitement of inter-ethnic, racial, or religious enmity, and the encroachment on human rights and freedoms and the health of the population\". \nII. \"\"CRIMINAL CODEX OF UKRAINE\"\" :\n\nin Ukraine, all criminal punishments for crimes committed under the law are required to be registered in only one law, it is the only one: \"CRIMINAL CODEX OF UKRAINE\"\n\nThe crimes committed for Hate crime reinforce the punishment in many articles of the criminal law. There are also separate articles on punishment for Hate crime.\n\n\"CRIMINAL CODEX OF UKRAINE\" :\n\nArticle 161 : \"Violations of equality of citizens depending on their race, nationality, religious beliefs, disability and other grounds\n\n1. Intentional acts aimed at incitement to national, racial or religious hatred and violence, to humiliate national honor and dignity, or to repulse citizens' feelings due to their religious beliefs, \n\nas well as direct or indirect restriction of rights or the establishment of direct or indirect privileges citizens on the grounds of race, color, political, religious or other beliefs, sex, disability, ethnic or social origin, property status, place of residence, language or other grounds\"(Maximum criminal sentence of up to 8 years in prison)\n\nArticle 300 : \"Importation, manufacture or distribution of works promoting a cult of violence and cruelty, racial, national or religious intolerance and discrimination\" (Maximum criminal sentence of up to 5 years in prison) \n\nIn the United Kingdom, several statutes criminalize hate speech against several categories of people. The statutes forbid communication that is hateful, threatening, or abusive, and targets a person on account of disability, ethnic or national origin, nationality (including citizenship), race, religion, sexual orientation, or skin colour. The penalties for hate speech include fines, imprisonment, or both. Legislation against Sectarian hate in Scotland, which is aimed principally at football matches, does not criminalise jokes about people's beliefs, nor outlaw \"harsh\" comment about their religious faith.\n\nThe United States does not have hate speech laws, since American courts have repeatedly ruled that laws criminalizing hate speech violate the guarantee to freedom of speech contained in the First Amendment to the U.S. Constitution. There are several categories of speech that are not protected by the First Amendment, such as speech that calls for imminent violence upon a person or group. However, the U.S. Supreme Court has ruled that hate speech is not one of these categories. Court rulings often must be reexamined to ensure the U.S. Constitution is being upheld in the ruling on whether or not the words count as a violation.\n\nProponents of hate speech legislation in the United States have argued that freedom of speech undermines the 14th Amendment by bolstering an oppressive narrative which demeans equality and the Reconstructive Amendment's purpose of guaranteeing equal protection under the law.\n\nOn May 31, 2016, Facebook, Google, Microsoft, and Twitter, jointly agreed to a European Union code of conduct obligating them to review \"[the] majority of valid notifications for removal of illegal hate speech\" posted on their services within 24 hours.\n\nPrior to this in 2013, Facebook, with pressure from over 100 advocacy groups including the Everyday Sexism Project, agreed to change their hate speech policies after data released regarding content that promoted domestic and sexual violence against women led to the withdrawal of advertising by 15 large companies.\n\nMany extremist organizations disseminate hate speech by publishing posts that act as prompts. Content analysis algorithms catch obvious hate speech, however they don't pick up covert hate speech. Therefore, though an original post may technically adhere to hate speech policy, the ideas the post conveys prompts readers to use the comment section to spread overt hate speech. These sections are not monitored as heavily as main posts.\n\n\n"}
{"id": "14236", "url": "https://en.wikipedia.org/wiki?curid=14236", "title": "Henrik Ibsen", "text": "Henrik Ibsen\n\nHenrik Johan Ibsen (; ; 20 March 1828 – 23 May 1906) was a Norwegian playwright, theatre director, and poet. As one of the founders of Modernism in theatre, Ibsen is often referred to as \"the father of realism\" and one of the most influential playwrights of his time. His major works include \"Brand\", \"Peer Gynt\", \"An Enemy of the People\", \"Emperor and Galilean\", \"A Doll's House\", \"Hedda Gabler\", \"Ghosts\", \"The Wild Duck\", \"When We Dead Awaken\", \"Pillars of Society\", \"The Lady from the Sea\", \"Rosmersholm\", \"The Master Builder\", and \"John Gabriel Borkman\". He is the most frequently performed dramatist in the world after Shakespeare, and by the early 20th century \"A Doll's House\" became the world's most performed play.\n\nSeveral of his later dramas were considered scandalous to many of his era, when European theatre was expected to model strict morals of family life and propriety. Ibsen's later work examined the realities that lay behind the façades, revealing much that was disquieting to a number of his contemporaries. He had a critical eye and conducted a free inquiry into the conditions of life and issues of morality. His early poetic and cinematic play \"Peer Gynt\", however, has also strong surreal elements.\n\nIbsen is often ranked as one of the most distinguished playwrights in the European tradition. Richard Hornby describes him as \"a profound poetic dramatist—the best since Shakespeare\". He is widely regarded as the most important playwright since Shakespeare. He influenced other playwrights and novelists such as George Bernard Shaw, Oscar Wilde, Arthur Miller, James Joyce, Eugene O'Neill, and Miroslav Krleža. Ibsen was nominated for the Nobel Prize in Literature in 1902, 1903, and 1904.\n\nIbsen wrote his plays in Danish (the common written language of Denmark and Norway during his lifetime) and they were published by the Danish publisher Gyldendal. Although most of his plays are set in Norway—often in places reminiscent of Skien, the port town where he grew up—Ibsen lived for 27 years in Italy and Germany, and rarely visited Norway during his most productive years. Born into a merchant family connected to the patriciate of Skien, Ibsen shaped his dramas according to his family background. He was the father of Prime Minister Sigurd Ibsen. Ibsen's dramas have a strong influence upon contemporary culture.\n\nIbsen was born to Knud Ibsen (1797–1877) and Marichen Altenburg (1799–1869), into a well-to-do merchant family, in the small port town of Skien in Telemark county, a city which was noted for shipping timber. As he wrote in an 1882 letter to critic and scholar Georg Brandes, \"my parents were members on both sides of the most respected families in Skien\", explaining that he was closely related with \"just about all the patrician families who then dominated the place and its surroundings\", mentioning the families Paus, Plesner, von der Lippe, Cappelen and Blom. Ibsen's grandfather, ship captain Henrich Ibsen (1765–1797), had died at sea in 1797, and Knud Ibsen was raised on the estate of ship-owner Ole Paus (1766–1855), after his mother Johanne, Plesner (1770–1847), remarried. Knud Ibsen's half-brothers included lawyer and politician Christian Cornelius Paus, banker and ship-owner Christopher Blom Paus, and lawyer Henrik Johan Paus, who grew up with Ibsen's mother in the Altenburg home and after whom Henrik (Johan) Ibsen was named.\nKnud Ibsen's paternal ancestors were ship captains of Danish origin, but he decided to become a merchant, and had some initial success. His marriage to Marichen Altenburg, a daughter of ship-owner Johan Andreas Altenburg (1763–1824) and Hedevig Christine Paus (1763–1848), was a successful match. Theodore Jorgenson points out that \"Henrik's ancestry [thus] reached back into the important Telemark family of Paus both on the father's and on the mother's side. Hedvig Paus must have been well known to the young dramatist, for she lived until 1848.\" Henrik Ibsen was fascinated by his parents' \"strange, almost incestuous marriage,\" and would treat the subject of incestuous relationships in several plays, notably his masterpiece \"Rosmersholm\".\n\nWhen Henrik Ibsen was around seven years old, however, his father's fortunes took a significant turn for the worse, and the family was eventually forced to sell the major Altenburg building in central Skien and move permanently to their small summer house, \"Venstøp\", outside of the city. Henrik's sister Hedvig would write about their mother: \"She was a quiet, lovable woman, the soul of the house, everything to her husband and children. She sacrificed herself time and time again. There was no bitterness or reproach in her.\" The Ibsen family eventually moved to a city house, Snipetorp, owned by Knud Ibsen's half-brother, wealthy banker and ship-owner Christopher Blom Paus.\n\nHis father's financial ruin would have a strong influence on Ibsen's later work; the characters in his plays often mirror his parents, and his themes often deal with issues of financial difficulty as well as moral conflicts stemming from dark secrets hidden from society. Ibsen would both model and name characters in his plays after his own family. A central theme in Ibsen's plays is the portrayal of suffering women, echoing his mother Marichen Altenburg; Ibsen's sympathy with women would eventually find significant expression with their portrayal in dramas such as \"A Doll's House\" and \"Rosmersholm\".\n\nAt fifteen, Ibsen was forced to leave school. He moved to the small town of Grimstad to become an apprentice pharmacist and began writing plays. In 1846, when Ibsen was 18, he had a liaison with Else Sophie Jensdatter Birkedalen which produced a son, Hans Jacob Hendrichsen Birkdalen, whose upbringing Ibsen paid for until the boy was fourteen, though Ibsen never saw Hans Jacob. Ibsen went to Christiania (later renamed Kristiania and then Oslo) intending to matriculate at the university. He soon rejected the idea (his earlier attempts at entering university were blocked as he did not pass all his entrance exams), preferring to commit himself to writing. His first play, the tragedy \"Catilina\" (1850), was published under the pseudonym \"Brynjolf Bjarme\", when he was only 22, but it was not performed. His first play to be staged, \"The Burial Mound\" (1850), received little attention. Still, Ibsen was determined to be a playwright, although the numerous plays he wrote in the following years remained unsuccessful. Ibsen's main inspiration in the early period, right up to \"Peer Gynt\", was apparently the Norwegian author Henrik Wergeland and the Norwegian folk tales as collected by Peter Christen Asbjørnsen and Jørgen Moe. In Ibsen's youth, Wergeland was the most acclaimed, and by far the most read, Norwegian poet and playwright.\n\nHe spent the next several years employed at Det norske Theater (Bergen), where he was involved in the production of more than 145 plays as a writer, director, and producer. During this period, he published five new, though largely unremarkable, plays. Despite Ibsen's failure to achieve success as a playwright, he gained a great deal of practical experience at the Norwegian Theater, experience that was to prove valuable when he continued writing.\n\nIbsen returned to Christiania in 1858 to become the creative director of the Christiania Theatre. He married Suzannah Thoresen on 18 June 1858 and she gave birth to their only child Sigurd on 23 December 1859. The couple lived in very poor financial circumstances and Ibsen became very disenchanted with life in Norway. In 1864, he left Christiania and went to Sorrento in Italy in self-imposed exile. He didn't return to his native land for the next 27 years, and when he returned to it he was a noted, but controversial, playwright.\n\nHis next play, \"Brand\" (1865), brought him the critical acclaim he sought, along with a measure of financial success, as did the following play, \"Peer Gynt\" (1867), to which Edvard Grieg famously composed incidental music and songs. Although Ibsen read excerpts of the Danish philosopher Søren Kierkegaard and traces of the latter's influence are evident in \"Brand\", it was not until after \"Brand\" that Ibsen came to take Kierkegaard seriously. Initially annoyed with his friend Georg Brandes for comparing Brand to Kierkegaard, Ibsen nevertheless read \"Either/Or\" and \"Fear and Trembling\". Ibsen's next play \"Peer Gynt\" was consciously informed by Kierkegaard.\n\nWith success, Ibsen became more confident and began to introduce more and more of his own beliefs and judgements into the drama, exploring what he termed the \"drama of ideas\". His next series of plays are often considered his Golden Age, when he entered the height of his power and influence, becoming the center of dramatic controversy across Europe.\n\nIbsen moved from Italy to Dresden, Germany, in 1868, where he spent years writing the play he regarded as his main work, \"Emperor and Galilean\" (1873), dramatizing the life and times of the Roman emperor Julian the Apostate. Although Ibsen himself always looked back on this play as the cornerstone of his entire works, very few shared his opinion, and his next works would be much more acclaimed. Ibsen moved to Munich in 1875 and began work on his first contemporary realist drama \"The Pillars of Society\", first published and performed in 1877. \"A Doll's House\" followed in 1879. This play is a scathing criticism of the marital roles accepted by men and women which characterized Ibsen's society.\n\n\"Ghosts\" followed in 1881, another scathing commentary on the morality of Ibsen's society, in which a widow reveals to her pastor that she had hidden the evils of her marriage for its duration. The pastor had advised her to marry her fiancé despite his philandering, and she did so in the belief that her love would reform him. But his philandering continued right up until his death, and his vices are passed on to their son in the form of syphilis. The mention of venereal disease alone was scandalous, but to show how it could poison a respectable family was considered intolerable.\n\nIn \"An Enemy of the People\" (1882), Ibsen went even further. In earlier plays, controversial elements were important and even pivotal components of the action, but they were on the small scale of individual households. In \"An Enemy\", controversy became the primary focus, and the antagonist was the entire community. One primary message of the play is that the individual, who stands alone, is more often \"right\" than the mass of people, who are portrayed as ignorant and sheeplike. Contemporary society's belief was that the community was a noble institution that could be trusted, a notion Ibsen challenged. In \"An Enemy of the People\", Ibsen chastised not only the conservatism of society, but also the liberalism of the time. He illustrated how people on both sides of the social spectrum could be equally self-serving. \"An Enemy of the People\" was written as a response to the people who had rejected his previous work, \"Ghosts\". The plot of the play is a veiled look at the way people reacted to the plot of \"Ghosts\". The protagonist is a physician in a vacation spot whose primary draw is a public bath. The doctor discovers that the water is contaminated by the local tannery. He expects to be acclaimed for saving the town from the nightmare of infecting visitors with disease, but instead he is declared an 'enemy of the people' by the locals, who band against him and even throw stones through his windows. The play ends with his complete ostracism. It is obvious to the reader that disaster is in store for the town as well as for the doctor.\n\nAs audiences by now expected, Ibsen's next play again attacked entrenched beliefs and assumptions; but this time, his attack was not against society's mores, but against overeager reformers and their idealism. Always an iconoclast, Ibsen was equally willing to tear down the ideologies of any part of the political spectrum, including his own.\n\n\"The Wild Duck\" (1884) is by many considered Ibsen's finest work, and it is certainly the most complex. It tells the story of Gregers Werle, a young man who returns to his hometown after an extended exile and is reunited with his boyhood friend Hjalmar Ekdal. Over the course of the play, the many secrets that lie behind the Ekdals' apparently happy home are revealed to Gregers, who insists on pursuing the absolute truth, or the \"Summons of the Ideal\". Among these truths: Gregers' father impregnated his servant Gina, then married her off to Hjalmar to legitimize the child. Another man has been disgraced and imprisoned for a crime the elder Werle committed. Furthermore, while Hjalmar spends his days working on a wholly imaginary \"invention\", his wife is earning the household income.\n\nIbsen displays masterful use of irony: despite his dogmatic insistence on truth, Gregers never says what he thinks but only insinuates, and is never understood until the play reaches its climax. Gregers hammers away at Hjalmar through innuendo and coded phrases until he realizes the truth; Gina's daughter, Hedvig, is not his child. Blinded by Gregers' insistence on absolute truth, he disavows the child. Seeing the damage he has wrought, Gregers determines to repair things, and suggests to Hedvig that she sacrifice the wild duck, her wounded pet, to prove her love for Hjalmar. Hedvig, alone among the characters, recognizes that Gregers always speaks in code, and looking for the deeper meaning in the first important statement Gregers makes which does not contain one, kills herself rather than the duck in order to prove her love for him in the ultimate act of self-sacrifice. Only too late do Hjalmar and Gregers realize that the absolute truth of the \"ideal\" is sometimes too much for the human heart to bear.\n\nLate in his career, Ibsen turned to a more introspective drama that had much less to do with denunciations of society's moral values and more to do with the problems of individuals. In such later plays as \"Hedda Gabler\" (1890) and \"The Master Builder\" (1892), Ibsen explored psychological conflicts that transcended a simple rejection of current conventions. Many modern readers, who might regard anti-Victorian didacticism as dated, simplistic or hackneyed, have found these later works to be of absorbing interest for their hard-edged, objective consideration of interpersonal confrontation. \"Hedda Gabler\" is probably Ibsen's most performed play, with the title role regarded as one of the most challenging and rewarding for an actress even in the present day. \"Hedda Gabler\" and \"A Doll's House\" center on female protagonists whose almost demonic energy proves both attractive and destructive for those around them, and while Hedda has a few similarities with the character of Nora in \"A Doll's House\", many of today's audiences and theatre critics feel that Hedda's intensity and drive are much more complex and much less comfortably explained than what they view as rather routine feminism on the part of Nora.\n\nIbsen had completely rewritten the rules of drama with a realism which was to be adopted by Chekhov and others and which we see in the theatre to this day. From Ibsen forward, challenging assumptions and directly speaking about issues has been considered one of the factors that makes a play art rather than entertainment. His works were brought to an English-speaking audience, largely thanks to the efforts of William Archer and Edmund Gosse. These in turn had a profound influence on the young James Joyce who venerates him in his early autobiographical novel \"Stephen Hero\". Ibsen returned to Norway in 1891, but it was in many ways not the Norway he had left. Indeed, he had played a major role in the changes that had happened across society. Modernism was on the rise, not only in the theatre, but across public life.\n\nIbsen intentionally obscured his influences. However, asked later what he had read when he wrote Catiline, Ibsen replied that he had read only the Danish Norse saga-inspired Romantic tragedian Adam Oehlenschläger and Ludvig Holberg, \"the Scandinavian Molière\". [BBC Radio 4's in Our Time from Thursday, 31 May 2018 www.bbc.co.uk/programmes/b0b42q58]\n\nOn 23 May 1906, Ibsen died in his home at Arbins gade 1 in Kristiania (now Oslo) after a series of strokes in March 1900. When, on 22 May, his nurse assured a visitor that he was a little better, Ibsen spluttered his last words \"On the contrary\" (\"Tvertimod!\"). He died the following day at 2:30 pm.\n\nIbsen was buried in Vår Frelsers gravlund (\"The Graveyard of Our Savior\") in central Oslo.\n\nThe 100th anniversary of Ibsen's death in 2006 was commemorated with an \"Ibsen year\" in Norway and other countries. This year the homebuilding company Selvaag also opened \"Peer Gynt\" Sculpture Park in Oslo, Norway, in Henrik Ibsen's honour, making it possible to follow the dramatic play \"Peer Gynt\" scene by scene. Will Eno's adaptation of Ibsen's \"Peer Gynt\", titled \"Gnit\", had its world premiere at the 37th Humana Festival of New American Plays in March 2013.\n\nOn 23 May 2006, The Ibsen Museum in Oslo reopened to the public the house where Ibsen had spent his last eleven years, completely restored with the original interior, colors, and decor.\n\nOn the occasion of the 100th anniversary of Ibsen's death in 2006, the Norwegian government organised the Ibsen Year, which included celebrations around the world. The NRK produced a miniseries on Ibsen's childhood and youth in 2006, \"An Immortal Man\". Several prizes are awarded in the name of Henrik Ibsen, among them the International Ibsen Award, the Norwegian Ibsen Award and the Ibsen Centennial Commemoration Award.\n\nEvery year, since 2008, the annual \"Delhi Ibsen Festival\", is held in Delhi, India, organized by the Dramatic Art and Design Academy (DADA) in collaboration with The Royal Norwegian Embassy in India. It features plays by Ibsen, performed by artists from various parts of the world in varied languages and styles.\n\nThe Ibsen Society of America (ISA) was founded in 1978 at the close of the Ibsen Sesquicentennial Symposium held in New York City to mark the 150th anniversary of Henrik Ibsen's birth. Distinguished Ibsen translator and critic Rolf Fjelde, Professor of Literature at Pratt Institute and the chief organizer of the Symposium, was elected Founding President. In December 1979, the ISA was certified as a non-profit corporation under the laws of the State of New York. Its purpose is to foster through lectures, readings, performances, conferences, and publications an understanding of Ibsen's works as they are interpreted as texts and produced on stage and in film and other media. An annual newsletter \"Ibsen News and Comment\" is distributed to all members.\n\nIbsen's ancestry has been a much studied subject, due to his perceived foreignness and due to the influence of his biography and family on his plays. Ibsen often made references to his family in his plays, sometimes by name, or by modelling characters after them.\n\nThe oldest documented member of the Ibsen family was ship's captain Rasmus Ibsen (1632–1703) from Stege, Denmark. His son, ship's captain Peder Ibsen became a burgher of Bergen in Norway in 1726. Henrik Ibsen had Danish, German, Norwegian and some distant Scottish ancestry. Most of his ancestors belonged to the merchant class of original Danish and German extraction, and many of his ancestors were ship's captains.\n\nIbsen's biographer Henrik Jæger famously wrote in 1888 that Ibsen did not have a drop of Norwegian blood in his veins, stating that \"the ancestral Ibsen was a Dane\". This, however, is not completely accurate; notably through his grandmother Hedevig Paus, Ibsen was descended from one of the very few families of the patrician class of original Norwegian extraction, known since the 15th century. Ibsen's ancestors had mostly lived in Norway for several generations, even though many had foreign ancestry.\n\nThe name Ibsen is originally a patronymic, meaning \"son of Ib\" (Ib is a Danish variant of Jacob). The patronymic became \"frozen\", i.e. it became a permanent family name, in the 17th century. The phenomenon of patronymics becoming frozen started in the 17th century in bourgeois families in Denmark, and the practice was only widely adopted in Norway from around 1900.\n\nFrom his marriage with Suzannah Thoresen, Ibsen had one son, lawyer and government minister Sigurd Ibsen. Sigurd Ibsen married Bergljot Bjørnson, the daughter of Bjørnstjerne Bjørnson. Their son was Tancred Ibsen, who became a film director and was married to Lillebil Ibsen; their only child was diplomat Tancred Ibsen, Jr. Sigurd Ibsen's daughter, Irene Ibsen, married Josias Bille, a member of the Danish ancient noble Bille family; their son was Danish actor Joen Bille.\n\nIbsen was decorated Knight in 1873, Commander in 1892, and with the Grand Cross of the Order of St. Olav in 1893. He received the Grand Cross of the Danish Order of the Dannebrog, and the Grand Cross of the Swedish Order of the Polar Star, and was Knight, First Class of the Order of Vasa.\n\nWell known stage directors in Austria and Germany as Theodor Lobe (1833–1905), Paul Barnay (1884–1960), Max Burckhard (1854–1912), Otto Brahm (1956–1912), Carl Heine (1861–1927), Paul Albert Glaeser-Wilken (1874–1942), Victor Barnowsky (1875–1952), Eugen Robert (1877–1944), Leopold Jessner (1878–1945), Ludwig Barnay (1884–1960), Alfred Rotter (1886–1933), Fritz Rotter (1888–1939), (1900–1973) and Peter Zadek (1926–2009) performed the work of Ibsen.\n\nIn 1995, the asteroid 5696 Ibsen was named in his memory.\n\nThe authoritative translation in the English language for Ibsen remains the 1928 ten-volume version of the \"Complete Works of Henrik Ibsen\" from Oxford University Press. Many other translations of individual plays by Ibsen have appeared since 1928 though none have purported to be a new version of the complete works of Ibsen.\n\n\nThere have been numerous adaptations of Ibsen's work, particularly in film, theatre and music. Notable are Torstein Blixfjord's \"Terje\" and \"Identity of the Soul\" – two multimedia, film and dance pieces first presented in Yokohama in 2006, based on the poem \"Terje Vigen\".\n\n\n\n"}
{"id": "14240", "url": "https://en.wikipedia.org/wiki?curid=14240", "title": "Hawaiian language", "text": "Hawaiian language\n\nThe Hawaiian language (Hawaiian: \", ) is a Polynesian language that takes its name from Hawaii, the largest island in the tropical North Pacific archipelago where it developed. Hawaiian, along with English, is an official language of the State of Hawaii. King Kamehameha III established the first Hawaiian-language constitution in 1839 and 1840.\n\nFor various reasons, including territorial legislation establishing English as the official language in schools, the number of native speakers of Hawaiian gradually decreased during the period from the 1830s to the 1950s. Hawaiian was essentially displaced by English on six of seven inhabited islands. In 2001, native speakers of Hawaiian amounted to less than 0.1% of the statewide population. Linguists were unsure that Hawaiian and other endangered languages would survive.\n\nNevertheless, from around 1949 to the present day, there has been a gradual increase in attention to and promotion of the language. Public Hawaiian-language immersion preschools called Pūnana Leo were established in 1984; other immersion schools followed soon after that. The first students to start in immersion preschool have now graduated from college and many are fluent Hawaiian speakers. The federal government has acknowledged this development. For example, the Hawaiian National Park Language Correction Act of 2000 changed the names of several national parks in Hawaii, observing the Hawaiian spelling. However, the language is still classified as critically endangered by UNESCO.\n\nA creole language spoken in Hawaii is Hawaiian Pidgin (or Hawaii Creole English, HCE). It should not be mistaken for the Hawaiian language nor for a dialect of English.\n\nThe Hawaiian alphabet has 13 letters: five vowels (each with a long pronunciation and a short one) and eight consonants, one of which is the glottal stop called okina.\n\nThe Hawaiian language takes its name from the largest island in the Hawaiian state, Hawaii (\" in the Hawaiian language). The island name was first written in English in 1778 by British explorer James Cook and his crew members. They wrote it as \"Owhyhee\" or \"Owhyee\". Explorers Mortimer (1791) and Otto von Kotzebue (1821) used that spelling.\n\nThe initial \"O\" in the name is a reflection of the fact that unique identity is predicated in Hawaiian by using a copula form, \"o\", immediately before a proper noun. Thus, in Hawaiian, the name of the island is expressed by saying \"\", which means \"[This] is Hawaii.\" The Cook expedition also wrote \"Otaheite\" rather than \"Tahiti.\"\n\nThe spelling \"why\" in the name reflects the pronunciation of \"wh\" in 18th-century English (still used in parts of the English-speaking world). \"Why\" was pronounced . The spelling \"hee\" or \"ee\" in the name represents the sounds , or .\n\nPutting the parts together, \"O-why-(h)ee\" reflects , a reasonable approximation of the native pronunciation, .\n\nAmerican missionaries bound for Hawaii used the phrases \"Owhihe Language\" and \"Owhyhee language\" in Boston prior to their departure in October 1819 and during their five-month voyage to Hawaii. They still used such phrases as late as March 1822. However, by July 1823, they had begun using the phrase \"Hawaiian Language.\"\n\nIn Hawaiian, \"\" means \"Hawaiian language\", as adjectives follow nouns.\n\nHawaiian is a Polynesian member of the Austronesian language family. It is closely related to other Polynesian languages, such as Samoan, Marquesan, Tahitian, Māori, Rapa Nui (the language of Easter Island) and Tongan.\n\nAccording to Schütz (1994), the Marquesans colonized the archipelago in roughly 300 CE followed by later waves of immigration from the Society Islands and Samoa-Tonga. Their languages, over time, became the Hawaiian language within the Hawaiian Islands. Kimura and Wilson (1983) also state: \"Linguists agree that Hawaiian is closely related to Eastern Polynesian, with a particularly strong link in the Southern Marquesas, and a secondary link in Tahiti, which may be explained by voyaging between the Hawaiian and Society Islands.\"\n\nThe genetic history of the Hawaiian language is demonstrated primarily through the application of lexicostatistics, which involves quantitative comparison of lexical cognates, and the comparative method. Both the number of cognates and the phonological similarity of cognates are measures of language relationship.\n\nThe following table provides a limited lexicostatistical data set for ten numbers. The asterisk (*) is used to show that these are hypothetical, reconstructed forms. In the table, the year date of the modern forms is rounded off to 2000 CE to emphasize the 6000-year time lapse since the PAN era.\n\nNote: For the number \"10\", the Tongan form in the table is part of the word ('ten'). The Hawaiian cognate is part of the word ('ten days'); however, the more common word for \"10\" used in counting and quantifying is , a different root.\n\nApplication of the lexicostatistical method to the data in the table will show the four languages to be related to one another, with Tagalog having 100% cognacy with PAN, while Hawaiian and Tongan have 100% cognacy with each other, but 90% with Tagalog and PAN. This is because the forms for each number are cognates, except the Hawaiian and Tongan words for the number \"1\", which are cognate with each other, but not with Tagalog and PAN. When the full set of 200 meanings is used, the percentages will be much lower. For example, Elbert found Hawaiian and Tongan to have 49% (98 ÷ 200) shared cognacy. This points out the importance of data-set size for this method, where less data leads to cruder results, while more data leads to better results.\n\nApplication of the comparative method will show partly different genetic relationships. It will point out sound changes, such as:\nThis method will recognize sound change #1 as a shared innovation of Hawaiian and Tongan. It will also take the Hawaiian and Tongan cognates for \"1\" as another shared innovation. Due to these exclusively shared features, Hawaiian and Tongan are found to be more closely related to one another than either is to Tagalog or PAN.\n\nThe forms in the table show that the Austronesian vowels tend to be relatively stable, while the consonants are relatively volatile. It is also apparent that the Hawaiian words for \"3\", \"5\", and \"8\" have remained essentially unchanged for 6000 years.\n\nIn 1778, British explorer James Cook made Europe's initial, recorded first contact with Hawaiʻi, beginning a new phase in the development of Hawaiian. During the next forty years, the sounds of Spanish (1789), Russian (1804), French (1816), and German (1816) arrived in Hawaii via other explorers and businessmen. Hawaiian began to be written for the first time, largely restricted to isolated names and words, and word lists collected by explorers and travelers.\n\nThe early explorers and merchants who first brought European languages to the Hawaiian islands also took on a few native crew members who brought the Hawaiian language into new territory. Hawaiians took these nautical jobs because their traditional way of life changed due to plantations, and although there were not enough of these Hawaiian-speaking explorers to establish any viable speech communities abroad, they still had a noticeable presence. One of them, a boy in his teens known as Obookiah (), had a major impact on the future of the language. He sailed to New England, where he eventually became a student at the Foreign Mission School in Cornwall, Connecticut. He inspired New Englanders to support a Christian mission to Hawaii, and provided information on the Hawaiian language to the American missionaries there prior to their departure for Hawaii in 1819.\n\nLike all natural spoken languages, the Hawaiian language was originally just an oral language. The native people of the Hawaiian language relayed religion, traditions, history, and views of their world through stories that were handed down from generation to generation. One form of storytelling most commonly associated with the Hawaiian islands is hula. Nathaniel B. Emerson notes that \"It kept the communal imagination in living touch with the nation's legendary past\".\n\nThe islanders' connection with their stories is argued to be one reason why Captain James Cook received a pleasant welcome. Marshall Sahlins has observed that Hawaiian folktales began bearing similar content to those of the Western world in the eighteenth century. He argues this was caused by the timing of Captain Cook's arrival, which was coincidentally when the indigenous Hawaiians were celebrating the Makahiki festival. The islanders' story foretold of the god Lono's return at the time of the Makahiki festival.\n\nIn 1820, Protestant missionaries from New England arrived in Hawaii.\n\nAdelbert von Chamisso might have consulted with a native speaker of Hawaiian in Berlin, Germany, before publishing his grammar of Hawaiian (\"\") in 1837. When Hawaiian King David Kalākaua took a trip around the world, he brought his native language with him. When his wife, Queen Kapiolani, and his sister, Princess (later Queen) Liliuokalani, took a trip across North America and on to the British Islands, in 1887, Liliuokalani's composition \"Aloha Oe\" was already a famous song in the U.S.\nIn 1834, the first Hawaiian-language newspapers were published by missionaries working with locals. The missionaries also played a significant role in publishing a vocabulary (1836) grammar (1854) and dictionary (1865) of Hawaiian. Literacy in Hawaiian was widespread among the local population, especially ethnic Hawaiians. Use of the language among the general population might have peaked around 1881. Even so, some people worried, as early as 1854, that the language was \"soon destined to extinction.\"\n\nThe decline of the Hawaiian language dates back to a coup that overthrew the Hawaiian monarchy and dethroned the existing Hawaiian queen. Thereafter, a law was instituted that banned the Hawaiian language from being taught. The law cited as banning the Hawaiian language is identified as Act 57, sec. 30 of the 1896 Laws of the Republic of Hawaii:\n\nThis law established English as the medium of instruction for the government-recognized schools both \"public and private\". While it did not ban or make illegal the Hawaiian language in other contexts, its implementation in the schools had far-reaching effects. Those who had been pushing for English-only schools took this law as licence to extinguish the native language at the early education level. While the law stopped short of making Hawaiian illegal (it was still the dominant language spoken at the time), many children who spoke Hawaiian at school, including on the playground, were disciplined. This included corporal punishment and going to the home of the offending child to strongly advise them to stop speaking it in their home. Moreover, the law specifically provided for teaching languages \"in addition to the English language,\" reducing Hawaiian to the status of a foreign language, subject to approval by the Department. Hawaiian was not taught initially in any school, including the all-Hawaiian Kamehameha Schools. This is largely because when these schools were founded, like Kamehameha Schools founded in 1887 (nine years before this law), Hawaiian was being spoken in the home. Once this law was enacted, individuals at these institutions took it upon themselves to enforce a ban on Hawaiian. Beginning in 1900, Mary Kawena Pukui, who was later the co-author of the Hawaiian–English Dictionary, was punished for speaking Hawaiian by being rapped on the forehead, allowed to eat only bread and water for lunch, and denied home visits on holidays. Winona Beamer was expelled from Kamehameha Schools in 1937 for chanting Hawaiian.\n\nIn 1949, the legislature of the Territory of Hawaii commissioned Mary Pukui and Samuel Elbert to write a new dictionary of Hawaiian, either revising the Andrews-Parker work or starting from scratch. Pukui and Elbert took a middle course, using what they could from the Andrews dictionary, but making certain improvements and additions that were more significant than a minor revision. The dictionary they produced, in 1957, introduced an era of gradual increase in attention to the language and culture.\n\nEfforts to promote the language have increased in recent decades. Hawaiian-language \"immersion\" schools are now open to children whose families want to reintroduce Hawaiian language for future generations. The Aha Pūnana Leo’s Hawaiian language preschools in Hilo, Hawaii, have received international recognition. The local National Public Radio station features a short segment titled \"Hawaiian word of the day\" and a Hawaiian language news broadcast. Honolulu television station KGMB ran a weekly Hawaiian language program, \"Āhai Ōlelo Ola\", as recently as 2010. Additionally, the Sunday editions of the \"Honolulu Star-Advertiser\", the largest newspaper in Hawaii, feature a brief article called \"Kauakukalahale\" written entirely in Hawaiian by teachers, students, and community members.\n\nToday, the number of native speakers of Hawaiian, which was under 0.1% of the statewide population in 1997, has risen to 2,000, out of 24,000 total who are fluent in the language, according to the US 2011 census. On six of the seven permanently inhabited islands, Hawaiian has been largely displaced by English, but on Niihau, native speakers of Hawaiian have remained fairly isolated and have continued to use Hawaiian almost exclusively.\n\nThe isolated island of Niʻihau, located off the southwest coast of Kauai, is the one island where Hawaiian is still spoken as the language of daily life. \n\nHawaiians had no written language prior to Western contact, except for petroglyph symbols.\nThe modern Hawaiian alphabet, \"ka pīāpā Hawaii\", is based on the Latin script. Hawaiian words end \"only\" in vowels, and every consonant must be followed by a vowel. The Hawaiian alphabetical order has all of the vowels before the consonants, as in the following chart.\nThis writing system was developed by American Protestant missionaries during 1820–1826. It was the first thing they ever printed in Hawaii, on January 7, 1822, and it originally included the consonants \"B, D, R, T,\" and \"V,\" in addition to the current ones (\"H, K, L, M, N, P, W\"), and it had \"F, G, S, Y\" and \"Z\" for \"spelling foreign words\". The initial printing also showed the five vowel letters (\"A, E, I, O, U\") and seven of the short diphthongs (\"AE, AI, AO, AU, EI, EU, OU\").\n\nIn 1826, the developers voted to eliminate some of the letters which represented functionally redundant allophones (called \"interchangeable letters\"), enabling the Hawaiian alphabet to approach the ideal state of one-symbol-one-phoneme, and thereby optimizing the ease with which people could teach and learn the reading and writing of Hawaiian. For example, instead of spelling one and the same word as \"pule, bule, pure,\" and \"bure\" (because of interchangeable \"p/b\" and \"l/r\"), the word is spelled only as \"pule\".\n\nHowever, hundreds of words were very rapidly borrowed into Hawaiian from English, Greek, Hebrew, Latin, and Syriac. Although these loan words were necessarily Hawaiianized, they often retained some of their \"non-Hawaiian letters\" in their published forms. For example, \"Brazil\" fully Hawaiianized is \"Palakila\", but retaining \"foreign letters\" it is \"Barazila\". Another example is \"Gibraltar\", written as \"Kipalaleka\" or \"Gibaraleta\". While and are not regarded as Hawaiian sounds, , , and were represented in the original alphabet, so the letters (\"b\", \"r\", and \"t\") for the latter are not truly \"non-Hawaiian\" or \"foreign\", even though their post-1826 use in published matter generally marked words of foreign origin.\n\n\"ʻOkina\" (\"oki\" 'cut' + \"-na\" '-ing') is the modern Hawaiian name for the symbol (a letter) that represents the glottal stop. It was formerly known as \"uina\" ('snap').\n\nFor examples of the okina, consider the Hawaiian words \"Hawaii\" and \"Oahu\" (often simply \"Hawaii\" and \"Oahu\" in English orthography). In Hawaiian, these words can be pronounced and , and can be written with an okina where the glottal stop is pronounced.\n\nElbert & Pukui's \"Hawaiian Grammar\" says \"The glottal stop, ‘, is made by closing the glottis or space between the vocal cords, the result being something like the hiatus in English \"oh-oh\".\"\n\nAs early as 1823, the missionaries made some limited use of the apostrophe to represent the glottal stop, but they did not make it a letter of the alphabet. In publishing the Hawaiian Bible, they used it to distinguish \"kou\" ('my') from \"kou\" ('your'). In 1864, William DeWitt Alexander published a grammar of Hawaiian in which he made it clear that the glottal stop (calling it \"guttural break\") is definitely a true consonant of the Hawaiian language. He wrote it using an apostrophe. In 1922, the Andrews-Parker dictionary of Hawaiian made limited use of the opening single quote symbol, called \"reversed apostrophe\" or \"inverse comma\", to represent the glottal stop. Subsequent dictionaries have preferred to use that symbol. Today, many native speakers of Hawaiian do not bother, in general, to write any symbol for the glottal stop. Its use is advocated mainly among students and teachers of Hawaiian as a second language, and among linguists.\n\nThe okina is written in various ways for electronic uses:\n\nBecause many people who want to write the ʻokina are not familiar with these specific characters and/or do not have access to the appropriate fonts and input and display systems, it is sometimes written with more familiar and readily available characters:\n\nA modern Hawaiian name for the macron symbol is \"kahakō\" (\"kaha\" 'mark' + \"kō\" 'long'). It was formerly known as \"mekona\" (Hawaiianization of \"macron\"). It can be written as a diacritical mark which looks like a hyphen or dash written above a vowel, i.e., \"ā ē ī ō ū\" and \"Ā Ē Ī Ō Ū\". It is used to show that the marked vowel is a \"double\", or \"geminate\", or \"long\" vowel, in phonological terms. (See: Vowel length)\n\nAs early as 1821, at least one of the missionaries, Hiram Bingham, was using macrons (and breves) in making handwritten transcriptions of Hawaiian vowels. The missionaries specifically requested their sponsor in Boston to send them some type (fonts) with accented vowel characters, including vowels with macrons, but the sponsor made only one response and sent the wrong font size (pica instead of small pica). Thus, they could not print ā, ē, ī, ō, nor ū (at the right size), even though they wanted to.\n\nDue to extensive allophony, Hawaiian has more than 13 phones. Although vowel length is phonemic, long vowels are not always pronounced as such, even though under the rules for assigning stress in Hawaiian, a long vowel will always receive stress.\n\nHawaiian is known for having very few consonant phonemes – eight: . It is notable that Hawaiian has allophonic variation of with , with , and (in some dialects) with . The – variation is quite unusual among the world's languages, and is likely a product both of the small number of consonants in Hawaiian, and the recent shift of historical *t to modern –, after historical *k had shifted to . In some dialects, remains as in some words. These variations are largely free, though there are conditioning factors. tends to especially in words with both and , such as in the island name \"Lānai\" (–), though this is not always the case: \"eleele\" or \"eneene\" \"black\". The allophone is almost universal at the beginnings of words, whereas is most common before the vowel . is also the norm after and , whereas is usual after and . After and initially, however, and are in free variation. \"A consonant occurs only before a vowel; thus two consonants never occur in succession and a syllable always ends with a vowel\".\n\nHawaiian has five short and five long vowels, plus diphthongs.\n\nHawaiian has five pure vowels. The short vowels are , and the long vowels, if they are considered separate phonemes rather than simply sequences of like vowels, are . When stressed, short and have been described as becoming and , while when unstressed they are and . Parker Jones (2017), however, did not find a reduction of /a/ to in the phonetic analysis of a young speaker from Hilo, Hawaiʻi; so there is at least some variation in how /a/ is realised. also tends to become next to , , and another , as in \"Pele\" . Some grammatical particles vary between short and long vowels. These include \"a\" and \"o\" \"of\", \"ma\" \"at\", \"na\" and \"no\" \"for\". Between a back vowel or and a following non-back vowel (), there is an epenthetic , which is generally not written. Between a front vowel or and a following non-front vowel (), there is an epenthetic (a \"y\" sound), which is never written.\n\nThe short-vowel diphthongs are . In all except perhaps , these are falling diphthongs. However, they are not as tightly bound as the diphthongs of English, and may be considered vowel sequences. (The second vowel in such sequences may receive the stress, but in such cases it is not counted as a diphthong.) In fast speech, tends to and tends to , conflating these diphthongs with and .\n\nThere are only a limited number of vowels which may follow long vowels, and some authors treat these sequences as diphthongs as well: .\n\nHawaiian syllable structure is (C)V. All CV syllables occur except for \"wū\"; \"wu\" occurs only in two words borrowed from English. As shown by Schütz, Hawaiian word-stress is predictable in words of one to four syllables, but not in words of five or more syllables. Hawaiian phonological processes include palatalization and deletion of consonants, as well as raising, diphthongization, deletion, and compensatory lengthening of vowels. Phonological reduction (or \"decay\") of consonant phonemes during the historical development of the language has resulted in the phonemic glottal stop. Ultimate loss (deletion) of intervocalic consonant phonemes has resulted in Hawaiian long vowels and diphthongs.\n\nHawaiian is an analytic language with verb–subject–object word order. While there is no use of inflection for verbs, in Hawaiian, like other Austronesian personal pronouns, declension is found in the differentiation between a- and o-class genitive case personal pronouns in order to indicate inalienable possession in a binary possessive class system. Also like many Austronesian languages, Hawaiian pronouns employ separate words for inclusive and exclusive we (clusivity), and distinguish singular, dual, and plural. The grammatical function of verbs is marked by adjacent particles (short words) and by their relative positions, that indicate tense–aspect–mood.\n\nSome examples of verb phrase patterns:\n\nNouns can be marked with articles:\n\n\"ka\" and \"ke\" are singular definite articles. \"ke\" is used before words beginning with a-, e-, o- and k-, and with some words beginning - and p-. \"ka\" is used in all other cases. \"nā\" is the plural definite article.\n\nTo show part of a group, the word \"kekahi\" is used. To show a bigger part, \"mau\" is inserted to pluralize the subject.\n\nExamples:\n\n\n\n"}
{"id": "14245", "url": "https://en.wikipedia.org/wiki?curid=14245", "title": "Second Polish Republic", "text": "Second Polish Republic\n\nThe Second Polish Republic, commonly known as interwar Poland, refers to the country of Poland in the period between the First and Second World Wars (1918–1939). Officially known as the Republic of Poland (), sometimes Commonwealth of Poland, the Polish state was re-established in 1918, in the aftermath of World War I. When, after several regional conflicts, the borders of the state were fixed in 1922, Poland's neighbours were Czechoslovakia, Germany, the Free City of Danzig, Lithuania, Latvia, Romania and the Soviet Union. It had access to the Baltic Sea via a short strip of coastline either side of the city of Gdynia. Between March and August 1939, Poland also shared a border with the then-Hungarian governorate of Subcarpathia. The Second Republic ceased to exist in 1939, when Poland was invaded by Nazi Germany, the Soviet Union and the Slovak Republic, marking the beginning of European theatre of World War II.\n\nIn 1938, the Second Republic was the sixth largest country in Europe. According to the 1921 census, the number of inhabitants was 27.2 million. By 1939, just before the outbreak of World War II, this had grown to an estimated 35.1 million. Almost a third of population came from minority groups: 13.9% Ruthenians; 10% Ashkenazi Jews; 3.1% Belarusians; 2.3% Germans and 3.4% Czechs and Lithuanians. At the same time, a significant number of ethnic Poles lived outside the country's borders.\n\nThe political conditions of the Second Republic were heavily influenced by the aftermath of World War I and conflicts with neighbouring states (Ukraine, Czechoslovakia, Lithuania, the Soviet Union) and the emergence of Nazi Germany.\n\nThe Second Republic maintained moderate economic development. The cultural hubs of interwar PolandWarsaw, Kraków, Poznań, Wilno and Lwówbecame major European cities and the sites of internationally acclaimed universities and other institutions of higher education.\n\nAfter more than a century of Partitions between the Austrian, the Prussian, and the Russian imperial powers, Poland re-emerged as a sovereign state at the end of the First World War in Europe in 1917-1918. The victorious Allies of World War I confirmed the rebirth of Poland in the Treaty of Versailles of June 1919. It was one of the great stories of the 1919 Paris Peace Conference. Poland solidified its independence in a series of border wars fought by the newly formed Polish Army from 1918 to 1921. The extent of the eastern half of the interwar territory of Poland was settled diplomatically in 1922 and internationally recognized by the League of Nations.\n\nIn the course of World War I (1914-1918), Germany gradually gained overall dominance on the Eastern Front as the Imperial Russian Army fell back. German and Austro-Hungarian armies seized the Russian-ruled part of what became Poland. In a failed attempt to resolve the Polish question as quickly as possible, Berlin set up a German puppet state on 5 November 1916, with a governing Provisional Council of State and (from 15 October 1917) a Regency Council (\"Rada Regencyjna Królestwa Polskiego\"). The Council administered the country under German auspices (see also Mitteleuropa), pending the election of a king. A month before Germany surrendered on 11 November 1918 and the war ended, the Regency Council had dissolved the Council of State, and announced its intention to restore Polish independence (7 October 1918). With the notable exception of the Marxist-oriented Social Democratic Party of the Kingdom of Poland and Lithuania (\"SDKPiL\"), most Polish political parties supported this move. On 23 October the Regency Council appointed a new government under Józef Świeżyński and began conscription into the Polish Army.\n\nIn 1918–1919, over 100 workers' councils sprang up on Polish territories; on 5 November 1918, in Lublin, the first Soviet of Delegates was established. On 6 November socialists proclaimed the Republic of Tarnobrzeg at Tarnobrzeg in Austrian Galicia. The same day the Socialist, Ignacy Daszyński, set up a Provisional People's Government of the Republic of Poland (\"Tymczasowy Rząd Ludowy Republiki Polskiej\") in Lublin. On Sunday, 10 November at 7 a.m., Józef Piłsudski, newly freed from 16 months in a German prison in Magdeburg, returned by train to Warsaw. Piłsudski, together with Colonel Kazimierz Sosnkowski, was greeted at Warsaw's railway station by Regent Zdzisław Lubomirski and by Colonel Adam Koc. Next day, due to his popularity and support from most political parties, the Regency Council appointed Piłsudski as Commander in Chief of the Polish Armed Forces. On 14 November, the Council dissolved itself and transferred all its authority to Piłsudski as Chief of State (\"Naczelnik Państwa\"). After consultation with Piłsudski, Daszyński's government dissolved itself and a new government formed under Jędrzej Moraczewski. In 1918 Italy became the first country in Europe to recognise Poland's renewed sovereignty.\n\nCenters of government that formed at that time in Galicia (formerly Austrian-ruled southern Poland) included the National Council of the Principality of Cieszyn (established in November 1918), the Republic of Zakopane and the Polish Liquidation Committee (28 October). Soon afterward, the Polish–Ukrainian War broke out in Lwów (1 November 1918) between forces of the Military Committee of Ukrainians and the Polish irregular units made up of students known as the Lwów Eaglets, who were later supported by the Polish Army (see Battle of Lwów (1918), Battle of Przemyśl (1918)). Meanwhile, in western Poland, another war of national liberation began under the banner of the Greater Poland Uprising (1918–19). In January 1919 Czechoslovakian forces attacked Polish units in the area of Zaolzie (see Polish–Czechoslovak War). Soon afterwards the Polish–Lithuanian War (ca 1919-1920) began, and in August 1919 Polish-speaking residents of Upper Silesia initiated a series of three Silesian Uprisings. The most critical military conflict of that period, however, the Polish–Soviet War (1919-1921), ended in a decisive Polish victory. In 1919 the Warsaw government suppressed the Republic of Tarnobrzeg and the workers' councils.\n\nThe Second Polish Republic was a parliamentary democracy from 1919 (see Small Constitution of 1919) to 1926, with the President having limited powers. The Parliament elected him, and he could appoint the Prime Minister as well as the government with the Sejm's (lower house's) approval, but he could only dissolve the Sejm with the Senate's consent. Moreover, his power to pass decrees was limited by the requirement that the Prime Minister and the appropriate other Minister had to verify his decrees with their signatures. Poland was one of the first countries in the world to recognize women's suffrage. Women in Poland were granted the right to vote on 28 November 1918 by a decree of Józef Piłsudski.\n\nThe major political parties at this time were the Polish Socialist Party, National Democrats, various Peasant Parties, Christian Democrats, and political groups of ethnic minorities (German: German Social Democratic Party of Poland, Jewish: General Jewish Labour Bund in Poland, United Jewish Socialist Workers Party, and Ukrainian: Ukrainian National Democratic Alliance). Frequently changing governments (see Polish legislative election, 1919, Polish legislative election, 1922) and other negative publicity the politicians received (such as accusations of corruption or 1919 Polish coup attempt), made them increasingly unpopular. Major politicians at this time, in addition to Piłsudski, included peasant activist Wincenty Witos (Prime Minister three times) and right-wing leader Roman Dmowski. Ethnic minorities were represented in the Sejm; e.g. in 1928 – 1930 there was the Ukrainian-Belarusian Club, with 26 Ukrainian and 4 Belarusian members.\nAfter the Polish – Soviet war, Marshal Piłsudski led an intentionally modest life, writing historical books for a living. After he took power by a military coup in May 1926, he emphasized that he wanted to heal the Polish society and politics of excessive partisan politics. His regime, accordingly, was called Sanacja in Polish. The 1928 parliamentary elections were still considered free and fair, although the pro-Piłsudski Nonpartisan Bloc for Cooperation with the Government won them. The following three parliamentary elections (in 1930, 1935 and 1938) were manipulated, with opposition activists sent to Bereza Kartuska prison (see also Brest trials). As a result, pro-government party Camp of National Unity won huge majorities in them. Piłsudski died just after an authoritarian constitution was approved in the spring of 1935. During the last four years of the Second Polish Republic, the major politicians included President Ignacy Mościcki, Foreign Minister Józef Beck and the Commander-in-Chief of the Polish Army, Edward Rydz-Śmigły. The country was divided into 104 electoral districts, and those politicians who were forced to leave Poland, founded Front Morges in 1936. The government that ruled Second Polish Republic in its final years is frequently referred to as Piłsudski's colonels.\nThe interwar Poland had a considerably large army of 950,000 soldiers on active duty: in 37 infantry divisions, 11 cavalry brigades, and two armored brigades, plus artillery units. Another 700,000 men served in the reserves. At the outbreak of the war, the Polish army was able to put in the field almost one million soldiers, 4,300 guns, 1,280 tanks and 745 aircraft.\n\nThe training of the Polish army was thorough. The N.C.O.s were a competent body of men with expert knowledge and high ideals. The officers, both senior and junior, constantly refreshed their training in the field and in the lecture-hall, where modern technical achievement and the lessons of contemporary wars were demonstrated and discussed. The equipment of the Polish army was less developed technically than that of Nazi Germany and its rearmament was slowed down by confidence in Western European military support and by budget difficulties.\n\nAfter regaining its independence, Poland was faced with major economic difficulties. In addition to the devastation wrought by World War I, the exploitation of the Polish economy by the German and Russian occupying powers, and the sabotage performed by retreating armies, the new republic was faced with the task of economically unifying disparate economic regions, which had previously been part of different countries. Within the borders of the Republic were the remnants of three different economic systems, with five different currencies (the German mark, the Russian ruble, the Austrian crown, the Polish marka and the Ostrubel) and with little or no direct infrastructural links. The situation was so bad that neighboring industrial centers as well as major cities lacked direct railroad links, because they had been parts of different nations. For example, there was no direct railroad connection between Warsaw and Kraków until 1934. This situation was described by Melchior Wańkowicz in his book Sztafeta.\n\nOn top of this was the massive destruction left after both World War I and the Polish–Soviet War. There was also a great economic disparity between the eastern (commonly called \"Poland B\") and western (called \"Poland A\") parts of the country, with the western half, especially areas that had belonged to the German Empire being much more developed and prosperous. Frequent border closures and a customs war with Germany also had negative economic impacts on Poland. In 1924 Prime Minister and Economic Minister Władysław Grabski introduced the złoty as a single common currency for Poland (it replaced the Polish marka), which remained a stable currency. The currency helped Poland to control the massive hyperinflation. It was the only country in Europe able to do this without foreign loans or aid. The average annual growth rate (GDP per capita) was 5.24% in 1920–29 and 0.34% in 1929–38.\n\nHostile relations with neighbours were a major problem for the economy of interbellum Poland. In the year 1937, foreign trade with all neighbours amounted to only 21% of Poland's total. Trade with Germany, Poland's most important neighbour, accounted for 14.3% of Polish exchange. Foreign trade with the Soviet Union (0.8%) was virtually nonexistent. Czechoslovakia accounted for 3.9%, Latvia for 0.3%, and Romania for 0.8%. By mid-1938, after the Anschluss of Austria, Greater Germany was responsible for as much as 23% of Polish foreign trade.\nThe basis of Poland's gradual recovery after the Great Depression was its mass economic development plans (see Four Year Plan), which oversaw the building of three key infrastructural elements. The first was the establishment of the Gdynia seaport, which allowed Poland to completely bypass Gdańsk (which was under heavy German pressure to boycott Polish coal exports). The second was construction of the 500-kilometer rail connection between Upper Silesia and Gdynia, called Polish Coal Trunk-Line, which served freight trains with coal. The third was the creation of a central industrial district, named \"COP – Central Industrial Region\" (Centralny Okręg Przemysłowy). Unfortunately, these developments were interrupted and largely destroyed by the German and Soviet invasion and the start of World War II. Other achievements of interbellum Poland included Stalowa Wola (a brand new city, built in a forest around a steel mill), Mościce (now a district of Tarnów, with a large nitrate factory), and the creation of a central bank. There were several trade fairs, with the most popular being Poznań International Fair, Lwów's Targi Wschodnie, and Wilno's Targi Północne. Polish Radio had ten stations (see Radio stations in interwar Poland), with the eleventh one planned to be opened in the autumn of 1939. Furthermore, in 1935 Polish engineers began working on the TV services. By early 1939, experts of the Polish Radio built four TV sets. The first movie broadcast by experimental Polish TV was Barbara Radziwiłłówna, and by 1940, regular TV service was scheduled to begin operation.\n\nInterbellum Poland was also a country with numerous social problems. Unemployment was high, and poverty was widespread, which resulted in several cases of social unrest, such as the 1923 Kraków riot, and 1937 peasant strike in Poland. There were conflicts with national minorities, such as Pacification of Ukrainians in Eastern Galicia (1930), relations with Polish neighbors were sometimes complicated (see Soviet raid on Stołpce, Polish–Czechoslovak border conflicts, 1938 Polish ultimatum to Lithuania). On top of this, there were natural disasters, such as the 1934 flood in Poland.\n\nInterbellum, Poland was unofficially divided into two parts – better developed \"Poland A\" in the west, and underdeveloped \"Poland B\" in the east. Polish industry was concentrated in the west, mostly in Polish Upper Silesia, and the adjacent Lesser Poland's province of Zagłębie Dąbrowskie, where the bulk of coal mines and steel plants was located. Furthermore, heavy industry plants were located in Częstochowa (\"Huta Częstochowa\", founded in 1896), Ostrowiec Świętokrzyski (\"Huta Ostrowiec\", founded in 1837–1839), Stalowa Wola (brand new industrial city, which was built from scratch in 1937 – 1938), Chrzanów (\"Fablok\", founded in 1919), Jaworzno, Trzebinia (oil refinery, opened in 1895), Łódź (the seat of Polish textile industry), Poznań (H. Cegielski – Poznań), Kraków and Warsaw (Ursus Factory). Further east, in Kresy, industrial centers included two major cities of the region – Lwów and Wilno (Elektrit).\n\nBesides coal mining, Poland also had deposits of oil in Borysław, Drohobycz, Jasło and Gorlice (see Polmin), potassium salt (TESP), and basalt (Janowa Dolina). Apart from already-existing industrial areas, in the mid-1930s, an ambitious, state-sponsored project of Central Industrial Region was started under Minister Eugeniusz Kwiatkowski. One of characteristic features of Polish economy in the interbellum was gradual nationalization of major plants. This was the case of Ursus Factory (see Państwowe Zakłady Inżynieryjne), and several steelworks, such as \"Huta Pokój\" in Ruda Śląska – Nowy Bytom, \"Huta Królewska\" in Chorzów – Królewska Huta, \"Huta Laura\" in Siemianowice Śląskie, as well as \"Scheibler and Grohman Works\" in Łódź.\n\nAccording to the 1939 Statistical Yearbook of Poland, total length of railways of Poland (as for 31 December 1937) was . Rail density was per . Railways were very dense in western part of the country, while in the east, especially Polesie, rail was non-existent in some counties. During the interbellum period, the Polish government constructed several new lines, mainly in the central part of the country (see also Polish State Railroads Summer 1939). Construction of extensive Warszawa Główna railway station was never finished due to the war, and Polish railroads were famous for their punctuality (see Luxtorpeda, Strzała Bałtyku, Latający Wilnianin).\n\nIn the interbellum, road network of Poland was dense, but the quality of the roads was very poor – only 7% of all roads was paved and ready for automobile use, and none of the major cities were connected with each other by a good-quality highway. Poles built in 1939 only one highway, 28 km of straight concrete road connecting villages Warlubie and Osiek (mid-northern Poland). It was designed by Italian engineer Piero Puricelli.\nIn the mid-1930s, Poland had of roads, but only 58,000 had hard surface (gravel, cobblestone or sett), and 2,500 were modern, with asphalt or concrete surface. In different parts of the country, there were sections of paved roads, which suddenly ended, and were followed by dirt roads. The poor condition of the roads was the result of both long-lasting foreign dominance and inadequate funding. On 29 January 1931, the Polish Parliament created the State Road Fund, the purpose of which was to collect money for the construction and conservation of roads. The government drafted a 10-year plan, with road priorities: a highway from Wilno, through Warsaw and Cracow, to Zakopane (called Marshall Pilsudski Highway), asphalt highways from Warsaw to Poznań and Łódź, as well as a Warsaw ring road. However, the plan turned out to be too ambitious, with insufficient money in the national budget to pay for it. In January 1938, the Polish Road Congress estimated that Poland would need to spend three times as much money on roads to keep up with Western Europe.\n\nIn 1939, before the outbreak of the war, LOT Polish Airlines, which was established in 1929, had its hub at Warsaw Okęcie Airport. At that time, LOT maintained several services, both domestic and international. Warsaw had regular domestic connections with Gdynia-Rumia, Danzig-Langfuhr, Katowice-Muchowiec, Kraków-Rakowice-Czyżyny, Lwów-Skniłów, Poznań-Ławica, and Wilno-Porubanek. Furthermore, in cooperation with Air France, LARES, Lufthansa, and Malert, international connections were maintained with Athens, Beirut, Berlin, Bucharest, Budapest, Helsinki, Kaunas, London, Paris, Prague, Riga, Rome, Tallinn, and Zagreb.\n\nStatistically, the majority of citizens lived in the countryside (75% in 1921). Farmers made up 65% of the population. In 1929, agricultural production made up 65% of Poland's GNP. After 123 years of partitions, regions of the country were very unevenly developed. Lands of former German Empire were most advanced; in Greater Poland and Pomerelia, crops were on Western European level. The situation was much worse in parts of Congress Poland, Eastern Borderlands, and former Galicia, where agriculture was most backward and primitive, with a large number of small farms, unable to succeed in either the domestic and international market. Another problem was the overpopulation of the countryside, which resulted in chronic unemployment. Living conditions were so bad that in several regions, such as counties inhabited by the Hutsuls, there was permanent starvation. Farmers rebelled against the government (see: 1937 peasant strike in Poland), and the situation began to change in the late 1930s, due to construction of several factories for the Central Industrial Region, which gave employment to thousands of countryside residents.\n\nBeginning in June 1925 there was a customs' war with the revanchist Weimar Republic imposing trade embargo against Poland for nearly a decade; involving tariffs, and broad economic restrictions. After 1933 the trade war ended. The new agreements regulated and promoted trade. Germany became Poland's largest trading partner, followed by Britain. In October 1938 Germany granted a credit of Rm 60,000,000 to Poland (120,000,000 zloty, or £4,800,000) which was never realized, due to the outbreak of war. Germany would deliver factory equipment and machinery in return for Polish timber and agricultural produce. This new trade was to be \"in addition\" to the existing German-Polish trade agreements.\n\nIn 1919, the Polish government introduced compulsory education for all children aged 7 to 14, in an effort to limit illiteracy, which was widespread especially in the former Russian Partition and the Austrian Partition of eastern Poland. In 1921, one-third of citizens of Poland remained illiterate (38% in the countryside). The process was slow, but by 1931, the illiteracy level had dropped to 23% overall (27% in the countryside) and further down to 18% in 1937. By 1939, over 90% of children attended school. In 1932, Minister of Religion and Education Janusz Jędrzejewicz carried out a major reform which introduced two main levels of education: \"common school\" (\"szkoła powszechna\"), with three levels – 4 grades + 2 grades + 1 grade; and \"middle school\" (\"szkoła średnia\"), with two levels – 4 grades of comprehensive middle school and 2 grades of specified high school (classical, humanistic, natural and mathematical). A graduate of middle school received a \"small matura\", while a graduate of high school received a \"big matura\", which enabled them to seek university-level education.\n\nBefore 1918, Poland had three universities: Jagiellonian University, University of Warsaw and Lwów University. Catholic University of Lublin was established in 1918; Adam Mickiewicz University, Poznań, in 1919; and finally, in 1922, after the annexation of Republic of Central Lithuania, Wilno University became the Republic's sixth university. There were also three technical colleges: the Warsaw University of Technology, Lwów Polytechnic and the AGH University of Science and Technology in Kraków, established in 1919. Warsaw University of Life Sciences was an agricultural institute. By 1939, there were around 50,000 students enrolled in further education. Women made up 28% of university students, the second highest proportion in Europe.\nPolish science in the interbellum was renowned for its mathematicians gathered around the Lwów School of Mathematics, the Kraków School of Mathematics, as well as Warsaw School of Mathematics. There were world-class philosophers in the Lwów–Warsaw school of logic and philosophy. Florian Znaniecki founded Polish sociological studies. Rudolf Weigl invented a vaccine against typhus. Bronisław Malinowski counted among the most important anthropologists of the 20th century. In Polish literature, the 1920s were marked by the domination of poetry. Polish poets were divided into two groups – the Skamanderites (Jan Lechoń, Julian Tuwim, Antoni Słonimski and Jarosław Iwaszkiewicz) and the Futurists (Anatol Stern, Bruno Jasieński, Aleksander Wat, Julian Przyboś). Apart from well-established novelists (Stefan Żeromski, Władysław Reymont), new names appeared in the interbellum – Zofia Nałkowska, Maria Dąbrowska, Jarosław Iwaszkiewicz, Jan Parandowski, Bruno Schultz, Stanisław Ignacy Witkiewicz, Witold Gombrowicz. Among other notable artists there were sculptor Xawery Dunikowski, painters Julian Fałat, Wojciech Kossak and Jacek Malczewski, composers Karol Szymanowski, Feliks Nowowiejski, and Artur Rubinstein, singer Jan Kiepura. Theatre was very popular in the interbellum, with three main centers in the cities of Warsaw, Wilno and Lwów. Altogether, there were 103 theaters in Poland and a number of other theatrical institutions (including 100 folk theaters). In 1936, different shows were seen by 5 million people, and main figures of Polish theatre of the time were Juliusz Osterwa, Stefan Jaracz, and Leon Schiller. Also, before the outbreak of the war, there were about a million radios (see Radio stations in interwar Poland).\n\nThe administrative division of the Republic was based on a three-tier system. On the lowest rung were the \"gminy\", local town and village governments akin to districts or parishes. These were then grouped together into \"powiaty\" (akin to counties), which, in turn, were grouped as \"województwa\" (voivodeships, akin to provinces).\n\nHistorically, Poland was a nation of many nationalities. This was especially true after independence was regained in the wake of World War I and the subsequent Polish–Soviet War ending at Peace of Riga. The census of 1921 shows 30.8% of the population consisted of ethnic minorities, compared with a share of 1.6% (solely identifying with a non-Polish ethnic group) or 3.8% (including those identifying with both the Polish ethnicity and with another ethnic group) in 2011. The first spontaneous flight of about 500,000 Poles from the Soviet Union occurred during the reconstitution of sovereign Poland. In the second wave, between November 1919 and June 1924 some 1,200,000 people left the territory of the USSR for Poland. It is estimated that some 460,000 of them spoke Polish as the first language. According to the 1931 Polish Census: 68.9% of the population was Polish, 13.9% were Ukrainian, around 10% Jewish, 3.1% Belarusian, 2.3% German and 2.8% other, including Lithuanian, Czech, Armenian, Russian, and Romani. The situation of minorities was a complex subject and changed during the period.\nPoland was also a nation of many religions. In 1921, 16,057,229 Poles (approx. 62.5%) were Roman (Latin) Catholics, 3,031,057 citizens of Poland (approx. 11.8%) were Eastern Rite Catholics (mostly Ukrainian Greek Catholics and Armenian Rite Catholics), 2,815,817 (approx. 10.95%) were Greek Orthodox, 2,771,949 (approx. 10.8%) were Jewish, and 940,232 (approx. 3.7%) were Protestants (mostly Lutheran).\n\nBy 1931, Poland had the second largest Jewish population in the world, with one-fifth of all the world's Jews residing within its borders (approx. 3,136,000). The urban population of interbellum Poland was rising steadily; in 1921, only 24% of Poles lived in the cities, in the late 1930s, that proportion grew to 30%. In more than a decade, the population of Warsaw grew by 200,000, Łódź by 150,000, and Poznań – by 100,000. This was due not only to internal migration, but also to an extremely high birth rate.\n\nThe Second Polish Republic was mainly flat with average elevation of above sea level, except for the southernmost Carpathian Mountains (after World War II and its border changes, the average elevation of Poland decreased to ). Only 13% of territory, along the southern border, was higher than . The highest elevation in the country was Mount Rysy, which rises in the Tatra Range of the Carpathians, approximately south of Kraków. Between October 1938 and September 1939, the highest elevation was Lodowy Szczyt (known in the Slovak language as \"Ľadový štít\"), which rises above sea level. The largest lake was Lake Narach.\nThe country's total area, after the annexation of Zaolzie, was . It extended from north to south and from east to west. On 1 January 1938, total length of boundaries was , including: of coastline (out of which were made by the Hel Peninsula), the with Soviet Union, 948 kilometers with Czechoslovakia (until 1938), with Germany (together with East Prussia), and with other countries (Lithuania, Romania, Latvia, Danzig). The warmest yearly average temperature was in Kraków among major cities of the Second Polish Republic, at in 1938; and the coldest in Wilno ( in 1938). Extreme geographical points of Poland included Przeświata River in Somino to the north (located in the Braslaw county of the Wilno Voivodeship); Manczin River to the south (located in the Kosów county of the Stanisławów Voivodeship); Spasibiorki near railway to Połock to the east (located in the Dzisna county of the Wilno Voivodeship); and Mukocinek near Warta River and Meszyn Lake to the west (located in the Międzychód county of the Poznań Voivodeship).\n\nAlmost 75% of the territory of interbellum Poland was drained northward into the Baltic Sea by the Vistula (total area of drainage basin of the Vistula within boundaries of the Second Polish Republic was , the Niemen (), the Odra () and the Daugava (). The remaining part of the country was drained southward, into the Black Sea, by the rivers that drain into the Dnieper (Pripyat, Horyn and Styr, all together ) as well as Dniester ()\n\nThe Second World War in 1939 ended the sovereign Second Polish Republic. The German invasion of Poland began on 1 September 1939, one week after Nazi Germany and the Soviet Union signed the secret Molotov–Ribbentrop Pact. On that day, Germany and Slovakia attacked Poland, and on 17 September the Soviets attacked eastern Poland. Warsaw fell to the Nazis on 28 September after a twenty-day siege. Open organized Polish resistance ended on 6 October 1939 after the Battle of Kock, with Germany and the Soviet Union occupying most of the country. Lithuania annexed the area of Wilno, and Slovakia seized areas along Poland's southern border - including Górna Orawa and Tatranská Javorina - which Poland had annexed from Czechoslovakia in October 1938. Poland did not surrender to the invaders, but continued fighting under the auspices of the Polish government-in-exile and of the Polish Underground State. After the signing of the German–Soviet Treaty of Friendship, Cooperation and Demarcation on 28 September 1939, Polish areas occupied by Nazi Germany either became directly annexed to the Third Reich, or became part of the so-called General Government. The Soviet Union, following Elections to the People's Assemblies of Western Ukraine and Western Belarus (22 October 1939), annexed eastern Poland partly to the Byelorussian Soviet Socialist Republic, and partly to the Ukrainian Soviet Socialist Republic (November 1939).\nPolish war plans (Plan West and Plan East) failed as soon as Germany invaded in 1939. The Polish losses in combat against Germans (killed and missing in action) amounted to ca. 70,000 men. Some 420,000 of them were taken prisoners. Losses against the Red Army (which invaded Poland on 17 September) added up to 6,000 to 7,000 of casualties and MIA, 250,000 were taken prisoners. Although the Polish army – considering the inactivity of the Allies – was in an unfavorable position – it managed to inflict serious losses to the enemies: 14,000 German soldiers were killed or MIA, 674 tanks and 319 armored vehicles destroyed or badly damaged, 230 aircraft shot down; the Red Army lost (killed and MIA) about 2,500 soldiers, 150 combat vehicles and 20 aircraft. The Soviet invasion of Poland, and lack of promised aid from the Western Allies, contributed to the Polish forces defeat by 6 October 1939.\nA popular myth is that Polish cavalry armed with lances charged German tanks during the September 1939 campaign. This often repeated account, first reported by Italian journalists as German propaganda, concerned an action by the Polish 18th Lancer Regiment near Chojnice. This arose from misreporting of a single clash on 1 September 1939 near Krojanty, when two squadrons of the Polish 18th Lancers armed with sabers surprised and wiped out a German infantry formation with a mounted sabre charge. Shortly after midnight the 2nd (Motorized) Division was compelled to withdraw by Polish cavalry, before the Poles were caught in the open by German armored cars. The story arose because some German armored cars appeared and gunned down 20 troopers as the cavalry escaped. Even this failed to persuade everyone to reexamine their beliefs—there were some who thought Polish cavalry had been improperly employed in 1939.\n\nBetween 1939 and 1990, the Polish government-in-exile operated in Paris and later in London, presenting itself as the only legal and legitimate representative of the Polish nation. In 1990 the last president in exile, Ryszard Kaczorowski handed the presidential insignia to the newly elected President, Lech Wałęsa, signifying continuity between the Second and Third republics.\n\n\n\n\n\n\n\n"}
{"id": "14246", "url": "https://en.wikipedia.org/wiki?curid=14246", "title": "Hedwig", "text": "Hedwig\n\nHedwig may refer to:\n\n\n\n\n\n"}
{"id": "14251", "url": "https://en.wikipedia.org/wiki?curid=14251", "title": "HMS Resolution", "text": "HMS Resolution\n\nSeveral ships of the Royal Navy have borne the name HMS \"Resolution\". However, the first English warship to bear the name \"Resolution\" was actually the first rate \"Prince Royal\" (built in 1610 and rebuilt in 1641), which was renamed \"Resolution\" in 1650 following the inauguration of the Commonwealth, and continued to bear that name until 1660, when the name \"Prince Royal\" was restored. The name \"Resolution\" was bestowed on the first of the vessels listed below:\n\n\nAlso\n\n\nCitations\n\nReferences\n"}
{"id": "14254", "url": "https://en.wikipedia.org/wiki?curid=14254", "title": "Helen Keller", "text": "Helen Keller\n\nHelen Adams Keller (June 27, 1880 – June 1, 1968) was an American author, political activist, and lecturer. She was the first deaf-blind person to earn a bachelor of arts degree. The story of Keller and her teacher, Anne Sullivan, was made famous by Keller's autobiography, \"The Story of My Life\", and its adaptations for film and stage, \"The Miracle Worker\". Her birthplace in West Tuscumbia, Alabama, is now a museum and sponsors an annual \"Helen Keller Day\". Her June 27 birthday is commemorated as Helen Keller Day in Pennsylvania and, in the centenary year of her birth, was recognized by a presidential proclamation from Jimmy Carter.\n\nA prolific author, Keller was well-traveled and outspoken in her convictions. A member of the Socialist Party of America and the Industrial Workers of the World, she campaigned for women's suffrage, labor rights, socialism, antimilitarism, and other similar causes. She was inducted into the Alabama Women's Hall of Fame in 1971 and was one of twelve inaugural inductees to the Alabama Writers Hall of Fame on June 8, 2015.\n\nHelen Adams Keller was born on June 27, 1880, in Tuscumbia, Alabama. Her family lived on a homestead, Ivy Green, that Helen's grandfather had built decades earlier. She had four siblings; two full siblings, Mildred Campbell (Keller) Tyson and Phillip Brooks Keller, and two older half-brothers from her father's prior marriage, James McDonald Keller and William Simpson Keller.\n\nHer father, Arthur Henley Keller (1836–1896), spent many years as an editor of the Tuscumbia \"North Alabamian\" and had served as a captain in the Confederate Army. Her mother, Catherine Everett (Adams) Keller (1856–1921), known as \"Kate\", was the daughter of Charles W. Adams, a Confederate general. Her paternal lineage was traced to Casper Keller, a native of Switzerland. One of Helen's Swiss ancestors was the first teacher for the deaf in Zurich. Keller reflected on this coincidence in her first autobiography, stating \"that there is no king who has not had a slave among his ancestors, and no slave who has not had a king among his.\"\n\nAt 19 months old Keller contracted an unknown illness described by doctors as \"an acute congestion of the stomach and the brain\", which might have been scarlet fever or meningitis. The illness left her both deaf and blind. She lived, as she recalled in her autobiography, \"at sea in a dense fog.\" \n\nAt that time, Keller was able to communicate somewhat with Martha Washington, the six-year-old daughter of the family cook, who understood her signs; by the age of seven, Keller had more than 60 home signs to communicate with her family. Even though blind and deaf, Helen Keller had passed through many obstacles and she learned to live with her disabilities. She learned how to tell which person was walking from the vibrations of their footsteps.\n\nIn 1886, Keller's mother, inspired by an account in Charles Dickens' \"American Notes\" of the successful education of another deaf and blind woman, Laura Bridgman, dispatched the young Keller, accompanied by her father, to seek out physician J. Julian Chisolm, an eye, ear, nose, and throat specialist in Baltimore, for advice. Chisholm referred the Kellers to Alexander Graham Bell, who was working with deaf children at the time. Bell advised them to contact the Perkins Institute for the Blind, the school where Bridgman had been educated, which was then located in South Boston. Michael Anagnos, the school's director, asked 20-year-old former student Anne Sullivan, herself visually impaired, to become Keller's instructor. It was the beginning of a 49-year-long relationship during which Sullivan evolved into Keller's governess and eventually her companion.\n\nSullivan arrived at Keller's house on March 5, 1887, a day Keller would forever remember as \"my soul's birthday.\" Sullivan immediately began to teach Helen to communicate by spelling words into her hand, beginning with \"d-o-l-l\" for the doll that she had brought Keller as a present. Keller was frustrated, at first, because she did not understand that every object had a word uniquely identifying it. In fact, when Sullivan was trying to teach Keller the word for \"mug\", Keller became so frustrated she broke the mug. Keller's breakthrough in communication came the next month, when she realized that the motions her teacher was making on the palm of her hand, while running cool water over her other hand, symbolized the idea of \"water\". Writing in her autobiography, \"The Story of My Life,\" Keller recalled the moment. \"I stood still, my whole attention fixed upon the motions of her fingers. Suddenly I felt a misty consciousness as of something forgotten — a thrill of returning thought; and somehow the mystery of language was revealed to me. I knew then that w-a-t-e-r meant the wonderful cool something that was flowing over my hand. The living word awakened my soul, gave it light, hope, set it free!\" Keller then nearly exhausted Sullivan demanding the names of all the other familiar objects in her world.\n\nHelen Keller was viewed as isolated but was very in touch with the outside world. She was able to enjoy music by feeling the beat and she was able to have a strong connection with animals through touch. She was delayed at picking up language, but that did not stop her from having a voice.\n\nIn May 1888, Keller started attending the Perkins Institute for the Blind. In 1894, Keller and Sullivan moved to New York to attend the Wright-Humason School for the Deaf, and to learn from Sarah Fuller at the Horace Mann School for the Deaf. In 1896, they returned to Massachusetts, and Keller entered The Cambridge School for Young Ladies before gaining admittance, in 1900, to Radcliffe College of Harvard University where she lived in Briggs Hall, South House. Her admirer, Mark Twain, had introduced her to Standard Oil magnate Henry Huttleston Rogers, who, with his wife Abbie, paid for her education. In 1904, at the age of 24, Keller graduated from Radcliffe, becoming the first deaf-blind person to earn a Bachelor of Arts degree. She maintained a correspondence with the Austrian philosopher and pedagogue Wilhelm Jerusalem, who was one of the first to discover her literary talent.\n\nDetermined to communicate with others as conventionally as possible, Keller learned to speak and spent much of her life giving speeches and lectures on aspects of her life. She learned to \"hear\" people's speech by reading their lips with her hands—her sense of touch had heightened. She became proficient at using braille and reading sign language with her hands as well. Shortly before World War I, with the assistance of the Zoellner Quartet, she determined that by placing her fingertips on a resonant tabletop she could experience music played close by.\n\nOn January 22, 1916, Keller and Sullivan traveled to the small town of Menomonie in western Wisconsin to deliver a lecture at the Mabel Tainter Memorial Building. Details of her talk were provided in the weekly \"Dunn County News\" on January 22, 1916:\nA message of optimism, of hope, of good cheer, and of loving service was brought to Menomonie Saturday—a message that will linger long with those fortunate enough to have received it. This message came with the visit of Helen Keller and her teacher, Mrs. John Macy, and both had a hand in imparting it Saturday evening to a splendid audience that filled The Memorial. The wonderful girl who has so brilliantly triumphed over the triple afflictions of blindness, dumbness and deafness, gave a talk with her own lips on \"Happiness,\" and it will be remembered always as a piece of inspired teaching by those who heard it.\n\nWhen part of the account was reprinted in the January 20, 2016, edition of the paper under the heading \"From the Files\", the column compiler added\n\nAccording to those who attended, Helen Keller spoke of the joy that life gave her. She was thankful for the faculties and abilities that she did possess and stated that the most productive pleasures she had were curiosity and imagination. Keller also spoke of the joy of service and the happiness that came from doing things for others ... Keller imparted that \"helping your fellow men were one's only excuse for being in this world and in the doing of things to help one's fellows lay the secret of lasting happiness.\" She also told of the joys of loving work and accomplishment and the happiness of achievement. Although the entire lecture lasted only a little over an hour, the lecture had a profound impact on the audience.\n\nAnne Sullivan stayed as a companion to Helen Keller long after she taught her. Sullivan married John Macy in 1905, and her health started failing around 1914. Polly Thomson (February 20, 1885 – March 21, 1960) was hired to keep house. She was a young woman from Scotland who had no experience with deaf or blind people. She progressed to working as a secretary as well, and eventually became a constant companion to Keller.\n\nKeller moved to Forest Hills, Queens, together with Sullivan and Macy, and used the house as a base for her efforts on behalf of the American Foundation for the Blind. \"While in her thirties Helen had a love affair, became secretly engaged, and defied her teacher and family by attempting an elopement with the man she loved.\" He was \"Peter Fagan, a young Boston Herald reporter who was sent to Helen's home to act as her private secretary when lifelong companion, Anne, fell ill.\"\n\nAnne Sullivan died in 1936 after a coma as a result of coronary thrombosis, with Keller holding her hand. Keller and Thomson moved to Connecticut. They traveled worldwide and raised funds for the blind. Thomson had a stroke in 1957 from which she never fully recovered, and died in 1960. Winnie Corbally, a nurse whom they originally hired to care for Thomson in 1957, stayed on after her death and was Keller's companion for the rest of her life.\n\nKeller went on to become a world-famous speaker and author. She is remembered as an advocate for people with disabilities, amid numerous other causes. The Deaf community was widely impacted by her. She traveled to twenty-five different countries giving motivational speeches about Deaf people's conditions. She was a suffragette, pacifist, radical socialist, birth control supporter, and opponent of Woodrow Wilson. In 1915 she and George A. Kessler founded the Helen Keller International (HKI) organization. This organization is devoted to research in vision, health and nutrition. In 1920, she helped to found the American Civil Liberties Union (ACLU). Keller traveled to over 40 countries with Sullivan, making several trips to Japan and becoming a favorite of the Japanese people. Keller met every U.S. President from Grover Cleveland to Lyndon B. Johnson and was friends with many famous figures, including Alexander Graham Bell, Charlie Chaplin and Mark Twain. Keller and Twain were both considered radicals at the beginning of the 20th century, and as a consequence, their political views have been forgotten or glossed over in the popular mind.\n\nKeller was a member of the Socialist Party and actively campaigned and wrote in support of the working class from 1909 to 1921. Many of her speeches and writings were about women's right to vote and the impacts of war; in addition, she supported causes that opposed military intervention. She had speech therapy in order to have her voice heard better by the public. When the Rockefeller-owned press refused to print her articles, she protested until her work was finally published. She supported Socialist Party candidate Eugene V. Debs in each of his campaigns for the presidency. Before reading \"Progress and Poverty\", Helen Keller was already a socialist who believed that Georgism was a good step in the right direction. She later wrote of finding \"in Henry George's philosophy a rare beauty and power of inspiration, and a splendid faith in the essential nobility of human nature.\"\n\nKeller claimed that newspaper columnists who had praised her courage and intelligence before she expressed her socialist views now called attention to her disabilities. The editor of the \"Brooklyn Eagle\" wrote that her \"mistakes sprung out of the manifest limitations of her development.\" Keller responded to that editor, referring to having met him before he knew of her political views:\n\nKeller joined the Industrial Workers of the World (the IWW, known as the Wobblies) in 1912, saying that parliamentary socialism was \"sinking in the political bog\". She wrote for the IWW between 1916 and 1918. In \"Why I Became an IWW\", Keller explained that her motivation for activism came in part from her concern about blindness and other disabilities:\n\nThe last sentence refers to prostitution and syphilis, the former a frequent cause of the latter, and the latter a leading cause of blindness. In the same interview, Keller also cited the 1912 strike of textile workers in Lawrence, Massachusetts for instigating her support of socialism.\n\nKeller supported eugenics. In 1915 she wrote in favor of refusing life-saving medical procedures to infants with severe mental impairments or physical deformities, stating that their lives were not worthwhile and they would likely become criminals. Keller also expressed concerns about human overpopulation.\n\nKeller wrote a total of 12 published books and several articles.\n\nOne of her earliest pieces of writing, at age 11, was \"The Frost King\" (1891). There were allegations that this story had been plagiarized from \"The Frost Fairies\" by Margaret Canby. An investigation into the matter revealed that Keller may have experienced a case of cryptomnesia, which was that she had Canby's story read to her but forgot about it, while the memory remained in her subconscious.\n\nAt age 22, Keller published her autobiography, \"The Story of My Life\" (1903), with help from Sullivan and Sullivan's husband, John Macy. It recounts the story of her life up to age 21 and was written during her time in college.\n\nKeller wrote \"The World I Live In\" in 1908, giving readers an insight into how she felt about the world. \"Out of the Dark\", a series of essays on socialism, was published in 1913.\n\nWhen Keller was young, Anne Sullivan introduced her to Phillips Brooks, who introduced her to Christianity, Keller famously saying: \"I always knew He was there, but I didn't know His name!\"\n\nHer spiritual autobiography, \"My Religion\", was published in 1927 and then in 1994 extensively revised and re-issued under the title \"Light in My Darkness\". It advocates the teachings of Emanuel Swedenborg, the Christian revelator and theologian who gives a spiritual interpretation of the teachings of the Bible and who claims that the second coming of Jesus Christ has already taken place. Adherents use several names to describe themselves, including Second Advent Christian, Swedenborgian, and New Church.\n\nKeller described the core of her belief in these words:\n\nBut in Swedenborg's teaching it [Divine Providence] is shown to be the government of God's Love and Wisdom and the creation of uses. Since His Life cannot be less in one being than another, or His Love manifested less fully in one thing than another, His Providence must needs be universal ... He has provided religion of some kind everywhere, and it does not matter to what race or creed anyone belongs if he is faithful to his ideals of right living.\n\nKeller visited 35 countries from 1946 to 1957.\n\nIn 1948 she went to New Zealand and visited deaf schools in Christchurch and Auckland. She met Deaf Society of Canterbury Life Member Patty Still in Christchurch.\n\nKeller suffered a series of strokes in 1961 and spent the last years of her life at her home.\n\nOn September 14, 1964, President Lyndon B. Johnson awarded her the Presidential Medal of Freedom, one of the United States' two highest civilian honors. In 1965 she was elected to the National Women's Hall of Fame at the New York World's Fair.\n\nKeller devoted much of her later life to raising funds for the American Foundation for the Blind. She died in her sleep on June 1, 1968, at her home, Arcan Ridge, located in Easton, Connecticut, a few weeks short of her eighty-eighth birthday. A service was held in her honor at the National Cathedral in Washington, D.C., her body was cremated and her ashes were placed there next to her constant companions, Anne Sullivan and Polly Thomson. She was buried at the Washington National Cathedral in Washington, D.C.\n\nKeller's life has been interpreted many times. She appeared in a silent film, \"Deliverance\" (1919), which told her story in a melodramatic, allegorical style.\n\nShe was also the subject of the documentaries \"Helen Keller in Her Story\", narrated by Katharine Cornell, and \"The Story of Helen Keller\", part of the Famous Americans series produced by Hearst Entertainment.\n\n\"The Miracle Worker\" is a cycle of dramatic works ultimately derived from her autobiography, \"The Story of My Life\". The various dramas each describe the relationship between Keller and Sullivan, depicting how the teacher led her from a state of almost feral wildness into education, activism, and intellectual celebrity. The common title of the cycle echoes Mark Twain's description of Sullivan as a \"miracle worker.\" Its first realization was the 1957 \"Playhouse 90\" teleplay of that title by William Gibson. He adapted it for a Broadway production in 1959 and an Oscar-winning feature film in 1962, starring Anne Bancroft and Patty Duke. It was remade for television in 1979 and 2000.\n\nIn 1984, Keller's life story was made into a TV movie called \"The Miracle Continues\". This film, a semi-sequel to \"The Miracle Worker\", recounts her college years and her early adult life. None of the early movies hint at the social activism that would become the hallmark of Keller's later life, although a Disney version produced in 2000 states in the credits that she became an activist for social equality.\n\nThe Bollywood movie \"Black\" (2005) was largely based on Keller's story, from her childhood to her graduation.\n\nA documentary called \"Shining Soul: Helen Keller's Spiritual Life and Legacy\" was produced by the Swedenborg Foundation in the same year. The film focuses on the role played by Emanuel Swedenborg's spiritual theology in her life and how it inspired Keller's triumph over her triple disabilities of blindness, deafness and a severe speech impediment.\n\nOn March 6, 2008, the New England Historic Genealogical Society announced that a staff member had discovered a rare 1888 photograph showing Helen and Anne, which, although previously published, had escaped widespread attention. Depicting Helen holding one of her many dolls, it is believed to be the earliest surviving photograph of Anne Sullivan Macy.\n\nVideo footage showing Helen Keller learning to mimic speech sounds also exists.\n\nA biography of Helen Keller was written by the German Jewish author H.J.Kaeser.\n\nA painting titled \"The Advocate: Tribute to Helen Keller\" was created by three artists from Kerala as a tribute to Helen Keller. The Painting was created in association with a non-profit organization Art d'Hope Foundation, artists groups Palette People and XakBoX Design & Art Studio. This painting was created for a fundraising event to help blind students in India and was inaugurated by M. G. Rajamanikyam, IAS (District Collector Ernakulam) on Helen Keller day (June 27, 2016). The painting depicts the major events of Helen Keller's life and is one of the biggest paintings done based on Helen Keller's life.\n\nA preschool for the deaf and hard of hearing in Mysore, India, was originally named after Helen Keller by its founder, K. K. Srinivasan.\nIn 1999, Keller was listed in Gallup's Most Widely Admired People of the 20th century.\n\nIn 2003, Alabama honored its native daughter on its state quarter. The Alabama state quarter is the only circulating U.S. coin to feature braille.\n\nThe Helen Keller Hospital in Sheffield, Alabama, is dedicated to her.\n\nStreets are named after Helen Keller in Zürich, Switzerland, in the US, in Getafe, Spain, in Lod, Israel, in Lisbon, Portugal, and in Caen, France.\n\nIn 1973, Helen Keller was inducted into the National Women's Hall of Fame.\n\nA stamp was issued in 1980 by the United States Postal Service depicting Keller and Sullivan, to mark the centennial of Keller's birth.\n\nOn October 7, 2009, a bronze statue of Keller was added to the National Statuary Hall Collection, as a replacement for the State of Alabama's former 1908 statue of the education reformer Jabez Lamar Monroe Curry.\n\nArchival material of Helen Keller stored in New York was lost when the Twin Towers were destroyed in the September 11 attacks.\n\nThe Helen Keller Archives are owned by the American Foundation for the Blind.\n\n\n\n\n\n"}
{"id": "14257", "url": "https://en.wikipedia.org/wiki?curid=14257", "title": "Haddocks' Eyes", "text": "Haddocks' Eyes\n\nHaddocks' Eyes is a term for the name of a song sung by The White Knight from Lewis Carroll's \"Through the Looking-Glass\", . \n\n\"Haddocks' Eyes\" is an example used to elaborate on the symbolic status of the concept of \"name\": a name as identification marker may be assigned to anything, including another name, thus introducing different levels of symbolization. It was discussed in several works on logic and philosophy.\n\nThe White Knight explains to Alice a confusing nomenclature for the song.\n\n\nThe complicated terminology distinguishing between 'the song, what the song is called, the name of the song, and what the name of the song is called' both uses and mentions the use–mention distinction.\n\nThe White Knight sings the song to a tune he claims as his own invention, but which Alice recognises as \"I give thee all, I can no more\". By the time Alice heard it, she was already tired of poetry.\n\nThe song parodies the plot, but not the style or metre, of \"Resolution and Independence\" by William Wordsworth.\n\nLike \"Jabberwocky,\" another poem published in \"Through the Looking Glass,\" \"Haddocks’ Eyes\" appears to have been revised over the course of many years. In 1856, Carroll published the following poem anonymously under the name \"Upon the Lonely Moor\". It bears an obvious resemblance to \"Haddocks' Eyes.\"\n\n"}
{"id": "14260", "url": "https://en.wikipedia.org/wiki?curid=14260", "title": "Hoosier", "text": "Hoosier\n\nHoosier is the official demonym for a resident of the U.S. state of Indiana. The origin of the term remains a matter of debate within the state, but \"Hoosier\" was in general use by the 1840s, having been popularized by Richmond resident John Finley's 1833 poem \"The Hoosier's Nest\". Anyone born in Indiana or a resident at the time is considered to be a Hoosier. Indiana adopted the nickname \"The Hoosier State\" more than 150 years ago.\n\n\"Hoosier\" is used in the names of numerous Indiana-based businesses and organizations. \"Hoosiers\" is also the name of the Indiana University athletic teams and seven active and one disbanded athletic conferences in the Indiana High School Athletic Association have the word \"Hoosier\" in their name. As there is no accepted embodiment of a Hoosier, the IU schools are represented through their letters and colors alone. In addition to general acceptance by residents of Indiana, the term is also the official demonym according to the U.S. Government Publishing Office.\nOn January 12, 2017, the Federal Government officially changed the nickname of people from the state of Indiana from \"Indianans\" to \"Hoosiers\", making Indiana the first state not to have a version of its state name in its nickname (\"Illinoisans\", \"Texans\", etc.).\n\nIn addition to \"The Hoosier's Nest\", the term also appeared in the \"Indianapolis Journal\"<nowiki>'</nowiki>s \"Carrier's Address\" on January 1, 1833. There are many suggestions for the derivation of the word, but none is universally accepted.\n\nIn 1900, Meredith Nicholson wrote \"The Hoosiers\", an early attempt to study the etymology of the word as applied to Indiana residents. Jacob Piatt Dunn, longtime secretary of the Indiana Historical Society, published \"The Word Hoosier\", a similar attempt, in 1907. Both chronicled some of the popular and satirical etymologies circulating at the time and focused much of their attention on the use of the word in the Upland South to refer to woodsmen, yokels, and rough people. Dunn traced the word back to the Cumbrian \"hoozer\", meaning anything unusually large, derived from the Old English \"hoo\" (as at Sutton Hoo), meaning \"high\" and \"hill\". The importance of immigrants from northern England and southern Scotland was reflected in numerous placenames including the Cumberland Mountains, the Cumberland River, and the Cumberland Gap. Nicholson defended the people of Indiana against such an association, while Dunn concluded that the early settlers had adopted the nickname self-mockingly and that it had lost its negative associations by the time of Finley's poem.\n\nJohnathan Clark Smith subsequently showed that Nicholson and Dunn's earliest sources within Indiana were mistaken. A letter by James Curtis cited by Dunn and others as the earliest known use of the term was actually written in 1846, not 1826. Similarly, the use of the term in an 1859 newspaper item quoting an 1827 diary entry by Sandford Cox was more likely an editorial comment and not from the original diary. Smith's earliest sources led him to argue that the word originated as a term along the Ohio River for flatboatmen from Indiana and did not acquire its pejorative meanings until 1836, \"after\" Finley's poem.\nWilliam Piersen, a history professor at Fisk University, argued for a connection to the black Methodist minister Rev. Harry Hosier (–May 1806), who evangelized the American frontier at the beginning of the 19th century as part of the Second Great Awakening. \"Black Harry\" had been born a slave in North Carolina and sold north to Baltimore, Maryland, before gaining his freedom and beginning his ministry around the end of the American Revolution. He was a close associate and personal friend of Bishop Francis Asbury, the \"Father of the American Methodist Church\". Dr. Benjamin Rush said that, \"making allowances for his illiteracy, he was the greatest orator in America\" and his sermons called on Methodists to reject slavery and champion the common working man. Piersen proposed that Methodist communities inspired by his example took or were given a variant spelling of his name (possibly influenced by the \"yokel\" slang) during the decades after his ministry.\n\nAccording to Washington County newspaper reports of the time, Abraham Stover was Colonel of the Indiana Militia. He was a colorful figure in early Washington County history. Along with his son-in-law, John B. Brough, he was considered one of the two strongest men in Washington County, IN. He was always being challenged to prove his might, and seems to have won several fights over men half his age. After whipping six or eight men in a fist fight in Louisville, Ky, he cracked his fists and said, \"Ain't I a husher,\" which was changed in the news to \"Hoosier,\" and thus originated the name of Hoosier in connection with Indiana men.\n\nJorge Santander Serrano, a PhD student from Indiana University has also suggested that \"Hoosier\" might come from the French words for redness \"\"rougeur\"\" or red-faced \"\"rougeaud\"\". According to this theory, the early pejorative use of the word \"Hoosier\" may have a link to the color red (\"rouge\" in French) which is associated with indigenous peoples, pejoratively called \"red men\" or \"red-skins\", and also with poor white people by calling them \"red-necks.\"\n\nHumorous folk etymologies for the term \"hoosier\" have a long history, as recounted by Dunn in \"The Word Hoosier\".\n\nOne account traces the word to the necessary caution of approaching houses on the frontier. In order to avoid being shot, a traveler would call out from afar to let themselves be known. The inhabitants of the cabin would then reply \"Who's here?\" which in the Appalachian English of the early settlers slurred into \"Who'sh 'ere?\" and thence into \"Hoosier?\" A variant of this account had the Indiana pioneers calling out \"Who'sh 'ere?\" as a general greeting and warning when hearing someone in the bushes and tall grass, to avoid shooting a relative or friend in error.\n\nThe poet James Whitcomb Riley facetiously suggested that the fierce brawling that took place in Indiana involved enough biting that the expression \"Whose ear?\" became notable. This arose from or inspired the story of two 19th-century French immigrants brawling in a tavern in the foothills of southern Indiana. One was cut and a third Frenchman walked in to see an ear on the dirt floor of the tavern, prompting him to slur out \"Whosh ear?\"\n\nTwo related stories trace the origin of the term to gangs of workers from Indiana under the direction of a Mr. Hoosier.\n\nThe account related by Dunn is that a Louisville contractor named Samuel Hoosier preferred to hire workers from communities on the Indiana side of the Ohio River like New Albany rather than Kentuckians. During the excavation of the first canal around the Falls of the Ohio from 1826 to 1833, his employees became known as \"Hoosier's men\" and then simply \"Hoosiers\". The usage spread from these hard-working laborers to all of the Indiana boatmen in the area and then spread north with the settlement of the state. The story was told to Dunn in 1901 by a man who had heard it from a Hoosier relative while traveling in southern Tennessee. Dunn could not find any family of the given name in any directory in the region or anyone else in southern Tennessee who had heard the story and accounted himself dubious. This version was subsequently retold by Gov. Evan Bayh and Sen. Vance Hartke, who introduced the story into the \"Congressional Record\" in 1975, and matches the timing and location of Smith's subsequent research. However, the U.S. Army Corps of Engineers has been unable to find any record of a Hoosier or Hosier in surviving canal company records.\n\nThe word \"hoosier\" is still used in Greater St. Louis to denote a \"yokel\" or \"white trash\". The word is also encountered in sea shanties. In the book \"Shanties from the Seven Seas\" by Stan Hugill, in reference to its former use to denote cotton-stowers, who would move bales of cotton to and from the holds of ships and force them in tightly by means of jackscrews. \"To hoosier\" is sometimes still encountered as a verb meaning \"to trick\" or \"to swindle\".\n\nA Hoosier cabinet, often shortened to \"hoosier\", is a type of free-standing kitchen cabinet popular in the early decades of the twentieth century. Almost all of these cabinets were produced by companies located in Indiana and the name derives from the largest of them, the Hoosier Manufacturing Co. of New Castle, Indiana. Other Indiana businesses include Hoosier Racing Tire and the Hoosier Bat Company, manufacturer of wooden baseball bats.\n\nThe word may have originated from the term for shooing a pig away from it's mate at feeding time.\n\nThe RCA Dome, former home of the Indianapolis Colts, was known as the \"Hoosier Dome\" before RCA purchased the naming rights in 1994. The RCA Dome was replaced by Lucas Oil Stadium in 2008.\n\n\n"}
{"id": "14263", "url": "https://en.wikipedia.org/wiki?curid=14263", "title": "Horner's method", "text": "Horner's method\n\nIn mathematics, the term Horner's rule (or Horner's method, Horner's scheme etc) refers to a polynomial evaluation method named after William George Horner expressed by\n\nThis allows evaluation of a polynomial of degree with only formula_2 multiplications and formula_2 additions. This is optimal, since there are polynomials of degree that cannot be evaluated with fewer arithmetic operations.\n\nThis algorithm is much older than Horner. He himself ascribed it to Joseph-Louis Lagrange but it can be traced back many hundreds of years to Chinese and Persian mathematicians.\n\nHorner's root-finding method: Until computers came into general use in about 1970 the term 'Horner's method' was used the refer to a root-finding method for polynomials named after Horner who described a similar method in 1819. This method was widely used and became a standard method for hand calculation. It gave a convenient way for using the Newton–Raphson method for polynomials. It relied on the algorithm for polynomial evaluation now named after Horner. After the introduction of computers this root-finding method went out of use and as a result the term Horner's method (rule etc) has become understood to mean just the polynomial evaluation algorithm.\n\nGiven the polynomial\n\nwhere formula_5 are constant coefficients, we wish to evaluate the polynomial at a specific value of formula_6 that we'll call formula_7.\n\nTo accomplish this, we define a new sequence of constants as follows:\n\nThen formula_9 is the value of formula_10.\n\nTo see why this works, note that the polynomial can be written in the form\n\nThus, by iteratively substituting the formula_12 into the expression,\n\nEvaluate formula_14 for formula_15\n\nWe use synthetic division as follows:\n\nThe entries in the third row are the sum of those in the first two. Each entry in the second row is the product of the \"x\"-value (3 in this example) with the third-row entry immediately to the left. The entries in the first row are the coefficients of the polynomial to be evaluated. Then the remainder of formula_16 on division by formula_17 is 5.\n\nBut by the polynomial remainder theorem, we know that the remainder is formula_18. Thus formula_19\n\nIn this example, if formula_20 we can see that formula_21, the entries in the third row. So, synthetic division is based on Horner's method.\n\nAs a consequence of the polynomial remainder theorem, the entries in the third row are the coefficients of the second-degree polynomial, the quotient of formula_16 on division by formula_23. \nThe remainder is 5. This makes Horner's method useful for polynomial long division.\n\nDivide formula_24 by formula_25:\n\nThe quotient is formula_26.\n\nLet formula_27 and formula_28. Divide formula_29 by formula_30 using Horner's method.\nThe third row is the sum of the first two rows, divided by 2. Each entry in the second row is the product of 1 with the third-row entry to the left. The answer is\n\nHorner's method is a fast, code-efficient method for multiplication and division of binary numbers on a microcontroller with no hardware multiplier. One of the binary numbers to be multiplied is represented as a trivial polynomial, where (using the above notation) formula_32, and formula_33. Then, \"x\" (or \"x\" to some power) is repeatedly factored out. In this binary numeral system (base 2), formula_33, so powers of 2 are repeatedly factored out.\n\nFor example, to find the product of two numbers (0.15625) and \"m\":\n\nTo find the product of two binary numbers \"d\" and \"m\":\n\nIn general, for a binary number with bit values (formula_36) the product is\nAt this stage in the algorithm, it is required that terms with zero-valued coefficients are dropped, so that only binary coefficients equal to one are counted, thus the problem of multiplication or division by zero is not an issue, despite this implication in the factored equation:\n\nThe denominators all equal one (or the term is absent), so this reduces to\nor equivalently (as consistent with the \"method\" described above)\n\nIn binary (base-2) math, multiplication by a power of 2 is merely a register shift operation. Thus, multiplying by 2 is calculated in base-2 by an arithmetic shift. The factor (2) is a right arithmetic shift, a (0) results in no operation (since 2 = 1 is the multiplicative identity element), and a (2) results in a left arithmetic shift.\nThe multiplication product can now be quickly calculated using only arithmetic shift operations, addition and subtraction.\n\nThe method is particularly fast on processors supporting a single-instruction shift-and-addition-accumulate. Compared to a C floating-point library, Horner's method sacrifices some accuracy, however it is nominally 13 times faster (16 times faster when the \"canonical signed digit\" (CSD) form is used) and uses only 20% of the code space.\n\nUsing Horner's method in combination with Newton's method, it is possible to approximate the real roots of a polynomial. The algorithm works as follows. Given a polynomial formula_41 of degree formula_42 with zeros formula_43 make some initial guess formula_44 such that formula_45. Now iterate the following two steps:\n\n1. Using Newton's method, find the largest zero formula_46 of formula_41 using the guess formula_7.\n\n2. Using Horner's method, divide out formula_49 to obtain formula_50. Return to step 1 but use the polynomial formula_50 and the initial guess formula_46.\n\nThese two steps are repeated until all real zeros are found for the polynomial. If the approximated zeros are not precise enough, the obtained values can be used as initial guesses for Newton's method but using the full polynomial rather than the reduced polynomials.\n\nConsider the polynomial\n\nwhich can be expanded to\n\nFrom the above we know that the largest root of this polynomial is 7 so we are able to make an initial guess of 8. Using Newton's method the first zero of 7 is found as shown in black in the figure to the right. Next formula_55 is divided by formula_56 to obtain\n\nwhich is drawn in red in the figure to the right. Newton's method is used to find the largest zero of this polynomial with an initial guess of 7. The largest zero of this polynomial which corresponds to the second largest zero of the original polynomial is found at 3 and is circled in red. The degree 5 polynomial is now divided by formula_58 to obtain\n\nwhich is shown in yellow. The zero for this polynomial is found at 2 again using Newton's method and is circled in yellow. Horner's method is now used to obtain\n\nwhich is shown in green and found to have a zero at −3. This polynomial is further reduced to\n\nwhich is shown in blue and yields a zero of −5. The final root of the original polynomial may be found by either using the final zero as an initial guess for Newton's method, or by reducing formula_62 and solving the linear equation. As can be seen, the expected roots of −8, −5, −3, 2, 3, and 7 were found.\n\nHorner's method can be used to convert between different positional numeral systems – in which case \"x\" is the base of the number system, and the \"a\" coefficients are the digits of the base-\"x\" representation of a given number – and can also be used if \"x\" is a matrix, in which case the gain in computational efficiency is even greater. In fact, when \"x\" is a matrix, further acceleration is possible which exploits the structure of matrix multiplication, and only formula_63 instead of \"n\" multiplies are needed (at the expense of requiring more storage) using the 1973 method of Paterson and Stockmeyer.\n\nEvaluation using the monomial form of a degree-\"n\" polynomial requires at most \"n\" additions and (\"n\" + \"n\")/2 multiplications, if powers are calculated by repeated multiplication and each monomial is evaluated individually. (This can be reduced to \"n\" additions and 2\"n\" − 1 multiplications by evaluating the powers of \"x\" iteratively.) If numerical data are represented in terms of digits (or bits), then the naive algorithm also entails storing approximately 2\"n\" times the number of bits of \"x\" (the evaluated polynomial has approximate magnitude \"x\", and one must also store \"x\" itself). By contrast, Horner's method requires only \"n\" additions and \"n\" multiplications, and its storage requirements are only \"n\" times the number of bits of \"x\". Alternatively, Horner's method can be computed with \"n\" fused multiply–adds. Horner's method can also be extended to evaluate the first \"k\" derivatives of the polynomial with \"kn\" additions and multiplications.\n\nHorner's method is optimal, in the sense that any algorithm to evaluate an arbitrary polynomial must use at least as many operations. Alexander Ostrowski proved in 1954 that the number of additions required is minimal. Victor Pan proved in 1966 that the number of multiplications is minimal. However, when \"x\" is a matrix, Horner's method is not optimal.\n\nThis assumes that the polynomial is evaluated in monomial form and no preconditioning of the representation is allowed, which makes sense if the polynomial is evaluated only once. However, if preconditioning is allowed and the polynomial is to be evaluated many times, then faster algorithms are possible. They involve a transformation of the representation of the polynomial. In general, a degree-\"n\" polynomial can be evaluated using only +2 multiplications and \"n\" additions.\n\nA disadvantage of Horner's rule is that all of the operations are sequentially dependent, so it is not possible to take advantage of instruction level parallelism on modern computers. In most applications where the efficiency of polynomial evaluation matters, many low-order polynomials are evaluated simultaneously (for each pixel or polygon in computer graphics, or for each grid square in a numerical simulation), so it is not necessary to find parallelism within a single polynomial evaluation.\n\nIf, however, one is evaluating a single polynomial of very high order, it may be useful to break it up as follows:\n\nMore generally, the summation can be broken into \"k\" parts:\nwhere the inner summations may be evaluated using separate parallel instances of Horner's method. This requires slightly more operations than the basic Horner's method, but allows \"k\"-way SIMD execution of most of them.\n\nHorner's method can be modified to compute the divided difference formula_66 Given the polynomial (as before)\n\nproceed as follows\n\nAt completion, we have\nThis computation of the divided difference is subject to less\nround-off error than evaluating formula_55 and formula_71 separately, particularly when\nformula_72. Substituting\nformula_73 in this method gives formula_74, the derivative of formula_55.\n\nHorner's paper entitled \"A new method of solving numerical equations of all orders, by continuous approximation\" was read before the Royal Society of London, at its meeting on July 1, 1819, with Davies Gilbert, Vice-President and Treasurer, in the chair; this was the final meeting of the session before the Society adjorned for its Summer recess. When a sequel was read before the Society in 1823, it was again at the final meeting of the session. On both occasions, papers by James Ivory, FRS, were also read. In 1819, it was Horner's paper that got through to publication in the \"Philosophical Transactions\". later in the year, Ivory's paper falling by the way, despite Ivory being a Fellow; in 1823, when a total of ten papers were read, fortunes as regards publication, were reversed. But Gilbert, who had strong connections with the West of England and may have had social contact with Horner, resident as Horner was in Bristol and Bath, published his own survey of Horner-type methods earlier in 1823.\n\nHorner's paper in Part II of \"Philosophical Transactions of the Royal Society of London\" for 1819 was warmly and expansively welcomed by a reviewer in the issue of \"The Monthly Review: or, Literary Journal\" for April, 1820; in comparison, a technical paper by Charles Babbage is dismissed curtly in this review. However, the reviewer noted that another, similar method had also recently been published by the architect and mathematical expositor, Peter Nicholson. This theme is developed in a further review of some of Nicholson's books in the issue of \"The Monthly Review\" for December, 1820, which in turn ends with notice of the appearance of a booklet by Theophilus Holdred, from whom Nicholson acknowledges he obtained the gist of his approach in the first place, although claiming to have improved upon it. The sequence of reviews is concluded in the issue of \"The Monthly Review\" for September, 1821, with the reviewer concluding that whereas Holdred was the first person to discover a direct and general practical solution of numerical equations, he had not reduced it to its simplest form by the time of Horner's publication, and saying that had Holdred published forty years earlier when he first discovered his method, his contribution could be more easily recognized. The reviewer is exceptionally well-informed, even having cited Horner's preparatory correspondence with Peter Barlow in 1818, seeking work of Budan. The Bodlean Library, Oxford has the Editor's annotated copy of \"The Monthly Review\" from which it is clear that the most active reviewer in mathematics in 1814 and 1815 (the last years for which this information has been published) was none other than Peter Barlow, one of the foremost specialists on approximation theory of the period, suggesting that it was Barlow, who wrote this sequence of reviews. As it also happened, Henry Atkinson, of Newcastle, devised a similar approximation scheme in 1809; he had consulted his fellow Geordie, Charles Hutton, another specialist and a senior colleague of Barlow at the Royal Military Academy, Woolwich, only to be advised that, while his work was publishable, it was unlikely to have much impact. J. R. Young, writing in the mid-1830s, concluded that Holdred's first method replicated Atkinson's while his improved method was only added to Holdred's booklet some months after its first appearance in 1820, when Horner's paper was already in circulation.\n\nThe feature of Horner's writing that most distinguishes it from his English contemporaries is the way he draws on the Continental literature, notably the work of Arbogast. The advocacy, as well as the detraction, of Horner's Method has this as an unspoken subtext. Quite how he gained that familiarity has not been determined. Horner is known to have made a close reading of John Bonneycastle's book on algebra. Bonneycastle recognizes that Arbogast has the general, combinatorial expression for the reversion of series, a project going back at least to Newton. But Bonneycastle's main purpose in mentioning Arbogast is not to praise him, but to observe that Arbogast's notation is incompatible with the approach he adopts. The gap in Horner's reading was the work of Paolo Ruffini, except that, as far as awareness of Ruffini goes, citations of Ruffini's work by authors, including medical authors, in \"Philosophical Transactions\" speak volumes: there are none - Ruffini's name only appears in 1814, recording a work he donated to the Royal Society. Ruffini might have done better if his work had appeared in French, as had Malfatti's Problem in the reformulation of Joseph Diaz Gergonne, or had he written in French, as had , a source quoted by Bonneycastle on series reversion (today, Cagnoli is in the Italian Wikipedia, as shown, but has yet to make it into either French or English).\n\nFuller showed that the method in Horner's 1819 paper differs from what afterwards became known as 'Horner's method' and that in consequence the priority for this method should go to Holdred (1920). This view may be compared with the remarks concerning the works of Horner and Holdred in the previous paragraph. Fuller also takes aim at Augustus De Morgan. Precocious though Augustus de Morgan was, he was not the reviewer for \"The Monthly Review\", while several others - Thomas Stephens Davies, J. R. Young, Stephen Fenwick, T. T. Wilkinson - wrote Horner firmly into their records, not least Horner himself, as he published extensively up until the year of his death in 1837. His paper in 1819 was one that would have been difficult to miss. In contrast, the only other mathematical sighting of Holdred is a single named contribution to \"The Gentleman's Mathematical Companion\", an answer to a problem.\n\nIt is questionable to what extent it was De Morgan's advocacy of Horner's priority in discovery that led to \"Horner's method\" being so called in textbooks, but it is true that those suggesting this tend themselves to know of Horner largely through intermediaries, of whom De Morgan made himself a prime example. However, this method \"qua\" method was known long before Horner. In reverse chronological order, Horner's method was already known to:\n\n\nHowever, this observation on its own masks significant differences in conception and also, as noted with Ruffini's work, issues of accessibility.\n\nQin Jiushao, in his \"Shu Shu Jiu Zhang\" (\"Mathematical Treatise in Nine Sections\"; 1247), presents a portfolio of methods of Horner-type for solving polynomial equations, which was based on earlier works of the 11th century Song dynasty mathematician Jia Xian; for example, one method is specifically suited to bi-quintics, of which Qin gives an instance, in keeping with the then Chinese custom of case studies. The first person writing in English to note the connection with Horner's method was Alexander Wylie, writing in \"The North China Herald\" in 1852; perhaps conflating and misconstruing different Chinese phrases, Wylie calls the method \"Harmoniously Alternating Evolution\" (which does not agree with his Chinese, \"linglong kaifang\", not that at that date he uses pinyin), working the case of one of Qin's quartics and giving, for comparison, the working with Horner's method. Yoshio Mikami in \"Development of Mathematics in China and Japan\" published in Leipzig in 1913, gave a detailed description of Qin's method, using the quartic illustrated to the above right in a worked example; he wrote: \"who can deny the fact of Horner's illustrious process being used in China at least nearly six long centuries earlier than in Europe ... We of course don't intend in any way to ascribe Horner's invention to a Chinese origin, but the lapse of time sufficiently makes it not altogether impossible that the Europeans could have known of the Chinese method in a direct or indirect way.\". However, as Mikami is also aware, it was \"not altogether impossible\" that a related work, \"Si Yuan Yu Jian\" (\"Jade Mirror of the Four Unknowns; 1303)\" by Zhu Shijie might make the shorter journey across to Japan, but seemingly it never did, although another work of Zhu, \"Suan Xue Qi Meng\", had a seminal influence on the development of traditional mathematics in the Edo period, starting in the mid-1600s. Ulrich Libbrecht (at the time teaching in school, but subsequently a professor of comparative philosophy) gave a detailed description in his doctoral thesis of Qin's method, he concluded: \"It is obvious that this procedure is a Chinese invention...the method was not known in India\". He said, Fibonacci probably learned of it from Arabs, who perhaps borrowed from the Chinese. Here, the problems is that there is no more evidence for this speculation than there is of the method being known in India. Of course, the extraction of square and cube roots along similar lines is already discussed by Liu Hui in connection with Problems IV.16 and 22 in \"Jiu Zhang Suan Shu\", while Wang Xiaotong in the 7th century supposes his readers can solve cubics by an approximation method described in his book Jigu Suanjing.\n\n\n\n"}
{"id": "14268", "url": "https://en.wikipedia.org/wiki?curid=14268", "title": "Hapworth 16, 1924", "text": "Hapworth 16, 1924\n\n\"Hapworth 16, 1924\" was the last original work J. D. Salinger published in his lifetime. It appeared in the June 19, 1965, edition of \"The New Yorker\", infamously taking up almost the entire magazine. It is the \"youngest\" of Salinger's Glass family stories, in the sense that the narrated events happen chronologically before those in the rest of the series. \n\nBoth contemporary and later literary critics harshly panned \"Hapworth 16, 1924\"; writing in \"The New York Times\", Michiko Kakutani called it \"a sour, implausible and, sad to say, completely charmless story ... filled with digressions, narcissistic asides and ridiculous shaggy-dog circumlocutions.\" Even kind critics have regarded the work as \"a long-winded sob story\" that many have found \"simply unreadable\", and it has been speculated that this response was the reason Salinger decided to quit publishing. But Salinger is also said to have considered the story a \"high point of his writing\" and made tentative steps to have it reprinted, though those came to nothing.\n\nThe story is presented in the form of a letter from camp written by a seven-year-old Seymour Glass (the main character of \"A Perfect Day for Bananafish\"). In this respect, the plot is identical to Salinger's previous unpublished story \"The Ocean Full of Bowling Balls\", written 18 years earlier in 1947. In the course of requesting an inordinate quantity of reading matter from home, Seymour predicts his brother's success as a writer as well as his own death and offers critical assessments of a number of major writers.\n\nAfter the story's appearance in \"The New Yorker\", Salinger—who had already withdrawn to his home in New Hampshire—stopped publishing altogether. Since the story never appeared in book form, readers had to seek out that issue or find it on microfilm. Finally, with the release of \"The Complete New Yorker\" on DVD in 2005, the story was once again widely available.\n\nIn 1996, Orchises Press, a small Virginia publishing house, started a process of publishing \"Hapworth\" in book form. Orchises Press owner Roger Lathbury has described the effort in \"The Washington Post\" and, three months after Salinger's death, in \"New York\" magazine\".\" According to Lathbury, Salinger was deeply concerned with the proposed book's appearance, even visiting Washington to examine the cloth for the binding. Salinger also sent Lathbury numerous \"infectious and delightful and loving\" letters.\n\nFollowing publishing norms, Lathbury applied for Library of Congress Cataloging in Publication data, unaware of how publicly available the information would be. A writer in Seattle, researching an article on Jeff Bezos, came across the \"Hapworth\" publication date, and told his sister, a journalist for the \"Washington Business Journal\", who wrote an article about the upcoming book. This led to substantial coverage in the press. Shortly before the books were to be shipped, Salinger changed his mind, and Orchises withdrew the book. New publication dates were repeatedly announced, but it never appeared. Lathbury said, \"I never reached back out. I thought about writing some letters, but it wouldn't have done any good.\"\n\n\n"}
{"id": "14269", "url": "https://en.wikipedia.org/wiki?curid=14269", "title": "Hypnotic", "text": "Hypnotic\n\nHypnotic (from Greek \"Hypnos\", sleep) or soporific drugs, commonly known as sleeping pills, are a class of psychoactive drugs whose primary function is to induce sleep and to be used in the treatment of insomnia (sleeplessness), or for surgical anesthesia.\n\nThis group is related to sedatives. Whereas the term \"sedative\" describes drugs that serve to calm or relieve anxiety, the term \"hypnotic\" generally describes drugs whose main purpose is to initiate, sustain, or lengthen sleep. Because these two functions frequently overlap, and because drugs in this class generally produce dose-dependent effects (ranging from anxiolysis to loss of consciousness) they are often referred to collectively as sedative-hypnotic drugs.\n\nHypnotic drugs are regularly prescribed for insomnia and other sleep disorders, with over 95% of insomnia patients being prescribed hypnotics in some countries. Many hypnotic drugs are habit-forming and, due to a large number of factors known to disturb the human sleep pattern, a physician may instead recommend changes in the environment before and during sleep, better sleep hygiene, the avoidance of caffeine or other stimulating substances, or behavioral interventions such as Cognitive Behavioral Therapy for Insomnia (CBT-I) before prescribing medication for sleep. When prescribed, hypnotic medication should be used for the shortest period of time necessary.\n\nAmong individuals with sleep disorders, 13.7% are taking or prescribed nonbenzodiazepines, while 10.8% are taking benzodiazepines, as of 2010. Early classes of drugs, such as barbiturates, have fallen out of use in most practices but are still prescribed for some patients. In children, prescribing hypnotics is not yet acceptable unless used to treat night terrors or somnambulism. Elderly people are more sensitive to potential side effects of daytime fatigue and cognitive impairments, and a meta-analysis found that the risks generally outweigh any marginal benefits of hypnotics in the elderly. A review of the literature regarding benzodiazepine hypnotics and Z-drugs concluded that these drugs can have adverse effects, such as dependence and accidents, and that optimal treatment uses the lowest effective dose for the shortest therapeutic time period, with gradual discontinuation in order to improve health without worsening of sleep.\n\nFalling outside the above-mentioned categories, the neuro-hormone melatonin has a hypnotic function.\n\nHypnotica was a class of somniferous drugs and substances tested in medicine of the 1890s and later, including: Urethan, Acetal, Methylal, Sulfonal, paraldehyde, Amylenhydrate, Hypnon, Chloralurethan and Ohloralamid or Chloralimid.\n\nResearch about using medications to treat insomnia evolved throughout the last half of the 20th century. Treatment for insomnia in psychiatry dates back to 1869 when chloral hydrate was first used as a soporific. Barbiturates emerged as the first class of drugs that emerged in the early 1900s, after which chemical substitution allowed derivative compounds. Although the best drug family at the time (less toxic and with fewer side effects) they were dangerous in overdose and tended to cause physical and psychological dependence.\n\nDuring the 1970s, quinazolinones and benzodiazepines were introduced as safer alternatives to replace barbiturates; by the late 1970s benzodiazepines emerged as the safer drug.\n\nBenzodiazepines are not without their drawbacks; substance dependence is possible, and deaths from overdoses sometimes occur, especially in combination with alcohol and/or other depressants. Questions have been raised as to whether they disturb sleep architecture.\n\nNonbenzodiazepines are the most recent development (1990s–present). Although it's clear that they are less toxic than their predecessors, barbiturates, comparative efficacy over benzodiazepines have not been established. Without longitudinal studies, it is hard to determine; however some psychiatrists recommend these drugs, citing research suggesting they are equally potent with less potential for abuse.\n\nOther sleep remedies that may be considered \"sedative-hypnotics\" exist; psychiatrists will sometimes prescribe medicines off-label if they have sedating effects. Examples of these include mirtazapine (an antidepressant), clonidine (generally prescribed to regulate blood pressure), quetiapine (an antipsychotic), and the over-the-counter sleep aid diphenhydramine (Benadryl – an antihistamine). Off-label sleep remedies are particularly useful when first-line treatment is unsuccessful or deemed unsafe (for example, in patients with a history of substance abuse).\n\nBarbiturates are drugs that act as central nervous system depressants, and can therefore produce a wide spectrum of effects, from mild sedation to total anesthesia. They are also effective as anxiolytics, hypnotics, and anticonvulsalgesic effects; however, these effects are somewhat weak, preventing barbiturates from being used in surgery in the absence of other analgesics. They have dependence liability, both physical and psychological. Barbiturates have now largely been replaced by benzodiazepines in routine medical practice – for example, in the treatment of anxiety and insomnia – mainly because benzodiazepines are significantly less dangerous in overdose. However, barbiturates are still used in general anesthesia, for epilepsy, and assisted suicide. Barbiturates are derivatives of barbituric acid.\n\nThe principal mechanism of action of barbiturates is believed to be positive allosteric modulation of GABA receptors.\n\nExamples include amobarbital, pentobarbital, phenobarbital, secobarbital, and sodium thiopental.\n\nQuinazolinones are also a class of drugs which function as hypnotic/sedatives that contain a 4-quinazolinone core. Their use has also been proposed in the treatment of cancer.\n\nExamples of quinazolinones include cloroqualone, diproqualone, etaqualone (Aolan, Athinazone, Ethinazone), mebroqualone, mecloqualone (Nubarene, Casfen), and methaqualone (Quaalude).\n\nBenzodiazepines can be useful for short-term treatment of insomnia. Their use beyond 2 to 4 weeks is not recommended due to the risk of dependence. It is preferred that benzodiazepines be taken intermittently and at the lowest effective dose. They improve sleep-related problems by shortening the time spent in bed before falling asleep, prolonging the sleep time, and, in general, reducing wakefulness. Like alcohol, benzodiazepines are commonly used to treat insomnia in the short-term (both prescribed and self-medicated), but worsen sleep in the long-term. While benzodiazepines can put people to sleep (i.e., inhibit NREM stage 1 and 2 sleep), while asleep, the drugs disrupt sleep architecture: decreasing sleep time, delaying time to REM sleep, and decreasing deep slow-wave sleep (the most restorative part of sleep for both energy and mood).\n\nOther drawbacks of hypnotics, including benzodiazepines, are possible tolerance to their effects, rebound insomnia, and reduced slow-wave sleep and a withdrawal period typified by rebound insomnia and a prolonged period of anxiety and agitation. The list of benzodiazepines approved for the treatment of insomnia is fairly similar among most countries, but which benzodiazepines are officially designated as first-line hypnotics prescribed for the treatment of insomnia can vary distinctly between countries. Longer-acting benzodiazepines such as nitrazepam and diazepam have residual effects that may persist into the next day and are, in general, not recommended.\n\nIt is not clear as to whether the new nonbenzodiazepine hypnotics (Z-drugs) are better than the short-acting benzodiazepines. The efficacy of these two groups of medications is similar. According to the US Agency for Healthcare Research and Quality, indirect comparison indicates that side-effects from benzodiazepines may be about twice as frequent as from nonbenzodiazepines. Some experts suggest using nonbenzodiazepines preferentially as a first-line long-term treatment of insomnia. However, the UK National Institute for Health and Clinical Excellence (NICE) did not find any convincing evidence in favor of Z-drugs. A NICE review pointed out that short-acting Z-drugs were inappropriately compared in clinical trials with long-acting benzodiazepines. There have been no trials comparing short-acting Z-drugs with appropriate doses of short-acting benzodiazepines. Based on this, NICE recommended choosing the hypnotic based on cost and the patient's preference.\n\nOlder adults should not use benzodiazepines to treat insomnia unless other treatments have failed to be effective. When benzodiazepines are used, patients, their caretakers, and their physician should discuss the increased risk of harms, including evidence which shows twice the incidence of traffic collisions among driving patients as well as falls and hip fracture for all older patients.\n\nTheir mechanism of action is primarily at GABA receptors.\n\nNonbenzodiazepines are a class of psychoactive drugs that are very \"benzodiazepine-like\" in nature. Nonbenzodiazepine pharmacodynamics are almost entirely the same as benzodiazepine drugs and therefore entail similar benefits, side-effects, and risks. Nonbenzodiazepines, however, have dissimilar or entirely different chemical structures, and therefore are unrelated to benzodiazepines on a molecular level.\n\nExamples include zopiclone (Imovane, Zimovane), eszopiclone (Lunesta), zaleplon (Sonata), and zolpidem (Ambien, Stilnox, Stilnoct).\n\nResearch on nonbenzodiazepines is new and conflicting. A review by a team of researchers suggests the use of these drugs for people that have trouble falling asleep but not staying asleep, as next-day impairments were minimal. The team noted that the safety of these drugs had been established, but called for more research into their long-term effectiveness in treating insomnia. Other evidence suggests that tolerance to nonbenzodiazepines may be slower to develop than with benzodiazepines. A different team was more skeptical, finding little benefit over benzodiazepines.\n\nMelatonin, the hormone produced in the pineal gland in the brain and secreted in dim light and darkness, among its other functions, promotes sleep in diurnal mammals.\n\nIn common use, the term \"antihistamine\" refers only to compounds that inhibit action at the H receptor (and not H, etc.).\n\nClinically, H antagonists are used to treat certain allergies. Sedation is a common side-effect, and some H antagonists, such as diphenhydramine (Benadryl) and doxylamine, are also used to treat insomnia.\n\nSecond-generation antihistamines cross the blood–brain barrier to a much lower degree than the first ones. This results in their primarily affecting peripheral histamine receptors, and therefore having a much lower sedative effect. High doses can still induce the central nervous system effect of drowsiness.\n\nSome antidepressants have sedating effects. Some \"may\" increase actual quality of sleep (biologically) in contrast to Benzodiazepines that decrease quality.\n\nExamples include:\n\nExamples of antipsychotics with sedation as a side effect:\n\n\n\n\n\n\n\n\n"}
{"id": "14273", "url": "https://en.wikipedia.org/wiki?curid=14273", "title": "HMS Dunraven", "text": "HMS Dunraven\n\nHMS \"Dunraven\" was a Q-Ship of the Royal Navy during World War I.\n\nOn 8 August 1917, 130 miles southwest of Ushant in the Bay of Biscay, disguised as the collier \"Boverton\" and commanded by Gordon Campbell, VC, \"Dunraven\" spotted , commanded by \"Oberleutnant zur See\" Reinhold Saltzwedel. Saltzwedel believed the disguised ship was a merchant vessel. The U-boat submerged and closed with \"Dunraven\" before surfacing astern at 11:43 am and opening fire at long range. \"Dunraven\" made smoke and sent off a panic party (a small number of men who \"abandon ship\" during an attack to continue the impersonation of a merchant).\n\nShells began hitting \"Dunraven\", detonating her depth charges and setting her stern afire. Her crew remained hidden letting the fires burn. Then a 4 inch (102 mm) gun and crew were blown away revealing \"Dunraven\"s identity as a warship, and \"UC-71\" submerged. A second \"panic party\" abandoned ship. \"Dunraven\" was hit by a torpedo. A third \"panic party\" went over the side, leaving only two guns manned. \"UC-71\" surfaced, shelled \"Dunraven\" and again submerged. Campbell replied with two torpedoes that missed, and around 3 pm, the undamaged U-boat left that area. Only one of \"Dunraven\"s crew was killed, but the Q-Ship was sinking.\n\nThe British destroyer picked up \"Dunraven\"s survivors and took her in tow for Plymouth, but \"Dunraven\" sank at 1:30 am early on 10 August 1917 to the north of Ushant.\n\nIn recognition, two Victoria Crosses were awarded, one to the ship's First Lieutenant, Lt. Charles George Bonner RNR, and the other, by ballot, to a gunlayer, Petty Officer Ernest Herbert Pitcher.\n\nCaptain Campbell later wrote:\n\nCaptain Campbell had been previously awarded the Victoria Cross, in February 1917, for the sinking of .\n"}
{"id": "14275", "url": "https://en.wikipedia.org/wiki?curid=14275", "title": "Hacker ethic", "text": "Hacker ethic\n\nHacker ethic is a term for the moral values and philosophy that are common in hacker culture. Practitioners of the hacker ethic acknowledge that sharing information and data responsibly is beneficial and helpful. Whilst the philosophy originated at the Massachusetts Institute of Technology in the 1950s–1960s, the term \"hacker ethic\" is attributed to journalist Steven Levy as described in his 1984 book titled \".\" The key points within this ethic are access, freedom of information, and improvement to quality of life. While some tenets of hacker ethic were described in other texts like \"Computer Lib/Dream Machines\" (1974) by Ted Nelson, Levy appears to have been the first to document both the philosophy and the founders of the philosophy.\n\nLevy explains that MIT housed an early IBM 704 computer inside the Electronic Accounting Machinery (EAM) room in 1959. This room became the staging grounds for early hackers, as MIT students from the Tech Model Railroad Club sneaked inside the EAM room after hours to attempt programming the 30-ton, computer.\n\nThe MIT group defined a \"hack\" as a project undertaken or a product built to fulfill some constructive goal, but also with some wild pleasure taken in mere involvement. The term \"hack\" arose from MIT lingo, as the word had long been used to describe college pranks that MIT students would regularly devise. However, Levy's hacker ethic also has often been quoted out of context and misunderstood to refer to hacking as in breaking into computers, and so many sources incorrectly imply that it is describing the ideals of white-hat hackers. However, what Levy is talking about does not necessarily have anything particular to do with computer security, but addresses broader issues.\n\nThe hacker ethic was described as a \"new way of life, with a philosophy, an ethic and a dream\". However, the elements of the hacker ethic were not openly debated and discussed; rather they were implicitly accepted and silently agreed upon.\n\nThe free software movement was born in the early 1980s from followers of the hacker ethic. Its founder, Richard Stallman, is referred to by Steven Levy as \"the last true hacker\". Modern hackers who hold true to the hacker ethics—especially the Hands-On Imperative—are usually supporters of free and open source software. This is because free and open source software allows hackers to get access to the source code used to create the software, to allow it to be improved or reused in other projects.\n\nRichard Stallman describes:\n\nThe hacker ethic refers to the feelings of right and wrong, to the ethical ideas this community of people had—that knowledge should be shared with other people who can benefit from it, and that important resources should be utilized rather than wasted.\n\nand states more precisely that hacking (which Stallman defines as playful cleverness) and ethics are two separate issues:\n\nJust because someone enjoys hacking does not mean he has an ethical commitment to treating other people properly. Some hackers care about ethics—I do, for instance—but that is not part of being a hacker, it is a separate trait. [...] Hacking is not primarily about an ethical issue. [...] hacking tends to lead a significant number of hackers to think about ethical questions in a certain way. I would not want to completely deny all connection between hacking and views on ethics.\n\nAs Levy summarized in the preface of \"Hackers\", the general tenets or principles of hacker ethic include:\n\n\nIn addition to those principles, Levy also described more specific hacker ethics and beliefs in chapter 2, \"The Hacker Ethic\": The ethics he described in chapter 2 are:\n\n\nFrom the early days of modern computing through to the 1970s, it was far more common for computer users to have the freedoms that are provided by an ethic of open sharing and collaboration. Software, including source code, was commonly shared by individuals who used computers. Most companies had a business model based on hardware sales, and provided or bundled the associated software free of charge. According to Levy's account, sharing was the norm and expected within the non-corporate hacker culture. The principle of sharing stemmed from the open atmosphere and informal access to resources at MIT. During the early days of computers and programming, the hackers at MIT would develop a program and share it with other computer users.\n\nIf the hack was deemed particularly good, then the program might be posted on a board somewhere near one of the computers. Other programs that could be built upon it and improved it were saved to tapes and added to a drawer of programs, readily accessible to all the other hackers. At any time, a fellow hacker might reach into the drawer, pick out the program, and begin adding to it or \"bumming\" it to make it better. Bumming referred to the process of making the code more concise so that more can be done in fewer instructions, saving precious memory for further enhancements.\n\nIn the second generation of hackers, sharing was about sharing with the general public in addition to sharing with other hackers. A particular organization of hackers that was concerned with sharing computers with the general public was a group called Community Memory. This group of hackers and idealists put computers in public places for anyone to use. The first community computer was placed outside of Leopold's Records in Berkeley, California.\n\nAnother sharing of resources occurred when Bob Albrecht provided considerable resources for a non-profit organization called the People's Computer Company (PCC). PCC opened a computer center where anyone could use the computers there for fifty cents per hour.\n\nThis second generation practice of sharing contributed to the battles of free and open software. In fact, when Bill Gates' version of BASIC for the Altair was shared among the hacker community, Gates claimed to have lost a considerable sum of money because few users paid for the software. As a result, Gates wrote an Open Letter to Hobbyists. This letter was published by several computer magazines and newsletters, most notably that of the Homebrew Computer Club where much of the sharing occurred.\n\nMany of the principles and tenets of hacker ethic contribute to a common goal: the Hands-On Imperative. As Levy described in Chapter 2, \"Hackers believe that essential lessons can be learned about the systems—about the world—from taking things apart, seeing how they work, and using this knowledge to create new and more interesting things.\"\n\nEmploying the Hands-On Imperative requires free access, open information, and the sharing of knowledge. To a true hacker, if the Hands-On Imperative is restricted, then the ends justify the means to make it unrestricted \"so that improvements can be made\". When these principles are not present, hackers tend to work around them. For example, when the computers at MIT were protected either by physical locks or login programs, the hackers there systematically worked around them in order to have access to the machines. Hackers assumed a \"willful blindness\" in the pursuit of perfection.\n\nThis behavior was not malicious in nature: the MIT hackers did not seek to harm the systems or their users. This deeply contrasts with the modern, media-encouraged image of hackers who crack secure systems in order to steal information or complete an act of cyber-vandalism.\n\nThroughout writings about hackers and their work processes, a common value of community and collaboration is present. For example, in Levy's \"Hackers\", each generation of hackers had geographically based communities where collaboration and sharing occurred. For the hackers at MIT, it was the labs where the computers were running. For the hardware hackers (second generation) and the game hackers (third generation) the geographic area was centered in Silicon Valley where the Homebrew Computer Club and the People's Computer Company helped hackers network, collaborate, and share their work.\n\nThe concept of community and collaboration is still relevant today, although hackers are no longer limited to collaboration in geographic regions. Now collaboration takes place via the Internet. Eric S. Raymond identifies and explains this conceptual shift in \"The Cathedral and the Bazaar\":\n\nBefore cheap Internet, there were some geographically compact communities where the culture encouraged Weinberg's egoless programming, and a developer could easily attract a lot of skilled kibitzers and co-developers. Bell Labs, the MIT AI and LCS labs, UC Berkeley: these became the home of innovations that are legendary and still potent.\n\nRaymond also notes that the success of Linux coincided with the wide availability of the World Wide Web. The value of community is still in high practice and use today.\n\nLevy identifies several \"true hackers\" who significantly influenced the hacker ethic. Some well-known \"true hackers\" include:\n\n\nLevy also identified the \"hardware hackers\" (the \"second generation\", mostly centered in Silicon Valley) and the \"game hackers\" (or the \"third generation\"). All three generations of hackers, according to Levy, embodied the principles of the hacker ethic. Some of Levy's \"second-generation\" hackers include:\n\n\nLevy's \"third generation\" practitioners of hacker ethic include:\n\n\nIn this digital age, and due to our reliance on technology, hackers are able to gather more information on us than before. One way to combat this is to teach students to hack in such a way that they become what are called \"white hat hackers\". White hat hackers follow ethical guidelines that proscribe harming either other people or the systems on which other people depend. Through their efforts, they have the ability to prevent malicious attacks. The movement of ethical hacking has gained traction through different programs such as the L0pht and GhettoHackers, and courses have become integrated into university- and college-level curriculum.\n\nSecurity researcher and an application security engineer Joe Gervais pointed out that students who are intellectually curious enough may start to experiment with computers without thinking of the ethical repercussions of their actions. He points out that there are a lot of classes that exist for more gifted students in areas such as math, reading, etc. However, there doesn’t seem to be courses that can address the curiosity that a young hacker may have.\n\nHacking courses can create a moral compass for young hackers. They require a constructive environment that allows them to satiate their desire to understand computers. Students in these classes have the ability to learn what they are passionate about while also understanding the ethical boundaries that should not be encroached upon. However, the integral part of the curriculum would be to prevent the development of black hat hackers.\n\nThere seems to be a lack of skilled cyber security experts. Moreover, there doesn’t seem to be sufficient curriculum to teach individuals the skills required to protect systems against malicious action. Teaching ethical hacking is a plausible way to fill the gap in the supply of technically skilled people; capable of successfully implementing defensive mechanisms to overcome real world threats.\n\nIn 2012, Ymir Vigfusson held a talk at TEDxRekjavijk entitled \"Why I Teach People to Hack\", illustrating reasons for supporting the teaching of ethical hacking.\n\nIn 2001, Finnish philosopher Pekka Himanen promoted the hacker ethic in opposition to the Protestant work ethic. In Himanen's opinion, the hacker ethic is more closely related to the virtue ethics found in the writings of Plato and of Aristotle. Himanen explained these ideas in a book, \"The Hacker Ethic and the Spirit of the Information Age\", with a prologue contributed by Linus Torvalds and an epilogue by Manuel Castells.\n\nIn this manifesto, the authors wrote about a hacker ethic centering on passion, hard work, creativity and joy in creating software. Both Himanen and Torvalds were inspired by the Sampo in Finnish mythology. The Sampo, described in the Kalevala saga, was a magical artifact constructed by Ilmarinen, the blacksmith god, that brought good fortune to its holder; nobody knows exactly what it was supposed to be. The Sampo has been interpreted in many ways: a world pillar or world tree, a compass or astrolabe, a chest containing a treasure, a Byzantine coin die, a decorated Vendel period shield, a Christian relic, etc. Kalevala saga compiler Lönnrot interpreted it to be a \"quern\" or mill of some sort that made flour, salt, and gold out of thin air.\n\nThe hacker ethic and its wider context can be associated with liberalism and anarchism.\n\n\n\n"}
{"id": "14276", "url": "https://en.wikipedia.org/wiki?curid=14276", "title": "Hotel", "text": "Hotel\n\nA hotel is an establishment that provides paid lodging on a short-term basis. Facilities provided may range from a modest-quality mattress in a small room to large suites with bigger, higher-quality beds, a dresser, a refrigerator and other kitchen facilities, upholstered chairs, a flat screen television, and en-suite bathrooms. Small, lower-priced hotels may offer only the most basic guest services and facilities. Larger, higher-priced hotels may provide additional guest facilities such as a swimming pool, business centre (with computers, printers, and other office equipment), childcare, conference and event facilities, tennis or basketball courts, gymnasium, restaurants, day spa, and social function services. Hotel rooms are usually numbered (or named in some smaller hotels and B&Bs) to allow guests to identify their room. Some boutique, high-end hotels have custom decorated rooms. Some hotels offer meals as part of a room and board arrangement. In the United Kingdom, a hotel is required by law to serve food and drinks to all guests within certain stated hours. In Japan, capsule hotels provide a tiny room suitable only for sleeping and shared bathroom facilities.\n\nThe precursor to the modern hotel was the inn of medieval Europe. For a period of about 200 years from the mid-17th century, coaching inns served as a place for lodging for coach travelers. Inns began to cater to richer clients in the mid-18th century. One of the first hotels in a modern sense was opened in Exeter in 1768. Hotels proliferated throughout Western Europe and North America in the early 19th century, and luxury hotels began to spring up in the later part of the 19th century.\n\nHotel operations vary in size, function, complexity, and cost. Most hotels and major hospitality companies have set industry standards to classify hotel types. An upscale full-service hotel facility offers luxury amenities, full service accommodations, an on-site restaurant, and the highest level of personalized service, such as a concierge, room service, and clothes pressing staff. Full service hotels often contain upscale full-service facilities with a large number of full service accommodations, an on-site full service restaurant, and a variety of on-site amenities. Boutique hotels are smaller independent, non-branded hotels that often contain upscale facilities. Small to medium-sized hotel establishments offer a limited amount of on-site amenities. Economy hotels are small to medium-sized hotel establishments that offer basic accommodations with little to no services. Extended stay hotels are small to medium-sized hotels that offer longer-term full service accommodations compared to a traditional hotel.\n\nTimeshare and destination clubs are a form of property ownership involving ownership of an individual unit of accommodation for seasonal usage. A motel is a small-sized low-rise lodging with direct access to individual rooms from the car park. Boutique hotels are typically hotels with a unique environment or intimate setting. A number of hotels have entered the public consciousness through popular culture, such as the Ritz Hotel in London. Some hotels are built specifically as a destination in itself, for example at casinos and holiday resorts.\n\nMost hotel establishments are run by a General Manager who serves as the head executive (often referred to as the \"Hotel Manager\"), department heads who oversee various departments within a hotel (e.g., food service), middle managers, administrative staff, and line-level supervisors. The organizational chart and volume of job positions and hierarchy varies by hotel size, function and class, and is often determined by hotel ownership and managing companies.\n\nThe word \"hotel\" is derived from the French \"hôtel\" (coming from the same origin as \"hospital\"), which referred to a French version of a building seeing frequent visitors, and providing care, rather than a place offering accommodation. In contemporary French usage, \"hôtel\" now has the same meaning as the English term, and \"hôtel particulier\" is used for the old meaning, as well as \"hôtel\" in some place names such as Hôtel-Dieu (in Paris), which has been a hospital since the Middle Ages. The French spelling, with the circumflex, was also used in English, but is now rare. The circumflex replaces the 's' found in the earlier \"hostel\" spelling, which over time took on a new, but closely related meaning. Grammatically, hotels usually take the definite article – hence \"The Astoria Hotel\" or simply \"The Astoria.\"\n\nFacilities offering hospitality to travellers have been a feature of the earliest civilizations. In Greco-Roman culture and ancient Persia, hospitals for recuperation and rest were built at thermal baths. Japan's Nishiyama Onsen Keiunkan, founded in 705, was officially recognised by the Guinness World Records as the oldest hotel in the world. During the Middle Ages, various religious orders at monasteries and abbeys would offer accommodation for travellers on the road.\n\nThe precursor to the modern hotel was the inn of medieval Europe, possibly dating back to the rule of Ancient Rome. These would provide for the needs of travellers, including food and lodging, stabling and fodder for the traveller's horse(s) and fresh horses for the mail coach. Famous London examples of inns include the George and the Tabard. A typical layout of an inn had an inner court with bedrooms on the two sides, with the kitchen and parlour at the front and the stables at the back.\n\nFor a period of about 200 years from the mid-17th century, coaching inns served as a place for lodging for coach travellers (in other words, a roadhouse). Coaching inns stabled teams of horses for stagecoaches and mail coaches and replaced tired teams with fresh teams. Traditionally they were seven miles apart, but this depended very much on the terrain.\nSome English towns had as many as ten such inns and rivalry between them was intense, not only for the income from the stagecoach operators but for the revenue for food and drink supplied to the wealthy passengers. By the end of the century, coaching inns were being run more professionally, with a regular timetable being followed and fixed menus for food.\n\nInns began to cater for richer clients in the mid-18th century, and consequently grew in grandeur and the level of service provided. One of the first hotels in a modern sense was opened in Exeter in 1768, although the idea only really caught on in the early 19th century. In 1812 Mivart's Hotel opened its doors in London, later changing its name to Claridge's.\n\nHotels proliferated throughout Western Europe and North America in the 19th century, and luxury hotels, including the Savoy Hotel in the United Kingdom and the Ritz chain of hotels in London and Paris and Tremont House and Astor House in the United States, began to spring up in the later part of the century, catering to an extremely wealthy clientele.\n\nHotels cater to travelers from many countries and languages, since no one country dominates the travel industry.\n\nHotel operations vary in size, function, and cost. Most hotels and major hospitality companies that operate hotels have set widely accepted industry standards to classify hotel types. General categories include the following:\n\nA luxury hotel offers high quality amenities, full service accommodations, on-site full-service restaurants, and the highest level of personalized and professional service. Luxury hotels are classified with at least a Five Diamond rating or Five Star hotel rating depending on the country and local classification standards. \"Examples include: Grand Hyatt, Waldorf Astoria, Conrad, InterContinental, Sofitel, Mandarin Oriental, Four Seasons, The Peninsula, Rosewood, St. Regis, JW Marriott and The Ritz-Carlton.\"\n\nLifestyle resorts are branded properties that appeal to a guest with specific lifestyle or personal image. They are typically full-service and sometimes classified as luxury. A key characteristic of lifestyle resorts are focus on providing a unique guest experience as opposed to simply providing lodging. Normally, lifestyle resorts are classified with a Five Star hotel rating depending on the country and local classification standards. Examples include W Hotels, Shangri-La, Sheraton, Andaz, Jumeirah, Lotte, Aman, Taj Hotels, Renaissance, Hoshino, Raffles, Fairmont and Banyan Tree.\n\nFull service hotels often provide a wide array of guest services and on-site facilities. Commonly found amenities may include: on-site food and beverage (room service and restaurants), meeting and conference services and facilities, fitness center, and business center. Full-service hotels range in quality from mid-scale to luxury. This classification is based upon the quality of facilities and amenities offered by the hotel. Examples include: Holiday Inn, Kimpton Hotels, Hilton, Marriott and Hyatt Regency brands.\n\nBoutique hotels are smaller independent non-branded hotels that often contain upscale facilities of varying size in unique or intimate settings with full service accommodations. These hotels are generally 100 rooms or fewer.\n\nSmall to medium-sized hotel establishments that offer a limited number of on-site amenities that only cater and market to a specific demographic of travelers, such as the single business traveler. Most focused or select service hotels may still offer full service accommodations but may lack leisure amenities such as an on-site restaurant or a swimming pool. Examples include Hyatt Place, Courtyard by Marriott and Hilton Garden Inn.\n\nSmall to medium-sized hotel establishments that offer a very limited number of on-site amenities and often only offer basic accommodations with little to no services, these facilities normally only cater and market to a specific demographic of travelers, such as the budget-minded traveler seeking a \"no frills\" accommodation. Limited service hotels often lack an on-site restaurant but in return may offer a limited complimentary food and beverage amenity such as on-site continental breakfast service. Examples include Ibis Budget, Hampton Inn, Aloft, Holiday Inn Express, Fairfield Inn, Four Points by Sheraton.\n\nExtended stay hotels are small to medium-sized hotels that offer longer term full service accommodations compared to a traditional hotel. Extended stay hotels may offer non-traditional pricing methods such as a weekly rate that caters towards travelers in need of short-term accommodations for an extended period of time. Similar to limited and select service hotels, on-site amenities are normally limited and most extended stay hotels lack an on-site restaurant. Examples include Staybridge Suites, Candlewood Suites, Homewood Suites by Hilton, Home2 Suites by Hilton, Residence Inn by Marriott, Element, and Extended Stay America.\n\nTimeshare and Destination clubs are a form of property ownership also referred to as a vacation ownership involving the purchase and ownership of an individual unit of accommodation for seasonal usage during a specified period of time. Timeshare resorts often offer amenities similar that of a Full service hotel with on-site restaurant(s), swimming pools, recreation grounds, and other leisure-oriented amenities. Destination clubs on the other hand may offer more exclusive private accommodations such as private houses in a neighborhood-style setting. Examples of timeshare brands include Hilton Grand Vacations, Marriott Vacation Club International, Westgate Resorts, Disney Vacation Club, and Holiday Inn Club Vacations.\n\nA motel, an abbreviation for \"motor hotel\", is a small-sized low-rise lodging establishment similar to a limited service, lower-cost hotel, but typically with direct access to individual rooms from the car park. Motels were built to serve road travellers, including travellers on road trip vacations and workers who drive for their job (travelling salespeople, truck drivers, etc.). Common during the 1950s and 1960s, motels were often located adjacent to a major highway, where they were built on inexpensive land at the edge of towns or along stretches of freeway.\n\nNew motel construction is rare in the 2000s as hotel chains have been building economy-priced, limited service franchised properties at freeway exits which compete for largely the same clientele, largely saturating the market by the 1990s. Motels are still useful in less populated areas for driving travelers, but the more populated an area becomes, the more hotels move in to meet the demand for accommodation. While many motels are unbranded and independent, many of the other motels which remain in operation joined national franchise chains, often rebranding themselves as hotels, inns or lodges. Some examples of chains with motels include EconoLodge, Motel 6, Super 8, and Travelodge.\n\nMotels in some parts of the world are more often regarded as places for romantic assignations where rooms are often rented by the hour. This is fairly common in parts of Latin America.\n\nHotels may offer rooms for microstays, a type of booking for less than 24 hours where the customer chooses the check in time and the length of the stay. This allows the hotel increased revenue by reselling the same room several times a day.\n\nHotel management is a globally accepted professional career field and academic field of study. Degree programs such as hospitality management studies, a business degree, and/or certification programs formally prepare hotel managers for industry practice.\n\nMost hotel establishments consist of a General Manager who serves as the head executive (often referred to as the \"Hotel Manager\"), department heads who oversee various departments within a hotel, middle managers, administrative staff, and line-level supervisors. The organizational chart and volume of job positions and hierarchy varies by hotel size, function, and is often determined by hotel ownership and managing companies.\n\nBoutique hotels are typically hotels with a unique environment or intimate setting.\nSome hotels have gained their renown through tradition, by hosting significant events or persons, such as Schloss Cecilienhof in Potsdam, Germany, which derives its fame from the Potsdam Conference of the World War II allies Winston Churchill, Harry Truman and Joseph Stalin in 1945. The Taj Mahal Palace & Tower in Mumbai is one of India's most famous and historic hotels because of its association with the Indian independence movement. Some establishments have given name to a particular meal or beverage, as is the case with the Waldorf Astoria in New York City, United States where the Waldorf Salad was first created or the Hotel Sacher in Vienna, Austria, home of the Sachertorte. Others have achieved fame by association with dishes or cocktails created on their premises, such as the Hotel de Paris where the crêpe Suzette was invented or the Raffles Hotel in Singapore, where the Singapore Sling cocktail was devised.\n\nA number of hotels have entered the public consciousness through popular culture, such as the Ritz Hotel in London, through its association with Irving Berlin's song, 'Puttin' on the Ritz'. The Algonquin Hotel in New York City is famed as the meeting place of the literary group, the Algonquin Round Table, and Hotel Chelsea, also in New York City, has been the subject of a number of songs and the scene of the stabbing of Nancy Spungen (allegedly by her boyfriend Sid Vicious).\n\nSome hotels are built specifically as a destination in itself to create a captive trade, example at casinos, amusement parks and holiday resorts. Though hotels have always been built in popular destinations, the defining characteristic of a resort hotel is that it exists purely to serve another attraction, the two having the same owners.\n\nOn the Las Vegas Strip there is a tradition of one-upmanship with luxurious and extravagant hotels in a concentrated area. This trend now has extended to other resorts worldwide, but the concentration in Las Vegas is still the world's highest: nineteen of the world's twenty-five largest hotels by room count are on the Strip, with a total of over 67,000 rooms.\n\nIn Europe Center Parcs might be considered a chain of resort hotels, since the sites are largely man-made (though set in natural surroundings such as country parks) with captive trade, whereas holiday camps such as Butlins and Pontin's are probably not considered as resort hotels, since they are set at traditional holiday destinations which existed before the camps.\n\n\nThe Null Stern Hotel in Teufen, Appenzellerland, Switzerland and the Concrete Mushrooms in Albania are former nuclear bunkers transformed into hotels.\n\nThe Cuevas Pedro Antonio de Alarcón (named after the author) in Guadix, Spain, as well as several hotels in Cappadocia, Turkey, are notable for being built into natural cave formations, some with rooms underground. The Desert Cave Hotel in Coober Pedy, South Australia is built into the remains of an opal mine.\n\nLocated on the coast but high above sea level, these hotels offer unobstructed panoramic views and a great sense of privacy without the feeling of total isolation. Some examples from around the globe are the Riosol Hotel in Gran Canaria, Caruso Belvedere Hotel in Amalfi Coast (Italy), Aman Resorts Amankila in Bali, Birkenhead House in Hermanus (South Africa), The Caves in Jamaica and Caesar Augustus in Capri.\n\nCapsule hotels are a type of economical hotel first introduced in Japan, where people sleep in stacks of rectangular containers.\n\nSome hotels fill daytime occupancy with day rooms, for example, Rodeway Inn and Suites near Port Everglades in Fort Lauderdale, Florida. Day rooms are booked in a block of hours typically between 8 am and 5 pm, before the typical night shift. These are similar to transit hotels in that they appeal to travelers, however, unlike transit hotels, they do not eliminate the need to go through Customs.\n\nGarden hotels, famous for their gardens before they became hotels, include Gravetye Manor, the home of garden designer William Robinson, and Cliveden, designed by Charles Barry with a rose garden by Geoffrey Jellicoe.\n\nThe Ice Hotel in Jukkasjärvi, Sweden, was the first ice hotel in the world; first built in 1990, it is built each winter and melts every spring. Other ice hotels include the Igloo Village in Kakslauttanen, Finland, and the Hotel de Glace in Duschenay, Canada. They can also be included within larger ice complexes; for example, the Mammut Snow Hotel in Finland is located within the walls of the Kemi snow castle; and the Lainio Snow Hotel is part of a snow village near Ylläs, Finland.\n\nA love hotel (also 'love motel', especially in Taiwan) is a type of short-stay hotel found around the world, operated primarily for the purpose of allowing guests privacy for sexual activities, typically for one to three hours, but with overnight as an option. Styles of premises vary from extremely low-end to extravagantly appointed. In Japan, love hotels have a history of over 400 years.\n\nA referral hotel is a hotel chain that offers branding to independently-operated hotels; the chain itself is founded by or owned by the member hotels as a group. Many former referral chains have been converted to franchises; the largest surviving member-owned chain is Best Western.\n\nThe first recorded purpose-built railway hotel was the Great Western Hotel, which opened adjacent to Reading railway station in 1844, shortly after the Great Western Railway opened its line from London. The building still exists, and although it has been used for other purposes over the years, it is now again a hotel and a member of the Malmaison hotel chain.\n\nFrequently, expanding railway companies built grand hotels at their termini, such as the Midland Hotel, Manchester next to the former Manchester Central Station, and in London the ones above St Pancras railway station and Charing Cross railway station. London also has the Chiltern Court Hotel above Baker Street tube station, there are also Canada's grand railway hotels. They are or were mostly, but not exclusively, used by those traveling by rail.\n\nThe Maya Guesthouse in Nax Mont-Noble in the Swiss Alps, is the first hotel in Europe built entirely with straw bales. Due to the insulation values of the walls it needs no conventional heating or air conditioning system, although the Maya Guesthouse is built at an altitude of in the Alps.\n\nTransit hotels are short stay hotels typically used at international airports where passengers can stay while waiting to change airplanes. The hotels are typically on the airside and do not require a visa for a stay or re-admission through security checkpoints.\n\nSome hotels are built with living trees as structural elements, for example the Treehotel near Piteå, Sweden, the Costa Rica Tree House in the Gandoca-Manzanillo Wildlife Refuge, Costa Rica; the Treetops Hotel in Aberdare National Park, Kenya; the Ariau Towers near Manaus, Brazil, on the Rio Negro in the Amazon; and Bayram's Tree Houses in Olympos, Turkey.\n\nSome hotels have accommodation underwater, such as Utter Inn in Lake Mälaren, Sweden. Hydropolis, project in Dubai, would have had suites on the bottom of the Persian Gulf, and Jules' Undersea Lodge in Key Largo, Florida requires scuba diving to access its rooms.\n\nA resort island is an island or an archipelago that contains resorts, hotels, overwater bungalows, restaurants, tourist attractions and its amenities. Maldives has the most overwater bungalows resorts.\n\nIn 2006, \"Guinness World Records\" listed the First World Hotel in Genting Highlands, Malaysia, as the world's largest hotel with a total of 6,118 rooms (and which has now expanded to 7,351 rooms). The Izmailovo Hotel in Moscow has the most beds, with 7,500, followed by The Venetian and The Palazzo complex in Las Vegas (7,117 rooms) and MGM Grand Las Vegas complex (6,852 rooms).\n\nAccording to the Guinness Book of World Records, the oldest hotel in operation is the Nisiyama Onsen Keiunkan in Yamanashi, Japan. The hotel, first opened in AD 707 has been operated by the same family for forty-six generations. The title was held until 2011 by the Hoshi Ryokan, in the Awazu Onsen area of Komatsu, Japan, which opened in the year 718, as the history of the Nisiyama Onsen Keiunkan was virtually unknown.\n\nThe Ritz-Carlton, Hong Kong claims to be the world's highest hotel. It is located on the top floors of the International Commerce Centre in Hong Kong, at above ground level.\n\nIn October 2014, the Anbang Insurance Group, based in China, purchased the Waldorf Astoria New York in Manhattan for US$1.95 billion, making it the world's most expensive hotel ever sold.\n\nA number of public figures have notably chosen to take up semi-permanent or permanent residence in hotels.\n\n"}
{"id": "14277", "url": "https://en.wikipedia.org/wiki?curid=14277", "title": "Hebrew mythology", "text": "Hebrew mythology\n\nHebrew mythology may refer to:\n\n"}
{"id": "14279", "url": "https://en.wikipedia.org/wiki?curid=14279", "title": "Hugh Hefner", "text": "Hugh Hefner\n\nHugh Marston Hefner (April 9, 1926 – September 27, 2017) was an American magazine publisher and life-stylist. He was the founder and editor-in-chief of \"Playboy\" magazine, a publication with revealing glamour photographs and sensational articles that provoked charges of obscenity. The first issue of \"Playboy\", published in 1953, featured Marilyn Monroe in a nude calendar shoot and sold over 50,000 copies.\nHefner extended the Playboy brand into a world network of Playboy Clubs. He also resided in luxury mansions where Playboy ‘playmates’ shared his wild partying life, fueling keen media interest. An advocate of sexual liberation and freedom of expression, Hefner was a political activist in other causes; those causes included the Democratic Party, First Amendment rights, animal rescue, and the restoration of the Hollywood Sign.\n\nHefner was born in Chicago on April 9, 1926, the first child of Glenn Lucius Hefner (1896–1976), an accountant, and his wife Grace Caroline (Swanson) Hefner (1895–1997) who worked as a teacher. His parents were from Nebraska. He had a younger brother, Keith (1929–2016). His mother was of Swedish ancestry, and his father was German and English.\n\nThrough his father's line, Hefner was a descendant of Plymouth governor William Bradford. He described his family as \"conservative, Midwestern, [and] Methodist\". His mother had wanted him to become a missionary.\n\nHe attended Sayre Elementary School and Steinmetz High School, then served from 1944 to 1946 as a U.S. Army writer for a military newspaper. Hefner graduated from the University of Illinois at Urbana–Champaign in 1949 with a Bachelor of Arts in Psychology and a double minor in Creative Writing and Art, having earned his degree in two and a half years. After graduation, he took a semester of graduate courses in Sociology at Northwestern University, but dropped out soon after.\n\nIn January 1952, Hefner left his job as a copywriter for \"Esquire\" after he was denied a $5 raise. In 1953, he took out a mortgage loan of $600 and raised $8,000 from 45 investors (including $1,000 from his mother--\"not because she believed in the venture,\" he told \"E!\" in 2006, \"but because she believed in her son\") to launch \"Playboy\", which was initially going to be called \"Stag Party\". The first issue, published in December 1953, featured Marilyn Monroe from her 1949 nude calendar shoot and sold over 50,000 copies. (Hefner, who never met Monroe, bought the crypt next to hers at the Westwood Village Memorial Park Cemetery in 1992 for $75,000.)\n\nAfter the Charles Beaumont science fiction short story \"The Crooked Man\" was rejected by \"Esquire\" magazine in 1955, Hefner agreed to publish the story in \"Playboy.\" The story highlighted straight men being persecuted in a world where homosexuality was the norm. After the magazine received angry letters, Hefner wrote a response to criticism where he said, \"If it was wrong to persecute heterosexuals in a homosexual society then the reverse was wrong, too.\" In 1961, Hefner watched Dick Gregory perform at the Herman Roberts Show Bar in Chicago. Based on that performance, Hefner hired Gregory to work at the Chicago Playboy Club; Gregory attributed the subsequent launch of his career to that night. \n\nHefner promoted a bon vivant lifestyle in his magazine and in two TV shows he hosted, \"Playboy's Penthouse\" (1959–1960) and \"Playboy After Dark\" (1969–1970). He was also the chief creative officer of Playboy Enterprises, the publishing group that operates the magazine.\n\nOn June 4, 1963, Hefner was arrested for promoting obscene literature after he published an issue of \"Playboy\" that featured nude shots of Jayne Mansfield in bed with a man present. The case went to trial and resulted in a hung jury.\n\nIn the 1960s, \"private key\" clubs would be created by Hefner, and these clubs would be racially diverse, in a time where the scent of segregation was still lingering heavy in the air. Also during the civil rights movement in 1966, Hefner sent Alex Haley to interview George Lincoln Rockwell, much to Rockwell's surprise because Haley was black. Rockwell had founded the American Nazi Party and would be later described by some as the \"American Hitler\". Rockwell agreed to meet with Haley only after gaining assurance from the Playboy writer that he was not Jewish, although Rockwell kept a handgun on the table throughout the interview. The interview was recreated in \"\" in 1979, with James Earl Jones as Haley and Marlon Brando as Rockwell; Brando won a Primetime Emmy Award for his portrayal of Rockwell. Haley had also interviewed Malcolm X in 1963 and Martin Luther King Jr. in 1966 for the newly established 1962 \"playboy interview\"; all three interviewees would be assassinated by 1968.\nIn 1970, Hugh Hefner stated that \"militant feminists\" are \"unalterably opposed to the romantic boy-girl society that Playboy promotes\" and ordered a hit piece in his magazine against them.\n\nIn the 1993 \"The Simpsons\" episode \"Krusty Gets Kancelled\", Hefner guest-voiced himself. In 1999, Hefner financed the Clara Bow documentary, \"Discovering the It Girl.\" \"Nobody has what Clara had. She defined an era and made her mark on the nation,\" he stated. Hefner guest-starred as himself in the 2000 \"Sex and the City\" episode \"Sex and Another City\". In 2005, Hefner guest-starred on the HBO TV shows \"Curb Your Enthusiasm\" and \"Entourage\". Hefner guest-starred as himself in a 2006 episode of Seth Green's \"Robot Chicken\" on the late-night programming block Adult Swim. In the 2007 \"Family Guy\" episode \"Airport '07\", Hefner guest-voiced himself. He has a star on the Hollywood Walk of Fame for television and made several movie appearances as himself on the small screen. In 2009, he received a \"worst supporting actor\" nomination for a Razzie award for his performance as himself in \"Miss March\". On his official Twitter account he joked about this nomination: \"Maybe I didn't understand the character.\"\n\nA documentary by Brigitte Berman, \"\", was released on July 30, 2010. He had previously granted full access to documentary filmmaker and television producer Kevin Burns for the A&E \"Biography\" special \"Hugh Hefner: American Playboy\" in 1996. Hefner and Burns later collaborated on numerous other television projects, most notably on \"The Girls Next Door\", a reality series that ran for six seasons (2005–2009) and 90 episodes.\n\nIn 2012, Hefner announced that his youngest son, Cooper, would likely succeed him as the public face of \"Playboy\".\n\nKnown to friends and family as simply \"Hef,\" in 1949, Hefner married Northwestern University student Mildred (\"Millie\") Williams. They had two children: daughter Christie (b. 1952) and son David (b. 1955). Before the wedding, Mildred confessed that she had an affair while he was away in the army. He called the admission \"the most devastating moment of my life.\" A 2006 \"E! True Hollywood Story\" profile of Hefner revealed that Mildred allowed him to have sex with other women, out of guilt for her own infidelity and in the hope that it would preserve their marriage. The two were divorced in 1959.\n\nHefner remade himself as a bon vivant and man about town, a lifestyle he promoted in his magazine and TV shows. He admitted to being \"'involved' with maybe eleven out of twelve months' worth of Playmates\" during some years. Donna Michelle, Marilyn Cole, Lillian Müller, Shannon Tweed, Barbi Benton, Karen Christy, Sondra Theodore, and Carrie Leigh – who filed a $35 million palimony suit against him – were a few of his many lovers. In 1971, he acknowledged that he experimented in bisexuality. Also in 1971, Hefner established a second residence in Los Angeles with the acquisition of Playboy Mansion West and, in 1975, moved there permanently from Chicago.\n\nIn 1985, Hefner had a minor stroke at age 59. After re-evaluating his lifestyle, he made several changes. The wild, all-night parties were toned down significantly and in 1988, daughter Christie took over the operation of the Playboy empire. The following year, he married Playmate of the Year Kimberley Conrad; they were 36 years apart in age. The couple had two sons: Marston Glenn (born 1990) and Cooper Hefner (born 1991). The \"E! True Hollywood Story\" profile noted that the notorious Playboy Mansion had been transformed into a family-friendly homestead. After he and Conrad separated in 1998, she moved into a house next door to the mansion.\n\nHefner became known for moving an ever-changing coterie of young women into the Playboy Mansion, including twins Sandy and Mandy Bentley. He dated as many as seven women concurrently. He also dated Brande Roderick, Izabella St. James, Tina Marie Jordan, Holly Madison, Bridget Marquardt, and Kendra Wilkinson. Madison, Wilkinson, and Marquardt appeared on \"The Girls Next Door\" depicting their lives at the Playboy Mansion. In October 2008, all three girls decided to leave the mansion. After an 11-year separation, Hefner filed for divorce from Conrad citing irreconcilable differences. Hefner has stated that he only remained nominally married to her for the sake of his children, and his youngest child had just turned 18.\n\nIn January 2009, Hefner began a relationship with Crystal Harris; she joined the Shannon Twins after his previous \"number one girlfriend\", Holly Madison, had ended their seven-year relationship. On December 24, 2010, he became engaged to Harris, to become his third wife. Harris broke off their engagement on June 14, 2011, five days before their planned wedding. In anticipation of the wedding, the July issue of \"Playboy\", which reached store shelves and customer's homes within days of the wedding date, featured Harris on the cover and in a photo spread as well. The headline on the cover read \"Introducing America's Princess, Mrs. Crystal Hefner\". Hefner and Harris subsequently reconciled and married on December 31, 2012.\n\nHefner's brother Keith died at the age of 87 on April 8, 2016, one day before Hefner's 90th birthday.\n\nIn January 2016, the Playboy Mansion was put on the market for $200 million, on condition that Hugh Hefner would continue to work and live in the mansion. Later that year it was sold to Daren Metropoulos, a principal at private equity firm Metropoulos & Company, for $100 million. Metropoulos planned to reconnect the Playboy Mansion property with a neighboring estate that he purchased in 2009, combining the two for a 7.3 acre (3-hectare) compound as his own private residence.\n\nIn May 2017, Eugena Washington was the last Playmate of the Year to be announced by Hugh Hefner at the Playboy Mansion.\n\nThe Hugh M. Hefner First Amendment Award was created by Christie Hefner \"to honor individuals who have made significant contributions in the vital effort to protect and enhance First Amendment rights for Americans.\"\n\nHe donated and raised money for the Democratic Party. In 2011, he referred to himself as an independent due to dissatisfaction with both the Democratic and Republican parties. Nonetheless, in 2012, he supported Barack Obama's reelection campaign.\n\nIn 1978, Hefner helped organize fund-raising efforts that led to the restoration of the Hollywood Sign. He hosted a gala fundraiser at the Playboy Mansion and contributed $27,000 (or 1/9 of the total restoration costs) by purchasing the letter Y in a ceremonial auction.\n\nHefner donated $100,000 to the University of Southern California's School of Cinematic Arts to create a course called \"Censorship in Cinema\", and $2 million to endow a chair for the study of American film. In 2007, the university's audiovisual archive at the Norris Theater received a donation from Hefner and was renamed to the Hugh M. Hefner Moving Image Archive in his honor.\n\nBoth through his charitable foundation and individually, Hefner also contributed to charities outside the sphere of politics and publishing, throwing fundraiser events for Much Love Animal Rescue as well as Generation Rescue, an anti-vaccinationist campaign organization supported by Jenny McCarthy.\n\nOn November 18, 2010, Children of the Night founder and president Dr. Lois Lee presented Hefner with the organization's first-ever Founder's Hero of the Heart Award in appreciation for his unwavering dedication, commitment and generosity.\n\nOn April 26, 2010, Hefner donated the last $900,000 sought by a conservation group for a land purchase needed to stop the development of the famed vista of the Hollywood Sign. \"Sylvilagus palustris hefneri\", an endangered subspecies of marsh rabbit, is named after him in honor of financial support that he provided.\n\nThe Barbi Twins who are among a notable cohort of celebrity Playmates, including Pamela Anderson and Hefner's third wife Crystal Harris, praised the publishing icon for providing centerfolds and extended members of the Playboy family with a platform for activism and advocacy on behalf of animal populations in need.\n\nHefner supported legalizing same-sex marriage, and he stated that a fight for gay marriage was \"a fight for all our rights. Without it, we will turn back the sexual revolution and return to an earlier, puritanical time.\"\n\nHefner died at his home in Holmby Hills, Los Angeles, California, on September 27, 2017, at the age of 91. The cause was sepsis brought on by an \"E. coli\" infection.\n\nHe is interred at Westwood Memorial Park in Los Angeles, in the $75,000 crypt beside Marilyn Monroe. \"Spending eternity next to Marilyn is an opportunity too sweet to pass up,\" Hefner had told the \"Los Angeles Times\" in 2009.\n\nIn \"The Guardian\", journalist Suzanne Moore wrote that Hefner threatened to file a lawsuit against her for calling him a \"pimp\". Defending her position, Moore argued that \"he was a man who bought and sold women to other men\". She further stated that \"Part of Hefner's business acumen was to make the selling of female flesh respectable and hip, to make soft porn acceptable.\"\n\nWriting for \"The Independent\", English writer Julie Bindel argued that Hefner \"caused immeasurable damage by turning porn and therefore the buying and selling of women's bodies into a legitimate business.\"\n\nIn the \"Los Angeles Times\", Robin Abcarian wrote that Hefner \"probably did more to the mainstream exploitation of women's bodies than any other figure in American history,\" adding that he \"managed to convince many women that taking off their clothes for men's pleasure was not just empowering, but a worthy goal in itself.\" She further stated that Hefner \"embodied the aesthetic notion that images of women — and women themselves — exist to please men.\"\n\nWriting for \"Christianity Today\", Ed Stetzer wrote that during his lifetime, when Christie Hefner visited the Playboy Mansion, he would have the residence systematically \"cleaned\" in order \"to keep the realities from his own daughter\". Stezer further lamented the consequences of Hefner's role as a \"general\" of the sexual revolution:\n\nHefner's former girlfriend, Holly Madison, said that while she lived in the Playboy Mansion, Hefner \"would encourage competition—and body image issues—between his multiple live-in girlfriends. His legacy is full of evidence of the exploitation of women for professional gain.\"\n\nOn October 3, 2017, it was announced that Academy Award-winning actor Jared Leto would play Hugh Hefner in a biopic directed by Brett Ratner with the screenplay by Jeff Nathanson. However, the film was indefinitely put on hold and it was confirmed that Leto would not portray Hefner following an emergence of sexual harassment allegations against Ratner on November 2, 2017.\n\n\n"}
{"id": "14280", "url": "https://en.wikipedia.org/wiki?curid=14280", "title": "Hafizullah Amin", "text": "Hafizullah Amin\n\nHafizullah Amin (Pashto/; born 1 August 1929 – 27 December 1979) was an Afghan communist politician during the Cold War. Amin was born in Paghman and educated at Kabul University, after which he started his career as a teacher. After a few years in that occupation, he went to the United States to study. He would visit the United States a second time before moving permanently to Afghanistan, and starting his career in radical politics. He ran as a candidate in the 1965 parliamentary election but failed to secure a seat. Amin was the only Khalqist elected to parliament in the 1969 parliamentary election, thus increasing his standing within the party. He was one of the leading organisers of the Saur Revolution which overthrew the government of Mohammad Daoud Khan.\n\nAmin's short-lived presidency was marked by controversies from beginning to end. He came to power by disposing of his predecessor Nur Muhammad Taraki and later ordering his death. Amin made attempts to win support from those who revolted against the communist regime which had begun under Taraki, but his government was unable to solve this problem. Many Afghans held Amin responsible for the regime's harshest measures, such as ordering thousands of executions. The Soviet Union, which was dissatisfied with Amin and also alleged that he could be an agent of the CIA, intervened in Afghanistan while invoking the Twenty-Year Treaty of Friendship between Afghanistan and the Soviet Union. Amin was assassinated by the Soviets on December 27, 1979 as part of Operation Storm-333, having ruled for slightly longer than three months.\n\nHafizullah Amin was born to a Ghilzai Pashtun family in Paghman on 1 August 1929. His father, a civil servant, died when he was still very young. Thanks to his brother Abdullah, a primary school teacher, Amin was able to attend both primary and secondary school, which in turn allowed him to attend Kabul University (KU). After studying mathematics there, he also graduated from the Darul Mualimeen Teachers College in Kabul, and became a teacher. Amin later became vice-principal of the Darul Mualimeen College, and then principal of the prestigious Avesina High School, and in 1957 left Afghanistan for Columbia University in New York City, where he earned M. A. in education. It was at Columbia that Amin became attracted to Marxism, and in 1958 he became a member of the university's Socialist Progressive Club. When he returned to Afghanistan, Amin became a teacher at Kabul University, and later, for the second time, the principal of Avesina High School. During this period Amin became acquainted with Nur Muhammad Taraki, a communist. Around this time, Amin quit his position as principal of Avesina High School in order to become principal of the Darul Mualimeen College.\n\nIt is alleged that Amin became radicalised during his second stay in the United States in 1962, when he enrolled in a work-study group at the University of Wisconsin. Amin studied in the doctoral programme at the Columbia University Teachers College, but started to neglect his studies in favour of politics; in 1963 he became head of the Afghan students' association at the college. When he returned to Afghanistan in the mid-1960s, the route flew to Afghanistan by way of Moscow. There, Amin met the Afghan ambassador to the Soviet Union, his old friend Ali Ahmad Popel, a previous Afghan Minister of Education. During his short stay, Amin became even more radicalised. Some people, Nabi Misdaq for instance, do not believe he travelled through Moscow, but rather West Germany and Lebanon. By the time he had returned to Afghanistan, the Communist People's Democratic Party of Afghanistan (PDPA) had already held its founding congress, which was in 1965. Amin ran as a candidate for the PDPA in the 1965 parliamentary election, and lost by a margin of less than fifty votes.\n\nIn 1966, when the PDPA Central Committee was expanded, Amin was elected as a non-voting member, and in the spring of 1967 he gained full membership. Amin's standing in the Khalq faction of the PDPA increased when he was the only Khalqist elected to parliament in the 1969 parliamentary election. When the PDPA split along factional lines in 1967, between Khalqists led by Nur and Parchamites led by Babrak Karmal, Amin joined the Khalqists. As a member of parliament, Amin tried to win over support from the Pashtun people in the armed forces. According to a biography about Amin, he used his position as member of parliament to fight against imperialism, feudalism, and reactionary tendencies, and fought against the \"rotten\" regime, the monarchy. Amin himself said that he used his membership in parliament to pursue the class struggle against the bourgeoisie. Relations between Khalqists and Parchamites deteriorated during this period. Amin, the only Khalq member of parliament, and Babrak Karmal, the only Parcham member of parliament, did not cooperate with each other. Amin would later, during his short stint in power, mention these events with bitterness. Following the arrest of fellow PDPA members Dastagir Panjsheri and Saleh Mohammad Zeary in 1969, Amin became one of the party's leading members, and was still a pre-eminent party member by the time of their release in 1973.\n\nFrom 1973 until the PDPA unification in 1977, Amin was second only to Taraki in the Khalqist PDPA. When the PDPA ruled Afghanistan, their relationship was referred to as a disciple (Amin) following his mentor (Taraki). This official portrayal of the situation was misleading; their relationship was more work-oriented. Taraki needed Amin's \"tactical and strategic talents\"; Amin's motivations are more uncertain, but it is commonly believed that he associated with Taraki to protect his own position. Amin had attracted many enemies during his career, the most notable being Karmal. According to the official version of events, Taraki protected Amin from party members or others who wanted to hurt the PDPA and the country.\n\nWhen Mohammed Daoud Khan ousted the monarchy, and established the Republic of Afghanistan, the Khalqist PDPA offered its support for the new regime if it established a National Front which presumably included the Khalqist PDPA itself. The Parchamite PDPA had already established an alliance with Daoud at the beginning of his regime, and Karmal called for the dissolution of the Khalqist PDPA. Karmal's call for dissolution only worsened relations between the Khalqist and Parchamite PDPA. However, Taraki and Amin were lucky; Karmal's alliance actually hurt the Parchamites' standing in Afghan politics. Some communists in the armed forces became disillusioned with the government of Daoud, and turned to the Khalqist PDPA because of its apparent independence. Parchamite association with the Daoud government indirectly led to the Khalqist-led PDPA coup of 1978, popularly referred to as the Saur Revolution. From 1973 until the 1978 coup, Amin was responsible for organising party work in the Afghan armed forces. According to the official version, Amin \"met patriotic liaison officers day or night, in the desert or the mountains, in the fields or the forests, enlightening them on the basis of the principles of the working class ideology.\" Amin's success in recruiting military officers lay in the fact that Daoud \"betrayed the left\" soon after taking power. When Amin began recruiting military officers for the PDPA, it was not difficult for him to find disgruntled military officers. In the meantime, relations between the Parchamite and Khalqist PDPA deteriorated; in 1973 it was rumoured that Major Zia Mohammadzai, a Parchamite and head of the Republican Guard, planned to assassinate the entire Khalqist leadership. The plan, if true, failed because the Khalqists found out about it.\n\nThe assassination attempt proved to be a further blow to relations between the Parchamites and Khalqists. The Parchamites deny that they ever planned to assassinate the Khalqist leadership, but historian Beverley Male argues that Karmal's subsequent activities give credence to the Khalqist view of events. Because of the Parchamite assassination attempt, Amin pressed the Khalqist PDPA to seize power in 1976 by ousting Daoud. The majority of the PDPA leadership voted against such a move. The following year, in 1977, the Parchamites and Khalqists officially reconciled, and the PDPA was unified. The Parchamite and Khalqist PDPAs, which had separate general secretaries, politburos, central committees and other organisational structures, were officially unified in the summer of 1977. One reason for unification was that the international communist movement, represented by the Communist Party of India, Iraqi Communist Party and the Communist Party of Australia, called for party unification.\n\nOn 18 April 1978 Mir Akbar Khyber, the chief ideologue of the Parcham faction, was killed; he was commonly believed to have been assassinated by the Daoud government. Khyber's assassination initiated a chain of events which led to the PDPA taking power eleven days later, on 27 April. The assassin was never caught, but Anahita Ratebzad, a Parchamite, believed that Amin had ordered the assassination. Khyber's funeral evolved into a large anti-government demonstration. Daoud, who did not understand the significance of the events, began a mass arrest of PDPA members seven days after Khyber's funeral. Amin, who organised the subsequent revolution against Daoud, was one of the last Central Committee members to be arrested by the authorities. His late arrest can be considered as proof of the regime's lack of information; Amin was the leading revolutionary party organiser. The government's lack of awareness was proven by the arrest of Taraki – Taraki's arrest was the pre-arranged signal for the revolution to commence. When Amin found out that Taraki had been arrested, he ordered the revolution to begin at 9am on 27 April. Amin, in contrast to Taraki, was not imprisoned, but instead put under house arrest. His son, Abdur Rahman, was still allowed freedom of movement. The revolution was successful, thanks to overwhelming support from the Afghan military; for instance, it was supported by Defence Minister Ghulam Haidar Rasuli, Aslam Watanjar the commander of the ground forces, and the Chief of Staff of the Afghan Air Force, Abdul Qadir.\n\nAfter the Saur revolution, Taraki was appointed Chairman of the Presidium of the Revolutionary Council and Chairman of the Council of Ministers, and retained his post as PDPA general secretary. Taraki initially formed a government which consisted of both Khalqists and Parchamites; Karmal became Deputy Chairman of the Revolutionary Council while Amin became Minister of Foreign Affairs and a Deputy Prime Minister, and Mohammad Aslam Watanjar became a Deputy Prime Minister. The two Parchamites Abdul Qadir and Mohammad Rafi became Minister of National Defence and Minister of Public Works respectively. According to Angel Rasanayagam, the appointment of Amin, Karmal and Watanjar as Deputy Prime Ministers led to the establishment of three cabinets; the Khalqists were answerable to Amin, the Parchamites were answerable to Karmal, and the military officers (who were Parchamites) were answerable to Watanjar. The first conflict between the Khalqists and Parchamites arose when the Khalqists wanted to give PDPA Central Committee membership to the military officers who participated in the Saur Revolution. Amin, who had previously opposed the appointment of military officers to the PDPA leadership, switched sides; he now supported their elevation. The PDPA Politburo voted in favour of giving membership to the military officers; the victors (the Khalqists) portrayed the Parchamites as opportunists, implying that the Parchamites had ridden the revolutionary wave, but not actually participated in the revolution. To make matters worse for the Parchamites, the term Parcham was, according to Taraki, a word synonymous with factionalism.\n\nOn 27 June 1978, three months after the revolution, Amin managed to outmaneuver the Parchamites at a Central Committee meeting. The meeting decided that the Khalqists had exclusive rights to formulate and decide policy, a policy which left the Parchamites impotent. Karmal was exiled, but was able to establish a network with the remaining Parchamites in government. A coup to overthrow Amin was planned for September. Its leading members in Afghanistan were Qadir, the defence minister, and Army Chief of Staff General Shahpur Ahmedzai. The coup was planned for 4 September, on the Festival of Eid, because soldiers and officers would be off duty. The conspiracy failed when the Afghan ambassador to India told the Afghan leadership about the plan. A purge was initiated, and Parchamite ambassadors were recalled; few returned, for example Karmal and Mohammad Najibullah both stayed in their assigned countries.\n\nThe Afghan people revolted against the PDPA government when the government introduced several socialist reforms, including land reforms. By early 1979, twenty-five out of Afghanistan's twenty-eight provinces were unsafe because of armed resistance against the government. On 29 March 1979, the Herat uprising began; the uprising turned the revolt into an open war between the Mujahideen and the Afghan government. It was during this period that Amin became Kabul's strongman. Shortly after the Herat uprising had been crushed, the Revolutionary Council convened to ratify the new Five-Year Plan, the Afghan–Soviet Friendship Treaty, and to vote on whether or not to reorganise the cabinet and to enhance the power of the executive (the Chairman of the Revolutionary Council). While the official version of events said that all issues were voted on democratically at the meeting, the Revolutionary Council held another meeting the following day to ratify the new Five-Year Plan and to discuss the reorganisation of the cabinet.\n\nAlexander Puzanov, the Soviet ambassador to Afghanistan, was able to persuade Aslam Watanjar, Sayed Mohammad Gulabzoy and Sherjan Mazdoryar to become part of a conspiracy against Amin. These three men put pressure on Taraki, who by this time believed that \"he really was the 'great leader'\", to sack Amin from office. It is unknown if Amin knew anything about the conspiracy against him, but it was after the cabinet reorganisation that he talked about his dissatisfaction. On 26 March the PDPA Politburo and the Council of Ministers approved the extension of the powers of the executive branch, and the establishment of the Homeland Higher Defence Council (HHDC) to handle security matters. Many analysts of the day regarded Amin's appointment as Prime Minister as an increase in his powers at the expense of Taraki. However, the reorganisation of the cabinet and the strengthening of Taraki's position as Chairman of the Revolutionary Council, had reduced the authority of the Prime Minister. The Prime Minister was, due to the strengthening of the executive, now appointed by the Chairman of the Revolutionary Council. While Amin could appoint and dismiss new ministers, he needed Taraki's consent to actually do so. Another problem for Amin was that while the Council of Ministers was responsible to the Revolutionary Council and its chairman, individual ministers were only responsible to Taraki. When Amin became Prime Minister, he was responsible for planning, finance and budgetary matters, the conduct of foreign policy, and for order and security. The order and security responsibilities had been taken over by the HHDC, which was chaired by Taraki. While Amin was HHDC Deputy Chairman, the majority of HHDC members were members of the anti-Amin faction. For instance, the HHDC membership included Watanjar the Minister of National Defence, Interior Minister Mazdoryar, the President of the Political Affairs of the Armed Forces Mohammad Iqbal, Mohammad Yaqub, the Chief of the General Staff, the Commander of the Afghan Air Force Nazar Mohammad and Assadullah Sarwari the head of ASGA, the Afghan secret police.\n\nThe order of precedence had been institutionalised, whereby Taraki was responsible for defence and Amin responsible for assisting Taraki in defence related matters. Amin's position was given a further blow by the democratisation of the decision-making process, which allowed its members to contribute; most of them were against Amin. Another problem for Amin was that the office of HHDC Deputy Chairman had no specific functions or powers, and the appointment of a new defence minister who opposed him drastically weakened his control over the Ministry of National Defence. The reorganisation of ministers was a further blow to Amin's position; he had lost control of the defence ministry, the interior ministry and the ASGA. Amin still had allies at the top, many of them in strategically important positions, for instance, Yaqub was his brother-in-law and the Security Chief in the Ministry of Interior was Sayed Daoud Taroon, who was also later appointed to the HHDC as an ordinary member in April. Amin succeeded in appointing two more of his allies to important positions; Mohammad Sediq Alemyar as Minister of Planning and Khayal Mohammad Katawazi as Minister of Information and Culture; and Faqir Mohammad Faqir was appointed Deputy Prime Minister in April 1978. Amin's political position was not secure when Alexei Yepishev, the Head of the Main Political Directorate of the Soviet Army and Navy, visited Kabul. Yepishev met personally with Taraki on 7 April, but never met with Amin. The Soviets were becoming increasingly worried about Amin's control over the Afghan military. Even so, during Yepishev's visit Amin's position was actually strengthened; Taroon was appointed Taraki's aide-de-camp.\nSoon after, at two cabinet meetings, the strengthening of the executive powers of the Chairman of the Revolutionary Council was proven. Even though Amin was Prime Minister, Taraki chaired the meetings instead of him. Amin's presence at these two meetings was not mentioned at all, and it was made clear that Taraki, through his office as Chairman of the Revolutionary Council, also chaired the Council of Ministers. Another problem facing Amin was Taraki's policy of autocracy; he tried to deprive the PDPA Politburo of its powers as a party and state decision-making organ. The situation deteriorated when Amin personally warned Taraki that \"the prestige and popularity of leaders among the people has no common aspect with a personality cult.\"\n\nFactionalism within the PDPA made it ill-prepared to handle the intensified counter-revolutionary activities in the country. Amin tried to win support for the communist government by depicting himself as a devout Muslim. Taraki and Amin blamed different countries for helping the counter-revolutionaries; Amin attacked the United Kingdom and the British Broadcasting Corporation (BBC) and played down American and Chinese involvement, while Taraki blamed American imperialism and Iran and Pakistan for supporting the uprising. Amin's criticism of the United Kingdom and the BBC fed on the traditional anti-British sentiments held by rural Afghans. In contrast to Taraki, \"Amin bent over backwards to avoid making hostile reference to\", China, the United States or other foreign governments. Amin's cautious behavior was in deep contrast to the Soviet Union's official stance on the situation; it seemed, according to Beverley Male, that the Soviet leadership tried to force a confrontation between Afghanistan and its enemies. Amin also tried to appease the Shia communities by meeting with their leaders; despite this, a section of the Shia leadership called for the continuation of the resistance. Subsequently, a revolt broke out in a Shia populated district in Kabul; this was the first sign of unrest in Kabul since the Saur Revolution. To add to the government's problems, Taraki's ability to lead the country was questioned – he was a heavy drinker and was not in good health. Amin on the other hand was characterised in this period by portrayals of strong self-discipline. In the summer of 1979 Amin began to disassociate himself from Taraki. On 27 June Amin became a member of the PDPA Politburo, the leading decision-making body in Afghanistan.\n\nIn-mid July the Soviets made their view official when \"Pravda\" wrote an article about the situation in Afghanistan; the Soviets did not wish to see Amin become leader of Afghanistan. This triggered a political crisis in Afghanistan, as Amin initiated a policy of extreme repression, which became one of the main reasons for the Soviet intervention later that year. On 28 July, a vote in the PDPA Politburo approved Amin's proposal of creating a collective leadership with collective decision-making; this was a blow to Taraki, and many of his supporters were replaced by pro-Amin PDPA members. Ivan Pavlovsky, the Commander of the Soviet Ground Forces, visited Kabul in mid-August to study the situation in Afghanistan. Amin, in a speech just a few days after Pavlovsky's arrival, said that he wanted closer relations between Afghanistan and the People's Republic of China; in the same speech he hinted that he had reservations about Soviet meddling in Afghanistan. He likened Soviet assistance to Afghanistan with Vladimir Lenin's assistance to the Hungarian Soviet Republic in 1919. Taraki, a delegate to the conference held by the Non-Aligned Movement in Havana, met personally with Andrei Gromyko, the Soviet Minister of Foreign Affairs, to discuss the Afghanistan situation on 9 September. Shah Wali, the Minister of Foreign Affairs, who was a supporter of Amin, did not participate in the meeting. This, according to Beverley Male, \"suggested that some plot against Amin was in preparation\".\n\nTaraki was instructed to stop-over in Moscow, where the Soviet leaders urged him to remove Amin from power as per the KGB's decision, because Amin posed danger. Amin's trusted aid, Daoud Taroon, informed Amin of the meeting and the KGB's plan. In Kabul, Taraki's aides, the Gang of Four (consisting of Watanjar, Mazdoryar, Gulabzoi and Sarwari), planned a plot to assassinate Amin, but it failed as Amin was informed of this. Within hours of Taraki's return to Kabul on 11 September, Taraki convened the cabinet \"ostensibly to report on the Havana Summit\". Instead of reporting on the summit, Taraki tried to dismiss Amin as Prime Minister. Amin, aware of the murder plot, demanded the Gang of Four to be removed from their posts, but Taraki laughed it off. Taraki sought to neutralise Amin's power and influence by requesting that he serve overseas as an ambassador. Amin turned down the proposal, shouting \"You are the one who should quit! Because of drink and old age you have taken leave of your senses.\"\n\nOn September 13, Taraki invited Amin to the presidential palace for lunch with him and the Gang of Four. Amin turned down the offer, stating he would prefer their resignation rather than lunching with them. Soviet ambassador Puzanov persuaded Amin to make the visit to the Presidential Palace along with Taroon, the Chief of Police, and Nawab Ali, an intelligence officer. Inside the palace on September 14, bodyguards within the building opened fire on the visitors. Taroon was killed but Amin only sustained an injury and escaped. Amin drove to the Ministry of Defence building, put the Army on high alert and ordered Taraki's arrest. At 6:30pm tanks from the 4th Armoured Corps entered the city and stood at government buildings. Shortly afterwards, Amin returned to the palace with a contingent of Army officers, and placed Taraki under arrest. The Gang of Four, however, had \"disappeared\" and sought refuge in the Soviet Embassy.\n\nAfter Taraki's arrest, the Soviets tried to rescue Taraki (or, according to other sources, kidnap Amin) via the embassy or Bagram Air Base but the strength of Amin's officers repelled their decision to make a move. Amin was told by the Soviets not to punish Taraki and strip him and his comrades of their positions, but Amin ignored them. Amin reportedly discussed the incident with Leonid Brezhnev, and indirectly asked for the permission to kill Taraki, to which Brezhnev replied that it was his choice. Amin, who now believed he had the full support of the Soviets, ordered the death of Taraki. It is believed Taraki was suffocated with pillows on October 8, 1979. The Afghan media would report that the ailing Taraki had died, omitting any mention of his murder. Taraki's murder shocked and upset Brezhnev.\n\nFollowing Taraki's fall from power, Amin was elected Chairman of the Presidum of the Revolutionary Council and General Secretary of the PDPA Central Committee by the PDPA Politburo. The election of Amin as PDPA General Secretary and the removal of Taraki from all party posts was unanimous. The only members of the cabinet replaced when Amin took power were the Gang of Four – Beverley Male saw this as \"a clear indication that he had their [the ministers'] support\". Amin's rise to power was followed by a policy of moderation, and attempts to persuade the Afghan people that the regime was not anti-Islamic. Amin's government began to invest in the reconstruction, or reparation, of mosques. He also promised the Afghan people freedom of religion. Religious groups were given copies of the Quran, and Amin began to refer to Allah in speeches. He even claimed that the Saur Revolution was \"totally based on the principles of Islam\". The campaign proved to be unsuccessful, and many Afghans held Amin responsible for the regime's totalitarian behavior. Amin's rise to power was officially endorsed by the Jamiatul Ulama on 20 September 1979. Their endorsement led to the official announcement that Amin was a pious Muslim – Amin thus scored a point against the counter-revolutionary propaganda which claimed the communist regime was atheist. Amin also tried to increase his popularity with tribal groups, a feat Taraki had been unable or unwilling to achieve. In a speech to tribal elders Amin was defensive about the Western way he dressed; an official biography was published which depicted Amin in traditional Pashtun clothes. During his short stay in power, Amin became committed to establishing a collective leadership; when Taraki was ousted, Amin promised \"from now on there will be no one-man government...\"\n\nAttempting to pacify the population, Amin released a list of 18,000 people who had been executed, and blamed the executions on Taraki. The total number of arrested during Taraki's and Amin's combined reign number between 17,000 and 45,000. Amin was not liked by the Afghan people. During his rule, opposition to the communist regime increased, and the government lost control of the countryside. The state of the Afghan military deteriorated; due to desertions the number of military personnel in the Afghan army decreased from 100,000 in the immediate aftermath of the Saur Revolution, to somewhere between 50,000 and 70,000. Another problem Amin faced was the KGB's penetration of the PDPA, the military and the government bureaucracy. While Amin's position in Afghanistan was becoming more perilous by the day, his enemies who were exiled in the Soviet Union and the Eastern Bloc were agitating for his removal. Babrak Karmal, the Parchamite leader, met several leading Eastern Bloc figures during this period, and Mohammad Aslam Watanjar, Sayed Mohammad Gulabzoy and Assadullah Sarwari wanted to exact revenge upon Amin.\n\nWhen Amin became leader, he tried to reduce Afghanistan's dependence on the Soviet Union. To accomplish this, he aimed to balance Afghanistan's relations with the Soviet Union by strengthening relations with Pakistan and Iran. The Soviets were concerned when they received reports that Amin had met personally with Gulbuddin Hekmatyar, one of the leading anti-communists in Afghanistan. His general untrustworthiness and his unpopularity amongst Afghans made it more difficult for Amin to find new \"foreign patrons\". Amin's involvement in the death of Adolph Dubs, the American Ambassador to Afghanistan, strained his relations with the United States. He tried to improve relations by reestablishing contact, met with three different American chargé d'affaires, and was interviewed by an American correspondent. But this did not improve Afghanistan's standing in the eyes of the United States Government. After the third meeting with Amin, J. Bruce Amstutz, the American Ambassador to Afghanistan from 1979 to 1980, believed the wisest thing to do was to maintain \"a low profile, trying to avoid issues, and waiting to see what happens\". In early December 1979, the Ministry of Foreign Affairs proposed a joint summit meeting between Amin and Muhammad Zia-ul-Haq, the President of Pakistan. The Pakistani Government, accepting a modified version of the offer, agreed to send Agha Shahi, the Pakistani foreign minister, to Kabul for talks. In the meanwhile, the Inter-Services Intelligence (ISI), Pakistani's secret police, continued to train Mujahideen fighters who opposed the communist regime.\n\nContrary to popular belief, the Soviet leadership headed by Leonid Brezhnev, Alexei Kosygin and the Politburo, were not eager to send troops to Afghanistan. The Soviet Politburo decisions were guided by a Special Commission on Afghanistan, which consisted of Yuri Andropov the KGB Chairman, Andrei Gromyko the Minister of Foreign Affairs, Defence Minister Dmitriy Ustinov, and Boris Ponomarev, the head of the International Department of the Central Committee. The Politburo was opposed to the removal of Taraki and his subsequent murder. According to Brezhnev, the General Secretary of the Central Committee of the Communist Party of the Soviet Union, \"Events developed so swiftly in Afghanistan that essentially there was little opportunity to somehow interfere in them. Right now our mission is to determine our further actions, so as to preserve our position in Afghanistan and to secure our influence there.\" Although Afghan–Soviet relations deteriorated during Amin's short stint in power, he was invited on an official visit to Moscow by Alexander Puzanov, the Soviet ambassador to Afghanistan, because of the Soviet leadership's satisfaction with his party and state-building policy. Not everything went as planned, and Andropov talked about \"the undesirable turn of events\" taking place in Afghanistan under Amin's rule. Andropov also brought up the ongoing political shift in Afghanistan under Amin; the Soviets were afraid that Amin would move Afghanistan's foreign policy from a pro-Soviet position to a pro-United States position. By early-to-mid December 1979, the Soviet leadership had established an alliance with Babrak Karmal and Assadullah Sarwari.\nAmin kept a portrait of Joseph Stalin on his desk. When Soviet officials criticized him of his brutality, Amin replied \"Comrade Stalin showed us how to build socialism in a backward country.\"\n\nAs it turned out, the relationship between Puzanov and Amin broke down. Amin started a smear campaign to discredit Puzanov. This in turn led to an assassination attempt against Amin, in which Puzanov participated. The situation was worsened by the KGB accusing Amin of misrepresenting the Soviet position on Afghanistan in the PDPA Central Committee and the Revolutionary Council. The KGB also noted an increase in anti-Soviet agitation by the government during Amin's rule, and harassment against Soviet citizens increased under Amin. A group of senior politicians reported to the Soviet Central Committee that it was necessary to do \"everything possible\" to prevent a change in political orientation in Afghanistan. However, the Soviet leadership did not advocate intervention at this time, and instead called for increasing its influence in the Amin leadership to expose his \"true intentions\". A Soviet Politburo assessment referred to Amin as \"a power-hungry leader who is distinguished by brutality and treachery\". Amongst the many sins they alleged were his \"insincerity and duplicity\" when dealing with the Soviet Union, creating fictitious accusations against PDPA-members who opposed him, indulging in a policy of nepotism, and his tendency to conduct a more \"balanced policy\" towards First World countries. According to the former senior Soviet diplomat, Oleg Grinevsky, the KGB was becoming increasingly convinced that Amin couldn't be counted on to effectively deal with the insurgency and preserve the survival of the Afghan Marxist state.\n\nBy the end of October the Special Commission on Afghanistan, which consisted of Andropov, Gromyko, Ustinov and Ponomarev, wanted to end the impression that the Soviet government supported Amin's leadership and policy. The KGB's First Chief Directorate was put under orders that something had to be done about Afghanistan, and several of its personnel were assembled to deal with the task. Andropov fought hard for Soviet intervention, saying to Brezhnev that Amin's policies had destroyed the military and the government's capabilities to handle the crisis by use of mass repression. The plan, according to Andropov, was to assemble a small force to intervene and remove Amin from power and replace him with Karmal. The Soviet Union declared its plan to intervene in Afghanistan on 12 December 1979, and the Soviet leadership initiated Operation Storm-333 (the first phase of the intervention) on 27 December 1979.\n\nAmin trusted the Soviet Union until the very end, despite the deterioration of official relations, and was unaware that the tide in Moscow had turned against him since he ordered Taraki's death. When the Afghan intelligence service handed Amin a report that the Soviet Union would invade the country and topple him, Amin claimed that the report was a product of imperialism. His view can be explained by the fact that the Soviet Union, after several months, finally gave in to Amin's demands and sent troops into Afghanistan to secure the PDPA government. Contrary to common Western belief, Amin was informed of the Soviet decision to send troops into Afghanistan. General Tukharinov, commander of the 40th Army, met with Afghan Major General Babadzhan to talk about Soviet troop movements before the Soviet army's intervention. On 25 December, Dmitry Ustinov issued a formal order, stating that \"[t]he state frontier of the Democratic Republic of Afghanistan is to be crossed on the ground and in the air by forces of the 40th Army and the Air Force at 1500 hrs on 25 December\". This was the formal beginning of the Soviet intervention in Afghanistan.\n\nConcerned for his safety, on 20 December Amin moved from the Presidential Palace, located in the centre of Kabul, to the Tajbeg Palace, which had previously been the headquarters of the Central Army Corps of the Afghan military. The palace was formidable, with walls strong enough to withstand artillery fire. According to Rodric Braithwaite, \"its defences had been carefully and intelligently organised\". All roads to the palace had been mined, with the exception of one, which had heavy machine guns and artillery positioned to defend it. To make matters worse for the Soviets, the Afghans had established a second line of defence which consisted of seven posts, \"each manned by four sentries armed with a machine gun, a mortar, and automatic rifles\". The external defences of the palace were handled by the Presidential Guard, which consisted of 2,500 troops and three T-54 tanks. Several Soviet commanders involved in the assassination of Amin thought the plan to attack the palace was \"crazy\". Although the military had been informed by the Soviet leadership through their commanders, Yuri Drozdov and Vasily Kolesnik, that the president was a \"CIA agent\" who had betrayed the Saur Revolution, many Soviet soldiers hesitated; despite what their commanders had told them, it seemed implausible that Amin, the leader of the PDPA government, was an American double agent. Despite several objections, the plan to assassinate Amin went ahead.\n\nBefore resorting to killing Amin by brute force, the Soviets had tried to poison as early as 13 December (but nearly killed his nephew instead) and to kill him with a sniper shot on his way to work (this proved impossible as the Afghans had improved their security measures). They even tried to poison Amin just hours before the assault on the Presidential Palace on 27 December. Amin had organised a lunch for party members to show guests his palace and to celebrate Ghulam Dastagir Panjsheri's return from Moscow. Panjsheri's return improved the mood even further; he boasted that the Soviet divisions had already crossed the border, and that he and Gromyko always kept in contact with each other. During the meal, Amin and several of his guests lost consciousness as they had been poisoned. Luckily for Amin, but unfortunately for the Soviets, he survived his encounter with death, because the carbonation of the Coca-Cola he was drinking diluted the toxic agent. Mikhail Talybov, a KGB agent, was given responsibility for the poisonings.\n\nThe assault on the palace began shortly afterward. During the attack Amin still believed the Soviet Union was on his side, and told his adjutant, \"The Soviets will help us\". The adjutant replied that it was the Soviets who were attacking them; Amin initially replied that this was a lie. Only after he tried but failed to contact the Chief of the General Staff, he muttered, \"I guessed it. It's all true\". There are various accounts of how Amin died, but the exact details have never been confirmed. Amin was either killed by a deliberate attack or died by a \"random burst of fire\". Amin's son was fatally wounded and died shortly after. His daughter was wounded, but survived. It was Gulabzoy who had been given orders to kill Amin and Watanjar who later confirmed his death. The men of Amin's family were all executed, while the women including his daughter were imprisoned at Pul-e-Charkhi prison until being released by President Najibullah in early 1992. After Amin's death on 27 December 1979, Radio Kabul broadcast Babrak Karmal's pre-recorded speech to the Afghan people, saying: \"Today the torture machine of Amin has been smashed\". Karmal was installed by the Soviets as the new president, while the Soviet Army began its intervention in Afghanistan that would last for nine years.\n\nOn 2 January 1980 on the PDPA's 15th anniversary, Karmal who was now the new General Secretary called Amin a \"conspirator, professional criminal and recognised spy of the U.S.\", as reported in the \"Kabul New Times\". Anahita Ratebzad, the education minister, said about Amin:\n\n\n"}
{"id": "14282", "url": "https://en.wikipedia.org/wiki?curid=14282", "title": "Hubris", "text": "Hubris\n\nHubris (, from ancient Greek ) describes a personality quality of extreme or foolish pride or dangerous over confidence, often in combination with (or synonymous with) arrogance. In its ancient Greek context, it typically describes behavior that defies the norms of behavior or challenges the gods, and which in turn brings about the downfall, or nemesis, of the perpetrator of hubris.\n\nThe adjectival form of the noun \"hubris\" is \"hubristic\". Hubris is usually perceived as a characteristic of an individual rather than a group, although the group the offender belongs to may suffer collateral consequences from the wrongful act. Hubris often indicates a loss of contact with reality and an overestimation of one's own competence, accomplishments or capabilities.\n\nIn ancient Greek, \"hubris\" referred to actions that shamed and humiliated the victim for the pleasure or gratification of the abuser. The term had a strong sexual connotation, and the shame reflected upon the perpetrator as well.\n\nViolations of the law against hubris included what might today be termed assault and battery; sexual crimes; or the theft of public or sacred property. Two well-known cases are found in the speeches of Demosthenes, a prominent statesman and orator in ancient Greece. These two examples occurred when first Midias punched Demosthenes in the face in the theatre (\"Against Midias\"), and second when (in \"Against Conon\") a defendant allegedly assaulted a man and crowed over the victim. Yet another example of hubris appears in Aeschines' \"Against Timarchus\", where the defendant, Timarchus, is accused of breaking the law of hubris by submitting himself to prostitution and anal intercourse. Aeschines brought this suit against Timarchus to bar him from the rights of political office and his case succeeded.\n\nIn ancient Athens, hubris was defined as the use of violence to shame the victim (this sense of hubris could also characterize rape). Aristotle defined hubris as shaming the victim, not because of anything that happened to the committer or might happen to the committer, but merely for that committer's own gratification:\nto cause shame to the victim, not in order that anything may happen to you, nor because anything has happened to you, but merely for your own gratification. Hubris is not the requital of past injuries; this is revenge. As for the pleasure in hubris, its cause is this: naive men think that by ill-treating others they make their own superiority the greater.\n\nCrucial to this definition are the ancient Greek concepts of honour (τιμή, \"timē\") and shame (αἰδώς, \"aidōs\"). The concept of honour included not only the exaltation of the one receiving honour, but also the shaming of the one overcome by the act of hubris. This concept of honour is akin to a zero-sum game. Rush Rehm simplifies this definition of hubris to the contemporary concept of \"insolence, contempt, and excessive violence\".\n\nThe Greek word for sin, hamartia (ἁμαρτία), originally meant \"error\" in the ancient dialect, and so poets like Hesiod and Aeschylus used the word \"hubris\" to describe transgressions against the gods. A common way that hubris was committed was when a mortal claimed to be better than a god in a particular skill or attribute. Claims like these were rarely left unpunished, and so Arachne, a talented young weaver, was transformed into a spider when she said that her skills exceeded those of the goddess Athena. Additional examples include Icarus, Phaethon, Salmoneus, Niobe, Cassiopeia, and Tereus.\n\nThese events were not limited to myth, and certain figures in history were considered to be have been punished for committing hubris through their arrogance. One such person was king Xerxes as portrayed in Aeschylus's play The Persians, and who allegedly threw chains to bind the Hellespont sea as punishment for daring to destroy his fleet.\n\nWhat is common to all these examples is the breaching of limits, as the Greeks believed that the Fates (Μοῖραι) had assigned each being with a particular area of freedom, an area that even the gods could not breach. \n\nThe goddess Hybris has been described as having \"insolent encroachment upon the rights of others\".\n\nThe word hubris as used in the New Testament parallels the Hebrew word \"pasha\", meaning transgression. It represents a sense of false pride that makes a man defy God, sometimes to the degree that he considers himself an equal. In contrast to this, the common word for sin was hamartia, which refers to an error and reflects the complexity of the human condition. Its result is guilt rather than direct punishment as in the case of hubris .\n\nIn its modern usage, hubris denotes overconfident pride combined with arrogance. Hubris is often associated with a lack of humility. Sometimes a person's hubris is also associated with ignorance. The accusation of hubris often implies that suffering or punishment will follow, similar to the occasional pairing of hubris and nemesis in Greek mythology. The proverb \"pride goeth (goes) before destruction, a haughty spirit before a fall\" (from the biblical Book of Proverbs, 16:18) is thought to sum up the modern use of hubris. Hubris is also referred to as \"pride that blinds\" because it often causes a committer of hubris to act in foolish ways that belie common sense. In other words, the modern definition may be thought of as, \"that pride that goes just before the fall.\"\n\nExamples of hubris are often found in literature, most famously in John Milton's \"Paradise Lost\", in which Lucifer attempts to compel the other angels to worship him, is cast into hell by God and the innocent angels, and proclaims: \"Better to reign in hell than serve in heaven.\" Victor in Mary Shelley's \"Frankenstein\" manifests hubris in his attempt to become a great scientist; he creates life through technological means, but comes to regret his project. Marlowe's play \"Doctor Faustus\" portrays the eponymous character as a scholar whose arrogance and pride compel him to sign a deal with the Devil, and retain his haughtiness until his death and damnation, despite the fact that he could easily have repented had he chosen to do so.\n\nAn example in pop culture is the comic book hero Doctor Strange, wherein highly talented and arrogant neurosurgeon Dr. Stephen Strange is involved in a vehicular accident. Unlike the Greek figures Salmoneus, Icarus and Phaethon, he survives, though his hands are severely damaged, and thus his career as a neurosurgeon is shattered. After western medicine fails to help him, he seeks healing in the mystic arts, and though he never fully recovers, he becomes a powerful sorcerer.\n\nA historical example of hubris was furnished by General George Armstrong Custer in the decisions that culminated in the Battle of Little Big Horn; Custer is apocryphally quoted as having exclaimed: \"Where did all those damned Indians come from?\"\n\nC. S. Lewis wrote in \"Mere Christianity\" that pride is the \"anti-God\" state, the position in which the ego and the self are directly opposed to God: \"Unchastity, anger, greed, drunkenness, and all that, are mere fleabites in comparison: it was through Pride that the devil became the devil: Pride leads to every other vice: it is the complete anti-God state of mind.\"\n\n\n\n"}
{"id": "14283", "url": "https://en.wikipedia.org/wiki?curid=14283", "title": "Heavy water", "text": "Heavy water\n\nHeavy water (deuterium oxide, ', ') is a form of water that contains a larger than normal amount of the hydrogen isotope deuterium ( or D, also known as \"heavy hydrogen\"), rather than the common hydrogen-1 isotope ( or H, also called protium) that makes up most of the hydrogen in normal water. The presence of deuterium gives the chemical different nuclear properties, and the increase of mass gives it different physical and chemical properties when compared to normal water.\n\nDeuterium is a hydrogen isotope with a nucleus containing a neutron and a proton; the nucleus of a protium (normal hydrogen) atom consists of just a proton. The additional neutron makes a deuterium atom roughly twice as heavy as a protium atom.\n\nA molecule of heavy water has two deuterium atoms in place of the two protium atoms of ordinary \"light\" water. The weight of a heavy water molecule, however, is not substantially different from that of a normal water molecule, because about 89% of the molecular weight of water comes from the single oxygen atom rather than the two hydrogen atoms. The colloquial term \"heavy water\" refers to a highly enriched water mixture that contains mostly deuterium oxide , but also some hydrogen-deuterium oxide (HDO) and a smaller amount of ordinary hydrogen oxide . For instance, the heavy water used in CANDU reactors is 99.75% enriched by hydrogen atom-fraction—meaning that 99.75% of the hydrogen atoms are of the heavy type. For comparison, ordinary water (the \"ordinary water\" used for a deuterium standard) contains only about 156 deuterium atoms per million hydrogen atoms, meaning that 0.0156% of the hydrogen atoms are of the heavy type.\n\nHeavy water is not radioactive. In its pure form, it has a density about 11% greater than water, but is otherwise physically and chemically similar. Nevertheless, the various differences in deuterium-containing water (especially affecting the biological properties) are larger than in any other commonly occurring isotope-substituted compound because deuterium is unique among heavy stable isotopes in being twice as heavy as the lightest isotope. This difference increases the strength of water's hydrogen-oxygen bonds, and this in turn is enough to cause differences that are important to some biochemical reactions. The human body naturally contains deuterium equivalent to about five grams of heavy water, which is harmless. When a large fraction of water (> 50%) in higher organisms is replaced by heavy water, the result is cell dysfunction and death.\n\nHeavy water was first produced in 1932, a few months after the discovery of deuterium. With the discovery of nuclear fission in late 1938, and the need for a neutron moderator that captured few neutrons, heavy water became a component of early nuclear energy research. Since then, heavy water has been an essential component in some types of reactors, both those that generate power and those designed to produce isotopes for nuclear weapons. These heavy water reactors have the advantage of being able to run on natural uranium without using graphite moderators that pose radiological and dust explosion hazards in the decommissioning phase. Most modern reactors use enriched uranium with ordinary water as the moderator.\n\nSemiheavy water, HDO, exists whenever there is water with light hydrogen (protium, ) and deuterium (D or ) in the mix. This is because hydrogen atoms (hydrogen-1 and deuterium) are rapidly exchanged between water molecules. Water containing 50% H and 50% D in its hydrogen actually contains about 50% HDO and 25% each of and , in dynamic equilibrium.\nIn normal water, about 1 molecule in 3,200 is HDO (one hydrogen in 6,400 is in the form of D), and heavy water molecules () only occur in a proportion of about 1 molecule in 41 million (i.e. one in 6,400). Thus semiheavy water molecules are far more common than \"pure\" (homoisotopic) heavy water molecules.\n\nWater enriched in the heavier oxygen isotopes and is also commercially available, e.g., for use as a non-radioactive isotopic tracer. It is \"heavy water\" as it is denser than normal water ( is approximately as dense as , is about halfway between and )—but is rarely called heavy water, since it does not contain the deuterium that gives DO its unusual nuclear and biological properties. It is more expensive than DO due to the more difficult separation of O and O. HO is also used for production of fluorine-18 for radiopharmaceuticals and radiotracers and for positron emission tomography.\n\nTritiated water contains tritium (H) in place of protium (H) or deuterium (H), and therefore it is radioactive.\n\nThe physical properties of water and heavy water differ in several respects. Heavy water is less dissociated than light water at given temperature, and the true concentration of D ions is less than ions would be for a light water sample at the same temperature. The same is true of OD vs. ions. For heavy water Kw DO (25.0 °C) = 1.35 × 10, and [D] must equal [OD] for neutral water. Thus pKw DO = p[OD] + p[D] = 7.44 + 7.44 = 14.87 (25.0 °C), and the p[D] of neutral heavy water at 25.0 °C is 7.44.\n\nThe pD of heavy water is generally measured using pH electrodes giving a pH (apparent) value, or pHa, and at various temperatures a true acidic pD can be estimated from the directly pH meter measured pHa, such that pD+ = pHa (apparent reading from pH meter) + 0.41. The electrode correction for alkaline conditions is 0.456 for heavy water. The alkaline correction is then pD+ = pH(apparent reading from pH meter) + 0.456. These corrections are slightly different from the differences in p[D+] and p[OD-] of 0.44 from the corresponding ones in heavy water.\n\nHeavy water is 10.6% denser than ordinary water, and heavy water's physically different properties can be seen without equipment if a frozen sample is dropped into normal water, as it will sink. If the water is ice-cold the higher melting temperature of heavy ice can also be observed: it melts at 3.7 °C, and thus does not melt in ice-cold normal water.\n\nAn early experiment reported not the \"slightest difference\" in taste between ordinary and heavy water. However, rats given a choice between distilled normal water and heavy water were able to avoid the heavy water based on smell, and it may have a different taste. Some humans have reported that heavy water produces a \"burning sensation or sweet flavor\".\n\nNo physical properties are listed for \"pure\" semi-heavy water, because it is unstable as a bulk liquid. In the liquid state, a few water molecules are always in an ionised state, which means the hydrogen atoms can exchange among different oxygen atoms. Semi-heavy water could, in theory, be created via a chemical method, but it would rapidly transform into a dynamic mixture of 25% light water, 25% heavy water, and 50% semi-heavy water. However, if it were made in the gas phase and directly deposited into a solid, semi heavy water in the form of ice could be stable. This is due to collisions between water vapour molecules being almost completely negligible in the gas phase at standard temperatures, and once crystallized, collisions between the molecules cease altogether due to the rigid lattice structure of solid ice.\n\nHarold Urey discovered the isotope deuterium in 1931 and was later able to concentrate it in water. Urey's mentor Gilbert Newton Lewis isolated the first sample of pure heavy water by electrolysis in 1933. George de Hevesy and Erich Hofer used heavy water in 1934 in one of the first biological tracer experiments, to estimate the rate of turnover of water in the human body. The history of large-quantity production and use of heavy water in early nuclear experiments is given below.\nEmilian Bratu and Otto Redlich studied the autodissociation of heavy water in 1934.\n\nDifferent isotopes of chemical elements have slightly different chemical behaviors, but for most elements the differences are far too small to use, or even detect. For hydrogen, however, this is not true. The larger chemical isotope-effects seen between protium (light hydrogen) versus deuterium and tritium manifest because bond energies in chemistry are determined in quantum mechanics by equations in which the quantity of reduced mass of the nucleus and electrons appears. This quantity is altered in heavy-hydrogen compounds (of which deuterium oxide is the most common) more than for heavy-isotope substitution in other chemical elements. This isotope effect of heavy hydrogen is magnified further in biological systems, which are very sensitive to small changes in the solvent properties of water.\n\nHeavy water is the only known chemical substance that affects the period of circadian oscillations, consistently increasing the length of each cycle. The effect is seen in unicellular organisms, green plants, isopods, insects, birds, mice, and hamsters. The mechanism is unknown.\n\nTo perform their tasks, enzymes rely on their finely tuned networks of hydrogen bonds, both in the active center with their substrates, and outside the active center, to stabilize their tertiary structures. As a hydrogen bond with deuterium is slightly stronger than one involving ordinary hydrogen, in a highly deuterated environment, some normal reactions in cells are disrupted.\n\nParticularly hard-hit by heavy water are the delicate assemblies of mitotic spindle formation necessary for cell division in eukaryotes. Plants stop growing and seeds do not germinate when given only heavy water, because heavy water stops eukaryotic cell division. The deuterium cell is larger and is a modification of the direction of division. The cell membrane also changes, and it reacts first to the impact of heavy water. In 1972 it was demonstrated that an increase in the percentage content of deuterium in water reduces plant growth. Research conducted on the growth of prokaryote microorganisms in artificial conditions of a heavy hydrogen environment showed that in this environment, all the hydrogen atoms of water could be replaced with deuterium. Experiments showed that bacteria can live in 98% heavy water. However, all concentrations over 50% of deuterium in the water molecules were found to kill plants.\n\nExperiments in mice, rats, and dogs have shown that a degree of 25% deuteration causes (sometimes irreversible) sterility, because neither gametes nor zygotes can develop. High concentrations of heavy water (90%) rapidly kill fish, tadpoles, flatworms, and \"Drosophila\". Mammals (for example, rats) given heavy water to drink die after a week, at a time when their body water approaches about 50% deuteration. The mode of death appears to be the same as that in cytotoxic poisoning (such as chemotherapy) or in acute radiation syndrome (though deuterium is not radioactive), and is due to deuterium's action in generally inhibiting cell division. It is more toxic to malignant cells than normal cells but the concentrations needed are too high for regular use. As in chemotherapy, deuterium-poisoned mammals die of a failure of bone marrow (bleeding and infection) and intestinal-barrier functions (diarrhea and fluid loss).\n\nDespite the problems of plants and animals in living with too much deuterium, prokaryotic organisms such as bacteria, which do not have the mitotic problems induced by deuterium, may be grown and propagated in fully deuterated conditions, resulting in replacement of all hydrogen atoms in the bacterial proteins and DNA with the deuterium isotope.\n\nFull replacement with heavy atom isotopes can be accomplished in higher organisms with other non-radioactive heavy isotopes (such as carbon-13, nitrogen-15, and oxygen-18), but this cannot be done for the stable heavy isotope of hydrogen. This is a consequence of the relative difference in nuclear mass between the isotopes of hydrogen that is the greatest in all elements. This isotopic effect alters physical properties of heavy water to a greater extent than other isotopes, and consequently induces toxicity at high concentration due to slowing down of essential biochemical reactions.\n\nDeuterium oxide is used to enhance boron neutron capture therapy, but this effect does not rely on the biological effects of deuterium per se, but instead on deuterium's ability to moderate (slow) neutrons without capturing them.\n\nBecause it would take a very large amount of heavy water to replace 25% to 50% of a human being's body water (water being in turn 50–75% of body weight) with heavy water, accidental or intentional poisoning with heavy water is unlikely to the point of practical disregard. Poisoning would require that the victim ingest large amounts of heavy water without significant normal water intake for many days to produce any noticeable toxic effects.\n\nOral doses of heavy water in the range of several grams, as well as heavy oxygen O, are routinely used in human metabolic experiments. See doubly labeled water testing. Since one in about every 6,400 hydrogen atoms is deuterium, a 50 kg human containing 32 kg of body water would normally contain enough deuterium (about 1.1 g) to make 5.5 g of pure heavy water, so roughly this dose is required to double the amount of deuterium in the body.\n\nA loss of blood pressure may partially explain the reported incidence of dizziness upon ingestion of heavy water. However, it is more likely that this symptom can be attributed to altered vestibular function.\n\nAlthough many people associate heavy water primarily with its use in nuclear reactors, pure heavy water is not radioactive. Commercial-grade heavy water is slightly radioactive due to the presence of minute traces of natural tritium, but the same is true of ordinary water. Heavy water that has been used as a coolant in nuclear power plants contains substantially more tritium as a result of neutron bombardment of the deuterium in the heavy water (tritium is a health risk when ingested in large quantities).\n\nIn 1990, a disgruntled employee at the Point Lepreau Nuclear Generating Station in Canada obtained a sample (estimated as about a \"half cup\") of heavy water from the primary heat transport loop of the nuclear reactor, and loaded it into a cafeteria drink dispenser. Eight employees drank some of the contaminated water. The incident was discovered when employees began leaving bioassay urine samples with elevated tritium levels. The quantity of heavy water involved was far below levels that could induce heavy water toxicity, but several employees received elevated radiation doses from tritium and neutron-activated chemicals in the water. This was not an incident of heavy water poisoning, but rather radiation poisoning from other isotopes in the heavy water. Some news services were not careful to distinguish these points, and some of the public were left with the impression that heavy water is normally radioactive and more severely toxic than it is. Even if pure heavy water had been used in the water cooler indefinitely, it is not likely the incident would have been detected or caused harm, since no employee would be expected to get much more than 25% of their daily drinking water from such a source.\n\nOn Earth, deuterated water, HDO, occurs naturally in normal water at a proportion of about 1 molecule in 3,200. This means that 1 in 6,400 hydrogen atoms is deuterium, which is 1 part in 3,200 by weight (hydrogen weight). The HDO may be separated from normal water by distillation or electrolysis and also by various chemical exchange processes, all of which exploit a kinetic isotope effect. With the partial enrichment also occurring in natural bodies of water under particular evaporation conditions. (For more information about the isotopic distribution of deuterium in water, see Vienna Standard Mean Ocean Water.) \nIn theory, deuterium for heavy water could be created in a nuclear reactor, but separation from ordinary water is the cheapest bulk production process.\n\nThe difference in mass between the two hydrogen isotopes translates into a difference in the zero-point energy and thus into a slight difference in the speed of the reaction. Once HDO becomes a significant fraction of the water, heavy water becomes more prevalent as water molecules trade hydrogen atoms very frequently. Production of pure heavy water by distillation or electrolysis requires a large cascade of stills or electrolysis chambers and consumes large amounts of power, so the chemical methods are generally preferred.\n\nThe most cost-effective process for producing heavy water is the dual temperature exchange sulfide process (known as the Girdler sulfide process) developed in parallel by Karl-Hermann Geib and Jerome S. Spevack in 1943.\n\nAn alternative process, patented by Graham M. Keyser, uses lasers to selectively dissociate deuterated hydrofluorocarbons to form deuterium fluoride, which can then be separated by physical means. Although the energy consumption for this process is much less than for the Girdler sulfide process, this method is currently uneconomical due to the expense of procuring the necessary hydrofluorocarbons.\n\nAs noted, modern commercial heavy water is almost universally referred to, and sold as, deuterium oxide. It is most often sold in various grades of purity, from 98% enrichment to 99.75–99.98% deuterium enrichment (nuclear reactor grade) and occasionally even higher isotopic purity.\n\nArgentina is the main producer of heavy water, using an ammonia/hydrogen exchange based plant supplied by Switzerland's Sulzer company. It is also a major exporter to Canada, Germany, the US and other countries. The heavy water production facility located in Arroyito is the world's largest heavy water production facility. Argentina produces of heavy water per year using, not HS bithermal method, but \"monothermal ammonia-hydrogen isotopic exchange\".\n\nIn October 1939, Soviet physicists Yakov Borisovich Zel'dovich and Yulii Borisovich Khariton concluded that heavy water and carbon were the only feasible moderators for a natural uranium reactor, and in August 1940, along with Georgy Flyorov, submitted a plan to the Russian Academy of Sciences calculating that 15 tons of heavy water were needed for a reactor. With the Soviet Union having no uranium mines at the time, young Academy workers were sent to Leningrad photographic shops to buy uranium nitrate, but the entire heavy water project was halted in 1941 when German forces invaded during Operation Barbarossa.\n\nBy 1943, Soviet scientists had discovered that all scientific literature relating to heavy water had disappeared from the West, which Flyorov in a letter warned Soviet leader Joseph Stalin about, and at which time there was only 2–3 kg of heavy water in the entire country. In late 1943, the Soviet purchasing commission in the U.S. obtained 1 kg of heavy water and a further 100 kg in February 1945, and upon World War II ending, the NKVD took over the project.\n\nIn October 1946, as part of the Russian Alsos, the NKVD deported to the Soviet Union from Germany the German scientists who had worked on heavy water production during the war, including Karl-Hermann Geib, the inventor of the Girdler sulfide process. These German scientists worked under the supervision of German physical chemist Max Volmer at the Institute of Physical Chemistry in Moscow with the plant they constructed producing large quantities of heavy water by 1948.\n\nDuring the Manhattan Project the United States constructed three heavy water production plants as part of the P-9 Project at Morgantown Ordnance Works, near Morgantown, West Virginia; at the Wabash River Ordnance Works, near Dana and Newport, Indiana; and at the Alabama Ordnance Works, near Childersburg and Sylacauga, Alabama. Heavy water was also acquired from the Cominco plant in Trail, British Columbia, Canada. The Chicago Pile-3 experimental reactor used heavy water as a moderator and went critical in 1944. The three domestic production plants were shut down in 1945 after producing around 20 metric tons of product (around 20,000 litres). The Wabash plant was reopened and began resumption of heavy water production in 1952.\n\nIn 1953, the United States began using heavy water in plutonium production reactors at the Savannah River Site. The first of the five heavy water reactors came online in 1953, and the last was placed in cold shutdown in 1996. The SRS reactors were heavy water reactors so that they could produce both plutonium and tritium for the US nuclear weapons program.\n\nThe U.S. developed the Girdler sulfide chemical exchange production process—which was first demonstrated on a large scale at the Dana, Indiana plant in 1945 and at the Savannah River Plant, South Carolina in 1952. DuPont operated the SRP for the USDOE until 1 April 1989, when Westinghouse took it over.\n\nIndia is one of the world's largest producers of heavy water through its Heavy Water Board and also exports to countries like Republic of Korea and the US. Development of heavy water process in India happened in three phases: The first phase (late 1950s to mid-1980s) was a period of technology development, the second phase was of deployment of technology and process stabilisation (mid-1980s to early 1990s) and third phase saw consolidation and a shift towards improvement in production and energy conservation.\n\nIn the 1930s, it was suspected by the United States and Soviet Union that Austrian chemist Fritz Johann Hansgirg built a pilot plant for the Empire of Japan in Japanese ruled northern Korea to produce heavy water by using a new process he had invented.\n\nIn 1934, Norsk Hydro built the first commercial heavy water plant at Vemork, Tinn, with a capacity of 12 tonnes per year. From 1940 and throughout World War II, the plant was under German control and the Allies decided to destroy the plant and its heavy water to inhibit German development of nuclear weapons. In late 1942, a planned raid by British airborne troops failed, both gliders crashing. The raiders were killed in the crash or subsequently executed by the Germans. On the night of 27 February 1943 Operation Gunnerside succeeded. Norwegian commandos and local resistance managed to demolish small, but key parts of the electrolytic cells, dumping the accumulated heavy water down the factory drains.\n\nOn 16 November 1943, the Allied air forces dropped more than 400 bombs on the site. The Allied air raid prompted the Nazi government to move all available heavy water to Germany for safekeeping. On 20 February 1944, a Norwegian partisan sank the ferry M/F \"Hydro\" carrying heavy water across Lake Tinn, at the cost of 14 Norwegian civilian lives, and most of the heavy water was presumably lost. A few of the barrels were only half full, and therefore could float, and may have been salvaged and transported to Germany.\n\nRecent investigation of production records at Norsk Hydro and analysis of an intact barrel that was salvaged in 2004 revealed that although the barrels in this shipment contained water of pH 14—indicative of the alkaline electrolytic refinement process—they did not contain high concentrations of DO. Despite the apparent size of the shipment, the total quantity of pure heavy water was quite small, most barrels only containing 0.5–1% pure heavy water. The Germans would have needed a total of about 5 tons of heavy water to get a nuclear reactor running. The manifest clearly indicated that there was only half a ton of heavy water being transported to Germany. \"Hydro\" was carrying far too little heavy water for one reactor, let alone the 10 or more tons needed to make enough plutonium for a nuclear weapon.\n\nIsrael admitted running the Dimona reactor with Norwegian heavy water sold to it in 1959. Through re-export using Romania and Germany, India probably also used Norwegian heavy water.\n\nAs part of its contribution to the Manhattan Project, Canada built and operated a 6-tonnes-per-year electrolytic heavy water plant at Trail, British Columbia, which started operation in 1943.\n\nThe Atomic Energy of Canada Limited (AECL) design of power reactor requires large quantities of heavy water to act as a neutron moderator and coolant. AECL ordered two heavy water plants, which were built and operated in Atlantic Canada at Glace Bay, Nova Scotia (by Deuterium of Canada Limited) and Port Hawkesbury, Nova Scotia (by General Electric Canada). These plants proved to have significant design, construction and production problems. Consequently, AECL built the Bruce Heavy Water Plant (), which it later sold to Ontario Hydro, to ensure a reliable supply of heavy water for future power plants. The two Nova Scotia plants were shut down in 1985 when their production proved unnecessary.\n\nThe Bruce Heavy Water Plant (BHWP) in Ontario was the world's largest heavy water production plant with a capacity of 1600 tonnes per year at its peak (800 tonnes per year per full plant, two fully operational plants at its peak). It used the Girdler sulfide process to produce heavy water, and required 340,000 tonnes of feed water to produce one tonne of heavy water. It was part of a complex that included eight CANDU reactors, which provided heat and power for the heavy water plant. The site was located at Douglas Point/Bruce Nuclear Generating Station near Tiverton, Ontario, on Lake Huron where it had access to the waters of the Great Lakes.\n\nAECL issued the construction contract in 1969 for the first BHWP unit (BHWP A). Commissioning of BHWP A was done by Ontario Hydro from 1971 through 1973, with the plant entering service on June 28, 1973 and design production capacity being achieved in April 1974. Due to the success of BHWP A and the large amount of heavy water that would be required for the large numbers of upcoming planned CANDU nuclear power plant construction projects, Ontario Hydro commissioned three additional heavy water production plants for the Bruce site (BHWP B, C, and D). BHWP B was placed into service in 1979. These first two plants were significantly more efficient than planned, and the number of CANDU construction projects ended up being significantly lower than originally planned, which led to the cancellation of construction on BHWP C & D. In 1984 BHWP A was shut down. By 1993 Ontario Hydro had produced enough heavy water to meet all of its anticipated domestic needs (which were lower than expected due to improved efficiency in the use and recycling of heavy water), so they shut down and demolished half of the capacity of BHWP B. The remaining capacity continued to operate in order to fulfill demand for heavy water exports until it was permanently shut down in 1997, after which the plant was gradually dismantled and the site cleared.\n\nAECL is currently researching other more efficient and environmentally benign processes for creating heavy water. This is essential for the future of the CANDU reactors since heavy water represents about 15–20% of the total capital cost of each CANDU plant.\n\nSince 1996 a plant for production of heavy water was being constructed at Khondab near Arak. On 26 August 2006, Iranian President Ahmadinejad inaugurated the expansion of the country's heavy-water plant. Iran has indicated that the heavy-water production facility will operate in tandem with a 40 MW research reactor that had a scheduled completion date in 2009.\n\nIran produced deuterated solvents in early 2011 for the first time.\n\nThe core of the IR-40 is supposed to be re-designed based on the nuclear agreement in July 2015.\n\nIran is permitted to store only of heavy water. Iran exports excess production after exceeding their allotment making Iran the world's third largest exporter of heavy water.\n\nThe 50 MW heavy water and natural uranium research reactor at Khushab, in Punjab province, is a central element of Pakistan's program for production of plutonium, deuterium and tritium for advanced compact warheads (i.e. thermonuclear weapons). Pakistan succeeded in acquiring a tritium purification and storage plant and deuterium and tritium precursor materials from two German firms.\n\nRomania produces heavy water at the Drobeta Girdler sulfide plant for domestic and export purposes.\n\nFrance operated a small plant during the 1950s and 1960s.\n\nHeavy water exists in elevated concentration in the hypolimnion of Lake Tanganyika in East Africa. It is likely that similar elevated concentrations exist in lakes with similar limnology, but this is only 4% enrichment (24 vs 28) and surface waters are usually enriched in by evaporation to even greater extend by faster evaporation. \n\nDeuterium oxide is used in nuclear magnetic resonance spectroscopy when using water as solvent if the nuclide of interest is hydrogen. This is because the signal from light-water (HO) solvent molecules interfere with observing the signal from the molecule of interest dissolved in it. Deuterium has a different magnetic moment and therefore does not contribute to the H-NMR signal at the hydrogen-1 resonance frequency.\n\nFor some experiments, it may be desirable to identify the labile hydrogens on a compound, that is hydrogens that can easily exchange away as H ions on some positions in a molecule. With addition of DO, sometimes referred to as a \"DO shake\", labile hydrogens exchange away and are substituted by deuterium (H) atoms. These positions in the molecule then do not appear in the H-NMR spectrum.\n\nDeuterium oxide is often used as the source of deuterium for preparing specifically labelled isotopologues of organic compounds. For example, C-H bonds adjacent to ketonic carbonyl groups can be replaced by C-D bonds, using acid or base catalysis. Trimethylsulfoxonium iodide, made from dimethyl sulfoxide and methyl iodide can be recrystallized from deuterium oxide, and then dissociated to regenerate methyl iodide and dimethyl sulfoxide, both deuterium labelled. In cases where specific double labelling by deuterium and tritium is contemplated, the researcher must be aware that deuterium oxide, depending upon age and origin, can contain some tritium.\n\nDeuterium oxide is often used instead of water when collecting FTIR spectra of proteins in solution. HO creates a strong band that overlaps with the amide I region of proteins. The band from DO is shifted away from the amide I region.\n\nHeavy water is used in certain types of nuclear reactors, where it acts as a neutron moderator to slow down neutrons so that they are more likely to react with the fissile uranium-235 than with uranium-238, which captures neutrons without fissioning.\nThe CANDU reactor uses this design. Light water also acts as a moderator, but because light water absorbs more neutrons than heavy water, reactors using light water for a reactor moderator must use enriched uranium rather than natural uranium, otherwise criticality is impossible. A significant fraction of outdated power reactors, such as the RBMK reactors in the USSR, were constructed using normal water for cooling but graphite as a moderator. However, the danger of graphite in power reactors (graphite fires in part led to the Chernobyl disaster) has led to the discontinuation of graphite in standard reactor designs.\n\nBecause they do not require uranium enrichment, heavy water reactors are more of a concern in regards to nuclear proliferation. The breeding and extraction of plutonium can be a relatively rapid and cheap route to building a nuclear weapon, as chemical separation of plutonium from fuel is easier than isotopic separation of U-235 from natural uranium.\nAmong current and past nuclear weapons states, Israel, India, and North Korea first used plutonium from heavy water moderated reactors burning natural uranium, while China, South Africa and Pakistan first built weapons using highly enriched uranium.\n\nIn the U.S., however, the first experimental atomic reactor (1942), as well as the Manhattan Project Hanford production reactors that produced the plutonium for the Trinity test and Fat Man bombs, all used pure carbon (graphite) neutron moderators combined with normal water cooling pipes. They functioned with neither enriched uranium nor heavy water. Russian and British plutonium production also used graphite-moderated reactors.\n\nThere is no evidence that civilian heavy water power reactors—such as the CANDU or Atucha designs—have been used to produce military fissile materials. In nations that do not already possess nuclear weapons, nuclear material at these facilities is under IAEA safeguards to discourage any diversion.\n\nDue to its potential for use in nuclear weapons programs, the possession or import/export of large industrial quantities of heavy water are subject to government control in several countries. Suppliers of heavy water and heavy water production technology typically apply IAEA (International Atomic Energy Agency) administered safeguards and material accounting to heavy water. (In Australia, the \"Nuclear Non-Proliferation (Safeguards) Act 1987\".) In the U.S. and Canada, non-industrial quantities of heavy water (i.e., in the gram to kg range) are routinely available without special license through chemical supply dealers and commercial companies such as the world's former major producer Ontario Hydro.\n\nThe Sudbury Neutrino Observatory (SNO) in Sudbury, Ontario uses 1,000 tonnes of heavy water on loan from Atomic Energy of Canada Limited. The neutrino detector is underground in a mine, to shield it from muons produced by cosmic rays. SNO was built to answer the question of whether or not electron-type neutrinos produced by fusion in the Sun (the only type the Sun should be producing directly, according to theory) might be able to turn into other types of neutrinos on the way to Earth. SNO detects the Cherenkov radiation in the water from high-energy electrons produced from electron-type neutrinos as they undergo charged current (CC) interactions with neutrons in deuterium, turning them into protons and electrons (however, only the electrons are fast enough to produce Cherenkov radiation for detection). SNO also detects neutrino↔electron scattering (ES) events, where the neutrino transfers energy to the electron, which then proceeds to generate Cherenkov radiation distinguishable from that produced by CC events. The first of these two reactions is produced only by electron-type neutrinos, while the second can be caused by all of the neutrino flavors. The use of deuterium is critical to the SNO function, because all three \"flavours\" (types) of neutrinos may be detected in a third type of reaction as well, neutrino-disintegration, in which a neutrino of any type (electron, muon, or tau) scatters from a deuterium nucleus (deuteron), transferring enough energy to break up the loosely bound deuteron into a free neutron and proton via a neutral current (NC) interaction. This event is detected when the free neutron is absorbed by Cl present from NaCl deliberately dissolved in the heavy water, causing emission of characteristic capture gamma rays. Thus, in this experiment, heavy water not only provides the transparent medium necessary to produce and visualize Cherenkov radiation, but it also provides deuterium to detect exotic mu type (μ) and tau (τ) neutrinos, as well as a non-absorbent moderator medium to preserve free neutrons from this reaction, until they can be absorbed by an easily detected neutron-activated isotope.\n\nHeavy water is employed as part of a mixture with HO for a common and safe test of mean metabolic rate in humans and animals undergoing their normal activities.\n\nTritium is the active substance in self-powered lighting and controlled nuclear fusion, its other uses including autoradiography and radioactive labeling. It is also used in nuclear weapon design for boosted fission weapons and initiators. Some tritium is created in heavy water moderated reactors when deuterium captures a neutron. This reaction has a small cross-section (probability of a single neutron-capture event) and produces only small amounts of tritium, although enough to justify cleaning tritium from the moderator every few years to reduce the environmental risk of tritium escape.\n\nProducing a lot of tritium in this way would require reactors with very high neutron fluxes, or with a very high proportion of heavy water to nuclear fuel and very low neutron absorption by other reactor material. The tritium would then have to be recovered by isotope separation from a much larger quantity of deuterium, unlike production from lithium-6 (the present method), where only chemical separation is needed.\n\nDeuterium's absorption cross section for thermal neutrons is 0.52 millibarns (5.2 × 10 m; 1 barn = 10 m), while those of oxygen-16 and oxygen-17 are 0.19 and 0.24 millibarns, respectively. O makes up 0.038% of natural oxygen, making the overall cross section 0.28 millibarns. Therefore, in DO with natural oxygen, 21% of neutron captures are on oxygen, rising higher as O builds up from neutron capture on O. Also, O may emit an alpha particle on neutron capture, producing radioactive carbon-14.\n\n\n"}
{"id": "14285", "url": "https://en.wikipedia.org/wiki?curid=14285", "title": "History of science and technology", "text": "History of science and technology\n\nThe history of science and technology (HST) is a field of history which examines how humanity's understanding of the natural world (science) and ability to manipulate it (technology) have changed over the centuries. This academic discipline also studies the cultural, economic, and political impacts of scientific innovation.\n\nHistories of science were originally written by practicing and retired scientists, starting primarily with William Whewell, as a way to communicate the virtues of science to the public. In the early 1930s, after a famous paper given by the Soviet historian Boris Hessen, was focused into looking at the ways in which scientific practices were allied with the needs and motivations of their context. After World War II, extensive resources were put into teaching and researching the discipline, with the hopes that it would help the public better understand both Science and Technology as they came to play an exceedingly prominent role in the world. In the 1960s, especially in the wake of the work done by Thomas Kuhn, the discipline began to serve a very different function, and began to be used as a way to critically examine the scientific enterprise. At the present time it is often closely aligned with the field of science studies.\n\nModern engineering as it is understood today took form during the scientific revolution, though much of the mathematics and science was built on the work of the Greeks, Egyptians, Mesopotamians, Chinese, Indians. See the main articles History of science and History of technology for these respective topics.\n\n\n\n\n\n\n\n\nHistory of science and technology is a well developed field in India. At least three generations of scholars can be identified.\nThe first generation includes D.D.Kosambi, Dharmpal, Debiprasad Chattopadhyay and Rahman. The second generation mainly consists of Ashis Nandy, Deepak Kumar, Dhruv Raina, S. Irfan Habib, Shiv Visvanathan, Gyan Prakash, Stan Lourdswamy, V.V. Krishna, Itty Abraham, Richard Grove, Kavita Philip, Mira Nanda and Rob Anderson. There is an emergent third generation that includes scholars like Abha Sur and Jahnavi Phalkey.\n\nDepartments and Programmes\n\nThe National Institute of Science, Technolology and Development Studies had a research group active in the 1990s which consolidated social history of science as a field of research in India. \nCurrently there are several institutes and university departments offering HST programmes.\n\n\n\n\n\n\n\n\nAcademic study of the history of science as an independent discipline was launched by George Sarton at Harvard with his book \"Introduction to the History of Science\" (1927) and the \"Isis\" journal (founded in 1912). Sarton exemplified the early 20th century view of the history of science as the history of great men and great ideas. He shared with many of his contemporaries a Whiggish belief in history as a record of the advances and delays in the march of progress. The History of Science was not a recognized subfield of American history in this period, and most of the work was carried out by interested Scientists and Physicians rather than professional Historians. With the work of I. Bernard Cohen at Harvard, the history of Science became an established subdiscipline of history after 1945.\n\n\n\n\n\nHistoriography of science\n\nHistory of science as a discipline\n\n"}
{"id": "14286", "url": "https://en.wikipedia.org/wiki?curid=14286", "title": "Holographic principle", "text": "Holographic principle\n\nThe holographic principle is a principle of string theories and a supposed property of quantum gravity that states that the description of a volume of space can be thought of as encoded on a lower-dimensional boundary to the region—preferably a light-like boundary like a gravitational horizon. First proposed by Gerard 't Hooft, it was given a precise string-theory interpretation by Leonard Susskind who combined his ideas with previous ones of 't Hooft and Charles Thorn. As pointed out by Raphael Bousso, Thorn observed in 1978 that string theory admits a lower-dimensional description in which gravity emerges from it in what would now be called a holographic way. The prime example of holography is the AdS/CFT correspondence.\n\nThe holographic principle was inspired by black hole thermodynamics, which conjectures that the maximal entropy in any region scales with the radius \"squared\", and not cubed as might be expected. In the case of a black hole, the insight was that the informational content of all the objects that have fallen into the hole might be entirely contained in surface fluctuations of the event horizon. The holographic principle resolves the black hole information paradox within the framework of string theory.\nHowever, there exist classical solutions to the Einstein equations that allow values of the entropy larger than those allowed by an area law, hence in principle larger than those of a black hole. These are the so-called \"Wheeler's bags of gold\". The existence of such solutions conflicts with the holographic interpretation, and their effects in a quantum theory of gravity including the holographic principle are not yet fully understood.\n\nThe anti-de Sitter/conformal field theory correspondence, sometimes called Maldacena duality or gauge/gravity duality, is a conjectured relationship between two kinds of physical theories. On one side are anti-de Sitter spaces (AdS) which are used in theories of quantum gravity, formulated in terms of string theory or M-theory. On the other side of the correspondence are conformal field theories (CFT) which are quantum field theories, including theories similar to the Yang–Mills theories that describe elementary particles.\n\nThe duality represents a major advance in our understanding of string theory and quantum gravity. This is because it provides a non-perturbative formulation of string theory with certain boundary conditions and because it is the most successful realization of the holographic principle, an idea in quantum gravity originally proposed by Gerard 't Hooft and promoted by Leonard Susskind.\n\nIt also provides a powerful toolkit for studying strongly coupled quantum field theories. Much of the usefulness of the duality results from the fact that it is a strong-weak duality: when the fields of the quantum field theory are strongly interacting, the ones in the gravitational theory are weakly interacting and thus more mathematically tractable. This fact has been used to study many aspects of nuclear and condensed matter physics by translating problems in those subjects into more mathematically tractable problems in string theory.\n\nThe AdS/CFT correspondence was first proposed by Juan Maldacena in late 1997. Important aspects of the correspondence were elaborated in articles by Steven Gubser, Igor Klebanov, and Alexander Markovich Polyakov, and by Edward Witten. By 2015, Maldacena's article had over 10,000 citations, becoming the most highly cited article in the field of high energy physics.\n\nAn object with relatively high entropy is microscopically random, like a hot gas. A known configuration of classical fields has zero entropy: there is nothing random about electric and magnetic fields, or gravitational waves. Since black holes are exact solutions of Einstein's equations, they were thought not to have any entropy either.\n\nBut Jacob Bekenstein noted that this leads to a violation of the second law of thermodynamics. If one throws a hot gas with entropy into a black hole, once it crosses the event horizon, the entropy would disappear. The random properties of the gas would no longer be seen once the black hole had absorbed the gas and settled down. One way of salvaging the second law is if black holes are in fact random objects with an entropy that increases by an amount greater than the entropy of the consumed gas.\n\nBekenstein assumed that black holes are maximum entropy objects—that they have more entropy than anything else in the same volume. In a sphere of radius \"R\", the entropy in a relativistic gas increases as the energy increases. The only known limit is gravitational; when there is too much energy [entropy?] the gas collapses into a black hole. Bekenstein used this to put an upper bound on the entropy in a region of space, and the bound was proportional to the area of the region. He concluded that the black hole entropy is directly proportional to the area of the event horizon.\n\nStephen Hawking had shown earlier that the total horizon area of a collection of black holes always increases with time. The horizon is a boundary defined by light-like geodesics; it is those light rays that are just barely unable to escape. If neighboring geodesics start moving toward each other they eventually collide, at which point their extension is inside the black hole. So the geodesics are always moving apart, and the number of geodesics which generate the boundary, the area of the horizon, always increases. Hawking's result was called the second law of black hole thermodynamics, by analogy with the law of entropy increase, but at first, he did not take the analogy too seriously.\n\nHawking knew that if the horizon area were an actual entropy, black holes would have to radiate. When heat is added to a thermal system, the change in entropy is the increase in mass-energy divided by temperature:\n"}
{"id": "14288", "url": "https://en.wikipedia.org/wiki?curid=14288", "title": "Hamilton, Ontario", "text": "Hamilton, Ontario\n\nHamilton () is a port city in the Canadian province of Ontario. An industrialized city in the Golden Horseshoe at the west end of Lake Ontario, Hamilton has a population of 536,917, and a metropolitan (which includes Burlington and Grimsby) population of 747,545. The city is located about 60 km (37 miles) southwest of Toronto, Canada's largest city and metropolitan area. \n\nOn January 1, 2001, the current boundaries of Hamilton was created through the amalgamation of the original city with other municipalities of the Regional Municipality of Hamilton-Wentworth. Residents of the city are known as Hamiltonians. Since 1981, the metropolitan area has been listed as the ninth largest in Canada and the third largest in Ontario. \n\nHamilton is home to the Royal Botanical Gardens, the Canadian Warplane Heritage Museum, the Bruce Trail, McMaster University, Redeemer University College and Mohawk College. McMaster University is ranked 4th in Canada and 77th in the world by Times Higher Education Rankings 2018–19 and has a well-known medical school.\n\nIn pre-colonial times, the Neutral First Nation used much of the land but were gradually driven out by the Five (later Six) Nations (Iroquois) who were allied with the British against the Huron and their French allies. A member of the Iroquois Confederacy provided the route and name for Mohawk Road, which originally included King Street in the lower city.\n\nFollowing the United States gaining independence after their American Revolutionary War, in 1784, about 10,000 United Empire Loyalists settled in Upper Canada (what is now southern Ontario), chiefly in Niagara, around the Bay of Quinte, and along the St. Lawrence River between Lake Ontario and Montreal. The Crown granted them land in these areas in order to develop Upper Canada and to compensate them for losses in the United States. With former First Nations lands available for purchase, these new settlers were soon followed by many more Americans, attracted by the availability of inexpensive, arable land. At the same time, large numbers of Iroquois who had been allied with Britain arrived from the United States and were settled on reserves west of Lake Ontario as compensation for lands they lost in what was now the United States. During the War of 1812, British regulars and Canadian militia defeated invading American troops at the Battle of Stoney Creek, fought in what is now a park in eastern Hamilton.\n\nThe town of Hamilton was conceived by George Hamilton (a son of a Queenston entrepreneur and founder, Robert Hamilton), when he purchased farm holdings of James Durand, the local Member of the British Legislative Assembly, shortly after the War of 1812. Nathaniel Hughson, a property owner to the north, cooperated with George Hamilton to prepare a proposal for a courthouse and jail on Hamilton's property. Hamilton offered the land to the crown for the future site. Durand was empowered by Hughson and Hamilton to sell property holdings which later became the site of the town. As he had been instructed, Durand circulated the offers at York during a session of the Legislative Assembly, which established a new Gore District, of which the Hamilton townsite was a member.\n\nInitially, this town was not the most important centre of the Gore District. An early indication of Hamilton's sudden prosperity was marked by the fact that in 1816 it was chosen over Ancaster, Ontario that year to be the administrative center for the new Gore District. Another dramatic economic turnabout for Hamilton occurred in 1832 when a canal was finally cut through the outer sand bar that enabled Hamilton to become a major port. A permanent jail was not constructed until 1832, when a cut-stone design was completed on Prince's Square, one of the two squares created in 1816. Subsequently, the first police board and the town limits were defined by statute on February 13, 1833. Official city status was achieved on June 9, 1846, by an act of Parliament, 9 Victoria Chapter 73. \n\nBy 1845, the population was 6,475. In 1846, there were useful roads to many communities as well as stage coaches and steamboats to Toronto, Queenston, and Niagara. Eleven cargo schooners were owned in Hamilton. Eleven churches were in operation. A reading room provided access to newspapers from other cities and from England and the U.S. In addition to stores of all types, four banks, tradesmen of various types, and sixty-five taverns, industry in the community included three breweries, ten importers of dry goods and groceries, five importers of hardware, two tanneries, three coachmakers, and a marble and a stone works.\nAs the city grew, several prominent buildings were constructed in the late 19th century, including the Grand Lodge of Canada in 1855, West Flamboro Methodist Church in 1879 (later purchased by Dufferin Masonic Lodge in 1893), a public library in 1890, and the Right House department store in 1893. The first commercial telephone service in Canada, the first telephone exchange in the British Empire, and the second telephone exchange in all of North America were each established in the city between 1877–78. The city had several interurban electric street railways and two inclines, all powered by the Cataract Power Co.\n\nThough suffering through the Hamilton Street Railway strike of 1906, with industrial businesses expanding, Hamilton's population doubled between 1900 and 1914. Two steel manufacturing companies, Stelco and Dofasco, were formed in 1910 and 1912, respectively. Procter & Gamble and the Beech-Nut Packing Company opened manufacturing plants in 1914 and 1922, respectively, their first outside the US. Population and economic growth continued until the 1960s. In 1929 the city's first high-rise building, the Pigott Building, was constructed; in 1930 McMaster University moved from Toronto to Hamilton, in 1934 the second Canadian Tire store in Canada opened here; in 1940 the airport was completed; and in 1948, the Studebaker assembly line was constructed. Infrastructure and retail development continued, with the Burlington Bay James N. Allan Skyway opening in 1958, and the first Tim Hortons store in 1964.\n\nSince then, many of the large industries have moved or shut down operations in restructuring that also affected the United States. The economy has shifted more toward the service sector, such as transportation, education, and health services.\n\nOn January 1, 2001, the new city of Hamilton was formed from the amalgamation of Hamilton and its five neighbouring municipalities: Ancaster, Dundas, Flamborough, Glanbrook, and Stoney Creek. Before amalgamation, the \"old\" City of Hamilton had 331,121 residents and was divided into 100 neighbourhoods. The former region of Hamilton-Wentworth had a population of 490,268. The amalgamation created a single-tier municipal government ending subsidization of its suburbs. The new amalgamated city has 519,949 people in more than 100 neighbourhoods, and surrounding communities.\n\nIn 1997 there was a devastating fire at the Plastimet plastics plant. Approximately 300 firefighters battled the blaze, and many sustained severe chemical burns and inhaled volatile organic compounds when at least 400 tonnes of PVC plastic were consumed in the fire.\n\nHamilton is in Southern Ontario on the western end of the Niagara Peninsula and wraps around the westernmost part of Lake Ontario; most of the city, including the downtown section, is on the south shore. Hamilton is in the geographic centre of the Golden Horseshoe and is roughly the midway point between Toronto and Buffalo, New York, although slightly closer to the former. Its major physical features are Hamilton Harbour, marking the northern limit of the city, and the Niagara Escarpment running through the middle of the city across its entire breadth, bisecting the city into \"upper\" and \"lower\" parts. The maximum high point is 250m (820') above the level of Lake Ontario.\n\nAccording to all records from local historians, this district was called \"Attiwandaronia\" by the native Neutral people. The first aboriginals to settle in the Hamilton area called the bay \"Macassa\", meaning \"beautiful waters\". Hamilton is one of 11 cities showcased in the book, \"Green City: People, Nature & Urban Places\" by Quebec author Mary Soderstrom, which examines the city as an example of an industrial powerhouse co-existing with nature. Soderstrom credits Thomas McQuesten and family in the 1930s who \"became champions of parks, greenspace and roads\" in Hamilton.\n\nHamilton Harbour is a natural harbour with a large sandbar called the Beachstrip. This sandbar was deposited during a period of higher lake levels during the last ice age, and extends southeast through the central lower city to the escarpment. Hamilton's deep sea port is accessed by ship canal through the beach strip into the harbour and is traversed by two bridges, the QEW's Burlington Bay James N. Allan Skyway and the lower Canal Lift Bridge.\n\nBetween 1788 and 1793, the townships at the Head-of-the-Lake were surveyed and named. The area was first known as The Head-of-the-Lake for its location at the western end of Lake Ontario. John Ryckman, born in Barton township (where present day downtown Hamilton is), described the area in 1803 as he remembered it: \"The city in 1803 was all forest. The shores of the bay were difficult to reach or see because they were hidden by a thick, almost impenetrable mass of trees and undergrowth ... Bears ate pigs, so settlers warred on bears. Wolves gobbled sheep and geese, so they hunted and trapped wolves. They also held organized raids on rattlesnakes on the mountainside. There was plenty of game. Many a time have I seen a deer jump the fence into my back yard, and there were millions of pigeons which we clubbed as they flew low.\"\n\nGeorge Hamilton, a settler and local politician, established a town site in the northern portion of Barton Township in 1815. He kept several east–west roads which were originally Indian trails, but the north–south streets were on a regular grid pattern. Streets were designated \"East\" or \"West\" if they crossed James Street or Highway 6. Streets were designated \"North\" or \"South\" if they crossed King Street or Highway 8. The overall design of the townsite, likely conceived in 1816, was commonplace. George Hamilton employed a grid street pattern used in most towns in Upper Canada and throughout the American frontier. The eighty original lots had frontages of fifty feet; each lot faced a broad street and backed onto a twelve-foot lane. It took at least a decade for all of the original lots to be sold, but the construction of the Burlington Canal in 1823, and a new court-house in 1827 encouraged Hamilton to add more blocks around 1828–9. At this time, he included a market square in an effort to draw commercial activity onto his lands, but the natural growth of the town was to the north of Hamilton's plot.\n\nThe Hamilton Conservation Authority owns, leases or manages about of land with the city operating of parkland at 310 locations. Many of the parks are along the Niagara Escarpment, which runs from Tobermory at the tip of the Bruce Peninsula in the north, to Queenston at the Niagara River in the south, and provides views of the cities and towns at Lake Ontario's western end. The hiking path Bruce Trail runs the length of the escarpment. Hamilton is home to more than 100 waterfalls and cascades, most of which are on or near the Bruce Trail as it winds through the Niagara Escarpment.\n\nHamilton's climate is humid-continental, characterized by changeable weather patterns. In the Köppen classification, Hamilton it is on the Dfb/Dfa border found in southern Ontario because the average temperature in July is 22 °C, although the east falls on the hot summer subtype towards Niagara Falls. However, its climate is moderate compared with most of Canada. Hamilton's location on an embayment at the southwestern corner of Lake Ontario with an escarpment dividing upper and lower parts of the city results in noticeable disparities in weather over short distances. This is also the case with pollution levels, which depending on localized winds patterns or low clouds can be high in certain areas mostly originating from the city's steel industry mixed with regional vehicle pollution. With a July average of exactly , the lower city is in a pocket of the found at the southwestern end of Lake Ontario (between Hamilton and Toronto and eastward into the Niagara Peninsula), while the upper reaches of the city fall into the .\n\nThe airport's open, rural location and higher altitude (240m vs. 85m ASL downtown) results in lower temperatures, generally windier conditions, and higher snowfall amounts than lower, built-up areas of the city. One exception is on early spring afternoons; when colder than air lake temperatures keep shoreline areas significantly cooler, under the presence of an east or north-east onshore flow.\n\nThe highest temperature ever recorded in Hamilton was 41.1 °C (106 °F) on 14 July 1868. The coldest temperature ever recorded was -30.6 °C (-23 °F) on 25 January 1884.\n\nAs per the 2016 Canadian census, 24.69% of the city's population was not born in Canada. Between 2001 and 2006, the foreign-born population increased by 7.7% while the total population of the Hamilton census metropolitan area (CMA) grew by 4.3%.\n\nHamilton is home to 26,330 immigrants who arrived in Canada between 2001 and 2010 and 13,150 immigrants who arrived between 2011 and 2016.\n\nHamilton maintains significant Italian, English, Scottish, German and Irish ancestry. 130,705 Hamiltonians claim English heritage, while 98,765 indicate their ancestors arrived from Scotland, 87,825 from Ireland, 62,335 from Italy, 50,400 from Germany.\n\nIn February 2014, the city's council voted to declare Hamilton a sanctuary city, offering municipal services to undocumented immigrants at risk of deportation.\n\nHamilton also has a notable French community for which provincial services are offered in French. In Ontario, urban centres where there are at least 5000 Francophones, or where at least 10% of the population is francophone, are designated areas where bilingual provincial services have to be offered. As per the 2016 census, the Francophone community maintains a population of 6,760, while 30,530 residents, or 5.8% of the city's population, have knowledge of both official languages. The Franco-Ontarian community of Hamilton boasts two school boards, the public \"Conseil scolaire Viamonde\" and the Catholic \"Conseil scolaire catholique MonAvenir\", which operate five schools (2 secondary and 3 elementary). Additionally, the city maintains a Francophone community health centre that is part of the LHIN (Centre de santé communautaire Hamilton/Niagara), a cultural centre (Centre français Hamilton), three daycare centres, a provincially funded employment centre (Options Emploi), a community college site (Collège Boréal) and a community organization that supports the development of the francophone community in Hamilton (ACFO Régionale Hamilton).\n\nThe top countries of birth for the newcomers living in Hamilton in the 1990s were: former Yugoslavia, Poland, India, China, the Philippines, and Iraq.\n\nChildren aged 14 years and under accounted for 16.23% of the city's population, a decline of 1.57% from the 2011 census. Hamiltonians aged 65 years and older constituted 17.3% of the population, an increase of 2.4% since 2011. The city's average age is 41.3 years.\n\n54.9% of Hamiltonians are married or in a common-law relationship, while 6.4% of city residents are divorced. Same-sex couples (married or in common-law relationships) constitute 0.08% (2,710 individuals) of the partnered population in Hamilton.\nThe most described religion in Hamilton is Christianity although other religions brought by immigrants are also growing. The 2011 census indicates 67.6% of the population adheres to a Christian denomination, with Catholics being the largest at 34.3% of the city's population. The Christ the King Cathedral is the seat of the Diocese of Hamilton. Other denominations include the United Church (6.5%), Anglican (6.4%), Presbyterian (3.1%), Christian Orthodox (2.9%), and other denominations (9.8%). Other religions with significant populations include Islam (3.7%), Buddhist (0.9%), Sikh (0.8%), Hindu (0.8%), and Jewish (0.7%). Those with no religious affiliation accounted for 24.9% of the population.\n\nEnvironics Analytics, a geodemographic marketing firm that created 66 different \"clusters\" of people complete with profiles of how they live, what they think and what they consume, sees a future Hamilton with younger upscale Hamiltonians—who are tech savvy and university educated—choosing to live in the downtown and surrounding areas rather than just visiting intermittently. More two and three-storey townhouses and apartments will be built on downtown lots; small condos will be built on vacant spaces in areas such as Dundas, Ainslie Wood and Westdale to accommodate newly retired seniors; and more retail and commercial zones will be created. The city is also expected to grow by more than 28,000 people and 18,000 households by the year 2012.\n\nThe most important economic activity in Ontario is manufacturing, and the Toronto–Hamilton region is the country's most highly industrialized area. The area from Oshawa, Ontario around the west end of Lake Ontario to Niagara Falls, with Hamilton at its centre, is known as the Golden Horseshoe and had a population of approximately 8.1 million people in 2006. The phrase was first used by Westinghouse President Herbert H. Rogge in a speech to the Hamilton Chamber of Commerce, on January 12, 1954. \"Hamilton in 50 years will be the forward cleat in a golden horseshoe of industrial development from Oshawa to the Niagara River ... 150 miles long and wide...It will run from Niagara Falls on the south to about Oshawa on the north and take in numerous cities and towns already there, including Hamilton and Toronto.\"\n\nWith sixty percent of Canada's steel being produced in Hamilton by Stelco and Dofasco, the city has become known as the Steel Capital of Canada. After nearly declaring bankruptcy, Stelco returned to profitability in 2004. On August 26, 2007 United States Steel Corporation acquired Stelco for C$38.50 in cash per share, owning more than 76 percent of Stelco's outstanding shares. On September 17, 2014, US Steel Canada announced it was applying for bankruptcy protection and it would close its Hamilton operations. \n\nA stand-alone subsidiary of Arcelor Mittal, the world's largest steel producer, Dofasco produces products for the automotive, construction, energy, manufacturing, pipe and tube, appliance, packaging, and steel distribution industries. It has approximately 7,300 employees at its Hamilton plant, and the four million tons of steel it produces each year represents about 30% of Canada's flat-rolled sheet steel shipments. Dofasco was North America's most profitable steel producer in 1999 and the most profitable in Canada in 2000 as well as a long-time member of the Dow Jones Sustainability World Index. Previously ordered by the U.S. Department of Justice to divest itself of the Canadian company, Arcelor Mittal has been allowed to retain Dofasco provided it sells several of its American assets.\n\nIn the 1940s, the John C. Munro Hamilton International Airport was used as a wartime air force training station. Today TradePort International Corporation manages and operates the John C. Munro Hamilton International Airport. Under TradePort management, passenger traffic at the Hamilton terminal has grown from 90,000 in 1996 to approximately 900,000 in 2002. The airport's mid-term target for growth in its passenger service is five million air travelers annually. The airport's air cargo sector has 24–7 operational capability and strategic geographic location, allowing its capacity to increase by 50% since 1996; 91,000 metric tonnes (100,000 tons) of cargo passed through the airport in 2002. Courier companies with operations at the airport include United Parcel Service and Cargojet Canada. In 2003, the city began developing a 30-year growth management strategy which called, in part, for a massive aerotropolis industrial park centred on Hamilton Airport. The aerotropolis proposal, now known as the \"Airport Employment Growth District\", is touted as a solution to the city's shortage of employment lands. Hamilton turned over operation of the airport to TradePort International Corp. in 1996. In 2007, YVR Airport Services (YVRAS), which runs the Vancouver International Airport, took over 100 percent ownership of TradePort in a $13-million deal. The airport is also home to the Canadian Warplane Heritage Museum.\n\nA report by Hemson Consulting identified an opportunity to develop of greenfields (the size of the Royal Botanical Gardens) that could generate an estimated 90,000 jobs by 2031. A proposed aerotropolis industrial park at Highway 6 and 403, has been debated at City Hall for years. Opponents feel the city needs to do more investigation about the cost to taxpayers before embarking on the project.\n\nThe Hamilton GO Centre, formerly the Toronto, Hamilton and Buffalo Railway station, is a commuter rail station on the Lakeshore West line of GO Transit. While Hamilton is not directly served by intercity rail, the Lakeshore West line does offer an off-peak bus connection and a peak-hours rail connection to Aldershot station in Burlington, which doubles as a VIA Rail station.\n\nWhen ranked on a \"total crime severity index\", Hamilton was 21st in Canada in 2011 for a metropolitan area. This was an eight percent decrease from 2010. Hamilton ranks first in Canada for police-reported hate crimes in 2016.\n\nCitizens of Hamilton are represented at all three levels of Canadian government - federal, provincial, and munipical. Following the 2015 Federal Election, representation in the Parliament of Canada will consist of five Members of Parliament representing the federal ridings of Hamilton West—Ancaster—Dundas, Hamilton Centre, Hamilton East—Stoney Creek, Hamilton Mountain, and Flamborough—Glanbrook. This election marked the first occasion in which Hamilton will have five Members of Parliament representing areas wholly within Hamilton's city boundaries, with previous boundaries situating rural ridings across municipal lines.\n\nProvincially, there are five elected Members of Provincial Parliament who serve in the Legislature of Ontario. Leader of the Ontario New Democratic Party and Leader of the Official Opposition, Andrea Horwath, represents Hamilton Centre, Paul Miller (NDP) represents Hamilton East-Stoney Creek, Monique Taylor (NDP) represents Hamilton Mountain, Sandy Shaw (NDP) represents Hamilton West—Ancaster—Dundas, and Progressive Conservative Donna Skelly represents Flamborough—Glanbrook.\n\nHamilton's municipal government consists of one mayor, elected city wide, and 15 city councillors, elected individually by each of the city's wards, to serve on the Hamilton City Council. Presently, Hamilton's mayor is Fred Eisenberger, elected on October 22, 2018 to a third term. Additionally, both Public and Catholic school board trustees are elected for defined areas ranging from two trustees for multiple wards to a single trustee for an individual ward.\n\nThe Hamilton City Council is granted authority to govern by the province through the Municipal Act of Ontario. As with all municipalities, the Province of Ontario has supervisory privilege over the municipality and the power to redefine, restrict or expand the powers of all municipalities in Ontario.\n\nThe Criminal Code of Canada is the chief piece of legislation defining criminal conduct and penalty. The Hamilton Police Service is chiefly responsible for the enforcement of federal and provincial law. Although the Hamilton Police Service has authority to enforce, bylaws passed by the Hamilton City Council are mainly enforced by Provincial Offences Officers employed by the City of Hamilton.\n\nThe Canadian Military maintains a presence in Hamilton, with the John Weir Foote Armoury in the downtown core on James Street North, housing the Royal Hamilton Light Infantry as well as the 11th Field Hamilton-Wentworth Battery and the Argyll and Sutherland Highlanders of Canada. The Hamilton Reserve Barracks on Pier Nine houses the naval reserve division , 23 Service Battalion and the 23 Field Ambulance.\n\nHamilton is home to several post-secondary institutions that have created numerous direct and indirect jobs in education and research. McMaster University moved to the city in 1930 and today has around 30,000 enrolled students, of which almost two-thirds come from outside the immediate Hamilton region. Brock University of St. Catharines, Ontario has a satellite campus used primarily for teacher education in Hamilton. Colleges in Hamilton include:\nFrom 1995 to 2001, the city was home to a satellite campus of the defunct francophone Collège des Grands-Lacs.\nPublic education for students from kindergarten through high school is administered by three school boards. The Hamilton-Wentworth District School Board manages 114 public schools, while the Hamilton-Wentworth Catholic District School Board operates 55 schools in the greater Hamilton area. The Conseil scolaire Viamonde operates one elementary and one secondary school (École secondaire Georges-P.-Vanier), and the Conseil scolaire de district catholique Centre-Sud operates two elementary schools and one secondary school. Calvin Christian School, Providence Christian School and Timothy Christian School are independent Christian elementary schools. Hamilton District Christian High School, Rehoboth Christian High School and Guido de Bres Christian High School are independent Christian high schools in the area. Both HDCH and Guido de Brès participate in the city's interscholastic athletics. Hillfield Strathallan College is on the West Hamilton mountain and is a CAIS member, non-profit school for children from early Montessori ages through grade twelve. Columbia International College is Canada's largest private boarding high school, with 1,700 students from 73 countries.\n\nThe Dundas Valley School of Art is an independent art school which has served the Hamilton region since 1964. Students range in age from 4 years old to senior citizens and enrollment as of February 2007 was close to 4,000. In 1998, a new full-time diploma programme was launched as a joint venture with McMaster University. The faculty and staff are highly regarded regional artists.\n\nThe Hamilton Conservatory for the Arts is home to many of the area's talented young actors, dancers, musicians, singers and visual artists. The school has a keyboard studio, spacious dance studios, art and sculpting studios, gallery space and a 300 seat recital hall. HCA offers over 90 programs for ages 3–93, creating a \"united nations\" of arts under one roof.\n\nThe Hamilton Literacy Council is a non-profit organization that provides basic (grades 1–5 equivalent) training in reading, writing, and math to English-speaking adults. The council's service is free, private, and one-to-one. It started to assist adults with their literacy skills in 1973.\n\nHamilton is home to two think tanks, the Centre for Cultural Renewal and Cardus, which deals with social architecture, culture, urbanology, economics and education and also publishes the \"LexView Policy Journal\" and \"Comment Magazine\".\n\nHamilton's local attractions include the Canadian Warplane Heritage Museum, the National Historic Site, Dundurn Castle (the residence of a Allan MacNab, the 8th Premier of Canada West), the Royal Botanical Gardens, the Canadian Football Hall of Fame, the African Lion Safari Park, the Cathedral of Christ the King, the Workers' Arts and Heritage Centre, and the Hamilton Museum of Steam & Technology\n\n, there are 40 pieces in the city's Public Art Collection. The works are owned and maintained by the city. Information and the locations of each piece in Public Art Collection can be viewed on this interactive map.\n\nFounded in 1914, the Art Gallery of Hamilton is Ontario's third largest public art gallery. The gallery has over 9,000 works in its permanent collection that focus on three areas: 19th century European, Historical Canadian and Contemporary Canadian.\nThe McMaster Museum of Art (MMA), founded at McMaster University in 1967, houses and exhibits the university's art collection of more than 7,000 objects, including historical, modern and contemporary art, the Levy Collection of Impressionist and Post-Impressionist paintings, and a collection of over 300 German Expressionist prints.\nHamilton has an active theatre scene, with the professional company Theatre Aquarius, plus long-time amateur companies, the Players' Guild of Hamilton and Hamilton Theatre Inc.. Many smaller theatre companies have also opened in the past decade, bringing a variety of theatre to the area.\n\nGrowth in the arts and culture sector has garnered media attention for Hamilton. A 2006 article in \"The Globe and Mail\", entitled \"Go West, Young Artist,\" focused on the growing art scene in Hamilton. The Factory: Hamilton Media Arts Centre, opened up a new home on James Street North in 2006. Art galleries have sprung up on streets across the city: James Street, King William Street, Locke Street and King Street.The opening of the Downtown Arts Centre on Rebecca Street has spurred further creative activities in the core. The Community Centre for Media Arts (CCMA) continues to operate in downtown Hamilton. The CCMA works with marginalized populations and combines new media services with arts education and skills development programming.\n\nSupercrawl is a large community arts and music festival that takes place in September in the James Street North area of the city. In 2018, Supercrawl celebrated its 10th year anniversary with over 220,000 visitors.\n\nIn March 2015, Hamilton was host to the JUNO Awards, which featured performances by Hedley, Alanis Morissette and Magic!. The award ceremony was held at the FirstOntario Centre in downtown Hamilton. During JUNOfest, hundreds of local acts performed across the city, bringing thousands of tourists.\n\nHamilton was the host of Canada's first major international athletic event, the first Commonwealth Games (then called the British Empire Games) in 1930. Hamilton bid unsuccessfully for the Commonwealth Games in 2010, losing out to New Delhi in India. On November 7, 2009, in Guadalajara, Mexico it was announced that Toronto would host the 2015 Pan Am Games after beating out two rival South American cities, Lima, Peru and Bogota, Colombia. The city of Hamilton co-hosted the Games with Toronto. Hamilton Mayor Fred Eisenberger said, \"the Pan Am Games will provide a 'unique opportunity for Hamilton to renew major sport facilities giving Hamiltonians a multi-purpose stadium, a 50-metre swimming pool, and an international-calibre velodrome to enjoy for generations to come.'\" Hamilton's major sports complexes include Tim Hortons Field and FirstOntario Centre.\n\nHamilton is represented by the Tiger-Cats in the Canadian Football League. The team traces their origins to the 1869 \"Hamilton Foot Ball Club.\" Hamilton is also home to the Canadian Football Hall of Fame museum. The museum hosts an annual induction event in a week-long celebration that includes school visits, a golf tournament, a formal induction dinner and concludes with the Hall of Fame game involving the local CFL Hamilton Tiger-Cats at Tim Hortons Field.\n\nIn 2019, Forge FC will debut as Hamilton's soccer team in the Canadian Premier League. The team will play at Tim Hortons Field and share the venue with the Tiger-Cats.\nHamilton hosted an NHL team in the 1920s called the Hamilton Tigers. The team folded after a players' strike in 1925. Research in Motion CEO Jim Balsillie has shown interest in bringing another NHL team to southern Ontario. The NHL's Phoenix Coyotes filed for bankruptcy in 2009 and have included within their Chapter 11 reorganization a plan to sell the team to Balsillie and move the team and its operations to Hamilton, Ontario. In late September, however, the bankruptcy judge did not rule in favour of Balsillie.\n\nThe Around the Bay Road Race circumnavigates Hamilton Harbour. Although it is not a marathon distance, it is the longest continuously held long distance foot race in North America. The local newspaper also hosts the amateur Spectator Indoor Games.\nIn addition to team sports, Hamilton is home to an auto race track, Flamboro Speedway and Canada's fastest half-mile harness horse racing track, Flamboro Downs. Another auto race track, Cayuga International Speedway, is near Hamilton in the Haldimand County community of Nelles Corners, between Hagersville and Cayuga.\n\nHamilton is a sister city with Flint, Michigan, and its young amateur athletes compete in the CANUSA Games, held alternatively in the two cities since 1958. Flint and Hamilton hold the distinction of having the oldest continuous sister-city relationship between a U.S. and Canadian city, since 1957.\n\nOther sister cities with Hamilton include:\n\n\n\nOther city relationships:\n\n\n"}
{"id": "14291", "url": "https://en.wikipedia.org/wiki?curid=14291", "title": "Hussites", "text": "Hussites\n\nThe Hussites ( or \"Kališníci\"; \"Chalice People\") were a pre-Protestant Christian movement that followed the teachings of Czech reformer Jan Hus, who became the best known representative of the Bohemian Reformation. \n\nThe Hussite movement began in the Kingdom of Bohemia and quickly spread throughout the remaining Lands of the Bohemian Crown, including Moravia and Silesia. It also made inroads into the northern parts of the Kingdom of Hungary (now Slovakia), but was rejected and gained infamy for the plundering behavior of the Hussite soldiers. There were also very small temporary communities in Poland-Lithuania and Transylvania which moved to Bohemia after being confronted with religious intolerance. It was a regional movement that failed to expand anywhere farther. Hussites emerged as a majority Utraquist movement with a significant Taborite faction, and smaller regional ones that included Adamites, Orebites and Orphans. Major Hussite theologians included Petr Chelcicky, Jerome of Prague, and others. A number of Czech national heroes were Hussite, including Jan Zizka, who led a fierce resistance to five consecutive crusades proclaimed on Hussite Bohemia by the Papacy. Hussites were one of the most important forerunners of the Protestant Reformation. This predominantly religious movement was propelled by social issues and strengthened Czech national awareness.\n\nAfter the Council of Constance lured Jan Hus in with a letter of indemnity, then tried him for heresy and put him to death at the stake on 6 July 1415, the Hussites fought the Hussite Wars (1420–1434) for their religious and political cause. After the Hussite Wars ended, the Catholic-supported Utraquist side came out victorious from conflict with the Taborites and became the most common representation of the Hussite faith in Bohemia. Catholics and Utraquists were emancipated in Bohemia after the religious peace of Kutná Hora in 1485.\n\nBohemia and Moravia, or what is now the territory of the Czech Republic, remained majority Hussite for two centuries until Roman Catholicism was reimposed by the Holy Roman Emperor after the 1620 Battle of White Mountain during the Thirty Years' War. Due to this event and centuries of Habsburg persecution, Hussite traditions are merely represented in the Moravian Church, Unity of the Brethren, and the refounded Czechoslovak Hussite churches among present-day Christians.\n\nThe arrest of Hus in 1414 caused considerable resentment in Czech lands. The authorities of both countries appealed urgently and repeatedly to King Sigismund to release Jan Hus.\n\nWhen news of his death at the Council of Constance in 1415 arrived, disturbances broke out, directed primarily against the clergy and especially against the monks. Even the Archbishop narrowly escaped from the effects of this popular anger. The treatment of Hus was felt to be a disgrace inflicted upon the whole country and his death was seen as a criminal act. King Wenceslaus, prompted by his grudge against Sigismund, at first gave free vent to his indignation at the course of events in Constance. His wife openly favoured the friends of Hus. Avowed Hussites stood at the head of the government.\n\nA league was formed by certain lords, who pledged themselves to protect the free preaching of the Gospel upon all their possessions and estates and to obey the power of the Bishops only where their orders accorded with the injunctions of the Bible. The university would arbitrate any disputed points. The entire Hussite nobility joined the league. Other than verbal protest of the council's treatment of Hus, there was little evidence of any actions taken by the nobility until 1417. At that point several of the lesser nobility and some barons, signatories of the 1415 protest letter, removed Romanist priests from their parishes, replacing them with priests willing to give communion in both wine and bread. The chalice of wine became the central identifying symbol of the Hussite movement. If the king had joined, its resolutions would have received the sanction of the law; but he refused, and approached the newly formed Roman Catholic League of lords, whose members pledged themselves to support the king, the Catholic Church, and the Council. The prospect of a civil war began to emerge.\n\nPope Martin V as Cardinal Otto of Colonna had attacked Hus with relentless severity. He energetically resumed the battle against Hus's teaching after the enactments of the Council of Constance. He wished to eradicate completely the doctrine of Hus, for which purpose the co-operation of King Wenceslaus had to be obtained. In 1418, Sigismund succeeded in winning his brother over to the standpoint of the council by pointing out the inevitability of a religious war if the heretics in Bohemia found further protection. Hussite statesmen and army leaders had to leave the country and Roman Catholic priests were reinstated. These measures caused a general commotion which hastened the death of King Wenceslaus by a paralytic stroke in 1419. His heir was Sigismund.\n\nHussitism organised itself during the years 1415–1419. From the beginning, there formed two parties, with a smaller number of people withdrawing from both parties around the pacifist Petr Chelčický, whose teachings would form the foundation of the Unitas Fratrum.\n\nThe moderate party, who followed Hus more closely, sought to conduct reform while leaving the whole hierarchical and liturgical order of the Church untouched.\n\nThe more radical party identified itself more boldly with the doctrines of John Wycliffe, sharing his passionate hatred of the monastic clergy, and his desire to return the Church to its supposed condition during the time of the apostles. This required the removal of the existing hierarchy and the secularisation of ecclesiastical possessions. The radicals preached the \"\"sufficientia legis Christi\"\"—the divine law (i.e. the Bible) is the sole rule and canon for human society, not only in the church, but also in political and civil matters. They rejected therefore, as early as 1416, everything that they believed had no basis in the Bible, such as the veneration of saints and images, fasts, superfluous holidays, the oath, intercession for the dead, auricular Confession, indulgences, the sacraments of Confirmation and the Anointing of the Sick; they admitted laymen and women to the preacher's office, and chose their own priests. But above all they clung to Wycliffe's doctrine of the Lord's Supper, denying transubstantiation, and this is the principal point by which they are distinguished from the moderate party.\n\nThe programme of the more conservative Hussites (the moderate party) is contained in the Four Articles of Prague, which were written by Jakoubek ze Stříbra and agreed upon in July 1420, promulgated in the Latin, Czech, and German languages. The full text is about two pages long, but they are often summarized as:\n\n\nThe views of the moderate Hussites were widely represented at the University and among the citizens of Prague; they were therefore called the Prague Party, but also Calixtines (Latin \"calix\" chalice) or Utraquists (Latin \"utraque\" both), because they emphasized the second article of Prague, and the chalice became their emblem.\n\nThe radicals (the radical party) had their gathering-places all around the country. Their first armed assault fell on the small town of Ústí, on the river Lužnice, south of Prague (today's Sezimovo Ústí). However, as the place did not prove to be defensible, they settled in the remains of an older town upon a hill not far away and founded a new town, which they named Tábor (after the traditional name of the mountain on which Jesus was expected to return; see Mark 13); hence they were called Táborité (Taborites). They comprised the essential force of the radical Hussites. Their aim was to destroy the enemies of the law of God, and to defend his kingdom (which had been expected to come in a short time) by the sword. Their end-of-world visions did not come true. In order to preserve their settlement and spread their ideology, they waged bloody wars; in the beginning they observed a strict regime, inflicting the severest punishment equally for murder, as for less severe faults as adultery, perjury and usury, and also tried to apply rigid Biblical standards to the social order of the time. The Taborites usually had the support of the Orebites (later called Orphans), an eastern Bohemian sect of Hussitism based in Hradec Králové.\n\nHussites were not a unitary movement, but a diverse one with multiple factions that held different views and opposed each other in the Hussite Wars.\n\nHussites can be divided into:\n\n\nThe news of the death of King Wenceslaus in 1419 produced a great commotion among the people of Prague. A revolution swept over the country: churches and monasteries were destroyed, and church property was seized by the Hussite nobility. It was then, and remained till much later, in question whether Bohemia was a hereditary or an elective monarchy, especially as the line through which Sigismund claimed the throne had accepted that the Kingdom of Bohemia was an elective monarchy elected by the nobles, and thus the regent of the kingdom (Čeněk of Wartenberg) also explicitly stated that Sigismund had not been elected as reason for Sigismund's claim to not be accepted. Sigismund could get possession of \"his\" kingdom only by force of arms. Pope Martin V called upon Catholics of the West to take up arms against the Hussites, declaring a crusade, and there followed twelve years of warfare.\n\nThe Hussites initially campaigned defensively, but after 1427 they assumed the offensive. Apart from their religious aims, they fought for the national interests of the Czechs. The moderate and radical parties were united, and they not only repelled the attacks of the army of crusaders but crossed the borders into neighboring countries. On March 23, 1430, Joan of Arc dictated a letter that threatened to lead a crusading army against the Hussites unless they returned to the Catholic faith, but her capture by English and Burgundian troops two months later would keep her from carrying out this threat.\n\nEventually, the opponents of the Hussites found themselves forced to consider an amicable settlement. They invited a Bohemian embassy to appear at the Council of Basel. The discussions began on 10 January 1432, centering chiefly on the four articles of Prague. No agreement emerged. After repeated negotiations between the Basel Council and Bohemia, a Bohemian–Moravian state assembly in Prague accepted the \"\"Compacta\"\" of Prague on 30 November 1433. The agreement granted communion in both kinds to all who desired it, but with the understanding that Christ was entirely present in each kind. Free preaching was granted conditionally: the Church hierarchy had to approve and place priests, and the power of the bishop must be considered. The article which prohibited the secular power of the clergy was almost reversed.\n\nThe Taborites refused to conform. The Calixtines united with the Roman Catholics and destroyed the Taborites at the Battle of Lipany on (30 May 1434). From that time, the Taborites lost their importance, though the Hussite movement would continue in Poland for another five years, until the Royalist forces of Poland defeated the Polish Hussites at the Battle of Grotniki. The state assembly of Jihlava in 1436 confirmed the \"\"Compacta\"\" and gave them the sanction of law. This accomplished the reconciliation of Bohemia with Rome and the Western Church, and at last Sigismund obtained possession of the Bohemian crown. His reactionary measures caused a ferment in the whole country, but he died in 1437. The state assembly in Prague rejected Wyclif's doctrine of the Lord's Supper, which was obnoxious to the Utraquists, as heresy in 1444. Most of the Taborites now went over to the party of the Utraquists; the rest joined the \"Brothers of the Law of Christ\" () (see Unity of the Brethren; also Bohemian Brethren and Moravian Church).\n\nIn 1462, Pope Pius II declared the \"\"Compacta\"\" null and void, prohibited communion in both kinds, and acknowledged King George of Podebrady as king on condition that he would promise an unconditional harmony with the Roman Church. This he refused, but his successor, King Vladislaus II, favored the Roman Catholics and proceeded against some zealous clergymen of the Calixtines. The troubles of the Utraquists increased from year to year. In 1485, at the Diet of Kutná Hora, an agreement was made between the Roman Catholics and Utraquists that lasted for thirty-one years. It was only later, at the Diet of 1512, that the equal rights of both religions were permanently established. The appearance of Martin Luther was hailed by the Utraquist clergy, and Luther himself was astonished to find so many points of agreement between the doctrines of Hus and his own. But not all Utraquists approved of the German Reformation; a schism arose among them, and many returned to the Roman doctrine, while other elements had organised the \"\"Unitas Fratrum\"\" already in 1457.\n\nUnder Emperor Maximilian II, the Bohemian state assembly established the \"\"Confessio Bohemica\"\", upon which Lutherans, Reformed, and Bohemian Brethren agreed. From that time forward Hussitism began to die out. After the Battle of White Mountain on 8 November 1620 the Roman Catholic Faith was re-established with vigour, which fundamentally changed the religious conditions of the Czech lands.\n\nLeaders and members of Unitas Fratrum were forced to choose to either leave the many and varied southeastern principalities of what was the Holy Roman Empire (mainly Austria, Hungary, Bohemia, Moravia and parts of Germany and its many states), or to practice their beliefs secretly. As a result, members were forced underground and dispersed across northwestern Europe. The largest remaining communities of the Brethren were located in Lissa (Leszno) in Poland, which had historically strong ties with the Czechs, and in small, isolated groups in Moravia. Some, among them Jan Amos Comenius, fled to western Europe, mainly the Low Countries. A settlement of Hussites in Herrnhut, Saxony, now Germany, in 1722 caused the emergence of the Moravian Church.\n\nIn 1918, as a result of World War I, the Czech lands regained independence from Austria-Hungary controlled by the Habsburg monarchy as Czechoslovakia.\n\nToday, the Czechoslovak Hussite Church claims to be the modern successor of the Hussite tradition.\n\n\n\n\n"}
{"id": "14292", "url": "https://en.wikipedia.org/wiki?curid=14292", "title": "HMS Ark Royal", "text": "HMS Ark Royal\n\nFive ships of the Royal Navy have borne the name HMS \"Ark Royal\":\n\n\n"}
{"id": "14293", "url": "https://en.wikipedia.org/wiki?curid=14293", "title": "Herman of Alaska", "text": "Herman of Alaska\n\nSaint Herman of Alaska (; 1750s – November 15, 1836) was a Russian Orthodox monk and missionary to Alaska, which was then part of Russian America. His gentle approach and ascetic life earned him the love and respect of both the native Alaskans and the Russian colonists. He is considered by many Orthodox Christians as the patron saint of North America.\n\nBiographers disagree about Herman's early life. His official biography, which Valaam Monastery published in 1867, said that his pre-monastic name was unknown, but that Herman was born into a merchant's family in Serpukhov, a city in Moscow Governorate. He was said to later become a novice at the Trinity-St. Sergius Hermitage near St. Petersburg before going to Valaam to complete his training and receive full tonsure as a monk. But, modern biographer Sergei Korsun found this account to be based on erroneous information provided by Semyon Yanovsky, an administrator from 1818 through part of 1820 of the Russian-American Company (RAC) in Alaska. He confused Herman's biographical information with that of another monk, Joseph (Telepnev).\n\nAnother former RAC Chief Manager, Ferdinand von Wrangel, stated Herman was originally from a prosperous peasant family in the Voronezh Governorate and served in the military. He then entered monastic life as a novice at Sarov Monastery. This concurred with testimony of Archimandrite Theophan (Sokolov), and a letter written by Herman himself. These agree that Herman began his monastic life as a novice at Sarov, and later received the full tonsure at Valaam. A young military clerk named Egor Ivanovich Popov, from the Voronezh Governorate, was tonsured with the name 'Herman' at Valaam in 1782.\n\nAll biographers agree that at Valaam, Herman studied under Abbot Nazarius, previously of Sarov Monastery. The abbot had been influenced by the hesychastic tradition of Paisius Velichkovsky. Herman undertook various obediences and was well-liked by the brethren, but wanted a more solitary life. He became a hermit with Abbot Nazarius' blessing. His hermitage, which later became known as \"Herman's field\" or Germanovo, was two kilometers from the monastery. Metropolitan Gabriel of St. Petersburg offered to ordain Herman to the priesthood and twice offered to send him to lead the Russian Orthodox Mission in China, but he refused, preferring the solitary life and remaining a simple monk. Years after he left for North America, Herman continued to keep in touch with his spiritual home. In a letter to Abbot Nazarius, he wrote, \"in my mind I imagine my beloved Valaam, and constantly behold it across the great ocean.\"\n\nThe Russian colonization of the Americas began when Vitus Bering and Aleksei Chirikov discovered Alaska in 1741. The expedition harvested 1,500 sea otter pelts, which Chinese merchants bought for 1,000 rubles each at their trading post near Lake Baikal. This spurred a \"fur rush\" from 1741 to 1798 in which frontiersmen known as \"promyshlenniki\" explored Alaska and the Aleutian Islands and alternately fought and intermarried with the native peoples. Grigory Shelikhov, a fur-trader, subjugated the native population of Kodiak Island and with Ivan Golikov founded a fur-trading company which eventually received a monopoly from the Imperial government and became the Russian-American Company. Shelikhov founded a school for the natives, of whom many were converted to Russian Orthodox Christianity.\n\nThe Shelikhov-Golikov Company appealed to the Most Holy Synod of the Russian Orthodox Church to provide a priest for the natives. Catherine the Great decided instead to send an entire mission to America. She entrusted the task of recruiting missionaries to Metropolitan Gabriel of St. Petersburg, who sent ten monks from Valaam, including Herman. The missionaries arrived on Kodiak on September 24, 1794.\n\nHerman and the other missionaries encountered a harsh reality at Kodiak that did not correspond to Shelikhov's rosy descriptions. The native Kodiak population, called \"Americans\" by the Russian settlers, were subject to harsh treatment by the Russian-American Company, which was being overseen by Shelikhov's manager Alexander Baranov who later became the first governor of the colony. The men were forced to hunt for sea otter even during harsh weather, and women and children were abused. The monks were also shocked at the widespread alcoholism in the Russian population, and the fact that most of the settlers had taken native mistresses. The monks themselves were not given the supplies that Shelikhov promised them, and had to till the ground with wooden implements. Despite these difficulties, the monks managed to baptize over 7,000 natives in the Kodiak region, and set about building a church and monastery. Herman was assigned in the bakery and acted as the mission's steward (\"ekonom\").\n\nThe monks became the defenders of the native Kodiak population. Herman was especially noted for his zeal in protecting them from the excessive demands of the RAC, and Baranov disparaged him in a letter as a \"hack writer and chatterer.\" A contemporary historian compares him to Bartolomé de las Casas, the Roman Catholic friar who defended the rights of native South Americans against the Spanish.\n\nAfter over a decade spent in Alaska, Herman became the head of the mission in 1807, although he was not ordained to the priesthood. The local population loved and respected him, and he even had good relations with Baranov. Herman ran the mission school, where he taught church subjects such as singing and catechism alongside reading and writing. He also taught agriculture on Spruce Island. However, because he longed for the life of a hermit he soon retired from active duty in the mission and moved to Spruce Island.\n\nHerman moved to Spruce Island around 1811 to 1817. The island is separated from Kodiak by a mile-wide strait, making it ideal for eremetic life. Herman named his hermitage \"New Valaam.\" He wore simple clothes and slept on a bench covered with a deerskin. When asked how he could bear to be alone in the forest, he replied, \"I am not alone. God is here, as God is everywhere.\"\n\nDespite his solitary life, he soon gained a following. He received many visitors—especially native Aleuts—on Sundays and church feasts. Soon his hermitage had next to it a chapel and guesthouse, and then a school for orphans. Herman had a few disciples, including the Creole orphan Gerasim Ivanovich Zyrianov, a young Aleut woman named Sofia Vlasova, and others. Entire families moved in order to be closer to the Elder, who helped to sort out their disputes. Herman had a deep love for the native Aleuts: he stood up for them against the excesses of the Russian-American Company, and once during an epidemic he was the only Russian to visit them, working tirelessly to care for the sick and console the dying. Herman spent the rest of his life on Spruce Island, where he died on November 15, 1836.\n\nOn March 11, 1969, the bishops of the Orthodox Church in America (OCA) formally declared their intention to canonize Herman, \"as a sublime example of the Holy Life, for our spiritual benefit, inspiration, comfort, and the confirmation of our Faith.\" On August 9, 1970, Metropolitan Ireney (Bekish) of the OCA along with Archbishop Paul (Olmari) of Finland and other hierarchs and clergy presided over the canonization service, which was held at Holy Resurrection Cathedral on Kodiak Island. His relics were transferred from his grave underneath the Sts. Sergius and Herman of Valaam Chapel (i.e., the Saints Sergius and Herman of Valaam Chapel), on Spruce Island, to the Holy Resurrection Cathedral.\n\nOn the same date, the bishops of the Russian Orthodox Church Outside of Russia also canonized Herman at the Holy Virgin Cathedral (\"Joy of All Who Sorrow\") in San Francisco. At the all-night vigil, the canon to St. Herman was read for the first time by Brother Gleb Podmoshensky, one of the founding brothers of the St. Herman of Alaska Serbian Orthodox Brotherhood in 1963. He, Eugene (Seraphim) Rose, and Lawrence Campbell gathered material for the Synod of Bishops in order to support the glorification of Herman, and also helped compose the liturgical service in his honor.\n\nThere are several feast days throughout the year on which Saint Herman of Alaska is commemorated. Since there are two different calendars currently in use among various Orthodox churches, two dates are listed: the first date is the date on the traditional Julian Calendar, the second date, after the slash, is the same day on the modern Gregorian Calendar:\n\n\nThe major portion of his relics are preserved at Holy Resurrection Cathedral in Kodiak, Alaska, while his burial site at the Sts. Sergius and Herman Chapel, Spruce Island, Alaska is an important pilgrimage site, where the devout will often take soil from his grave and water from the spring named in his honour. A portion of his relics are enshrined at the St. Ignatius Chapel at the Antiochan Village in Pennsylvania, a conference and retreat center of the Antiochian Orthodox Christian Archdiocese of North America, where he is regarded as one of their patron saints.\n\nIn 1963, with the blessing of John Maximovitch, Archbishop of Shanghai and San Francisco, a community of Orthodox booksellers and publishers called the St. Herman of Alaska Brotherhood was formed to publish Orthodox missionary information in English. One of the founders was Father Seraphim Rose. The Brotherhood did much to advance the cause of St. Herman's glorification as a saint. Saint Herman's Orthodox Theological Seminary in Kodiak, Alaska is named in his honor, as are numerous parish churches throughout the world.\n\nOn Tuesday, August 4, 1970, the 91st Congress of the United States acknowledged the glorification of St Herman of Alaska with a speech in the Senate, and his biography was formally entered into the Congressional Record.\n\nIn 1993, Patriarch Alexis II visited Kodiak to venerate the relics of Saint Herman. He left as a gift an ornate \"lampada\" (oil lamp) which burns constantly over the reliquary. Pilgrims from all over the world are anointed with holy oil from this \"lampada\".\n\nHerman is also honored with a feast day on the liturgical calendar of the Episcopal Church (USA) on August 9.\n\nThe Finnish Orthodox Church chapel in Tapiola, Finland is dedicated to St. Herman of Alaska.\n\n\n"}
{"id": "14294", "url": "https://en.wikipedia.org/wiki?curid=14294", "title": "Hausdorff dimension", "text": "Hausdorff dimension\n\nIn mathematics, Hausdorff dimension (a.k.a. fractal dimension) is a measure of \"roughness\" and/or chaos that was first introduced in 1918 by mathematician Felix Hausdorff. Applying its mathematical formalisms provides that the Hausdorff dimension of a single point is zero, of a line segment is 1, of a square is 2, and of a cube is 3. That is, for sets of points that define a smooth shape or a shape that has a small number of corners—the shapes of traditional geometry and science—the Hausdorff dimension is an integer agreeing with the usual sense of dimension, also known as the topological dimension. However, formalisms have also been developed that allow calculation of the dimension of other less simple objects, where, based solely on its properties of scaling and self-similarity, one is led to the conclusion that particular objects—including fractals—have non-integer Hausdorff dimensions. Because of the significant technical advances made by Abram Samoilovitch Besicovitch allowing computation of dimensions for highly irregular or \"rough\" sets, this dimension is also commonly referred to as the \"Hausdorff–Besicovitch dimension.\"\n\nThe Hausdorff dimension, more specifically, is a further dimensional number associated with a given set, where the distances between all members of that set are defined. Such a set is termed a metric space. The dimension is drawn from the extended real numbers, , as opposed to the more intuitive notion of dimension, which is not associated to general metric spaces, and only takes values in the non-negative integers.\n\nIn mathematical terms, the Hausdorff dimension generalizes the notion of the dimension of a real vector space. That is, the Hausdorff dimension of an \"n\"-dimensional inner product space equals \"n\". This underlies the earlier statement that the Hausdorff dimension of a point is zero, of a line is one, etc., and that irregular sets can have noninteger Hausdorff dimensions. For instance, the Koch snowflake summarized earlier is constructed from an equilateral triangle; in each iteration, its component line segments are divided into 3 segments of unit length, the newly created middle segment is used as the base of a new equilateral triangle that points outward, and this base segment is then deleted to leave a final object from the iteration of unit length of 4. That is, after the first iteration, each original line segment has been replaced with N=4, where each self-similar copy is 1/S = 1/3 as long as the original. Stated another way, we have taken an object with Euclidean dimension, D, and reduced its linear scale by 1/3 in each direction, so that its length increases to N=S. This equation is easily solved for D, yielding the ratio of logarithms (or natural logarithms) appearing in the figures, and giving—in the Koch and other fractal cases—non-integer dimensions for these objects.\n\nThe Hausdorff dimension is a successor to the simpler, but usually equivalent, box-counting or Minkowski–Bouligand dimension.\n\nThe intuitive concept of dimension of a geometric object \"X\" is the number of independent parameters one needs to pick out a unique point inside. However, any point specified by two parameters can be instead specified by one, because the cardinality of the real plane is equal to the cardinality of the real line (this can be seen by an argument involving interweaving the digits of two numbers to yield a single number encoding the same information). The example of a space-filling curve shows that one can even take one real number into two both surjectively (so all pairs of numbers are covered) and \"continuously\", so that a one-dimensional object completely fills up a higher-dimensional object.\n\nEvery space filling curve hits some points multiple times, and does not have a continuous inverse. It is impossible to map two dimensions onto one in a way that is continuous and continuously invertible. The topological dimension, also called Lebesgue covering dimension, explains why. This dimension is \"n\" if, in every covering of \"X\" by small open balls, there is at least one point where \"n\" + 1 balls overlap. For example, when one covers a line with short open intervals, some points must be covered twice, giving dimension \"n\" = 1.\n\nBut topological dimension is a very crude measure of the local size of a space (size near a point). A curve that is almost space-filling can still have topological dimension one, even if it fills up most of the area of a region. A fractal has an integer topological dimension, but in terms of the amount of space it takes up, it behaves like a higher-dimensional space.\n\nThe Hausdorff dimension measures the local size of a space taking into account the distance between points, the metric. Consider the number \"N\"(\"r\") of balls of radius at most \"r\" required to cover \"X\" completely. When \"r\" is very small, \"N\"(\"r\") grows polynomially with 1/\"r\". For a sufficiently well-behaved \"X\", the Hausdorff dimension is the unique number \"d\" such that N(\"r\") grows as 1/\"r\" as \"r\" approaches zero. More precisely, this defines the box-counting dimension, which equals the Hausdorff dimension when the value \"d\" is a critical boundary between growth rates that are insufficient to cover the space, and growth rates that are overabundant.\n\nFor shapes that are smooth, or shapes with a small number of corners, the shapes of traditional geometry and science, the Hausdorff dimension is an integer agreeing with the topological dimension. But Benoit Mandelbrot observed that fractals, sets with noninteger Hausdorff dimensions, are found everywhere in nature. He observed that the proper idealization of most rough shapes you see around you is not in terms of smooth idealized shapes, but in terms of fractal idealized shapes:\n\nClouds are not spheres, mountains are not cones, coastlines are not circles, and bark is not smooth, nor does lightning travel in a straight line.\n\nFor fractals that occur in nature, the Hausdorff and box-counting dimension coincide. The packing dimension is yet another similar notion which gives the same value for many shapes, but there are well documented exceptions where all these dimensions differ.\n\nLet \"X\" be a metric space. If \"S\" ⊂ \"X\" and \"d\" ∈ [0, ∞), the \"d\"-dimensional Hausdorff content of \"S\" is defined by\nIn other words, formula_2 is the infimum of the set of numbers δ ≥ 0 such that there is some (indexed) collection of balls formula_3 covering \"S\" with \"r\" > 0 for each \"i\" ∈ \"I\" that satisfies formula_4. (Here, we use the standard convention that inf Ø = ∞.)\n\nThe Hausdorff dimension of \"X\" is defined by\n\nEquivalently, dim(\"X\") may be defined as the infimum of the set of \"d\" ∈ [0, ∞) such that the \"d\"-dimensional Hausdorff measure of \"X\" is zero. This is the same as the supremum of the set of \"d\" ∈ [0, ∞) such that the \"d\"-dimensional Hausdorff measure of \"X\" is infinite (except that when this latter set of numbers \"d\" is empty the Hausdorff dimension is zero).\n\n\n\nLet \"X\" be an arbitrary separable metric space. There is a topological notion of inductive dimension for \"X\" which is defined recursively. It is always an integer (or +∞) and is denoted dim(\"X\").\n\nTheorem. Suppose \"X\" is non-empty. Then \nMoreover,\nwhere \"Y\" ranges over metric spaces homeomorphic to \"X\". In other words, \"X\" and \"Y\" have the same underlying set of points and the metric \"d\" of \"Y\" is topologically equivalent to \"d\".\n\nThese results were originally established by Edward Szpilrajn (1907–1976), e.g., see Hurewicz and Wallman, Chapter VII.\n\nThe Minkowski dimension is similar to, and at least as large as, the Hausdorff dimension, and they are equal in many situations. However, the set of rational points in [0, 1] has Hausdorff dimension zero and Minkowski dimension one. There are also compact sets for which the Minkowski dimension is strictly larger than the Hausdorff dimension.\n\nIf there is a measure μ defined on Borel subsets of a metric space \"X\" such that \"μ\"(\"X\") > 0 and \"μ\"(\"B\"(\"x\", \"r\")) ≤ \"r\" holds for some constant \"s\" > 0 and for every ball \"B\"(\"x\", \"r\") in \"X\", then dim(\"X\") ≥ \"s\". A partial converse is provided by Frostman's lemma.\n\nIf formula_8 is a finite or countable union, then\n\nThis can be verified directly from the definition.\n\nIf \"X\" and \"Y\" are non-empty metric spaces, then the Hausdorff dimension of their product satisfies\n\nThis inequality can be strict. It is possible to find two sets of dimension 0 whose product has dimension 1. In the opposite direction, it is known that when \"X\" and \"Y\" are Borel subsets of R, the Hausdorff dimension of \"X\" × \"Y\" is bounded from above by the Hausdorff dimension of \"X\" plus the upper packing dimension of \"Y\". These facts are discussed in Mattila (1995).\n\nTheorem. For any given formula_11 there are uncountable fractals with Hausdorff dimension formula_12 in n-dimensional Euclidean space formula_13 \n\nMany sets defined by a self-similarity condition have dimensions which can be determined explicitly. Roughly, a set \"E\" is self-similar if it is the fixed point of a set-valued transformation ψ, that is ψ(\"E\") = \"E\", although the exact definition is given below.\n\nTheorem. Suppose\n\nare contractive mappings on R with contraction constant \"r\" < 1. Then there is a unique \"non-empty\" compact set \"A\" such that\n\nThe theorem follows from Stefan Banach's contractive mapping fixed point theorem applied to the complete metric space of non-empty compact subsets of R with the Hausdorff distance.\n\nTo determine the dimension of the self-similar set \"A\" (in certain cases), we need a technical condition called the \"open set condition\" (OSC) on the sequence of contractions ψ.\n\nThere is a relatively compact open set \"V\" such that\n\nwhere the sets in union on the left are pairwise disjoint.\n\nThe open set condition is a separation condition that ensures the images ψ(\"V\") do not overlap \"too much\".\n\nTheorem. Suppose the open set condition holds and each ψ is a similitude, that is a composition of an isometry and a dilation around some point. Then the unique fixed point of ψ is a set whose Hausdorff dimension is \"s\" where \"s\" is the unique solution of\n\nThe contraction coefficient of a similitude is the magnitude of the dilation.\n\nWe can use this theorem to compute the Hausdorff dimension of the Sierpinski triangle (or sometimes called Sierpinski gasket). Consider three non-collinear points \"a\", \"a\", \"a\" in the plane R and let ψ be the dilation of ratio 1/2 around \"a\". The unique non-empty fixed point of the corresponding mapping ψ is a Sierpinski gasket and the dimension \"s\" is the unique solution of\n\nTaking natural logarithms of both sides of the above equation, we can solve for \"s\", that is: \"s\" = ln(3)/ln(2). The Sierpinski gasket is self-similar and satisfies the OSC. In general a set \"E\" which is a fixed point of a mapping\n\nis self-similar if and only if the intersections\n\nwhere \"s\" is the Hausdorff dimension of \"E\" and \"H\" denotes Hausdorff measure. This is clear in the case of the Sierpinski gasket (the intersections are just points), but is also true more generally:\n\nTheorem. Under the same conditions as the previous theorem, the unique fixed point of ψ is self-similar.\n\n\n\n"}
{"id": "14296", "url": "https://en.wikipedia.org/wiki?curid=14296", "title": "Heckler &amp; Koch", "text": "Heckler &amp; Koch\n\nHeckler & Koch GmbH (HK) () is a German defense manufacturing company that manufactures handguns, rifles, submachine guns, and grenade launchers. The company is located in Oberndorf in the state of Baden-Württemberg, and also has subsidiaries in the United Kingdom, France and the United States.\n\nThe Heckler & Koch Group comprises Heckler & Koch GmbH, Heckler & Koch Defense, NSAF Ltd., and Heckler & Koch France SAS. The company's motto is \"\"Keine Kompromisse!\"\" (No Compromises!). HK provides firearms for many military and paramilitary units, like the SAS, KMar, the US Navy SEALs, Delta Force, HRT, Canada's Joint Task Force 2, the German KSK and GSG 9 and many other counter-terrorist and hostage rescue teams.\n\nSome of their more notable products include the MP5, UMP submachine guns, the G3, HK417 battle rifles, the HK33, G36, HK416 assault rifles, the MG5, HK21 General-purpose machine guns, the MP7 personal defense weapon, the USP series of handguns, and the high-precision PSG1 sniper rifle. All HK firearms are named by a prefix and the official designation, with suffixes used for variants.\n\nHK has a history of innovation in firearms, such as the use of polymers in weapon designs and the use of an integral rail for flashlights on handguns. HK also developed modern polygonal rifling, noted for its high accuracy, increased muzzle velocity and barrel life. Not all its technologically ambitious designs have become commercially successful products (for instance, the advanced but now abandoned G11 military rifle, which fired caseless high-velocity ammunition). In its extensive product range, HK has used the following operating systems for small arms: blowback operation, short-recoil, roller-delayed blowback, gas-delayed blowback, and gas operation (via Short-stroke piston).\n\nWith the fall of Germany at the end of World War II, Oberndorf came under French control, and the entire Waffenfabrik Mauser AG factory was dismantled by French occupying forces. All factory records were destroyed on orders of the local French Army commander. In 1948, three former Mauser engineers, Edmund Heckler, Theodor Koch, and Alex Seidel, saved what they could from the factory and used what they salvaged to start a machine tool plant in the vacant factory that became known as the Engineering Office Heckler & Co.\n\nOn December 28, 1949, the Engineering Office Heckler & Co. changed its name and was registered officially as Heckler & Koch GmbH. Initially the new company manufactured machine tools, bicycle and sewing machine parts, gauges and other precision parts.\n\nIn 1956, Heckler & Koch responded to the West German government's tender for a new infantry rifle for the Bundeswehr (German Federal Army) with the proposal of the G3 battle rifle, which was based on the Spanish CETME rifle. The German government awarded Heckler & Koch the tender and by 1959 declared the G3 the standard rifle of the Bundeswehr. In 1961, Heckler & Koch developed the 7.62×51mm HK21 general-purpose machine gun, based on the G3 battle rifle.\n\nIn 1966, Heckler & Koch introduced the HK54 machine pistol, which eventually launched in 1969 as the MP5 machine pistol. Two years later, the company introduced the 5.56×45mm HK33 assault rifle, a smaller version of the G3 battle rifle chambered in 5.56mm NATO.\n\nIn 1974, Heckler & Koch diversified into two more areas, HK Defense and Law Enforcement Technology and HK Hunting and Sports Firearms. Since then HK has designed and manufactured more than 100 different types of firearms and devices for the world's military and law enforcement organizations as well as sports shooters and hunters.\n\nIn 1990, Heckler & Koch completed two decades of development of their revolutionary caseless weapon system and produced prototypes of the HK G11. The company also produced prototypes of the HK G41 military rifle intended for the Bundeswehr. Due to the international political climate at the time (East and West Germany uniting and defense budget cuts) the company was unable to secure funded contracts from the German government to support production of either weapon system and became financially vulnerable. The next year, Heckler & Koch was sold to the British Aerospace's Royal Ordnance division.\n\nDuring 1994 and 1995, the German government awarded Heckler & Koch contracts for producing an updated standard assault rifle and updated standard sidearm for the Bundeswehr. Heckler & Koch developed and produced the Project HK50, a lightweight carbon fiber–reinforced polymer assault rifle, which became the HK G36 assault rifle. In addition, Heckler & Koch produced the HK P8 derived as a variant of its Universale Selbstladepistole (USP) series of handguns (which had been in production since 1989). The P8 was adopted as the standard handgun for the Bundeswehr in 1994 and the G36 in 1995.\n\nAs the result of a 1999 merger between British Aerospace and Marconi Electronic Systems, Heckler & Koch was owned by BAE Systems and contracted to refurbish the SA80 rifle for the British Army. This contract entailed a modification programme to the SA80 series of rifles to address a number of reliability issues with the SA80. In 2002, BAE Systems restructured and sold Heckler & Koch to a group of private investors, who created the German group holding company HK Beteiligungs GmbH.\n\nIn 2003, HK Beteiligungs GmbH's business organization restructured as Heckler & Koch Jagd und Sportwaffen GmbH (HKJS) and its business was separated into the two business areas similar to the 1974 business mission areas, Defense and Law Enforcement and Sporting Firearms.\n\nIn 2004, Heckler & Koch was awarded a major handgun contract for the DHS, worth a potential $26.2 million for up to 65,000 handguns. This contract ranks as the single largest handgun procurement contract in US law enforcement history.\n\nHK was contracted by the United States Army to produce the kinetic energy subsystem (see: kinetic projectiles or kinetic energy penetrator) of the Objective Individual Combat Weapon, a planned replacement for the M16/M203 grenade launcher combination. The OICW was designed to fire 5.56 mm bullets and 25 mm grenades. The kinetic energy component was also developed separately as the XM8, though both the OICW and XM8 are now indefinitely suspended.\n\nHeckler & Koch developed a Colt M4 variant, marketed as the HK416. HK replaced the direct impingement system used by the Stoner design on the original M16 with a short-stroke piston operating system.\n\nThere is no indication that the rifle will be adopted by the United States Armed Forces other than in the Marine Corps as the IAR or M27, but the elite Delta Force and other special operations units have fielded the HK416 in combat, and Oklahoma Senator Tom Coburn has called for \"free and open competition\" to determine whether the army should buy the HK416 or continue to purchase more M4 carbines. Incoming Secretary of the Army Pete Geren agreed in July 2007 to hold a \"dust chamber\" test pitting the M4 against HK's HK416 and XM8, as well as the rival Fabrique Nationale's SOF Combat Assault Rifle (SCAR) design. Coburn had threatened to stop Geren’s Senate confirmation if he did not agree to the test. The HK XM8 and FN SCAR had the fewest failures in the test, closely followed by the HK416, while the M4 had by far the most. In 2007, the Norwegian Army became the first to field the HK416 as a standard-issue rifle.\n\nHK sells its pistols in the United States to both law enforcement and civilian markets. The company has locations in Virginia, New Hampshire, and Georgia.\n\nHK has been accused of shipping small arms to conflict regions such as Bosnia and Nepal, and has licensed its weapons for production by governments with poor human rights records such as Sudan, Thailand and Burma. It has been argued that the company effectively evaded EU export restrictions when these licensees sold HK weapons to conflict zones including Indonesia, Sri Lanka and Sierra Leone.\n\nAccording to the newspaper \"Stuttgarter Nachrichten\" (31 August 2011), as well as the state broadcaster ARD, a large stockpile of G36 assault rifles fell into rebel hands during the August 2011 attack on Muammar Gaddafi's compound in Tripoli. It is unclear how many were exported to Libya and by whom.\n\nFormat: Abbreviation = \"German Text\" (\"English Text\")\n\n\n\n"}
{"id": "14297", "url": "https://en.wikipedia.org/wiki?curid=14297", "title": "Heckler &amp; Koch MP5", "text": "Heckler &amp; Koch MP5\n\nThe MP5 () is a 9x19mm Parabellum submachine gun, developed in the 1960s by a team of engineers from the German small arms manufacturer Heckler & Koch GmbH (H&K) of Oberndorf am Neckar. There are over 100 variants of the MP5, including some semi-automatic versions.\n\nThe MP5 is one of the most widely used submachine guns in the world, having been adopted by 40 nations and numerous military, law enforcement, intelligence, and security organizations. It was widely used by SWAT teams in North America, but has largely been supplemented by AR-15 variants in the 21st century.\n\nIn 1999, Heckler & Koch developed the Heckler & Koch UMP, the MP5's successor; both are available .\n\nHeckler & Koch, encouraged by the success of the G3 automatic rifle, developed a family of small arms consisting of four types of firearms all based on a common G3 design layout and operating principle. The first type was chambered for 7.62×51mm NATO, the second for the 7.62×39mm M43 round, the third for the intermediate 5.56×45mm NATO caliber, and the fourth type for the 9×19mm Parabellum pistol cartridge. The MP5 was created within the fourth group of firearms and was initially known as the HK54.\n\nWork on the MP5 began in 1964 and two years later it was adopted by the German Federal Police, border guard and army special forces.\n\nIn 1980, the MP5 achieved iconic status as a result of its use on live television by SAS commandos in Operation Nimrod, where they stormed the Iranian Embassy in London, rescuing hostages and killing five terrorists. The MP5 has become a mainstay of SWAT units of law enforcement agencies in the United States since then. However, in the late 1990s, as a result of the North Hollywood shootout, police special response teams have supplanted most MP5s with AR-15-based rifles.\n\nThe MP5 is manufactured under license in several nations including Greece (formerly at EBO – Hellenic Arms Industry, currently at EAΣ – Hellenic Defense Systems), Iran (Defense Industries Organization), Mexico (SEDENA), Pakistan (Pakistan Ordnance Factories), Saudi Arabia, Sudan (Military Industry Corporation), Turkey (MKEK), and the United Kingdom (initially at Royal Ordnance, later diverted to Heckler & Koch Great Britain).\n\nThe primary version of the MP5 family is the MP5A2, which is a lightweight, air-cooled, selective fire delayed blowback operated 9×19mm Parabellum weapon with a roller-delayed bolt. It fires from a closed bolt (bolt forward) position.\n\nThe fixed, free floating, cold hammer-forged barrel has 6 right-hand grooves with a 1 in 250 mm (1:10 in) rifling twist rate and is pressed and pinned into the receiver.\n\nThe first MP5 models used a double-column straight box magazine, but since 1977, slightly curved, steel magazines are used with a 15-round capacity (weighing 0.12 kg) or a 30-round capacity (0.17 kg empty).\n\nThe adjustable iron sights (closed type) consist of a rotating rear diopter drum and a front post installed in a hooded ring. The rear sight is mechanically adjustable for both windage and elevation with the use of a special tool, being adjusted at the factory for firing at with standard FMJ 9×19mm NATO ammunition. The rear sight drum provides four apertures of varying diameters used to adjust the diopter system, according to the user's preference and tactical situation. Changing between apertures does not change the point of impact down range. For accurate shooting the user should select the smallest aperture that still allows an equal circle of light between the rear sight aperture and the outside of the front sight hood ring.\n\nThe MP5 has a hammer firing mechanism. The trigger group is housed inside an interchangeable polymer trigger module (with an integrated pistol grip) and equipped with a three-position fire mode selector that serves as the manual safety toggle. The \"S\" or \"Sicher\" position in white denotes weapon safe, \"E\" or \"Einzelfeuer\" in red represents single fire, and \"F\" or \"Feuerstoß\" (also marked in red) designates continuous fire. The SEF symbols appear on both sides of the plastic trigger group. The selector lever is actuated with the thumb of the shooting hand and is located only on the left side of the original SEF trigger group or on both sides of the ambidextrous trigger groups. The safety/selector is rotated into the various firing settings or safety position by depressing the tail end of the lever. Tactile clicks (stops) are present at each position to provide a positive stop and prevent inadvertent rotation. The \"safe\" setting disables the trigger by blocking the hammer release with a solid section of the safety axle located inside the trigger housing.\n\nThe non-reciprocating cocking handle is located above the handguard and protrudes from the cocking handle tube at approximately a 45° angle. This rigid control is attached to a tubular piece within the cocking lever housing called the cocking lever support, which in turn makes contact with the forward extension of the bolt group. It is not however connected to the bolt carrier and therefore cannot be used as a forward assist to fully seat the bolt group. The cocking handle is held in a forward position by a spring detent located in the front end of the cocking lever support which engages in the cocking lever housing. The lever is locked back by pulling it fully to the rear and rotating it slightly clockwise where it can be hooked into an indent in the cocking lever tube.\n\nThe bolt rigidly engages the barrel extension—a cylindrical component welded to the receiver into which the barrel is pinned. The delay mechanism is of the same design as that used in the G3 rifle. The two-part bolt consists of a bolt head with rollers and a bolt carrier. The heavier bolt carrier lies up against the bolt head when the weapon is ready to fire and inclined planes on the front locking piece lie between the rollers and force them out into recesses in the barrel extension.\n\nWhen fired, expanding propellant gases produced from the burning powder in the cartridge exert rearward pressure on the bolt head transferred through the base of the cartridge case as it is propelled out of the chamber. A portion of this force is transmitted through the rollers projecting from the bolt head, which are cammed inward against the inclined flanks of the locking recesses in the barrel extension and to the angled shoulders of the locking piece. The selected angles of the recesses and the incline on the locking piece produce a velocity ratio of about 4:1 between the bolt carrier and the bolt head. This results in a calculated delay, allowing the projectile to exit the barrel and gas pressure to drop to a safe level before the case is extracted from the chamber.\n\nThe delay results from the amount of time it takes for enough recoil energy to be transferred through to the bolt carrier in a sufficient quantity for it to be driven to the rear against the force of inertia of the bolt carrier and the forward pressure exerted against the bolt by the recoil spring. As the rollers are forced inward they displace the locking piece and propel the bolt carrier to the rear. The bolt carrier's rearward velocity is four times that of the bolt head since the cartridge remains in the chamber for a short period of time during the initial recoil impulse. After the bolt carrier has traveled rearward 4 mm, the locking piece is withdrawn fully from the bolt head and the rollers are compressed into the bolt head. Only once the locking rollers are fully cammed into the bolt head can the entire bolt group continue its rearward movement in the receiver, breaking the seal in the chamber and continuing the feeding cycle.\n\nSince the 9×19mm Parabellum cartridge is relatively low powered, the bolt does not have an anti-bounce device like the G3, but instead the bolt carrier contains tungsten granules that prevent the bolt group from bouncing back after impacting the barrel extension. The weapon has a fluted chamber that enhances extraction reliability by bleeding gases backwards into the shallow flutes running along the length of the chamber to prevent the cartridge case from expanding and sticking to the chamber walls (since the bolt is opened under relatively high barrel pressure). A spring extractor is installed inside the bolt head and holds the case securely until it strikes the ejector arm and is thrown out of the ejection port to the right of the receiver. The lever-type ejector is located inside the trigger housing (activated by the movement of the recoiling bolt).\n\nIn the early 1970s, HK introduced a conversion kit for the MP5 that enables it to use rimfire ammunition (.22 LR). This unit consists of a barrel insert, a bolt group and two 20-round magazines. This modification reduces the cyclic rate to 650 rounds/min. It was sold mostly to law enforcement agencies as a way to train recruits on handling the MP5. It used ammunition that was cheaper and had a lower recoil than 9×19mm Parabellum. This reduced training costs and built up skill and confidence in the operators before transitioning them to the full-bore model.\n\nThreading is provided at the muzzle to work with certain muzzle devices made by Heckler & Koch, including: a slotted flash suppressor, blank firing attachment (marked with a red-painted band denoting use with blank ammunition only), an adapter for launching rifle grenades (for use with rifle-style grenades with an inside diameter of 22 mm using a special grenade launching cartridge) and a cup-type attachment used to launch tear gas grenades. An optional three-lugged barrel is also available for mounting a quick-detachable suppressor.\n\nThe receiver housing has a proprietary claw-rail mounting system that permits the attachment of a standard Heckler & Koch quick-detachable scope mount (also used with the G3, HK33 and G3SG/1). It can be used to mount daytime optical sights (telescopic 4×24), night sights, reflex sights and laser pointers. The mount features two spring-actuated bolts, positioned along the base of the mount, which exert pressure on the receiver to hold the mount in the same position at all times assuring zero retention. All versions of the quick-detachable scope mount provide a sighting tunnel through the mount so that the shooter can continue to use the fixed iron sights with the scope mount attached to the top of the receiver.\n\nA Picatinny rail adapter can be placed on top that locks into the claw rails. This allows the mounting of STANAG scopes and has a lower profile than the claw-rail system.\n\nAftermarket replacement handguards with Picatinny rails are available. Single-rail models have a Picatinny rail along the bottom and triple-rail models have rails along the bottom and sides. They allow the mounting of accessories like flashlights, laser pointers, target designators, vertical foregrips, and bipods.\n\nThe MP5A2 has a fixed buttstock (made of a synthetic polymer), whereas the compact \"MP5A3\" has a retractable metal stock. The stockless \"MP5A1\" has a buttcap with a sling mount for concealed carry; the MP5K series was a further development of this idea.\n\nThe \"MP5A4\" (fixed stock) and \"MP5A5\" (sliding stock) models, which were introduced in 1974, are available with four-position trigger groups. The pistol grips are straight, lacking the contoured grip and thumb groove of the \"MP5A1\", \"MP5A2\", and \"MP5A3\". The selector lever stops are marked with bullet pictograms rather than letters or numbers (each symbol represents the number of bullets that will be fired when the trigger is pulled and held rearward with a full magazine inserted in the weapon) and are fully ambidextrous (the selector lever is present on each side of the trigger housing). The additional setting of the fire selector, one place before the fully automatic setting, enables a two or three-shot burst firing mode.\n\nA variant with the last trigger group designated the MP5-N (N—Navy) was developed in 1986 for the United States Navy. This model has a collapsible stock, a tritium-illuminated front sight post and a threaded barrel for use with a stainless steel sound suppressor made by Knight's Armament Company together with quieter subsonic ammunition. It had ambidextrous controls, a straight pistol grip, pictogram markings, and originally had a four-position selector (Safe, Semi-Auto, 3-Round Burst, Full Auto). This was replaced with a similar three-position ambidextrous selector after an improperly-reassembled trigger group spontaneously fired during an exercise. The \"Navy\"-style ambidextrous trigger group later became standard, replacing the classic \"SEF\".\n\nH&K offers dedicated training variants of these weapons, designated \"MP5A4PT\" and \"MP5A5PT\" (PT—Plastic Training), modified to fire a plastic 9×19mm PT training cartridge produced by Dynamit Nobel of Germany. These weapons operate like the standard MP5 but have a floating chamber and both rollers have been omitted from the bolt to function properly when firing the lighter plastic projectiles. To help identify these weapons blue dots were painted on their cocking handles and additional lettering provided. The PT variant can be configured with various buttstocks and trigger groups and was developed for the West German Police and Border Guard.\n\nThe \"MP5SFA2\" (SF – single-fire) was developed in 1986 in response to the American FBI solicitation for a \"9 mm Single-fire Carbine\". It is the same as the MP5A2 but is fitted with an ambidextrous semi-automatic only trigger group. The \"MP5SFA3\" is similar except it has a retractable metal stock like the MP5A3. Versions delivered after December 1991 are assembled with select-fire bolt carriers allowing fully automatic operation when used with the appropriate trigger module.\n\nThe semi-automatic \"MP5SF\" models are widely use by British police forces including London's Metropolitan Police Service Specialist Firearms Command, Diplomatic Protection Group, Authorised firearms officers, and the Police Service of Northern Ireland to name a few.\n\nThe two-position trigger unit was used in the single-fire \"HK94\" carbine that was produced specifically for the civilian market with a barrel.\n\nIn 1974, H&K initiated design work on a sound-suppressed variant of the MP5, designated the MP5SD (SD—\"Schalldämpfer\", German for \"sound suppressor\"), which features an integral but detachable aluminium sound suppressor and a lightweight bolt. The weapon's barrel has 30 ports drilled forward of the chamber through which escaping gases are diverted to the surrounding sealed tubular casing that is screwed onto threading on the barrel’s external surface just prior to the ported segment. The suppressor itself is divided into two stages; the initial segment surrounding the ported barrel serves as an expansion chamber for the propellant gases, reducing gas pressure to slow down the acceleration of the projectile. The second, decompression stage occupies the remaining length of the suppressor tube and contains a stamped metal helix separator with several compartments which increase the gas volume and decrease its temperature, deflecting the gases as they exit the muzzle, so muffling the exit report. The bullet leaves the muzzle at subsonic velocity, so it does not generate a sonic shock wave in flight. As a result of reducing the barrel's length and venting propellant gases into the suppressor, the bullet's muzzle velocity was lowered anywhere from 16% to 26% (depending on the ammunition used) while maintaining the weapon’s automation and reliability. The weapon was designed to be used with standard supersonic ammunition with the suppressor on at all times.\n\nThe MP5SD is produced exclusively by H&K in several versions: the MP5SD1 and MP5SD4 (both have a receiver end cap instead of a buttstock), MP5SD2 and MP5SD5 (equipped with a fixed synthetic buttstock) and the MP5SD3 and MP5SD6 (fitted with a collapsible metal stock). The MP5SD1, MP5SD2 and MP5SD3 use a standard 'SEF' trigger group (from the MP5A2 and MP5A3), while the MP5SD4, MP5SD5, and MP5SD6 use the 'Navy' trigger group—a trigger module with a mechanically limited 3-round burst mode and ambidextrous selector controls (from the MP5A4 and MP5A5). A suppressed version was produced for the U.S. Navy—designated the MP5SD-N, which is a version of the MP5SD3 with a retractable metal stock, front sight post with tritium-illuminated dot and a stainless steel suppressor. This model has a modified cocking handle support to account for the slightly larger outside diameter of the suppressor. The design of the suppressor allows the weapon to be fired with water inside, should water enter the device during operation in or near water.\n\nIn 1976, a shortened machine pistol version of the MP5A2 was introduced; the \"MP5K\" (K from the German word \"Kurz\" = \"short\") was designed for close quarters battle use by clandestine operations and special services. The MP5K does not have a shoulder stock (the receiver end was covered with a flat end cap, featuring a buffer on the inside and a sling loop on the outside), and the bolt and receiver were shortened at the rear. The resultant lighter bolt led to a higher rate of fire than the standard MP5. The barrel, cocking handle and its cover were shortened and a vertical foregrip was used to replace the standard handguard. The barrel ends at the base of the front sight, which prevents the use of any sort of muzzle device.\n\nThe MP5K is produced (by Heckler & Koch and under license in Iran and Turkey) in four different versions: the MP5K, \"MP5KA4\", \"MP5KA1\", \"MP5KA5\", where the first two variants have adjustable, open-type iron sights (with a notched rotary drum), and the two remaining variants – fixed open sights; however, the front sight post was changed and a notch was cut into the receiver top cover. The MP5K retained the capability to use optical sights through the use of an adapter.\n\nA civilian semiautomatic derivative of the MP5K known as the SP89 was produced that had a foregrip with a muzzle guard in place of the vertical grip.\n\nIn 1991, a further variant of the MP5K was developed, designated the \"MP5K-PDW\" (PDW—Personal Defense Weapon) that retained the compact dimensions of the MP5K but restored the fire handling characteristics of the full-size MP5A2. The MP5K-PDW uses a side-folding synthetic shoulder stock (made by the U.S. company Choate Machine and Tool), a \"Navy\" trigger group, a front sight post with a built-in tritium insert and a slightly lengthened threaded, three-lug barrel (analogous to the MP5-N). The stock can be removed and replaced with a receiver endplate; a rotary drum with apertures from the MP5A2 can also be used.\n\nIn 1992, Heckler & Koch introduced the \"MP5/10\" (chambered in 10mm Auto) and \"MP5/40\" (chambered for the .40 S&W cartridge), which are based on the MP5A4 and MP5A5. These weapons were assembled in fixed and retractable stock configurations (without a separate designation) and are fed from translucent 30-round polymer box magazines. These weapons include a bolt hold-open device, which captures the bolt group in its rear position after expending the last cartridge from the magazine. The bolt is then released by pressing a lever positioned on the left side of the receiver. Both weapons use a barrel with 6 right-hand grooves and a 380 mm (1:15 in) twist rate, and like the MP5-N, both have a 3-lugged muzzle device and a tritium-illuminated front sight aiming dot.\n\nProblems with the MP5/10 and MP5/40 led to their discontinuation in 2000, although Heckler & Koch continues to provide support and spare parts.\n\n\n\n\n\n\n"}
{"id": "14298", "url": "https://en.wikipedia.org/wiki?curid=14298", "title": "Henry Middleton", "text": "Henry Middleton\n\nHenry Middleton (1717 – June 13, 1784) was a planter and public official from South Carolina. A member of the colonial legislature, during the American Revolution he attended the Continental Congress and served as that body's presiding officer for a few days in 1774. He left Congress before it declared independence. Back in South Carolina, he served as president of the provincial congress and senator in the newly created state government. After his capture by the British in 1780, he accepted defeat and returned to the status of a British subject until the end of the war.\n\nHenry Middleton was born in 1717 near Charleston, Province of South Carolina, to Arthur Middleton (1681–1737) and Susan Amory (1690-1722), on the family plantation, \"The Oaks\". Henry's father Arthur Middleton was a wealthy planter who had served as an acting governor of South Carolina. Henry was educated in England before returning to South Carolina to inherit his father's plantation. He became one of the largest landowners in the colony, owning and about 800 slaves.\n\nMiddleton married Mary Williams in 1741, with whom he would have five sons and seven daughters. After Mary’s death in 1761, Middleton would go on to marry twice more, second to Maria Henrietta Bull (in 1762) and third to Lady Mary McKenzie (in 1776).\n\nMiddleton served in a variety of public offices in South Carolina. He was a justice of the peace and a member of the Commons House of Assembly, where he was elected speaker in 1747, 1754, and 1755. He was a member of provincial council, but resigned in 1770 in opposition to British policy.\n\nIn 1774, at the outset of the American Revolution, Middleton was selected as a delegate to the Continental Congress. He served as that body's president during the last few days of the First Continental Congress, following the departure of Peyton Randolph. Middleton opposed declaring independence from Great Britain, and resigned from the Second Continental Congress in February 1776 when more radical delegates began pushing for independence. He was succeeded in Congress by his son, Arthur Middleton (1742–1787), who was more radical than his father and became a signer of the Declaration of Independence.\n\nAfter Middleton's return to South Carolina, he was elected president of the provincial congress and, beginning on November 16, 1775, served on the council of safety. In 1776, he and his son Arthur helped frame a temporary state constitution. In 1779, he became a state senator in the new government.\n\nWhen Charleston was captured by the British in 1780, Middleton accepted defeat and status as a British subject. This reversal apparently did not damage his reputation in the long run, due to his previous support of the Revolution, and he did not suffer the fate of having his estates confiscated, as many Loyalists did after the war.\n\nMiddleton died on June 13, 1784 in Charleston.\n\nHis grandson, also named Henry (1770–1846), had a long career in politics. He was Governor of South Carolina (1810–1812), U.S. Representative (1815–1819), and the minister to Russia (1820–1830). Some of Middleton's children married into prominent families. Daughter Henrietta married Governor Edward Rutledge, Sarah was the first wife of Charles Cotesworth Pinckney, and his daughter Susannah married John Parker.\n\n\n \n"}
{"id": "14299", "url": "https://en.wikipedia.org/wiki?curid=14299", "title": "Ham", "text": "Ham\n\nHam is pork from a leg cut that has been preserved by wet or dry curing, with or without smoking. As a processed meat, the term \"ham\" includes both whole cuts of meat and ones that have been mechanically formed. \n\nHam is made around the world, including a number of highly coveted regional specialties, such as Westphalian ham and some varieties of Spanish \"jamón\". In addition, numerous ham products have specific geographical naming protection, such as Prosciutto di Parma and Prosciutto Toscano in Europe, and Smithfield ham in the US.\n\nThe preserving of pork leg as ham has a long history, with Cato the Elder writing about the \"salting of hams\" in his \"De Agri Cultura\" tome around 160 BC.\n\nThere are claims that the Chinese were the first people to mention the production of cured ham. Larousse Gastronomique claims an origin from Gaul. It was certainly well established by the Roman period, as evidenced by an import trade from Gaul mentioned by Marcus Terentius Varro in his writings.\n\nThe modern word \"ham\" is derived from the Old English \"ham\" or \"hom\" meaning the hollow or bend of the knee, from a Germanic base where it meant \"crooked\". It began to refer to the cut of pork derived from the hind leg of a pig around the 15th century.\n\nBecause of the preservation process, ham is a compound foodstuff or ingredient, being made up of the original meat, as well as the remnants of the preserving agent(s), such as salt, but it is still recognised as a food in its own right.\n\nHam is produced by curing raw pork by salting, also known as dry curing, or brining, also known as wet curing. Additionally, smoking may be employed. Besides salt, several ingredients may be used to obtain flavoring and preservation, from black pepper (e.g. Prosciutto Toscano) to saffron (e.g. the \"Zafferano di San Gimignano\").\n\nTraditional dry cure hams may use only salt as the curative agent, such as with San Daniele or Parma hams, although this is comparatively rare. This process involves cleaning the raw meat, covering it in salt while it is gradually pressed draining all the blood. Specific herbs and spices may be used to add flavour during this step. The hams are then washed and hung in a dark, temperature-regulated place until dry. It is then hung to air for another period of time.\n\nThe duration of the curing process varies by the type of ham, with, for example, Serrano ham curing in 9–12 months, Parma hams taking more than 12 months, and Iberian ham taking up to 2 years to reach the desired flavour characteristics. Some dry cured hams, such as the Jinhua ham, take approximately 8 to 10 months to complete.\n\nMost modern dry cure hams also use nitrites (either sodium nitrite or potassium nitrate), which are added along with the salt. Nitrates are used because they prevent bacterial growth and, in a reaction with the meat's myoglobin, give the product a desirable dark red color. The amount and mixture of salt and nitrites used have an effect on the shrinkage of the meat. Because of the toxicity of nitrite (the lethal dose of nitrite for humans is about 22 mg per kg body weight), some areas specify a maximum allowable content of nitrite in the final product. Under certain conditions, especially during cooking, nitrites in meat can react with degradation products of amino acids, forming nitrosamines, which are known carcinogens.\n\nThe dry curing of ham involves a number of enzymatic reactions. The enzymes involved are proteinases (cathepsins – B, D, H & L, and calpains) and exopeptidases (peptidase and aminopeptidase). These enzymes cause proteolysis of muscle tissue, which creates large numbers of small peptides and free amino acids, while the adipose tissue undergoes lipolysis to create free fatty acids. Salt and phosphates act as strong inhibitors of proteolytic activity. Animal factors influencing enzymatic activity include age, weight, and breed. During the process itself, conditions such as temperature, duration, water content, redox potential, and salt content all have an effect.\n\nThe salt content in dry-cured ham varies throughout a piece of meat, with gradients determinable through sampling and testing or non-invasively through CT scanning.\n\nWet-cured hams are brined, which involves the immersion of the meat in a brine, sometimes with other ingredients such as sugar also added for flavour. Meat is typically kept in the brine for around 3 to 14 days. Wet curing also has the effect of increasing volume and weight of the finished product, by about 4%.\n\nThe wet curing process can also be achieved by pumping the curing solution into the meat. This can be quicker, increase the weight of the finished product by more than immersion, and ensure a more even distribution of salt through the meat. This process is quicker than traditional brining, normally being completed in a few days.\n\nHam can also be additionally preserved through smoking, in which the meat is placed in a smokehouse (or equivalent) to be cured by the action of smoke.\n\nThe main flavor compounds of smoked ham are guaiacol, and its 4-, 5-, and 6-methyl derivatives as well as 2,6-dimethylphenol. These compounds are produced by combustion of lignin, a major constituent of wood used in the smokehouse.\n\nIn many countries the term is now protected by statute, with a specific definition. For instance, in the United States, the Code of Federal Regulations (CFR) says that \"the word 'ham', without any prefix indicating the species of animal from which derived, shall be used in labeling only in connection with the hind legs of swine\".\n\nIn addition to the main categories, some processing choices can affect legal labeling. For instance, in the United States, a \"smoked\" ham must have been smoked by hanging over burning wood chips in a smokehouse or an atomized spray of liquid smoke such that the product appearance is equivalent; a \"hickory-smoked\" ham must have been smoked using only hickory. However, injecting \"smoke flavor\" is not legal grounds for claiming the ham was \"smoked\"; these are labeled \"smoke flavor added\". Hams can only be labeled \"honey-cured\" if honey was at least 50% of the sweetener used, is at least 3% of the formula, and has a discernible effect on flavor. So-called \"lean\" and \"extra lean\" hams must adhere to maximum levels of fat and cholesterol per 100 grams of product.\n\nWhole fresh pork leg can be labeled as \"fresh ham\" in the United States.\n\nA number of hams worldwide have some level of protection of their unique characteristics, usually relating to their method of preservation or location of production or processing. Dependent on jurisdiction, rules may prevent any other product being sold with the particular appellation, such as through the European protected geographical indication.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHam is typically used in its sliced form, often as a filling for sandwiches and similar foods, such as in the ham sandwich and ham and cheese sandwich. Other variations include toasted sandwiches such as the croque-monsieur and the Cubano. It is also a popular topping for pizza in the United States. \n\nIn the United Kingdom, a pork leg cut, either whole or sliced, that has been cured but requires additional cooking is known as gammon. Gammons were traditional cured before being cut from a side of pork along with bacon. When cooked, gammon is ham. Such roasts are a traditional part of British Christmas dinners. \n\nAs a processed meat, there has been concern over the health effects of ham consumption. A meta-analysis study from 2012 has shown a statistically relevant correlation between processed meat consumption and the risk of pancreatic cancer, with an increase in consumption of per day leading to a 19% increase in risk.\n\nThis supported earlier studies, including the 2007 study \"\", by the World Cancer Research Fund and the American Institute for Cancer Research, which reviewed more than 7,000 studies published worldwide. Among the recommendations was that, except for very rare occasions, people should avoid eating ham or other processed meats – cured, smoked, salted or chemically preserved meat products such as bacon, hot dogs, sausage, salami, and pastrami. The report states that once an individual reaches the weekly limit for red meat, every of processed meat consumed a day increases cancer risk by 21%.\n\nA European cohort study from 2013 also positively correlated processed meat consumption with higher all-cause mortality, with an estimation that 3.3% of the deaths amongst participants could have been prevented by consuming less than of \n\n\n"}
{"id": "14300", "url": "https://en.wikipedia.org/wiki?curid=14300", "title": "Henry Laurens", "text": "Henry Laurens\n\nHenry Laurens (December 8, 1792) was an American merchant, slave trader, and rice planter from South Carolina who became a political leader during the Revolutionary War. A delegate to the Second Continental Congress, Laurens succeeded John Hancock as President of the Congress. He was a signatory to the Articles of Confederation and President of the Continental Congress when the Articles were passed on November 15, 1777.\n\nLaurens had earned great wealth as a partner in the largest slave-trading house in North America, Austin and Laurens. In the 1750s alone, this Charleston firm oversaw the sale of more than 8,000 enslaved Africans.\n\nLaurens served for a time as Vice-President of South Carolina, and as the United States Minister to the Netherlands during the Revolutionary War. He was captured at sea by the British, and imprisoned for several years in the Tower of London.\n\nHis oldest son, John Laurens, was an \"aide-de-camp\" to George Washington and a colonel in the Continental Army.\n\nHenry Laurens' forebears were Huguenots who fled France after the Edict of Nantes was revoked in 1685. Henry's grandfather Andre Laurens left earlier, in 1682, and eventually made his way to America, settling first in New York City and then Charleston, South Carolina. Andre's son John married Hester (or Esther) Grasset, also a Huguenot refugee. Henry was their third child and eldest son. John Laurens became a saddler, and his business eventually grew to be the largest of its kind in the colonies.\n\nIn 1744 John Laurens sent Henry to London to augment the young man's business training. This took place in the company of Richard Oswald. John Laurens died in 1747, bequeathing a considerable estate to 23-year-old Henry.\n\nHe married Eleanor Ball, also of a South Carolina rice planter family, on June 25, 1750. They had thirteen children, many of whom died in infancy or childhood. Eleanor died in 1770, one month after giving birth to their last child. Laurens took their three sons to England for their education, encouraging their oldest, John Laurens, to study law. Instead of completing his studies, John Laurens returned to the United States in 1776, to serve in the American Revolutionary War.\n\nHenry Laurens served in the militia, as did most able-bodied men in his time. He rose to the rank of Lt. Colonel in the campaigns against the Cherokee Indians in 1757–1761, during the French and Indian War (also known as the Seven Years' War).\n\n1757 also marked the first year he was elected to the colonial assembly. Laurens was elected again every year but one until the Revolution replaced the assembly with a state Convention as an interim government. The year he missed was 1773, when he visited England to arrange for his sons' educations. He was named to the colony's Council in 1764 and 1768, but declined both times. In 1772 he joined the American Philosophical Society of Philadelphia, and carried on extensive correspondence with other members.\n\nAs the American Revolution neared, Laurens was at first inclined to support reconciliation with the British Crown. But as conditions deteriorated, he came to fully support the American position. When Carolina began to create a revolutionary government, Laurens was elected to the Provincial Congress, which first met on January 9, 1775. He was president of the Committee of Safety, and presiding officer of that congress from June until March 1776. When South Carolina installed a fully independent government, he served as the Vice President of South Carolina from March 1776 to June 27, 1777.\n\nHenry Laurens was first named a delegate to the Continental Congress on January 10, 1777. He served in the Congress from until 1780. He was the President of the Continental Congress from November 1, 1777 to December 9, 1778.\n\nIn the fall of 1779, the Congress named Laurens their minister to the Netherlands. In early 1780 he took up that post and successfully negotiated Dutch support for the war. But on his return voyage to Amsterdam that fall, the British frigate intercepted his ship, the continental packet \"Mercury\", off the banks of Newfoundland. Although his dispatches were tossed in the water, they were retrieved by the British, who discovered the draft of a possible U.S.-Dutch treaty prepared in Aix-la-Chapelle in 1778 by William Lee and the Amsterdam banker Jean de Neufville. This prompted Britain to declare war on the Dutch Republic, it becoming known as the Fourth Anglo-Dutch War.\n\nThe British charged Laurens with treason, transported him to England, and imprisoned him in the Tower of London (he is the only American to have been held prisoner in the Tower). His imprisonment was protested by the Americans. In the field, most captives were regarded as prisoners of war, and while conditions were frequently appalling, prisoner exchanges and mail privileges were accepted practice. During his imprisonment, Laurens was assisted by Richard Oswald, his former business partner and the principal owner of Bunce Island. Oswald argued on Laurens' behalf to the British government. Finally, on December 31, 1781 he was released in exchange for General Lord Cornwallis and completed his voyage to Amsterdam. He helped raise funds for the American effort.\n\nLaurens' oldest son, Colonel John Laurens, was killed in 1782 in the Battle of the Combahee River, as one of the last casualties of the Revolutionary War. He had supported enlisting and freeing slaves for the war effort, and suggested to his father that he begin with the 40 he stood to inherit. He had urged his father to free the family's slaves, but although conflicted, Henry Laurens never manumitted his 260 slaves.\n\nIn 1783 Laurens was sent to Paris as one of the Peace Commissioners for the negotiations leading to the Treaty of Paris. While he was not a signatory of the primary treaty, he was instrumental in reaching the secondary accords that resolved issues related to the Netherlands and Spain. Richard Oswald, a former partner of Laurens in the slave trade, was the principal negotiator for the British during the Paris peace talks.\n\nLaurens generally retired from public life in 1784. He was sought for a return to the Continental Congress, the Constitutional Convention in 1787 and the state assembly, but he declined all of these positions. He did serve in the state convention of 1788, where he voted to ratify the United States Constitution.\n\nBritish forces, during their occupation of Charleston, had burned the Laurens home at Mepkin during the war. When Laurens and his family returned in 1784, they lived in an outbuilding while the great house was rebuilt. He lived on the estate the rest of his life, working to recover the estimated £40,000 that the revolution had cost him (equivalent to about $ in ).\n\nLaurens died on December 8, 1792, at his estate, Mepkin. In his will he stated he wished to be cremated, and his ashes be interred at his estate. It is reported that his was the first formal cremation in United States. Afterward, the estate passed through several hands. Large portions of the estate still exist and are used today as a Trappist abbey.\n\n\n\n\n"}
{"id": "14301", "url": "https://en.wikipedia.org/wiki?curid=14301", "title": "HOTOL", "text": "HOTOL\n\nHOTOL, for Horizontal Take-Off and Landing, was a 1980s British design for a single-stage-to-orbit (SSTO) spaceplane that was to be powered by an airbreathing jet engine. Development was being conducted by a consortium led by Rolls-Royce and British Aerospace (BAe).\n\nDesigned as a single-stage-to-orbit (SSTO) reusable winged launch vehicle, HOTOL was to be fitted with a unique air-breathing engine, the RB545 or Swallow, that was under development by British engine manufacturer Rolls-Royce. The propellant for the engine technically consisted of a combination of liquid hydrogen/liquid oxygen; however, it was to employ a new means of dramatically reducing the amount of oxidizer needed to be carried on board by utilising atmospheric oxygen as the spacecraft climbed through the lower atmosphere. Since propellant typically represents the majority of the takeoff weight of a rocket, HOTOL was to be considerably smaller than normal pure-rocket designs, roughly the size of a medium-haul airliner such as the McDonnell Douglas DC-9/MD-80.\n\nWhile HOTOL's proof-of-concept design study was being carried out, attempts were made by both industry and the British government to establish international cooperation to develop, produce, and deploy the spacecraft. In spite of American interest in the programme, there was little appetite amongst the members of the European Space Agency (ESA), and the British government was not prepared to depart from ESA cooperation. Additionally, technical issues were encountered, and there were allegations that comparisons with alternative launch systems such as conventional rocket vehicle using similar construction techniques failed to show much advantage to HOTOL. In 1989, funding for the project ended. The termination of development work on HOTOL led to the formation of Reaction Engines Limited (REL) to develop and produce Skylon, a proposed spacecraft based on HOTOL technologies, including its engine.\n\nThe ideas behind HOTOL originated from work done by British Engineer Alan Bond in the field of precooled jet engines. Bond had specifically performed this research with the intention of producing a viable engine for powering a space launch system. In 1982, British Aerospace (BAe), which was Europe's principal satellite-builder, began studying a prospective new launch system with the aim of providing launch costs that were 20 per cent of the American Space Shuttle operated by NASA. BAe became aware of work by British engine manufacturer Rolls-Royce on a suitable engine, and soon conceived of an unmanned, fully reuseable single-stage-to-orbit (SSTO) winged spaceplane as a launch vehicle.\n\nThus, the project had soon became a joint venture between BAe and Rolls-Royce, led by John Scott-Scott and Dr Bob Parkinson. Early on, there was an ambition to 'Europeanise' the project and to involve other nations in its development and manufacture as it was recognised that an estimated £4 billion would be needed to fund full-scale development. In August 1984, BAe unveiled a public display of the HOTOL satellite launcher project and released details on its proposed operations.\n\nIn December 1984, a Department of Trade and Industry (DTI) memorandum noted that West Germany was interested in the program, while France had adopted a critical attitude towards HOTOL, which the ministry viewed as potentially due to it being seen as a competitor to French-led projects. According to the Minister of Trade and Industry Geoffrey Pattie, French diplomatic pressure to gather support for its own proposed Hermes space vehicle had inadvertently generated support and interest amongst European Space Agency (ESA) members in the HOTOL project. Despite this climate of tentative interest and possible European support, there was a general attitude of reluctance within the British government to take the lead on a new space launcher.\n\nIn March 1985, there were claims that Rolls-Royce was in the process of conducting licensing talks for HOTOL engine technology with American propulsion company Rocketdyne. In April 1985, Pattie wrote to Secretary of State for Defence Michael Heseltine to propose a two-year £3 million proof of concept study be performed under a public-private partnership arrangement, consisting of £1 million provided by the UK government and the remainder being financed by Rolls-Royce and BAe themselves. Pattie reasoned that the project would serve Britain's \"strategic capability, and that tests of key technologies could foster international collaboration. According to aerospace publication Flight International, the support of the Ministry of Defense (MoD) was critical as the design of HOTOL's engine had been classified.\n\nIn July 1985, Rolls-Royce's technical director Gordon Lewis stated that the firm sought the involvement of the Royal Aircraft Establishment's (RAE) propulsion group, and that Rolls-Royce was not prepared to invest its own funds into engine development for HOTOL. By the second half of 1985, work had commenced on the two-year concept-of-proof study. Early on, there was considerable pressure to demonstrate the project's feasibility and credibility in advance of final decisions being taken by the ESA on the Hermes and what would become the Ariane 5 launch system, thus the work concentrated on the validation of critical technologies involved.\n\nBy November 1985, DTI and RAE discussions noted that Rolls-Royce were seeking American data on ramjet technology to support their work on the engine, which it referred to by the name \"Swallow\". Reportedly, the United States Air Force were interested in the technology used in the Swallow engine for its own purposes. In November 1985, discussions between Prime Minister Margaret Thatcher, Minister without portfolio David Young and US President Ronald Reagan's scientific advisor George Keyworth noted American interest in collaboration on developing hypersonic vehicles such as HOTOL, and that a prototype could be flying as early as 1990.\n\nAccording to British government files, neither BAe nor the MoD were enthusiastic for the prospects of American involvement in the programme, expressing reluctance out of a belief that the outcome of such a move could result in the UK becoming a junior member in a project that it once led. There was also a belief that if Britain chose to pair up with the United States, it would find itself frozen out of work on future European launchers. However, Rolls-Royce viewed transatlantic cooperation as necessary. BAe's head of future business, Peter Conchie, stated that, if possible, HOTOL should become a part of the European space framework. In early 1986, the British government formally approved the two-year study.\n\nIn December 1984, project management consultant David Andrews issued an eight-page critique of the programme, noting that the design was optimised for the ascent while exposing itself to extended thermal loads during descent due to a low level of drag. He also claimed that the vehicle offered no capability that was not already available; BAe responded that the criticisms made had been answered. In April 1985, the Ministry of Defence's research and development department deputy controller James Barnes claimed that HOTOL lacked a justification, and that there was no defence requirement for such vehicles. He also noted that the \"engineering problems are considerable\" and that it was unlikely to enter service until the 2020s; Barnes also observed the HOTOL engine to be \"ingenious\".\n\nIn November 1985, the RAE issued an assessment of HOTOL's study proposal; the organisation believe that HOTOL would take up to 20 years to develop, rather than the 12-year timetable that had been envisioned by industry. The RAE also projected that the project would have an estimated total cost of £5 billion (as of its value in 1985), £750 million of which would be required in a six-year definition phase and an estimated £25 million in a pre-definition feasibility study.\n\nDuring development, it was found that the comparatively heavy rear-mounted engine moved the centre of mass of the vehicle rearwards. This meant that the vehicle had to be designed to push the centre of drag as far rearward as possible to ensure stability during the entire flight regime. Redesign of the vehicle to do this required a large mass of hydraulic systems, which cost a significant proportion of the payload, and made the economics unclear. In particular, some of the analysis seemed to indicate that similar technology applied to a pure rocket approach would give approximately the same performance at less cost.\n\nBy 1989, the outlook for HOTOL had become bleak; from the onset of the project, support between the British government and industrial partners had been uneven, while the United States had emerged as the only foreign nation that showed willingness to contribute to the programme, in part because of the secrecy surrounding the program. There was little prospect for European involvement, the ESA having elected to pursue development of what would become the Ariane 5, a conventional space launch system. Rolls-Royce withdrew from the project, judging the eventual market for the engine was unlikely to be large enough to repay the development costs. The British government declined to offer further funding for HOTOL. The project was almost at the end of its design phase while much of the plans remained in a speculative state; the craft was reportedly still dogged with aerodynamic problems and operational disadvantages at this point.\n\nA cheaper redesign, Interim HOTOL or HOTOL 2, which was to be launched from the back of a modified Antonov An-225 \"Mriya\" transport aircraft, was promoted by BAe in 1991; however, this proposal was rejected as well. The design for Interim HOTOL was to have dispensed with an air-breathing engine cycle and was designed to use a more conventional mix of LOX and liquid hydrogen as fuel instead.\n\nIn 1989, HOTOL co-creator Alan Bond and engineers John Scott-Scott and Richard Varvill formed Reaction Engines Limited (REL) which has since been working on a new air-breathing engine, SABRE, which used alternative designs to work around (and improve upon) the Rolls-Royce patents, and the Skylon vehicle intended to solve the problems of HOTOL. They first published these engine and spacecraft concepts in 1993, and has since been developing the core technologies, particularly the engine and its frost-controlled pre-cooler; initially supported by private funding, but latterly with support from the European Space Agency, the British National Space Centre, the United Kingdom Space Agency, BAe, and the Air Force Research Laboratory. REL plan to demonstrate a flight-ready pre-cooler operating under simulated flight conditions in 2018, and statically test a demonstration engine core in 2020.\n\nHOTOL was envisioned as an unmanned, fully reuseable single-stage-to-orbit (SSTO) winged spaceplane. The unmanned craft was intended to put a payload of around 7 to 8 tonnes in orbit, at 300 km altitude. It was intended to take off from a runway, mounted on the back of a large rocket-boosted trolley that would help get the craft up to \"working speed\". The engine was intended to switch from jet propulsion to pure rocket propulsion at 26–32 km high, by which time the craft would be travelling at Mach 5 to 7. After reaching low Earth orbit (LEO), HOTOL was intended to re-enter the atmosphere and glide down to land on a conventional runway (approx 1,500 metres minimum). Only a single payload would have been carried at a time as BAe had judged this to be more economic as it removed any need for satellite interfacing and allowed for missions to be tailored to individual requirements.\n\nDuring its high-altitude phase, its flight control system would have been linked to ground stations and to space-based global navigation system navigation, while radar would have been used during the take-off and landing phases. In additional to the placing of satellites into geosynchronous orbit or LOE, HOTOL was also projected as being able to also perform the retrieval of satellites and hardware from LOE. BAe promotional material depicts HOTOL docking with the International Space Station (ISS), a feat that the company claimed would have required manned operate as automated systems were not capable of performing such docking manoeuvres at that time. HOTOL was designed to conduct fully automated unmanned flights; however, it had been intended at a later stage to potentially re-introduce a pilot. Manned operations would have required the installation of a dedicated pressurised module within the payload bay.\n\nAs designed, HOTOL would have been 62 metres long, 12.8 metres high, a fuselage diameter of 5.7 meters and a wingspan of 19.7 metres. It featured a wing design that had been derived from that of Concorde; its large area resulted in relatively low wing loading, which would have resulted in lower reentry temperatures (never rising above 1,400 °C). Built out of carbon composite materials, there would have been no need for the use of insulating tiles akin to those that comprised the Space Shuttle thermal protection system. The internally stowed landing gear would have been too small to carry the weight of the fully fuelled rocket, so emergency landings would have required the fuel to be dumped.\n\nThe RB545, which was given the name \"Swallow\" by its manufacturer, British engine maker Rolls-Royce, was an air-breathing rocket engine. It would have functioned as an integrated dual-role powerplant, having been capable of air-breathing while operating within the atmosphere and operating in a similar manner to that of a rocket when having attained close to and within LEO. This engine would have also been capable of powering the spacecraft to hypersonic speeds. It was a crucial element of the programme, having been publicly attributed as \"the heart of Hotol's very low launch costs\".\n\nThe exact details of this engine were covered by the Official Secrets Act of the United Kingdom; consequently, there is relatively little public information about its development and on its operation. However, material was later declassified when government policy changed to prevent the keeping of secret patents without an attributed justification.\n\nWithin the atmosphere, air is taken in through two vertically mounted Intake ramps, then the flow would be split, passing the correct amount to the precoolers, and the excess to spill ducts. Hydrogen from the fuel tanks would be passed through two heat exchangers to precool the air prior to entering a high overall pressure-ratio turbojet-like engine cycle — the heated hydrogen driving a turbine to compress and feed the cooled air into the rocket engine, where it was combusted with some of the hydrogen used to cool the air. The majority of the remaining hot hydrogen was released from the back of the engine, with a small amount drawn off to reheat the air in the spill ducts in a ramjet arrangement to produce \"negative intake momentum drag.\" These ramjets were typically depicted as two glowing red circles below the rocket engines in pictures of HOTOL.\n\nTo prevent the precoolers from icing up, the first precooler cooled the air to around 10 degrees above freezing point, to liquefy the water vapour in the air. Then LOX would have been injected into the airflow to drop the temperature to -50C, (-58F) flash freezing the water into microscopic ice crystals, sufficiently cold that they wouldn't melt due to kinetic heating if they struck the second precooler elements. A water trap could have been added after the first precooler if operating conditions resulted in an excess of moisture.\n\nWhen it was no longer possible to use the atmosphere for combustion, the RB545 would switch to using on-board liquid oxygen (LOX) to burn with the hydrogen as a high-efficiency hydrogen/oxygen rocket.\n\n\n"}
{"id": "14306", "url": "https://en.wikipedia.org/wiki?curid=14306", "title": "Hammerhead shark", "text": "Hammerhead shark\n\nThe hammerhead sharks are a group of sharks in the family Sphyrnidae, so named for the unusual and distinctive structure of their heads, which are flattened and laterally extended into a \"hammer\" shape called a cephalofoil. Most hammerhead species are placed in the genus Sphyrna, while the winghead shark is placed in its own genus, Eusphyra. Many, but not necessarily mutually exclusive, functions have been proposed for the cephalofoil, including sensory reception, manoeuvering, and prey manipulation. Hammerheads are found worldwide in warmer waters along coastlines and continental shelves. Unlike most sharks, hammerheads usually swim in schools during the day, becoming solitary hunters at night. Some of these schools can be found near Malpelo Island in Colombia, the Galapagos Islands in Ecuador, Cocos Island off Costa Rica, and near Molokai in Hawaii. Large schools are also seen in the waters off southern and eastern Africa.\n\nThe known species range from in length and weigh from . They are usually light gray and have a greenish tint. Their bellies are white, which allows them to blend into the ocean when viewed from the bottom and sneak up on their prey. Their heads have lateral projections which give them a hammer-like shape.\n\nHammerheads have disproportionately small mouths. They are also known to form schools during the day, sometimes in groups over 100. In the evening, like other sharks, they become solitary hunters. \"National Geographic\" explains that hammerheads can be found in warm tropical waters, but during the summer, they participate in a mass migration to search for cooler waters.\n\nSince sharks do not have mineralized bones and rarely fossilize, their teeth alone are commonly found as fossils. The hammerheads seem closely related to the carcharhinid sharks that evolved during the mid-Tertiary period. According to DNA studies, the ancestor of the hammerheads probably lived in the Miocene epoch about 20 million years ago.\n\nUsing mitochondrial DNA, a phylogenetic tree of the hammerhead sharks showed the winghead shark as its most basal member. As the winghead shark has proportionately the largest \"hammer\" of the hammerhead sharks, this suggests that the first ancestral hammerhead sharks also had large hammers.\nFossils show that hammerheads might have evolved earlier during the Paleocene.\n\nA theory has been advanced that the hammer-like shape of the head may have evolved (at least in part) to enhance the animal's vision. The positioning of the eyes, mounted on the sides of the shark's distinctive hammer head, allows 360° of vision in the vertical plane, meaning the animals can see above and below them at all times. The shape of the head was previously thought to help the shark find food, aiding in close-quarters maneuverability, and allowing sharp turning movement without losing stability. However, the unusual structure of its vertebrae has been found to be instrumental in making the turns correctly, more often than the shape of its head, though it would also shift and provide lift. From what is known about the winghead shark, the shape of the hammerhead apparently has to do with an evolved sensory function. Like all sharks, hammerheads have electroreceptory sensory pores called ampullae of Lorenzini. The pores on the shark's head lead to sensory tubes, which detect electricity given off by other living creatures. By distributing the receptors over a wider area, like a larger radio antenna, hammerheads can sweep for prey more effectively.\n\nReproduction occurs only once a year for hammerhead sharks, and usually occurs with the male shark biting the female shark violently until she agrees to mate with him. The hammerhead sharks exhibit a viviparous mode of reproduction with females giving birth to live young. Like other sharks, fertilization is internal, with the male transferring sperm to the female through one of two intromittent organs called claspers. The developing embryos are at first sustained by a yolk sac. When the supply of yolk is exhausted, the depleted yolk sac transforms into a structure analogous to a mammalian placenta (called a \"yolk sac placenta\" or \"pseudoplacenta\"), through which the mother delivers sustenance until birth. Once the baby sharks are born, they are not taken care of by the parents in any way. Usually, a litter consists of 12 to 15 pups, except for the great hammerhead, which gives birth to litters of 20 to 40 pups. These baby sharks huddle together and swim toward warmer water until they are old enough and large enough to survive on their own.\n\nIn 2007, the bonnethead shark was found to be capable of asexual reproduction via automictic parthenogenesis, in which a female's ovum fuses with a polar body to form a zygote without the need for a male. This was the first shark known to do this.\n\nHammerhead sharks are known to eat a large range of prey such as fish (including other sharks), squid, octopus, and crustaceans. Stingrays are a particular favorite. These sharks are often found swimming along the bottom of the ocean, stalking their prey. Their unique heads are used as a weapon when hunting down prey. The hammerhead shark uses its head to pin down stingrays and eats the ray when the ray is weak and in shock. The great hammerhead, tending to be larger and more aggressive than most hammerheads, occasionally engages in cannibalism, eating other hammerhead sharks, including its own young. In addition to the typical animal prey, bonnetheads have been found to feed on seagrass, which sometimes makes up as much as half their stomach contents. They may swallow it unintentionally, but they are able to partially digest it. This is the only known case of a potentially omnivorous species of shark.\n\nAccording to the International Shark Attack File, humans have been subject to 17 documented, unprovoked attacks by hammerhead sharks within the genus \"Sphyrna\" since 1580 AD. No human fatalities have been recorded.\n\nThe great and the scalloped hammerheads are listed on the World Conservation Union's (IUCN) 2008 Red List as endangered, whereas the smalleye hammerhead is listed as vulnerable. The status given to these sharks is as a result of overfishing and demand for their fins, an expensive delicacy. Among others, scientists expressed their concern about the plight of the scalloped hammerhead at the American Association for the Advancement of Science annual meeting in Boston. The young swim mostly in shallow waters along shores all over the world to avoid predators.\n\nShark fins are prized as a delicacy in certain countries in Asia (such as China), and overfishing is putting many hammerhead sharks at risk of extinction. Fishermen who harvest the animals typically cut off the fins and toss the remainder of the fish, which is often still alive, back into the sea. This practice, known as finning, is lethal to the shark.\n\nIn native Hawaiian culture, sharks are considered to be gods of the sea, protectors of humans, and cleaners of excessive ocean life. Some of these sharks are believed to be family members who died and have been reincarnated into shark form. However, some sharks are considered man-eaters, also known as \"niuhi\". These sharks include great white sharks, tiger sharks, and bull sharks. The hammerhead shark, also known as \"mano kihikihi\", is not considered a man-eater or \"niuhi\"; it is considered to be one of the most respected sharks of the ocean, an \"aumakua\". Many Hawaiian families believe that they have an \"aumakua\" watching over them and protecting them from the \"niuhi\". The hammerhead shark is thought to be the birth animal of some children. Hawaiian children who are born with the hammerhead shark as an animal sign are believed to be warriors and are meant to sail the oceans. Hammerhead sharks rarely pass through the waters of Maui, but many Maui natives believe that their swimming by is a sign that the gods are watching over the families, and the oceans are clean and balanced.\nThe relatively small bonnethead is regular at public aquariums as it has proven easier to keep in captivity than the larger hammerhead species, and it has been bred at a handful of facilities. Nevertheless, at up to in length and with highly specialized requirements, very few private aquarists have the experience and resources necessary to maintain a bonnethead in captivity. The larger hammerhead species can reach more than twice that size and are considered difficult, even compared to most other similar-sized sharks (such as \"Carcharhinus\" species, lemon shark and sand tiger shark) regularly kept by public aquariums. They are particularly vulnerable during transport between facilities, may rub on surfaces in tanks, and may collide with rocks, causing injuries to their heads, so they require very large, specially adapted tanks. As a consequence, relatively few public aquariums have kept them for long periods. The scalloped hammerhead is the most frequently maintained large species, and it has been kept long term at public aquariums in most continents, but primarily in North America, Europe, and Asia. In 2014, less than 15 public aquariums in the world kept scalloped hammerheads. Great hammerheads have been kept at a few facilities in North America, including Atlantis Paradise Island Resort (Bahamas), Adventure Aquarium (New Jersey), Georgia Aquarium (Atlanta), Mote Marine Laboratory (Florida), and the Shark Reef at Mandalay Bay (Las Vegas). Smooth hammerheads have also been kept in the past.\n\nIn March 2013, three endangered, commercially valuable sharks, the hammerheads, the oceanic whitetip, and porbeagle, were added to Appendix II of CITES, bringing shark fishing and commerce of these species under licensing and regulation.\n\n\n"}
{"id": "14307", "url": "https://en.wikipedia.org/wiki?curid=14307", "title": "Hall effect", "text": "Hall effect\n\nThe Hall effect is the production of a voltage difference (the Hall voltage) across an electrical conductor, transverse to an electric current in the conductor and to an applied magnetic field perpendicular to the current. It was discovered by Edwin Hall in 1879. For clarity, the original effect is sometimes called the ordinary Hall effect to distinguish it from other \"Hall effects\" which have different physical mechanisms.\n\nThe Hall coefficient is defined as the ratio of the induced electric field to the product of the current density and the applied magnetic field. It is a characteristic of the material from which the conductor is made, since its value depends on the type, number, and properties of the charge carriers that constitute the current.\n\nThe Hall effect was discovered in 1879 by Edwin Hall while he was working on his doctoral degree at Johns Hopkins University in Baltimore, Maryland. Eighteen years before the electron was discovered, his measurements of the tiny effect produced in the apparatus he used were an experimental tour de force, published under the name \"On a New Action of the Magnet on Electric Currents\".\n\nThe Hall effect is due to the nature of the current in a conductor. Current consists of the movement of many small charge carriers, typically electrons, holes, ions (see Electromigration) or all three. When a magnetic field is present, these charges experience a force, called the Lorentz force. When such a magnetic field is absent, the charges follow approximately straight, 'line of sight' paths between collisions with impurities, phonons, etc. However, when a magnetic field with a perpendicular component is applied, their paths between collisions are curved, thus moving charges accumulate on one face of the material. This leaves equal and opposite charges exposed on the other face, where there is a scarcity of mobile charges. The result is an asymmetric distribution of charge density across the Hall element, arising from a force that is perpendicular to both the 'line of sight' path and the applied magnetic field. The separation of charge establishes an electric field that opposes the migration of further charge, so a steady electric potential is established for as long as the charge is flowing.\n\nIn classical electromagnetism electrons move in the opposite direction of the current (by convention \"current\" describes a theoretical \"hole flow\"). In some semiconductors it \"appears\" \"holes\" are actually flowing because the direction of the voltage is opposite to the derivation below.\n\nFor a simple metal where there is only one type of charge carrier (electrons), the Hall voltage can be derived by using the Lorentz force and seeing that, in the steady-state condition, charges are not moving in the -axis direction. Thus, the magnetic force on each electron in the -axis direction is cancelled by a -axis electrical force due to the buildup of charges. The term is the drift velocity of the current which is assumed at this point to be holes by convention. The term is negative in the -axis direction by the right hand rule.\n\nIn steady state, , so , where is assigned in the direction of the -axis, (and not with the arrow of the induced electric field as in the image (pointing in the direction), which tells you where the field caused by the electrons is pointing).\n\nIn wires, electrons instead of holes are flowing, so and . Also . Substituting these changes gives\n\nThe conventional \"hole\" current is in the negative direction of the electron current and the negative of the electrical charge which gives where is charge carrier density, is the cross-sectional area, and is the charge of each electron. Solving for formula_3 and plugging into the above gives the Hall voltage:\n\nIf the charge build up had been positive (as it appears in some semiconductors), then the assigned in the image would have been negative (positive charge would have built up on the left side).\n\nThe Hall coefficient is defined as\n\nwhere is the current density of the carrier electrons, and is the induced electric field. In SI units, this becomes\n\n(The units of are usually expressed as m/C, or Ω·cm/G, or other variants.) As a result, the Hall effect is very useful as a means to measure either the carrier density or the magnetic field.\n\nOne very important feature of the Hall effect is that it differentiates between positive charges moving in one direction and negative charges moving in the opposite. The Hall effect offered the first real proof that electric currents in metals are carried by moving electrons, not by protons. The Hall effect also showed that in some substances (especially p-type semiconductors), it is more appropriate to think of the current as positive \"holes\" moving rather than negative electrons. A common source of confusion with the Hall effect is that holes moving to the left are really electrons moving to the right, so one expects the same sign of the Hall coefficient for both electrons and holes. This confusion, however, can only be resolved by modern quantum mechanical theory of transport in solids.\n\nThe sample inhomogeneity might result in spurious sign of the Hall effect, even in ideal van der Pauw configuration of electrodes. For example, positive Hall effect was observed in evidently n-type semiconductors. Another source of artifact, in uniform materials, occurs when the sample's aspect ratio is not long enough: the full Hall voltage only develops far away from the current-introducing contacts, since at the contacts the transverse voltage is shorted out to zero.\n\nWhen a current-carrying semiconductor is kept in a magnetic field, the charge carriers of the semiconductor experience a force in a direction perpendicular to both the magnetic field and the current. At equilibrium, a voltage appears at the semiconductor edges.\n\nThe simple formula for the Hall coefficient given above is usually a good explanation when conduction is dominated by a single charge carrier. However, in semiconductors the theory is more complex, because in these materials conduction can involve significant, simultaneous contributions from both electrons and holes, which may be present in different concentrations and have different mobilities. For moderate magnetic fields the Hall coefficient is\nor equivalently\nwith\nHere is the electron concentration, the hole concentration, the electron mobility, the hole mobility and the elementary charge.\n\nFor large applied fields the simpler expression analogous to that for a single carrier type holds.\n\nAlthough it is well known that magnetic fields play an important role in star formation, research models indicate that Hall diffusion critically influences the dynamics of gravitational collapse that forms protostars.\n\nFor a two-dimensional electron system which can be produced in a MOSFET, in the presence of large magnetic field strength and low temperature, one can observe the quantum Hall effect, in which the Hall conductance undergoes quantum Hall transitions to take on the quantized values.\n\nThe spin Hall effect consists in the spin accumulation on the lateral boundaries of a current-carrying sample. No magnetic field is needed. It was predicted by M. I. Dyakonov and V. I. Perel in 1971 and observed experimentally more than 30 years later, both in semiconductors and in metals, at cryogenic as well as at room temperatures.\n\nFor mercury telluride two dimensional quantum wells with strong spin-orbit coupling, in zero magnetic field, at low temperature, the quantum spin Hall effect has been recently observed.\n\nIn ferromagnetic materials (and paramagnetic materials in a magnetic field), the Hall resistivity includes an additional contribution, known as the anomalous Hall effect (or the extraordinary Hall effect), which depends directly on the magnetization of the material, and is often much larger than the ordinary Hall effect. (Note that this effect is \"not\" due to the contribution of the magnetization to the total magnetic field.) For example, in nickel, the anomalous Hall coefficient is about 100 times larger than the ordinary Hall coefficient near the Curie temperature, but the two are similar at very low temperatures. Although a well-recognized phenomenon, there is still debate about its origins in the various materials. The anomalous Hall effect can be either an \"extrinsic\" (disorder-related) effect due to spin-dependent scattering of the charge carriers, or an \"intrinsic\" effect which can be described in terms of the Berry phase effect in the crystal momentum space (-space).\n\nThe Hall effect in an ionized gas (plasma) is significantly different from the Hall effect in solids (where the Hall parameter is always much less than unity). In a plasma, the Hall parameter can take any value. The Hall parameter, , in a plasma is the ratio between the electron gyrofrequency, , and the electron-heavy particle collision frequency, :\n\nwhere\n\nThe Hall parameter value increases with the magnetic field strength.\n\nPhysically, the trajectories of electrons are curved by the Lorentz force. Nevertheless, when the Hall parameter is low, their motion between two encounters with heavy particles (neutral or ion) is almost linear. But if the Hall parameter is high, the electron movements are highly curved. The current density vector, , is no longer collinear with the electric field vector, . The two vectors and make the Hall angle, , which also gives the Hall parameter:\n\nHall probes are often used as magnetometers, i.e. to measure magnetic fields, or inspect materials (such as tubing or pipelines) using the principles of magnetic flux leakage.\n\nHall effect devices produce a very low signal level and thus require amplification. While suitable for laboratory instruments, the vacuum tube amplifiers available in the first half of the 20th century were too expensive, power consuming, and unreliable for everyday applications. It was only with the development of the low cost integrated circuit that the Hall effect sensor became suitable for mass application. Many devices now sold as Hall effect sensors in fact contain both the sensor as described above plus a high gain integrated circuit (IC) amplifier in a single package. Recent advances have further added into one package an analog-to-digital converter and I²C (Inter-integrated circuit communication protocol) IC for direct connection to a microcontroller's I/O port.\n\nHall effect devices (when appropriately packaged) are immune to dust, dirt, mud, and water. These characteristics make Hall effect devices better for position sensing than alternative means such as optical and electromechanical sensing.\n\nWhen electrons flow through a conductor, a magnetic field is produced. Thus, it is possible to create a non-contacting current sensor. The device has three terminals.\nA sensor voltage is applied across two terminals and the third provides a voltage proportional to the current being sensed. This has several advantages; no additional resistance (a \"shunt\", required for the most common current sensing method) need to be inserted in the primary circuit. Also, the voltage present on the line to be sensed is not transmitted to the sensor, which enhances the safety of measuring equipment.\n\nMagnetic flux from the surroundings (such as other wires) may diminish or enhance the field the Hall probe intends to detect, rendering the results inaccurate. Also, as Hall voltage is often on the order of millivolts, the output from this type of sensor cannot be used to directly drive actuators but instead must be amplified by a transistor-based circuit.\n\nWays to measure mechanical positions within an electromagnetic system, such as a brushless direct current motor, include (1) the Hall effect, (2) optical position encoder (e.g., absolute and incremental encoders) and (3) induced voltage by moving the amount of metal core inserted into a transformer. When Hall is compared to photo-sensitive methods, it is harder to get absolute position with Hall. Hall detection is also sensitive to stray magnetic fields.\n\nHall effect sensors are readily available from a number of different manufacturers, and may be used in various sensors such as rotating speed sensors (bicycle wheels, gear-teeth, automotive speedometers, electronic ignition systems), fluid flow sensors, current sensors, and pressure sensors. Common applications are often found where a robust and contactless switch or potentiometer is required. These include: electric airsoft guns, triggers of electropneumatic paintball guns, go-cart speed controls, smart phones, and some global positioning systems.\n\nHall sensors can detect stray magnetic fields easily, including that of Earth, so they work well as electronic compasses: but this also means that such stray fields can hinder accurate measurements of small magnetic fields. To solve this problem, Hall sensors are often integrated with magnetic shielding of some kind. For example, a Hall sensor integrated into a ferrite ring (as shown) can reduce the detection of stray fields by a factor of 100 or better (as the external magnetic fields cancel across the ring, giving no residual magnetic flux). This configuration also provides an improvement in signal-to-noise ratio and drift effects of over 20 times that of a bare Hall device.\n\nThe range of a given feedthrough sensor may be extended upward and downward by appropriate wiring. To extend the range to lower currents, multiple turns of the current-carrying wire may be made through the opening, each turn adding to the sensor output the same quantity; when the sensor is installed onto a printed circuit board, the turns can be carried out by a staple on the board. To extend the range to higher currents, a current divider may be used. The divider splits the current across two wires of differing widths and the thinner wire, carrying a smaller proportion of the total current, passes through the sensor.\n\nA variation on the ring sensor uses a split sensor which is clamped onto the line enabling the device to be used in temporary test equipment. If used in a permanent installation, a split sensor allows the electric current to be tested without dismantling the existing circuit.\n\nThe output is proportional to both the applied magnetic field and the applied sensor voltage. If the magnetic field is applied by a solenoid, the sensor output is proportional to the product of the current through the solenoid and the sensor voltage. As most applications requiring computation are now performed by small digital computers, the remaining useful application is in power sensing, which combines current sensing with voltage sensing in a single Hall effect device.\n\nBy sensing the current provided to a load and using the device's applied voltage as a sensor voltage it is possible to determine the power dissipated by a device.\n\nHall effect devices used in motion sensing and motion limit switches can offer enhanced reliability in extreme environments. As there are no moving parts involved within the sensor or magnet, typical life expectancy is improved compared to traditional electromechanical switches. Additionally, the sensor and magnet may be encapsulated in an appropriate protective material. This application is used in brushless DC motors.\n\nHall effect sensors, affixed to mechanical gauges that have magnetized indicator needles, can translate the physical position or orientation of the mechanical indicator needle into an electrical signal that can be used by electronic indicators, controls or communications devices.\n\nCommonly used in distributors for ignition timing (and in some types of crank and camshaft position sensors for injection pulse timing, speed sensing, etc.) the Hall effect sensor is used as a direct replacement for the mechanical breaker points used in earlier automotive applications. Its use as an ignition timing device in various distributor types is as follows. A stationary permanent magnet and semiconductor Hall effect chip are mounted next to each other separated by an air gap, forming the Hall effect sensor. A metal rotor consisting of windows and tabs is mounted to a shaft and arranged so that during shaft rotation, the windows and tabs pass through the air gap between the permanent magnet and semiconductor Hall chip. This effectively shields and exposes the Hall chip to the permanent magnet's field respective to whether a tab or window is passing through the Hall sensor. For ignition timing purposes, the metal rotor will have a number of equal-sized tabs and windows matching the number of engine cylinders. This produces a uniform square wave output since the on/off (shielding and exposure) time is equal. This signal is used by the engine computer or ECU to control ignition timing. Many automotive Hall effect sensors have a built-in internal NPN transistor with an open collector and grounded emitter, meaning that rather than a voltage being produced at the Hall sensor signal output wire, the transistor is turned on providing a circuit to ground through the signal output wire.\n\nThe sensing of wheel rotation is especially useful in anti-lock braking systems. The principles of such systems have been extended and refined to offer more than anti-skid functions, now providing extended vehicle handling enhancements.\n\nSome types of brushless DC electric motors use Hall effect sensors to detect the position of the rotor and feed that information to the motor controller. This allows for more precise motor control.\n\nApplications for Hall effect sensing have also expanded to industrial applications, which now use Hall effect joysticks to control hydraulic valves, replacing the traditional mechanical levers with contactless sensing. Such applications include mining trucks, backhoe loaders, cranes, diggers, scissor lifts, etc.\n\nA Hall-effect thruster (HET) is a relatively low power device that is used to propel some spacecraft, after it gets into orbit or farther out into space. In the HET, atoms are ionized and accelerated by an electric field. A radial magnetic field established by magnets on the thruster is used to trap electrons which then orbit and create an electric field due to the Hall effect. A large potential is established between the end of the thruster where neutral propellant is fed, and the part where electrons are produced; so, electrons trapped in the magnetic field cannot drop to the lower potential. They are thus extremely energetic, which means that they can ionize neutral atoms. Neutral propellant is pumped into the chamber and is ionized by the trapped electrons. Positive ions and electrons are then ejected from the thruster as a quasineutral plasma, creating thrust.\n\nThe Corbino effect is a phenomenon involving the Hall effect, but a disc-shaped metal sample is used in place of a rectangular one. Because of its shape the Corbino disc allows the observation of Hall effect–based magnetoresistance without the associated Hall voltage.\n\nA radial current through a circular disc, subjected to a magnetic field perpendicular to the plane of the disc, produces a \"circular\" current through the disc.\n\nThe absence of the free transverse boundaries renders the interpretation of the Corbino effect simpler than that of the Hall effect.\n\n\n"}
{"id": "14308", "url": "https://en.wikipedia.org/wiki?curid=14308", "title": "Hoover Dam", "text": "Hoover Dam\n\nHoover Dam is a concrete arch-gravity dam in the Black Canyon of the Colorado River, on the border between the U.S. states of Nevada and Arizona. It was constructed between 1931 and 1936 during the Great Depression and was dedicated on September 30, 1935, by President Franklin D. Roosevelt. Its construction was the result of a massive effort involving thousands of workers, and cost over one hundred lives. Originally known as Boulder Dam from 1933, it was officially renamed Hoover Dam, for President Herbert Hoover, by a joint resolution of Congress in 1947.\n\nSince about 1900, the Black Canyon and nearby Boulder Canyon had been investigated for their potential to support a dam that would control floods, provide irrigation water and produce hydroelectric power. In 1928, Congress authorized the project. The winning bid to build the dam was submitted by a consortium called Six Companies, Inc., which began construction on the dam in early 1931. Such a large concrete structure had never been built before, and some of the techniques were unproven. The torrid summer weather and lack of facilities near the site also presented difficulties. Nevertheless, Six Companies turned the dam over to the federal government on March 1, 1936, more than two years ahead of schedule.\n\nHoover Dam impounds Lake Mead, the largest reservoir in the United States by volume (when it is full). The dam is located near Boulder City, Nevada, a municipality originally constructed for workers on the construction project, about southeast of Las Vegas, Nevada. The dam's generators provide power for public and private utilities in Nevada, Arizona, and California. Hoover Dam is a major tourist attraction; nearly a million people tour the dam each year. The heavily traveled U.S. Route 93 (US 93) ran along the dam's crest until October 2010, when the Hoover Dam Bypass opened.\n\nAs the United States developed the Southwest, the Colorado River was seen as a potential source of irrigation water. An initial attempt at diverting the river for irrigation purposes occurred in the late 1890s, when land speculator William Beatty built the Alamo Canal just north of the Mexican border; the canal dipped into Mexico before running to a desolate area Beatty named the Imperial Valley. Though water from the Imperial Canal allowed for the widespread settlement of the valley, the canal proved expensive to maintain. After a catastrophic breach that caused the Colorado River to fill the Salton Sea, the Southern Pacific Railroad spent $3 million in 1906–07 to stabilize the waterway, an amount it hoped in vain would be reimbursed by the Federal Government. Even after the waterway was stabilized, it proved unsatisfactory because of constant disputes with landowners on the Mexican side of the border.\n\nAs the technology of electric power transmission improved, the Lower Colorado was considered for its hydroelectric-power potential. In 1902, the Edison Electric Company of Los Angeles surveyed the river in the hope of building a rock dam which could generate . However, at the time, the limit of transmission of electric power was , and there were few customers (mostly mines) within that limit. Edison allowed land options it held on the river to lapse—including an option for what became the site of Hoover Dam.\n\nIn the following years, the Bureau of Reclamation (BOR), known as the Reclamation Service at the time, also considered the Lower Colorado as the site for a dam. Service chief Arthur Powell Davis proposed using dynamite to collapse the walls of Boulder Canyon, north of the eventual dam site, into the river. The river would carry off the smaller pieces of debris, and a dam would be built incorporating the remaining rubble. In 1922, after considering it for several years, the Reclamation Service finally rejected the proposal, citing doubts about the unproven technique and questions as to whether it would in fact save money.\nIn 1922, the Reclamation Service presented a report calling for the development of a dam on the Colorado River for flood control and electric power generation. The report was principally authored by Davis, and was called the Fall-Davis report after Interior Secretary Albert Fall. The Fall-Davis report cited use of the Colorado River as a federal concern because the river's basin covered several states, and the river eventually entered Mexico. Though the Fall-Davis report called for a dam \"at or near Boulder Canyon\", the Reclamation Service (which was renamed the Bureau of Reclamation the following year) found that canyon unsuitable. One potential site at Boulder Canyon was bisected by a geologic fault; two others were so narrow there was no space for a construction camp at the bottom of the canyon or for a spillway. The Service investigated Black Canyon and found it ideal; a railway could be laid from the railhead in Las Vegas to the top of the dam site. Despite the site change, the dam project was referred to as the \"Boulder Canyon Project\".\n\nWith little guidance on water allocation from the Supreme Court, proponents of the dam feared endless litigation. A Colorado attorney proposed that the seven states which fell within the river's basin (California, Nevada, Arizona, Utah, New Mexico, Colorado and Wyoming) form an interstate compact, with the approval of Congress. Such compacts were authorized by Article I of the United States Constitution but had never been concluded among more than two states. In 1922, representatives of seven states met with then-Secretary of Commerce Herbert Hoover. Initial talks produced no result, but when the Supreme Court handed down the \"Wyoming v. Colorado\" decision undermining the claims of the upstream states, they became anxious to reach an agreement. The resulting Colorado River Compact was signed on November 24, 1922.\n\nLegislation to authorize the dam was introduced repeatedly by two California Republicans, Representative Phil Swing and Senator Hiram Johnson, but representatives from other parts of the country considered the project as hugely expensive and one that would mostly benefit California. The 1927 Mississippi flood made Midwestern and Southern congressmen and senators more sympathetic toward the dam project. On March 12, 1928, the failure of the St. Francis Dam, constructed by the city of Los Angeles, caused a disastrous flood that killed up to 600 people. As that dam was a curved-gravity type, similar in design to the arch-gravity as was proposed for the Black Canyon dam, opponents claimed that the Black Canyon dam's safety could not be guaranteed. Congress authorized a board of engineers to review plans for the proposed dam. The Colorado River Board found the project feasible, but warned that should the dam fail, every downstream Colorado River community would be destroyed, and that the river might change course and empty into the Salton Sea. The Board cautioned: \"To avoid such possibilities, the proposed dam should be constructed on conservative if not ultra-conservative lines.\"\n\nOn December 21, 1928, President Coolidge signed the bill authorizing the dam. The Boulder Canyon Project Act appropriated $165 million for the Hoover Dam along with the downstream Imperial Dam and All-American Canal, a replacement for Beatty's canal entirely on the U.S. side of the border. It also permitted the compact to go into effect when at least six of the seven states approved it. This occurred on March 6, 1929, with Utah's ratification; Arizona did not approve it until 1944.\n\nEven before Congress approved the Boulder Canyon Project, the Bureau of Reclamation was considering what kind of dam should be used. Officials eventually decided on a massive concrete arch-gravity dam, the design of which was overseen by the Bureau's chief design engineer John L. Savage. The monolithic dam would be thick at the bottom and thin near the top, and would present a convex face towards the water above the dam. The curving arch of the dam would transmit the water's force into the abutments, in this case the rock walls of the canyon. The wedge-shaped dam would be thick at the bottom, narrowing to at the top, leaving room for a highway connecting Nevada and Arizona.\n\nOn January 10, 1931, the Bureau made the bid documents available to interested parties, at five dollars a copy. The government was to provide the materials; but the contractor was to prepare the site and build the dam. The dam was described in minute detail, covering 100 pages of text and 76 drawings. A $2 million bid bond was to accompany each bid; the winner would have to post a $5 million performance bond. The contractor had seven years to build the dam, or penalties would ensue.\n\nThe Wattis Brothers, heads of the Utah Construction Company, were interested in bidding on the project, but lacked the money for the performance bond. They lacked sufficient resources even in combination with their longtime partners, Morrison-Knudsen, which employed the nation's leading dam builder, Frank Crowe. They formed a joint venture to bid for the project with Pacific Bridge Company of Portland, Oregon; Henry J. Kaiser & W. A. Bechtel Company of San Francisco; MacDonald & Kahn Ltd. of Los Angeles; and the J.F. Shea Company of Portland, Oregon. The joint venture was called Six Companies, Inc. as Bechtel and Kaiser were considered one company for purposes of Six in the name. The name was descriptive and was an inside joke among the San Franciscans in the bid, where \"Six Companies\" was also a Chinese benevolent association in the city. There were three valid bids, and Six Companies' bid of $48,890,955 was the lowest, within $24,000 of the confidential government estimate of what the dam would cost to build, and five million dollars less than the next-lowest bid.\n\nThe city of Las Vegas had lobbied hard to be the headquarters for the dam construction, closing its many speakeasies when the decision maker, Secretary of the Interior Ray Wilbur, came to town. Instead, Wilbur announced in early 1930 that a model city was to be built in the desert near the dam site. This town became known as Boulder City, Nevada. Construction of a rail line joining Las Vegas and the dam site began in September 1930.\n\nSoon after the dam was authorized, increasing numbers of unemployed people converged on southern Nevada. Las Vegas, then a small city of some 5,000, saw between 10,000 and 20,000 unemployed descend on it. A government camp was established for surveyors and other personnel near the dam site; this soon became surrounded by a squatters' camp. Known as McKeeversville, the camp was home to men hoping for work on the project, together with their families. Another camp, on the flats along the Colorado River, was officially called Williamsville, but was known to its inhabitants as \"Ragtown\". When construction began, Six Companies hired large numbers of workers, with more than 3,000 on the payroll by 1932 and with employment peaking at 5,251 in July 1934. \"Mongolian\" (Chinese) labor was prevented by the construction contract, while the number of blacks employed by Six Companies never exceeded thirty, mostly lowest-pay-scale laborers in a segregated crew, who were issued separate water buckets.\n\nAs part of the contract, Six Companies, Inc. was to build Boulder City to house the workers. The original timetable called for Boulder City to be built before the dam project began, but President Hoover ordered work on the dam to begin in March 1931 rather than in October. The company built bunkhouses, attached to the canyon wall, to house 480 single men at what became known as River Camp. Workers with families were left to provide their own accommodations until Boulder City could be completed, and many lived in Ragtown. The site of Hoover Dam endures extremely hot weather, and the summer of 1931 was especially torrid, with the daytime high averaging . Sixteen workers and other riverbank residents died of heat prostration between June 25 and July 26, 1931.\n\nThe Industrial Workers of the World (IWW or \"Wobblies\"), though much-reduced from their heyday as militant labor organizers in the early years of the century, hoped to unionize the Six Companies workers by capitalizing on their discontent. They sent eleven organizers, several of whom were arrested by Las Vegas police. On August 7, 1931, the company cut wages for all tunnel workers. Although the workers sent away the organizers, not wanting to be associated with the \"Wobblies\", they formed a committee to represent them with the company. The committee drew up a list of demands that evening and presented them to Crowe the following morning. He was noncommittal. The workers hoped that Crowe, the general superintendent of the job, would be sympathetic; instead he gave a scathing interview to a newspaper, describing the workers as \"malcontents\".\n\nOn the morning of the 9th, Crowe met with the committee and told them that management refused their demands, was stopping all work, and was laying off the entire work force, except for a few office workers and carpenters. The workers were given until 5 p.m. to vacate the premises. Concerned that a violent confrontation was imminent, most workers took their paychecks and left for Las Vegas to await developments. Two days later, the remainder were talked into leaving by law enforcement. On August 13, the company began hiring workers again, and two days later, the strike was called off. While the workers received none of their demands, the company guaranteed there would be no further reductions in wages. Living conditions began to improve as the first residents moved into Boulder City in late 1931.\n\nA second labor action took place in July 1935, as construction on the dam wound down. When a Six Companies manager altered working times to force workers to take lunch on their own time, workers responded with a strike. Emboldened by Crowe's reversal of the lunch decree, workers raised their demands to include a $1-per-day raise. The company agreed to ask the Federal government to supplement the pay, but no money was forthcoming from Washington. The strike ended.\n\nBefore the dam could be built, the Colorado River needed to be diverted away from the construction site. To accomplish this, four diversion tunnels were driven through the canyon walls, two on the Nevada side and two on the Arizona side. These tunnels were in diameter. Their combined length was nearly 16,000 ft, or more than . The contract required these tunnels to be completed by October 1, 1933, with a $3,000-per-day fine to be assessed for any delay. To meet the deadline, Six Companies had to complete work by early 1933, since only in late fall and winter was the water level in the river low enough to safely divert.\n\nTunneling began at the lower portals of the Nevada tunnels in May 1931. Shortly afterward, work began on two similar tunnels in the Arizona canyon wall. In March 1932, work began on lining the tunnels with concrete. First the base, or invert, was poured. Gantry cranes, running on rails through the entire length of each tunnel were used to place the concrete. The sidewalls were poured next. Movable sections of steel forms were used for the sidewalls. Finally, using pneumatic guns, the overheads were filled in. The concrete lining is thick, reducing the finished tunnel diameter to . The river was diverted into the two Arizona tunnels on November 13, 1932; the Nevada tunnels were kept in reserve for high water. This was done by exploding a temporary cofferdam protecting the Arizona tunnels while at the same time dumping rubble into the river until its natural course was blocked.\n\nFollowing the completion of the dam, the entrances to the two outer diversion tunnels were sealed at the opening and halfway through the tunnels with large concrete plugs. The downstream halves of the tunnels following the inner plugs are now the main bodies of the spillway tunnels. The inner diversion tunnels were plugged at approximately one-third of their length, beyond which they now carry steel pipes connecting the intake towers to the power plant and outlet works. The inner tunnels' outlets are equipped with gates that can be closed to drain the tunnels for maintenance.\n\nTo protect the construction site from the Colorado River and to facilitate the river's diversion, two cofferdams were constructed. Work on the upper cofferdam began in September 1932, even though the river had not yet been diverted. The cofferdams were designed to protect against the possibility of the river's flooding a site at which two thousand men might be at work, and their specifications were covered in the bid documents in nearly as much detail as the dam itself. The upper cofferdam was high, and thick at its base, thicker than the dam itself. It contained of material.\n\nWhen the cofferdams were in place and the construction site was drained of water, excavation for the dam foundation began. For the dam to rest on solid rock, it was necessary to remove accumulated erosion soils and other loose materials in the riverbed until sound bedrock was reached. Work on the foundation excavations was completed in June 1933. During this excavation, approximately of material was removed. Since the dam was an arch-gravity type, the side-walls of the canyon would bear the force of the impounded lake. Therefore, the side-walls were excavated too, to reach virgin rock, as weathered rock might provide pathways for water seepage. Shovels for the excavation came from the Marion Power Shovel Company.\n\nThe men who removed this rock were called \"high scalers\". While suspended from the top of the canyon with ropes, the high-scalers climbed down the canyon walls and removed the loose rock with jackhammers and dynamite. Falling objects were the most common cause of death on the dam site; the high scalers' work thus helped ensure worker safety. One high scaler was able to save a life in a more direct manner: when a government inspector lost his grip on a safety line and began tumbling down a slope towards almost certain death, a high scaler was able to intercept him and pull him into the air. The construction site had, even then, become a magnet for tourists; the high scalers were prime attractions and showed off for the watchers. The high scalers received considerable media attention, with one worker dubbed the \"Human Pendulum\" for swinging co-workers (and, at other times, cases of dynamite) across the canyon. To protect themselves against falling objects, some high scalers took cloth hats and dipped them in tar, allowing them to harden. When workers wearing such headgear were struck hard enough to inflict broken jaws, they sustained no skull damage, Six Companies ordered thousands of what initially were called \"hard boiled hats\" (later \"hard hats\") and strongly encouraged their use.\n\nThe cleared, underlying rock foundation of the dam site was reinforced with grout, called a grout curtain. Holes were driven into the walls and base of the canyon, as deep as into the rock, and any cavities encountered were to be filled with grout. This was done to stabilize the rock, to prevent water from seeping past the dam through the canyon rock, and to limit \"uplift\"—upward pressure from water seeping under the dam. The workers were under severe time constraints due to the beginning of the concrete pour, and when they encountered hot springs or cavities too large to readily fill, they moved on without resolving the problem. A total of 58 of the 393 holes were incompletely filled. After the dam was completed and the lake began to fill, large numbers of significant leaks into the dam caused the Bureau of Reclamation to look into the situation. It found that the work had been incompletely done, and was based on less than a full understanding of the canyon's geology. New holes were drilled from inspection galleries inside the dam into the surrounding bedrock. It took nine years (1938–47) under relative secrecy to complete the supplemental grout curtain.\n\nThe first concrete was poured into the dam on June 6, 1933, 18 months ahead of schedule. Since concrete heats and contracts as it cures, the potential for uneven cooling and contraction of the concrete posed a serious problem. Bureau of Reclamation engineers calculated that if the dam were to be built in a single continuous pour, the concrete would take 125 years to cool, and the resulting stresses would cause the dam to crack and crumble. Instead, the ground where the dam would rise was marked with rectangles, and concrete blocks in columns were poured, some as large as and high. Each five-foot form contained a series of steel pipes; cool riverwater would be poured through the pipes, followed by ice-cold water from a refrigeration plant. When an individual block had cured and had stopped contracting, the pipes were filled with grout. Grout was also used to fill the hairline spaces between columns, which were grooved to increase the strength of the joins.\n\nThe concrete was delivered in huge steel buckets and almost 7 feet in diameter; Crowe was awarded two patents for their design. These buckets, which weighed when full, were filled at two massive concrete plants on the Nevada side, and were delivered to the site in special railcars. The buckets were then suspended from aerial cableways which were used to deliver the bucket to a specific column. As the required grade of aggregate in the concrete differed depending on placement in the dam (from pea-sized gravel to 9-inch or 23 cm stones), it was vital that the bucket be maneuvered to the proper column. When the bottom of the bucket opened up, disgorging of concrete, a team of men worked it throughout the form. Although there are myths that men were caught in the pour and are entombed in the dam to this day, each bucket deepened the concrete in a form by only an inch, and Six Companies engineers would not have permitted a flaw caused by the presence of a human body.\n\nA total of of concrete was used in the dam before concrete pouring ceased on May 29, 1935. In addition, were used in the power plant and other works. More than of cooling pipes were placed within the concrete. Overall, there is enough concrete in the dam to pave a two-lane highway from San Francisco to New York. Concrete cores were removed from the dam for testing in 1995; they showed that \"Hoover Dam's concrete has continued to slowly gain strength\" and the dam is composed of a \"durable concrete having a compressive strength exceeding the range typically found in normal mass concrete\". Hoover Dam concrete is not subject to alkali–silica reaction (ASR), as the Hoover Dam builders happened to use nonreactive aggregate, unlike that at downstream Parker Dam, where ASR has caused measurable deterioration.\n\nWith most work finished on the dam itself (the powerhouse remained uncompleted), a formal dedication ceremony was arranged for September 30, 1935, to coincide with a western tour being made by President Franklin D. Roosevelt. The morning of the dedication, it was moved forward three hours from 2 p.m. Pacific time to 11 a.m.; this was done because Secretary of the Interior Harold L. Ickes had reserved a radio slot for the President for 2 p.m. but officials did not realize until the day of the ceremony that the slot was for 2 p.m. Eastern Time. Despite the change in the ceremony time, and temperatures of , 10,000 people were present for the President's speech, in which he avoided mentioning the name of former President Hoover, who was not invited to the ceremony. To mark the occasion, a three-cent stamp was issued by the United States Post Office Department—bearing the name \"Boulder Dam\", the official name of the dam between 1933 and 1947. After the ceremony, Roosevelt made the first visit by any American president to Las Vegas.\n\nMost work had been completed by the dedication, and Six Companies negotiated with the government through late 1935 and early 1936 to settle all claims and arrange for the formal transfer of the dam to the Federal Government. The parties came to an agreement and on March 1, 1936, Secretary Ickes formally accepted the dam on behalf of the government. Six Companies was not required to complete work on one item, a concrete plug for one of the bypass tunnels, as the tunnel had to be used to take in irrigation water until the powerhouse went into operation.\n\nThere were 112 deaths reported as associated with the construction of the dam. The first was J. G. Tierney, a surveyor who drowned on December 20, 1922, while looking for an ideal spot for the dam. The last death on the project's official fatality list occurred on December 20, 1935, when an \"electrician's helper\", Patrick Tierney, the son of J. G. Tierney, fell from an intake tower. Included in the fatality list are three workers, one in 1932 and two in 1933, who committed suicide onsite. Ninety-six of the deaths occurred during construction at the site. Of the 112 fatalities, 91 were Six Companies employees, three were BOR employees, and one was a visitor to the site, with the remainder employees of various contractors not part of Six Companies.\n\nNot included in the official number of fatalities were deaths that were recorded as pneumonia. Workers alleged that this diagnosis was a cover for death from carbon monoxide poisoning (brought on by the use of gasoline-fueled vehicles in the diversion tunnels), and a classification used by Six Companies to avoid paying compensation claims. The site's diversion tunnels frequently reached , enveloped in thick plumes of vehicle exhaust gases. A total of 42 workers were recorded as having died from pneumonia and were not included in the above total; none were listed as having died from carbon monoxide poisoning. No deaths of non-workers from pneumonia were recorded in Boulder City during the construction period.\n\nThe initial plans for the facade of the dam, the power plant, the outlet tunnels and ornaments clashed with the modern look of an arch dam. The Bureau of Reclamation, more concerned with the dam's functionality, adorned it with a Gothic-inspired balustrade and eagle statues. This initial design was criticized by many as being too plain and unremarkable for a project of such immense scale, so Los Angeles-based architect Gordon B. Kaufmann, then the supervising architect to the Bureau of Reclamation, was brought in to redesign the exteriors. Kaufmann greatly streamlined the design and applied an elegant Art Deco style to the entire project. He designed sculptured turrets rising seamlessly from the dam face and clock faces on the intake towers set for the time in Nevada and Arizona — both states are in different time zones, but since Arizona does not observe Daylight Saving Time, the clocks display the same time for more than half the year.\n\nAt Kaufmann's request, Denver artist Allen Tupper True was hired to handle the design and decoration of the walls and floors of the new dam. True's design scheme incorporated motifs of the Navajo and Pueblo tribes of the region. Although some initially were opposed to these designs, True was given the go-ahead and was officially appointed consulting artist. With the assistance of the National Laboratory of Anthropology, True researched authentic decorative motifs from Indian sand paintings, textiles, baskets and ceramics. The images and colors are based on Native American visions of rain, lightning, water, clouds, and local animals — lizards, serpents, birds — and on the Southwestern landscape of stepped mesas. In these works, which are integrated into the walkways and interior halls of the dam, True also reflected on the machinery of the operation, making the symbolic patterns appear both ancient and modern.\n\nWith the agreement of Kaufmann and the engineers, True also devised for the pipes and machinery an innovative color-coding which was implemented throughout all BOR projects. True's consulting artist job lasted through 1942; it was extended so he could complete design work for the Parker, Shasta and Grand Coulee dams and power plants. True's work on the Hoover Dam was humorously referred to in a poem published in \"The New Yorker\", part of which read, \"lose the spark, and justify the dream; but also worthy of remark will be the color scheme\".\n\nComplementing Kaufmann and True's work, the Norwegian-born, naturalized American sculptor Oskar J.W. Hansen designed many of the sculptures on and around the dam. His works include the monument of dedication plaza, a plaque to memorialize the workers killed and the bas-reliefs on the elevator towers. In his words, Hansen wanted his work to express \"the immutable calm of intellectual resolution, and the enormous power of trained physical strength, equally enthroned in placid triumph of scientific accomplishment\", because \"[t]he building of Hoover Dam belongs to the sagas of the daring.\" Hansen's dedication plaza, on the Nevada abutment, contains a sculpture of two winged figures flanking a flagpole.\nSurrounding the base of the monument is a terrazzo floor embedded with a \"star map\". The map depicts the Northern Hemisphere sky at the moment of President Roosevelt's dedication of the dam. This is intended to help future astronomers, if necessary, calculate the exact date of dedication. The bronze figures, dubbed \"Winged Figures of the Republic\", were each formed in a continuous pour. To put such large bronzes into place without marring the highly polished bronze surface, they were placed on ice and guided into position as the ice melted. Hansen's bas-relief on the Nevada elevator tower depicts the benefits of the dam: flood control, navigation, irrigation, water storage, and power. The bas-relief on the Arizona elevator depicts, in his words, \"the visages of those Indian tribes who have inhabited mountains and plains from ages distant.\"\n\nExcavation for the powerhouse was carried out simultaneously with the excavation for the dam foundation and abutments. The excavation of this U-shaped structure located at the downstream toe of the dam was completed in late 1933 with the first concrete placed in November 1933. Filling of Lake Mead began February 1, 1935, even before the last of the concrete was poured that May. The powerhouse was one of the projects uncompleted at the time of the formal dedication on September 30, 1935; a crew of 500 men remained to finish it and other structures. To make the powerhouse roof bombproof, it was constructed of layers of concrete, rock, and steel with a total thickness of about , topped with layers of sand and tar.\n\nIn the latter half of 1936, water levels in Lake Mead were high enough to permit power generation, and the first three Allis Chalmers built Francis turbine-generators, all on the Nevada side, began operating. In March 1937, one more Nevada generator went online and the first Arizona generator by August. By September 1939, four more generators were operating, and the dam's power plant became the largest hydroelectricity facility in the world. The final generator was not placed in service until 1961, bringing the maximum generating capacity to 1,345 megawatts at the time. Original plans called for 16 large generators, eight on each side of the river, but two smaller generators were installed instead of one large one on the Arizona side for a total of 17. The smaller generators were used to serve smaller communities at a time when the output of each generator was dedicated to a single municipality, before the dam's total power output was placed on the grid and made arbitrarily distributable.\n\nBefore water from Lake Mead reaches the turbines, it enters the intake towers and then four gradually narrowing penstocks which funnel the water down towards the powerhouse. The intakes provide a maximum hydraulic head (water pressure) of as the water reaches a speed of about . The entire flow of the Colorado River passes through the turbines. The spillways and outlet works (jet-flow gates) are rarely used. The jet-flow gates, located in concrete structures above the river and also at the outlets of the inner diversion tunnels at river level, may be used to divert water around the dam in emergency or flood conditions, but have never done so, and in practice are used only to drain water from the penstocks for maintenance. Following an uprating project from 1986 to 1993, the total gross power rating for the plant, including two 2.4 megawatt Pelton turbine-generators that power Hoover Dam's own operations is a maximum capacity of 2080 megawatts. The annual generation of Hoover Dam varies. The maximum net generation was 10.348 TWh in 1984, and the minimum since 1940 was 2.648 TWh in 1956. The average power generated was 4.2 TWh/year for 1947–2008. In 2015, the dam generated 3.6 TWh.\n\nThe amount of electricity generated by Hoover Dam has been decreasing along with the falling water level in Lake Mead due to the prolonged drought in the 2010s and high demand for the Colorado River's water. Lake Mead fell to a new record low elevation of on July 1, 2016 before beginning to rebound slowly. Under its original design, the dam will no longer be able to generate power once the water level falls below , which could occur as early as 2017. To lower the minimum power pool elevation from , five wide-head turbines, designed to work efficiently with less flow, were installed. Due to the low water levels, by 2014 it was providing power only during periods of peak demand.\n\nControl of water was the primary concern in the building of the dam. Power generation has allowed the dam project to be self-sustaining: proceeds from the sale of power repaid the 50-year construction loan, and those revenues also finance the multimillion-dollar yearly maintenance budget. Power is generated in step with and only with the release of water in response to downstream water demands.\n\nLake Mead and downstream releases from the dam also provide water for both municipal and irrigation uses. Water released from the Hoover Dam eventually reaches several canals. The Colorado River Aqueduct and Central Arizona Project branch off Lake Havasu while the All-American Canal is supplied by the Imperial Dam. In total, water from the Lake Mead serves 18 million people in Arizona, Nevada and California and supplies the irrigation of over of land.\n\nIn 2018, the Los Angeles Department of Water and Power (LADWP) proposed a $3 billion pumped hydro storage project - a \"battery\" of sorts - that would use wind and solar power to recirculate water back up to Lake Mead from a pumping station 20 miles downriver.\n\nElectricity from the dam's powerhouse was originally sold pursuant to a fifty-year contract, authorized by Congress in 1934, which ran from 1937 to 1987. In 1984, Congress passed a new statute which set power allocations to southern California, Arizona, and Nevada from the dam from 1987 to 2017. The powerhouse was run under the original authorization by the Los Angeles Department of Water and Power and Southern California Edison; in 1987, the Bureau of Reclamation assumed control. In 2011, Congress enacted legislation extending the current contracts until 2067, after setting aside 5% of Hoover Dam's power for sale to Native American tribes, electric cooperatives, and other entities. The new arrangement began on October 1, 2017.\n\nThe Bureau of Reclamation reports that the energy generated under the contracts ending in 2017 was allocated as follows:\n\nThe dam is protected against over-topping by two spillways. The spillway entrances are located behind each dam abutment, running roughly parallel to the canyon walls. The spillway entrance arrangement forms a classic side-flow weir with each spillway containing four and steel-drum gates. Each gate weighs and can be operated manually or automatically. Gates are raised and lowered depending on water levels in the reservoir and flood conditions. The gates could not entirely prevent water from entering the spillways but could maintain an extra of lake level.\nWater flowing over the spillways falls dramatically into , spillway tunnels before connecting to the outer diversion tunnels, and reentering the main river channel below the dam. This complex spillway entrance arrangement combined with the approximate elevation drop from the top of the reservoir to the river below was a difficult engineering problem and posed numerous design challenges. Each spillway's capacity of was empirically verified in post-construction tests in 1941.\n\nThe large spillway tunnels have only been used twice, for testing in 1941 and because of flooding in 1983. Both times, when inspecting the tunnels after the spillways were used, engineers found major damage to the concrete linings and underlying rock. The 1941 damage was attributed to a slight misalignment of the tunnel invert (or base), which caused cavitation, a phenomenon in fast-flowing liquids in which vapor bubbles collapse with explosive force. In response to this finding, the tunnels were patched with special heavy-duty concrete and the surface of the concrete was polished mirror-smooth. The spillways were modified in 1947 by adding flip buckets, which both slow the water and decrease the spillway's effective capacity, in an attempt to eliminate conditions thought to have contributed to the 1941 damage. The 1983 damage, also due to cavitation, led to the installation of aerators in the spillways. Tests at Grand Coulee Dam showed that the technique worked, in principle.\n\nThere are two lanes for automobile traffic across the top of the dam, which formerly served as the Colorado River crossing for U.S. Route 93. In the wake of the September 11, 2001 terrorist attacks, authorities expressed security concerns and the Hoover Dam Bypass project was expedited. Pending the completion of the bypass, restricted traffic was permitted over Hoover Dam. Some types of vehicles were inspected prior to crossing the dam while semi-trailer trucks, buses carrying luggage, and enclosed-box trucks over long were not allowed on the dam at all, and were diverted to U.S. Route 95 or Nevada State Routes 163/68. The four-lane Hoover Dam Bypass opened on October 19, 2010. It includes a composite steel and concrete arch bridge, the Mike O'Callaghan–Pat Tillman Memorial Bridge, downstream from the dam.\nWith the opening of the bypass, through traffic is no longer allowed across Hoover Dam; dam visitors are allowed to use the existing roadway to approach from the Nevada side and cross to parking lots and other facilities on the Arizona side.\n\nHoover Dam opened for tours in 1937 after its completion, but following Japan's attack on Pearl Harbor on December 7, 1941, it was closed to the public when the United States entered World War II, during which only authorized traffic, in convoys, was permitted. After the war, it reopened September 2, 1945, and by 1953, annual attendance had risen to 448,081. The dam closed on November 25, 1963, and March 31, 1969, days of mourning in remembrance of Presidents Kennedy and Eisenhower. In 1995, a new visitors' center was built, and the following year, visits exceeded one million for the first time. The dam closed again to the public on September 11, 2001; modified tours were resumed in December and a new \"Discovery Tour\" was added the following year. Today, nearly a million people per year take the tours of the dam offered by the Bureau of Reclamation. Increased security concerns by the government have led to most of the interior structure being inaccessible to tourists. As a result, few of True's decorations can now be seen by visitors.\n\nThe changes in water flow and use caused by Hoover Dam's construction and operation have had a large impact on the Colorado River Delta. The construction of the dam has been implicated in causing the decline of this estuarine ecosystem. For six years after the construction of the dam, while Lake Mead filled, virtually no water reached the mouth of the river. The delta's estuary, which once had a freshwater-saltwater mixing zone stretching south of the river's mouth, was turned into an inverse estuary where the level of salinity was higher close to the river's mouth.\n\nThe Colorado River had experienced natural flooding before the construction of the Hoover Dam. The dam eliminated the natural flooding, threatening many species adapted to the flooding, including both plants and animals. The construction of the dam devastated the populations of native fish in the river downstream from the dam. Four species of fish native to the Colorado River, the Bonytail chub, Colorado pikeminnow, Humpback chub, and Razorback sucker, are listed as endangered.\n\nDuring the years of lobbying leading up to the passage of legislation authorizing the dam in 1928, the press generally referred to the dam as \"Boulder Dam\" or as \"Boulder Canyon Dam\", even though the proposed site had shifted to Black Canyon. The Boulder Canyon Project Act of 1928 (BCPA) never mentioned a proposed name or title for the dam. The BCPA merely allows the government to \"construct, operate, and maintain a dam and incidental works in the main stream of the Colorado River at Black Canyon or Boulder Canyon\".\n\nWhen Secretary Wilbur spoke at the ceremony starting the building of the railway between Las Vegas and the dam site on September 17, 1930, he named the dam \"Hoover Dam\", citing a tradition of naming dams after Presidents, though none had been so honored during their terms of office. Wilbur justified his choice on the ground that Hoover was \"the great engineer whose vision and persistence ... has done so much to make <nowiki>[the dam]</nowiki> possible\". One writer complained in response that \"the Great Engineer had quickly drained, ditched, and dammed the country.\"\n\nAfter Hoover's election defeat in 1932 and the accession of the Roosevelt administration, Secretary Ickes ordered on May 13, 1933, that the dam be referred to as \"Boulder Dam\". Ickes stated that Wilbur had been imprudent in naming the dam after a sitting president, that Congress had never ratified his choice, and that it had long been referred to as Boulder Dam. Unknown to the general public, Attorney General Homer Cummings informed Ickes that Congress had indeed used the name \"Hoover Dam\" in five different bills appropriating money for construction of the dam. The official status this conferred to the name \"Hoover Dam\" had been noted on the floor of the House of Representatives by Congressman Edward T. Taylor of Colorado on December 12, 1930, but was likewise ignored by Ickes.\n\nWhen Ickes spoke at the dedication ceremony on September 30, 1935, he was determined, as he recorded in his diary, \"to try to nail down for good and all the name Boulder Dam.\" At one point in the speech, he spoke the words \"Boulder Dam\" five times within thirty seconds. Further, he suggested that if the dam were to be named after any one person, it should be for California Senator Hiram Johnson, a lead sponsor of the authorizing legislation. Roosevelt also referred to the dam as Boulder Dam, and the Republican-leaning \"Los Angeles Times\", which at the time of Ickes' name change had run an editorial cartoon showing Ickes ineffectively chipping away at an enormous sign \"HOOVER DAM,\" reran it showing Roosevelt reinforcing Ickes, but having no greater success.\n\nIn the following years, the name \"Boulder Dam\" failed to fully take hold, with many Americans using both names interchangeably and mapmakers divided as to which name should be printed. Memories of the Great Depression faded, and Hoover to some extent rehabilitated himself through good works during and after World War II. In 1947, a bill passed both Houses of Congress unanimously restoring the name \"Hoover Dam.\" Ickes, who was by then a private citizen, opposed the change, stating, \"I didn't know Hoover was that small a man to take credit for something he had nothing to do with.\"\n\nHoover Dam was recognized as a National Civil Engineering Landmark in 1984. It was listed on the National Register of Historic Places in 1981, and was designated a National Historic Landmark in 1985, cited for its engineering innovations.\n\n\n\nOther sources\n\n\n"}
{"id": "14309", "url": "https://en.wikipedia.org/wiki?curid=14309", "title": "Holger Pedersen", "text": "Holger Pedersen\n\nHolger Pedersen may refer to:\n"}
{"id": "14311", "url": "https://en.wikipedia.org/wiki?curid=14311", "title": "Adventures of Huckleberry Finn", "text": "Adventures of Huckleberry Finn\n\nAdventures of Huckleberry Finn (or, in more recent editions, The Adventures of Huckleberry Finn) is a novel by Mark Twain, first published in the United Kingdom in December 1884 and in the United States in February 1885. Commonly named among the Great American Novels, the work is among the first in major American literature to be written throughout in vernacular English, characterized by local color regionalism. It is told in the first person by Huckleberry \"Huck\" Finn, the narrator of two other Twain novels (\"Tom Sawyer Abroad\" and \"Tom Sawyer, Detective\") and a friend of Tom Sawyer. It is a direct sequel to \"The Adventures of Tom Sawyer\".\n\nThe book is noted for its colorful description of people and places along the Mississippi River. Set in a Southern antebellum society that had ceased to exist about 20 years before the work was published, \"Adventures of Huckleberry Finn\" is an often scathing satire on entrenched attitudes, particularly racism.\n\nPerennially popular with readers, \"Adventures of Huckleberry Finn\" has also been the continued object of study by literary critics since its publication. The book was widely criticized upon release because of its extensive use of coarse language. Throughout the 20th century, and despite arguments that the protagonist and the tenor of the book are anti-racist, criticism of the book continued due to both its perceived use of racial stereotypes and its frequent use of the racial slur \"nigger\".\n\nIn order of appearance:\n\nThe story begins in fictional St. Petersburg, Missouri (based on the actual town of Hannibal, Missouri), on the shore of the Mississippi River \"forty to fifty years ago\" (the novel having been published in 1884). Huckleberry \"Huck\" Finn (the protagonist and first-person narrator) and his friend, Thomas \"Tom\" Sawyer, have each come into a considerable sum of money as a result of their earlier adventures (detailed in \"The Adventures of Tom Sawyer\"). Huck explains how he is placed under the guardianship of the Widow Douglas, who, together with her stringent sister, Miss Watson, are attempting to \"sivilize\" him and teach him religion. Finding civilized life confining, his spirits are raised somewhat when Tom Sawyer helps him to escape one night past Miss Watson's slave Jim, to meet up with Tom's gang of self-proclaimed \"robbers.\" Just as the gang's activities begin to bore Huck, he is suddenly interrupted by the reappearance of his shiftless father, \"Pap\", an abusive alcoholic. Knowing that Pap would only spend the money on alcohol, Huck is successful in preventing Pap from acquiring his fortune; however, Pap kidnaps Huck and leaves town with him.\n\nPap forcibly moves Huck to his isolated cabin in the woods along the Illinois shoreline. Because of Pap's drunken violence and imprisonment of Huck inside the cabin, Huck, during one of his father's absences, elaborately fakes his own death, escapes from the cabin, and sets off downriver. He settles comfortably, on Jackson's Island. Here, Huck reunites with Jim, Miss Watson's slave. Jim has also run away after he overheard Miss Watson planning to sell him \"down the river\" to presumably more brutal owners. Jim plans to make his way to the town of Cairo in Illinois, a free state, so that he can later buy the rest of his enslaved family's freedom. At first, Huck is conflicted about the sin and crime of supporting a runaway slave, but as the two talk in depth and bond over their mutually held superstitions, Huck emotionally connects with Jim, who increasingly becomes Huck's close friend and guardian. After heavy flooding on the river, the two find a raft (which they keep) as well as an entire house floating on the river (Chapter 9: \"The House of Death Floats By\"). Entering the house to seek loot, Jim finds the naked body of a dead man lying on the floor, shot in the back. He prevents Huck from viewing the corpse.\n\nTo find out the latest news in town, Huck dresses as a girl and enters the house of Judith Loftus, a woman new to the area. Huck learns from her about the news of his own supposed murder; Pap was initially blamed, but since Jim ran away he is also a suspect and a reward for Jim's capture has initiated a manhunt. Mrs. Loftus becomes increasingly suspicious that Huck is a boy, finally proving it by a series of tests. Huck develops another story on the fly and explains his disguise as the only way to escape from an abusive foster family. Once he is exposed, she nevertheless allows him to leave her home without commotion, not realizing that he is the allegedly murdered boy they have just been discussing. Huck returns to Jim to tell him the news and that a search party is coming to Jackson's Island that very night. The two hastily load up the raft and depart.\n\nAfter a while, Huck and Jim come across a grounded steamship. Searching it, they stumble upon two thieves discussing murdering a third, but they flee before being noticed. They are later separated in a fog, making Jim intensely anxious, and when they reunite, Huck tricks Jim into thinking he dreamed the entire incident. Jim is not deceived for long, and is deeply hurt that his friend should have teased him so mercilessly. Huck becomes remorseful and apologizes to Jim, though his conscience troubles him about humbling himself to a black man.\n\nTraveling onward, Huck and Jim's raft is struck by a passing steamship, again separating the two. Huck is given shelter on the Kentucky side of the river by the Grangerfords, an \"aristocratic\" family. He befriends Buck Grangerford, a boy about his age, and learns that the Grangerfords are engaged in a 30-year blood feud against another family, the Shepherdsons. The Grangerfords and Shepherdsons go to the same church, which ironically preaches brotherly love. The vendetta finally comes to a head when Buck's older sister elopes with a member of the Shepherdson clan. In the resulting conflict, all the Grangerford males from this branch of the family are shot and killed, including Buck, whose horrific murder Huck witnesses. He is immensely relieved to be reunited with Jim, who has since recovered and repaired the raft.\n\nNear the Arkansas-Missouri-Tennessee border, Jim and Huck take two on-the-run grifters aboard the raft. The younger man, who is about thirty, introduces himself as the long-lost son of an English duke (the Duke of Bridgewater). The older one, about seventy, then trumps this outrageous claim by alleging that he himself is the Lost Dauphin, the son of Louis XVI and rightful King of France. The \"duke\" and \"king\" soon become permanent passengers on Jim and Huck's raft, committing a series of confidence schemes upon unsuspecting locals all along their journey. To divert suspicions from the public away from Jim, they pose him as recaptured slave runaway, but later paint him up entirely blue and call him the \"Sick Arab\" so that he can move about the raft without bindings.\n\nOn one occasion, the swindlers advertise a three-night engagement of a play called \"The Royal Nonesuch\". The play turns out to be only a couple of minutes' worth of an absurd, bawdy sham. On the afternoon of the first performance, a drunk called Boggs is shot dead by a gentleman named Colonel Sherburn; a lynch mob forms to retaliate against Sherburn; and Sherburn, surrounded at his home, disperses the mob by making a defiant speech describing how true lynching should be done. By the third night of \"The Royal Nonesuch\", the townspeople prepare for their revenge on the duke and king for their money-making scam, but the two cleverly skip town together with Huck and Jim just before the performance begins.\n\nIn the next town, the two swindlers then impersonate brothers of Peter Wilks, a recently deceased man of property. To match accounts of Wilks's brothers, the king attempts an English accent and the duke pretends to be a deaf-mute while starting to collect Wilks's inheritance. Huck decides that Wilks's three orphaned nieces, who treat Huck with kindness, do not deserve to be cheated thus and so he tries to retrieve for them the stolen inheritance. In a desperate moment, Huck is forced to hide the money in Wilks's coffin, which is abruptly buried the next morning. The arrival of two new men who seem to be the real brothers throws everything into confusion, so that the townspeople decide to dig up the coffin in order to determine which are the true brothers, but, with everyone else distracted, Huck leaves for the raft, hoping to never see the duke and king again. Suddenly, though, the two villains return, much to Huck's despair. When Huck is finally able to get away a second time, he finds to his horror that the swindlers have sold Jim away to a family that intends to return him to his proper owner for the reward. Defying his conscience and accepting the negative religious consequences he expects for his actions—\"All right, then, I'll go to hell!\"—Huck resolves to free Jim once and for all.\n\nHuck learns that Jim is being held at the plantation of Silas and Sally Phelps. The family's nephew, Tom, is expected for a visit at the same time as Huck's arrival, so Huck is mistaken for Tom and welcomed into their home. He plays along, hoping to find Jim's location and free him; in a surprising plot twist, it is revealed that the expected nephew is, in fact, Tom Sawyer. When Huck intercepts the real Tom Sawyer on the road and tells him everything, Tom decides to join Huck's scheme, pretending to be his own younger half-brother, Sid, while Huck continues pretending to be Tom. In the meantime, Jim has told the family about the two grifters and the new plan for \"The Royal Nonesuch\", and so the townspeople capture the duke and king, who are then tarred and feathered and ridden out of town on a rail.\n\nRather than simply sneaking Jim out of the shed where he is being held, Tom develops an elaborate plan to free him, involving secret messages, a hidden tunnel, snakes in a shed, a rope ladder sent in Jim's food, and other elements from adventure books he has read, including an anonymous note to the Phelps warning them of the whole scheme. During the actual escape and resulting pursuit, Tom is shot in the leg, while Jim remains by his side, risking recapture rather than completing his escape alone. Although a local doctor admires Jim's decency, he has Jim arrested in his sleep and returned to the Phelps. After this, events quickly resolve themselves. Tom's Aunt Polly arrives and reveals Huck and Tom's true identities to the Phelps family. Jim is revealed to be a free man: Miss Watson died two months earlier and freed Jim in her will, but Tom (who already knew this) chose not to reveal this information to Huck so that he could come up with an artful rescue plan for Jim. Jim tells Huck that Huck's father (Pap Finn) has been dead for some time (he was the dead man they found earlier in the floating house), and so Huck may now return safely to St. Petersburg. Huck declares that he is quite glad to be done writing his story, and despite Sally's plans to adopt and civilize him, he intends to flee west to Indian Territory.\n\n\"Adventures of Huckleberry Finn\" explores themes of race and identity. A complexity exists concerning Jim's character. While some scholars point out that Jim is good-hearted, moral, and he is not unintelligent (in contrast to several of the more negatively depicted white characters), others have criticized the novel as racist, citing the use of the word \"nigger\" and emphasizing the stereotypically \"comic\" treatment of Jim's lack of education, superstition and ignorance.\n\nThroughout the story, Huck is in moral conflict with the received values of the society in which he lives, and while he is unable to consciously refute those values even in his thoughts, he makes a moral choice based on his own valuation of Jim's friendship and Jim's human worth, a decision in direct opposition to the things he has been taught. Mark Twain, in his lecture notes, proposes that \"a sound heart is a surer guide than an ill-trained conscience\" and goes on to describe the novel as \"...a book of mine where a sound heart and a deformed conscience come into collision and conscience suffers defeat\".\n\nTo highlight the hypocrisy required to condone slavery within an ostensibly moral system, Twain has Huck's father enslave his son, isolate him, and beat him. When Huck escapes, he then immediately encounters Jim \"illegally\" doing the same thing. The treatments both of them receive are radically different, especially with an encounter with Mrs. Judith Loftus who takes pity on who she presumes to be a runaway apprentice, Huck, yet boasts about her husband sending the hounds after a runaway slave, Jim.\n\nSome scholars discuss Huck's own character, and the novel itself, in the context of its relation to African-American culture as a whole. John Alberti quotes Shelley Fisher Fishkin, who writes in her 1990s book \"Was Huck Black?: Mark Twain and African-American Voices\", \"by limiting their field of inquiry to the periphery,\" white scholars \"have missed the ways in which African-American voices shaped Twain's creative imagination at its core.\" It is suggested that the character of Huckleberry Finn illustrates the correlation, and even interrelatedness, between white and black culture in the United States.\n\nThe original illustrations were done by E.W. Kemble, at the time a young artist working for \"Life\" magazine. Kemble was hand-picked by Twain, who admired his work. Hearn suggests that Twain and Kemble had a similar skill, writing that:\nWhatever he may have lacked in technical grace ... Kemble shared with the greatest illustrators the ability to give even the minor individual in a text his own distinct visual personality; just as Twain so deftly defined a full-rounded character in a few phrases, so too did Kemble depict with a few strokes of his pen that same entire personage.\n\nAs Kemble could afford only one model, most of his illustrations produced for the book were done by guesswork. When the novel was published, the illustrations were praised even as the novel was harshly criticized. E.W. Kemble produced another set of illustrations for Harper's and the American Publishing Company in 1898 and 1899 after Twain lost the copyright.\n\nTwain initially conceived of the work as a sequel to \"The Adventures of Tom Sawyer\" that would follow Huckleberry Finn through adulthood. Beginning with a few pages he had removed from the earlier novel, Twain began work on a manuscript he originally titled \"Huckleberry Finn's Autobiography.\" Twain worked on the manuscript off and on for the next several years, ultimately abandoning his original plan of following Huck's development into adulthood. He appeared to have lost interest in the manuscript while it was in progress, and set it aside for several years. After making a trip down the Hudson River, Twain returned to his work on the novel. Upon completion, the novel's title closely paralleled its predecessor's: \"Adventures of Huckleberry Finn (Tom Sawyer's Comrade)\".\n\nMark Twain composed the story in pen on notepaper between 1876 and 1883. Paul Needham, who supervised the authentication of the manuscript for Sotheby's books and manuscripts department in New York in 1991, stated, \"What you see is [Clemens'] attempt to move away from pure literary writing to dialect writing\". For example, Twain revised the opening line of \"Huck Finn\" three times. He initially wrote, \"You will not know about me\", which he changed to, \"You do not know about me\", before settling on the final version, \"You don't know about me, without you have read a book by the name of 'The Adventures of Tom Sawyer'; but that ain't no matter.\" The revisions also show how Twain reworked his material to strengthen the characters of Huck and Jim, as well as his sensitivity to the then-current debate over literacy and voting.\n\nA later version was the first typewritten manuscript delivered to a printer.\n\nDemand for the book spread outside of the United States. \"Adventures of Huckleberry Finn\" was eventually published on December 10, 1884, in Canada and the United Kingdom, and on February 18, 1885, in the United States. The illustration on page 283 became a point of issue after an engraver, whose identity was never discovered, made a last-minute addition to the printing plate of Kemble's picture of old Silas Phelps, which drew attention to Phelps' groin. Thirty thousand copies of the book had been printed before the obscenity was discovered. A new plate was made to correct the illustration and repair the existing copies.\n\nIn 1885, the Buffalo Public Library's curator, James Fraser Gluck, approached Twain to donate the manuscript to the library. Twain did so. Later it was believed that half of the pages had been misplaced by the printer. In 1991, the missing first half turned up in a steamer trunk owned by descendants of Gluck's. The library successfully claimed possession and, in 1994, opened the Mark Twain Room to showcase the treasure.\n\nIn relation to the literary climate at the time of the book's publication in 1885, Henry Nash Smith describes the importance of Mark Twain's already established reputation as a \"professional humorist\", having already published over a dozen other works. Smith suggests that while the \"dismantling of the decadent Romanticism of the later nineteenth century was a necessary operation,\" \"Adventures of Huckleberry Finn\" illustrated \"previously inaccessible resources of imaginative power, but also made vernacular language, with its new sources of pleasure and new energy, available for American prose and poetry in the twentieth century.\"\n\nWhile it was clear that the publication of \"Adventures of Huckleberry Finn\" was controversial from the outset, Norman Mailer, writing in \"The New York Times\" in 1984, concluded that Twain's novel was not initially \"too unpleasantly regarded.\" In fact, Mailer writes: \"the critical climate could hardly anticipate T. S. Eliot and Ernest Hemingway's encomiums 50 years later,\" reviews that would remain longstanding in the American consciousness.\n\nAlberti suggests that the academic establishment responded to the book's challenges both dismissively and with confusion. During Twain's time, and today, defenders of \"Adventures of Huckleberry Finn\" \"lump all nonacademic critics of the book together as extremists and ‘censors' thus equating the complaints about the book's ‘coarseness' from the genteel bourgeois trustees of the Concord Public Library in the 1880s with more recent objections based on race and civil rights.\"\n\nUpon issue of the American edition in 1885 several libraries banned it from their shelves. The early criticism focused on what was perceived as the book's crudeness. One incident was recounted in the newspaper the \"Boston Transcript\":\n\nThe Concord (Mass.) Public Library committee has decided to exclude Mark Twain's latest book from the library. One member of the committee says that, while he does not wish to call it immoral, he thinks it contains but little humor, and that of a very coarse type. He regards it as the veriest trash. The library and the other members of the committee entertain similar views, characterizing it as rough, coarse, and inelegant, dealing with a series of experiences not elevating, the whole book being more suited to the slums than to intelligent, respectable people.\nWriter Louisa May Alcott criticized the book's publication as well, saying that if Twain \"[could not] think of something better to tell our pure-minded lads and lasses he had best stop writing for them\".\n\nTwain later remarked to his editor, \"Apparently, the Concord library has condemned Huck as 'trash and only suitable for the slums.' This will sell us another twenty-five thousand copies for sure!\"\n\nIn 1905, New York's Brooklyn Public Library also banned the book due to \"bad word choice\" and Huck's having \"not only itched but scratched\" within the novel, which was considered obscene. When asked by a Brooklyn librarian about the situation, Twain sardonically replied: I am greatly troubled by what you say. I wrote 'Tom Sawyer' & 'Huck Finn' for adults exclusively, & it always distressed me when I find that boys and girls have been allowed access to them. The mind that becomes soiled in youth can never again be washed clean. I know this by my own experience, & to this day I cherish an unappeased bitterness against the unfaithful guardians of my young life, who not only permitted but compelled me to read an unexpurgated Bible through before I was 15 years old. None can do that and ever draw a clean sweet breath again on this side of the grave.\n\nMany subsequent critics, Ernest Hemingway among them, have deprecated the final chapters, claiming the book \"devolves into little more than minstrel-show satire and broad comedy\" after Jim is detained. Although Hemingway declared, \"All modern American literature comes from\" \"Huck Finn\", and hailed it as \"the best book we've had\", he cautioned, \"If you must read it you must stop where the Nigger Jim is stolen from the boys . That is the real end. The rest is just cheating.\" Pulitzer Prize winner Ron Powers states in his Twain biography (\"Mark Twain: A Life\") that \"Huckleberry Finn endures as a consensus masterpiece despite these final chapters\", in which Tom Sawyer leads Huck through elaborate machinations to rescue Jim.\n\nIn his introduction to \"The Annotated Huckleberry Finn\", Michael Patrick Hearn writes that Twain \"could be uninhibitedly vulgar\", and quotes critic William Dean Howells, a Twain contemporary, who wrote that the author's \"humor was not for most women\". However, Hearn continues by explaining that \"the reticent Howells found nothing in the proofs of Huckleberry Finn so offensive that it needed to be struck out\".\n\nMuch of modern scholarship of \"Huckleberry Finn\" has focused on its treatment of race. Many Twain scholars have argued that the book, by humanizing Jim and exposing the fallacies of the racist assumptions of slavery, is an attack on racism. Others have argued that the book falls short on this score, especially in its depiction of Jim. According to Professor Stephen Railton of the University of Virginia, Twain was unable to fully rise above the stereotypes of black people that white readers of his era expected and enjoyed, and, therefore, resorted to minstrel show-style comedy to provide humor at Jim's expense, and ended up confirming rather than challenging late-19th century racist stereotypes.\n\nIn one instance, the controversy caused a drastically altered interpretation of the text: in 1955, CBS tried to avoid controversial material in a televised version of the book, by deleting all mention of slavery and omitting the character of Jim entirely.\n\nBecause of this controversy over whether \"Huckleberry Finn\" is racist or anti-racist, and because the word \"nigger\" is frequently used in the novel (a commonly used word in Twain's time which has since become vulgar and taboo), many have questioned the appropriateness of teaching the book in the U.S. public school system—this questioning of the word \"nigger\" is illustrated by a school administrator of Virginia in 1982 calling the novel the \"most grotesque example of racism I've ever seen in my life\". According to the American Library Association, \"Huckleberry Finn\" was the fifth most frequently challenged book in the United States during the 1990s.\n\nThere have been several more recent cases involving protests for the banning of the novel. In 2003, high school student Calista Phair and her grandmother, Beatrice Clark, in Renton, Washington, proposed banning the book from classroom learning in the Renton School District, though not from any public libraries, because of the word \"nigger\". Clark filed a request with the school district in response to the required reading of the book, asking for the novel to be removed from the English curriculum. The two curriculum committees that considered her request eventually decided to keep the novel on the 11th grade curriculum, though they suspended it until a panel had time to review the novel and set a specific teaching procedure for the novel's controversial topics.\n\nIn 2009, a Washington state high school teacher called for the removal of the novel from a school curriculum. The teacher, John Foley, called for replacing \"Adventures of Huckleberry Finn\" with a more modern novel. In an opinion column that Foley wrote in the \"Seattle Post Intelligencer\", he states that all \"novels that use the ‘N-word' repeatedly need to go.\" He states that teaching the novel is not only unnecessary, but difficult due to the offensive language within the novel with many students becoming uncomfortable at \"just hear[ing] the N-word.\" He views this change as \"common sense,\" with Obama's election into office as a sign that Americans \"are ready for a change,\" and that by removing these books from the reading lists, they would be following this change.\n\nIn 2016, \"Adventures of Huckleberry Finn\" was removed from a public school district in Virginia, along with the novel \"To Kill a Mockingbird\", due to their use of racial slurs.\n\nPublishers have made their own attempts at easing the controversy by way of releasing editions of the book with the word \"nigger\" replaced by less controversial words. A 2011 edition of the book, published by NewSouth Books, employed the word \"slave\" (although being incorrectly addressed to a freed man), and did not use the term \"Injun.\" Mark Twain scholar Alan Gribben said he hoped the edition would be more friendly for use in classrooms, rather than have the work banned outright from classroom reading lists due to its language.\n\nAccording to publisher Suzanne La Rosa \"At NewSouth, we saw the value in an edition that would help the works find new readers. If the publication sparks good debate about how language impacts learning or about the nature of censorship or the way in which racial slurs exercise their baneful influence, then our mission in publishing this new edition of Twain's works will be more emphatically fulfilled.\" Another scholar, Thomas Wortham, criticized the changes, saying the new edition \"doesn't challenge children to ask, 'Why would a child like Huck use such reprehensible language?'\"\n\nTwo similarly expurged editions of the book were published in 2011. The Hipster Huckleberry Finn employed the word \"hipster\". The Adventures of Huckleberry Finn: Robotic Edition employed the word \"robot\", and included modified illustrations in which Jim was replaced with a robot character.\n\n\n\n\n\n\n\n\n\n"}
{"id": "14312", "url": "https://en.wikipedia.org/wiki?curid=14312", "title": "Harpsichord", "text": "Harpsichord\n\nA harpsichord is a musical instrument played by means of a keyboard which activates a row of levers that in turn trigger a mechanism that plucks one or more strings with a small plectrum.\n\nThe term denotes the whole family of similar plucked-keyboard instruments, including the smaller virginals, muselar, and spinet. The harpsichord was widely used in Renaissance and Baroque music. During the late 18th century, with the rise of the piano, it gradually disappeared from the musical scene. In the 20th century, it made a resurgence, being used in historically informed performances of older music, in new compositions, and in certain styles of popular music.\n\nHarpsichords vary in size and shape, but all have the same basic mechanism. The player depresses a key that rocks over a pivot in the middle of its length. The other end of the key lifts a jack (a long strip of wood) that holds a small plectrum (a wedge-shaped piece of quill, often made of plastic today), which plucks the string. When the player releases the key, the far end returns to its rest position, and the jack falls back; the plectrum, mounted on a tongue that can swivel backwards away from the string, passes the string without plucking it again. As the key reaches its rest position, a felt damper atop the jack stops the string's vibrations. These basic principles are explained in detail below.\n\nEach string is wound around a \"tuning pin\", normally at the end of the string closer to the player. When rotated with a wrench or tuning hammer, the tuning pin adjusts the tension so that the string sounds the correct pitch. Tuning pins are held tightly in holes drilled in the \"pinblock\" or \"wrestplank\", an oblong hardwood plank. Proceeding from the tuning pin, a string next passes over the \"nut\", a sharp edge that is made of hardwood and is normally attached to the wrestplank. The section of the string beyond the nut forms its \"vibrating length\", which is plucked and creates sound.\n\nAt the other end of its vibrating length, the string passes over the bridge, another sharp edge made of hardwood. As with the nut, the horizontal position of the string along the bridge is determined by a vertical metal pin inserted into the bridge, against which the string rests. The bridge itself rests on a \"soundboard\", a thin panel of wood usually made of spruce, fir or—in some Italian harpsichords—cypress. The soundboard efficiently transduces the vibrations of the strings into vibrations in the air; without a soundboard, the strings would produce only a very feeble sound. A string is attached at its far end by a loop to a \"hitchpin\" that secures it to the case.\n\nWhile many harpsichords have one string per note, more elaborate harpsichords can have two or more strings for each note. When there are multiple strings for each note, these additional strings are called \"choirs\" of strings. This provides two advantages: the ability to vary volume and ability to vary tonal quality. Volume is increased when the mechanism of the instrument is set up by the player (see below) so that the press of a single key plucks more than one string. Tonal quality can be varied in two ways. First, different choirs of strings can be designed to have distinct tonal qualities, usually by having one set of strings plucked closer to the nut, which emphasizes the higher harmonics, and produces a \"nasal\" sound quality. The mechanism of the instrument, called \"stops\" (following the use of the term in pipe organs) permits the player to select one choir or the other. Second, having one key pluck two strings at once changes not just volume but also tonal quality; for instance, when two strings tuned to the same pitch are plucked simultaneously, the note is not just louder but also richer and more complex.\n\nA particularly vivid effect is obtained when the strings plucked simultaneously are an octave apart. This is normally heard by the ear not as two pitches but as one: the sound of the higher string is blended with that of the lower one, and the ear hears the lower pitch, enriched in tonal quality by the additional strength in the upper harmonics of the note sounded by the higher string.\n\nWhen describing a harpsichord it is customary to specify its choirs of strings, often called its disposition. Strings at eight foot pitch sound at the normal expected pitch, strings at four foot pitch sound an octave higher. Harpsichords occasionally include a sixteen-foot choir (one octave lower than eight-foot) or a two-foot choir (two octaves higher; quite rare). When there are multiple choirs of strings, the player is often able to control which choirs sound. This is usually done by having a set of jacks for each choir, and a mechanism for \"turning off\" each set, often by moving the upper register (through which the jacks slide) sideways a short distance, so that their plectra miss the strings. In simpler instruments this is done by manually moving the registers, but as the harpsichord evolved, builders invented levers, knee levers and pedal mechanisms to make it easier to change registration.\n\nHarpsichords with more than one keyboard (this usually means two keyboards, stacked one on top of the other in a step-wise fashion, as with pipe organs) provide flexibility in selecting which strings play, since each manual can be set to control the plucking of a different set of strings. In addition, such harpsichords often have a mechanism (the \"coupler\") that couples manuals together, so that a single manual plays both sets of strings. The most flexible system is the French \"shove coupler\", in which the lower manual slides forward and backward. In the backward position, \"dogs\" attached to the upper surface of the lower manual engage the lower surface of the upper manual's keys. Depending on choice of keyboard and coupler position, the player can select any of the sets of jacks labeled in figure 4 as A, or B and C, or all three.\n\nThe English \"dogleg\" jack system (also used in Baroque Flanders) does not require a coupler. The jacks labeled A in Figure 5 have a \"dogleg\" shape that permits either keyboard to play A. If the player wishes to play the upper 8' from the upper manual only and not from the lower manual, a stop handle disengages the jacks labeled A and engages instead an alternative row of jacks called \"lute stop\" (not shown in the Figure). A lute stop is used to imitate the gentle sound of a plucked lute.\n\nThe case holds in position all of the important structural members: pinblock, soundboard, hitchpins, keyboard, and the jack action. It usually includes a solid bottom, and also internal bracing to maintain its form without warping under the tension of the strings. Cases vary greatly in weight and sturdiness: Italian harpsichords are often of light construction; heavier construction is found in the later Flemish instruments and those derived from them.\nThe case also gives the harpsichord its external appearance and protects the instrument. A large harpsichord is, in a sense, a piece of furniture, as it stands alone on legs and may be styled in the manner of other furniture of its place and period. Early Italian instruments, on the other hand, were so light in construction that they were treated rather like a violin: kept for storage in a protective outer case, and played after taking it out of its case and placing it on a table. Such tables were often quite high – until the late 18th century people usually played standing up. Eventually, harpsichords came to be built with just a single case, though an intermediate stage also existed: the \"false inner–outer\", which for purely aesthetic reasons was built to look as if the outer case contained an inner one, in the old style. Even after harpsichords became self-encased objects, they often were supported by separate stands, and some modern harpsichords have separate legs for improved portability.\n\nMany harpsichords have a lid that can be raised, a cover for the keyboard, and a stand for music.\n\nHarpsichords have been decorated in a great many different ways: with plain buff paint (e.g. some Flemish instruments), with paper printed with patterns, with leather or velvet coverings, with chinoiserie, or occasionally with highly elaborate painted artwork.\n\nIn modern usage, \"harpsichord\" can mean any member of the family of instruments. More often, though, it specifically denotes a grand-piano-shaped instrument with a roughly triangular case accommodating long bass strings at the left and short treble strings at the right. The characteristic profile of such a harpsichord is more elongated than a modern piano, with a sharper curve than the bentside.\n\nThe virginal is a smaller and simpler rectangular form of the harpsichord having only one string per note; the strings run parallel to the keyboard, which is on the long side of the case.\n\nA spinet is a harpsichord with the strings set at an angle (usually about 30 degrees) to the keyboard. The strings are too close together for the jacks to fit between them. Instead, the strings are arranged in pairs, and the jacks are in the larger gaps between the pairs. The two jacks in each gap face in opposite directions, and each plucks a string adjacent to the gap.\n\nThe English diarist Samuel Pepys mentions his \"tryangle\" several times. This was not the percussion instrument that we call triangle today; rather, it was a name for octave-pitched spinets, which were triangular in shape.\n\nA clavicytherium is a harpsichord with the soundboard and strings mounted vertically facing the player, the same space-saving principle as an upright piano. In a clavicytherium, the jacks move horizontally without the assistance of gravity, so that clavicytherium actions are more complex than those of other harpsichords.\n\nOttavini are small spinets or virginals at four-foot pitch. Harpsichords at octave pitch were more common in the early Renaissance, but lessened in popularity later on. However, the ottavino remained very popular as a domestic instrument in Italy until the 19th century. In the Low Countries, an ottavino was commonly paired with an 8' virginals, encased in a small cubby under the soundboard of the larger instrument. The ottavino could be removed and placed on top of the virginal, making, in effect, a double manual instrument. These are sometimes called 'mother-and-child' or 'double' virginals.\n\nThe archicembalo, built in the 16th century, had an unusual keyboard layout, designed to accommodate variant tuning systems demanded by compositional practice and theoretical experimentation. More common were instruments with split sharps, also designed to accommodate the tuning systems of the time.\n\nThe folding harpsichord was an instrument that could be folded up for travel.\n\nPedal Harpsichord: Occasionally, harpsichords were built which included another set or sets of strings underneath and operated by pedals which pluck the lowest keys of the harpsichord. Although there are no known extant pedal harpsichords from the 18th century or before, from Adlung (1758): the lower set of usually 8' strings \"...is built like an ordinary harpsichord, but with an extent of two octaves only. The jacks are similar, but they will benefit from being arranged back to back, since the two [bass] octaves take as much space as four in an ordinary harpsichord Prior to 1980 when Keith Hill introduced his design for a pedal harpsichord, most pedal harpsichords were built based on the designs of extant pedal pianos from the 19th century, in which the instrument is as wide as the pedalboard. While these were mostly intended as practice instruments for organists, a few pieces are believed to have been written specifically for the pedal harpsichord. However, the set of pedals can augment the sound from any piece performed on the instrument, as demonstrated on several albums by E. Power Biggs.\n\nOn the whole, earlier harpsichords have smaller ranges than later ones, although there are many exceptions. The largest harpsichords have a range of just over five octaves, and the smallest have under four. Usually, the shortest keyboards were given extended range in the bass with a \"short octave\". The traditional pitch range for a 5-octave instrument is F–F (FF–f‴).\n\nTuning pitch is often taken to be A = 415 Hz, roughly a semitone lower than the modern standard concert pitch of A = 440 Hz. An accepted exception is for French baroque repertoire, which is often performed with a = 392 Hz, approximately a semitone lower again. See Jean-Philippe Rameau's \"Treatise on Harmony\" (1722) [Dover Publications], Book One, chapter five, for insight into French baroque tuning; \"Since most of these semitones are absolutely necessary in the tuning of organs and other similar instruments, the following chromatic system has been drawn up.\" Tuning an instrument nowadays usually starts with setting an A; historically it would commence from a C or an F.\n\nSome modern instruments are built with keyboards that can shift sideways, allowing the player to align the mechanism with strings at either A = 415 Hz or A = 440 Hz. If a tuning other than equal temperament is used, the instrument requires retuning once the keyboard is shifted.\n\nThe harpsichord was most likely invented in the late Middle Ages. By the 16th century, harpsichord makers in Italy were making lightweight instruments with low string tension. A different approach was taken in the Southern Netherlands starting in the late 16th century, notably by the Ruckers family. Their harpsichords used a heavier construction and produced a more powerful and distinctive tone. They included the first harpsichords with two keyboards, used for transposition.\n\nThe Flemish instruments served as the model for 18th century harpsichord construction in other nations. In France, the double keyboards were adapted to control different choirs of strings, making a more musically flexible instrument. Instruments from the peak of the French tradition, by makers such as the Blanchet family and Pascal Taskin, are among the most widely admired of all harpsichords, and are frequently used as models for the construction of modern instruments. In England, the Kirkman and Shudi firms produced sophisticated harpsichords of great power and sonority. German builders extended the sound repertoire of the instrument by adding sixteen foot and two foot choirs; these instruments have recently served as models for modern builders.\n\nIn the late 18th century the harpsichord was supplanted by the piano and almost disappeared from view for most of the 19th century: an exception was its continued use in opera for accompanying recitative, but the piano sometimes displaced it even there. Twentieth century efforts to revive the harpsichord began with instruments that used piano technology, with heavy strings and metal frames. Starting in the middle of the 20th century, ideas about harpsichord making underwent a major change, when builders such as Frank Hubbard, William Dowd, and Martin Skowroneck sought to re-establish the building traditions of the Baroque period. Harpsichords of this type of historically informed building practice dominate the current scene.\n\nThe great bulk of the standard repertoire for the harpsichord was written during its first historical flowering, the Renaissance and Baroque eras.\n\nThe first music written specifically for solo harpsichord was published around the early 16th century. Composers who wrote solo harpsichord music were numerous during the whole Baroque era in European countries including Italy, Germany, England and France. Solo harpsichord compositions included dance suites, fantasias, and fugues. Among the most famous composers who wrote for the harpsichord were the members of English virginal school of the late Renaissance, notably William Byrd (ca. 1540–1623). In France, a great number of highly characteristic solo works were created and compiled into four books of \"ordres\" by François Couperin (1668–1733). Domenico Scarlatti (1685–1757) began his career in Italy but wrote most of his solo harpsichord works in Spain; his most famous work is his series of 555 harpsichord sonatas. Perhaps the most celebrated composers who wrote for the harpsichord were Georg Friedrich Händel (1685–1759), who composed numerous suites for harpsichord, and especially J. S. Bach (1685–1750), whose solo works (for instance, the Well-Tempered Clavier and the Goldberg Variations), continue to be performed very widely, often on the piano. Bach was also a pioneer of the harpsichord concerto, both in works designated as such, and in the harpsichord part of his Fifth Brandenburg Concerto.\n\nTwo of the most prominent composers of the Classical era, Joseph Haydn (1732–1809) and Wolfgang Amadeus Mozart (1756–1791), wrote harpsichord music. For both, the instrument featured in the earlier period of their careers, \n\nThrough the 19th century, the harpsichord was almost completely supplanted by the piano. In the 20th century, composers returned to the instrument, as they sought out variation in the sounds available to them. Under the influence of Arnold Dolmetsch, the harpsichordists Violet Gordon-Woodhouse (1872–1951) and in France, Wanda Landowska (1879–1959), were at the forefront of the instrument's renaissance. Concertos for the instrument were written by Francis Poulenc (the \"Concert champêtre\", 1927–28), and Manuel de Falla. Elliott Carter's \"Double Concerto\" is scored for harpsichord, piano and two chamber orchestras. For a detailed account of music composed for the revived harpsichord, see \"Contemporary harpsichord\".\n\n\n\nInstruments\n\nHistory\nListen\n\nImages\n\nOrganisations\n\nCraftsman insights\n\nMusic\n\nTechnical\n"}
