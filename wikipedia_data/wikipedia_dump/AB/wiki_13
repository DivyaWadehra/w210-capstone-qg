{"id": "13998", "url": "https://en.wikipedia.org/wiki?curid=13998", "title": "Hierarchy", "text": "Hierarchy\n\nA hierarchy (from the Greek \"hierarkhia\", \"rule of a high priest\", from \"hierarkhes\", \"president of sacred rites\") is an arrangement of items (objects, names, values, categories, etc.) in which the items are represented as being \"above\", \"below\", or \"at the same level as\" one another. Hierarchy is an important concept in a wide variety of fields, such as philosophy, mathematics, computer science, organizational theory, systems theory, and the social sciences (especially political philosophy).\n\nA hierarchy can link entities either directly or indirectly, and either vertically or diagonally. The only direct links in a hierarchy, insofar as they are hierarchical, are to one's immediate superior or to one of one's subordinates, although a system that is largely hierarchical can also incorporate alternative hierarchies. Hierarchical links can extend \"vertically\" upwards or downwards via multiple links in the same direction, following a path. All parts of the hierarchy which are not linked vertically to one another nevertheless can be \"horizontally\" linked through a path by traveling up the hierarchy to find a common direct or indirect superior, and then down again. This is akin to two co-workers or colleagues; each reports to a common superior, but they have the same relative amount of authority. Organizational forms exist that are both alternative and complementary to hierarchy. Heterarchy is one such form.\n\nHierarchies have their own special vocabulary. These terms are easiest to understand when a hierarchy is diagrammed (see below).\n\nIn an organizational context, the following terms are often used related to hierarchies:\n\nIn a mathematical context (in graph theory), the general terminology used is different.\n\nMost hierarchies use a more specific vocabulary pertaining to their subject, but the idea behind them is the same. For example, with data structures, objects are known as nodes, superiors are called parents and subordinates are called children. In a business setting, a superior is a supervisor/boss and a peer is a colleague.\n\nDegree of branching refers to the number of direct subordinates or children an object has (in graph theory, equivalent to the number of other vertices connected to via outgoing arcs, in a directed graph) a node has. Hierarchies can be categorized based on the \"maximum degree\", the highest degree present in the system as a whole. Categorization in this way yields two broad classes: \"linear\" and \"branching\".\n\nIn a linear hierarchy, the maximum degree is 1. In other words, all of the objects can be visualized in a line-up, and each object (excluding the top and bottom ones) has exactly one direct subordinate and one direct superior. Note that this is referring to the \"objects\" and not the \"levels\"; every hierarchy has this property with respect to levels, but normally each level can have an infinite number of objects. An example of a linear hierarchy is the hierarchy of life.\n\nIn a branching hierarchy, one or more objects has a degree of 2 or more (and therefore the minimum degree is 2 or higher). For many people, the word \"hierarchy\" automatically evokes an image of a branching hierarchy. Branching hierarchies are present within numerous systems, including organizations and classification schemes. The broad category of branching hierarchies can be further subdivided based on the degree.\n\nA flat hierarchy is a branching hierarchy in which the maximum degree approaches infinity, i.e., that has a wide span. Most often, systems intuitively regarded as hierarchical have at most a moderate span. Therefore, a flat hierarchy is often not viewed as a hierarchy at all. For example, diamonds and graphite are flat hierarchies of numerous carbon atoms which can be further decomposed into subatomic particles.\n\nAn overlapping hierarchy is a branching hierarchy in which at least one object has two parent objects. For example, a graduate student can have two co-supervisors to whom the student reports directly and equally, and who have the same level of authority within the university hierarchy (i.e., they have the same position or tenure status).\n\nPossibly the first use of the English word \"hierarchy\" cited by the \"Oxford English Dictionary\" was in 1881, when it was used in reference to the three orders of three angels as depicted by Pseudo-Dionysius the Areopagite (5th–6th centuries). Pseudo-Dionysius used the related Greek word (ἱεραρχία \"hierarchia\") both in reference to the celestial hierarchy and the ecclesiastical hierarchy. The Greek term ἱεραρχία means \"rule of a high priest\" (from ἱεράρχης \"hierarches\", meaning \"president of sacred rites, high-priest\" and that from ἱερεύς \"hiereus\", \"priest\" and ἀρχή \"arche\", amongst others \"first place or power, rule\"), and Dionysius is credited with first use of it as an abstract noun. Since hierarchical churches, such as the Roman Catholic (see Catholic Church hierarchy) and Eastern Orthodox churches, had tables of organization that were \"hierarchical\" in the modern sense of the word (traditionally with God as the pinnacle or head of the hierarchy), the term came to refer to similar organizational methods in secular settings.\n\nA hierarchy is typically depicted as a pyramid, where the height of a level represents that level's status and width of a level represents the quantity of items at that level relative to the whole. For example, the few Directors of a company could be at the apex, and the base could be thousands of people who have no subordinates.\n\nThese pyramids are typically diagrammed with a tree or triangle diagram (but note that not all triangle/pyramid diagrams are hierarchical, for example, the 1992 USDA food guide pyramid), both of which serve to emphasize the size differences between the levels. An example of a triangle diagram appears to the right. An organizational chart is the diagram of a hierarchy within an organization, and is depicted in tree form below.\n\nMore recently, as computers have allowed the storage and navigation of ever larger data sets, various methods have been developed to represent hierarchies in a manner that makes more efficient use of the available space on a computer's screen. Examples include fractal maps, TreeMaps and Radial Trees.\n\nIn the design field, mainly graphic design, successful layouts and formatting of the content on documents are heavily dependent on the rules of visual hierarchy. Visual hierarchy is also important for proper organization of files on computers.\n\nAn example of visually representing hierarchy is through the Nested clusters. The Nested clusters represents hierarchical relationships by using layers of information. The child element is within the parent element, such as in a Venn diagram. This structure of representing hierarchy is most effective in representing simple relationships. For example, when directing someone to open a file on a computer desktop, one may first direct them towards the main folder, then the subfolders within the main folder. They will keep opening files within the folders until the designated file is located.\n\nFor more complicated hierarchies, the stair structure represents hierarchical relationships through the use of visual stacking. Visually imagine the top of a downward staircase beginning at the left and descending on the right. The child elements are towards the bottom of the stairs and the parent elements are at the top. This structure is effective when representing more complicated hierarchies where steps are not placed in obvious sequences. Further steps are concealed unless all of the steps are revealed in sequence. In the computer desktop example, a file that is being sought after can only be found once another file is opened. The link for the desired file is within another document. All the steps must be completed until the final destination is reached.\n\nIn plain English, a hierarchy can be thought of as a set in which:\nThe first requirement is also interpreted to mean that a hierarchy can have no circular relationships; the association between two objects is always transitive.\nThe second requirement asserts that a hierarchy must have a leader or root that is common to all of the objects.\n\nMathematically, in its most general form, a hierarchy is a partially ordered set or \"poset\". The system in this case is the entire poset, which is constituted of elements. Within this system, each element shares a particular unambiguous property. Objects with the same property value are grouped together, and each of those resulting levels is referred to as a class.\n\n\"Hierarchy\" is particularly used to refer to a poset in which the classes are organized in terms of increasing complexity. \nOperations such as addition, subtraction, multiplication and division are often performed in a certain sequence or order. Usually, addition and subtraction are performed after multiplication and division has already been applied to a problem. The use of parenthesis is also a representation of hierarchy, for they show which operation is to be done prior to the following ones. For example:\n(2 + 5) × (7 - 4).\nIn this problem, typically one would multiply 5 by 7 first, based on the rules of mathematical hierarchy. But when the parentheses are placed, one will know to do the operations within the parentheses first before continuing on with the problem. These rules are largely dominant in algebraic problems, ones that include several steps in order to solve. The use of hierarchy in mathematics is beneficial in order to quickly and efficiently solve a problem without having to go through the process of slowly dissecting the problem. Most of these rules are now known as the proper way into solving certain equations.\n\nA nested hierarchy or \"inclusion hierarchy\" is a hierarchical ordering of nested sets. The concept of nesting is exemplified in Russian matryoshka dolls. Each doll is encompassed by another doll, all the way to the outer doll. The outer doll holds all of the inner dolls, the next outer doll holds all the remaining inner dolls, and so on. Matryoshkas represent a nested hierarchy where each level contains only one object, i.e., there is only one of each size of doll; a generalized nested hierarchy allows for multiple objects within levels but with each object having only one parent at each level. The general concept is both demonstrated and mathematically formulated in the following example:\n\nA square can always also be referred to as a quadrilateral, polygon or shape. In this way, it is a hierarchy. However, consider the set of polygons using this classification. A square can \"only\" be a quadrilateral; it can never be a triangle, hexagon, etc.\n\nNested hierarchies are the organizational schemes behind taxonomies and systematic classifications. For example, using the original Linnaean taxonomy (the version he laid out in the 10th edition of \"Systema Naturae\"), a human can be formulated as:\n\nTaxonomies may change frequently (as seen in biological taxonomy), but the underlying concept of nested hierarchies is always the same.\n\nIn many programming taxonomies and syntax models (as well as fractals in mathematics), nested hierarchies, including Russian dolls, are also used to illustrate the properties of self-similarity and recursion. Recursion itself is included as a subset of hierarchical programming, and recursive thinking can be synonymous with a form of hierarchical thinking and logic.\n\nA containment hierarchy is a direct extrapolation of the nested hierarchy concept. All of the ordered sets are still nested, but every set must be \"strict\"—no two sets can be identical. The shapes example above can be modified to demonstrate this:\n\nThe notation formula_4 means \"x\" is a subset of \"y\" but is not equal to \"y\".\n\nA general example of a containment hierarchy is demonstrated in class inheritance in object-oriented programming.\n\nTwo types of containment hierarchies are the \"subsumptive\" containment hierarchy and the \"compositional\" containment hierarchy. A subsumptive hierarchy \"subsumes\" its children, and a compositional hierarchy is \"composed\" of its children. A hierarchy can also be both subsumptive \"and\" compositional.\n\nA \"subsumptive\" containment hierarchy is a classification of object classes from the general to the specific. Other names for this type of hierarchy are \"taxonomic hierarchy\" and \"IS-A hierarchy\". The last term describes the relationship between each level—a lower-level object \"is a\" member of the higher class. The taxonomical structure outlined above is a subsumptive containment hierarchy. Using again the example of Linnaean taxonomy, it can be seen that an object that is part of the level \"Mammalia\" \"is a\" member of the level \"Animalia\"; more specifically, a human \"is a\" primate, a primate \"is a\" mammal, and so on. A subsumptive hierarchy can also be defined abstractly as a hierarchy of \"concepts\". For example, with the Linnaean hierarchy outlined above, an entity name like \"Animalia\" is a way to group all the species that fit the conceptualization of an animal.\n\nA \"compositional\" containment hierarchy is an ordering of the parts that make up a system—the system is \"composed\" of these parts. Most engineered structures, whether natural or artificial, can be broken down in this manner.\n\nThe compositional hierarchy that every person encounters at every moment is the hierarchy of life. Every person can be reduced to organ systems, which are composed of organs, which are composed of tissues, which are composed of cells, which are composed of molecules, which are composed of atoms. In fact, the last two levels apply to all matter, at least at the macroscopic scale. Moreover, each of these levels inherit all the properties of their children.\n\nIn this particular example, there are also \"emergent properties\"—functions that are not seen at the lower level (e.g., cognition is not a property of neurons but is of the brain)—and a scalar quality (molecules are bigger than atoms, cells are bigger than molecules, etc.). Both of these concepts commonly exist in compositional hierarchies, but they are not a required general property. These \"level hierarchies\" are characterized by bi-directional causation. \"Upward causation\" involves lower-level entities causing some property of a higher level entity; children entities may interact to yield parent entities, and parents are composed at least partly by their children. \"Downward causation\" refers to the effect that the incorporation of entity \"x\" into a higher-level entity can have on \"x\"'s properties and interactions. Furthermore, the entities found at each level are \"autonomous\".\n\nAlmost every system of organization applied to the world is arranged hierarchically. By their common definitions, every nation has a government and every government is hierarchical. Socioeconomic systems are stratified into a social hierarchy (the social stratification of societies), and all systematic classification schemes (taxonomies) are hierarchical. Most organized religions, regardless of their internal governance structures, operate as a hierarchy under God. Many Christian denominations have an autocephalous ecclesiastical hierarchy of leadership. Families are viewed as a hierarchical structure in terms of cousinship (e.g., first cousin once removed, second cousin, etc.), ancestry (as depicted in a family tree) and inheritance (succession and heirship). All the requisites of a well-rounded life and lifestyle can be organized using Maslow's hierarchy of human needs. Learning must often follow a hierarchical scheme—to learn differential equations one must first learn calculus; to learn calculus one must first learn elementary algebra; and so on. Even nature itself has its own hierarchies, as numerous schemes such as Linnaean taxonomy, the organization of life, and biomass pyramids attempt to document. Hierarchies are so infused into daily life that they are viewed as trivial.\n\nWhile the above examples are often clearly depicted in a hierarchical form and are classic examples, hierarchies exist in numerous systems where this branching structure is not immediately apparent. For example, most postal code systems are hierarchical. Using the Canadian postal code system as an example, the top level's binding concept is the \"postal district\", and consists of 18 objects (letters). The next level down is the \"zone\", where the objects are the digits 0–9. This is an example of an overlapping hierarchy, because each of these 10 objects has 18 parents. The hierarchy continues downward to generate, in theory, 7,200,000 unique codes of the format \"A0A 0A0\" (the second and third letter position allow 20 objects each). Most library classification systems are also hierarchical. The Dewey Decimal System is regarded as infinitely hierarchical because there is no finite bound on the number of digits can be used after the decimal point.\n\nOrganizations can be structured as a dominance hierarchy. In an organizational hierarchy, there is a single person or group with the most power and authority, and each subsequent level represents a lesser authority. Most organizations are structured in this manner, including governments, companies, militia and organized religions. The units or persons within an organization are depicted hierarchically in an organizational chart.\n\nIn a reverse hierarchy, the conceptual pyramid of authority is turned upside-down, so that the apex is at the bottom and the base is at the top. This mode represents the idea that members of the higher rankings are responsible for the members of the lower rankings.\n\nEmpirically, we observe in nature a large proportion of the (complex) biological systems, they exhibit hierarchic structure. On theoretical grounds we could expect complex systems to be hierarchies in a world in which complexity had to evolve from simplicity. System hierarchies analysis performed in the 1950s, laid the empirical foundations for a field that would be, from the 1980s, hierarchical ecology.\n\nThe theoretical foundations are summarized by Thermodynamics.\nWhen biological systems are modeled as physical systems, in its most general abstraction, they are thermodynamic open systems that exhibit self-organised behavior, and the set/subset relations between dissipative structures can be characterized in a hierarchy.\n\nCGI and computer animation programs mostly use hierarchies for models. On a 3D model of a human for example, the chest is a parent of the upper left arm, which is a parent of the lower left arm, which is a parent of the hand. This is used in modeling and animation for almost everything built as a 3D digital model.\n\nMany grammatical theories, such as phrase-structure grammar, involve hierarchy.\n\nDirect–inverse languages such as Cree and Mapudungun distinguish subject and object on verbs not by different subject and object markers, but via a hierarchy of persons.\n\nIn this system, the three (or four with Algonquian languages) persons are placed in a hierarchy of salience. To distinguish which is subject and which object, \"inverse markers\" are used if the object outranks the subject.\n\nThe structure of a musical composition is often understood hierarchically (for example by Heinrich Schenker (1768–1835, see Schenkerian analysis), and in the (1985) Generative Theory of Tonal Music, by composer Fred Lerdahl and linguist Ray Jackendoff). The sum of all notes in a piece is understood to be an all-inclusive surface, which can be reduced to successively more sparse and more fundamental types of motion. The levels of structure that operate in Schenker's theory are the foreground, which is seen in all the details of the musical score; the middle ground, which is roughly a summary of an essential contrapuntal progression and voice-leading; and the background or Ursatz, which is one of only a few basic \"long-range counterpoint\" structures that are shared in the gamut of tonal music literature.\n\nThe pitches and form of tonal music are organized hierarchically, all pitches deriving their importance from their relationship to a tonic key, and secondary themes in other keys are brought back to the tonic in a recapitulation of the primary theme. Susan McClary connects this specifically in the sonata-allegro form to the feminist hierarchy of gender (see above) in her book \"Feminine Endings\", even pointing out that primary themes were often previously called \"masculine\" and secondary themes \"feminine.\"\n\nIn ethics, various virtues are enumerated and sometimes organized hierarchically according to certain brands of virtue theory.\n\nIn some of these random examples, there is an asymmetry of 'compositional' significance between levels of structure, so that small parts of the whole hierarchical array depend, for their meaning, on their membership in larger parts.There is a hierarchy of activities in human life: productive activity serves or is guided by the moral life; the moral life is guided by practical reason; practical reason (used in moral and political life) serves contemplative reason (whereby we contemplate God). Practical reason sets aside time and resources for contemplative reason.\n\nIn the work of diverse theorists such as William James (1842–1910), Michel Foucault (1926–1984) and Hayden White, important critiques of hierarchical epistemology are advanced. James famously asserts in his work \"Radical Empiricism\" that clear distinctions of type and category are a constant but unwritten goal of scientific reasoning, so that when they are discovered, success is declared. But if aspects of the world are organized differently, involving inherent and intractable ambiguities, then scientific questions are often considered unresolved.\n\nHierarchy in ethics emerged in Western Europe, West Asia and North Africa around the 1600s. In this aspect, the term hierarchy refers to how distinguishable they are from real to unreal. Feminists, Marxists, anarchists, communists, critical theorists and others, all of whom have multiple interpretations, criticize the hierarchies commonly found within human society, especially in social relationships. Hierarchies are present in all parts of society: in businesses, schools, families, etc. These relationships are often viewed as necessary. Entities that stand in hierarchical arrangements are animals, humans, plants, etc. In some cultures, God can also be an addition to this hierarchy. However, feminists, Marxists, critical theorists, and others analyze hierarchy in terms of the values and power that it arbitrarily assigns to one group over another. Hierarchical ethics offers a way of logical reasoning that is compatible with religious commitments. In some cultures, there is hierarchy within humanity: The man in a family is above the woman, and children are after, and in social classes there might be a hierarchy as follows: king, civic officials, craftsmen, unskilled workers.\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "14002", "url": "https://en.wikipedia.org/wiki?curid=14002", "title": "Outline of health sciences", "text": "Outline of health sciences\n\nThe following outline is provided as an overview of and topical guide to health sciences:\n\nHealth sciences – are those sciences which focus on health, or health care, as core parts of their subject matter. Because these two subject matter relate to multiple academic disciplines, both STEM disciplines as well as emerging patient safety disciplines (such as social care research) are relevant to current health scientific knowledge.\n\nHealth sciences knowledge bases are currently diverse, with intellectual foundations which are sometimes mutually-inconsistent. There is currently an existing bias in the field, towards high valuation of knowledge deriving from controlling views on human agency (as epitomized by the epistemological basis of Randomized Control Trial designs); compare this against the more naturalistic views on human agency taken by research based on Ethnography for example).\n\nMental health\n\nSocial health\n\nPhysical health\n\nMedicine – applied science or practice of the diagnosis, treatment, and prevention of disease. It encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Some of its branches are:\n\n\n\n\n\n"}
{"id": "14004", "url": "https://en.wikipedia.org/wiki?curid=14004", "title": "Hour", "text": "Hour\n\nAn hour (symbol: h; also abbreviated hr.) is a unit of time conventionally reckoned as of a day and scientifically reckoned as 3,599–3,601 seconds, depending on conditions.\n\nThe seasonal, temporal, or unequal hour was established in the ancient Near East as of the night or daytime. Such hours varied by season, latitude, and weather. It was subsequently divided into 60 minutes, each of 60 seconds. Its East Asian equivalent was the \"shi\", which was of the apparent solar day; a similar system was eventually developed in Europe which measured its equal or equinoctial hour as of such days measured from noon to noon. The minor variations of this unit were eventually smoothed by making it of the mean solar day, based on the measure of the sun's transit along the celestial equator rather than along the ecliptic. This was finally abandoned due to the minor slowing caused by the Earth's tidal deceleration by the Moon.\n\nIn the modern metric system, hours are an accepted unit of time equal to 3,600 seconds but an hour of Coordinated Universal Time (UTC) may incorporate a positive or negative leap second, making it last 3,599 or 3,601 seconds, in order to keep it within 0.9 seconds of universal time, which is based on measurements of the mean solar day at 0° longitude.\n\nThe modern English word \"hour\" is a development of the Anglo-Norman ' and Middle English ', first attested in the 13th century. It displaced the Old English \"tide\" (, \"time\") and \"stound\" (', \"span of time\"). The Anglo-Norman term was a borrowing of Old French ', a variant of ', which derived from Latin ' and Greek \"hṓrā\" (). Like Old English ' and ', \"hṓrā\" was originally a vaguer word for any span of time, including seasons and years. Its Proto-Indo-European root has been reconstructed as \"\" (\"year, summer\"), making \"hour\" distantly cognate with \"year\".\n\nThe time of day is typically expressed in English in terms of hours. Whole hours on a 12-hour clock are expressed using the contracted phrase \"o'clock\", from the older \"of clock\". (10 am and 10 pm are both read as \"ten o'clock\".) Hours on a 24-hour clock (\"military time\") are expressed as \"hundred\" or \"hundred hours\". (1000 is read \"ten hundred\" or \"ten hundred hours\"; 10 pm would be \"twenty-two hundred\".) Fifteen and thirty minutes past the hour is expressed as \"a quarter past\" or \"after\" and \"half past\", respectively, from their fraction of the hour. Fifteen minutes before the hour may be expressed as \"a quarter to\", \"of\", \"till\", or \"before\" the hour. (9:45 may be read \"nine forty-five\" or \"a quarter till ten\".)\n\nThe ancient Egyptians began dividing the night into \" at some time before the compilation of the Dynasty V Pyramid Texts in the 24thcentury. By 2150 (Dynasty IX), diagrams of stars inside Egyptian coffin lids—variously known as \"diagonal calendars\" or \"star clocks\"—attest that there were exactly 12 of these. Clagett writes that it is \"certain\" this duodecimal division of the night followed the adoption of the Egyptian civil calendar, usually placed on the basis of analyses of the Sothic cycle, but a lunar calendar presumably long predated this and also would have had twelve months in each of its years. The coffin diagrams show that the Egyptians took note of the heliacal risings of 36 stars or constellations (now known as \"decans\"), one for each of the ten-day \"weeks\" of their civil calendar. (12 sets of alternate \"triangle decans\" were used for the 5 epagomenal days between years.) Each night, the rising of eleven of these decans were noted, separating the night into twelve divisions whose middle terms would have lasted about 40minutes each. (Another seven stars were noted by the Egyptians during the twilight and predawn periods, although they were not important for the hour divisions.) The original decans used by the Egyptians would have fallen noticeably out of their proper places over a span of several centuries. By the time of (), the priests at Karnak were using water clocks to determine the hours. These were filled to the brim at sunset and the hour determined by comparing the water level against one of its twelve gauges, one for each month of the year. During the New Kingdom, another system of decans was used, made up of 24 stars over the course of the year and 12 within any one night.\n\nThe later division of the day into 12 hours was accomplished by sundials marked with ten equal divisions. The morning and evening periods when the sundials failed to note time were observed as the first and last hours.\n\nThe Egyptian hours were closely connected both with the priesthood of the gods and with their divine services. By the New Kingdom, each hour was conceived as a specific region of the sky or underworld through which Ra's solar barge travelled. Protective deities were assigned to each and were used as the names of the hours. As the protectors and resurrectors of the sun, the goddesses of the night hours were considered to hold power over all lifespans and thus became part of Egyptian funerary rituals. Two fire-spitting cobras were said to guard the gates of each hour of the underworld, and Wadjet and the rearing cobra (uraeus) were also sometimes referenced as ' from their role protecting the dead through these gates. The Egyptian for astronomer, used as a synonym for priest, was ', \"One of the Hours\" or \"Hour-Watcher\". The earliest forms of \" include one or three stars, with the later solar hours including the determinative hieroglyph for \"sun\".\n\nAncient China divided its day into 100 \"marks\" running from midnight to midnight. The system is said to have been used since remote antiquity, credited to the legendary Yellow Emperor, but is first attested in Han-era water clocks and in the 2nd-century history of that dynasty. It was measured with sundials and water clocks. Into the Eastern Han, the Chinese measured their day schematically, adding the 20-\"ke\" difference between the solstices evenly throughout the year, one every nine days. During the night, time was more commonly reckoned during the night by the \"watches\" of the guard, which were reckoned as a fifth of the time from sunset to sunrise.\n\nImperial China continued to use \"ke\" and \"geng\" but also began to divide the day into 12 \"double hours\" named after the earthly branches and sometimes also known by the name of the corresponding animal of the Chinese zodiac. The first \"shi\" originally ran from 11pm to 1am but was reckoned as starting at midnight by the time of the History of Song, compiled during the early Yuan. These apparently began to be used during the Eastern Han that preceded the Three Kingdoms era, but the sections that would have covered them are missing from their official histories; they first appear in official use in the Tang-era Book of Sui. Variations of all these units were subsequently adopted by Japan and the other countries of the Sinosphere.\n\nThe 12 \"shi\" supposedly began to be divided into 24 hours under the Tang, although they are first attested in the Ming-era Book of Yuan. In that work, the hours were known by the same earthly branches as the \"shi\", with the first half noted as its \"starting\" and the second as \"completed\" or \"proper\" \"shi\". In modern China, these are instead simply numbered and described as \"little \"shi\"\". The modern \"ke\" is now used to count quarter-hours, rather than a separate unit.\n\nAs with the Egyptian night and daytime hours, the division of the day into twelve \"shi\" has been credited to the example set by the rough number of lunar cycles in a solar year, although the 12-year Jovian orbital cycle was more important to traditional Chinese and Babylonian reckoning of the zodiac.\n\nIn Thailand, Laos, and Cambodia, the traditional system of noting hours is the six-hour clock. This reckons each of a day's 24 hours apart from noon as part of a fourth of the day. 7 am was the first hour of the first half of daytime; 1 pm the first hour of the latter half of daytime; 7 pm the first hour of the first half of nighttime; and 1 am the first hour of the latter half of nighttime. This system existed in the Ayutthaya Kingdom, deriving its current phrasing from the practice of publicly announcing the daytime hours with a gong and the nighttime hours with a drum. It was abolished in Laos and Cambodia during their French occupation and is uncommon there now. The Thai system remains in informal use in the form codified in 1901 by King Chulalongkorn.\n\nIt is most well known as the day in the hour of minutes, as the ancient Egyptians referred to it.\nThe Vedas and Puranas employed units of time based on the sidereal day (\"nakṣatra ahorātram\"). This was variously divided into 30 \"muhūtras\" of 48 minutes each or 60 \"dandas\" or \"nadís\" of 24 minutes each. The solar day was later similarly divided into 60 \"ghaṭikás\" of about the same duration, each divided in turn into 60 \"vinadis\". The Sinhalese followed a similar system but called their sixtieth of a day a \"peya\".\n\nThe ancient Greeks and Romans originally divided the day into 12 hours and the night into 3 or 4 night watches. They were notionally deified as the Horae, although sometimes only as a triad. The Greek astronomer Andronicus of Cyrrhus oversaw the construction of a horologion called the Tower of the Winds in Athens during the first century. This structure tracked a 24-hour day using both sundials and mechanical hour indicators. The night was eventually also divided into 12 hours.\n\nDuring Europe's Middle Ages, the Roman hours continued to be marked on sundials but the more important units of time were the canonical hours of the Orthodox and Catholic Church. During daylight, these followed the pattern set by the three-hour bells of the Roman markets, which were succeeded by the bells of local churches. They rang prime at about 6am, terce at about 9am, sext at noon, nones at about 3pm, and vespers at either 6pm or sunset. Matins and lauds precede these irregularly in the morning hours; compline follows them irregularly before sleep; and the midnight office follows that. Vatican II ordered their reformation for the Catholic Church in 1963, though they continue to be observed in the Orthodox churches.\n\nWhen mechanical clocks began to be used to show hours of daylight or nighttime, their period needed to be changed every morning and evening (for example, by changing the length of their pendula). The use of 24 hours for the entire day meant hours varied much less and the clocks needed to be adjusted only a few times a month.\n\nThe minor irregularities of the apparent solar day were smoothed by measuring time using the mean solar day, using the Sun's movement along the celestial equator rather than along the ecliptic. The irregularities of this time system were so minor that most clocks reckoning such hours did not need adjustment. However, scientific measurements eventually became precise enough to note the effect of tidal deceleration of the Earth by the Moon, which gradually lengthens the Earth's days. \n\nDuring the French Revolution, a general decimalization of measures was enacted, including decimal time between 1793 and 1795. Under its provisions, the French hour () was of the day and divided formally into 100 decimal minutes (') and informally into 10 tenths ('). This hour was only briefly in official use, being repealed by the same 1795 legislation that first established the metric system.\n\nThe metric system bases its measurements of time upon the second, defined since 1952 in terms of the Earth's rotation in 1900. Its hours are a secondary unit computed as precisely 3,600 seconds. However, an hour of Coordinated Universal Time (UTC), used as the basis of most civil time, has lasted 3,601 seconds 27 times since 1972 in order to keep it within 0.9 seconds of universal time, which is based on measurements of the mean solar day at 0° longitude. The addition of these seconds accommodates the very gradual slowing of the rotation of the Earth.\n\nIn modern life, the ubiquity of clocks and other timekeeping devices means that segmentation of days according to their hours is commonplace. Most forms of employment, whether wage or salaried labour, involves compensation based upon measured or expected hours worked. The fight for an eight-hour day was a part of labour movements around the world. Informal rush hours and happy hours cover the times of day when commuting slows down due to congestion or alcoholic drinks are available at discounted prices. The hour record for the greatest distance travelled by a cyclist within the span of an hour is one of cycling's greatest honours.\n\nMany different ways of counting the hours have been used. Because sunrise, sunset, and, to a lesser extent, noon, are the conspicuous points in the day, starting to count at these times was, for most people in most early societies, much easier than starting at midnight. However, with accurate clocks and modern astronomical equipment (and the telegraph or similar means to transfer a time signal in a split-second), this issue is much less relevant.\n\nAstrolabes, sundials, and astronomical clocks sometimes show the hour length and count using some of these older definitions and counting methods.\n\nIn ancient and medieval cultures, the counting of hours generally started with sunrise. Before the widespread use of artificial light, societies were more concerned with the division between night and day, and daily routines often began when light was sufficient.\n\n\"Babylonian hours\", as used on modern sundials, divide the day and night into 24 equal hours, reckoned from the time of sunrise. They are so named from the false belief of ancient authors that the Babylonians divided the day into 24 parts, beginning at sunrise. In fact, they divided the day into 12 parts (called \"kaspu\" or \"double hours\") or into 60 equal parts.\n\nSunrise marked the beginning of the first hour, the middle of the day was at the end of the sixth hour and sunset at the end of the twelfth hour. This meant that the duration of hours varied with the season. In the Northern hemisphere, particularly in the more northerly latitudes, summer daytime hours were longer than winter daytime hours, each being one twelfth of the time between sunrise and sunset. These variable-length hours were variously known as temporal, unequal, or seasonal hours and were in use until the appearance of the mechanical clock, which furthered the adoption of equal length hours.\n\nThis is also the system used in Jewish law and frequently called \"Talmudic hour\" (\"Sha'a Zemanit\") in a variety of texts. The Talmudic hour is one twelfth of time elapsed from sunrise to sunset, day hours therefore being longer than night hours in the summer; in winter they reverse.\n\nThe Indic day began at sunrise. The term \"hora\" was used to indicate an hour. The time was measured based on the length of the shadow at day time. A \"hora\" translated to 2.5 \"pe\". There are 60 \"pe\" per day, 60 minutes per \"pe\" and 60 \"kshana\" (snap of a finger or instant) per minute. \"Pe\" was measured with a bowl with a hole placed in still water. Time taken for this graduated bowl was one \"pe\". Kings usually had an officer in charge of this clock.\n\nIn so-called \"Italian time\", \"Italian hours\", or \"old Czech time\", the first hour started with the sunset Angelus bell (or at the end of dusk, i.e., half an hour after sunset, depending on local custom and geographical latitude). The hours were numbered from 1 to 24. For example, in Lugano, the sun rose in December during the 14th hour and noon was during the 19th hour; in June the Sun rose during the 7th hour and noon was in the 15th hour. Sunset was always at the end of the 24th hour. The clocks in church towers struck only from 1 to 12, thus only during night or early morning hours.\n\nThis manner of counting hours had the advantage that everyone could easily know how much time they had to finish their day's work without artificial light. It was already widely used in Italy by the 14th century and lasted until the mid-18th century; it was officially abolished in 1755, or in some regions customary until the mid-19th century.\n\nThe system of Italian hours can be seen on a number of clocks in Europe, where the dial is numbered from 1 to 24 in either Roman or Arabic numerals. The St Mark's Clock in Venice, and the Orloj in Prague are famous examples. It was also used in Poland and Bohemia until the 17th century.\n\nThe Islamic day begins at sunset. The first prayer of the day (maghrib) is to be performed between just after sunset and the end of twilight. Until 1968 Saudi Arabia used the system of counting 24 equal hours with the first hour starting at sunset.\n\nFor many centuries, up to 1925, astronomers counted the hours and days from noon, because it was the easiest solar event to measure accurately. An advantage of this method (used in the Julian Date system, in which a new Julian Day begins at noon) is that the date doesn't change during a single night's observing.\n\nIn the modern 12-hour clock, counting the hours starts at midnight and restarts at noon. Hours are numbered 12, 1, 2, ..., 11. Solar noon is always close to 12 noon (ignoring artificial adjustments due to time zones and daylight saving time), differing according to the equation of time by as much as fifteen minutes either way. At the equinoxes sunrise is around 6 a.m. (, before noon), and sunset around 6 p.m. (, after noon).\n\nIn the modern 24-hour clock, counting the hours starts at midnight, and hours are numbered from 0 to 23. Solar noon is always close to 12:00, again differing according to the equation of time. At the equinoxes sunrise is around 06:00, and sunset around 18:00.\n\n\n\n\n\n"}
{"id": "14005", "url": "https://en.wikipedia.org/wiki?curid=14005", "title": "Hezekiah", "text": "Hezekiah\n\nHezekiah () was, according to the Hebrew Bible, the son of Ahaz and the 13th king of Judah. Edwin Thiele concluded that his reign was between c. 715 and 686 BC. He is considered a very righteous king by the author of the Books of Kings. He is also one of the most prominent kings of Judah mentioned in the Bible and is one of the kings mentioned in the genealogy of Jesus in the Gospel of Matthew.\n\nAccording to the Bible, Hezekiah witnessed the destruction of the northern Kingdom of Israel by Sargon's Assyrians in c. 722 BC and was king of Judah during the siege of Jerusalem by Sennacherib in 701 BC. Hezekiah enacted sweeping religious reforms, including a strict mandate for the sole worship of Yahweh and a prohibition on venerating other deities within the Temple of Jerusalem. Isaiah and Micah prophesied during his reign.\n\nThe name Hezekiah means \"Yahweh (Jehovah) Strengthens\" in Hebrew.\n\nThe main account of Hezekiah's reign is found in , , and of the Hebrew Bible. mentions that it is a collection of King Solomon's proverbs that were \"copied by the officials of King Hezekiah of Judah\". His reign is also referred to in the books of the prophets Isaiah, Jeremiah, Hosea, and Micah. The books of Hosea and Micah record that their prophecies were made during Hezekiah’s reign.\n\nHezekiah was the son of King Ahaz and Abijah. His mother, Abijah (also called Abi), was a daughter of the high priest Zechariah. Based on Thiele's dating, Hezekiah was born in c. 741 BC. He was married to Hephzi-bah. () He died from natural causes at the age of 54 in c. 687 BC, and was succeeded by his son Manasseh ().\n\nAccording to the Bible, Hezekiah assumed the throne of Judah at the age of 25 and reigned for 29 years (). Some writers have proposed that Hezekiah served as coregent with his father Ahaz for about 14 years. His sole reign is dated by William F. Albright as 715–687 BC, and by Edwin R. Thiele as 716–687 BC (the last ten years being a co-regency with his son Manasseh).\n\nHezekiah purified and repaired the Temple, purged its idols, and reformed the priesthood. In an effort to abolish idolatry from his kingdom, he destroyed the high places (or \"bamot\") and the \"bronze serpent\" (or \"Nehushtan\"), recorded as being made by Moses, which became objects of idolatrous worship. In place of this, he centralized the worship of God at the Jerusalem Temple. Hezekiah also defeated the Philistines, \"as far as Gaza and its territory\", () and resumed the Passover pilgrimage and the tradition of inviting the scattered tribes of Israel to take part in a Passover festival. He sent messengers to Ephraim and Manasseh inviting them to Jerusalem for the celebration of the Passover. The messengers, however, were not only not listened to, but were even laughed at; only a few men of Asher, Manasseh, and Zebulun came to the city. Nevertheless, the Passover was celebrated with great solemnity and such rejoicing as had not been in Jerusalem since the days of Solomon. Hezekiah is portrayed by the Bible as a great and good king.\n\nAfter the death of Assyrian king Sargon II in 705 BC, Sargon's son Sennacherib became king of Assyria. In 703 BC, Sennacherib began a series of major campaigns to quash opposition to Assyrian rule, starting with cities in the eastern part of the realm. In 701 BC, Sennacherib turned toward cities in the west. Hezekiah then had to face the invasion of Judah. According to the Bible, Hezekiah did not rely on Egypt for support, but relied on God and prayed to Him for deliverance of his capital city Jerusalem. (; ; ; ; )\n\nThe Assyrians recorded that Sennacherib lifted his siege of Jerusalem after Hezekiah paid Sennacherib tribute. The Bible records that Hezekiah paid him three hundred talents of silver and thirty of gold as tribute, even sending the doors of the Temple to produce the promised amount, but, even after the payment was made, Sennacherib renewed his assault on Jerusalem. Sennacherib surrounded the city and sent his Rabshakeh to the walls as a messenger. The Rabshakeh addressed the soldiers manning the city wall in Hebrew (\"Yĕhuwdiyth\"), asking them to distrust Yahweh and Hezekiah, claiming that Hezekiah's righteous reforms (destroying the idols and High Places) were a sign that the people should not trust their god to be favorably disposed (). records that Hezekiah went to the Temple and there he prayed to God.\n\nKnowing that Jerusalem would eventually be subject to siege, Hezekiah had been preparing for some time by fortifying the walls of the capital, building towers, and constructing a tunnel to bring fresh water to the city from a spring outside its walls. He made at least two major preparations that would help Jerusalem to resist conquest: the construction of the Siloam Tunnel, and construction of the Broad Wall.\n\n\"When Sennacherib had come, intent on making war against Jerusalem, Hezekiah consulted with his officers about stopping the flow of the springs outside the city … for otherwise, they thought, the King of Assyria would come and find water in abundance\" (). \n\nThe narratives of the Bible state that Sennacherib's army besieged Jerusalem. (; ; ; )\n\nAccording to the biblical record, Sennacherib sent threatening letters warning Hezekiah that he had not desisted from his determination to take the Judean capital. () Although they besieged Jerusalem, the biblical accounts state that the Assyrians did not so much as \"shoot an arrow there, ... nor cast up a siege rampart against it\", and that God sent out an angel who, in one night, struck down \"a hundred and eighty-five thousand in the camp of the Assyrians,\" sending Sennacherib back \"with shame of face to his own land\".\n\nSennacherib's inscriptions make no mention of the disaster suffered by his forces. But, as Professor Jack Finegan comments: \"In view of the general note of boasting which pervades the inscriptions of the Assyrian kings, ... it is hardly to be expected that Sennacherib would record such a defeat.\" The Cambridge Bible for Schools and Colleges refers to an \"Egyptian tradition, according to which Sennacherib had already reached Pelusium in Egypt, when in a single night his army was rendered helpless by a plague of field-mice which gnawed the bows of the soldiers and the thongs of their shields\". The version of the matter that Sennacherib presents, as found inscribed on what is known as the Sennacherib Prism preserved in the University of Chicago Oriental Institute, in part says: \"As to Hezekiah, the Jew, he did not submit to my yoke ... Hezekiah himself ... did send me, later, to Nineveh, my lordly city, together with 30 talents of gold, 800 talents of silver, ...\" This version inflates the number of silver talents sent from 300 to 800; but in other regards it confirms the biblical record and shows that Sennacherib made no claim that he captured Jerusalem. However, Sennacherib presents the matter of Hezekiah's paying tribute as having come after the Assyrian threat of a siege against Jerusalem, whereas the Bible states it was paid before.\n\nOf Sennacherib's death says\n\n\"It came about as he was worshiping in the house of Nisroch his god, that Adrammelech and Sharezer killed him [Sennacherib] with the sword; and they escaped into the land of Ararat. And Esarhaddon his son became king in his place.\"\n\nAccording to Assyrian records, Sennacherib was assassinated in 681 BC, twenty years after the 701 BC invasion of Judah. A Neo-Babylonian letter corroborates with the biblical account a sentiment from Sennacherib’s sons to assassinate him, an event Assyriologists have reconstructed as historical. The son Ardi-Mulishi, who is mentioned in the letter as killing anyone who would reveal his conspiracy, successfully murders his father in c. 681 BC, and was most likely the Adrammelech in 2 Kings, though Sharezer is not known elsewhere. Assyriologists posit the murder was motivated because Esarhaddon was chosen as heir to the throne instead of Ardi-Mulishi, the next eldest son. Assyrian and Hebrew biblical history corroborate that Esarhaddon ultimately did succeed the throne. Other Assyriologists assert that Sennacherib was murdered in revenge for his destruction of Babylon, a city sacred to all Mesopotamians, including the Assyrians.\n\nLater in his life, Hezekiah was ill with a boil or an inflammation which Isaiah initially thought would be fatal. The narrative of his sickness and miraculous recovery is found in , and . Various ambassadors came to congratulate him on his recovery, among them from Merodach-baladan, son of the king of Babylon, \"for he had heard that Hezekiah had been sick\". Hezekiah, his vanity flattered by the visit, showed the Babylonian embassy all the wealth, arms and stores of Jerusalem, revealing too much information to Baladan, king of Babylon (or perhaps boasting about his wealth): he was then confronted by Isaiah, who foretold that a future generation of the people of Judah would be taken as captives to Babylon. Hezekiah was reassured that his own lifetime would see peace and security.\n\nAccording to , Hezekiah lived another 15 years after praying to God. His son and successor, Manasseh, was born during this time: he was 12 years of age when he succeeded Hezekiah.\n\nAccording to the Talmud, the disease came about because of a dispute between him and Isaiah over who should pay whom a visit and over Hezekiah's refusal to marry and have children, although in the end he married Isaiah's daughter. Some Talmudists also considered that it might have come about as a way for Hezekiah to purge his sins or due to his arrogance in assuming his righteousness.\n\nExtra-biblical sources do much more for us than give us a pan-Mid Eastern picture into which we contextualize Hezekiah: there are extra-biblical sources that specify Hezekiah by name, along with his reign and influence. \"Historiographically, his reign is noteworthy for the convergence of a variety of biblical sources and diverse extrabiblical evidence often bearing on the same events. Significant data concerning Hezekiah appear in the Deuteronomistic History, the Chronicler, Isaiah, Assyrian annals and reliefs, Israelite epigraphy, and, increasingly, stratigraphy\". Archaeologist Amihai Mazar calls the tensions between Assyria and Judah \"one of the best-documented events of the Iron Age\" (172). Hezekiah's story is one of the best to cross-reference with the rest of the Mid Eastern world's historical documents.\n\nA seal impression dating back to 727–698 BCE, reading \"לחזקיהו [בן] אחז מלך יהדה\" \"Belonging to Hezekiah [son of] Ahaz king of Judah\" was uncovered in a dig at the Ophel in Jerusalem. The impression on this inscription was set in ancient Hebrew script.\n\nA lintel inscription, found over the doorway of a tomb, has been ascribed to his secretary, Shebnah ().\nLMLK stored jars along the border with Assyria \"demonstrate careful preparations to counter Sennacherib's likely route of invasion\" and show \"a notable degree of royal control of towns and cities which would facilitate Hezekiah's destruction of rural sacrificial sites and his centralization of worship in Jerusalem\". Evidence suggests they were used throughout his 29-year reign (Grena, 2004, p. 338). There are some Bullae from sealed documents that may have belonged to Hezekiah himself (Grena, 2004, p. 26, Figs. 9 and 10). There are also some that name his servants (\"ah-vah-deem\" in Hebrew, ayin-bet-dalet-yod-mem). In 2015 Eilat Mazar discovered a bulla that bears an inscription in ancient Hebrew script that translates as: \"Belonging to Hezekiah [son of] Ahaz king of Judah.\"This is the first seal impression of an Israelite or Judean king to come to light in a scientific archaeological excavation. Archaeological findings like the Hezekiah seal led scholars to surmise that the ancient Judahite kingdom had a highly developed administrative system. In 2018 Mazar published a report discussing the discovery of a bulla (a type of seal) which she says may have to have belonged to Isaiah. She believes the fragment to have been part of a seal whose complete text might have read \"Belonging to Isaiah the prophet.\" Several other biblical archaeologists, including George Washington University's Christopher Rollston have pointed to the bulla being incomplete, and the present inscription not enough to necessarily refer to the biblical figure.\nAccording to the work of archaeologists and philologists, the reign of Hezekiah saw a notable increase in the power of the Judean state. At this time Judah was the strongest nation on the Assyrian-Egyptian frontier. There were increases in literacy and in the production of literary works. The massive construction of the Broad Wall was made during his reign, the city was enlarged to accommodate a large influx, and population increased in Jerusalem up to 25,000, \"five times the population under Solomon.\" Archaeologist Amihai Mazar explains, \"Jerusalem was a virtual city-state where the majority of the state's population was concentrated,\" in comparison to the rest of Judah's cities (167). Archaeologist Israel Finkelstein says, \"The key phenomenon—which cannot be explained solely against the background of economic prosperity—was the sudden growth of the population of Jerusalem in particular, and of Judah in general\" (153). He says the cause of this growth must be a large influx of Israelites fleeing from the Assyrian destruction of the northern state. It is \"[t]he only reasonable way to explain this unprecedented demographic development\" (154). This, according to Finkelstein, set the stage for motivations to compile and reconcile Hebrew history into a text at that time (157). Mazar questions this explanation, since, he argues, it is \"no more than an educated guess\" (167).\n\nThe Siloam Tunnel was chiseled through 533 meters (1,750 feet) of solid rock in order to provide Jerusalem underground access to the waters of the Gihon Spring or Siloam Pool, which lay outside the city.\n\nThe Siloam Inscription from the Siloam Tunnel is now in the Istanbul Archaeology Museum. It \"commemorates the dramatic moment when the two original teams of tunnelers, digging with picks from opposite ends of the tunnel, met each other\" (564). It is \"[o]ne of the most important ancient Hebrew inscriptions ever discovered.\" Finkelstein and Mazar cite this tunnel as an example of Jerusalem's impressive state-level power at the time.\n\nArchaeologists like William G. Dever have pointed at archaeological evidence for the iconoclasm during the period of Hezekiah's reign. The central cult room of the temple at Arad (a royal Judean fortress) was deliberately and carefully dismantled, \"with the altars and massebot\" concealed \"beneath a Str. 8 plaster floor\". This stratum correlates with the late 8th century; Dever concludes that \"the deliberate dismantling of the temple and its replacement by another structure in the days of Hezekiah is an archeological fact. I see no reason for skepticism here.\"\n\nUnder Rehoboam, Lachish became the second most important city of the kingdom of Judah. During the revolt of king Hezekiah against Assyria, it was captured by Sennacherib despite determined resistance (see Siege of Lachish).\n\nAs the Lachish relief attests, Sennacherib began his siege of the city of Lachish in 701 BC. The Lachish Relief graphically depicts the battle, and the defeat of the city, including Assyrian archers marching up a ramp and Judahites pierced through on mounted stakes. \"The reliefs on these slabs\" discovered in the Assyrian palace at Nineveh \"originally formed a single, continuous work, measuring 8 feet ... tall by 80 feet ... long, which wrapped around the room\" (559). Visitors \"would have been impressed not only by the magnitude of the artwork itself but also by the magnificent strength of the Assyrian war machine.\"\n\nSennacherib's Prism was found buried in the foundations of the Nineveh palace. It was written in cuneiform, the Mesopotamian form of writing of the day. The prism records the conquest of 46 strong towns and \"uncountable smaller places,\" along with the siege of Jerusalem where Sennacherib says he just \"shut him up...like a bird in a cage,\" subsequently enforcing a larger tribute upon him.\n\nThe Hebrew Bible states that during the night, the angel of Jehovah (YHWH Hebrew) brought death to 185,000 Assyrians troops (), forcing the army to abandon the siege, yet it also records a tribute paid to Sennacherib of 300 silver talents following the siege. There is no account of the supernatural event in the prism. Sennacherib's account records his levying of a tribute from Hezekiah, the king of Judea, who was within Jerusalem, leaving the city as the only one intact following the exile of the northern ten-tribe kingdom of Israel due to idolatry. (2 Kings 17:22,23; 2 Kings 18:1-8) Sennacherib recorded a payment of 800 silver talents, which suggests a capitulation to end the siege. However, Inscriptions have been discovered describing Sennacherib’s defeat of the Ethiopian forces. These say: “As to Hezekiah, the Jew, he did not submit to my yoke, I laid siege to 46 of his strong cities . . . and conquered (them) . . . Himself I made a prisoner in Jerusalem, his royal residence, like a bird in a cage.” (Ancient Near Eastern Texts, p. 288) He does not claim to have captured the city. This is consistent with the Bible account of Hezekiah’s revolt against Assyria in the sense that neither account seems to indicate that Sennacherib ever entered or formally captured the city. Sennacherib in this inscription claims that Hezekiah paid for tribute 800 talents of silver, in contrast with the Bible’s 300, however this could be due to boastful exaggeration which was not uncommon amongst kings of the period. Furthermore, the annals record a list of booty sent from Jerusalem to Nineveh. In the inscription, Sennacherib claims that Hezekiah accepted servitude, and some theorize that Hezekiah remained on his throne as a vassal ruler. The campaign is recorded with differences in the Assyrian records and in the biblical Books of Kings; there is agreement that the Assyrian have a propensity for exaggeration.\n\nOne theory that takes the biblical view posits that a defeat was caused by \"possibly an outbreak of the bubonic plague\" (303). Another that this is a composite text which makes use of a 'legendary motif' analogous to that of the Exodus story.\n\n\nThe Talmud (Bava Batra 15a) credits Hezekiah with overseeing the compilation of the biblical books of Isaiah, Proverbs, Song of Songs and Ecclesiastes.\n\nAccording to Jewish tradition, the victory over the Assyrians and Hezekiah's return to health happened at the same time, the first night of Passover.\n\nThe Greek historian Herodotus (c. 484 BC – c. 425 BC) wrote of the invasion and acknowledges many Assyrian deaths, which he claims were the result of a plague of mice. The Jewish historian Josephus followed the writings of Herodotus. These historians record Sennacherib's failure to take Jerusalem is \"uncontested\".\n\nUnderstanding the biblically recorded sequence of events in Hezekiah's life as chronological or not is critical to the contextual interpretation of his reign. According to scholar Stephen L. Harris, chapter 20 of 2 Kings does not follow the events of chapters 18 and 19 (161). Rather, the Babylonian envoys precede the Assyrian invasion and siege. Chapter 20 would have been added during the exile, and Harris says it \"evidently took place before Sennacherib's invasion' when Hezekiah was \"trying to recruit Babylon as an ally against Assyria.' Consequently, \"Hezekiah ends his long reign impoverished and ruling over only a tiny scrap of his former domain.' Likewise, \"The Archaeological Study Bible\" says, \"The presence of these riches' that Hezekiah shows to the Babylonians \"indicates that this event took place before Hezekiah's payment of tribute to Sennacherib in 701 BC\" (564). Again, \"Though the king's illness and the subsequent Babylonian mission are described at the end of the accounts of his reign, they must have occurred before the war with Assyria. Thus, Isaiah's chastening of Hezekiah is due to his alliances made with other countries during the Assyrian conflict for insurance. To a reader who interprets the chapters chronologically, it would appear that Hezekiah ended his reign at a climax, but with a scholarly analysis, his end would contrarily be interpreted as a long fall from where he began.”\n\nThere has been considerable academic debate about the actual dates of reigns of the Israelite kings. Scholars have endeavored to synchronize the chronology of events referred to in the Hebrew Bible with those derived from other external sources. In the case of Hezekiah, scholars have noted that the apparent inconsistencies are resolved by accepting the evidence that Hezekiah, like his predecessors for four generations in the kings of Judah, had a coregency with his father, and this coregency began in 729 BC.\n\nAs an example of the reasoning that finds inconsistencies in calculations when coregencies are \"a priori\" ruled out, dates the fall of Samaria (the Northern Kingdom) to the 6th year of Hezekiah's reign. William F. Albright has dated the fall of the Kingdom of Israel to 721 BC, while E. R. Thiele calculates the date as 723 BC. If Abright's or Thiele's dating are correct, then Hezekiah's reign would begin in either 729 or 727 BC. On the other hand, states that Sennacherib invaded Judah in the 14th year of Hezekiah's reign. Dating based on Assyrian records date this invasion to 701 BC, and Hezekiah's reign would therefore begin in 716/715 BC. This dating would be confirmed by the account of Hezekiah's illness in chapter 20, which immediately follows Sennacherib's departure (). This would date his illness to Hezekiah's 14th year, which is confirmed by Isaiah's statement () that he will live fifteen more years (29 − 15 = 14). As shown below, these problems are all addressed by scholars who make reference to the ancient Near Eastern practice of coregency.\n\nFollowing the approach of Wellhausen, another set of calculations shows it is probable that Hezekiah did not ascend the throne before 722 BC. By Albright's calculations, Jehu's initial year is 842 BC; and between it and Samaria's destruction the \"Books of Kings\" give the total number of the years the kings of Israel ruled as 143 7/12, while for the kings of Judah the number is 165. This discrepancy, amounting in the case of Judah to 45 years (165–120), has been accounted for in various ways; but every one of those theories must allow that Hezekiah's first six years fell before 722 BC. (That Hezekiah began to reign before 722 BC, however, is entirely consistent with the principle that the Ahaz/Hezekiah coregency began in 729 BC.) Nor is it clearly known how old Hezekiah was when called to the throne, although states he was twenty-five years of age. His father died at the age of thirty-six (); it is not likely that Ahaz at the age of eleven should have had a son. Hezekiah's own son Manasseh ascended the throne twenty-nine years later, at the age of twelve. This places his birth in the seventeenth year of his father's reign, or gives Hezekiah's age as forty-two, if he was twenty-five at his ascension. It is more probable that Ahaz was twenty-one or twenty-five when Hezekiah was born (and suggesting an error in the text), and that the latter was thirty-two at the birth of his son and successor, Manasseh.\nSince Albright and Friedman, several scholars have explained these dating problems on the basis of a coregency between Hezekiah and his father Ahaz between 729 and 716/715 BC. Assyriologists and Egyptologists recognize that coregency was a practice both in Assyria and Egypt. After noting that coregencies were only used sporadically in the northern kingdom (Israel), Nadav Na'aman writes,\nIn the kingdom of Judah, on the other hand, the nomination of a co-regent was the common procedure, beginning from David who, before his death, elevated his son Solomon to the throne. When taking into account the permanent nature of the co-regency in Judah from the time of Joash, one may dare to conclude that dating the co-regencies accurately is indeed the key for solving the problems of biblical chronology in the eighth century BC.\"\n\nAmong the numerous scholars who have recognized the coregency between Ahaz and Hezekiah are Kenneth Kitchen in his various writings, Leslie McFall, and Jack Finegan. McFall, in his 1991 article, argues that if 729 BC (that is, the Judean regnal year beginning in Tishri of 729) is taken as the start of the Ahaz/Hezekiah coregency, and 716/715 BC as the date of the death of Ahaz, then all the extensive chronological data for Hezekiah and his contemporaries in the late eighth century BC are in harmony. Further, McFall found that no textual emendations are required among the numerous dates, reign lengths, and synchronisms given in the Hebrew Testament for this period. In contrast, those who do not accept the Ancient Near Eastern principle of coregencies require multiple emendations of the Scriptural text, and there is no general agreement on which texts should be emended, nor is there any consensus among these scholars on the resultant chronology for the eighth century BC. This is in contrast with the general consensus among those who accept the biblical and near Eastern practice of coregencies that Hezekiah was installed as coregent with his father Ahaz in 729 BC, and the synchronisms of 2 Kings 18 must be measured from that date, whereas the synchronisms to Sennacherib are measured from the sole reign starting in 716/715 BC. The two synchronisms to Hoshea of Israel in 2 Kings 18 are then in exact agreement with the dates of Hoshea's reign that can be determined from Assyrian sources, as is the date of Samaria's fall as stated in 2 Kings 18:10. An analogous situation of two ways of measurement, both equally valid, is encountered in the dates given for Jehoram of Israel, whose first year is synchronized to the 18th year of the sole reign of Jehoshaphat of Judah in 2 Kings 3:1 (853/852 BC), but his reign is also reckoned according to another method as starting in the second year of the coregency of Jehoshaphat and his son Jehoram of Judah (2 Kings 1:17); both methods refer to the same calendrical year.\n\nScholars who accept the principle of coregencies note that abundant evidence for their use is found in the biblical material itself. The agreement of scholarship built on these principles with both biblical and secular texts was such that the Thiele/McFall chronology was accepted as the best chronology for the kingdom period in Jack Finegan's encyclopedic \"Handbook of Biblical Chronology\".\n\n\n"}
{"id": "14006", "url": "https://en.wikipedia.org/wiki?curid=14006", "title": "Haemophilia", "text": "Haemophilia\n\nHaemophilia is a mostly inherited genetic disorder that impairs the body's ability to make blood clots, a process needed to stop bleeding. This results in people bleeding longer after an injury, easy bruising, and an increased risk of bleeding inside joints or the brain. Those with a mild case of the disease may have symptoms only after an accident or during surgery. Bleeding into a joint can result in permanent damage while bleeding in the brain can result in long term headaches, seizures, or a decreased level of consciousness.\nThere are two main types of haemophilia: haemophilia A, which occurs due to not enough clotting factor VIII, and haemophilia B, which occurs due to not enough clotting factor IX. They are typically inherited from one's parents through an X chromosome with a nonfunctional gene. Rarely a new mutation may occur during early development or haemophilia may develop later in life due to antibodies forming against a clotting factor. Other types include haemophilia C, which occurs due to not enough factor XI, and parahaemophilia, which occurs due to not enough factor V. Acquired haemophilia is associated with cancers, autoimmune disorders, and pregnancy. Diagnosis is by testing the blood for its ability to clot and its levels of clotting factors.\nPrevention may occur by removing an egg, fertilizing it, and testing the embryo before transferring it to the uterus. Treatment is by replacing the missing blood clotting factors. This may be done on a regular basis or during bleeding episodes. Replacement may take place at home or in hospital. The clotting factors are made either from human blood or by recombinant methods. Up to 20% of people develop antibodies to the clotting factors which makes treatment more difficult. The medication desmopressin may be used in those with mild haemophilia A. Studies of gene therapy are in early human trials.\nHaemophilia A affects about 1 in 5,000–10,000, while haemophilia B affects about 1 in 40,000, males at birth. As haemophilia A and B are both X-linked recessive disorders, females are rarely severely affected. Some females with a nonfunctional gene on one of the X chromosomes may be mildly symptomatic. Haemophilia C occurs equally in both sexes and is mostly found in Ashkenazi Jews. In the 1800s haemophilia was common within the royal families of Europe. The difference between haemophilia A and B was determined in 1952. The word is from the Greek \"haima\" αἷμα meaning blood and \"philia\" φιλία meaning love.\nCharacteristic symptoms vary with severity. In general symptoms are internal or external bleeding episodes, which are called \"bleeds\". People with more severe haemophilia suffer more severe and more frequent bleeds, while people with mild haemophilia usually suffer more minor symptoms except after surgery or serious trauma. In cases of moderate haemophilia symptoms are variable which manifest along a spectrum between severe and mild forms.\n\nIn both haemophilia A and B, there is spontaneous bleeding but a normal bleeding time, normal prothrombin time, normal thrombin time, but prolonged partial thromboplastin time. Internal bleeding is common in people with severe haemophilia and some individuals with moderate haemophilia. The most characteristic type of internal bleed is a joint bleed where blood enters into the joint spaces. This is most common with severe haemophiliacs and can occur spontaneously (without evident trauma). If not treated promptly, joint bleeds can lead to permanent joint damage and disfigurement. Bleeding into soft tissues such as muscles and subcutaneous tissues is less severe but can lead to damage and requires treatment.\n\nChildren with mild to moderate haemophilia may not have any signs or symptoms at birth especially if they do not undergo circumcision. Their first symptoms are often frequent and large bruises and haematomas from frequent bumps and falls as they learn to walk. Swelling and bruising from bleeding in the joints, soft tissue, and muscles may also occur. Children with mild haemophilia may not have noticeable symptoms for many years. Often, the first sign in very mild haemophiliacs is heavy bleeding from a dental procedure, an accident, or surgery. Females who are carriers usually have enough clotting factors from their one normal gene to prevent serious bleeding problems, though some may present as mild haemophiliacs.\n\nSevere complications are much more common in cases of severe and moderate haemophilia. Complications may arise from the disease itself or from its treatment:\nHaemophilic arthropathy is characterized by chronic proliferative synovitis and cartilage destruction. If an intra-articular bleed is not drained early, it may cause apoptosis of chondrocytes and affect the synthesis of proteoglycans. The hypertrophied and fragile synovial lining while attempting to eliminate excessive blood may be more likely to easily rebleed, leading to a vicious cycle of hemarthrosis-synovitis-hemarthrosis. In addition, iron deposition in the synovium may induce an inflammatory response activating the immune system and stimulating angiogenesis, resulting in cartilage and bone destruction.\n\nFemales possess two X-chromosomes, males have one X and one Y-chromosome. Since the mutations causing the disease are X-linked recessive, a female carrying the defect on one of her X-chromosomes may not be affected by it, as the equivalent allele on her other chromosome should express itself to produce the necessary clotting factors, due to X inactivation. However, the Y-chromosome in the male has no gene for factors VIII or IX. If the genes responsible for production of factor VIII or factor IX present on a male's X-chromosome are deficient there is no equivalent on the Y-chromosome to cancel it out, so the deficient gene is not masked and the disorder will develop.\n\nSince a male receives his single X-chromosome from his mother, the son of a healthy female silently carrying the deficient gene will have a 50% chance of inheriting that gene from her and with it the disease; and if his mother is affected with haemophilia, he will have a 100% chance of being a haemophiliac. In contrast, for a female to inherit the disease, she must receive two deficient X-chromosomes, one from her mother and the other from her father (who must therefore be a haemophiliac himself). Hence, haemophilia is expressed far more commonly among males than females, while double-X females are far more likely to be silent carriers, survive childhood and to submit each of her genetic children to an at least 50% risk of receiving the deficient gene. However, it is possible for female carriers to become mild haemophiliacs due to lyonisation (inactivation) of the X-chromosomes. Haemophiliac daughters are more common than they once were, as improved treatments for the disease have allowed more haemophiliac males to survive to adulthood and become parents. Adult females may experience menorrhagia (heavy periods) due to the bleeding tendency. The pattern of inheritance is criss-cross type. This type of pattern is also seen in colour blindness.\n\nA mother who is a carrier has a 50% chance of passing the faulty X-chromosome to her daughter, while an affected father will always pass on the affected gene to his daughters. A son cannot inherit the defective gene from his father. This is a recessive trait and can be passed on if cases are more severe with carrier. Genetic testing and genetic counselling is recommended for families with haemophilia. Prenatal testing, such as amniocentesis, is available to pregnant women who may be carriers of the condition.\n\nAs with all genetic disorders, it is of course also possible for a human to acquire it spontaneously through mutation, rather than inheriting it, because of a new mutation in one of their parents' gametes. Spontaneous mutations account for about 33% of all cases of haemophilia A. About 30% of cases of haemophilia B are the result of a spontaneous gene mutation.\n\nIf a female gives birth to a haemophiliac son, either the female is a carrier for the blood disorder or the haemophilia was the result of a spontaneous mutation. Until modern direct DNA testing, however, it was impossible to determine if a female with only healthy children was a carrier or not. Generally, the more healthy sons she bore, the higher the probability that she was not a carrier.\n\nIf a male is afflicted with the disease and has children with a female who is not a carrier, his daughters will be carriers of haemophilia. His sons, however, will not be affected with the disease. The disease is X-linked and the father cannot pass haemophilia through the Y-chromosome. Males with the disorder are then no more likely to pass on the gene to their children than carrier females, though all daughters they sire will be carriers and all sons they father will not have haemophilia (unless the mother is a carrier).\n\nThere are numerous different mutations which cause each type of haemophilia. Due to differences in changes to the genes involved, people with haemophilia often have some level of active clotting factor. Individuals with less than 1% active factor are classified as having severe haemophilia, those with 1-5% active factor have moderate haemophilia, and those with mild haemophilia have between 5-40% of normal levels of active clotting factor.\n\nHaemophilia can be diagnosed before, during or after birth if there is a family history of the condition. Several options are available to parents. If there is no family history of haemophilia, it is usually only diagnosed when a child begins to walk or crawl. They may experience joint bleeds or easy bruising.\n\nMild haemophilia may only be discovered later, usually after an injury or a dental or surgical procedure.\n\nGenetic testing and counselling are available to help determine the risk of passing the condition onto a child. This may involve testing a sample of tissue or blood to look for signs of the genetic mutation that causes haemophilia.\n\nA pregnant woman with a history of haemophilia in her family can test for the haemophilia gene. Such tests include:\nThere's a small risk of these procedures causing problems such as miscarriage or premature labour, so the woman may discuss this with the doctor in charge of her care.\n\nIf haemophilia is suspected after a child has been born, a blood test can usually confirm the diagnosis. Blood from the umbilical cord can be tested at birth if there's a family history of haemophilia. A blood test will also be able to identify whether a child has haemophilia A or B, and how severe it is.\n\nThere are several types of haemophilia: haemophilia A, haemophilia B, haemophilia C, \"parahaemophilia\", and \"acquired haemophilia A\".\n\nHaemophilia A, is a recessive X-linked genetic disorder resulting in a deficiency of functional clotting Factor VIII. Haemophilia B, is also a recessive X-linked genetic disorder involving a lack of functional clotting Factor IX. Haemophilia C, is an autosomal genetic disorder involving a lack of functional clotting Factor XI. Haemophilia C is not completely recessive, as heterozygous individuals also show increased bleeding.\n\nThe type of haemophilia known as \"parahaemophilia\" is a mild and rare form and is due to a deficiency in factor V. This type can be inherited or acquired.\n\nA non-genetic form of haemophilia is caused by autoantibodies against factor VIII and so is known as \"acquired haemophilia A\". Acquired haemophilia can be associated with cancers, autoimmune disorders and following childbirth.\n\nThere is no long-term cure. Treatment and prevention of bleeding episodes is done primarily by replacing the missing blood clotting factors. \n\nClotting factors are usually not needed in mild haemophilia. In moderate haemophilia clotting factors are typically only needed when bleeding occurs or to prevent bleeding with certain events. In severe haemophilia preventive use is often recommended two or three times a week and may continue for life. Rapid treatment of bleeding episodes decreases damage to the body.\n\nFactor VIII is used in haemophilia A and factor IX in haemophilia B. Factor replacement can be either isolated from human blood serum, recombinant, or a combination of the two. Some people develop antibodies (inhibitors) against the replacement factors given to them, so the amount of the factor has to be increased or non-human replacement products must be given, such as porcine factor VIII.\n\nIf a person becomes refractory to replacement coagulation factor as a result of high levels of circulating inhibitors, this may be partially overcome with recombinant human factor VII.\n\nIn early 2008, the US Food and Drug Administration (FDA) approved anti-haemophilic factor genetically engineered from the genes of Chinese hamster ovary cells. Since 1993 recombinant factor products (which are typically cultured in Chinese hamster ovary (CHO) tissue culture cells and involve little, if any human plasma products) have been available and have been widely used in wealthier western countries. While recombinant clotting factor products offer higher purity and safety, they are, like concentrate, extremely expensive, and not generally available in the developing world. In many cases, factor products of any sort are difficult to obtain in developing countries.\n\nClotting factors are either given preventively or on-demand. Preventive use involves the infusion of clotting factor on a regular schedule in order to keep clotting levels sufficiently high to prevent spontaneous bleeding episodes. On-demand (or episodic) treatment involves treating bleeding episodes once they arise. In 2007, a trial comparing on-demand treatment of boys (< 30 months) with haemophilia A with prophylactic treatment (infusions of 25 IU/kg body weight of Factor VIII every other day) in respect to its effect on the prevention of joint-diseases. When the boys reached 6 years of age, 93% of those in the prophylaxis group and 55% of those in the episodic-therapy group had a normal index joint-structure on MRI. Preventative treatment, however, resulted in average costs of $300,000 per year. The author of an editorial published in the same issue of the \"NEJM\" supports the idea that prophylactic treatment not only is more effective than on demand treatment but also suggests that starting after the first serious joint-related haemorrhage may be more cost effective than waiting until the fixed age to begin. Most haemophiliacs in third world countries have limited or no access to commercial blood clotting factor products.\n\nDesmopressin (DDAVP) may be used in those with mild haemophilia A. Tranexamic acid or epsilon aminocaproic acid may be given along with clotting factors to prevent breakdown of clots.\n\nPain medicines, steroids, and physical therapy may be used to reduce pain and swelling in an affected joint. In those with severe hemophilia A already receiving FVIII, emicizumab may provide some benefit.\n\nAnticoagulants such as heparin and warfarin are contraindicated for people with haemophilia as these can aggravate clotting difficulties. Also contraindicated are those drugs which have \"blood thinning\" side effects. For instance, medicines which contain aspirin, ibuprofen, or naproxen sodium should not be taken because they are well known to have the side effect of prolonged bleeding.\n\nAlso contraindicated are activities with a high likelihood of trauma, such as motorcycling and skateboarding. Popular sports with very high rates of physical contact and injuries such as American football, hockey, boxing, wrestling, and rugby should be avoided by people with haemophilia. Other active sports like soccer, baseball, and basketball also have a high rate of injuries, but have overall less contact and should be undertaken cautiously and only in consultation with a doctor.\n\nLike most aspects of the disorder, life expectancy varies with severity and adequate treatment. People with severe haemophilia who don't receive adequate, modern treatment have greatly shortened lifespans and often do not reach maturity. Prior to the 1960s when effective treatment became available, average life expectancy was only 11 years. By the 1980s the life span of the average haemophiliac receiving appropriate treatment was 50–60 years. Today with appropriate treatment, males with haemophilia typically have a near normal quality of life with an average lifespan approximately 10 years shorter than an unaffected male.\n\nSince the 1980s the primary leading cause of death of people with severe haemophilia has shifted from haemorrhage to HIV/AIDS acquired through treatment with contaminated blood products. The second leading cause of death related to severe haemophilia complications is intracranial haemorrhage which today accounts for one third of all deaths of people with haemophilia. Two other major causes of death include hepatitis infections causing cirrhosis and obstruction of air or blood flow due to soft tissue haemorrhage.\n\nHaemophilia is rare, with only about 1 instance in every 10,000 births (or 1 in 5,000 male births) for haemophilia A and 1 in 50,000 births for haemophilia B. About 18,000 people in the United States have haemophilia. Each year in the US, about 400 babies are born with the disorder. Haemophilia usually occurs in males and less often in females. It is estimated that about 2500 Canadians have haemophilia A, and about 500 Canadians have haemophilia B.\n\nThe first medical professional to describe the disease was Abulcasis. In the tenth century he described families whose males died of bleeding after only minor traumas. While many other such descriptive and practical references to the disease appear throughout historical writings, scientific analysis did not begin until the start of the nineteenth century.\n\nIn 1803, John Conrad Otto, a Philadelphian physician, wrote an account about \"a hemorrhagic disposition existing in certain families\" in which he called the affected males \"bleeders\". He recognised that the disorder was hereditary and that it affected mostly males and was passed down by healthy females. His paper was the second paper to describe important characteristics of an X-linked genetic disorder (the first paper being a description of colour blindness by John Dalton who studied his own family). Otto was able to trace the disease back to a woman who settled near Plymouth, NH in 1720. The idea that affected males could pass the trait onto their unaffected daughters was not described until 1813 when John F. Hay, published an account in The New England Journal of Medicine.\n\nIn 1924, a Finnish doctor discovered a hereditary bleeding disorder similar to haemophilia localised in the Åland Islands, southwest of Finland. This bleeding disorder is called \"Von Willebrand Disease\".\n\nThe term \"haemophilia\" is derived from the term \"haemorrhaphilia\" which was used in a description of the condition written by Friedrich Hopff in 1828, while he was a student at the University of Zurich. In 1937, Patek and Taylor, two doctors from Harvard, discovered anti-haemophilic globulin. In 1947, Pavlosky, a doctor from Buenos Aires, found haemophilia A and haemophilia B to be separate diseases by doing a lab test. This test was done by transferring the blood of one haemophiliac to another haemophiliac. The fact that this corrected the clotting problem showed that there was more than one form of haemophilia.\n\nHaemophilia has featured prominently in European royalty and thus is sometimes known as 'the royal disease'. Queen Victoria passed the mutation for haemophilia B to her son Leopold and, through two of her daughters, Alice and Beatrice, to various royals across the continent, including the royal families of Spain, Germany, and Russia. In Russia, Tsarevich Alexei, the son and heir of Tsar Nicholas II, famously suffered from haemophilia, which he had gotten from his mother, Empress Alexandra, one of Queen Victoria's granddaughters. The haemophilia of Alexei would result in the rise to prominence of the Russian mystic Grigori Rasputin, at the imperial court.\n\nIt was claimed that Rasputin was successful at treating Tsarevich Alexei's haemophilia. At the time, a common treatment administered by professional doctors was to use aspirin, which worsened rather than lessened the problem. It is believed that, by simply advising against the medical treatment, Rasputin could bring visible and significant improvement to the condition of Tsarevich Alexei.\n\nIn Spain, Queen Victoria's youngest daughter, Princess Beatrice, had a daughter Victoria Eugenie of Battenberg, who later became Queen of Spain. Two of her sons were haemophiliacs and both died from minor car accidents. Her eldest son, Prince Alfonso of Spain, Prince of Asturias, died at the age of 31 from internal bleeding after his car hit a telephone booth. Her youngest son, Infante Gonzalo, died at age 19 from abdominal bleeding following a minor car accident in which he and his sister hit a wall while avoiding a cyclist. Neither appeared injured or sought immediate medical care and Gonzalo died two days later from internal bleeding.\n\nUp until late-1985 many people with haemophilia received clotting factor products that posed a risk of HIV and hepatitis C infection, the plasma used to create the products was not screened or tested, neither had most of the products been subject to any form of viral inactivation.\n\nTens of thousands worldwide were infected as a result of contaminated factor products including more than 10,000 people in the United States, 3,500 British, 1,400 Japanese, 700 Canadians, 250 Irish, and 115 Iraqis.\n\nInfection via the tainted factor products had mostly stopped by 1986 by which time viral inactivation methods had largely been put into place, although some products were shown to still be dangerous in 1987.\n\nIn those with severe haemophilia, gene therapy may reduce symptoms to those that a mild or moderate person with haemophilia might have. The best results have been found in haemophilia B. In 2016 early stage human research was ongoing with a few sites recruiting participants. In 2017 a gene therapy trial on nine people with haemophilia A reported that high doses did better than low doses. It is not currently an accepted treatment for haemophilia.\n\n\n"}
{"id": "14008", "url": "https://en.wikipedia.org/wiki?curid=14008", "title": "Hickory (disambiguation)", "text": "Hickory (disambiguation)\n\nHickory is a type of tree (\"Carya\" species) found in North America and East Asia.\n\nHickory may also refer to:\n\n\n\n"}
{"id": "14009", "url": "https://en.wikipedia.org/wiki?curid=14009", "title": "Hemicellulose", "text": "Hemicellulose\n\nA hemicellulose (also known as polyose) is one of a number of heteropolymer (matrix polysaccharides), such as arabinoxylans, present along with cellulose in almost all terrestrial plant cell walls. While cellulose is crystalline, strong, and resistant to hydrolysis, hemicelluloses have random, amorphous structure with little strength. They are easily hydrolyzed by dilute acid or base as well as a myriad of hemicellulase enzymes.\n\nHemicelluloses include xylan, glucuronoxylan, arabinoxylan, glucomannan, and xyloglucan.\n\nHemicelluloses are often associated with cellulose, but these polysaccharides have different compositions. Hemicellulases contain many different sugar monomers, while cellulose only contains anhydrous glucose. For instance, besides glucose, sugar monomers in hemicelluloses can include xylose, mannose, galactose, rhamnose, and arabinose. Hemicelluloses contain most of the D-pentose sugars, and occasionally small amounts of L-sugars as well. Xylose is in most cases the sugar monomer present in the largest amount, although in softwoods mannose can be the most abundant sugar. Not only regular sugars can be found in hemicellulose, but also their acidified form, for instance glucuronic acid and galacturonic acid can be present. \n\nUnlike cellulose, hemicelluloses consist of shorter chains – 500–3,000 sugar units as opposed to 7,000–15,000 glucose molecules per polymer in cellulose. In addition, hemicellulose may be branched polymers, while cellulose is unbranched.\n\nHemicelluloses are embedded in the cell walls of plants, sometimes in chains that form a 'ground' – they bind with pectin to cellulose to form a network of cross-linked fibres.\n\nHemicelluloses are synthesised from sugar nucleotides in the cell's Golgi apparatus. Two models explain their synthesis: 1) a '2 component model' where modification occurs at two transmembrane proteins, and 2) a '1 component model' where modification occurs only at one transmembrane protein. After synthesis, hemicelluloses are transported to the plasma membrane via Golgi vesicles.\n\nAs percent content of hemicellulose increases in animal feed, the voluntary feed intake decreases.\n\nHemicellulose is represented by the difference between neutral detergent fiber (NDF) and acid detergent fiber (ADF).\n\nMicrofibrils are cross-linked together by hemicellulose homopolymers. Lignins assist and strengthen the attachment of hemicelluloses to microfibrils.\n\nHemicellulose found in hardwood trees is predominantly xylan with some glucomannan, while in softwoods it is mainly rich in galactoglucomannan and contains only a small amount of xylan. The average molecular weight is lower than that of cellulose at less than 30,000, as opposed to the 100,000 average molecular weight reported for cellulose.\n\n\n"}
{"id": "14011", "url": "https://en.wikipedia.org/wiki?curid=14011", "title": "Hillbilly", "text": "Hillbilly\n\n\"Hillbilly\" is a term (often derogatory) for people who dwell in rural, mountainous areas in the United States, primarily in Appalachia and the Ozarks.\nThe first known instances of \"hillbilly\" in print were in \"The Railroad Trainmen's Journal\" (vol. ix, July 1892), an 1899 photograph of men and women in West Virginia labeled \"Camp Hillbilly\", and a 1900 \"New York Journal\" article containing the definition: \"a Hill-Billie is a free and untrammeled white citizen of Tennessee, who lives in the hills, has no means to speak of, dresses as he can, talks as he pleases, drinks whiskey when he gets it, and fires off his revolver as the fancy takes him\". The stereotype is twofold in that it incorporates both positive and negative traits: \"Hillbillies\" are often considered independent and self-reliant individuals who resist the modernization of society, but at the same time they are also defined as backward and violent. Scholars argue this duality is reflective of the split ethnic identities in white America.\n\nThe Appalachian Mountains were settled in the 18th century by settlers primarily from the Province of Ulster in Ireland. The settlers from Ulster were mainly Protestants who migrated to Ireland, during the Plantation of Ulster in the 17th century, from Scotland and Northern England. Many further migrated to the American colonies beginning in the 1730s, and in America became known as the Scots-Irish. \n\nScholars argue that the term \"hillbilly\" originated from Scottish dialect. The term \"hill-folk\" referred to people who preferred isolation from the greater society, and \"billy\" meant \"comrade\" or \"companion\". It is suggested that \"hill-folk\" and \"billie\" were combined when the Cameronians fled to the Scottish Highlands. There is also the belief that most of the settlers from Scotland and northern Ireland were followers of king William of Orange. The nick name for William is Billy. For the people who settle in America in the hills and who were Williamites, the term hillbilly connects both people who live in the hills and who are supporters of king William of Orange's ideologies. \n\nIn 17th century Ireland, during the Williamite War, when Protestant supporters of King William III (\"King Billy\") were often referred to as \"Billy's Boys\". However, some scholars disagree with this theory. Michael Montgomery's \"From Ulster to America: The Scotch-Irish Heritage of American English\" states, \"In Ulster in recent years it has sometimes been supposed that it was coined to refer to followers of King William III and brought to America by early Ulster emigrants, but this derivation is almost certainly incorrect. ... In America \"hillbilly\" was first attested only in 1898, which suggests a later, independent development.\"\n\nThe term \"hillbilly\" spread in the years following the American Civil War. At this time, the country was developing both technologically and socially, but the Appalachian region was falling behind. Before the war, Appalachia was not distinctively different from other rural areas of the country. Post-war, although the frontier pushed farther west, the region maintained frontier characteristics. Appalachians themselves were perceived as backward, quick to violence and inbred in their isolation. Fueled by news stories of mountain feuds such as that in the 1880s between the Hatfields and McCoys, the hillbilly stereotype developed in the late 19th to early 20th century.\n\nThe \"classic\" hillbilly stereotype reached its current characterization during the years of the Great Depression, when many mountaineers left their homes to find work in other areas of the country. The period of Appalachian out-migration, roughly from the 1930s through the 1950s, saw many mountain residents moving North to the Midwestern industrial cities of Chicago, Cleveland, Akron, and Detroit. \n\nThis movement North, which became known as the \"Hillbilly Highway\", brought these previously isolated communities into mainstream United States culture. In response, poor white mountaineers became central characters in newspapers, pamphlets, and eventually, motion pictures. Authors at the time were inspired by historical figures such as Davy Crockett and Daniel Boone. The mountaineer image transferred over to the 20th century where the \"hillbilly\" stereotype emerged.\n\nPop culture has perpetuated the \"hillbilly\" stereotype. Scholarly works suggest that the media has exploited both the Appalachian region and people by classifying them as \"hillbillies\". These generalizations do not match the cultural experiences of Appalachians. Appalachians, like many other groups, do not subscribe to a single identity. One of the issues associated with stereotyping is that it is profitable. When \"hillbilly\" became a widely used term, entrepreneurs saw a window for potential revenue. They \"recycled\" the image and brought it to life through various forms of media.\n\nTelevision and film have portrayed \"hillbillies\" in both derogatory and sympathetic terms. Films such as \"Sergeant York\" or the Ma and Pa Kettle series portrayed the \"hillbilly\" as wild but good-natured. Television programs of the 1960s such as \"The Real McCoys\", \"The Andy Griffith Show\", and especially \"The Beverly Hillbillies\", portrayed the \"hillbilly\" as backwards but with enough wisdom to outwit more sophisticated city folk. \"Gunsmoke\" Festus Haggen was portrayed as intelligent and quick-witted (but lacking \"education\"). The popular 1970s television variety show \"Hee Haw\" regularly lampooned the stereotypical \"hillbilly\" lifestyle. A darker image of the hillbilly is found in the film \"Deliverance\" (1972), based on a novel by James Dickey which depicted some \"hillbillies\" as genetically deficient, inbred, and murderous, while depicting others as helpful, friendly, and smart.\n\n\"Hillbillies\" were at the center of reality television in the 21st century. Network television shows such as \"New Beverly Hillbillies\", \"High Life\", and \"The Simple Life\" displayed the \"hillbilly\" lifestyle for viewers in the United States. This sparked protests across the country with rural-minded individuals gathering to fight the stereotype. The Center for Rural Strategies started a nationwide campaign stating the stereotype was \"politically incorrect\". The Kentucky-based organization engaged political figures in the movement such as Robert Byrd and Mike Huckabee. Both protestors argued that the discrimination of any other group in United States would not be tolerated, so neither should the discrimination against rural U.S. citizens. A 2003 piece published by \"The Cincinnati Enquirer\" read, \"In this day of hypersensitivity to diversity and political correctness, Appalachians have been a group that it is still socially acceptable to demean and joke about. ... But rural folks have spoken up and said 'enough' to the Hollywood mockers.\"\n\n\"\" (2016) is a memoir by J. D. Vance about the Appalachian values of his upbringing and their relationship to the social problems of his hometown, Middletown, Ohio. The book topped \"The New York Times\" Best Seller list in August 2016.\n\nA family of \"Hill People\", who are employed as migrant workers on a farm in 1952 Arkansas, have a major role in John Grisham's book \"A Painted House\", with Grisham trying to avoid sterotypes.\n\n\"Hillbilly music\" was at one time considered an acceptable label for what is now known as country music. The label, coined in 1925 by country pianist Al Hopkins, persisted until the 1950s.\n\nThe \"hillbilly music\" categorization covers a wide variety of musical genres including bluegrass, country, western, and gospel. Appalachian folk song existed long before the \"hillbilly\" label. When the commercial industry was combined with \"traditional Appalachian folksong\", \"hillbilly music\" was formed. Some argue this is a \"High Culture\" issue where sophisticated individuals may see something considered \"unsophisticated\" as \"trash\".\n\nIn the early-20th century, artists began to utilize the \"hillbilly\" label. The term gained momentum due to Ralph Peer, the recording director of OKeh Records, who heard it being used among Southerners when he went down to Virginia to record the music and labeled all Southern country music as so from then on. The York Brothers entitled one of their songs \"Hillbilly Rose\" and the Delmore Brothers followed with their song \"Hillbilly Boogie\". In 1927, the Gennett studios in Richmond, Indiana, made a recording of black fiddler Jim Booker. The recordings were labeled \"made for Hillbilly\" in the Gennett files and were marketed to a white audience. Columbia Records had much success with the \"Hill Billies\" featuring Al Hopkins and Fiddlin' Charlie Bowman.\n\nBy the late-1940s, radio stations started to use the \"hillbilly music\" label. Originally, \"hillbilly\" was used to describe fiddlers and string bands, but now it was used to describe traditional Appalachian music. Appalachians had never used this term to describe their own music. Popular songs whose style bore characteristics of both hillbilly and African American music were referred to as \"hillbilly boogie\" and \"rockabilly\". Elvis Presley was a prominent player of rockabilly and was known early in his career as the \"Hillbilly Cat\".\n\nWhen the Country Music Association was founded in 1958, the term \"hillbilly music\" gradually fell out of use. The music industry merged hillbilly music, Western swing, and Cowboy music, to form the current category C&W, Country and Western.\n\nSome artists (notably Hank Williams) and fans were offended by the \"hillbilly music\" label. While the term is not used as frequently today, it is still used on occasion to refer to old-time music or bluegrass. For example, WHRB broadcasts a popular weekly radio show entitled \"Hillbilly at Harvard\". The show is devoted to playing a mix of old-time music, bluegrass, and traditional country and western.\n\nThe hillbilly stereotype is considered to have had a traumatizing effect on some in the Appalachian region. Feelings of shame, self-hatred, and detachment are cited as a result of \"culturally transmitted traumatic stress syndrome\". Appalachian scholars say that the large-scale stereotyping has rewritten Appalachian history, making Appalachians feel particularly vulnerable. \"Hillbilly\" has now become part of Appalachian identity and some Appalachians feel they are constantly defending themselves against this image.\n\nThe stereotyping also has political implications for the region. There is a sense of \"perceived history\" that prevents many political issues from receiving adequate attention. Appalachians are often blamed for economic struggles. \"Moonshiners, welfare cheats, and coal miners\" are stereotypes stemming from the greater hillbilly stereotype in the region. This prejudice has been said to serve as a barrier for addressing some serious issues such as the economy and the environment.\n\nDespite the political and social difficulties associated with stereotyping, Appalachians have organized to enact change. The War on Poverty is sometimes considered to be an example of one effort that allowed for Appalachian community organization. Grassroots movements, protests, and strikes are common in the area, though not always successful.\n\nThe Springfield, Missouri Chamber of Commerce once presented dignitaries visiting the city with an \"Ozark Hillbilly Medallion\" and a certificate proclaiming the honoree a \"hillbilly of the Ozarks\". On June 7, 1952, President Harry S. Truman received the medallion after a breakfast speech at the Shrine Mosque for the 35th Division Association. Other recipients included US Army generals Omar Bradley and Matthew Ridgway, J. C. Penney, Johnny Olsen and Ralph Story.\n\nHillbilly Days is an annual festival held in mid-April in Pikeville, Kentucky celebrating the best of Appalachian culture. The event began by local Shriners as a fundraiser to support the Shriners Children's Hospital. It has grown since its beginning in 1976 and now is the second largest festival held in the state of Kentucky. Artists and craftspeople showcase their talents and sell their works on display. Nationally renowned musicians as well as the best of the regional mountain musicians share six different stages located throughout the downtown area of Pikeville. Aspiring hillbillies from across the nation compete to come up with the wildest Hillbilly outfit. The event has earned its name as the Mardi Gras of the Mountains. Fans of \"mountain music\" come from around the United States to hear this annual concentrated gathering of talent. Some refer to this event as the equivalent of a \"Woodstock\" for mountain music.\n\nThe term \"Hillbilly\" is used with pride by a number of people within the region as well as famous persons, such as singer Dolly Parton, chef Sean Brock, and actress Minnie Pearl. Positive self-identification with the term generally includes identification with a set of \"hillbilly values\" including love and respect for nature, strong work ethic, generosity toward neighbors and those in need, family ties, self-reliance, resiliency, and a simple lifestyle.\n\n"}
{"id": "14012", "url": "https://en.wikipedia.org/wiki?curid=14012", "title": "Host", "text": "Host\n\nHost (masculine) and hostess (feminine) most often refer to a person responsible for guests at an event or providing hospitality during it.\n\nHost may also refer to:\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "14013", "url": "https://en.wikipedia.org/wiki?curid=14013", "title": "Hernán Cortés", "text": "Hernán Cortés\n\nHernán Cortés de Monroy y Pizarro Altamirano, Marquis of the Valley of Oaxaca (; ; 1485 – December 2, 1547) was a Spanish \"Conquistador\" who led an expedition that caused the fall of the Aztec Empire and brought large portions of what is now mainland Mexico under the rule of the King of Castile in the early 16th century. Cortés was part of the generation of Spanish colonizers who began the first phase of the Spanish colonization of the Americas.\n\nBorn in Medellín, Spain, to a family of lesser nobility, Cortés chose to pursue adventure and riches in the New World. He went to Hispaniola and later to Cuba, where he received an \"encomienda\" (the right to the labor of certain subjects). For a short time, he served as \"alcalde\" (magistrate) of the second Spanish town founded on the island. In 1519, he was elected captain of the third expedition to the mainland, an expedition which he partly funded. His enmity with the Governor of Cuba, Diego Velázquez de Cuéllar, resulted in the recall of the expedition at the last moment, an order which Cortés ignored.\n\nArriving on the continent, Cortés executed a successful strategy of allying with some indigenous people against others. He also used a native woman, Doña Marina, as an interpreter. She later bore his first son. When the Governor of Cuba sent emissaries to arrest Cortés, he fought them and won, using the extra troops as reinforcements. Cortés wrote letters directly to the king asking to be acknowledged for his successes instead of being punished for mutiny. After he overthrew the Aztec Empire, Cortés was awarded the title of \"Marqués del Valle de Oaxaca\", while the more prestigious title of Viceroy was given to a high-ranking nobleman, Antonio de Mendoza. In 1541 Cortés returned to Spain, where he died six years later of natural causes but embittered.\n\nBecause of the controversial undertakings of Cortés and the scarcity of reliable sources of information about him, it is difficult to describe his personality or motivations. Early lionizing of the conquistadors did not encourage deep examination of Cortés. Later reconsideration of the conquistadors in the context of modern anti-colonial sentiment has done little to enlarge understanding of Cortés. As a result of these historical trends, descriptions of Cortés tend to be simplistic, and either damning or idealizing.\n\nCortés himself used the form \"Hernando\" or \"Fernando\" for his given name, as seen in his signature and the title of an early portrait. William Hickling Prescott's \"Conquest of Mexico\" (1843) also refers to him as Hernando Cortés. At some point writers began using the shortened form of \"Hernán\" more generally.\n\nCortés was born in 1485 in the town of Medellín, in modern-day Extremadura, Spain. His father, Martín Cortés de Monroy, born in 1449 to Rodrigo or Ruy Fernández de Monroy and his wife María Cortés, was an infantry captain of distinguished ancestry but slender means. Hernán's mother was Catalína Pizarro Altamirano.\n\nThrough his mother, Hernán was second cousin once removed of Francisco Pizarro, who later conquered the Inca Empire of modern-day Peru, and not to be confused with another Francisco Pizarro, who joined Cortés to conquer the Aztecs. (His maternal grandmother, Leonor Sánchez Pizarro Altamirano, was first cousin of Pizarro's father Gonazalo Pizarro y Rodriguez.) Through his father, Hernán was related to Nicolás de Ovando, the third Governor of Hispaniola. His paternal great-grandfather was Rodrigo de Monroy y Almaraz, 5th Lord of Monroy.\n\nAccording to his biographer, chaplain, and friend Francisco López de Gómara, Cortés was pale and sickly as a child. At the age of 14, he was sent to study Latin under an uncle in Salamanca. Modern historians have misconstrued this personal tutoring as time enrolled at the University of Salamanca.\n\nAfter two years, Cortés returned home to Medellín, much to the irritation of his parents, who had hoped to see him equipped for a profitable legal career. However, those two years at Salamanca, plus his long period of training and experience as a notary, first in Valladolid and later in Hispaniola, gave him knowledge of the legal codes of Castile that he applied to help justify his unauthorized conquest of Mexico.\n\nAt this point in his life, Cortés was described by Gómara as ruthless, haughty, and mischievous. The 16-year-old youth had returned home to feel constrained life in his small provincial town. By this time, news of the exciting discoveries of Christopher Columbus in the New World was streaming back to Spain.\n\nPlans were made for Cortés to sail to the Americas with a family acquaintance and distant relative, Nicolás de Ovando, the newly appointed Governor of Hispaniola. (This island is now divided between Haiti and the Dominican Republic). Cortés suffered an injury and was prevented from traveling. He spent the next year wandering the country, probably spending most of his time in Spain's southern ports of Cadiz, Palos, Sanlucar, and Seville. He finally left for Hispaniola in 1504 and became a colonist.\n\nCortés reached Hispaniola in a ship commanded by Alonso Quintero, who tried to deceive his superiors and reach the New World before them in order to secure personal advantages. Quintero's mutinous conduct may have served as a model for Cortés in his subsequent career. The history of the conquistadores is rife with accounts of rivalry, jockeying for positions, mutiny, and betrayal.\n\nUpon his arrival in 1504 in Santo Domingo, the capital of Hispaniola, the 18-year-old Cortés registered as a citizen; this entitled him to a building plot and land to farm. Soon afterward, Governor Nicolás de Ovando granted him an \"encomienda\" and appointed him as a notary of the town of Azua de Compostela. His next five years seemed to help establish him in the colony; in 1506, Cortés took part in the conquest of Hispaniola and Cuba. The expedition leader awarded him a large estate of land and Indian slaves for his efforts.\n\nIn 1511, Cortés accompanied Diego Velázquez de Cuéllar, an aide of the Governor of Hispaniola, in his expedition to conquer Cuba. Velázquez was appointed Governor of New Spain. At the age of 26, Cortés was made clerk to the treasurer with the responsibility of ensuring that the Crown received the \"quinto\", or customary one fifth of the profits from the expedition.\n\nVelázquez was so impressed with Cortés that he secured a high political position for him in the colony. He became secretary for Governor Velázquez. Cortés was twice appointed municipal magistrate (\"alcalde\") of Santiago. In Cuba, Cortés became a man of substance with an \"encomienda\" to provide Indian labor for his mines and cattle. This new position of power also made him the new source of leadership, which opposing forces in the colony could then turn to. In 1514, Cortés led a group which demanded that more Indians be assigned to the settlers.\n\nAs time went on, relations between Cortés and Governor Velázquez became strained. This began once news reached Velázquez that Juan de Grijalva had established a colony on the mainland where there was a bonanza of silver and gold, and Velázquez decided to send him help. Cortés was appointed Captain-General of this new expedition in October 1518, but was advised to move fast before Velázquez changed his mind.\n\nWith Cortés' experience as an administrator, knowledge gained from many failed expeditions, and his impeccable rhetoric he was able to gather six ships and 300 men, within a month. Velázquez's jealousy exploded and he decided to put the expedition in other hands. However, Cortés quickly gathered more men and ships in other Cuban ports.\n\nCortés also found time to become romantically involved with Catalina Xuárez (or Juárez), the sister-in-law of Governor Velázquez. Part of Velázquez's displeasure seems to have been based on a belief that Cortés was trifling with Catalina's affections. Cortés was temporarily distracted by one of Catalina's sisters but finally married Catalina, reluctantly, under pressure from Governor Velázquez. However, by doing so, he hoped to secure the good will of both her family and that of Velázquez.\n\nIt was not until he had been almost 15 years in the Indies that Cortés began to look beyond his substantial status as mayor of the capital of Cuba and as a man of affairs in the thriving colony. He missed the first two expeditions, under the orders of Francisco Hernández de Córdoba and then Juan de Grijalva, sent by Diego Velázquez to Mexico in 1518.\n\nThere are differing perceptions about what happened to Hernán Cortés's ships. Some think that he burned the vessels, and others believe he beached them. The notion that he burned his ships did not become accepted until 250 years later. However, Bernal Díaz del Castillo, while attending an expedition with Cortés, gives reason to believe that Cortés ran them ashore. In a letter to King Charles, Cortés states that his ships were incapable of sailing, telling his men the reason was shipworm. However, after establishing the town of Vera Cruz, five Aztec emissaries arrived which made Cortés anxious to visit Tenochtitlán. Therefore, he destroyed all of his ships but one, which he sent back to Spain for King Charles. The fear of his men returning to Cuba, rather than embarking on the journey to the Aztec Empire, made him decide to demolish his ships. They no longer had an option but to accompany him on this journey. This decision brought about severe consequences because Cortés had trapped himself in Mexico.\n\nCortés created strife between his men and the Aztecs by taking over the city. However, worried his men would revolt, Montezuma decided to convince them to delay the attack. Cortés now had time to build more ships, but he had to stay on guard against the Aztecs because he was unable to leave Mexico. Furthermore, Velázquez was sending forces to arrest Cortés, which meant the lives of him and his men were at jeopardy. Still without ships, Cortés could not escape. This resulted in him fighting the battle at Cempoala. In addition to restraining himself in Mexico, Cortés also suffered financially. He had to repay Velázquez for the ships he destroyed. \n\nThroughout his journey, Cortés had written five letters to King Charles. He wanted to relieve himself from Velázquez's authority; therefore, Cortés bribed the King through sending him treasures. However, Velázquez did not respond well. He and his men convinced King Charles to revoke Cortés's position as governor. While King Charles forgave Cortés, he did receive punishment. Cortés was promoted to captain-general and given the title of Marquis, but he was not allowed to reclaim his governorship or return to New Spain.\n\nIn 1518, Velázquez put Cortés in command of an expedition to explore and secure the interior of Mexico for colonization. At the last minute, due to the old argument between the two, Velázquez changed his mind and revoked Cortés's charter. He ignored the orders and, in an act of open mutiny, went anyway in February 1519. He stopped in Trinidad, Cuba, to hire more soldiers and obtain more horses. Accompanied by about 11 ships, 500 men (including seasoned slaves), 13 horses, and a small number of cannon, Cortés landed on the Yucatan Peninsula in Mayan territory. There he encountered Geronimo de Aguilar, a Spanish Franciscan priest who had survived a shipwreck followed by a period in captivity with the Maya, before escaping. Aguilar had learned the Chontal Maya language and was able to translate for Cortés.\n\nIn March 1519, Cortés formally claimed the land for the Spanish crown. Then he proceeded to Tabasco, where he met with resistance and won a battle against the natives. He received twenty young indigenous women from the vanquished natives, and he converted them all to Christianity.\n\nAmong these women was La Malinche, his future mistress and mother of his son Martín. Malinche knew both the Nahuatl language and Chontal Maya, thus enabling Cortés to communicate with the Aztecs through Aguilar. At San Juan de Ulúa on Easter Sunday 1519, Cortés met with Moctezuma II's Aztec Empire governors Tendile and Pitalpitoque.\nIn July 1519, his men took over Veracruz. By this act, Cortés dismissed the authority of the Governor of Cuba to place himself directly under the orders of King Charles. In order to eliminate any ideas of retreat, Cortés scuttled his ships.\n\nIn Veracruz, he met some of the tributaries of the Aztecs and asked them to arrange a meeting with Moctezuma II, the \"tlatoani\" (ruler) of the Aztec Empire. Moctezuma repeatedly turned down the meeting, but Cortés was determined. Leaving a hundred men in Veracruz, Cortés marched on Tenochtitlan in mid-August 1519, along with 600 soldiers, 15 horsemen, 15 cannons, and hundreds of indigenous carriers and warriors.\n\nOn the way to Tenochtitlan, Cortés made alliances with indigenous peoples such as the Totonacs of Cempoala and the Nahuas of Tlaxcala. The Otomis initially, and then the Tlaxcalans fought with the Spanish in a series of three battles from 2 to 5 September 1519, and at one point, Diaz remarked, \"they surrounded us on every side\". After Cortés continued to release prisoners with messages of peace, and realizing the Spanish were enemies of Moctezuma, Xicotencatl the Elder and Maxixcatzin persuaded the Tlaxcalan warleader, Xicotencatl the Younger, that it would be better to ally with the newcomers than to kill them.\n\nIn October 1519, Cortés and his men, accompanied by about 1,000 Tlaxcalteca, marched to Cholula, the second largest city in central Mexico. Cortés, either in a pre-meditated effort to instill fear upon the Aztecs waiting for him at Tenochtitlan or (as he later claimed, when he was being investigated) wishing to make an example when he feared native treachery, massacred thousands of unarmed members of the nobility gathered at the central plaza, then partially burned the city.\nBy the time he arrived in Tenochtitlan the Spaniards had a large army. On November 8, 1519, they were peacefully received by Moctezuma II. Moctezuma deliberately let Cortés enter the Aztec capital, the island city of Tenochtitlan, hoping to get to know their weaknesses better and to crush them later.\n\nMoctezuma gave lavish gifts of gold to the Spaniards which, rather than placating them, excited their ambitions for plunder. In his letters to King Charles, Cortés claimed to have learned at this point that he was considered by the Aztecs to be either an emissary of the feathered serpent god Quetzalcoatl or Quetzalcoatl himself – a belief which has been contested by a few modern historians. But quickly Cortés learned that several Spaniards on the coast had been killed by Aztecs while supporting the Totonacs, and decided to take Moctezuma as a hostage in his own palace, indirectly ruling Tenochtitlán through him.\n\nMeanwhile, Velázquez sent another expedition, led by Pánfilo de Narváez, to oppose Cortés, arriving in Mexico in April 1520 with 1,100 men. Cortés left 200 men in Tenochtitlan and took the rest to confront Narváez. He overcame Narváez, despite his numerical inferiority, and convinced the rest of Narváez's men to join him. In Mexico, one of Cortés's lieutenants Pedro de Alvarado, committed the \"massacre in the Great Temple\", triggering a local rebellion.\n\nCortés speedily returned to Tenochtitlán. On July 1, 1520 Moctezuma was killed (the Spaniards claimed he was stoned to death by his own people; others claim he was murdered by the Spanish once they realized his inability to placate the locals). Faced with a hostile population, Cortés decided to flee for Tlaxcala. During the \"Noche Triste\" (June 30 – July 1, 1520), the Spaniards managed a narrow escape from Tenochtitlan across the Tlacopan causeway, while their rearguard was being massacred. Much of the treasure looted by Cortés was lost (as well as his artillery) during this panicked escape from Tenochtitlán.\n\nAfter a battle in Otumba, they managed to reach Tlaxcala, having lost 870 men. With the assistance of their allies, Cortés's men finally prevailed with reinforcements arriving from Cuba. Cortés began a policy of attrition towards Tenochtitlan, cutting off supplies and subduing the Aztecs' allied cities. The siege of Tenochtitlán ended with Spanish victory and the destruction of the city.\n\nIn January 1521, Cortés countered a conspiracy against him, headed by Antonio de Villafana, who was hanged for the offense. Finally, with the capture of Cuauhtémoc, the \"tlatoani\" (ruler) of Tenochtitlán, on August 13, 1521, the Aztec Empire was captured, and Cortés was able to claim it for Spain, thus renaming the city Mexico City. From 1521 to 1524, Cortés personally governed Mexico.\n\nMany historical sources have conveyed an impression that Cortés was unjustly treated by the Spanish Crown, and that he received nothing but ingratitude for his role in establishing New Spain. This picture is the one Cortés presents in his letters and in the later biography written by Francisco López de Gómara. However, there may be more to the picture than this. Cortés's own sense of accomplishment, entitlement, and vanity may have played a part in his deteriorating position with the king:\n\nKing Charles appointed Cortés as governor, captain general and chief justice of the newly conquered territory, dubbed \"New Spain of the Ocean Sea\". But also, much to the dismay of Cortés, four royal officials were appointed at the same time to assist him in his governing – in effect, submitting him to close observation and administration. Cortés initiated the construction of Mexico City, destroying Aztec temples and buildings and then rebuilding on the Aztec ruins what soon became the most important European city in the Americas.\n\nCortés managed the founding of new cities and appointed men to extend Spanish rule to all of New Spain, imposing the \"encomienda\" system in 1524. He reserved many encomiendas for himself and for his retinue, which they considered just rewards for their accomplishment in conquering central Mexico. However, later arrivals and members of factions antipathetic to Cortés complained of the favoritism that excluded them.\nIn 1523, the Crown (possibly influenced by Cortés's enemy, Bishop Fonseca), sent a military force under the command of Francisco de Garay to conquer and settle the northern part of Mexico, the region of Pánuco. This was another setback for Cortés who mentioned this in his fourth letter to the King in which he describes himself as the victim of a conspiracy by his archenemies Diego Velázquez de Cuéllar, Diego Columbus and Bishop Fonseca as well as Francisco Garay. The influence of Garay was effectively stopped by this appeal to the King who sent out a decree forbidding Garay to interfere in the politics of New Spain, causing him to give up without a fight.\n\nAlthough Cortés had flouted the authority of Diego Velázquez in sailing to the mainland and then leading an expedition of conquest, Cortés's spectacular success was rewarded by the crown with a coat of arms, a mark of high honor, following the conqueror's request. The document granting the coat of arms summarizes Cortés's accomplishments in the conquest of Mexico. The proclamation of the king says in part:\n\nWe, respecting the many labors, dangers, and adventures which you underwent as stated above, and so that there might remain a perpetual memorial of you and your services and that you and your descendants might be more fully honored ... it is our will that besides your coat of arms of your lineage, which you have, you may have and bear as your coat of arms, known and recognized, a shield ...\n\nThe grant specifies the iconography of the coat of arms, the central portion divided into quadrants. In the upper portion, there is a \"black eagle with two heads on a white field, which are the arms of the empire\". Below that is a \"golden lion on a red field, in memory of the fact that you, the said Hernando Cortés, by your industry and effort brought matters to the state described above\" (i.e., the conquest). The specificity of the other two quadrants is linked directly to Mexico, with one quadrant showing three crowns representing the three Aztec emperors of the conquest era, Moctezuma, Cuitlahuac, and Cuauhtemoc and the other showing the Aztec capital of Tenochtitlan. Encircling the central shield are symbols of the seven city-states around the lake and their lords that Cortés defeated, with the lords \"to be shown as prisoners bound with a chain which shall be closed with a lock beneath the shield\".\n\nCortés's wife Catalina Súarez arrived in New Spain around summer 1522, along with her sister and brother. His marriage to Catalina was at this point extremely awkward, since she was a kinswoman of the governor of Cuba, Diego Velázquez, whose authority Cortés had thrown off and who was therefore now his enemy. Catalina lacked the noble title of \"doña,\" so at this point his marriage with her no longer raised his status. Their marriage had been childless. Since Cortés had sired children with a variety of indigenous women, including a son around 1522 by his cultural translator, Doña Marina, Cortés knew he was capable of fathering children. Cortés's only male heir at this point was illegitimate, but nonetheless named after Cortés's father, Martín Cortés. This son Martín Cortés was sometimes called \"El Mestizo\".\n\nCatalina Suárez died under mysterious circumstances the night of November 1–2, 1522. There were accusations at the time that Cortés had murdered his wife. There was an investigation into her death, interviewing a variety of household residents and others. The documentation of the investigation was published in the nineteenth century in Mexico and these archival documents were uncovered in the twentieth century. The death of Catalina Suárez produced a scandal and investigation, but Cortés was now free to marry someone of high status more appropriate to his wealth and power. In 1526, he built an imposing residence for himself, the Palace of Cortés in Cuernavaca, in a region close to the capital where he had extensive encomienda holdings. In 1529 he had been accorded the noble designation of \"don\", but more importantly was given the noble title of Marquis of the Valley of Oaxaca and married the Spanish noblewoman Doña Juana de Zúñiga. The marriage produced three children, including another son, who was also named Martín. As the first-born legitimate son, Don Martín Cortés y Zúñiga was now Cortés' heir and succeeded him as holder of the title and estate of the Marquisate of the Valley of Oaxaca. Cortés's legitimate daughters were Doña Maria, Doña Catalina, and Doña Juana.\n\nSince the conversion to Christianity of indigenous peoples was an essential and integral part of the extension of Spanish power, making formal provisions for that conversion once the military conquest was completed was an important task for Cortés. During the Age of Discovery, the Catholic Church had seen early attempts at conversion in the Caribbean islands by Spanish friars, particularly the mendicant orders. Cortés made a request to the Spanish monarch to send Franciscan and Dominican friars to Mexico to convert the vast indigenous populations to Christianity. In his fourth letter to the king, Cortés pleaded for friars rather than diocesan or secular priests because those clerics were in his view a serious danger to the Indians' conversion.\n\nIf these people [Indians] were now to see the affairs of the Church and the service of God in the hands of canons or other dignitaries, and saw them indulge in the vices and profanities now common in Spain, knowing that such men were the ministers of God, it would bring our Faith into much harm that I believe any further preaching would be of no avail.\n\nHe wished the mendicants to be the main evangelists. Mendicant friars did not usually have full priestly powers to perform all the sacraments needed for conversion of the Indians and growth of the neophytes in the Christian faith, so Cortés laid out a solution to this to the king.\n\nYour Majesty should likewise beseech His Holiness [the pope] to grant these powers to the two principal persons in the religious orders that are to come here, and that they should be his delegates, one from the Order of St. Francis and the other from the Order of St. Dominic. They should bring the most extensive powers Your Majesty is able to obtain, for, because these lands are so far from the Church of Rome, and we, the Christians who now reside here and shall do so in the future, are so far from the proper remedies of our consciences and, as we are human, so subject to sin, it is essential that His Holiness should be generous with us and grant to these persons most extensive powers, to be handed down to persons actually in residence here whether it be given to the general of each order or to his provincials.\n\nThe Franciscans arrived in May 1524, a symbolically powerful group of twelve known as the Twelve Apostles of Mexico, led by Fray Martín de Valencia. Franciscan Geronimo de Mendieta claimed that Cortés's most important deed was the way he met this first group of Franciscans. The conqueror himself was said to have met the friars as they approached the capital, kneeling at the feet of the friars who had walked from the coast. This story was told by Franciscans to demonstrate Cortés piety and humility and was a powerful message to all, including the Indians, that Cortés's earthly power was subordinate to the spiritual power of the friars. However, one of the first twelve Franciscans, Fray Toribio de Benavente Motolinia does not mention it in his history. Cortés and the Franciscans had a particularly strong alliance in Mexico, with Franciscans seeing him as \"the new Moses\" for conquering Mexico and opening it to Christian evangelization. In Motolinia's 1555 response to Dominican Bartolomé de Las Casas, he praises Cortés.\n\nAnd as to those who murmur against the Marqués del Valle [Cortés], God rest him, and who try to blacken and obscure his deeds, I believe that before God their deeds are not as acceptable as those of the Marqués. Although as a human he was a sinner, he had faith and works of a good Christian, and a great desire to employ his life and property in widening and augmenting the fair of Jesus Christ, and dying for the conversion of these gentiles ... Who has loved and defended the Indians of this new world like Cortés? ... Through this captain, God opened the door for us to preach his holy gospel and it was he who caused the Indians to revere the holy sacraments and respect the ministers of the church.\n\nIn Fray Bernardino de Sahagún's 1585 revision of the conquest narrative first codified as Book XII of the Florentine Codex, there are laudatory references to Cortés that do not appear in the earlier text from the indigenous perspective. Whereas Book XII of the Florentine Codex concludes with an account of Spaniards' search for gold, in Sahagún's 1585 revised account, he ends with praise of Cortés for requesting the Franciscans be sent to Mexico to convert the Indians.\n\nFrom 1524 to 1526, Cortés headed an expedition to Honduras where he defeated Cristóbal de Olid, who had claimed Honduras as his own under the influence of the Governor of Cuba Diego Velázquez. Fearing that Cuauhtémoc might head an insurrection in Mexico, he brought him with him to Honduras. In a controversial move, Cuauhtémoc was executed during the journey. Raging over Olid's treason, Cortés issued a decree to arrest Velázquez, whom he was sure was behind Olid's treason. This, however, only served to further estrange the Crown of Castile and the Council of Indies, both of which were already beginning to feel anxious about Cortés's rising power.\nCortés's fifth letter to King Charles attempts to justify his conduct, concludes with a bitter attack on \"various and powerful rivals and enemies\" who have \"obscured the eyes of your Majesty\". Charles, who was also Holy Roman Emperor, had little time for distant colonies (much of Charles's reign was taken up with wars with France, the German Protestants and the expanding Ottoman Empire), except insofar as they contributed to finance his wars. In 1521, year of the Conquest, Charles was attending to matters in his German domains and Bishop Adrian of Utrecht functioned as regent in Spain.\n\nVelázquez and Fonseca persuaded the regent to appoint a commissioner (a \"Juez de residencia\", Luis Ponce de León) with powers to investigate Cortés's conduct and even arrest him. Cortés was once quoted as saying that it was \"more difficult to contend against [his] own countrymen than against the Aztecs.\" Governor Diego Velázquez continued to be a thorn in his side, teaming up with Bishop Juan Rodríguez de Fonseca, chief of the Spanish colonial department, to undermine him in the Council of the Indies.\n\nA few days after Cortés's return from his expedition, Ponce de León suspended Cortés from his office of governor of New Spain. The Licentiate then fell ill and died shortly after his arrival, appointing Marcos de Aguilar as \"alcalde mayor\". The aged Aguilar also became sick and appointed Alonso de Estrada governor, who was confirmed in his functions by a royal decree in August 1527. Cortés, suspected of poisoning them, refrained from taking over the government.\n\nEstrada sent Diego de Figueroa to the south. De Figueroa raided graveyards and extorted contributions, meeting his end when the ship carrying these treasures sank. Albornoz persuaded Alonso de Estrada to release Salazar and Chirinos. When Cortés complained angrily after one of his adherents' hands was cut off, Estrada ordered him exiled. Cortés sailed for Spain in 1528 to appeal to King Charles.\n\nIn 1528, Cortés returned to Spain to appeal to the justice of his master, Charles V. Juan Altamirano and Alonso Valiente stayed in Mexico and acted as Cortés' representatives during his absence. Cortés presented himself with great splendor before Charles V's court. By this time Charles had returned and Cortés forthrightly responded to his enemy's charges. Denying he had held back on gold due the crown, he showed that he had contributed more than the quinto (one-fifth) required. Indeed, he had spent lavishly to build the new capital of Mexico City on the ruins of the Aztec capital of Tenochtitlán, leveled during the siege that brought down the Aztec empire.\n\nHe was received by Charles with every distinction, and decorated with the order of Santiago. In return for his efforts in expanding the still young Spanish Empire, Cortés was rewarded in 1529 by being accorded the noble title of \"don\" but more importantly named the \"\"Marqués del Valle de Oaxaca\"\" (Marquis of the Valley of Oaxaca and married the Spanish noblewoman Doña Juana Zúñiga, after the 1522 death of his much less distinguished first wife, Catalina Suárez. The noble title and senorial estate of the Marquesado was passed down to his descendants until 1811. The Oaxaca Valley was one of the wealthiest regions of New Spain, and Cortés had 23,000 vassals in 23 named encomiendas in perpetuity.\n\nAlthough confirmed in his land holdings and vassals, he was not reinstated as governor and was never again given any important office in the administration of New Spain. During his travel to Spain, his property was mismanaged by abusive colonial administrators. He sided with local natives in a lawsuit. The natives documented the abuses in the Huexotzinco Codex.\n\nThe entailed estate and title passed to his legitimate son Don Martín Cortés upon Cortés's death in 1547, who became the Second Marquis. Don Martín's association with the so-called Encomenderos' Conspiracy endangered the entailed holdings, but they were restored and remained the continuing reward for Hernán Cortés's family through the generations.\n\nCortés returned to Mexico in 1530 with new titles and honors, but with diminished power. Although Cortés still retained military authority and permission to continue his conquests, viceroy Don Antonio de Mendoza was appointed in 1535 to administer New Spain's civil affairs. This division of power led to continual dissension, and caused the failure of several enterprises in which Cortés was engaged.\n\nOn returning to Mexico, Cortés found the country in a state of anarchy. There was a strong suspicion in court circles of an intended rebellion by Cortés, and a charge was brought against him that cast a fatal blight upon his character and plans. He was accused of murdering his first wife. The proceedings of the investigation were kept secret.\n\nNo report, either exonerating or condemning Cortés, was published. Had the Government declared him innocent, it would have greatly increased his popularity. Had it declared him a criminal, a crisis would have been precipitated by the accused and his party. Silence was the only safe policy, but that silence is suggestive that grave danger was feared from his influence.\n\nAfter reasserting his position and reestablishing some sort of order, Cortés retired to his estates at Cuernavaca, about 30 miles (48 km) south of Mexico City. There he concentrated on the building of his palace and on Pacific exploration. Remaining in Mexico between 1530 and 1541, Cortés quarreled with Nuño Beltrán de Guzmán and disputed the right to explore the territory that is today California with Antonio de Mendoza, the first viceroy.\n\nCortes acquired several silver mines in Zumpango del Rio in 1534. By the early 1540s, he owned 20 silver mines in Sultepec, 12 in Taxco, and 3 in Zacualpan. Earlier, Cortes had claimed the silver in the Tamazula area.\n\nIn 1536, Cortés explored the northwestern part of Mexico and discovered the Baja California Peninsula. Cortés also spent time exploring the Pacific coast of Mexico. The Gulf of California was originally named the \"Sea of Cortes\" by its discoverer Francisco de Ulloa in 1539. This was the last major expedition by Cortés.\n\nAfter his exploration of Baja California, Cortés returned to Spain in 1541, hoping to confound his angry civilians, who had brought many lawsuits against him (for debts, abuse of power, etc.).\n\nOn his return he was utterly neglected, and could scarcely obtain an audience. On one occasion he forced his way through a crowd that surrounded the emperor's carriage, and mounted on the footstep. The emperor, astounded at such audacity, demanded of him who he was. \"I am a man,\" replied Cortés proudly, \"who has given you more provinces than your ancestors left you cities.\"\n\nThe emperor finally permitted Cortés to join him and his fleet commanded by Andrea Doria at the great expedition against Algiers in the Barbary Coast in 1541, which was then part of the Ottoman Empire and was used as a base by Hayreddin Barbarossa, a famous Turkish corsair and Admiral-in-Chief of the Ottoman Fleet. During this unfortunate campaign, which was his last, Cortés was almost drowned in a storm that hit his fleet while he was pursuing Barbarossa.\n\nHaving spent a great deal of his own money to finance expeditions, he was now heavily in debt. In February 1544 he made a claim on the royal treasury, but was ignored for the next three years. Disgusted, he decided to return to Mexico in 1547. When he reached Seville, he was stricken with dysentery. He died in Castilleja de la Cuesta, Seville province, on December 2, 1547, from a case of pleurisy at the age of 62.\n\nLike Columbus, he died a wealthy but embittered man. He left his many mestizo and white children well cared for in his will, along with every one of their mothers. He requested in his will that his remains eventually be buried in Mexico. Before he died he had the Pope remove the \"natural\" status of four of his children (legitimizing them in the eyes of the church), including Martin, the son he had with Doña Marina (also known as La Malinche), said to be his favourite. His daughter, Doña Catalina, however, died shortly after her father's death.\n\nAfter his death, his body was moved more than eight times for several reasons. On December 4, 1547 he was buried in the mausoleum of the Duke of Medina in the church of San Isidoro del Campo, Sevilla. Three years later (1550) due to the space being required by the duke, his body was moved to the altar of Santa Catarina in the same church. In his testament, Cortés asked for his body to be buried in the monastery he had ordered to be built in Coyoacan in México, ten years after his death, but the monastery was never built. So in 1566, his body was sent to New Spain and buried in the church of San Francisco de Texcoco, where his mother and one of his sisters were buried.\n\nIn 1629, \"Don Pedro Cortés fourth \"Marquez del Valle\", his last male descendant, died, so the viceroy decided to move the bones of Cortés along with those of his descendant to the Franciscan church in México. This was delayed for nine years, while his body stayed in the main room of the palace of the viceroy. Eventually it was moved to the Sagrario of Franciscan church, where it stayed for 87 years. In 1716, it was moved to another place in the same church. In 1794, his bones were moved to the \"Hospital de Jesus\" (founded by Cortés), where a statue by Tolsá and a mausoleum were made. There was a public ceremony and all the churches in the city rang their bells.\n\nIn 1823, after the independence of México, it seemed imminent that his body would be desecrated, so the mausoleum was removed, the statue and the coat of arms were sent to Palermo, Sicily, to be protected by the Duke of Terranova. The bones were hidden, and everyone thought that they had been sent out of México. In 1836, his bones were moved to another place in the same building.\n\nIt was not until November 24, 1946 that they were rediscovered, thanks to the discovery of a secret document by Lucas Alamán. His bones were put in the charge of the Instituto Nacional de Antropología e Historia (INAH). The remains were authenticated by INAH. They were then restored to the same place, this time with a bronze inscription and his coat of arms. When the bones were first rediscovered, the supporters of the Hispanic tradition in Mexico were excited, but one supporter of an indigenist vision of Mexico \"proposed that the remains be publicly burned in front of the statue of Cuauhtemoc, and the ashes flung into the air\". Following the discovery and authentication of Cortés's remains, there was a discovery of what were described as the bones of Cuauhtémoc, resulting in a \"battle of the bones\". In 1981, when a copy of the bust by Tolsa was put in the church, there was a failed attempt to destroy his bones.\n\nCortés is commemorated in the scientific name of a subspecies of Mexican lizard, \"Phrynosoma orbiculare cortezii\".\n\nThere are relatively few sources to the early life of Cortés; his fame arose from his participation in the conquest of Mexico and it was only after this that people became interested in reading and writing about him.\n\nProbably the best source is his letters to the king which he wrote during the campaign in Mexico, but they are written with the specific purpose of putting his efforts in a favourable light and so must be read critically. Another main source is the biography written by Cortés's private chaplain Lopez de Gómara, which was written in Spain several years after the conquest. Gómara never set foot in the Americas and knew only what Cortés had told him, and he had an affinity for knightly romantic stories which he incorporated richly in the biography. The third major source is written as a reaction to what its author calls \"the lies of Gomara\", the eyewitness account written by the Conquistador Bernal Díaz del Castillo does not paint Cortés as a romantic hero but rather tries to emphasize that Cortés's men should also be remembered as important participants in the undertakings in Mexico.\n\nIn the years following the conquest more critical accounts of the Spanish arrival in Mexico were written. The Dominican friar Bartolomé de Las Casas wrote his \"A Short Account of the Destruction of the Indies\" which raises strong accusations of brutality and heinous violence towards the Indians; accusations against both the conquistadors in general and Cortés in particular. The accounts of the conquest given in the Florentine Codex by the Franciscan Bernardino de Sahagún and his native informants are also less than flattering towards Cortés. The scarcity of these sources has led to a sharp division in the description of Cortés's personality and a tendency to describe him as either a vicious and ruthless person or a noble and honorable cavalier.\n\nIn México there are few representations of Cortés. However, many landmarks still bear his name, from the castle Palacio de Cortés in the city of Cuernavaca to some street names throughout the republic.\n\nThe pass between the volcanoes Iztaccíhuatl and Popocatépetl where Cortés took his soldiers on their march to Mexico City. It is known as the Paso de Cortés.\n\nThe muralist Diego Rivera painted several representation of him but the most famous, depicts him as a powerful and ominous figure along with Malinche in a mural in the National Palace in Mexico City.\nIn 1981, President Lopez Portillo tried to bring Cortés to public recognition. First, he made public a copy of the bust of Cortés made by Manuel Tolsá in the Hospital de Jesús Nazareno with an official ceremony, but soon a nationalist group tried to destroy it, so it had to be taken out of the public. Today the copy of the bust is in the \"Hospital de Jesús Nazareno\" while the original is in Naples, Italy, in the Villa Pignatelli.\n\nLater, another monument, known as \"Monumento al Mestizaje\" by Julián Martínez y M. Maldonado (1982) was commissioned by Mexican president José López Portillo to be put in the \"Zócalo\" (Main square) of Coyoacan, near the place of his country house, but it had to be removed to a little known park, the Jardín Xicoténcatl, Barrio de San Diego Churubusco, to quell protests. The statue depicts Cortés, Malinche and their son Martín.\n\nThere is another statue by Sebastián Aparicio, in Cuernavaca, was in a hotel \"El casino de la selva\". Cortés is barely recognizable, so it sparked little interest. The hotel was closed to make a commercial center, and the statue was put out of public display by Costco the builder of the commercial center.\n\nHernán Cortés is a character in the opera \"La Conquista\" (2005) by Italian composer Lorenzo Ferrero, which depicts the major episodes of the Spanish conquest of the Aztec Empire in 1521.\n\nCortés' personal account of the conquest of Mexico is narrated in his five letters addressed to Charles V. These five letters, the \"cartas de relación\", are Cortés' only surviving writings. See \"Letters and Dispatches of Cortés\", translated by George Folsom (New York, 1843); Prescott's \"Conquest of Mexico\" (Boston, 1843); and Sir Arthur Helps's \"Life of Hernando Cortes\" (London, 1871).\n\nHis first letter was considered lost, and the one from the municipality of Veracruz has to take its place. It was published for the first time in volume IV of \"Documentos para la Historia de España\", and subsequently reprinted. The first \"carta de relación\" is available online at the University of Wisconsin.\n\nThe \"Segunda Carta de Relacion\", bearing the date of October 30, 1520, appeared in print at Seville in 1522. The third letter, dated May 15, 1522, appeared at Seville in 1523. The fourth, October 20, 1524, was printed at Toledo in 1525. The fifth, on the Honduras expedition, is contained in volume IV of the \"Documentos para la Historia de España\". The important letter mentioned in the text has been published under the heading of \"Carta inédita de Cortés\" by Ycazbalceta. A great number of minor documents, either by Cortés or others, for or against him, are dispersed through the voluminous collection above cited and through the \"Colección de Documentos de Indias\", as well as in the \"Documentos para la Historia de México\" of Ycazbalceta. There are a number of reprints and translations of Cortés's writings into various languages.\n\nNatural children of Don Hernán Cortés\n\nHe married twice: firstly in Cuba to Catalina Suárez Marcaida, who died at Coyoacán in 1522 without issue, and secondly in 1529 to \"doña\" Juana Ramírez de Arellano de Zúñiga, daughter of \"don\" Carlos Ramírez de Arellano, 2nd Count of Aguilar and wife the Countess \"doña\" Juana de Zúñiga, and had:\n\n\n"}
{"id": "14015", "url": "https://en.wikipedia.org/wiki?curid=14015", "title": "Herstory", "text": "Herstory\n\nHerstory is a term for history written from a feminist perspective, emphasizing the role of women, or told from a woman's point of view. The principal aim of herstory is to bring women out of alleged obscurity from the historical record. It is a neologism coined as a pun with the word \"history\", as part of a feminist critique of conventional historiography, which in their opinion is traditionally written as \"his story\", i.e., from the masculine point of view. (The word \"history\"—from the Ancient Greek ἱστορία, or \"historia\", meaning \"knowledge obtained by inquiry\"—is etymologically unrelated to the possessive pronoun \"his\".) This movement has led to an increase in activity in other female-centric disciplines such as femistry and galgebra. \n\nThe herstory movement has spawned women-centered presses, such as Virago Press in 1973, which publishes fiction and non-fiction by noted women authors like Janet Frame and Sarah Dunant.\n\nRobin Morgan, in a book of her selected writings states that the debut of the word \"herstory\" was in the byline of her article \"Goodbye to All That\", in early 1970, in the first issue of the \"underground\" New Left newspaper \"Rat\" after it was overtaken by women to clean it of sexism. She writes that she identified herself as a member of W.I.T.C.H., decoding the acronym as \"Women Inspired to Commit Herstory\".\n\nIn 1976, Casey Miller and Kate Swift wrote in \"Words & Women,\"\n\nDuring the 1970s and 1980s, second-wave feminists saw the study of history as a male-dominated intellectual enterprise and presented \"herstory\" as a means of compensation. The term, intended to be both serious and comic, became a rallying cry used on T-shirts and buttons as well as in academia.\n\nIn 2017, Hridith Sudev, an inventor, environmentalist and social activist associated with various youth movements, launched 'The Herstory Movement'; an online platform to \"celebrate lesser known great persons; female, queer or otherwise marginalized, who helped shape the modern World History\". It is intended as an academic platform to feature stories of female historic persons and thus help facilitate more widespread knowledge about 'Great Women' History.\n\nChristina Hoff Sommers has been a vocal critic of the concept of herstory, and presented her argument against the movement in her 1994 book, \"Who Stole Feminism?\". Sommers defined herstory as an attempt to infuse education with ideology, at the expense of knowledge. The \"gender feminists\", as she termed them, were the band of feminists responsible for the movement, which she felt amounted to negationism. She regarded most attempts to make historical studies more female-inclusive as being artificial in nature, and an impediment to progress.\n\nProfessor and author Devoney Looser has criticized the concept of herstory for overlooking the contributions that some women made as historians before the twentieth century.\n\nThe Global Language Monitor, a nonprofit group that analyzes and tracks trends in language, named \"herstory\" the third most \"politically incorrect\" word of 2006—rivaled only by \"\"macaca\"\" and \"\"Global Warming Denier\".\"\n\nBooks published on the topic include:\n\n"}
{"id": "14017", "url": "https://en.wikipedia.org/wiki?curid=14017", "title": "House of Cards (UK TV series)", "text": "House of Cards (UK TV series)\n\nHouse of Cards is a 1990 British political thriller television serial in four episodes, set after the end of Margaret Thatcher's tenure as Prime Minister of the United Kingdom. It was televised by the BBC from 18 November to 9 December 1990, to critical and popular acclaim.\n\nAndrew Davies adapted the story from the novel of the same title by Michael Dobbs, a former Chief of Staff at Conservative Party headquarters. Neville Teller also dramatised Dobbs's novel for BBC World Service in 1996, and it had two television sequels (\"To Play the King\" and \"The Final Cut\"). The opening and closing theme music for those TV series is entitled \"Francis Urquhart's March.\"\n\n\"House of Cards\" was ranked 84th in the British Film Institute list of the 100 Greatest British Television Programmes in 2000. In 2013, the serial and the Dobbs novel were the basis for a US adaptation set in Washington, D.C., commissioned and released by Netflix.\n\nThe antihero of \"House of Cards\" is Francis Urquhart, a fictional Chief Whip of the Conservative Party, played by Ian Richardson. The plot follows his amoral and manipulative scheme to become leader of the governing party and, thus, Prime Minister of the United Kingdom.\n\nMichael Dobbs did not envision writing the second and third books, as Urquhart dies at the end of the first novel. The screenplay of the BBC's dramatisation of \"House of Cards\" differs from the book, and hence allows future series. Dobbs wrote two following books, \"To Play the King\" and \"The Final Cut\", which were televised in 1993 and 1995, respectively.\n\n\"House of Cards\" was said to draw from Shakespeare's plays \"Macbeth\" and \"Richard III\", both of which feature main characters who are corrupted by power and ambition. Richardson has a Shakespearean background and said he based his characterisation of Urquhart on Shakespeare's portrayal of Richard III.\n\nUrquhart frequently talks through the camera to the audience, breaking the fourth wall.\n\nAfter Margaret Thatcher's resignation, the ruling Conservative Party is about to elect a new leader. Francis Urquhart (Ian Richardson), an MP and the Government Chief Whip in the House of Commons, introduces viewers to the contestants, from which Henry \"Hal\" Collingridge (David Lyon) emerges victorious. Urquhart is secretly contemptuous of the well-meaning but weak Collingridge, but expects a promotion to a senior position in the Cabinet. After the general election, which the party wins by a reduced majority, Urquhart submits his suggestions for a reshuffle that includes his desired promotion. However, Collingridge – citing Harold Macmillan's political demise after the 1962 Night of the Long Knives – effects no changes at all. Urquhart resolves to oust Collingridge, with encouragement from his wife, Elizabeth (Diane Fletcher).\n\nAt the same time, with Elizabeth's blessing, Urquhart begins an affair with Mattie Storin (Susannah Harker), a junior political reporter at a Conservative-leaning tabloid newspaper called \"The Chronicle\". The affair allows Urquhart to manipulate Mattie and indirectly skew her coverage of the Conservative leadership contest in his favour. Mattie has an apparent Electra complex; she finds appeal in Urquhart's much older age and later refers to him as \"Daddy.\" Another unwitting pawn is Roger O'Neill (Miles Anderson), the party's cocaine-addicted public relations consultant.\n\nUrquhart blackmails O'Neill into leaking information on budget cuts that humiliates Collingridge during the Prime Minister's Questions. Later, he blames party chairman Lord \"Teddy\" Billsborough (Nicholas Selby) for leaking an internal poll showing a drop in Tory numbers, leading Collingridge to sack him. As Collingridge's image suffers, Urquhart encourages ultraconservative Foreign Secretary Patrick Woolton (Malcolm Tierney) and \"Chronicle\" owner Benjamin Landless to support his removal. Urquhart also poses as Collingridge's alcoholic brother Charles (James Villiers), to trade shares in a chemical company about to benefit from advance information confidential to the government. Consequently, Collingridge becomes falsely accused of insider trading and is forced to resign.\n\nIn the ensuing leadership race, Urquhart initially feigns unwillingness to stand before announcing his candidacy. With the help of his underling, Tim Stamper (Colin Jeavons), Urquhart goes about making sure his competitors drop out of the race: Health Secretary Peter MacKenzie (Christopher Owen) accidentally runs his car over a disabled protester at a demonstration staged by Urquhart and is forced by the public outcry to withdraw, while Education Secretary Harold Earle (Kenneth Gilbert) is blackmailed into withdrawing when Urquhart anonymously sends pictures of him in the company of a rent boy whom Earle had paid for sex.\n\nThe first ballot leaves Urquhart to face Woolton and Michael Samuels, the moderate Environment Secretary supported by Billsborough. Urquhart eliminates Woolton by a prolonged scheme: at the party conference, he pressures O'Neill into persuading his personal assistant and lover, Penny Guy (Alphonsia Emmanuel), to have a one-night stand with Woolton in his suite, which Urquhart records via a bugged ministerial red box. When the tape is sent to Woolton, he is led to assume that Samuels is behind the scheme and backs Urquhart in the contest. Urquhart also receives support from Collingridge, who is unaware of Urquhart's role in his own downfall. Samuels is forced out of the running when the tabloids reveal that he backed leftist causes as a student at University of Cambridge.\n\nStumbling across contradictions in the allegations against Collingridge and his brother, Mattie begins to dig deeper. On Urquhart's orders, O'Neill arranges for her car and flat to be vandalised in a show of intimidation. However, O'Neill becomes increasingly uneasy with what he is being asked to do, and his cocaine addiction adds to his instability. Urquhart mixes O'Neill's cocaine with rat poison, causing him to kill himself when taking the cocaine in a motorway lavatory. Though initially blind to the truth of matters thanks to her relations with Urquhart, Mattie eventually deduces that Urquhart is responsible for O'Neill's death and is behind the unfortunate downfalls of Collingridge and all of Urquhart's rivals.\n\nMattie looks for Urquhart at the point when it seems his victory is certain. She eventually finds him on the roof garden of the Houses of Parliament, where she confronts him. He admits to O'Neill's murder and everything else he has done. He then asks whether he can trust Mattie, and, though she answers in the affirmative, he does not believe her and throws her off the roof onto a van parked below. An unseen person picks up Mattie's tape recorder, which she had been using to secretly record her conversations with Urquhart. The series ends with Urquhart defeating Samuels in the second leadership ballot and being driven to Buckingham Palace to be invited to form a government by Elizabeth II.\n\nIn the first novel, but not in the television series:\n\nBefore the series was reissued in 2013 to coincide with the release of the US version of \"House of Cards\", Dobbs rewrote portions of the novel to bring the series in line with the television mini-series and restore continuity among the three novels. In the 2013 version:\n\n\nThe first installment of the TV series coincidentally aired two days before the Conservative Party leadership election. Author Dobbs said that John Major's leadership headquarters \"came to a halt\" to view the show. During a time of \"disillusionment with politics\", the series \"caught the nation's mood\".\n\nIan Richardson won a Best Actor BAFTA in 1991 for his role as Urquhart, and Andrew Davies won an Emmy for outstanding writing in a miniseries.\n\nThe series ranked 84th in the British Film Institute list of the 100 Greatest British Television Programmes.\n\nThe Urquhart trilogy has been adapted in the United States as \"House of Cards\". The show stars Kevin Spacey as Francis \"Frank\" Underwood, the Majority Whip of the Democratic Party, who schemes and murders his way to becoming President of the United States. It is produced by David Fincher and Spacey's Trigger Street Productions, with the initial episodes directed by Fincher.\n\nThe series, produced and financed by independent studio Media Rights Capital, is one of Netflix's first forays into original programming. Series one was made available online on 1 February 2013. The series is filmed in Baltimore, Maryland. The first series was critically acclaimed and earned four Golden Globe Nominations, including Best Drama, actor, actress and supporting actor, with Robin Wright winning best actress. It also earned nine Primetime Emmy Award nominations, winning three, and was the first show to earn nominations that was broadcast solely via an internet streaming service.\n\nThe drama introduced and popularised the phrase: \"You might very well think that; I couldn't possibly comment\". It was a non-confirmation confirmative statement, used by Urquhart whenever he could not be seen to agree with a leading statement, with the emphasis on either the \"I\" or the \"possibly\", depending on the situation. The phrase was even used in the House of Commons, House of Lords and Parliamentary Committees following the series.\n\nA variation on the phrase was written into the TV adaptation of Terry Pratchett's \"Hogfather\" for the character Death, as an in-joke on the fact that he was voiced by Richardson.\n\nDuring the first Gulf War, a British reporter speaking from Baghdad, conscious of the possibility of censorship, used the code phrase \"You might very well think that; I couldn't possibly comment\" to answer a BBC presenter's question.\n\nA further variation was used by Nicola Murray, a fictional government minister, in the third series finale of \"The Thick of It\".\n\nIn the U.S. adaptation, the phrase is used by Frank Underwood in the first episode during his initial meeting with Zoe Barnes, the US counterpart of Mattie Storin.\n\n\n"}
{"id": "14018", "url": "https://en.wikipedia.org/wiki?curid=14018", "title": "Helen Gandy", "text": "Helen Gandy\n\nHelen W. Gandy (April 8, 1897 – July 7, 1988) was an American civil servant. For 54 years, she was the secretary to Federal Bureau of Investigation director J. Edgar Hoover, who called her \"indispensable\". She exercised great behind-the-scenes influence on Hoover and the workings of the Bureau. Following Hoover's death in 1972, she spent weeks destroying his \"Personal File\", thought to be where the most incriminating material he used to manipulate and control the most powerful figures in Washington was kept.\n\nHelen Gandy was born in Rockville, New Jersey, one of three children (two daughters and a son) born to Franklin Dallas and Annie (née Williams) Gandy. She grew up in New Jersey in Fairton or the Port Norris section of Commercial Township (sources differ) and graduated from Bridgeton High School in Bridgeton New Jersey. In 1918, aged 21, she moved to Washington, D.C., where she later took classes at Strayer Business College and George Washington University Law School.\n\nGandy briefly worked in a department store in Washington before finding a job as a file clerk at the Justice Department in 1918. Within weeks, she went to work as a typist for Hoover, effective March 25, 1918, having told Hoover in her interview she had \"no immediate plans to marry.\" She, like Hoover, would never marry; both were completely devoted to the Bureau.\n\nWhen Hoover went to the Bureau of Investigation (its original title; it became the F.B.I. in 1935) as its assistant director on August 22, 1921, he specifically requested Gandy return from vacation to help him in the new post. Hoover became director of the Bureau in 1924, and Gandy continued in his service. She was promoted to \"office assistant\" on August 23, 1937 and \"executive assistant\" on October 1, 1939. Though she would receive promotions in her civil service grade subsequently, she retained her title as executive assistant until her retirement on May 2, 1972, the day Hoover died. Hoover said of her: \"if there is anyone in this Bureau whose services are indispensable, I consider Miss Gandy to be that person.\" Despite this, Curt Gentry wrote:\n\nTheirs was a rigidly formal relationship. He'd always called her 'Miss Gandy' (when angry, barking it out as one word). In all those fifty-four years he had never once called her by her first name.\n\nHoover biographers Theoharis and Cox would say \"her stern face recalled Cerberus at the gate,\" a view echoed by Anthony Summers in his life of Hoover, who also pictured Gandy as Hoover's first line of defense against the outside world. When Attorney General Robert F. Kennedy, Hoover's superior, had a direct telephone line installed between their offices, Hoover refused to answer the phone. \"Put that damn thing on Miss Gandy's desk where it belongs,\" Hoover would declare.\n\nGentry described Gandy's influence:\n\nHer genteel manner and pleasant voice contrasted sharply with this domineering presence. Yet behind the politeness was a resolute firmness not unlike his, and no small amount of influence. Many a career in the Bureau had been quietly manipulated by her. Even those who disliked him, praised her, most often commenting on her remarkable ability to get along with all kinds of people. That she had held her position for fifty-four years was the best evidence of this, for it was a Bureau tradition that the closer you were to him, the more demanding he was.\n\nWilliam C. Sullivan, an agent with the Bureau for three decades, reported in his memoir when he worked in the public relations section answering mail from the public, he gave a correspondent the wrong measurements for Hoover's personal popover recipe, relying on memory rather than the files. Gandy, ever protective of her boss, caught the error and brought it to Hoover's attention. The director then placed an official letter of reprimand in Sullivan's file for the lapse. Mark Felt, deputy associate director of the Bureau, wrote in his memoir that Gandy \"was bright and alert and quick-tempered—and completely dedicated to her boss.\"\n\nHoover died during the night of May 1–2, 1972. According to Curt Gentry, who wrote the 1991 book \"J Edgar Hoover: The Man and the Secrets\", Hoover's body was not discovered by his live-in cook and general housekeeper, Annie Fields; rather, it was discovered by James Crawford, who had been Hoover's chauffeur for 37 years. Crawford then yelled out to Fields and Tom Moton (Hoover's new chauffeur after Crawford had retired in January 1972). Ms. Fields first called Hoover's personal physician, Dr. Robert Choisser, then used another phone to call Clyde Tolson's private number. Tolson then called Helen Gandy's private number with the news of Hoover's death along with orders to begin destroying the files. Within an hour, the \"D List\" (\"d\" standing for destruction) was being distributed, and the destruction of files began. However, \"The New York Times\" quoted an anonymous F.B.I. source in spring 1975, who said: \"Gandy had begun almost a year before Mr. Hoover's death and was instructed to purge the files that were then in his office.\"\nAnthony Summers reported that G. Gordon Liddy had said of his sources in the F.B.I.: \"by the time Gray went in to get the files, Miss Gandy had already got rid of them.\" The day after Hoover died, Gray, who had been named acting director by President Richard Nixon upon Tolson's resignation from that position, went to Hoover's office. Gandy paused from her work to give Gray a tour. He found file cabinets open and packing boxes being filled with papers. She informed him the boxes contained personal papers of Hoover's. Gandy stated Gray flipped through a few files and approved her work, but Gray was to deny he looked at any papers. Gandy also told Gray it would be a week before she could clear Hoover's effects out so Gray could move into the suite.\n\nGray reported to Nixon that he had secured Hoover's office and its contents. However, he had sealed only Hoover's personal inner office, where no files were stored, not the entire suite of offices. Since 1957, Hoover's \"Official/Confidential\" files, containing material too sensitive to include in the Bureau's central files, had been kept in the outer office, where Gandy sat. Gentry reported that Gray would not have known where to look in Gandy's office for the files, as her office was lined floor to ceiling with filing cabinets; moreover, without her index to the files, he would not have been able to locate incriminating material, for files were deliberately mislabeled, e.g., President Nixon's file was labeled \"Obscene Matters\".\n\nOn May 4, Gandy turned over 12 boxes labelled \"Official/Confidential\", containing 167 files and 17,750 pages, to Mark Felt. Many of them contained derogatory information. Gray told the press that afternoon that \"there are no dossiers or secret files. There are just general files and I took steps to preserve their integrity.\" Gandy retained the \"Personal File\".\n\nGandy worked on going through Hoover's \"Personal File\" in the office until May 12. She then transferred at least 32 file drawers of material to the basement rec room of Hoover's Washington home at 4936 Thirtieth Place, NW, where she continued her work from May 13 to July 17. Gandy later testified nothing official had been removed from the Bureau's offices, \"not even his badge.\" At Hoover's residence the destruction was overseen by John P. Mohr, the number three man in the Bureau after Hoover and Tolson. They were aided by James Jesus Angleton, the Central Intelligence Agency's counterintelligence chief, whom Hoover's neighbors saw removing boxes from Hoover's home. Mohr would claim the boxes Angleton removed were cases of spoiled wine.\n\nWhen the House Committee on Government Oversight investigated the F.B.I.'s spying on and harassment of Martin Luther King, Jr. and others in 1975, Gandy was called to testify. \"I tore them up, put them in boxes, and they were taken away to be shredded,\" she told the congressmen about the papers. The Bureau's Washington field office had F.B.I. drivers transport the material to Hoover's home, then once Gandy had gone through the material, the drivers transported it back to the field office in the Old Post Office Building on Pennsylvania Avenue, where it was shredded and burned.\n\nGandy stated that Hoover had left standing instructions to destroy his personal papers upon his death, and that this instruction was confirmed by Tolson and Gray. Gandy stated that she destroyed no official papers, that everything was personal papers of Hoover's. The staff of the subcommittee did not believe her, but she told the committee: \"I have no reason to lie.\" Representative Andrew Maguire (D-New Jersey), a freshman member of the 94th Congress, said \"I find your testimony very difficult to believe.\" Gandy held her ground: \"That is your privilege.\"\n\n\"I can give you my word. I know what there was—letters to and from friends, personal friends, a lot of letters,\" she testified. Gandy also said the files she took to his home also included his financial papers, such as tax returns and investment statements, the deed to his home, and papers relating to his dogs' pedigrees.\n\nCurt Gentry wrote:\n\nIn \"J. Edgar Hoover: The Man and His Secrets\", Gentry describes the nature of the files: \"... their contents included blackmail material on the patriarch of an American political dynasty, his sons, their wives, and other women; allegations of two homosexual arrests which Hoover leaked to help defeat a witty, urbane Democratic presidential candidate; the surveillance reports on one of America's best-known first ladies and her alleged lovers, both male and female, white and black; the child molestation documentation the director used to control and manipulate one of the Red-baiting proteges; a list of the Bureau's spies in the White House during the eight administrations when Hoover was FBI director; the forbidden fruit of hundreds of illegal wiretaps and bugs, containing, for example, evidence that an attorney general, Tom C. Clark, who later became Supreme Court justice, had received payoffs from the Chicago syndicate; as well as celebrity files, with all the unsavory gossip Hoover could amass on some of the biggest names in show business.\"\n\nWhile Gandy officially retired the day Hoover died, she spent the next few weeks destroying his papers (as described and referenced above). Hoover left her $5,000 in his will.\n\nIn 1961, Gandy and her sister, Lucy G. Rodman, donated a portrait of their mother by Thomas Eakins to the Smithsonian American Art Museum. Gandy lived in Washington until 1986, when she moved to DeLand, Florida, in Volusia County, where a niece lived. Gandy was an avid trout fisherman.\n\nGandy died of a heart attack on July 7, 1988, either in DeLand (as indicated by her \"New York Times\" obituary) or in nearby Orange City, Florida (as stated in her \"Post\" obituary).\n\nGandy was portrayed by actresses Lee Kessler in the television film \"J. Edgar Hoover\" (1987) and Naomi Watts in the cinematic release \"J. Edgar\" (2011).\n\n\n"}
{"id": "14019", "url": "https://en.wikipedia.org/wiki?curid=14019", "title": "Horsepower", "text": "Horsepower\n\nHorsepower (hp) is a unit of measurement of power (the rate at which work is done). There are many different standards and types of horsepower. Two common definitions being used today are the mechanical horsepower (or imperial horsepower), which is about 745.7 watts, and the metric horsepower, which is approximately 735.5 watts.\n\nThe term was adopted in the late 18th century by Scottish engineer James Watt to compare the output of steam engines with the power of draft horses. It was later expanded to include the output power of other types of piston engines, as well as turbines, electric motors and other machinery. The definition of the unit varied among geographical regions. Most countries now use the SI unit \"watt\" for measurement of power. With the implementation of the EU Directive 80/181/EEC on January 1, 2010, the use of horsepower in the EU is permitted only as a supplementary unit.\n\nThe development of the steam engine provided a reason to compare the output of horses with that of the engines that could replace them. In 1702, Thomas Savery wrote in \"The Miner's Friend\":\n\nSo that an engine which will raise as much water as two horses, working together at one time in such a work, can do, and for which there must be constantly kept ten or twelve horses for doing the same. Then I say, such an engine may be made large enough to do the work required in employing eight, ten, fifteen, or twenty horses to be constantly maintained and kept for doing such a work…\n\nThe idea was later used by James Watt to help market his improved steam engine. He had previously agreed to take royalties of one third of the savings in coal from the older Newcomen steam engines. This royalty scheme did not work with customers who did not have existing steam engines but used horses instead.\n\nWatt determined that a horse could turn a mill wheel 144 times in an hour (or 2.4 times a minute). The wheel was in radius; therefore, the horse travelled feet in one minute. Watt judged that the horse could pull with a force of . So:\n\nWatt defined and calculated the horsepower as 32,572 ft⋅lbf/min, which was rounded to an even 33,000 ft⋅lbf/min.\n\nWatt determined that a pony could lift an average per minute over a four-hour working shift. Watt then judged a horse was 50% more powerful than a pony and thus arrived at the 33,000 ft⋅lbf/min figure. \"Engineering in History\" recounts that John Smeaton initially estimated that a horse could produce per minute. John Desaguliers had previously suggested per minute and Tredgold per minute. \"Watt found by experiment in 1782 that a 'brewery horse' could produce per minute.\" James Watt and Matthew Boulton standardized that figure at per minute the next year.\n\nA common legend states that the unit was created when one of Watt's first customers, a brewer, specifically demanded an engine that would match a horse, and chose the strongest horse he had and driving it to the limit. Watt, while aware of the trick, accepted the challenge and built a machine which was actually even stronger than the figure achieved by the brewer, and it was the output of that machine which became the horsepower.\n\nIn 1993, R. D. Stevenson and R. J. Wassersug published correspondence in \"Nature\" summarizing measurements and calculations of peak and sustained work rates of a horse. Citing measurements made at the 1926 Iowa State Fair, they reported that the peak power over a few seconds has been measured to be as high as and also observed that for sustained activity, a work rate of about per horse is consistent with agricultural advice from both the 19th and 20th centuries and also consistent with a work rate of about 4 times the basal rate expended by other vertebrates for sustained activity.\n\nWhen considering human-powered equipment, a healthy human can produce about briefly (see orders of magnitude) and sustain about indefinitely; trained athletes can manage up to about briefly\nand for a period of several hours. The Jamaican sprinter Usain Bolt produced a maximum of 0.89 seconds into his 9.58 second dash world record in 2009.\n\nWhen torque formula_2 is in pound-foot units, rotational speed formula_3 is in rpm and power is required in horsepower:\n\nformula_4\n\nThe constant 5252 is the rounded value of (33,000 ft⋅lbf/min)/(2π rad/rev).\n\nWhen torque formula_2 is in inch pounds:\n\nformula_6\n\nThe constant 63,025 is the approximation of\n\nformula_7.\n\nIf torque and rotational speed are expressed in coherent SI units, the power is calculated by;\n\nformula_8\n\nwhere formula_9 is power in watts when formula_10 is torque in newton-metres, and formula_11 is angular speed in radians per second. When using other units or if the speed is in revolutions per unit time rather than radians, a conversion factor has to be included.\n\nThe following definitions have been or are widely used:\n\nIn certain situations it is necessary to distinguish between the various definitions of horsepower and thus a suffix is added: hp(I) for mechanical (or imperial) horsepower, hp(M) for metric horsepower, hp(S) for boiler (or steam) horsepower and hp(E) for electrical horsepower.\n\nAssuming the third CGPM (1901, CR 70) definition of standard gravity, , is used to define the pound-force as well as the kilogram force, and the international avoirdupois pound (1959), one mechanical horsepower is:\n\nOr given that 1 hp = 550 ft⋅lbf/s, 1 ft = 0.3048 m, 1 lbf ≈ 4.448 N, 1 J = 1 N⋅m, 1 W = 1 J/s: 1 hp ≈ 746 W\n\nThe various units used to indicate this definition (\"PS\", \"cv\", \"hk\", \"pk\", \"ks\" and \"ch\") all translate to \"horse power\" in English. British manufacturers often intermix metric horsepower and mechanical horsepower depending on the origin of the engine in question. Sometimes the metric horsepower rating of an engine is conservative enough so that the same figure can be used for both 80/1269/EEC with metric hp and SAE J1349 with imperial hp.\n\nDIN 66036 defines one metric horsepower as the power to raise a mass of 75 kilograms against the Earth's gravitational force over a distance of one metre in one second: = 75 ⋅m/s = 1 PS. This is equivalent to 735.499 W, or 98.6% of an imperial mechanical horsepower.\n\nIn 1972, the PS was rendered obsolete by EEC directives, when it was replaced by the kilowatt as the official power-measuring unit. It is still in use for commercial and advertising purposes, in addition to the kilowatt rating, as many customers are still not familiar with the use of kilowatts for engines.\n\nOther names for the metric horsepower are the Dutch , the French , the Spanish and Portuguese , the Russian , the Swedish , the Finnish , the Estonian , the Norwegian and Danish , the Hungarian , the Czech and Slovak or ), the Bosnian/Croatian/Serbian , the Bulgarian , the Macedonian , the Polish , Slovenian and the Romanian , which all equal the German .\n\nIn the 19th century, the French had their own unit, which they used instead of the CV or horsepower. It was called the poncelet and was abbreviated \"p\".\n\nTax horsepower is a non-linear rating of a motor vehicle for tax purposes. The fiscal power is formula_12, where \"P\" is the maximum power in kilowatts and \"U\" is the amount of carbon dioxide (CO) emitted in grams per kilometre. The term for CO measurements has been included in the definition only since 1998, so older ratings in CV are not directly comparable. The fiscal power has found its way into naming of automobile models, such as the popular Citroën deux-chevaux. The (ch) unit should not be confused with the French (CV).\n\nThe horsepower used for electrical machines is defined as exactly 746 W. In the US, nameplates on electrical motors show their power output in hp, not their power input. Outside the United States watts or kilowatts are generally used for electric motor ratings and in such usage it is the output power that is stated.\n\nHydraulic horsepower can represent the power available within hydraulic machinery, power through the down-hole nozzle of a drilling rig, or can be used to estimate the mechanical power needed to generate a known hydraulic flow rate.\n\nIt may be calculated as\nwhere pressure is in psi, and flow rate is in US gallons per minute.\n\nDrilling rigs are powered mechanically by rotating the drill pipe from above. Hydraulic power is still needed though, as between 2 and 7 hp are required to push mud through the drill bit to clear waste rock. Additional hydraulic power may also be used to drive a down-hole mud motor to power directional drilling.\n\nBoiler horsepower is a boiler's capacity to deliver steam to a steam engine and is not the same unit of power as the 550 ft-lb/s definition. One boiler horsepower is equal to the thermal energy rate required to evaporate 34.5 lb of fresh water at 212 °F in one hour. In the early days of steam use, the boiler horsepower was roughly comparable to the horsepower of engines fed by the boiler.\n\nThe term \"boiler horsepower\" was originally developed at the Philadelphia Centennial Exhibition in 1876, where the best steam engines of that period were tested. The average steam consumption of those engines (per output horsepower) was determined to be the evaporation of 30 pounds of water per hour, based on feed water at 100 °F, and saturated steam generated at 70 psig. This original definition is equivalent to a boiler heat output of 33,485 Btu/h. Years later in 1884, the ASME re-defined the boiler horsepower as the thermal output equal to the evaporation of 34.5 pounds per hour of water \"from and at\" 212 °F. This considerably simplified boiler testing, and provided more accurate comparisons of the boilers at that time. This revised definition is equivalent to a boiler heat output of 33,469 Btu/h. Present industrial practice is to define \"boiler horsepower\" as a boiler thermal output equal to 33,475 Btu/h, which is very close to the original and revised definitions.\n\nBoiler horsepower is still used to measure boiler output in industrial boiler engineering in Australia, the US, and New Zealand. Boiler horsepower is abbreviated BHP, not to be confused with brake horsepower, below, which is also abbreviated BHP.\n\nDrawbar horsepower (dbhp) is the power a railway locomotive has available to haul a train or an agricultural tractor to pull an implement. This is a measured figure rather than a calculated one. A special railway car called a dynamometer car coupled behind the locomotive keeps a continuous record of the drawbar pull exerted, and the speed. From these, the power generated can be calculated. To determine the maximum power available, a controllable load is required; it is normally a second locomotive with its brakes applied, in addition to a static load.\n\nIf the drawbar force (formula_14) is measured in pounds-force (lbf) and speed (formula_15) is measured in miles per hour (mph), then the drawbar power (formula_9) in horsepower (hp) is:\n\nExample: How much power is needed to pull a drawbar load of 2,025 pounds-force at 5 miles per hour?\n\n"}
{"id": "14020", "url": "https://en.wikipedia.org/wiki?curid=14020", "title": "History of London", "text": "History of London\n\nThe history of London, the capital city of England and the United Kingdom, extends over 2000 years. In that time, it has become one of the world's most significant financial and cultural capital cities. It has withstood plague, devastating fire, civil war, aerial bombardment, terrorist attacks, and riots.\n\nThe City of London, often referred to simply as \"the City\", is the historic core of the Greater London area, and is today its primary financial district, though it represents only a small part of the wider metropolis.\n\nAccording to the legendary \"Historia Regum Britanniae\", by Geoffrey of Monmouth, London was founded by Brutus of Troy about 1000–1100 B.C. after he defeated the native giant Gogmagog; the settlement was known as ', ' (Latin for New Troy), which, according to a pseudo-etymology, was corrupted to \"Trinovantum\". Trinovantes were the Iron Age tribe who inhabited the area prior to the Romans. Geoffrey provides prehistoric London with a rich array of legendary kings, such as Lud (see also Lludd, from Welsh mythology) who, he claims, renamed the town \"Caer Ludein\", from which London was derived, and was buried at Ludgate.\n\nSome recent discoveries indicate probable very early settlements near the Thames in the London area. In 1993, the remains of a Bronze Age bridge were found on the Thames's south foreshore, upstream of Vauxhall Bridge. This bridge either crossed the Thames, or went to a now lost island in the river. Dendrology dated the timbers to between 1750 BC and 1285 BC. In 2001, a further dig found that the timbers were driven vertically into the ground on the south bank of the Thames west of Vauxhall Bridge. In 2010, the foundations of a large timber structure, dated to between 4,800 BC and 4,500 BC, were found, again on the foreshore south of Vauxhall Bridge. The function of the mesolithic structure is not known. All these structures are on the south bank at a natural crossing point where the River Effra flows into the Thames.\n\nIt is thought that the Thames was an important tribal boundary, and numerous finds have been made of spear heads and weaponry from the Bronze and Iron Ages near the banks of the Thames in the London area, many of which had clearly been used in battle.\n\nArchaeologist Leslie Wallace notes that \"Because no LPRIA [Late pre-Roman Iron Age] settlements or significant domestic refuse have been found in London, despite extensive archaeological excavation, arguments for a purely Roman foundation of London are now common and uncontroversial.\"\n\n\"Londinium\" was established as a civilian town by the Romans about four years after the invasion of AD 43. London, like Rome, was founded on the point of the river where it was narrow enough to bridge and the strategic location of the city provided easy access to much of Europe. Early Roman London occupied a relatively small area, roughly equivalent to the size of Hyde Park. In around AD 60, it was destroyed by the Iceni led by their queen Boudica. The city was quickly rebuilt as a planned Roman town and recovered after perhaps 10 years, the city growing rapidly over the following decades.\n\nDuring the 2nd century \"Londinium\" was at its height and replaced Colchester as the capital of Roman Britain (Britannia). Its population was around 60,000 inhabitants. It boasted major public buildings, including the largest basilica north of the Alps, temples, bath houses, an amphitheatre and a large fort for the city garrison. Political instability and recession from the 3rd century onwards led to a slow decline.\n\nAt some time between AD 180 and AD 225, the Romans built the defensive London Wall around the landward side of the city. The wall was about long, high, and thick. The wall would survive for another 1,600 years and define the City of London's perimeters for centuries to come. The perimeters of the present City are roughly defined by the line of the ancient wall.\n\nLondonium was an ethnically diverse city with inhabitants from across the Roman Empire, including natives of Britannia, continental Europe, the Middle East, and North Africa.\n\nIn the late 3rd century, Londinium was raided on several occasions by Saxon pirates. This led, from around 255 onwards, to the construction of an additional riverside wall. Six of the traditional seven city gates of London are of Roman origin, namely: Ludgate, Newgate, Aldersgate, Cripplegate, Bishopsgate and Aldgate (Moorgate is the exception, being of medieval origin).\n\nBy the 5th century, the Roman Empire was in rapid decline and in AD 410, the Roman occupation of Britannia came to an end. Following this, the Roman city also went into rapid decline and by the end of the 5th century was practically abandoned.\n\nUntil recently it was believed that Anglo-Saxon settlement initially avoided the area immediately around Londinium. However, the discovery in 2008 of an Anglo-Saxon cemetery at Covent Garden indicates that the incomers had begun to settle there at least as early as the 6th century and possibly in the 5th. The main focus of this settlement was outside the Roman walls, clustering a short distance to the west along what is now the Strand, between the Aldwych and Trafalgar Square. It was known as \"Lundenwic\", the \"-wic\" suffix here denoting a trading settlement. Recent excavations have also highlighted the population density and relatively sophisticated urban organisation of this earlier Anglo-Saxon London, which was laid out on a grid pattern and grew to house a likely population of 10-12,000.\n\nEarly Anglo-Saxon London belonged to a people known as the Middle Saxons, from whom the name of the county of Middlesex is derived, but who probably also occupied the approximate area of modern Hertfordshire and Surrey. However, by the early 7th century the London area had been incorporated into the kingdom of the East Saxons. In 604 King Saeberht of Essex converted to Christianity and London received Mellitus, its first post-Roman bishop.\n\nAt this time Essex was under the overlordship of King Æthelberht of Kent, and it was under Æthelberht's patronage that Mellitus founded the first St. Paul's Cathedral, traditionally said to be on the site of an old Roman Temple of Diana (although Christopher Wren found no evidence of this). It would have only been a modest church at first and may well have been destroyed after he was expelled from the city by Saeberht's pagan successors.\n\nThe permanent establishment of Christianity in the East Saxon kingdom took place in the reign of King Sigeberht II in the 650s. During the 8th century, the kingdom of Mercia extended its dominance over south-eastern England, initially through overlordship which at times developed into outright annexation. London seems to have come under direct Mercian control in the 730s.\n\nViking attacks dominated most of the 9th century, becoming increasingly common from around 830 onwards. London was sacked in 842 and again in 851. The Danish \"Great Heathen Army\", which had rampaged across England since 865, wintered in London in 871. The city remained in Danish hands until 886, when it was captured by the forces of King Alfred the Great of Wessex and reincorporated into Mercia, then governed under Alfred's sovereignty by his son-in-law Ealdorman Æthelred.\n\nAround this time the focus of settlement moved within the old Roman walls for the sake of defence, and the city became known as \"Lundenburh\". The Roman walls were repaired and the defensive ditch re-cut, while the bridge was probably rebuilt at this time. A second fortified Borough was established on the south bank at Southwark, the \"Suthringa Geworc\" (defensive work of the men of Surrey). The old settlement of \"Lundenwic\" became known as the \"ealdwic\" or \"old settlement\", a name which survives today as Aldwich.\n\nFrom this point, the City of London began to develop its own unique local government. Following Ethelred's death in 911 it was transferred to Wessex, preceding the absorption of the rest of Mercia in 918. Although it faced competition for political pre-eminence in the united Kingdom of England from the traditional West Saxon centre of Winchester, London's size and commercial wealth brought it a steadily increasing importance as a focus of governmental activity. King Athelstan held many meetings of the \"witan\" in London and issued laws from there, while King Æthelred the Unready issued the Laws of London there in 978.\n\nFollowing the resumption of Viking attacks in the reign of Ethelred, London was unsuccessfully attacked in 994 by an army under King Sweyn Forkbeard of Denmark. As English resistance to the sustained and escalating Danish onslaught finally collapsed in 1013, London repulsed an attack by the Danes and was the last place to hold out while the rest of the country submitted to Sweyn, but by the end of the year it too capitulated and Æthelred fled abroad. Sweyn died just five weeks after having been proclaimed king and Æthelred was restored to the throne, but Sweyn's son Cnut returned to the attack in 1015.\n\nAfter Æthelred's death at London in 1016 his son Edmund Ironside was proclaimed king there by the \"witangemot\" and left to gather forces in Wessex. London was then subjected to a systematic siege by Cnut but was relieved by King Edmund's army; when Edmund again left to recruit reinforcements in Wessex the Danes resumed the siege but were again unsuccessful. However, following his defeat at the Battle of Assandun Edmund ceded to Cnut all of England north of the Thames, including London, and his death a few weeks later left Cnut in control of the whole country.\n\nA Norse saga tells of a battle when King Æthelred returned to attack Danish-occupied London. According to the saga, the Danes lined London Bridge and showered the attackers with spears. Undaunted, the attackers pulled the roofs off nearby houses and held them over their heads in the boats. Thus protected, they were able to get close enough to the bridge to attach ropes to the piers and pull the bridge down, thus ending the Viking occupation of London. This story presumably relates to Æthelred's return to power after Sweyn's death in 1014, but there is no strong evidence of any such struggle for control of London on that occasion.\n\nFollowing the extinction of Cnut's dynasty in 1042 English rule was restored under Edward the Confessor. He was responsible for the foundation of Westminster Abbey and spent much of his time at Westminster, which from this time steadily supplanted the City itself as the centre of government. Edward's death at Westminster in 1066 without a clear heir led to a succession dispute and the Norman conquest of England. Earl Harold Godwinson was elected king by the \"witangemot\" and crowned in Westminster Abbey but was defeated and killed by William the Bastard, Duke of Normandy at the Battle of Hastings. The surviving members of the \"witan\" met in London and elected King Edward's young nephew Edgar the Ætheling as king.\n\nThe Normans advanced to the south bank of the Thames opposite London, where they defeated an English attack and burned Southwark but were unable to storm the bridge. They moved upstream and crossed the river at Wallingford before advancing on London from the north-west. The resolve of the English leadership to resist collapsed and the chief citizens of London went out together with the leading members of the Church and aristocracy to submit to William at Berkhamstead, although according to some accounts there was a subsequent violent clash when the Normans reached the city. Having occupied London, William was crowned king in Westminster Abbey.\n\nThe new Norman regime established new fortresses within the city to dominate the native population. By far the most important of these was the Tower of London at the eastern end of the city, where the initial timber fortification was rapidly replaced by the construction of the first stone castle in England. The smaller forts of Baynard's Castle and Montfichet's Castle were also established along the waterfront. King William also granted a charter in 1067 confirming the city's existing rights, privileges and laws. London was a centre of England's nascent Jewish population, the first of whom arrived in about 1070. Its growing self-government was consolidated by the election rights granted by King John in 1199 and 1215.\n\nIn 1097, William Rufus, the son of William the Conqueror began the construction of 'Westminster Hall', which became the focus of the Palace of Westminster.\n\nIn 1176, construction began of the most famous incarnation of London Bridge (completed in 1209) which was built on the site of several earlier timber bridges. This bridge would last for 600 years, and remained the only bridge across the River Thames until 1739.\n\nViolence against Jews took place in 1190, after it was rumoured that the new King had ordered their massacre after they had presented themselves at his coronation.\n\nIn 1216, during the First Barons' War London was occupied by Prince Louis of France, who had been called in by the baronial rebels against King John and was acclaimed as King of England in St Paul's Cathedral. However, following John's death in 1217 Louis's supporters reverted to their Plantagenet allegiance, rallying round John's son Henry III, and Louis was forced to withdraw from England.\n\nIn 1224, after an accusation of ritual murder, the Jewish community was subjected to a steep punitive levy. Then in 1232, Henry III confiscated the principal synagogue of the London Jewish community because he claimed their chanting was audible in a neighboring church. In 1264, during the Second Barons' War, Simon de Montfort's rebels occupied London and killed 500 Jews while attempting to seize records of debts.\n\nLondon's Jewish community was forced to leave England by the expulsion by Edward I in 1290. They left for France, Holland and further afield; their property was seized, and many suffered robbery and murder as they departed.\n\nOver the following centuries, London would shake off the heavy French cultural and linguistic influence which had been there since the times of the Norman conquest. The city would figure heavily in the development of Early Modern English.\nDuring the Peasants' Revolt of 1381, London was invaded by rebels led by Wat Tyler. A group of peasants stormed the Tower of London and executed the Lord Chancellor, Archbishop Simon Sudbury, and the Lord Treasurer. The peasants looted the city and set fire to numerous buildings. Tyler was stabbed to death by the Lord Mayor William Walworth in a confrontation at Smithfield and the revolt collapsed.\n\nTrade increased steadily during the Middle Ages, and London grew rapidly as a result. In 1100, London's population was somewhat more than 15,000. By 1300, it had grown to roughly 80,000. London lost at least half of its population during the Black Death in the mid-14th century, but its economic and political importance stimulated a rapid recovery despite further epidemics. Trade in London was organised into various guilds, which effectively controlled the city, and elected the Lord Mayor of the City of London.\n\nMedieval London was made up of narrow and twisting streets, and most of the buildings were made from combustible materials such as timber and straw, which made fire a constant threat, while sanitation in cities was of low-quality.\n\nIn 1475, the Hanseatic League set up its main English trading base (\"kontor\") in London, called \"Stalhof\" or \"Steelyard\". It existed until 1853, when the Hanseatic cities of Lübeck, Bremen and Hamburg sold the property to South Eastern Railway. Woollen cloth was shipped undyed and undressed from 14th/15th century London to the nearby shores of the Low Countries, where it was considered indispensable.\n\nDuring the Reformation, London was the principal early centre of Protestantism in England. Its close commercial connections with the Protestant heartlands in northern continental Europe, large foreign mercantile communities, disproportionately large number of literate inhabitants and role as the centre of the English print trade all contributed to the spread of the new ideas of religious reform. Before the Reformation, more than half of the area of London was the property of monasteries, nunneries and other religious houses.\n\nHenry VIII's \"Dissolution of the Monasteries\" had a profound effect on the city as nearly all of this property changed hands. The process started in the mid 1530s, and by 1538 most of the larger monastic houses had been abolished. Holy Trinity Aldgate went to Lord Audley, and the Marquess of Winchester built himself a house in part of its precincts. The Charterhouse went to Lord North, Blackfriars to , the leper hospital of St Giles to Lord Dudley, while the king took for himself the leper hospital of St James, which was rebuilt as St James's Palace.\n\nThe period saw London rapidly rising in importance among Europe's commercial centres. Trade expanded beyond Western Europe to Russia, the Levant, and the Americas. This was the period of mercantilism and monopoly trading companies such as the Muscovy Company (1555) and the British East India Company (1600) were established in London by Royal Charter. The latter, which ultimately came to rule India, was one of the key institutions in London, and in Britain as a whole, for two and a half centuries. Immigrants arrived in London not just from all over England and Wales, but from abroad as well, for example Huguenots from France; the population rose from an estimated 50,000 in 1530 to about 225,000 in 1605. The growth of the population and wealth of London was fuelled by a vast expansion in the use of coastal shipping.\n\nThe late 16th and early 17th century saw the great flourishing of drama in London whose preeminent figure was William Shakespeare. During the mostly calm later years of Elizabeth's reign, some of her courtiers and some of the wealthier citizens of London built themselves country residences in Middlesex, Essex and Surrey. This was an early stirring of the villa movement, the taste for residences which were neither of the city nor on an agricultural estate, but at the time of Elizabeth's death in 1603, London was still very compact.\n\nXenophobia was rampant in London, and increased after the 1580s. Many immigrants became disillusioned by routine threats of violence and molestation, attempts at expulsion of foreigners, and the great difficulty in acquiring English citizenship. Dutch cities proved more hospitable, and many left London permanently. Foreigners are estimated to have made up 4,000 of the 100,000 residents of London by 1600, many being Dutch and German workers and traders.\n\nLondon's expansion beyond the boundaries of the City was decisively established in the 17th century. In the opening years of that century the immediate environs of the City, with the principal exception of the aristocratic residences in the direction of Westminster, were still considered not conducive to health. Immediately to the north was Moorfields, which had recently been drained and laid out in walks, but it was frequented by beggars and travellers, who crossed it in order to get into London. Adjoining Moorfields were Finsbury Fields, a favourite practising ground for the archers, Mile End, then a common on the Great Eastern Road and famous as a rendezvous for the troops.\n\nThe preparations for King James I becoming king were interrupted by a severe plague epidemic, which may have killed over thirty thousand people. The Lord Mayor's Show, which had been discontinued for some years, was revived by order of the king in 1609. The dissolved monastery of the Charterhouse, which had been bought and sold by the courtiers several times, was purchased by Thomas Sutton for £13,000. The new hospital, chapel, and schoolhouse were begun in 1611. Charterhouse School was to be one of the principal public schools in London until it moved to Surrey in Victorian times, and the site is still used as a medical school.\n\nThe general meeting-place of Londoners in the day-time was the nave of Old St. Paul's Cathedral. Merchants conducted business in the aisles, and used the font as a counter upon which to make their payments; lawyers received clients at their particular pillars; and the unemployed looked for work. St Paul's Churchyard was the centre of the book trade and Fleet Street was a centre of public entertainment. Under James I the theatre, which established itself so firmly in the latter years of Elizabeth, grew further in popularity. The performances at the public theatres were complemented by elaborate masques at the royal court and at the inns of court.\n\nCharles I acceded to the throne in 1625. During his reign, aristocrats began to inhabit the West End in large numbers. In addition to those who had specific business at court, increasing numbers of country landowners and their families lived in London for part of the year simply for the social life. This was the beginning of the \"London season\". Lincoln's Inn Fields was built about 1629. The piazza of Covent Garden, designed by England's first classically trained architect Inigo Jones followed in about 1632. The neighbouring streets were built shortly afterwards, and the names of Henrietta, Charles, James, King and York Streets were given after members of the royal family.\nIn January 1642 five members of parliament whom the King wished to arrest were granted refuge in the City. In August of the same year the King raised his banner at Nottingham, and during the English Civil War London took the side of the parliament. Initially the king had the upper hand in military terms and in November he won the Battle of Brentford a few miles to the west of London. The City organised a new makeshift army and Charles hesitated and retreated. Subsequently, an extensive system of fortifications was built to protect London from a renewed attack by the Royalists. This comprised a strong earthen rampart, enhanced with bastions and redoubts. It was well beyond the City walls and encompassed the whole urban area, including Westminster and Southwark. London was not seriously threatened by the royalists again, and the financial resources of the City made an important contribution to the parliamentarians' victory in the war.\n\nThe unsanitary and overcrowded City of London has suffered from the numerous outbreaks of the plague many times over the centuries, but in Britain it is the last major outbreak which is remembered as the \"Great Plague\" It occurred in 1665 and 1666 and killed around 60,000 people, which was one fifth of the population. Samuel Pepys chronicled the epidemic in his diary. On 4 September 1665 he wrote \"I have stayed in the city till above 7400 died in one week, and of them about 6000 of the plague, and little noise heard day or night but tolling of bells.\"\n\nThe Great Plague was immediately followed by another catastrophe, albeit one which helped to put an end to the plague. On the Sunday, 2 September 1666 the Great Fire of London broke out at one o'clock in the morning at a bakery in Pudding Lane in the southern part of the City. Fanned by an eastern wind the fire spread, and efforts to arrest it by pulling down houses to make firebreaks were disorganised to begin with. On Tuesday night the wind fell somewhat, and on Wednesday the fire slackened. On Thursday it was extinguished, but on the evening of that day the flames again burst forth at the Temple. Some houses were at once blown up by gunpowder, and thus the fire was finally mastered. The Monument was built to commemorate the fire: for over a century and a half it bore an inscription attributing the conflagration to a \"\"popish frenzy\"\".\nThe fire destroyed about 60% of the City, including Old St Paul's Cathedral, 87 parish churches, 44 livery company halls and the Royal Exchange. However, the number of lives lost was surprisingly small; it is believed to have been 16 at most. Within a few days of the fire, three plans were presented to the king for the rebuilding of the city, by Christopher Wren, John Evelyn and Robert Hooke.\n\nWren proposed to build main thoroughfares north and south, and east and west, to insulate all the churches in conspicuous positions, to form the most public places into large piazzas, to unite the halls of the 12 chief livery companies into one regular square annexed to the Guildhall, and to make a fine quay on the bank of the river from Blackfriars to the Tower of London. Wren wished to build the new streets straight and in three standard widths of thirty, sixty and ninety feet. Evelyn's plan differed from Wren's chiefly in proposing a street from the church of St Dunstan's in the East to the St Paul's, and in having no quay or terrace along the river. These plans were not implemented, and the rebuilt city generally followed the streetplan of the old one, and most of it has survived into the 21st century.\n\nNonetheless, the new City was different from the old one. Many aristocratic residents never returned, preferring to take new houses in the West End, where fashionable new districts such as St. James's were built close to the main royal residence, which was Whitehall Palace until it was destroyed by fire in the 1690s, and thereafter St. James's Palace. The rural lane of Piccadilly sprouted courtiers mansions such as Burlington House. Thus the separation between the middle class mercantile City of London, and the aristocratic world of the court in Westminster became complete.\n\nIn the City itself there was a move from wooden buildings to stone and brick construction to reduce the risk of fire. Parliament's Rebuilding of London Act 1666 stated \"\"building with brick [is] not only more comely and durable, but also more safe against future perils of fire\"\". From then on only doorcases, window-frames and shop fronts were allowed to be made of wood.\n\nChristopher Wren's plan for a new model London came to nothing, but he was appointed to rebuild the ruined parish churches and to replace St Paul's Cathedral. His domed baroque cathedral was the primary symbol of London for at least a century and a half. As city surveyor, Robert Hooke oversaw the reconstruction of the City's houses. The East End, that is the area immediately to the east of the city walls, also became heavily populated in the decades after the Great Fire. London's docks began to extend downstream, attracting many working people who worked on the docks themselves and in the processing and distributive trades. These people lived in Whitechapel, Wapping, Stepney and Limehouse, generally in slum conditions.\n\nIn the winter of 1683–1684, a frost fair was held on the Thames. The frost, which began about seven weeks before Christmas and continued for six weeks after, was the greatest on record. The Revocation of the Edict of Nantes in 1685 led to a large migration on Huguenots to London. They established a silk industry at Spitalfields.\n\nAt this time the Bank of England was founded, and the British East India Company was expanding its influence. Lloyd's of London also began to operate in the late 17th century. In 1700, London handled 80% of England's imports, 69% of its exports and 86% of its re-exports. Many of the goods were luxuries from the Americas and Asia such as silk, sugar, tea and tobacco. The last figure emphasises London's role as an entrepot: while it had many craftsmen in the 17th century, and would later acquire some large factories, its economic prominence was never based primarily on industry. Instead it was a great trading and redistribution centre. Goods were brought to London by England's increasingly dominant merchant navy, not only to satisfy domestic demand, but also for re-export throughout Europe and beyond.\n\nWilliam III, a Dutchman, cared little for London, the smoke of which gave him asthma, and after the first fire at Whitehall Palace (1691) he purchased Nottingham House and transformed it into Kensington Palace. Kensington was then an insignificant village, but the arrival of the court soon caused it to grow in importance. The palace was rarely favoured by future monarchs, but its construction was another step in the expansion of the bounds of London. During the same reign Greenwich Hospital, then well outside the boundary of London, but now comfortably inside it, was begun; it was the naval complement to the Chelsea Hospital for former soldiers, which had been founded in 1681. During the reign of Queen Anne an act was passed authorising the building of 50 new churches to serve the greatly increased population living outside the boundaries of the City of London.\n\nThe 18th century was a period of rapid growth for London, reflecting an increasing national population, the early stirrings of the Industrial Revolution, and London's role at the centre of the evolving British Empire.\n\nIn 1707, an Act of Union was passed merging the Scottish and the English Parliaments, thus establishing the Kingdom of Great Britain. A year later, in 1708 Christopher Wren's masterpiece, St Paul's Cathedral was completed on his birthday. However, the first service had been held on 2 December 1697; more than 10 years earlier. This Cathedral replaced the original St. Paul's which had been completely destroyed in the Great Fire of London. This building is considered one of the finest in Britain and a fine example of Baroque architecture.\n\nMany tradesmen from different countries came to London to trade goods and merchandise. Also, more immigrants moved to London making the population greater. More people also moved to London for work and for business making London an altogether bigger and busier city. Britain's victory in the Seven Years' War increased the country's international standing and opened large new markets to British trade, further boosting London's prosperity.\n\nDuring the Georgian period London spread beyond its traditional limits at an accelerating pace. This is shown in a series of detailed maps, particularly John Rocque's 1741–45 map \"(see below)\" and his 1746 Map of London. New districts such as Mayfair were built for the rich in the West End, new bridges over the Thames encouraged an acceleration of development in South London and in the East End, the Port of London expanded downstream from the City. During this period was also the uprising of the American colonies. In 1780, the Tower of London held its only American prisoner, former President of the Continental Congress, Henry Laurens. In 1779, he was the Congress's representative of Holland, and got the country's support for the Revolution. On his return voyage back to America, the Royal Navy captured him and charged him with treason after finding evidence of a reason of war between Great Britain and the Netherlands. He was released from the Tower on 21 December 1781 in exchange for General Lord Cornwallis.\n\nIn 1762, George III acquired Buckingham Palace (then called Buckingham House) from the Duke of Buckingham. It was enlarged over the next 75 years by architects such as John Nash.\nA phenomenon of the era was the coffeehouse, which became a popular place to debate ideas. Growing literacy and the development of the printing press meant that news became widely available. Fleet Street became the centre of the embryonic national press during the century.\n\n18th-century London was dogged by crime. The Bow Street Runners were established in 1750 as a professional police force. Penalties for crime were harsh, with the death penalty being applied for fairly minor crimes. Public hangings were common in London, and were popular public events.\n\nIn 1780, London was rocked by the Gordon Riots, an uprising by Protestants against Roman Catholic emancipation led by Lord George Gordon. Severe damage was caused to Catholic churches and homes, and 285 rioters were killed.\n\nIn the year 1787, freed slaves from London, America, and many of Britain's colonies founded Freetown in modern-day Sierra Leone.\n\nUp until 1750, London Bridge was the only crossing over the Thames, but in that year Westminster Bridge was opened and, for the first time in history, London Bridge, in a sense, had a rival. In 1798, Frankfurt banker Nathan Mayer Rothschild arrived in London and set up a banking house in the city, with a large sum of money given to him by his father, Amschel Mayer Rothschild. The Rothschilds also had banks in Paris and Vienna. The bank financed numerous large-scale projects, especially regarding railways around the world and the Suez Canal.\n\nThe 18th century saw the breakaway of the American colonies and many other unfortunate events in London, but also great change and Enlightenment. This all led into the beginning of modern times, the 19th century.\n\nDuring the 19th century, London was transformed into the world's largest city and capital of the British Empire. Its population expanded from 1 million in 1800 to 6.7 million a century later. During this period, London became a global political, financial, and trading capital. In this position, it was largely unrivalled until the latter part of the century, when Paris and New York began to threaten its dominance.\n\nWhile the city grew wealthy as Britain's holdings expanded, 19th-century London was also a city of poverty, where millions lived in overcrowded and unsanitary slums. Life for the poor was immortalised by Charles Dickens in such novels as Oliver Twist In 1810, after the death of Sir Francis Baring and Abraham Goldsmid, Rothschild emerges as the major banker in London.\n\nIn 1829, the then Home Secretary (and future prime minister) Robert Peel established the Metropolitan Police as a police force covering the entire urban area. The force gained the nickname of \"bobbies\" or \"peelers\" named after Robert Peel.\n\n19th-century London was transformed by the coming of the railways. A new network of metropolitan railways allowed for the development of suburbs in neighbouring counties from which middle-class and wealthy people could commute to the centre. While this spurred the massive outward growth of the city, the growth of greater London also exacerbated the class divide, as the wealthier classes emigrated to the suburbs, leaving the poor to inhabit the inner city areas.\n\nThe first railway to be built in London was a line from London Bridge to Greenwich, which opened in 1836. This was soon followed by the opening of great rail termini which eventually linked London to every corner of Great Britain, including Euston station (1837), Paddington station (1838), Fenchurch Street station (1841), Waterloo station (1848), King's Cross station (1850), and St Pancras station (1863). From 1863, the first lines of the London Underground were constructed.\n\nThe urbanised area continued to grow rapidly, spreading into Islington, Paddington, Belgravia, Holborn, Finsbury, Shoreditch, Southwark and Lambeth. Towards the middle of the century, London's antiquated local government system, consisting of ancient parishes and vestries, struggled to cope with the rapid growth in population. In 1855, the Metropolitan Board of Works (MBW) was created to provide London with adequate infrastructure to cope with its growth. One of its first tasks was addressing London's sanitation problems. At the time, raw sewage was pumped straight into the River Thames. This culminated in The Great Stink of 1858. Parliament finally gave consent for the MBW to construct a large system of sewers. The engineer put in charge of building the new system was Joseph Bazalgette. In what was one of the largest civil engineering projects of the 19th century, he oversaw construction of over 2100 km of tunnels and pipes under London to take away sewage and provide clean drinking water. When the London sewerage system was completed, the death toll in London dropped dramatically, and epidemics of cholera and other diseases were curtailed. Bazalgette's system is still in use today.\n\nOne of the most famous events of 19th-century London was the Great Exhibition of 1851. Held at The Crystal Palace, the fair attracted 6 million visitors from across the world and displayed Britain at the height of its Imperial dominance.\n\nAs the capital of a massive empire, London became a magnet for immigrants from the colonies and poorer parts of Europe. A large Irish population settled in the city during the Victorian period, with many of the newcomers refugees from the Great Famine (1845–1849). At one point, Catholic Irish made up about 20% of London's population; they typically lived in overcrowded slums. London also became home to a sizable Jewish community, which was notable for its entrepreneurship in the clothing trade and merchandising.\n\nIn 1888, the new County of London was established, administered by the London County Council. This was the first elected London-wide administrative body, replacing the earlier Metropolitan Board of Works, which had been made up of appointees. The County of London covered broadly what was then the full extent of the London conurbation, although the conurbation later outgrew the boundaries of the county. In 1900, the county was sub-divided into 28 metropolitan boroughs, which formed a more local tier of administration than the county council.\n\nMany famous buildings and landmarks of London were constructed during the 19th century including:\n\nLondon entered the 20th century at the height of its influence as the capital of one of the largest empires in history, but the new century was to bring many challenges.\n\nLondon's population continued to grow rapidly in the early decades of the century, and public transport was greatly expanded. A large tram network was constructed by the London County Council, through the LCC Tramways; the first motorbus service began in the 1900s. Improvements to London's overground and underground rail network, including large scale electrification were progressively carried out.\n\nDuring World War I, London experienced its first bombing raids carried out by German zeppelin airships; these killed around 700 people and caused great terror, but were merely a foretaste of what was to come. The city of London would experience many more terrors as a result of both World Wars. The largest explosion in London occurred during World War I: the Silvertown explosion, when a munitions factory containing 50 tons of TNT exploded, killing 73 and injuring 400.\n\nThe period between the two World Wars saw London's geographical extent growing more quickly than ever before or since. A preference for lower density suburban housing, typically semi-detached, by Londoners seeking a more \"rural\" lifestyle, superseded Londoners' old predilection for terraced houses. This was facilitated not only by a continuing expansion of the rail network, including trams and the Underground, but also by slowly widening car ownership. London's suburbs expanded outside the boundaries of the County of London, into the neighbouring counties of Essex, Hertfordshire, Kent, Middlesex and Surrey.\n\nLike the rest of the country, London suffered severe unemployment during the Great Depression of the 1930s. In the East End during the 1930s, politically extreme parties of both right and left flourished. The Communist Party of Great Britain and the British Union of Fascists both gained serious support. Clashes between right and left culminated in the Battle of Cable Street in 1936. The population of London reached an all-time peak of 8.6 million in 1939.\n\nLarge numbers of Jewish immigrants fleeing from Nazi Germany settled in London during the 1930s, mostly in the East End.\n\nLabour Party politician Herbert Morrison was a dominant figure in local government in the 1920s and 1930s. He became mayor of Hackney and a member of the London County Council in 1922, and for a while was Minister of Transport in Ramsay MacDonald's cabinet. When Labour gained power in London in 1934, Morrison unified the bus, tram and trolleybus services with the Underground, by the creation of the London Passenger Transport Board (known as London Transport) in 1933., He led the effort to finance and build the new Waterloo Bridge. He designed the Metropolitan Green Belt around the suburbs and worked to clear slums, build schools, and reform public assistance.\n\nDuring World War II, London, as many other British cities, suffered severe damage, being bombed extensively by the \"Luftwaffe\" as a part of The Blitz. Prior to the bombing, hundreds of thousands of children in London were evacuated to the countryside to avoid the bombing. Civilians took shelter from the air raids in underground stations.\n\nThe heaviest bombing took place during The Blitz between 7 September 1940 and 10 May 1941. During this period, London was subjected to 71 separate raids receiving over 18,000 tonnes of high explosive. One raid in December 1940, which became known as the Second Great Fire of London, saw a firestorm engulf much of the City of London and destroy many historic buildings. St Paul's Cathedral, however, remained unscathed; a photograph showing the Cathedral shrouded in smoke became a famous image of the war.\n\nHaving failed to defeat Britain, Hitler turned his attention to the Eastern front and regular bombing raids ceased. They began again, but on a smaller scale with the \"Little Blitz\" in early 1944. Towards the end of the war, during 1944/45 London again came under heavy attack by pilotless V-1 flying bombs and V-2 rockets, which were fired from Nazi occupied Europe. These attacks only came to an end when their launch sites were captured by advancing Allied forces.\n\nLondon suffered severe damage and heavy casualties, the worst hit part being the Docklands area. By the war's end, just under 30,000 Londoners had been killed by the bombing, and over 50,000 seriously injured, tens of thousands of buildings were destroyed, and hundreds of thousands of people were made homeless.\n\nThree years after the war, the 1948 Summer Olympics were held at the original Wembley Stadium, at a time when the city had barely recovered from the war. London's rebuilding was slow to begin. However, in 1951 the Festival of Britain was held, which marked an increasing mood of optimism and forward looking.\n\nIn the immediate postwar years housing was a major issue in London, due to the large amount of housing which had been destroyed in the war. The authorities decided upon high-rise blocks of flats as the answer to housing shortages. During the 1950s and 1960s the skyline of London altered dramatically as tower blocks were erected, although these later proved unpopular. In a bid to reduce the number of people living in overcrowded housing, a policy was introduced of encouraging people to move into newly built new towns surrounding London.\n\nThrough the 19th and in the early half of the 20th century, Londoners used coal for heating their homes, which produced large amounts of smoke. In combination with climatic conditions this often caused a characteristic smog, and London became known for its typical \"London Fog\", also known as \"Pea Soupers\". London was sometimes referred to as \"The Smoke\" because of this. In 1952, this culminated in the disastrous Great Smog of 1952 which lasted for five days and killed over 4,000 people. In response to this, the Clean Air Act 1956 was passed, mandating the creating of \"smokeless zones\" where the use of \"smokeless\" fuels was required (this was at a time when most households still used open fires); the Act was effective.\nStarting in the mid-1960s, and partly as a result of the success of such UK musicians as the Beatles and The Rolling Stones, London became a centre for the worldwide youth culture, exemplified by the Swinging London subculture which made Carnaby Street a household name of youth fashion around the world. London's role as a trendsetter for youth fashion was revived strongly in the 1980s during the new wave and punk eras. In the mid-1990s this was revived to some extent with the emergence of the Britpop era.\n\nFrom the 1950s onwards London became home to a large number of immigrants, largely from Commonwealth countries such as Jamaica, India, Bangladesh, Pakistan, which dramatically changed the face of London, turning it into one of the most diverse cities in Europe. However, the integration of the new immigrants was not always easy. Racial tensions emerged in events such as the Brixton Riots in the early 1980s.\n\nFrom the beginning of \"The Troubles\" in Northern Ireland in the early 1970s until the mid-1990s, London was subjected to repeated terrorist attacks by the Provisional IRA.\n\nThe outward expansion of London was slowed by the war, and the introduction of the Metropolitan Green Belt. Due to this outward expansion, in 1965 the old County of London (which by now only covered part of the London conurbation) and the London County Council were abolished, and the much larger area of Greater London was established with a new Greater London Council (GLC) to administer it, along with 32 new London boroughs.\n\nGreater London's population declined steadily in the decades after World War II, from an estimated peak of 8.6 million in 1939 to around 6.8 million in the 1980s. However, it then began to increase again in the late 1980s, encouraged by strong economic performance and an increasingly positive image.\n\nLondon's traditional status as a major port declined dramatically in the post-war decades as the old Docklands could not accommodate large modern container ships. The principal ports for London moved downstream to the ports of Felixstowe and Tilbury. The docklands area had become largely derelict by the 1980s, but was redeveloped into flats and offices from the mid-1980s onwards. The Thames Barrier was completed in the 1980s to protect London against tidal surges from the North Sea.\n\nIn the early 1980s political disputes between the GLC run by Ken Livingstone and the Conservative government of Margaret Thatcher led to the GLC's abolition in 1986, with most of its powers relegated to the London boroughs. This left London as the only large metropolis in the world without a central administration.\n\nIn 2000, London-wide government was restored, with the creation of the Greater London Authority (GLA) by Tony Blair's government, covering the same area of Greater London. The new authority had similar powers to the old GLC, but was made up of a directly elected Mayor and a London Assembly. The first election took place on 4 May, with Ken Livingstone comfortably regaining his previous post. London was recognised as one of the nine regions of England. In global perspective, it was emerging as a World city widely compared to New York and Tokyo.\n\nAround the start of the 21st century, London hosted the much derided Millennium Dome at Greenwich, to mark the new century. Other Millennium projects were more successful. One was the largest observation wheel in the world, the \"Millennium Wheel\", or the London Eye, which was erected as a temporary structure, but soon became a fixture, and draws four million visitors a year. The National Lottery also released a flood of funds for major enhancements to existing attractions, for example the roofing of the Great Court at the British Museum.\n\nThe London Plan, published by the Mayor of London in 2004, estimated that the population would reach 8.1 million by 2016, and continue to rise thereafter. This was reflected in a move towards denser, more urban styles of building, including a greatly increased number of tall buildings, and proposals for major enhancements to the public transport network. However, funding for projects such as Crossrail remained a struggle.\n\nOn 6 July 2005 London won the right to host the 2012 Olympics and Paralympics making it the first city to host the modern games three times. However, celebrations were cut short the following day when the city was rocked by a series of terrorist attacks. More than 50 were killed and 750 injured in three bombings on London Underground trains and a fourth on a double decker bus near King's Cross.\n\nLondon was the starting point for countrywide riots which occurred in August 2011, when thousands of people rioted in several city boroughs and in towns across England. In 2011, the population grew over 8 million people for the first time in decades. White British formed less than half of the population for the first time.\n\nIn the public there was ambivalence leading-up to the Olympics, though public sentiment changed strongly in their favour following a successful opening ceremony and when the anticipated organisational and transport problems never occurred.\n\n\n\n\n\n\n\n"}
{"id": "14021", "url": "https://en.wikipedia.org/wiki?curid=14021", "title": "History of astronomy", "text": "History of astronomy\n\nAstronomy is the oldest of the natural sciences, dating back to antiquity, with its origins in the religious, mythological, cosmological, calendrical, and astrological beliefs and practices of prehistory: vestiges of these are still found in astrology, a discipline long interwoven with public and governmental astronomy. It was not completely separated in Europe (see astrology and astronomy) during the Copernican Revolution starting in 1543. In some cultures, astronomical data was used for astrological prognostication.\n\nAncient astronomers were able to differentiate between stars and planets, as stars remain relatively fixed over the centuries while planets will move an appreciable amount during a comparatively short time.\n\nEarly cultures identified celestial objects with gods and spirits. They related these objects (and their movements) to phenomena such as rain, drought, seasons, and tides. It is generally believed that the first astronomers were priests, and that they understood celestial objects and events to be manifestations of the divine, hence early astronomy's connection to what is now called astrology. Ancient structures with possibly astronomical alignments (such as Stonehenge) probably fulfilled astronomical, religious, and social functions.\n\nCalendars of the world have often been set by observations of the Sun and Moon (marking the day, month and year), and were important to agricultural societies, in which the harvest depended on planting at the correct time of year, and for which the nearly full moon was the only lighting for night-time travel into city markets.\nThe common modern calendar is based on the Roman calendar. Although originally a lunar calendar, it broke the traditional link of the month to the phases of the moon and divided the year into twelve almost-equal months, that mostly alternated between thirty and thirty-one days. Julius Caesar instigated calendar reform in 46 BCE and introduced what is now called the Julian calendar, based upon the 365  day year length originally proposed by the 4th century BCE Greek astronomer Callippus.\n\nSince 1990 our understanding of prehistoric Europeans has been radically changed by discoveries of ancient astronomical artifacts throughout Europe. The artifacts demonstrate that Neolithic and Bronze Age Europeans had a sophisticated knowledge of mathematics and astronomy.\n\nAmong the discoveries are:\n\n\nThe origins of Western astronomy can be found in Mesopotamia, the \"land between the rivers\" Tigris and Euphrates, where the ancient kingdoms of Sumer, Assyria, and Babylonia were located. A form of writing known as cuneiform emerged among the Sumerians around 3500–3000 BC. Our knowledge of Sumerian astronomy is indirect, via the earliest Babylonian star catalogues dating from about 1200 BC. The fact that many star names appear in Sumerian suggests a continuity reaching into the Early Bronze Age. Astral theology, which gave planetary gods an important role in Mesopotamian mythology and religion, began with the Sumerians. They also used a sexagesimal (base 60) place-value number system, which simplified the task of recording very large and very small numbers. The modern practice of dividing a circle into 360 degrees, or an hour into 60 minutes, began with the Sumerians. For more information, see the articles on Babylonian numerals and mathematics.\n\nClassical sources frequently use the term Chaldeans for the astronomers of Mesopotamia, who were, in reality, priest-scribes specializing in astrology and other forms of divination.\n\nThe first evidence of recognition that astronomical phenomena are periodic and of the application of mathematics to their prediction is Babylonian. Tablets dating back to the Old Babylonian period document the application of mathematics to the variation in the length of daylight over a solar year. Centuries of Babylonian observations of celestial phenomena are recorded in the series of cuneiform tablets known as the \"Enūma Anu Enlil\". The oldest significant astronomical text that we possess is Tablet 63 of the \"Enūma Anu Enlil\", the Venus tablet of Ammi-saduqa, which lists the first and last visible risings of Venus over a period of about 21 years and is the earliest evidence that the phenomena of a planet were recognized as periodic. The MUL.APIN, contains catalogues of stars and constellations as well as schemes for predicting heliacal risings and the settings of the planets, lengths of daylight measured by a water clock, gnomon, shadows, and intercalations. The Babylonian GU text arranges stars in 'strings' that lie along declination circles and thus measure right-ascensions or time-intervals, and also employs the stars of the zenith, which are also separated by given right-ascensional differences.\n\nA significant increase in the quality and frequency of Babylonian observations appeared during the reign of Nabonassar (747–733 BC). The systematic records of ominous phenomena in Babylonian astronomical diaries that began at this time allowed for the discovery of a repeating 18-year cycle of lunar eclipses, for example. The Greek astronomer Ptolemy later used Nabonassar's reign to fix the beginning of an era, since he felt that the earliest usable observations began at this time.\n\nThe last stages in the development of Babylonian astronomy took place during the time of the Seleucid Empire (323–60 BC). In the 3rd century BC, astronomers began to use \"goal-year texts\" to predict the motions of the planets. These texts compiled records of past observations to find repeating occurrences of ominous phenomena for each planet. About the same time, or shortly afterwards, astronomers created mathematical models that allowed them to predict these phenomena directly, without consulting past records. A notable Babylonian astronomer from this time was Seleucus of Seleucia, who was a supporter of the heliocentric model.\n\nBabylonian astronomy was the basis for much of what was done in Greek and Hellenistic astronomy, in classical Indian astronomy, in Sassanian Iran, in Byzantium, in Syria, in Islamic astronomy, in Central Asia, and in Western Europe.\n\nAstronomy in the Indian subcontinent dates back to the period of Indus Valley Civilization during 3rd millennium BCE, when it was used to create calendars. As the Indus Valley civilization did not leave behind written documents, the oldest extant Indian astronomical text is the Vedanga Jyotisha, dating from the Vedic period. Vedanga Jyotisha describes rules for tracking the motions of the Sun and the Moon for the purposes of ritual. During the 6th century, astronomy was influenced by the Greek and Byzantine astronomical traditions.\n\nAryabhata (476–550), in his magnum opus \"Aryabhatiya\" (499), propounded a computational system based on a planetary model in which the Earth was taken to be spinning on its axis and the periods of the planets were given with respect to the Sun. He accurately calculated many astronomical constants, such as the periods of the planets, times of the solar and lunar eclipses, and the instantaneous motion of the Moon. Early followers of Aryabhata's model included Varahamihira, Brahmagupta, and Bhaskara II.\n\nAstronomy was advanced during the Shunga Empire and many star catalogues were produced during this time. The Shunga period is known as the \"Golden age of astronomy in India\".\nIt saw the development of calculations for the motions and places of various planets, their rising and setting, conjunctions, and the calculation of eclipses.\n\nIndian astronomers by the 6th century believed that comets were celestial bodies that re-appeared periodically. This was the view expressed in the 6th century by the astronomers Varahamihira and Bhadrabahu, and the 10th-century astronomer Bhattotpala listed the names and estimated periods of certain comets, but it is unfortunately not known how these figures were calculated or how accurate they were.\n\nBhāskara II (1114–1185) was the head of the astronomical observatory at Ujjain, continuing the mathematical tradition of Brahmagupta. He wrote the \"Siddhantasiromani\" which consists of two parts: \"Goladhyaya\" (sphere) and \"Grahaganita\" (mathematics of the planets). He also calculated the time taken for the Earth to orbit the sun to 9 decimal places. The Buddhist University of Nalanda at the time offered formal courses in astronomical studies.\n\nOther important astronomers from India include Madhava of Sangamagrama, Nilakantha Somayaji and Jyeshtadeva, who were members of the Kerala school of astronomy and mathematics from the 14th century to the 16th century. Nilakantha Somayaji, in his \"Aryabhatiyabhasya\", a commentary on Aryabhata's \"Aryabhatiya\", developed his own computational system for a partially heliocentric planetary model, in which Mercury, Venus, Mars, Jupiter and Saturn orbit the Sun, which in turn orbits the Earth, similar to the Tychonic system later proposed by Tycho Brahe in the late 16th century. Nilakantha's system, however, was mathematically more efficient than the Tychonic system, due to correctly taking into account the equation of the centre and latitudinal motion of Mercury and Venus. Most astronomers of the Kerala school of astronomy and mathematics who followed him accepted his planetary model.\n\nThe Ancient Greeks developed astronomy, which they treated as a branch of mathematics, to a highly sophisticated level. The first geometrical, three-dimensional models to explain the apparent motion of the planets were developed in the 4th century BC by Eudoxus of Cnidus and Callippus of Cyzicus. Their models were based on nested homocentric spheres centered upon the Earth. Their younger contemporary Heraclides Ponticus proposed that the Earth rotates around its axis.\n\nA different approach to celestial phenomena was taken by natural philosophers such as Plato and Aristotle. They were less concerned with developing mathematical predictive models than with developing an explanation of the reasons for the motions of the Cosmos. In his \"Timaeus\", Plato described the universe as a spherical body divided into circles carrying the planets and governed according to harmonic intervals by a world soul. Aristotle, drawing on the mathematical model of Eudoxus, proposed that the universe was made of a complex system of concentric spheres, whose circular motions combined to carry the planets around the earth. This basic cosmological model prevailed, in various forms, until the 16th century.\n\nIn the 3rd century BC Aristarchus of Samos was the first to suggest a heliocentric system, although only fragmentary descriptions of his idea survive. Eratosthenes, using the angles of shadows created at widely separated regions, estimated the circumference of the Earth with great accuracy.\n\nGreek geometrical astronomy developed away from the model of concentric spheres to employ more complex models in which an eccentric circle would carry around a smaller circle, called an epicycle which in turn carried around a planet. The first such model is attributed to Apollonius of Perga and further developments in it were carried out in the 2nd century BC by Hipparchus of Nicea. Hipparchus made a number of other contributions, including the first measurement of precession and the compilation of the first star catalog in which he proposed our modern system of apparent magnitudes.\n\nThe Antikythera mechanism, an ancient Greek astronomical observational device for calculating the movements of the Sun and the Moon, possibly the planets, dates from about 150–100 BC, and was the first ancestor of an astronomical computer. It was discovered in an ancient shipwreck off the Greek island of Antikythera, between Kythera and Crete. The device became famous for its use of a differential gear, previously believed to have been invented in the 16th century, and the miniaturization and complexity of its parts, comparable to a clock made in the 18th century. The original mechanism is displayed in the Bronze collection of the National Archaeological Museum of Athens, accompanied by a replica.\n\nDepending on the historian's viewpoint, the acme or corruption of physical Greek astronomy is seen with Ptolemy of Alexandria, who wrote the classic comprehensive presentation of geocentric astronomy, the \"Megale Syntaxis\" (Great Synthesis), better known by its Arabic title \"Almagest\", which had a lasting effect on astronomy up to the Renaissance. In his \"Planetary Hypotheses\", Ptolemy ventured into the realm of cosmology, developing a physical model of his geometric system, in a universe many times smaller than the more realistic conception of Aristarchus of Samos four centuries earlier.\n\nThe precise orientation of the Egyptian pyramids affords a lasting demonstration of the high degree of technical skill in watching the heavens attained in the 3rd millennium BC. It has been shown the Pyramids were aligned towards the pole star, which, because of the precession of the equinoxes, was at that time Thuban, a faint star in the constellation of Draco. Evaluation of the site of the temple of Amun-Re at Karnak, taking into account the change over time of the obliquity of the ecliptic, has shown that the Great Temple was aligned on the rising of the midwinter sun. The length of the corridor down which sunlight would travel would have limited illumination at other times of the year.\n\nAstronomy played a considerable part in religious matters for fixing the dates of festivals and determining the hours of the night. The titles of several temple books are preserved recording the movements and phases of the sun, moon and stars. The rising of Sirius (Egyptian: Sopdet, Greek: Sothis) at the beginning of the inundation was a particularly important point to fix in the yearly calendar.\n\nWriting in the Roman era, Clement of Alexandria gives some idea of the importance of astronomical observations to the sacred rites:\nAnd after the Singer advances the Astrologer (ὡροσκόπος), with a \"horologium\" (ὡρολόγιον) in his hand, and a \"palm\" (φοίνιξ), the symbols of astrology. He must know by heart the Hermetic astrological books, which are four in number. Of these, one is about the arrangement of the fixed stars that are visible; one on the positions of the sun and moon and five planets; one on the conjunctions and phases of the sun and moon; and one concerns their risings.\n\nThe Astrologer's instruments (\"horologium\" and \"palm\") are a plumb line and sighting instrument. They have been identified with two inscribed objects in the Berlin Museum; a short handle from which a plumb line was hung, and a palm branch with a sight-slit in the broader end. The latter was held close to the eye, the former in the other hand, perhaps at arms length. The \"Hermetic\" books which Clement refers to are the Egyptian theological texts, which probably have nothing to do with Hellenistic Hermetism.\n\nFrom the tables of stars on the ceiling of the tombs of Rameses VI and Rameses IX it seems that for fixing the hours of the night a man seated on the ground faced the Astrologer in such a position that the line of observation of the pole star passed over the middle of his head. On the different days of the year each hour was determined by a fixed star culminating or nearly culminating in it, and the position of these stars at the time is given in the tables as in the centre, on the left eye, on the right shoulder, etc. According to the texts, in founding or rebuilding temples the north axis was determined by the same apparatus, and we may conclude that it was the usual one for astronomical observations. In careful hands it might give results of a high degree of accuracy.\n\nThe astronomy of East Asia began in China. Solar term was completed in Warring States period. The knowledge of Chinese astronomy was introduced into East Asia.\n\nAstronomy in China has a long history. Detailed records of astronomical observations were kept from about the 6th century BC, until the introduction of Western astronomy and the telescope in the 17th century. Chinese astronomers were able to precisely predict eclipses.\n\nMuch of early Chinese astronomy was for the purpose of timekeeping. The Chinese used a lunisolar calendar, but because the cycles of the Sun and the Moon are different, astronomers often prepared new calendars and made observations for that purpose.\n\nAstrological divination was also an important part of astronomy. Astronomers took careful note of \"guest stars\" which suddenly appeared among the fixed stars. They were the first to record a supernova, in the Astrological Annals of the Houhanshu in 185 AD. Also, the supernova that created the Crab Nebula in 1054 is an example of a \"guest star\" observed by Chinese astronomers, although it was not recorded by their European contemporaries. Ancient astronomical records of phenomena like supernovae and comets are sometimes used in modern astronomical studies.\n\nThe world's first star catalogue was made by Gan De, a , in the 4th century BC.\n\nMaya astronomical codices include detailed tables for calculating phases of the Moon, the recurrence of eclipses, and the appearance and disappearance of Venus as morning and evening star. The Maya based their calendrics in the carefully calculated cycles of the Pleiades, the Sun, the Moon, Venus, Jupiter, Saturn, Mars, and also they had a precise description of the eclipses as depicted in the Dresden Codex, as well as the ecliptic or zodiac, and the Milky Way was crucial in their Cosmology. A number of important Maya structures are believed to have been oriented toward the extreme risings and settings of Venus. To the ancient Maya, Venus was the patron of war and many recorded battles are believed to have been timed to the motions of this planet. Mars is also mentioned in preserved astronomical codices and early mythology.\n\nAlthough the Maya calendar was not tied to the Sun, John Teeple has proposed that the Maya calculated the solar year to somewhat greater accuracy than the Gregorian calendar. Both astronomy and an intricate numerological scheme for the measurement of time were vitally important components of Maya religion.\n\nThe Arabic and the Persian world under Islam had become highly cultured, and many important works of knowledge from Greek astronomy and Indian astronomy and Persian astronomy were translated into Arabic, used and stored in libraries throughout the area. An important contribution by Islamic astronomers was their emphasis on observational astronomy. This led to the emergence of the first astronomical observatories in the Muslim world by the early 9th century. Zij star catalogues were produced at these observatories.\n\nIn the 10th century, Abd al-Rahman al-Sufi (Azophi) carried out observations on the stars and described their positions, magnitudes, brightness, and colour and drawings for each constellation in his \"Book of Fixed Stars\". He also gave the first descriptions and pictures of \"A Little Cloud\" now known as the Andromeda Galaxy. He mentions it as lying before the mouth of a Big Fish, an Arabic constellation. This \"cloud\" was apparently commonly known to the Isfahan astronomers, very probably before 905 AD. The first recorded mention of the Large Magellanic Cloud was also given by al-Sufi. In 1006, Ali ibn Ridwan observed SN 1006, the brightest supernova in recorded history, and left a detailed description of the temporary star.\n\nIn the late 10th century, a huge observatory was built near Tehran, Iran, by the astronomer Abu-Mahmud al-Khujandi who observed a series of meridian transits of the Sun, which allowed him to calculate the tilt of the Earth's axis relative to the Sun. He noted that measurements by earlier (Indian, then Greek) astronomers had found higher values for this angle, possible evidence that the axial tilt is not constant but was in fact decreasing. In 11th-century Persia, Omar Khayyám compiled many tables and performed a reformation of the calendar that was more accurate than the Julian and came close to the Gregorian.\n\nOther Muslim advances in astronomy included the collection and correction of previous astronomical data, resolving significant problems in the Ptolemaic model, the development of the universal latitude-independent astrolabe by Arzachel, the invention of numerous other astronomical instruments, Ja'far Muhammad ibn Mūsā ibn Shākir's belief that the heavenly bodies and celestial spheres were subject to the same physical laws as Earth, the first elaborate experiments related to astronomical phenomena, the introduction of exacting empirical observations and experimental techniques, and the introduction of empirical testing by Ibn al-Shatir, who produced the first model of lunar motion which matched physical observations.\n\nNatural philosophy (particularly Aristotelian physics) was separated from astronomy by Ibn al-Haytham (Alhazen) in the 11th century, by Ibn al-Shatir in the 14th century, and Qushji in the 15th century, leading to the development of an astronomical physics.\n\nAfter the significant contributions of Greek scholars to the development of astronomy, it entered a relatively static era in Western Europe from the Roman era through the 12th century. This lack of progress has led some astronomers to assert that nothing happened in Western European astronomy during the Middle Ages. Recent investigations, however, have revealed a more complex picture of the study and teaching of astronomy in the period from the 4th to the 16th centuries.\n\nWestern Europe entered the Middle Ages with great difficulties that affected the continent's intellectual production. The advanced astronomical treatises of classical antiquity were written in Greek, and with the decline of knowledge of that language, only simplified summaries and practical texts were available for study. The most influential writers to pass on this ancient tradition in Latin were Macrobius, Pliny, Martianus Capella, and Calcidius. In the 6th century Bishop Gregory of Tours noted that he had learned his astronomy from reading Martianus Capella, and went on to employ this rudimentary astronomy to describe a method by which monks could determine the time of prayer at night by watching the stars.\n\nIn the 7th century the English monk Bede of Jarrow published an influential text, \"On the Reckoning of Time\", providing churchmen with the practical astronomical knowledge needed to compute the proper date of Easter using a procedure called the \"computus\". This text remained an important element of the education of clergy from the 7th century until well after the rise of the Universities in the 12th century.\n\nThe range of surviving ancient Roman writings on astronomy and the teachings of Bede and his followers began to be studied in earnest during the revival of learning sponsored by the emperor Charlemagne. By the 9th century rudimentary techniques for calculating the position of the planets were circulating in Western Europe; medieval scholars recognized their flaws, but texts describing these techniques continued to be copied, reflecting an interest in the motions of the planets and in their astrological significance.\n\nBuilding on this astronomical background, in the 10th century European scholars such as Gerbert of Aurillac began to travel to Spain and Sicily to seek out learning which they had heard existed in the Arabic-speaking world. There they first encountered various practical astronomical techniques concerning the calendar and timekeeping, most notably those dealing with the astrolabe. Soon scholars such as Hermann of Reichenau were writing texts in Latin on the uses and construction of the astrolabe and others, such as Walcher of Malvern, were using the astrolabe to observe the time of eclipses in order to test the validity of computistical tables.\n\nBy the 12th century, scholars were traveling to Spain and Sicily to seek out more advanced astronomical and astrological texts, which they translated into Latin from Arabic and Greek to further enrich the astronomical knowledge of Western Europe. The arrival of these new texts coincided with the rise of the universities in medieval Europe, in which they soon found a home. Reflecting the introduction of astronomy into the universities, John of Sacrobosco wrote a series of influential introductory astronomy textbooks: the Sphere, a Computus, a text on the Quadrant, and another on Calculation.\n\nIn the 14th century, Nicole Oresme, later bishop of Liseux, showed that neither the scriptural texts nor the physical arguments advanced against the movement of the Earth were demonstrative and adduced the argument of simplicity for the theory that the earth moves, and \"not\" the heavens. However, he concluded \"everyone maintains, and I think myself, that the heavens do move and not the earth: For God hath established the world which shall not be moved.\" In the 15th century, cardinal Nicholas of Cusa suggested in some of his scientific writings that the Earth revolved around the Sun, and that each star is itself a distant sun.\n\nDuring the renaissance period, astronomy began to undergo a revolution in thought known as the Copernican revolution, which gets the name from the astronomer Nicolaus Copernicus, who proposed a heliocentric system, in which the planets revolved around the Sun and not the Earth. His \"De Revolutionibus Orbium Coelestium\" was published in 1543. While in the long term this was a very controversial claim, in the very beginning it only brought minor controversy. The theory became the dominant view because many figures, most notably Galileo Galilei, Johannes Kepler and Isaac Newton championed and improved upon the work. Other figures also aided this new model despite not believing the overall theory, like Tycho Brahe, with his well-known observations.\n\nBrahe, a Danish noble, was an essential astronomer in this period. He came on the astronomical scene with the publication of \"De Nova Stella\" in which he disproved conventional wisdom on the supernova SN 1572. He also created the Tychonic System in which he blended the mathematical benefits of the Copernican system and the “physical benefits” of the Ptolemaic system. This was one of the systems people believed in when they did not accept heliocentrism, but could no longer accept the Ptolemaic system. He is most known for his highly accurate observations of the stars and the solar system. Later he moved to Prague and continued his work. In Prague he was at work on the Rudolphine Tables, that were not finished until after his death. The Rudolphine Tables was a star map designed to be more accurate than either the Alphonsine Tables, made in the 1300s and the Prutenic Tables which were inaccurate. He was assisted at this time by his assistant Johannes Kepler, who would later use his observations to finish Brahe’s works and for his theories as well.\n\nAfter the death of Brahe, Kepler was deemed his successor and was given the job of complete Brahe’s uncompleted works, like the Rudolphine Tables. He completed the Rudolphine Tables in 1624, although it was not published for several years. Like many other figures of this era, he was subject to religious and political troubles, like the Thirty Years War, which led to chaos that almost destroyed some of his works. Kepler was, however, the first to attempt to derive mathematical predictions of celestial motions from assumed physical causes. He discovered the three Kepler's Laws of Planetary Motion that now carry his name, those laws being as follows:\n\n\nWith these laws, he managed to improve upon the existing Heliocentric model. The first two were published in 1609. Kepler's contributions improved upon the overall system, giving it more credibility because it adequately explained events and could cause more reliable predictions. Before this the Copernican model was just as unreliable as the ptolemaic model. This improvement came because Kepler realized the orbits were not perfect circles, but ellipses.Galileo Galilei was among the first to use a telescope to observe the sky, and after constructing a 20x refractor telescope. He discovered the four largest moons of Jupiter in 1610, which are now collectively known as the Galilean moons, in his honor. This discovery was the first known observation of satellites orbiting another planet. He also found that our Moon had craters and observed, and correctly explained, sunspots, and that Venus exhibited a full set of phases resembling lunar phases. Galileo argued that these facts demonstrated incompatibility with the Ptolemaic model, which could not explain the phenomenon and would even contradict it. With the moons it demonstrated that the earth does not have to have everything orbiting it and that other parts of the solar system could orbit another object, such as the earth orbiting the sun. In the Ptolemaic system the celestial bodies were supposed to be perfect so such objects should not have craters or sunspots. The phases of Venus could only happen in the event that Venus's orbit is insides earth's orbit, which could not happen if the earth was the center. He, as the most famous example, had to faced challenges from church officials, more specifically the Roman Inquisition. They accused him of heresy because these beliefs went against the teachings of the Bible and were challenging the Catholic church's authority when it was at its weakest. While he was able to avoid punishment for a little while he was eventually tried and pled guilty to heresy in 1633. Although this came at some expense, his book was banned, and he was put under house arrest until he died in 1642.Sir Isaac Newton developed further ties between physics and astronomy through his law of universal gravitation. Realizing that the same force that attracts objects to the surface of the Earth held the moon in orbit around the Earth, Newton was able to explain – in one theoretical framework – all known gravitational phenomena. In his \"Philosophiae Naturalis Principia Mathematica\", he derived Kepler's laws from first principles. Those first principles are as follows:\n\n\nThus while Kepler explained how the planets moved, Newton accurately managed to explain why the planets moved the way they do. Newton's theoretical developments laid many of the foundations of modern physics.\n\nOutside of England, Newton's theory took some time to become established. Descartes' theory of vortices held sway in France, and Huygens, Leibniz and Cassini accepted only parts of Newton's system, preferring their own philosophies. Voltaire published a popular account in 1738. In 1748, the French Academy of Sciences offered a reward for solving the perturbations of Jupiter and Saturn which was eventually solved by Euler and Lagrange. Laplace completed the theory of the planets, publishing from 1798 to 1825.\n\nEdmund Halley succeeded Flamsteed as Astronomer Royal in England and succeeded in predicting the return in 1758 of the comet that bears his name. Sir William Herschel found the first new planet, Uranus, to be observed in modern times in 1781. The gap between the planets Mars and Jupiter disclosed by the Titius–Bode law was filled by the discovery of the asteroids Ceres and Pallas in 1801 and 1802 with many more following.\n\nAt first, astronomical thought in America was based on Aristotelian philosophy, but interest in the new astronomy began to appear in Almanacs as early as 1659.\n\nIn the 19th century it was discovered that (by Joseph von Fraunhofer), when sunlight was dispersed, a multitude of spectral lines were observed (regions where there was less or no light). Experiments with hot gases showed that the same lines could be observed in the spectra of gases, specific lines corresponding to unique elements. It was proved that the chemical elements found in the Sun (chiefly hydrogen and helium) were also found on Earth.\nDuring the 20th century spectroscopy (the study of these lines) advanced, especially because of the advent of quantum physics, that was necessary to understand the observations.\n\nAlthough in previous centuries noted astronomers were exclusively male, at the turn of the 20th century women began to play a role in the great discoveries. In this period prior to modern computers, women at the United States Naval Observatory (USNO), Harvard University, and other astronomy research institutions began to be hired as human \"computers\", who performed the tedious calculations while scientists performed research requiring more background knowledge. A number of discoveries in this period were originally noted by the women \"computers\" and reported to their supervisors. For example, at the Harvard Observatory Henrietta Swan Leavitt discovered the cepheid variable star period-luminosity relation which she further developed into a method of measuring distance outside of our solar system. Annie Jump Cannon, also at Harvard, organized the stellar spectral types according to stellar temperature. In 1847, Maria Mitchell discovered a comet using a telescope. According to Lewis D. Eigen, Cannon alone, \"in only 4 years discovered and catalogued more stars than all the men in history put together.\"\nMost of these women received little or no recognition during their lives due to their lower professional standing in the field of astronomy. Although their discoveries and methods are taught in classrooms around the world, few students of astronomy can attribute the works to their authors or have any idea that there were active female astronomers at the end of the 19th century.\n\nMost of our current knowledge was gained during the 20th century. With the help of the use of photography, fainter objects were observed. Our sun was found to be part of a galaxy made up of more than 10 stars (10 billion stars). The existence of other galaxies, one of the matters of \"the great debate\", was settled by Edwin Hubble, who identified the Andromeda nebula as a different galaxy, and many others at large distances and receding, moving away from our galaxy.\n\nPhysical cosmology, a discipline that has a large intersection with astronomy, made huge advances during the 20th century, with the model of the hot big bang heavily supported by the evidence provided by astronomy and physics, such as the redshifts of very distant galaxies and radio sources, the cosmic microwave background radiation, Hubble's law and cosmological abundances of elements.\n\nIn the 19th century, scientists began discovering forms of light which were invisible to the naked eye: X-Rays, gamma rays, radio waves, microwaves, ultraviolet radiation, and infrared radiation. This had a major impact on astronomy, spawning the fields of infrared astronomy, radio astronomy, x-ray astronomy and finally gamma-ray astronomy. With the advent of spectroscopy it was proven that other stars were similar to our own sun, but with a range of temperatures, masses and sizes. The existence of our galaxy, the Milky Way, as a separate group of stars was only proven in the 20th century, along with the existence of \"external\" galaxies, and soon after, the expansion of the universe seen in the recession of most galaxies from us.\n\n\n\n\n\n"}
{"id": "14022", "url": "https://en.wikipedia.org/wiki?curid=14022", "title": "Haber process", "text": "Haber process\n\nThe Haber process, also called the Haber–Bosch process, is an artificial nitrogen fixation process and is the main industrial procedure for the production of ammonia today. It is named after its inventors, the German chemists Fritz Haber and Carl Bosch, who developed it in the first decade of the 20th century. The process converts atmospheric nitrogen (N) to ammonia (NH) by a reaction with hydrogen (H) using a metal catalyst under high temperatures and pressures:\n\nBefore the development of the Haber process, ammonia had been difficult to produce on an industrial scale, with early methods such as the Birkeland–Eyde process and Frank–Caro process all being highly inefficient.\n\nAlthough the Haber process is mainly used to produce fertilizer today, during World War I it provided Germany with a source of ammonia for the production of explosives, compensating for the Allied Powers' trade blockade on Chilean saltpeter.\n\nThroughout the 19th century the demand for nitrates and ammonia for use as fertilizers and industrial feedstocks had been steadily increasing. The main source was mining niter deposits. At the beginning of the 20th century it was being predicted that these reserves could not satisfy future demands and research into new potential sources of ammonia became more important. The obvious source was atmospheric nitrogen (N), comprising nearly 80% of the air, however N is exceptionally stable and will not readily react with other chemicals. Converting N into ammonia posed a challenge for chemists globally.\n\nHaber, with his assistant Robert Le Rossignol, developed the high-pressure devices and catalysts needed to demonstrate the Haber process at laboratory scale. They demonstrated their process in the summer of 1909 by producing ammonia from air, drop by drop, at the rate of about per hour. The process was purchased by the German chemical company BASF, which assigned Carl Bosch the task of scaling up Haber's tabletop machine to industrial-level production. He succeeded in 1910. Haber and Bosch were later awarded Nobel prizes, in 1918 and 1931 respectively, for their work in overcoming the chemical and engineering problems of large-scale, continuous-flow, high-pressure technology.\n\nAmmonia was first manufactured using the Haber process on an industrial scale in 1913 in BASF's Oppau plant in Germany, reaching 20 tonnes per day the following year. During World War I, the production of munitions required large amounts of nitrate. The Allies had access to large sodium nitrate deposits in Chile (Chile saltpetre) controlled by British companies. Germany had no such resources, so the Haber process proved essential to the German war effort. Synthetic ammonia from the Haber process was used for the production of nitric acid, a precursor to the nitrates used in explosives.\n\nThis conversion is typically conducted at and between , as the gases (nitrogen and hydrogen) are passed over four beds of catalyst, with cooling between each pass so as to maintain a reasonable equilibrium constant. On each pass only about 15% conversion occurs, but any unreacted gases are recycled, and eventually an overall conversion of 97% is achieved.\n\nThe steam reforming, shift conversion, carbon dioxide removal, and methanation steps each operate at pressures of about , and the ammonia synthesis loop operates at pressures ranging from , depending upon which proprietary process is used.\n\nThe major source of hydrogen is methane from natural gas. The conversion, steam reforming, is conducted with steam in a high temperature and pressure tube inside a reformer with a nickel catalyst, separating the carbon and hydrogen atoms in the natural gas.\n\nNitrogen (N) is very unreactive because the molecules are held together by strong triple bonds. The Haber process relies on catalysts that accelerate the scission of this triple bond.\n\nTwo opposing considerations are relevant to this synthesis: the position of the equilibrium and the rate of reaction. At room temperature, the equilibrium is strongly in favor of ammonia, but the reaction doesn't proceed at a detectable rate. The obvious solution is to raise the temperature, but because the reaction is exothermic, the equilibrium constant (using bar or atm units) becomes 1 around . (See Le Châtelier's principle.)\nAbove this temperature, the equilibrium quickly becomes quite unfavorable at atmospheric pressure, according to the Van 't Hoff equation. Thus one might suppose that a low temperature is to be used and some other means to increase rate. However, the catalyst itself requires a temperature of at least 400 °C to be efficient.\n\nPressure is the obvious choice to favor the forward reaction because there are 4 moles of reactant for every 2 moles of product, and the pressure used () alters the equilibrium concentrations to give a profitable yield. The reason for this is evident in the equilibrium relationship, which is\n\nwhere formula_3 is the fugacity coefficient of species formula_4, formula_5 is the mole fraction of the same species, formula_6 is the pressure in the reactor, and formula_7 is standard pressure, typically .\n\nEconomically, pressurization of the reactor is expensive: pipes, valves, and reaction vessels need to be strengthened, and there are safety considerations when working at 20 MPa. In addition, running compressors takes considerable energy, as work must be done on the (very compressible) gas. Thus, the compromise used gives a single pass yield of around 15%.\n\nAnother way to increase the yield of the reaction would be to remove the product (i.e., ammonia gas) from the system. In practice, gaseous ammonia is not removed from the reactor itself, since the temperature is too high; it is removed from the equilibrium mixture of gases leaving the reaction vessel. The hot gases are cooled enough, whilst maintaining a high pressure, for the ammonia to condense and be removed as liquid. Unreacted hydrogen and nitrogen gases are then returned to the reaction vessel to undergo further reaction.\n\nThe most popular catalysts are based on iron promoted with KO, CaO, SiO, and AlO. The original Haber–Bosch reaction chambers used osmium as the catalyst, but it was available in extremely small quantities. Haber noted uranium was almost as effective and easier to obtain than osmium. Under Bosch's direction in 1909, the BASF researcher Alwin Mittasch discovered a much less expensive iron-based catalyst, which is still used today. Some ammonia production utilizes ruthenium-based catalysts (the KAAP process). Ruthenium forms more active catalysts that allows milder operating pressures. Such catalysts are prepared by decomposition of triruthenium dodecacarbonyl on graphite.\n\nIn industrial practice, the iron catalyst is obtained from finely ground iron powder, which is usually obtained by reduction of high purity magnetite (FeO). The pulverized iron metal is burnt (oxidized) to give magnetite of a defined particle size. The magnetite particles are then partially reduced, removing some of the oxygen in the process. The resulting catalyst particles consist of a core of magnetite, encased in a shell of wüstite (FeO, ferrous oxide), which in turn is surrounded by an outer shell of iron metal. The catalyst maintains most of its bulk volume during the reduction, resulting in a highly porous high surface area material, which enhances its effectiveness as a catalyst. Other minor components of the catalyst include calcium and aluminium oxides, which support the iron catalyst and help it maintain its surface area. These oxides of Ca, Al, K, and Si are unreactive to reduction by the hydrogen.\nThe reaction mechanism, involving the heterogeneous catalyst, is believed to involve the following steps:\n\n\nReaction 5 occurs in three steps, forming NH, NH, and then NH. Experimental evidence points to reaction 2 as being the slow, rate-determining step. This is not unexpected since the bond broken, the nitrogen triple bond, is the strongest of the bonds that must be broken.\n\nA major contributor to the elucidation of this mechanism is Gerhard Ertl.\n\nWhen it was first invented, the Haber process needed to compete against another industrial process, the Cyanamide process. However, the Cyanamide process consumed large amounts of electrical power and was more labor-intensive than the Haber process.\n\nThe Haber process now produces 450 million tonnes of nitrogen fertilizer per year, mostly in the form of anhydrous ammonia, ammonium nitrate, and urea. Three to five percent of the world's natural gas production is consumed in the Haber process (around 1–2% of the world's energy supply). In combination with pesticides, these fertilizers have quadrupled the productivity of agricultural land:\n\nDue to its dramatic impact on the human ability to grow food, the Haber process served as the \"detonator of the population explosion\", enabling the global population to increase from 1.6 billion in 1900 to today's 7 billion. Nearly 50% of the nitrogen found in human tissues originated from the Haber-Bosch process. Since nitrogen use efficiency is typically less than 50%, farm runoff from heavy use of fixed industrial nitrogen disrupts biological habitats.\n\n\n"}
{"id": "14023", "url": "https://en.wikipedia.org/wiki?curid=14023", "title": "Hot or Not", "text": "Hot or Not\n\nHot or Not is a rating site that allows users to rate the attractiveness of photos submitted voluntarily by others. The site offers a matchmaking engine called 'Meet Me' and an extended profile feature called \"Hotlists\". The domain hotornot.com is currently owned by Hot Or Not Limited, and was previously owned by Avid Life Media. 'Hot or Not' was a significant influence on the people who went on to create the social media sites Facebook and YouTube.\n\nUsers would submit photographs of themselves to the site for the purpose of other users to rate said person's attractiveness on a scale of 1 - 10, with the cumulative average acting as the overall score for a given photograph.\n\nThe site was founded in October 2000 by James Hong and Jim Young, two friends and Silicon Valley-based engineers. Both graduated from the University of California, Berkeley in electrical engineering, with Young pursuing a Ph.D at the time. It was inspired by some other developers' ideas.\n\nThe site was a technical solution to a disagreement the founders had one day over a passing woman's attractiveness. The site was originally called \"Am I Hot or Not\". Within a week of launching, it had reached almost two million page views per day. Within a few months, the site was immediately behind CNET and NBCi on NetNielsen Rating's Top 25 advertising domains. To keep up with rising costs Hong and Young added a matchmaking component to their website called \"Meet Me at Hot or Not\", i.e. a system of range voting. The matchmaking service has been especially successful and the site continues to generate most of its revenue through subscriptions. In the December 2006 issue of \"Time\" magazine, the founders of YouTube stated that they originally set out to make a version of Hot or Not with Video before developing their more inclusive site. Mark Zuckerberg of Facebook similarly got his start by creating a Hot or Not type site called FaceMash, where he posted photos from Harvard's Facebook for the university's community to rate.\n\nHot or Not was sold for a rumored $20 million on February 8, 2008 to Avid Life Media, owners of Ashley Madison. Annual revenue reached $7.5 million, with net profits of $5.5 million. They initially started off $60,000 in debt due to tuition fees James paid for his MBA. On July 31, 2008, Hot or Not launched Hot or Not Gossip and a Baresi rate box (a \"hot meter\") – a subdivision to expand their market, run by former radio DJ turned celebrity blogger Zack Taylor.\n\nHot or Not was preceded by the rating sites, like RateMyFace, which was registered a year earlier in the summer of 1999, and AmIHot.com, which was registered in January 2000 by MIT freshman Daniel Roy. Regardless, despite any head starts of its predecessors, Hot or Not quickly became the most popular. Since AmIHotOrNot.com's launch, the concept has spawned many imitators. The concept always remained the same, but the subject matter varied greatly. The concept has also been integrated with a wide variety of dating and matchmaking systems. In 2007 BecauseImHot.com launched and deleted anyone with a rating below 7 after a voting audit or the first 50 votes (whichever is first).\n\nIn 2005, as an example of using image morphing methods to study the effects of averageness, imaging researcher Pierre Tourigny created a composite of about 30 faces to find out the current standard of good looks on the Internet (as shown above). On the Hot or Not web site, people rate others' attractiveness on a scale of 1 to 10. An average score based on hundreds or even thousands of individual ratings takes only a few days to emerge. To make this hot or not palette of morphed images, photos from the site were sorted by rank and used SquirlzMorph to create multi-morph composites from them. Unlike projects like Face of Tomorrow, where the subjects are posed for the purpose, the portraits are blurry because the source images are of low resolution with differences in variables such as posture, hair styles and glasses, so that in this instance images could use only 36 control points for the morphs. A similar study was done with Miss Universe contestants, as shown in the averageness article, as well as one for age, as shown in youthfulness article.\n\nA 2006 \"hot\" or \"not\" style study, involving 264 women and 18 men, at the Washington University School of Medicine, as published online in the journal \"Brain Research\", indicates that a person's brain determines whether an image is erotically appealing long before the viewer is even aware they are seeing the picture. Moreover, according to these researchers, one of the basic functions of the brain is to classify images into a hot or not type categorization. The study's researchers also discovered that sexy shots induce a uniquely powerful reaction in the brain, equal in effect for both men and women, and that erotic images produced a strong reaction in the hypothalamus.\n\n\n"}
{"id": "14024", "url": "https://en.wikipedia.org/wiki?curid=14024", "title": "H.263", "text": "H.263\n\nH.263 is a video compression standard originally designed as a low-bit-rate compressed format for videoconferencing. It was developed by the ITU-T Video Coding Experts Group (VCEG) in a project ending in 1995/1996 as one member of the H.26x family of video coding standards in the domain of the ITU-T, and it was later extended to add various additional enhanced features in 1998 and 2000. Smaller additions were also made in 1997 and 2001, and a unified edition was produced in 2005.\n\nThe H.263 standard was first designed to be utilized in H.324 based systems (PSTN and other circuit-switched network videoconferencing and videotelephony), but it also found use in H.323 (RTP/IP-based videoconferencing), H.320 (ISDN-based videoconferencing), RTSP (streaming media) and SIP (IP-based videoconferencing) solutions.\n\nH.263 is a required video coding format in ETSI 3GPP technical specifications for IP Multimedia Subsystem (IMS), Multimedia Messaging Service (MMS) and Transparent end-to-end Packet-switched Streaming Service (PSS). In 3GPP specifications, H.263 video is usually used in 3GP container format.\n\nH.263 also found many applications on the internet: much Flash Video content (as used on sites such as YouTube, Google Video, and MySpace) used to be encoded in Sorenson Spark format (an incomplete implementation of H.263). The original version of the RealVideo codec was based on H.263 until the release of RealVideo 8.\n\nH.263 was developed as an evolutionary improvement based on experience from H.261, the previous ITU-T standard for video compression, and the MPEG-1 and MPEG-2 standards. Its first version was completed in 1995 and provided a suitable replacement for H.261 at all bit rates. It was further enhanced in projects known as H.263v2 (also known as H.263+ or H.263 1998), MPEG-4 Part 2 and H.263v3 (also known as H.263++ or H.263 2000). MPEG-4 Part 2 is H.263 compatible in the sense that basic \"baseline\" H.263 bitstreams are correctly decoded by an MPEG-4 Video decoder.\n\nThe next enhanced format developed by ITU-T VCEG (in partnership with MPEG) after H.263 was the H.264 standard, also known as AVC and MPEG-4 part 10. As H.264 provides a significant improvement in capability beyond H.263, the H.263 standard is now considered a legacy design. Most new videoconferencing products now include H.264 as well as H.263 and H.261 capabilities. An even-newer standard format, HEVC, has also been developed by VCEG and MPEG, and has begun to emerge in some applications.\n\nSince the original ratification of H.263 in March 1996 (approving a document that was produced in November 1995), there have been two subsequent additions which improved on the original standard by additional optional extensions (for example, the H.263v2 project added a deblocking filter in its Annex J).\n\nThe original version of H.263 specified the following annexes:\n\nThe first version of H.263 supported a limited set of picture sizes:\n\nIn March 1997, an informative Appendix I describing Error Tracking – an encoding technique for providing improved robustness to data losses and errors, was approved to provide information for the aid of implementers having an interest in such techniques.\n\nH.263v2 (also known as \"H.263+\", or as \"the 1998 version of H.263\") is the informal name of the second edition of the ITU-T H.263 international video coding standard. It retained the entire technical content of the original version of the standard, but enhanced H.263 capabilities by adding several annexes which can substantially improve encoding efficiency and provide other capabilities (such as enhanced robustness against data loss in the transmission channel). The H.263+ project was ratified by the ITU in February 1998. It added the following Annexes:\nH.263v2 also added support for flexible customized picture formats and custom picture clock frequencies. As noted above, the only picture formats previously supported in H.263 had been Sub-QCIF, QCIF, CIF, 4CIF, and 16CIF, and the only picture clock frequency had been 30000/1001 (approximately 29.97) clock ticks per second.\n\nH.263v2 specified a set of recommended modes in an informative appendix (Appendix II, since deprecated):\nThe definition of H.263v3 (also known as H.263++ or as the 2000 version of H.263) added three annexes. These annexes and an additional annex that specified profiles (approved the following year) were originally published as separate documents from the main body of the standard itself. The additional annexes specified are:\n\nThe prior informative Appendix II (recommended optional enhancement) was obsoleted by the creation of the normative Annex X.\n\nIn June 2001, another informative appendix (Appendix III, Examples for H.263 encoder/decoder implementations) was approved. It describes techniques for encoding and for error/loss concealment by decoders.\n\nIn January 2005, a unified H.263 specification document was produced (with the exception of Appendix III, which remains as a separately-published document).\n\nIn August 2005, an implementors guide was approved to correct a small error in the seldom-used Annex Q reduced-resolution update mode.\n\nIn countries without software patents, H.263 video can be legally encoded and decoded with the free LGPL-licensed libavcodec library (part of the FFmpeg project) which is used by programs such as ffdshow, VLC media player and MPlayer.\n\n\n"}
{"id": "14026", "url": "https://en.wikipedia.org/wiki?curid=14026", "title": "House of Orange (disambiguation)", "text": "House of Orange (disambiguation)\n\nHouse of Orange may refer to:\n\n\n"}
{"id": "14029", "url": "https://en.wikipedia.org/wiki?curid=14029", "title": "Histone", "text": "Histone\n\nIn biology, histones are highly alkaline proteins found in eukaryotic cell nuclei that package and order the DNA into structural units called nucleosomes. They are the chief protein components of chromatin, acting as spools around which DNA winds, and playing a role in gene regulation. Without histones, the unwound DNA in chromosomes would be very long (a length to width ratio of more than 10 million to 1 in human DNA). For example, each human diploid cell (containing 23 pairs of chromosomes) has about 1.8 meters of DNA; wound on the histones, the diploid cell has about 90 micrometers (0.09 mm) of chromatin. When the diploid cells are duplicated and condensed during mitosis, the result is about 120 micrometers of chromosomes.\n\nFive major families of histones exist: H1/H5, H2A, H2B, H3, and H4. Histones H2A, H2B, H3 and H4 are known as the core histones, while histones H1/H5 are known as the linker histones.\n\nThe core histones all exist as dimers, which are similar in that they all possess the histone fold domain: three alpha helices linked by two loops. It is this helical structure that allows for interaction between distinct dimers, particularly in a head-tail fashion (also called the handshake motif). The resulting four distinct dimers then come together to form one octameric nucleosome core, approximately 63 Angstroms in diameter (a solenoid (DNA)-like particle). Around 146 base pairs (bp) of DNA wrap around this core particle 1.65 times in a left-handed super-helical turn to give a particle of around 100 Angstroms across. The linker histone H1 binds the nucleosome at the entry and exit sites of the DNA, thus locking the DNA into place and allowing the formation of higher order structure. The most basic such formation is the 10 nm fiber or beads on a string conformation. This involves the wrapping of DNA around nucleosomes with approximately 50 base pairs of DNA separating each pair of nucleosomes (also referred to as linker DNA). Higher-order structures include the 30 nm fiber (forming an irregular zigzag) and 100 nm fiber, these being the structures found in normal cells. During mitosis and meiosis, the condensed chromosomes are assembled through interactions between nucleosomes and other regulatory proteins.\n\nHistones are subdivided into canonical replication-dependent histones that are expressed during the S-phase of cell cycle and replication-independent histone variants, expressed during the whole cell cycle. In animals, genes encoding canonical histones are typically clustered along the chromosome, lack introns and use a stem loop structure at the 3’ end instead of a polyA tail. Genes encoding histone variants are usually not clustered, have introns and their mRNAs are regulated with polyA tails. Complex multicellular organisms typically have a higher number of histone variants providing a variety of different functions. Recent data are accumulating about the roles of diverse histone variants highlighting the functional links between variants and the delicate regulation of organism development. Histone variants from different organisms, their classification and variant specific features can be found in \"HistoneDB 2.0 - Variants\" database.\n\nThe following is a list of human histone proteins:\n\nThe nucleosome core is formed of two H2A-H2B dimers and a H3-H4 tetramer, forming two nearly symmetrical halves by tertiary structure (C2 symmetry; one macromolecule is the mirror image of the other). The H2A-H2B dimers and H3-H4 tetramer also show pseudodyad symmetry. The 4 'core' histones (H2A, H2B, H3 and H4) are relatively similar in structure and are highly conserved through evolution, all featuring a 'helix turn helix turn helix' motif (DNA-binding protein motif that recognize specific DNA sequence). They also share the feature of long 'tails' on one end of the amino acid structure - this being the location of post-translational modification (see below).\n\nIt has been proposed that histone proteins are evolutionarily related to the helical part of the extended AAA+ ATPase domain, the C-domain, and to the N-terminal substrate recognition domain of Clp/Hsp100 proteins. Despite the differences in their topology, these three folds share a homologous helix-strand-helix (HSH) motif.\n\nUsing an electron paramagnetic resonance spin-labeling technique, British researchers measured the distances between the spools around which eukaryotic cells wind their DNA. They determined the spacings range from 59 to 70 Å.\n\nIn all, histones make five types of interactions with DNA:\n\nThe highly basic nature of histones, aside from facilitating DNA-histone interactions, contributes to their water solubility.\n\nHistones are subject to post translational modification by enzymes primarily on their N-terminal tails, but also in their globular domains. Such modifications include methylation, citrullination, acetylation, phosphorylation, SUMOylation, ubiquitination, and ADP-ribosylation. This affects their function of gene regulation.\n\nIn general, genes that are active have less bound histone, while inactive genes are highly associated with histones during interphase. It also appears that the structure of histones has been evolutionarily conserved, as any deleterious mutations would be severely maladaptive. All histones have a highly positively charged N-terminus with many lysine and arginine residues.\n\nHistones were discovered in 1884 by Albrecht Kossel. The word \"histone\" dates from the late 19th century and is derived from the German word \"\"Histon\"\", a word itself of uncertain origin - perhaps from the Greek \"histanai\" or \"histos\".\n\nIn the early 1960s, before the types of histones were known and before histones were known to be highly conserved across taxonomically diverse organisms, James F. Bonner and his collaborators began a study of these proteins that were known to be tightly associated with the DNA in the nucleus of higher organisms. Bonner and his postdoctoral fellow Ru Chih C. Huang showed that isolated chromatin would not support RNA transcription in the test tube, but if the histones were extracted from the chromatin, RNA could be transcribed from the remaining DNA. Their paper became a citation classic. Paul T'so and James Bonner had called together a World Congress on Histone Chemistry and Biology in 1964, in which it became clear that there was no consensus on the number of kinds of histone and that no one know how they would compare when isolated from different organisms. Bonner and his collaborators then developed methods to separate each type of histones, purified individual histones, compared amino acid compositions in the same histone from different organisms, and compared amino acid sequences  of the same histone from different organisms in collaboration with Emil Smith from UCLA. For example, they found Histone IV sequence to be highly conserved between peas and calf thymus. However, their work on the biochemical characteristics of individual histones did not reveal how the histones interacted with each other or with DNA to which they were tightly bound.\n\nAlso in the 1960s, Vincent Allfrey and Alfred Mirsky had suggested, based on their analyses of histones, that acetylation and methylation of histones could provide a transcriptional control mechanism, but did not have available the kind of detailed analysis that later investigators were able to conduct to show how such regulation could be gene-specific. Until the early 1990s, histones were dismissed by most as inert packing material for eukaryotic nuclear DNA, a view based in part on the models of Mark Ptashne and others, who believed that transcription was activated by protein-DNA and protein-protein interactions on largely naked DNA templates, as is the case in bacteria.\n\nDuring the 1980s, Yahli Lorch and Roger Kornberg showed that a nucleosome on a core promoter prevents the initiation of transcription in vitro, and Michael Grunstein demonstrated that histones repress transcription in vivo, leading to the idea of the nucleosome as a general gene repressor. Relief from repression is believed to involve both histone modification and the action of chromatin-remodeling complexes. Vincent Allfrey and Alfred Mirsky had earlier proposed a role of histone modification in transcriptional activation, regarded as a molecular manifestation of epigenetics. Michael Grunstein and David Allis found support for this proposal, in the importance of histone acetylation for transcription in yeast and the activity of the transcriptional activator Gcn5 as a histone acetyltransferase.\n\nThe discovery of the H5 histone appears to date back to the 1970s, and it is now considered an isoform of Histone H1.\n\nHistones are found in the nuclei of eukaryotic cells, and in certain Archaea, namely Thermoproteales and Euryarchaea, but not in bacteria. The unicellular algae known as dinoflagellates were previously thought to be the only eukaryotes that completely lack histones, however, later studies showed that their DNA still encodes histone genes.\n\nArchaeal histones may well resemble the evolutionary precursors to eukaryotic histones. Histone proteins are among the most highly conserved proteins in eukaryotes, emphasizing their important role in the biology of the nucleus. In contrast mature sperm cells largely use protamines to package their genomic DNA, most likely because this allows them to achieve an even higher packaging ratio.\n\nThere are some \"variant\" forms in some of the major classes. They share amino acid sequence homology and core structural similarity to a specific class of major histones but also have their own feature that is distinct from the major histones. These \"minor histones\" usually carry out specific functions of the chromatin metabolism. For example, histone H3-like CENPA is associated with only the centromere region of the chromosome. Histone H2A variant H2A.Z is associated with the promoters of actively transcribed genes and also involved in the prevention of the spread of silent heterochromatin. Furthermore, H2A.Z has roles in chromatin for genome stability. Another H2A variant H2A.X is phosphorylated at S139 in regions around double-strand breaks and marks the region undergoing DNA repair. Histone H3.3 is associated with the body of actively transcribed genes.\n\nHistones act as spools around which DNA winds. This enables the compaction necessary to fit the large genomes of eukaryotes inside cell nuclei: the compacted molecule is 40,000 times shorter than an unpacked molecule.\n\nHistones undergo posttranslational modifications that alter their interaction with DNA and nuclear proteins. The H3 and H4 histones have long tails protruding from the nucleosome, which can be covalently modified at several places. Modifications of the tail include methylation, acetylation, phosphorylation, ubiquitination, SUMOylation, citrullination, and ADP-ribosylation. The core of the histones H2A and H2B can also be modified. Combinations of modifications are thought to constitute a code, the so-called \"histone code\". Histone modifications act in diverse biological processes such as gene regulation, DNA repair, chromosome condensation (mitosis) and spermatogenesis (meiosis).\n\nThe common nomenclature of histone modifications is:\n\nSo H3K4me1 denotes the monomethylation of the 4th residue (a lysine) from the start (i.e., the N-terminal) of the H3 protein.\n\nA huge catalogue of histone modifications have been described, but a functional understanding of most is still lacking. Collectively, it is thought that histone modifications may underlie a histone code, whereby combinations of histone modifications have specific meanings. However, most functional data concerns individual prominent histone modifications that are biochemically amenable to detailed study.\n\nThe addition of one, two, or many methyl groups to lysine has little effect on the chemistry of the histone; methylation leaves the charge of the lysine intact and adds a minimal number of atoms so steric interactions are mostly unaffected. However, proteins containing Tudor, chromo or PHD domains, amongst others, can recognise lysine methylation with exquisite sensitivity and differentiate mono, di and tri-methyl lysine, to the extent that, for some lysines (e.g.: H4K20) mono, di and tri-methylation appear to have different meanings. Because of this, lysine methylation tends to be a very informative mark and dominates the known histone modification functions.\nWhat was said above of the chemistry of lysine methylation also applies to arginine methylation, and some protein domains—e.g., Tudor domains—can be specific for methyl arginine instead of methyl lysine. Arginine is known to be mono- or di-methylated, and methylation can be symmetric or asymmetric, potentially with different meanings.\n\nEnzymes called peptidylarginine deiminases (PADs) hydrolyze the imine group of arginines and attach a keto group, so that there is one less positive charge on the amino acid residue. This process has been involved in the activation of gene expression by making the modified histones less tightly bound to DNA and thus making the chromatin more accessible. PADs can also produce the opposite effect by removing or inhibiting mono-methylation of arginine residues on histones and thus antagonizing the positive effect arginine methylation has on transcriptional activity.\n\nAddition of an acetyl group has a major chemical effect on lysine as it neutralises the positive charge. This reduces electrostatic attraction between the histone and the negatively charged DNA backbone, loosening the chromatin structure; highly acetylated histones form more accessible chromatin and tend to be associated with active transcription. Lysine acetylation appears to be less precise in meaning than methylation, in that histone acetyltransferases tend to act on more than one lysine; presumably this reflects the need to alter multiple lysines to have a significant effect on chromatin structure. The modification includes H3K27ac.\nAddition of a negatively charged phosphate group can lead to major changes in protein structure, leading to the well-characterised role of phosphorylation in controlling protein function. It is not clear what structural implications histone phosphorylation has, but histone phosphorylation has clear functions as a post-translational modification, and binding domains such as BRCT have been characterised.\n\nMost well-studied histone modifications are involved in control of transcription.\n\nTwo histone modifications are particularly associated with active transcription:\n\nThree histone modifications are particularly associated with repressed genes:\n\nAnalysis of histone modifications in embryonic stem cells (and other stem cells) revealed many gene promoters carrying both H3K4Me3 and H3K27Me3, in other words these promoters display both activating and repressing marks simultaneously. This peculiar combination of modifications marks genes that are poised for transcription; they are not required in stem cells, but are rapidly required after differentiation into some lineages. Once the cell starts to differentiate, these bivalent promoters are resolved to either active or repressive states depending on the chosen lineage.\n\nMarking sites of DNA damage is an important function for histone modifications. It also protects DNA from getting destroyed by ultraviolet radiation of sun.\n\nH3K36me3 has the ability to recruit the MSH2-MSH6 (hMutSα) complex of the DNA mismatch repair pathway. Consistently, regions of the human genome with high levels of H3K36me3 accumulate less somatic mutations due to mismatch repair activity.\n\n\n\nEpigenetic modifications of histone tails in specific regions of the brain are of central importance in addictions. Once particular epigenetic alterations occur, they appear to be long lasting \"molecular scars\" that may account for the persistence of addictions.\n\nCigarette smokers (about 15% of the US population) are usually addicted to nicotine. After 7 days of nicotine treatment of mice, acetylation of both histone H3 and histone H4 was increased at the FosB promoter in the nucleus accumbens of the brain, causing 61% increase in FosB expression. This would also increase expression of the splice variant Delta FosB. In the nucleus accumbens of the brain, Delta FosB functions as a \"sustained molecular switch\" and \"master control protein\" in the development of an addiction.\n\nAbout 7% of the US population is addicted to alcohol. In rats exposed to alcohol for up to 5 days, there was an increase in histone 3 lysine 9 acetylation in the pronociceptin promoter in the brain amygdala complex. This acetylation is an activating mark for pronociceptin. The nociceptin/nociceptin opioid receptor system is involved in the reinforcing or conditioning effects of alcohol.\n\nMethamphetamine addiction occurs in about 0.2% of the US population. Chronic methamphetamine use causes methylation of the lysine in position 4 of histone 3 located at the promoters of the \"c-fos\" and the \"C-C chemokine receptor 2 (ccr2)\" genes, activating those genes in the nucleus accumbens (NAc). c-fos is well known to be important in addiction. The \"ccr2\" gene is also important in addiction, since mutational inactivation of this gene impairs addiction.\n\nThe first step of chromatin structure duplication is the synthesis of histone proteins: H1, H2A, H2B, H3, H4. These proteins are synthesized during S phase of the cell cycle. There are different mechanisms which contribute to the increase of histone synthesis.\n\nYeast carry one or two copies of each histone gene, which are not clustered but rather scattered throughout chromosomes. Histone gene transcription is controlled by multiple gene regulatory proteins such as transcription factors which bind to histone promoter regions. In budding yeast, the candidate gene for activation of histone gene expression is SBF. SBF is a transcription factor that is activated in late G1 phase, when it dissociates from its repressor Whi5. This occurs when Whi5 is phosphorylated by Cdc8 which is a G1/S Cdk. Suppression of histone gene expression outside of S phases is dependent on Hir proteins which form inactive chromatin structure at the locus of histone genes, causing transcriptional activators to be blocked.\n\nIn metazoans the increase in the rate of histone synthesis is due to the increase in processing of pre-mRNA to its mature form as well as decrease in mRNA degradation; this results in an increase of active mRNA for translation of histone proteins. The mechanism for mRNA activation has been found to be the removal of a segment of the 3’ end of the mRNA strand, and is dependent on association with stem-loop binding protein (SLBP). SLBP also stabilizes histone mRNAs during S phase by blocking degradation by the 3’hExo nuclease. SLBP levels are controlled by cell-cycle proteins, causing SLBP to accumulate as cells enter S phase and degrade as cells leave S phase. SLBP are marked for degradation by phosphorylation at two threonine residues by cyclin dependent kinases, possibly cyclin A/ cdk2, at the end of S phase. Metazoans also have multiple copies of histone genes clustered on chromosomes which are localized in structures called Cajal bodies as determined by genome-wide chromosome conformation capture analysis (4C-Seq).\n\nNuclear protein Ataxia-Telangiectasia (NPAT), also known as nuclear protein coactivator of histone transcription, is a transcription factor which activates histone gene transcription on chromosomes 1 and 6 of human cells. NPAT is also a substrate of cyclin E-Cdk2, which is required for the transition between G1 phase and S phase. NPAT activates histone gene expression only after it has been phosphorylated by the G1/S-Cdk cyclin E-Cdk2 in early S phase. This shows an important regulatory link between cell-cycle control and histone synthesis.\n\n\n"}
{"id": "14031", "url": "https://en.wikipedia.org/wiki?curid=14031", "title": "Hierarchical organization", "text": "Hierarchical organization\n\nA hierarchical organization is an organizational structure where every entity in the organization, except one, is subordinate to a single other entity. This arrangement is a form of a hierarchy. In an organization, the hierarchy usually consists of a singular/group of power at the top with subsequent levels of power beneath them. This is the dominant mode of organization among large organizations; most corporations, governments, and organized religions are hierarchical organizations with different levels of management, power or authority. For example, the broad, top-level overview of the general organization of the Catholic Church consists of the Pope, then the Cardinals, then the Archbishops, and so on. \n\nMembers of hierarchical organizational structures chiefly communicate with their immediate superior and with their immediate subordinates. Structuring organizations in this way is useful partly because it can reduce the communication overhead by limiting information flow.\n\nA hierarchy is typically visualized as a pyramid, where the height of the ranking or person depicts their power status and the width of that level represents how many people or business divisions are at that level relative to the whole—the highest-ranking people are at the apex, and there are very few of them; the base may include thousands of people who have no subordinates. These hierarchies are typically depicted with a tree or triangle diagram, creating an organizational chart or organigram. Those nearest the top have more power than those nearest the bottom, and there being fewer people at the top than at the bottom. As a result, superiors in a hierarchy generally have higher status and command greater rewards than their subordinates.\n\nAll governments and most companies have similar structures. Traditionally, the monarch was the pinnacle of the state. In many countries, feudalism and manorialism provided a formal social structure that established hierarchical links at every level of society, with the monarch at the top. \n\nIn modern post-feudal states the nominal top of the hierarchy still remains the head of state, which may be a president or a constitutional monarch, although in many modern states the powers of the head of state are delegated among different bodies. Below the head, there is commonly a senate, parliament or congress, which in turn often delegate the day-to-day running of the country to a prime minister. In many democracies, the people are considered to be the notional top of the hierarchy, over the head of state; in reality, the people's power is restricted to voting in elections.\n\nIn business, the business owner traditionally occupied the pinnacle of the organization. In most modern large companies, there is now no longer a single dominant shareholder, and the collective power of the business owners is for most purposes delegated to a board of directors, which in turn delegates the day-to-day running of the company to a managing director or CEO. Again, although the shareholders of the company are the nominal top of the hierarchy, in reality many companies are run at least in part as personal fiefdoms by their management; corporate governance rules are an attempt to mitigate this tendency.\n\nThe organizational development theorist Elliott Jacques identified a special role for hierarchy in his concept of requisite organization. \nThe iron law of oligarchy, introduced by Robert Michels, describes the inevitable tendency of hierarchical organizations to become oligarchic in their decision making.\n\nThe Peter Principle is a term coined by Laurence J. Peter in which the selection of a candidate for a position in an hierarchical organization is based on the candidate's performance in their current role, rather than on abilities relevant to the intended role. Thus, employees only stop being promoted once they can no longer perform effectively, and managers in an hierarchical organization \"rise to the level of their incompetence.\" \n\nHierarchiology is another term coined by Laurence J. Peter, described in his humorous book of the same name, to refer to the study of hierarchical organizations and the behavior of their members.\n\nThe IRG Solution – hierarchical incompetence and how to overcome it argued that hierarchies were inherently incompetent, and were only able to function due to large amounts of informal lateral communication fostered by private informal networks.\n\nIn the work of diverse theorists such as William James (1842–1910), Michel Foucault (1926–1984) and Hayden White, important critiques of hierarchical epistemology are advanced. James famously asserts in his work \"Radical Empiricism\" that clear distinctions of type and category are a constant but unwritten goal of scientific reasoning, so that when they are discovered, success is declared. But if aspects of the world are organized differently, involving inherent and intractable ambiguities, then scientific questions are often considered unresolved. A hesitation to declare success upon the discovery of ambiguities leaves heterarchy at an artificial and subjective disadvantage in the scope of human knowledge. This bias is an artifact of an aesthetic or pedagogical preference for hierarchy, and not necessarily an expression of objective observation.\n\nHierarchies and hierarchical thinking has been criticized by many people, including Susan McClary and one political philosophy which is vehemently opposed to hierarchical organization: anarchism. Heterarchy is the most commonly proposed alternative to hierarchy and this has been combined with responsible autonomy by Gerard Fairtlough in his work on Triarchy theory. The most beneficial aspect of a hierarchical organization is the clear command that is established. However, hierarchy may become dismantled by abuse of power.\n\nAmidst constant innovation in information and communication technologies, hierarchical authority structures are giving way to greater decision-making latitude for individuals and more flexible definitions of job activities and this new style of work presents a challenge to existing organizational forms, with some research studies contrasting traditional organizational forms against groups that operate as online communities that are characterized by personal motivation and the satisfaction of making one's own decisions. With all levels of an organization having access to information and communication via digital means, power structures align more as a wirearchy, enabling the flow of power and authority to be based not on hierarchical levels, but on information, trust, credibility, and a focus on results.\n"}
{"id": "14033", "url": "https://en.wikipedia.org/wiki?curid=14033", "title": "Harry Secombe", "text": "Harry Secombe\n\nSir Harry Donald Secombe, CBE (8 September 1921 – 11 April 2001) was a Welsh comedian, actor and singer. Secombe was a member of the British radio comedy programme \"The Goon Show\" (1951–60), playing many characters, but most notably, Neddie Seagoon. An accomplished tenor, he also appeared in musicals and films – notably as Mr Bumble in \"Oliver!\" (1968) – and, in his later years, was a presenter of television shows incorporating hymns and other devotional songs.\n\nSecombe was born in St Thomas, Swansea, the third of four children of Nellie Jane Gladys (née Davies), a shop manageress, and Frederick Ernest Secombe, a grocer. From the age of 11 he attended Dynevor School, a state grammar school in central Swansea.\n\nHis family were regular churchgoers, belonging to the congregation of St Thomas Church. A member of the choir, from the age of 12 Secombe would perform a sketch entitled \"The Welsh Courtship\" at church socials, acting as \"feed\" to his sister Carol. His elder brother, Fred Secombe, was the author of several books about his experiences as an Anglican priest and rector.\n\nAfter leaving school in 1937, Secombe became a pay clerk at Baldwin's store. With war looming, he decided in 1938 that he would join the Territorial Army. Very short sighted, he got a friend to tell him the sight test, and then learnt it by heart. He served as a Lance Bombardier in No.132 Field Regiment of the Royal Artillery. He would refer to the unit in which he served during the Second World War in the North African Campaign, Sicily, and Italy, as \"The Five-Mile Snipers\". While in North Africa Secombe met Spike Milligan for the first time. In Sicily he joined a concert party and developed his own comedy routines to entertain the troops.\n\nWhen Secombe visited the Falkland Islands to entertain the troops after the 1982 Falklands War, his old regiment promoted him to the rank of sergeant: 37 years after he had been demobbed.\n\nHe made his first radio broadcast in May 1944 on a variety show aimed at the services. Following the end of fighting in the war but prior to demobilisation Secombe joined a pool of entertainers in Naples and formed a comedy duo with Spike Milligan.\n\nSecombe joined the cast of the Windmill Theatre in 1946, using a routine he had developed in Italy about how people shaved. Secombe always claimed that his ability to sing could always be counted on to save him when he bombed. Both Milligan and Sellers credited him with keeping the act on the bill when club owners had wanted to sack them.\n\nAfter a regional touring career, his first break came in radio when he was chosen as resident comedian for the Welsh series \"Welsh Rarebit,\" followed by appearances on \"Variety Bandbox\" and a regular role in \"Educating Archie\".\n\nSecombe met Michael Bentine at the Windmill Theatre, and was introduced to Peter Sellers by his agent Jimmy Grafton. Together with Spike Milligan, the four wrote a comedy radio script, and \"Those Crazy People\" was commissioned and first broadcast on 28 May 1951. Produced by Peter Ross, this would soon become \"The Goon Show\" and the show remained on the air until 1960. Secombe mainly played Neddie Seagoon, around whom the show's absurd plots developed. In 1955, whilst appearing on \"The Goon Show\", Secombe was approached by the BBC to step in at short notice to take the lead in the radio comedy \"Hancock's Half Hour\". The star of the show, Tony Hancock, had decided to take an unannounced break abroad the day before the live airing of the second season. Secombe appeared in the lead for the first three episodes and had a guest role in the fourth after Hancock's return. All four episodes are lost, but following the discovery of the original scripts the episodes were rerecorded in 2017, with Andrew Secombe performing the role held by his then late father.\n\nWith the success of \"The Goon Show\", Secombe developed a dual career as both a comedy actor and a singer. At the beginning of his career as an entertainer his act would end with a joke version of the duet \"Sweethearts,\" in which he sang both the baritone and falsetto parts. Trained under Italian maestro Manlio di Veroli, he emerged as a \"bel canto\" tenor (characteristically, he insisted that in his case this meant \"can belto\") and had a long list of best-selling record albums to his credit.\n\nIn 1958 he appeared in the film \"Jet Storm,\" which starred Dame Sybil Thorndike and Richard Attenborough and in the same year Secombe starred in the title role in \"Davy\", one of Ealing Studios' last films.\n\nThe power of his voice allowed Secombe to appear in many stage musicals. This included 1963's \"Pickwick,\" based on Charles Dickens' \"The Pickwick Papers\", which gave him the number 18 hit single \"If I Ruled the World\" – his later signature tune. In 1965 the show was produced on tour in the United States, where on Broadway he garnered a nomination for a Tony Award for Best Actor in a Musical. He also appeared in the musical \"The Four Musketeers\" (1967) at Drury Lane, as Mr. Bumble in Carol Reed's film of \"Oliver!\" (1968), and in the Envy segment of \"The Magnificent Seven Deadly Sins\" (1971).\n\nHe would go on to star in his own television show, \"The Harry Secombe Show\", which debuted on Christmas Day 1968 on BBC 1 and ran for thirty-one episodes until 1973. A sketch comedy show featuring Julian Orchard as Secombe's regular sidekick, the series also featured guest appearances by fellow Goon Spike Milligan as well as leading performers such as Ronnie Barker and Arthur Lowe. Secombe later starred in similar vehicles such as \"Sing a Song of Secombe\" and ITV's \"Secombe with Music\" during the 1970s.\n\nLater in life, Secombe (whose brother Fred Secombe was a priest in the Church in Wales, part of the Anglican Communion) attracted new audiences as a presenter of religious programmes, such as the BBC's \"Songs of Praise\" and ITV's \"Stars on Sunday\" and \"Highway\". He was also a special programming consultant to Harlech Television. and hosted a Thames Television programme in 1979 entitled \"Cross on the Donkey's Back\". In the latter half of the 1980s, Secombe personally sponsored a football team for boys aged 9–11 in the local West Sutton Little League, 'Secombes Knights'.\n\nIn 1990, he was one of a few to be honoured by a second appearance on \"This Is Your Life\", when he was surprised by Michael Aspel at a book signing in a London branch of WH Smith. Secombe had been a subject of the show previously in March 1958 when Eamonn Andrews surprised him at the BBC Television Theatre.\n\nIn 1963 he was appointed a Commander of the Order of the British Empire (CBE).\n\nHe was knighted in 1981, and jokingly referred to himself as Sir Cumference (in recognition of his rotund figure). The motto he chose for his coat of arms was \"GO ON\", a reference to goon.\n\nSecombe suffered from peritonitis in 1980. Within two years, taking advice from doctors, he had lost five stone in weight. He had a stroke in 1997, from which he made a slow recovery. He was then diagnosed with prostate cancer in September 1998. After suffering a second stroke in 1999, he was forced to abandon his television career, but made a documentary about his condition in the hope of giving encouragement to other sufferers. Secombe had diabetes in the latter part of his life.\n\nSecombe died on 11 April 2001 at the age of 79, from prostate cancer, in hospital in Guildford, Surrey. His ashes are interred at the parish church of Shamley Green, and a later memorial service to celebrate his life was held at Westminster Abbey on 26 October 2001. As well as family members and friends, the service was also attended by Charles, Prince of Wales and representatives of Prince Philip, Duke of Edinburgh, Anne, Princess Royal, Princess Margaret, Countess of Snowdon and Prince Edward, Duke of Kent. On his tombstone is the inscription: \"To know him was to love him.\"\n\nUpon hearing of his old friend's death, Spike Milligan quipped, \"I'm glad he died before me, because I didn't want him to sing at my funeral.\" But Secombe would have the last laugh: upon Milligan's own death the following year, a recording of Secombe singing was played at Spike's memorial service.\n\nThe Secombe Theatre at Sutton, London, bears his name in memory of this former local personality. He is also fondly remembered at the London Welsh Centre, where he opened the bar on St Patrick's Day (17 March) 1971.\n\nSecombe met Myra Joan Atherton at the Mumbles Dance hall in 1946. The couple were married from 1948 until his death, and had four children:\n\n\n\n\n\n\n"}
{"id": "14034", "url": "https://en.wikipedia.org/wiki?curid=14034", "title": "Heroin", "text": "Heroin\n\nHeroin, also known as diamorphine among other names, is an opioid most commonly used as a recreational drug for its euphoric effects. Medically it is used in several countries to relieve pain or in opioid replacement therapy. Heroin is typically injected, usually into a vein; however, it can also be smoked, snorted or inhaled. The onset of effects is usually rapid and lasts for a few hours.\nCommon side effects include respiratory depression (decreased breathing), dry mouth, drowsiness, impaired mental function, constipation, and addiction. Side effects of use by injection can include abscesses, infected heart valves, blood borne infections, and pneumonia. After a history of long-term use, withdrawal symptoms can begin within hours of last use. When given by injection into a vein, heroin has two to three times the effect as a similar dose of morphine. It typically comes as a white or brown powder.\nTreatment of heroin addiction often includes behavioral therapy and medications. Medications can include buprenorphine, methadone, or naltrexone. A heroin overdose may be treated with naloxone. An estimated 17 million people use opiates of which heroin is the most common. Together with other opioids, they resulted in 122,000 deaths. The total number of heroin users as of 2015 is believed to have increased in Africa, the Americas, and Asia since 2000. In the United States about 1.6 percent of people have used heroin at some point in time with about 950,000 using in the last year. When people die from overdosing on a drug, the drug is usually an opioid and often heroin.\nHeroin was first made by C. R. Alder Wright in 1874 from morphine, a natural product of the opium poppy. Internationally, heroin is controlled under Schedules I and IV of the Single Convention on Narcotic Drugs. It is generally illegal to make, possess, or sell heroin without a license. About 448 tons of heroin were made in 2016. In 2015 Afghanistan produced about 66% of the world's opium. Heroin, which is illegally sold, is sometimes mixed with other substances such as sugar, starch, quinine, or strychnine.\n\nThe original trade name of heroin is typically used in non-medical settings. It is used as a recreational drug for the euphoria it induces. Anthropologist Michael Agar once described heroin as \"the perfect whatever drug.\" Tolerance develops quickly, and increased doses are needed in order to achieve the same effects. Its popularity with recreational drug users, compared to morphine, reportedly stems from its perceived different effects.\n\nShort-term addiction studies by the same researchers demonstrated that tolerance developed at a similar rate to both heroin and morphine. When compared to the opioids hydromorphone, fentanyl, oxycodone, and pethidine (meperidine), former addicts showed a strong preference for heroin and morphine, suggesting that heroin and morphine are particularly susceptible to abuse and addiction. Morphine and heroin were also much more likely to produce euphoria and other positive subjective effects when compared to these other opioids.\n\nIn the United States, heroin is not accepted as medically useful.\n\nUnder the generic name diamorphine, heroin is prescribed as a strong pain medication in the United Kingdom, where it is administered via subcutaneous, intramuscular, intrathecal or intravenously. It may be prescribed for the treatment of acute pain, such as in severe physical trauma, myocardial infarction, post-surgical pain and chronic pain, including end-stage terminal illnesses. In other countries it is more common to use morphine or other strong opioids in these situations. In 2004 the National Institute for Health and Clinical Excellence produced guidance on the management of caesarean section, which recommended the use of intrathecal or epidural diamorphine for post-operative pain relief.\n\nDiamorphine continues to be widely used in palliative care in the UK, where it is commonly given by the subcutaneous route, often via a syringe driver, if patients cannot easily swallow morphine solution. The advantage of diamorphine over morphine is that diamorphine is more fat soluble and therefore more potent by injection, so smaller doses of it are needed for the same effect on pain. Both of these factors are advantageous if giving high doses of opioids via the subcutaneous route, which is often necessary in palliative care.\n\nA number of European countries prescribe heroin for treatment of heroin addiction. Diamorphine may be used as a maintenance drug to assist the treatment of opiate addiction, normally in long-term chronic intravenous (IV) heroin users. It is only prescribed following exhaustive efforts at treatment via other means. It is sometimes thought that heroin users can walk into a clinic and walk out with a prescription, but the process takes many weeks before a prescription for diamorphine is issued. Though this is somewhat controversial among proponents of a zero-tolerance drug policy, it has proven superior to methadone in improving the social and health situations of addicts.\n\nThe UK Department of Health's Rolleston Committee Report in 1926 established the British approach to diamorphine prescription to users, which was maintained for the next 40 years: dealers were prosecuted, but doctors could prescribe diamorphine to users when withdrawing. In 1964 the Brain Committee recommended that only selected approved doctors working at approved specialised centres be allowed to prescribe diamorphine and benzoylmethylecgonine (cocaine) to users. The law was made more restrictive in 1968. Beginning in the 1970s, the emphasis shifted to abstinence and the use of methadone; currently only a small number of users in the UK are prescribed diamorphine.\n\nIn 1994, Switzerland began a trial diamorphine maintenance program for users that had failed multiple withdrawal programs. The aim of this program was to maintain the health of the user by avoiding medical problems stemming from the illicit use of diamorphine. The first trial in 1994 involved 340 users, although enrollment was later expanded to 1000, based on the apparent success of the program. The trials proved diamorphine maintenance to be superior to other forms of treatment in improving the social and health situation for this group of patients. It has also been shown to save money, despite high treatment expenses, as it significantly reduces costs incurred by trials, incarceration, health interventions and delinquency. Patients appear twice daily at a treatment center, where they inject their dose of diamorphine under the supervision of medical staff. They are required to contribute about 450 Swiss francs per month to the treatment costs. A national referendum in November 2008 showed 68% of voters supported the plan, introducing diamorphine prescription into federal law. The previous trials were based on time-limited executive ordinances. The success of the Swiss trials led German, Dutch, and Canadian cities to try out their own diamorphine prescription programs. Some Australian cities (such as Sydney) have instituted legal diamorphine supervised injecting centers, in line with other wider harm minimization programs.\n\nSince January 2009, Denmark has prescribed diamorphine to a few addicts that have tried methadone and subutex without success. Beginning in February 2010, addicts in Copenhagen and Odense became eligible to receive free diamorphine. Later in 2010 other cities including Århus and Esbjerg joined the scheme. It was supposed that around 230 addicts would be able to receive free diamorphine.\n\nHowever, Danish addicts would only be able to inject heroin according to the policy set by Danish National Board of Health. Of the estimated 1500 drug users who did not benefit from the then-current oral substitution treatment, approximately 900 would not be in the target group for treatment with injectable diamorphine, either because of \"massive multiple drug abuse of non-opioids\" or \"not wanting treatment with injectable diamorphine\".\n\nIn July 2009, the German Bundestag passed a law allowing diamorphine prescription as a standard treatment for addicts; a large-scale trial of diamorphine prescription had been authorized in the country in 2002.\n\nOn August 26, 2016 Health Canada issued regulations amending prior regulations it had issued under the Controlled Drugs and Substances Act; the \"New Classes of Practitioners Regulations\", the \"Narcotic Control Regulations\", and the \"Food and Drug Regulations\", to allow doctors to prescribe diamorphine to people who have a severe opioid addiction who have not responded to other treatments. The prescription heroin can be accessed by doctors through Health Canada's Special Access Programme (SAP) for \"emergency access to drugs for patients with serious or life-threatening conditions when conventional treatments have failed, are unsuitable, or are unavailable.\"\n\nThe onset of heroin's effects depends upon the route of administration. Studies have shown that the subjective pleasure of drug use (the reinforcing component of addiction) is proportional to the rate at which the blood level of the drug increases. Intravenous injection is the fastest route of drug administration, causing blood concentrations to rise the most quickly, followed by smoking, suppository (anal or vaginal insertion), insufflation (snorting), and ingestion (swallowing).\n\nIngestion does not produce a rush as forerunner to the high experienced with the use of heroin, which is most pronounced with intravenous use. While the onset of the rush induced by injection can occur in as little as a few seconds, the oral route of administration requires approximately half an hour before the high sets in. Thus, with both higher the dosage of heroin used and faster the route of administration used, the higher potential risk for psychological addiction.\n\nLarge doses of heroin can cause fatal respiratory depression, and the drug has been used for suicide or as a murder weapon. The serial killer Harold Shipman used diamorphine on his victims, and the subsequent Shipman Inquiry led to a tightening of the regulations surrounding the storage, prescribing and destruction of controlled drugs in the UK. John Bodkin Adams is also known to have used heroin as a murder weapon.\n\nBecause significant tolerance to respiratory depression develops quickly with continued use and is lost just as quickly during withdrawal, it is often difficult to determine whether a heroin lethal overdose was accidental, suicide or homicide. Examples include the overdose deaths of Sid Vicious, Janis Joplin, Tim Buckley, Hillel Slovak, Layne Staley, Bradley Nowell, Ted Binion, and River Phoenix.\n\nChronic use of heroin and other opioids has been shown to be a potential cause of hyponatremia, resultant because of excess vasopressin secretion.\n\nUse of heroin by mouth is less common than other methods of administration, mainly because there is little to no \"rush\", and the effects are less potent. Heroin is entirely converted to morphine by means of first-pass metabolism, resulting in deacetylation when ingested. Heroin's oral bioavailability is both dose-dependent (as is morphine's) and significantly higher than oral use of morphine itself, reaching up to 64.2% for high doses and 45.6% for low doses; opiate-naive users showed far less absorption of the drug at low doses, having bioavailabilities of only up to 22.9%. The maximum plasma concentration of morphine following oral administration of heroin was around twice as much as that of oral morphine.\n\nInjection, also known as \"slamming\", \"banging\", \"shooting up\", \"digging\" or \"mainlining\", is a popular method which carries relatively greater risks than other methods of administration. Heroin base (commonly found in Europe), when prepared for injection, will only dissolve in water when mixed with an acid (most commonly citric acid powder or lemon juice) and heated. Heroin in the east-coast United States is most commonly found in the hydrochloride salt form, requiring just water (and no heat) to dissolve. Users tend to initially inject in the easily accessible arm veins, but as these veins collapse over time, users resort to more dangerous areas of the body, such as the femoral vein in the groin. Users who have used this route of administration often develop a deep vein thrombosis. Intravenous users can use a various single dose range using a hypodermic needle. The dose of heroin used for recreational purposes is dependent on the frequency and level of use: thus a first-time user may use between 5 and 20 mg, while an established addict may require several hundred mg per day. As with the injection of any drug, if a group of users share a common needle without sterilization procedures, blood-borne diseases, such as HIV/AIDS or hepatitis, can be transmitted.\nThe use of a common dispenser for water for the use in the preparation of the injection, as well as the sharing of spoons and/or filters can also cause the spread of blood-borne diseases. Many countries now supply small sterile spoons and filters for single use in order to prevent the spread of disease.\n\nSmoking heroin refers to vaporizing it to inhale the resulting fumes, rather than burning and inhaling the smoke. It is commonly smoked in glass pipes made from glassblown Pyrex tubes and light bulbs. Heroin may be smoked from aluminium foil, which is heated by an underneath flame, with the resulting smoke inhaled through a tube of rolled up foil, a method also known as \"chasing the dragon\".\n\nAnother popular route to intake heroin is insufflation (snorting), where a user crushes the heroin into a fine powder and then gently inhales it (sometimes with a straw or a rolled-up banknote, as with cocaine) into the nose, where heroin is absorbed through the soft tissue in the mucous membrane of the sinus cavity and straight into the bloodstream. This method of administration redirects first-pass metabolism, with a quicker onset and higher bioavailability than oral administration, though the duration of action is shortened. This method is sometimes preferred by users who do not want to prepare and administer heroin for injection or smoking, but still experience a fast onset. Snorting heroin becomes an often unwanted route, once a user begins to inject the drug. The user may still get high on the drug from snorting, and experience a nod, but will not get a rush. A \"rush\" is caused by a large amount of heroin entering the body at once. When the drug is taken in through the nose, the user does not get the rush because the drug is absorbed slowly rather than instantly.\n\nLittle research has been focused on the suppository (anal insertion) or pessary (vaginal insertion) methods of administration, also known as \"plugging\". These methods of administration are commonly carried out using an oral syringe. Heroin can be dissolved and withdrawn into an oral syringe which may then be lubricated and inserted into the anus or vagina before the plunger is pushed. The rectum or the vaginal canal is where the majority of the drug would likely be taken up, through the membranes lining their walls.\n\nLike most opioids, unadulterated heroin may lead to adverse effects. The purity of street heroin varies greatly, leading to overdoses when the purity is higher than they expected.\n\nUsers report an intense rush, an acute transcendent state of euphoria, which occurs while diamorphine is being metabolized into 6-monoacetylmorphine (6-MAM) and morphine in the brain. Some believe that heroin produces more euphoria than other opioids; one possible explanation is the presence of 6-monoacetylmorphine, a metabolite unique to heroin – although a more likely explanation is the rapidity of onset. While other opioids of recreational use produce only morphine, heroin also leaves 6-MAM, also a psycho-active metabolite. However, this perception is not supported by the results of clinical studies comparing the physiological and subjective effects of injected heroin and morphine in individuals formerly addicted to opioids; these subjects showed no preference for one drug over the other. Equipotent injected doses had comparable action courses, with no difference in subjects' self-rated feelings of euphoria, ambition, nervousness, relaxation, drowsiness, or sleepiness. The rush is usually accompanied by a warm flushing of the skin, dry mouth, and a heavy feeling in the extremities.  Nausea, vomiting, and severe itching may also occur. After the initial effects, users usually will be drowsy for several hours; mental function is clouded; heart function slows; and breathing is also severely slowed, sometimes enough to be life-threatening. Slowed breathing can also lead to coma and permanent brain damage.\n\nRepeated heroin use changes the physical structure and physiology of the brain, creating long-term imbalances in neuronal and hormonal systems that are not easily reversed. Studies have shown some deterioration of the brain's white matter due to heroin use, which may affect decision-making abilities, the ability to regulate behavior, and responses to stressful situations. Heroin also produces profound degrees of tolerance and physical dependence. Tolerance occurs when more and more of the drug is required to achieve the same effects. With physical dependence, the body adapts to the presence of the drug, and withdrawal symptoms occur if use is reduced abruptly.\n\nIntravenous use of heroin (and any other substance) with needles and syringes or other related equipment may lead to:\n\n\nThe withdrawal syndrome from heroin (the so-called \"cold turkey\") may begin within 6–24 hours of discontinuation of the drug; however, this time frame can fluctuate with the degree of tolerance as well as the amount of the last consumed dose. Symptoms may include: sweating, malaise, anxiety, depression, akathisia, priapism, extra sensitivity of the genitals in females, general feeling of heaviness, excessive yawning or sneezing, tears, rhinorrhea, sleep difficulties (insomnia), cold sweats, chills, severe muscle and bone aches, nausea, vomiting, diarrhea, cramps, watery eyes, fever and cramp-like pains and involuntary spasms in the limbs (thought to be an origin of the term \"kicking the habit\").\n\nHeroin overdose is usually treated with the opioid antagonist, naloxone. This reverses the effects of heroin and causes an immediate return of consciousness but may result in withdrawal symptoms. The half-life of naloxone is shorter than some opioids, such that it may need to be given multiple times until the opioid has been metabolized by the body.\n\nBetween 2012 and 2015 it was the leading cause of drug related deaths in the United States. Since then fentanyl is a more common causes of drug related deaths.\n\nDepending on drug interactions and numerous other factors, death from overdose can take anywhere from several minutes to several hours. Death usually occurs due to lack of oxygen resulting from the lack of breathing caused by the opioid. Heroin overdoses can occur because of an unexpected increase in the dose or purity or because of diminished opioid tolerance. However, many fatalities reported as overdoses are probably caused by interactions with other depressant drugs such as alcohol or benzodiazepines. It should also be noted that since heroin can cause nausea and vomiting, a significant number of deaths attributed to heroin overdose are caused by aspiration of vomit by an unconscious person. Some sources quote the median lethal dose (for an average 75 kg opiate-naive individual) as being between 75 and 600  mg. Illicit heroin is of widely varying and unpredictable purity. This means that the user may prepare what they consider to be a moderate dose while actually taking far more than intended. Also, tolerance typically decreases after a period of abstinence. If this occurs and the user takes a dose comparable to their previous use, the user may experience drug effects that are much greater than expected, potentially resulting in an overdose. It has been speculated that an unknown portion of heroin-related deaths are the result of an overdose or allergic reaction to quinine, which may sometimes be used as a cutting agent.\n\nWhen taken orally, heroin undergoes extensive first-pass metabolism via deacetylation, making it a prodrug for the systemic delivery of morphine. When the drug is injected, however, it avoids this first-pass effect, very rapidly crossing the blood–brain barrier because of the presence of the acetyl groups, which render it much more fat soluble than morphine itself. Once in the brain, it then is deacetylated variously into the inactive 3-monoacetylmorphine and the active 6-monoacetylmorphine (6-MAM), and then to morphine, which bind to μ-opioid receptors, resulting in the drug's euphoric, analgesic (pain relief), and anxiolytic (anti-anxiety) effects; heroin itself exhibits relatively low affinity for the μ receptor. Unlike hydromorphone and oxymorphone, however, administered intravenously, heroin creates a larger histamine release, similar to morphine, resulting in the feeling of a greater subjective \"body high\" to some, but also instances of pruritus (itching) when they first start using.\n\nBoth morphine and 6-MAM are μ-opioid agonists that bind to receptors present throughout the brain, spinal cord, and gut of all mammals. The μ-opioid receptor also binds endogenous opioid peptides such as β-endorphin, Leu-enkephalin, and Met-enkephalin. Repeated use of heroin results in a number of physiological changes, including an increase in the production of μ-opioid receptors (upregulation). These physiological alterations lead to tolerance and dependence, so that stopping heroin use results in uncomfortable symptoms including pain, anxiety, muscle spasms, and insomnia called the opioid withdrawal syndrome. Depending on usage it has an onset 4–24 hours after the last dose of heroin. Morphine also binds to δ- and κ-opioid receptors.\n\nThere is also evidence that 6-MAM binds to a subtype of μ-opioid receptors that are also activated by the morphine metabolite morphine-6β-glucuronide but not morphine itself. The third subtype of third opioid type is the mu-3 receptor, which may be a commonality to other six-position monoesters of morphine. The contribution of these receptors to the overall pharmacology of heroin remains unknown.\n\nA subclass of morphine derivatives, namely the 3,6 esters of morphine, with similar effects and uses, includes the clinically used strong analgesics nicomorphine (Vilan), and dipropanoylmorphine; there is also the latter's dihydromorphine analogue, diacetyldihydromorphine (Paralaudin). Two other 3,6 diesters of morphine invented in 1874–75 along with diamorphine, dibenzoylmorphine and acetylpropionylmorphine, were made as substitutes after it was outlawed in 1925 and, therefore, sold as the first \"designer drugs\" until they were outlawed by the League of Nations in 1930.\n\nHeroin is derived from opium through a process involving various chemicals such as acetone and acetic anhydride.\n\nThe major metabolites of diamorphine, 6-MAM, morphine, morphine-3-glucuronide and morphine-6-glucuronide, may be quantitated in blood, plasma or urine to monitor for abuse, confirm a diagnosis of poisoning or assist in a medicolegal death investigation. Most commercial opiate screening tests cross-react appreciably with these metabolites, as well as with other biotransformation products likely to be present following usage of street-grade diamorphine such as 6-acetylcodeine and codeine. However, chromatographic techniques can easily distinguish and measure each of these substances. When interpreting the results of a test, it is important to consider the diamorphine usage history of the individual, since a chronic user can develop tolerance to doses that would incapacitate an opiate-naive individual, and the chronic user often has high baseline values of these metabolites in his system. Furthermore, some testing procedures employ a hydrolysis step before quantitation that converts many of the metabolic products to morphine, yielding a result that may be 2 times larger than with a method that examines each product individually.\n\nThe opium poppy was cultivated in lower Mesopotamia as long ago as 3400 BCE. The chemical analysis of opium in the 19th century revealed that most of its activity could be ascribed to two alkaloids, codeine and morphine.\n\nDiamorphine was first synthesized in 1874 by C. R. Alder Wright, an English chemist working at St. Mary's Hospital Medical School in London. He had been experimenting with combining morphine with various acids. He boiled anhydrous morphine alkaloid with acetic anhydride for several hours and produced a more potent, acetylated form of morphine, now called \"diacetylmorphine\" or \"morphine diacetate\". The compound was sent to F. M. Pierce of Owens College in Manchester for analysis. Pierce told Wright:\n\nWright's invention did not lead to any further developments, and diamorphine became popular only after it was independently re-synthesized 23 years later by another chemist, Felix Hoffmann. Hoffmann, working at Bayer pharmaceutical company in Elberfeld, Germany, was instructed by his supervisor Heinrich Dreser to acetylate morphine with the objective of producing codeine, a constituent of the opium poppy, pharmacologically similar to morphine but less potent and less addictive. Instead, the experiment produced an acetylated form of morphine one and a half to two times more potent than morphine itself. The head of Bayer's research department reputedly coined the drug's new name, \"heroin,\" based on the German \"heroisch\", which means \"heroic, strong\" (from the ancient Greek word \"heros, ήρως\"). Bayer scientists were not the first to make heroin, but their scientists discovered ways to make it, and Bayer led commercialization of heroin.\n\nIn 1895, the German drug company Bayer marketed diacetylmorphine as an over-the-counter drug under the trademark name Heroin. It was developed chiefly as a morphine substitute for cough suppressants that did not have morphine's addictive side-effects. Morphine at the time was a popular recreational drug, and Bayer wished to find a similar but non-addictive substitute to market. However, contrary to Bayer's advertising as a \"non-addictive morphine substitute,\" heroin would soon have one of the highest rates of addiction among its users.\n\nFrom 1898 through to 1910, diamorphine was marketed under the trademark name Heroin as a non-addictive morphine substitute and cough suppressant. In the 11th edition of \"Encyclopædia Britannica\" (1910), the article on morphine states: \"In the cough of phthisis minute doses [of morphine] are of service, but in this particular disease morphine is frequently better replaced by codeine or by heroin, which checks irritable coughs without the narcotism following upon the administration of morphine.\"\n\nIn the U.S., the Harrison Narcotics Tax Act was passed in 1914 to control the sale and distribution of diacetylmorphine and other opioids, which allowed the drug to be prescribed and sold for medical purposes. In 1924, the United States Congress banned its sale, importation, or manufacture. It is now a Schedule I substance, which makes it illegal for non-medical use in signatory nations of the Single Convention on Narcotic Drugs treaty, including the United States.\n\nThe Health Committee of the League of Nations banned diacetylmorphine in 1925, although it took more than three years for this to be implemented. In the meantime, the first designer drugs, viz. 3,6 diesters and 6 monoesters of morphine and acetylated analogues of closely related drugs like hydromorphone and dihydromorphine, were produced in massive quantities to fill the worldwide demand for diacetylmorphine—this continued until 1930 when the Committee banned diacetylmorphine analogues with no therapeutic advantage over drugs already in use, the first major legislation of this type.\n\nBayer lost some of its trademark rights to heroin under the 1919 Treaty of Versailles following the German defeat in World War I.\n\nUse of heroin by jazz musicians in particular was prevalent in the mid-twentieth century, including Billie Holiday, saxophonists Charlie Parker and Art Pepper, guitarist Joe Pass and piano player/singer Ray Charles; a \"staggering number of jazz musicians were addicts\". It was also a problem with many rock musicians, particularly from the late 1960s through the 1990s. Pete Doherty is also a self-confessed user of heroin. Nirvana lead singer Kurt Cobain's heroin addiction was well documented. Pantera frontman, Phil Anselmo, turned to heroin while touring during the 1990s to cope with his back pain. Many musicians have made songs referencing their heroin usage.\n\n\"Diamorphine\" is the Recommended International Nonproprietary Name and British Approved Name. Other synonyms for heroin include: diacetylmorphine, and morphine diacetate. Heroin is also known by many street names including dope, H, smack, junk, horse, and brown, among others.\n\nIn Hong Kong, diamorphine is regulated under Schedule 1 of Hong Kong's Chapter 134 \"Dangerous Drugs Ordinance\". It is available by prescription. Anyone supplying diamorphine without a valid prescription can be fined $10,000 (HKD). The penalty for trafficking or manufacturing diamorphine is a $50,000 (HKD) fine and life imprisonment. Possession of diamorphine without a license from the Department of Health is illegal with a $10,000 (HKD) fine and/or 7 years of jail time.\nIn the Netherlands, diamorphine is a List I drug of the Opium Law. It is available for prescription under tight regulation exclusively to long-term addicts for whom methadone maintenance treatment has failed. It cannot be used to treat severe pain or other illnesses.\n\nIn the United Kingdom, diamorphine is available by prescription, though it is a restricted Class A drug. According to the 50th edition of the British National Formulary (BNF), diamorphine hydrochloride may be used in the treatment of acute pain, myocardial infarction, acute pulmonary oedema, and chronic pain. The treatment of chronic non-malignant pain must be supervised by a specialist. The BNF notes that all opioid analgesics cause dependence and tolerance but that this is \"no deterrent in the control of pain in terminal illness\". When used in the palliative care of cancer patients, diamorphine is often injected using a syringe driver.\n\nIn Switzerland, heroin is produced in injectable or tablet form under the name Diaphin by a private company under contract to the Swiss government. Swiss-produced heroin has been imported into Canada with government approval.\n\nIn Australia diamorphine is listed as a schedule 9 prohibited substance under the Poisons Standard (October 2015). A schedule 9 drug is outlined in the Poisons Act 1964 as \"Substances which may be abused or misused, the manufacture, possession, sale or use of which should be prohibited by law except when required for medical or scientific research, or for analytical, teaching or training purposes with approval of the CEO.\"\n\nIn Canada, diamorphine is a controlled substance under Schedule I of the Controlled Drugs and Substances Act (CDSA). Any person seeking or obtaining diamorphine without disclosing authorization 30 days before obtaining another prescription from a practitioner is guilty of an indictable offense and subject to imprisonment for a term not exceeding seven years. Possession of diamorphine for the purpose of trafficking is an indictable offense and subject to imprisonment for life.\n\nIn the United States, diamorphine is a Schedule I drug according to the Controlled Substances Act of 1970, making it illegal to possess without a DEA license. Possession of more than 100 grams of diamorphine or a mixture containing diamorphine is punishable with a minimum mandatory sentence of 5 years of imprisonment in a federal prison.\n\nAbused prescription medicine such as opioid can lead to heroin addiction. The number of death from illegal opioid overdose follows the increasing number of death caused by prescription opioid overdoses. Prescription opioids are relatively easy to obtain. This may ultimately lead to heroin injection because heroin is cheaper than prescribed pills.\n\nDiamorphine is produced from acetylation of morphine derived from natural opium sources. Numerous mechanical and chemical means are used to purify the final product. The final products have a different appearance depending on purity and have different names.\n\nHeroin purity has been classified into four grades. No.4 is the purest form – white powder (salt) to be easily dissolved and injected. No.3 is \"brown sugar\" for smoking (base). No.1 and No.2 are unprocessed raw heroin (salt or base).\n\nTraffic is heavy worldwide, with the biggest producer being Afghanistan. According to a U.N. sponsored survey, in 2004, Afghanistan accounted for production of 87 percent of the world's diamorphine. Afghan opium kills around 100,000 people annually.\n\nIn 2003 \"The Independent\" reported:\nOpium production in that country has increased rapidly since, reaching an all-time high in 2006. War in Afghanistan once again appeared as a facilitator of the trade. Some 3.3 million Afghans are involved in producing opium.\n\nAt present, opium poppies are mostly grown in Afghanistan (), and in Southeast Asia, especially in the region known as the Golden Triangle straddling Burma (), Thailand, Vietnam, Laos () and Yunnan province in China. There is also cultivation of opium poppies in Pakistan (), Mexico () and in Colombia (). According to the DEA, the majority of the heroin consumed in the United States comes from Mexico (50%) and Colombia (43-45%) via Mexican criminal cartels such as Sinaloa Cartel. However, these statistics may be significantly unreliable, the DEA's 50/50 split between Colombia and Mexico is contradicted by the amount of hectares cultivated in each country and in 2014, the DEA claimed most of the heroin in the US came from Colombia.\n, the Sinaloa Cartel is the most active drug cartel involved in smuggling illicit drugs such as heroin into the United States and trafficking them throughout the United States. According to the Royal Canadian Mounted Police, 90% of the heroin seized in Canada (where the origin was known) came from Afghanistan. Pakistan is the destination and transit point for 40 percent of the opiates produced in Afghanistan, other destinations of Afghan opiates are Russia, Europe and Iran.\n\nConviction for trafficking heroin carries the death penalty in most Southeast Asian, some East Asian and Middle Eastern countries (see Use of death penalty worldwide for details), among which Malaysia, Singapore and Thailand are the most strict. The penalty applies even to citizens of countries where the penalty is not in place, sometimes causing controversy when foreign visitors are arrested for trafficking, for example the arrest of nine Australians in Bali, the death sentence given to Nola Blake in Thailand in 1987, or the hanging of an Australian citizen Van Tuong Nguyen in Singapore.\n\nThe origins of the present international illegal heroin trade can be traced back to laws passed in many countries in the early 1900s that closely regulated the production and sale of opium and its derivatives including heroin. At first, heroin flowed from countries where it was still legal into countries where it was no longer legal. By the mid-1920s, heroin production had been made illegal in many parts of the world. An illegal trade developed at that time between heroin labs in China (mostly in Shanghai and Tianjin) and other nations. The weakness of government in China and conditions of civil war enabled heroin production to take root there. Chinese triad gangs eventually came to play a major role in the illicit heroin trade. The French Connection route started in the 1930s.\n\nHeroin trafficking was virtually eliminated in the U.S. during World War II because of temporary trade disruptions caused by the war. Japan's war with China had cut the normal distribution routes for heroin and the war had generally disrupted the movement of opium. After World War II, the Mafia took advantage of the weakness of the postwar Italian government and set up heroin labs in Sicily. The Mafia took advantage of Sicily's location along the historic route opium took westward into Europe and the United States. Large-scale international heroin production effectively ended in China with the victory of the communists in the civil war in the late 1940s. The elimination of Chinese production happened at the same time that Sicily's role in the trade developed.\n\nAlthough it remained legal in some countries until after World War II, health risks, addiction, and widespread recreational use led most western countries to declare heroin a controlled substance by the latter half of the 20th century. In the late 1960s and early 1970s, the CIA supported anti-Communist Chinese Nationalists settled near the Sino-Burmese border and Hmong tribesmen in Laos. This helped the development of the Golden Triangle opium production region, which supplied about one-third of heroin consumed in US after the 1973 American withdrawal from Vietnam. In 1999, Burma, the heartland of the Golden Triangle, was the second largest producer of heroin, after Afghanistan.\n\nThe Soviet-Afghan war led to increased production in the Pakistani-Afghan border regions, as U.S.-backed mujaheddin militants raised money for arms from selling opium, contributing heavily to the modern Golden Crescent creation. By 1980, 60 percent of heroin sold in the U.S. originated in Afghanistan. It increased international production of heroin at lower prices in the 1980s. The trade shifted away from Sicily in the late 1970s as various criminal organizations violently fought with each other over the trade. The fighting also led to a stepped-up government law enforcement presence in Sicily.\n\nFollowing the discovery at a Jordanian airport of a toner cartridge that had been modified into an improvised explosive device, the resultant increased level of airfreight scrutiny led to a major shortage (drought) of heroin from October 2010 until April 2011. This was reported in most of mainland Europe and the UK which led to a price increase of approximately 30 percent in the cost of street heroin and an increased demand for diverted methadone. The number of addicts seeking treatment also increased significantly during this period. Other heroin droughts (shortages) have been attributed to cartels restricting supply in order to force a price increase and also to a fungus that attacked the opium crop of 2009. Many people thought that the American government had introduced pathogens into the Afghanistan atmosphere in order to destroy the opium crop and thus starve insurgents of income.\n\nOn 13 March 2012, Haji Bagcho, with ties to the Taliban, was convicted by a U.S. District Court of conspiracy, distribution of heroin for importation into the United States and narco-terrorism. Based on heroin production statistics compiled by the United Nations Office on Drugs and Crime, in 2006, Bagcho's activities accounted for approximately 20 percent of the world's total production for that year.\n\nThe European Monitoring Centre for Drugs and Drug Addiction reports that the retail price of brown heroin varies from €14.5 per gram in Turkey to €110 per gram in Sweden, with most European countries reporting typical prices of €35–40 per gram. The price of white heroin is reported only by a few European countries and ranged between €27 and €110 per gram.\n\nThe United Nations Office on Drugs and Crime claims in its 2008 World Drug Report that typical US retail prices are US$172 per gram.\n\nHarm reduction is a public health philosophy that seeks to reduce the harms associated with the use of illicit drugs. One aspect of harm reduction initiatives focuses on the behaviour of individual users. In the case of diamorphine, this includes promoting safer means of taking the drug, such as smoking, nasal use, oral or rectal insertion. This attempts to avoid the higher risks of overdose, infections and blood-borne viruses associated with injecting the drug. Other measures include using a small amount of the drug first to gauge the strength, and minimize the risks of overdose. For the same reason, poly drug use (the use of two or more drugs at the same time) is discouraged. Injecting diamorphine users are encouraged to use new needles, syringes, spoons/steri-cups and filters every time they inject and not share these with other users. Users are also encouraged to not use it on their own, as others can assist in the event of an overdose.\n\nGovernments that support a harm reduction approach usually fund needle and syringe exchange programs, which supply new needles and syringes on a confidential basis, as well as education on proper filtering before injection, safer injection techniques, safe disposal of used injecting gear and other equipment used when preparing diamorphine for injection may also be supplied including citric acid sachets/vitamin C sachets, steri-cups, filters, alcohol pre-injection swabs, sterile water ampules and tourniquets (to stop use of shoe laces or belts).\n\nAnother harm reduction measure employed for example in Europe, Canada and Australia are safe injection sites where users can inject diamorphine and cocaine under the supervision of medically trained staff. Safe injection sites are low threshold and allow social services to approach problem users that would otherwise be hard to reach.\nIn the UK the Criminal Justice System has a protocol in place that requires that any individual that is arrested and is suspected of having a substance misuse problem be offered the chance to enter a treatment program. This has had the effect of drastically reducing an area's crime rate as individuals arrested for theft in order to supply the funds for their drugs are no longer in the position of having to steal to purchase heroin because they have been placed onto a methadone program, quite often more quickly than would have been possible had they not been arrested. This aspect of harm reduction is seen as being beneficial to both the individual and the community at large, who are then protected from the possible theft of their goods.\n\nDuring the late 1980s and early 1990s, Swiss authorities ran the ZIPP-AIDS (Zurich Intervention Pilot Project), handing out free syringes in the officially tolerated drug scene in Platzspitz park. In 1994, Zurich started a pilot project using prescription heroin in heroin-assisted treatment (HAT) which allowed users to obtain heroin and inject it under medical supervision. The HAT program proved to be cost-beneficial to society and improve patients overall health and social stability and has since been introduced in multiple European countries.\n\nResearchers are attempting to reproduce the biosynthetic pathway that produces morphine in genetically engineered yeast. In June 2015 the \"S\"-reticuline could be produced from sugar and \"R\"-reticuline could be converted to morphine, but the intermediate reaction could not be performed.\n\n\n"}
{"id": "14035", "url": "https://en.wikipedia.org/wiki?curid=14035", "title": "Hellas Verona F.C.", "text": "Hellas Verona F.C.\n\nHellas Verona Football Club, commonly known simply as Hellas Verona and locally as Verona or Hellas, is a professional Italian football club, based in Verona, in the region of Veneto, that currently plays in Serie B. The team won the Serie A Championship in 1984–85.\n\nFounded in 1903 by a group of high school students, the club was named \"Hellas\" (the Greek word for Greece), at the request of a professor of classics. At a time in which football was played seriously only in the larger cities of the northwest of Italy, most of Verona was indifferent to the growing sport. However, when in 1906 two city teams chose the city's Roman amphitheatre as a venue to showcase the game, crowd enthusiasm and media interest began to rise.\n\nDuring these first few years, Hellas was one of three or four area teams playing mainly at a municipal level while fighting against city rivals Bentegodi to become the city's premier football outfit. By the 1907–08 season, Hellas was playing against regional teams and an intense rivalry with Vicenza that lasts to this day was born.\n\nFrom 1898 to 1926, Italian football was organised into regional groups. In this period, Hellas was one of the founding teams of the early league and often among its top final contenders. In 1911, the city helped Hellas replace the early, gritty football fields with a proper venue. This allowed the team to take part in its first regional tournament, which until 1926, was the qualifying stage for the national title.\n\nIn 1919, following a return to activity after a four-year suspension of all football competition in Italy during World War I, the team merged with city rival Verona and changed its name to Hellas Verona. Between 1926 and 1929, the elite \"\"Campionato Nazionale\"\" assimilated the top sides from the various regional groups and Hellas Verona joined the privileged teams, yet struggled to remain competitive.\n\nSerie A, as it is structured today, began in 1929, when the \"Campionato Nazionale\" turned into a professional league. Still an amateur team, Hellas merged with two city rivals, Bentegodi and Scaligera, to form AC Verona. Hoping to build a first class contender for future years the new team debuted in Serie B in 1929. It would take the \"gialloblu\" 28 years to finally achieve their goal. After first being promoted to Serie A for one season in 1957–58, in 1959, the team merged with another city rival (called Hellas) and commemorated its beginnings by changing its name to Hellas Verona AC.\n\nCoached by Nils Liedholm, the team returned to Serie A in 1968 and remained in the elite league almost without interruption until 1990. Along the way, it scored a famous 5–3 win in the 1972–73 season that cost Milan the \"scudetto\" (the Serie A title). The fact that the result came late during the last matchday of the season makes the sudden and unexpected end to the \"rossoneri\"'s title ambitions all the more memorable.\n\nIn 1973–74, Hellas finished the season in fourth-last, just narrowly avoiding relegation, but were nonetheless sent down to Serie B during the summer months as a result of a scandal involving team president Saverio Garonzi. After a year in Serie B, Hellas returned to Serie A.\n\nIn the 1975–76 season, the team had a successful run in the Coppa Italia, eliminating highly rated teams such as Torino, Cagliari and Internazionale from the tournament. However, in their first ever final in the competition, Hellas were trounced 4–0 by Napoli.\n\nUnder the leadership of coach Osvaldo Bagnoli, in 1982–83 the team secured a fourth-place in Serie A (its highest finish at the time) and even led the Serie A standings for a few weeks. The same season Hellas again reached the Coppa Italia final. After a 2–0 home victory, Hellas then travelled to Turin to play Juventus but were defeated 3–0 after extra time.\n\nFurther disappointment followed in the 1983–84 season when the team again reached the Coppa Italia final, only to lose the Cup in the final minutes of the return match against defending Serie A champions Roma\n\nThe team made its first European appearance in the 1983-84 UEFA Cup and were knocked out in the second round of the tournament by Sturm Graz. Hellas were eliminated from the 1985–86 European Cup in the second round by defending champions and fellow Serie A side Juventus after a contested game, the result of a scandalous arbitrage by the French Wurtz, having beaten PAOK of Greece in the first round.\n\nIn 1988, the team had their best international result when they reached the UEFA Cup quarterfinals with four victories and three draws. The decisive defeat came from German side Werder Bremen.\n\nAlthough the 1984–85 season squad was made up of a mix of emerging players and mature stars, at the beginning of the season no one would have regarded the team as having the necessary ingredients to make it to the end. Certainly, the additions of Hans-Peter Briegel in midfield and of Danish striker Preben Elkjær to an attack that already featured the wing play of Pietro Fanna, the creative abilities of Antonio Di Gennaro and the scoring touch of Giuseppe Galderisi were to prove crucial.\n\nTo mention a few of the memorable milestones on the road to the \"scudetto\": a decisive win against Juventus (2–0), with a goal scored by Elkjær after having lost a boot in a tackle just outside the box, set the stage early in the championship; an away win over Udinese (5–3) ended any speculation that the team was losing energy at the midway point; three straight wins (including a hard-fought 1–0 victory against a strong Roma side) served notice that the team had kept its polish and focus intact during their rival's final surge; and a 1–1 draw in Bergamo against Atalanta secured the title with a game in hand.\n\nHellas finished the year with a 15–13–2 record and 43 points, four points ahead of Torino F.C. with Internazionale and Sampdoria rounding out the top four spots. This unusual final table of the Serie A (with the most successful Italian teams of the time, Juventus and Roma, ending up much lower than expected) has led to many speculations. The 1984–85 season was the only season when referees were assigned to matches by way of a random draw. Before then each referee had always been assigned to a specific match by a special commission of referees (\"designatori arbitrali\"). After the betting scandal of the early 1980 (the Calcio Scommesse scandal), it was decided to clean up the image of Italian football by assigning referees randomly instead of picking them, to clear up all the suspicions and accusations always accompanying Italy's football life. This resulted in a quieter championship and in a completely unexpected final table.\n\nIn the following season, won again by Juventus, the choice of the referees went back in the hands of the \"designatori arbitrali\". In 2006, a major scandal in Italian football revealed that certain clubs had been illegally influencing the referee selection process in an attempt to ensure that certain referees were assigned to their matches.\n\nThese were more than mere modest achievements for a mid-size city with a limited appeal to fans across the nation. But soon enough financial difficulties caught up with team managers. In 1991 the team folded and was reborn as Verona, regularly moving to and fro between Serie A and Serie B for several seasons. In 1995 the name was officially changed back to Hellas Verona.\n\nAfter a three-year stay, their last stint in Serie A ended in grief in 2002. That season emerging international talents such as Adrian Mutu, Mauro Camoranesi, Alberto Gilardino, Martin Laursen, Massimo Oddo, Marco Cassetti and coach Alberto Malesani failed to capitalise on an excellent start and eventually dropped into fourth-to-last place for the first time all season on the very last matchday, enforcing relegation into Serie B.\n\nFollowing the 2002 relegation to Serie B, team fortunes continued to slip throughout the decade. In the 2003–04 season Hellas Verona struggled in Serie B and spent most of the season fighting off an unthinkable relegation to Serie C1. Undeterred, the fans supported their team and a string of late season wins eventually warded off the danger. Over 5,000 of them followed Hellas to Como on the final day of the season to celebrate.\n\nIn 2004–05, things looked much brighter for the team. After a rocky start, Hellas put together a string of results and climbed to third spot. The \"gialloblù\" held on to the position until January 2005, when transfers weakened the team, yet they managed to take the battle for Serie A to the last day of the season.\n\nThe 2006–07 Serie B seemed to start well, due to the club takeover by Pietro Arvedi D'Emilei, which ended nine years of controversial leadership under chairman Gianbattista Pastorello, heavily contested by the supporters in his later years at Verona. However, Verona was immediately involved in the relegation battle, and Massimo Ficcadenti was replaced in December 2006 by Giampiero Ventura. Despite a recovery in the results, Verona ended in an 18th place, thus being forced to play a two-legged playoff against 19th-placed Spezia to avert relegation. A 2–1 away loss in the first leg at La Spezia was followed by a 0–0 home tie, and Verona were relegated to Serie C1 after 64 years of play in the two highest divisions.\n\nVerona appointed experienced coach Franco Colomba for the new season with the aim to return to Serie B as soon as possible. However, despite being widely considered the division favourite, the \"gialloblù\" spent almost the entire season in last place. After seven matches, club management sacked Colomba in early October and replaced him with youth team coach (and former Verona player) Davide Pellegrini. A new owner acquired the club in late 2007, appointing Giovanni Galli in December as new director of football and Maurizio Sarri as new head coach. Halfway through the 2007–08 season, the team remained at the bottom of Serie C1, on the brink of relegation to the fourth level (Serie C2). In response, club management sacked Sarri and brought back Pellegrini. Thanks to a late-season surge the \"scaligeri\" avoided direct relegation by qualifying for the relegation play-off, and narrowly averted dropping to Lega Pro Seconda Divisione in the final game, beating Pro Patria 2–1 on aggregate. However, despite the decline in results, attendance and season ticket sales remained on 15,000 average.\n\nFor the 2008–09 season, Verona appointed former Sassuolo and Piacenza manager Gian Marco Remondina with the aim to win promotion to Serie B. However, the season did not start impressively, with Verona being out of the playoff zone by mid-season, and club chairman Pietro Arvedi D'Emilei entering into a coma after being involved in a car crash on his way back from a league match in December 2008. Arvedi died in March 2009, two months after the club was bought by new chairman Giovanni Martinelli.\n\nThe following season looked promising, as new transfer players were brought aboard, and fans enthusiastically embraced the new campaign. Season ticket figures climbed to over 10,000, placing Verona ahead of several Serie A teams and all but Torino in Serie B attendance. The team led the standings for much of the season, accumulating a seven-point lead by early in the spring. However, the advantage was gradually squandered, and the team dropped to second place on the second-last day of the season, with a chance to regain first place in the final regular season match against Portogruaro on home soil. Verona, however, disappointed a crowd of over 25,000 fans and, with the loss, dropped to third place and headed towards the play-offs. A managerial change for the post-season saw the firing of Remondina and the arrival of Giovanni Vavassori. After eliminating Rimini in the semi-finals (1–0; 0–0) Verona lost the final to Pescara (2–2 on home soil and 0–1 in the return match) and were condemned to a fourth-straight year of third division football.\n\nFormer 1990 World Cup star Giuseppe Giannini (a famous captain of Roma for many years) signed as manager for the 2010–11 campaign. Once again, the team was almost entirely revamped during the transfer season. The squad struggled in the early months and Giannini was eventually sacked and replaced by former Internazionale defender Andrea Mandorlini, who succeeded in reorganising the team's play and bringing discipline both on and off the pitch. In the second half of the season, Verona climbed back from the bottom of the division to clinch a play-off berth (fifth place) on the last day of the regular season. The team advanced to the play-off final after eliminating Sorrento in the semi-finals 3–1 on aggregate. Following the play-off final, after four years of Lega Pro football, Verona were promoted back to Serie B after a 2–1 aggregate win over Salernitana on 19 June 2011.\n\nOn 18 May 2013, Verona finished second in Serie B and were promoted to Serie A after an 11-year absence. Their return to the top flight began against title contenders Milan and Roma, beating the former 2–1 and losing to the latter 3–0. The team continued at a steady pace, finishing the first half of the season with 32 points and sitting in sixth place—11 points behind the closest UEFA Champions League spot—and tied with Internazionale for the final UEFA Europa League spot. Verona, however, ultimately finished the year in tenth.\n\nDuring the 2015–16 season, Verona hadn't won a single match since the beginning of the campaign until the club edged Atalanta 2–1 on 3 February 2016 in a win at home; coming twenty-three games into the season. Consequently, Verona were relegated from Serie A.\n\nThe team's colours are yellow and blue and \"gialloblu\" (literally, \"yellow-blue\" in Italian) is the team's most widely used nickname. The colours represent the city itself and Verona's emblem (a yellow cross on a blue shield) appears on most team apparel. Two more team nicknames are \"Mastini\" (the mastiffs) and \"Scaligeri\", both references to Mastino I della Scala of the Della Scala princes that ruled the city during the 13th and 14th centuries.\n\nThe Scala family coat of arms is depicted on the team's jersey and on its trademark logo as a stylised image of two large, powerful mastiffs facing opposite directions, introduced in 1995. In essence, the term \"\"scaligeri\"\" is synonymous with Veronese, and therefore can describe anything or anyone from Verona (e.g., Chievo Verona, a different team that also links itself to the Scala family – specifically to Cangrande I della Scala).\n\nSince 1963, the club have played at the Stadio Marc'Antonio Bentegodi, which has a capacity of 39,211. The ground is shared with Hellas' rivals, Chievo Verona. It was used as a venue for the 1990 FIFA World Cup.\n\nThe intercity fixtures against Chievo Verona are known as the \"Derby della Scala\". The name refers to the Scaligeri or della Scala aristocratic family, who were rulers of Verona during the Middle Ages and early Renaissance. In the season 2001–02, both Hellas Verona and the city rivals of Chievo Verona were playing in the Serie A. The first ever derby of Verona in Serie A took place on 18 November 2001, while both teams were ranked among the top four. The match was won by Hellas, 3–2. Chievo got revenge in the return match in spring 2002, winning 2–1. Verona thus became the fifth city in Italy, after Milan, Rome, Turin and Genoa to host a cross-town derby in Serie A.\n\n\n\n\n\n"}
{"id": "14036", "url": "https://en.wikipedia.org/wiki?curid=14036", "title": "Hinayana", "text": "Hinayana\n\n\"Hīnayāna\" () is a Sanskrit term literally meaning the \"inferior vehicle\". Classical Chinese and Tibetan teachers translate it as \"smaller vehicle\". The term was applied to the \"Śrāvakayāna\", the Buddhist path followed by a śrāvaka who wished to become an arhat. This pejorative term appeared around the first or second century. Hīnayāna was often contrasted with \"Mahāyāna\", which means the \"great vehicle\".\n\nIn 1950 the World Fellowship of Buddhists declared that the term Hīnayana should not be used when referring to any form of Buddhism existing today.\n\nIn the past, the term was widely used by Western scholars to cover \"the earliest system of Buddhist doctrine\", as the \"Monier-Williams Sanskrit-English Dictionary\" put it. Modern Buddhist scholarship has deprecated the pejorative term, and uses instead the term \"Nikaya Buddhism\" to refer to early Buddhist schools. \n\n\"Hinayana\" has also been used as a synonym for Theravada, which is the main tradition of Buddhism in Sri Lanka and Southeast Asia; this is considered inaccurate and derogatory. Robert Thurman writes, \"'Nikaya Buddhism' is a coinage of Professor Masatoshi Nagatomi of Harvard University, who suggested it to me as a usage for the eighteen schools of Indian Buddhism to avoid the term 'Hinayana Buddhism,' which is found offensive by some members of the Theravada tradition.\" \n\nWithin Mahayana Buddhism, there were a variety of interpretations as to whom or to what the term \"Hinayana\" referred. Kalu Rinpoche stated the \"lesser\" or \"greater\" designation \"did not refer to economic or social status, but concerned the spiritual capacities of the practitioner\".\nThe Chinese monk Yijing, who visited India in the 7th century, distinguished Mahāyāna from Hīnayāna as follows:\nThe word \"hīnayāna\" is formed of \"hīna\": \"little\", \"poor\", \"inferior\", \"abandoned\", \"deficient\", \"defective\"; and \"yāna\" (यान): \"vehicle\", where \"vehicle\" means \"a way of going to enlightenment\". The Pali Text Society's \"Pali-English Dictionary\" (1921–25) defines \"hīna\" in even stronger terms, with a semantic field that includes \"poor, miserable; vile, base, abject, contemptible\", and \"despicable\".\n\nThe term was translated by Kumārajīva and others into Classical Chinese as \"small vehicle\" (小 meaning \"small\", 乘 meaning \"vehicle\"), although earlier and more accurate translations of the term also exist. In Mongolian (\"Baga Holgon\") the term for hinayana also means \"small\" or \"lesser\" vehicle, while in Tibetan there are at least two words to designate the term, \"theg chung\" meaning \"small vehicle\" and \"theg dman\" meaning \"inferior vehicle\" or \"inferior spiritual approach\".\n\nThrangu Rinpoche has emphasized that \"hinayana\" is in no way implying \"inferior\". In his translation and commentary of Asanga's \"Distinguishing Dharma from Dharmata\", he writes, \"all three traditions of hinayana, mahayana, and vajrayana were practiced in Tibet and that the hinayana which literally means \"lesser vehicle\" is in no way inferior to the mahayana.\"\n\nAccording to Jan Nattier, it is most likely that the term Hīnayāna postdates the term Mahāyāna and was only added at a later date due to antagonism and conflict between the bodhisattva and śrāvaka ideals. The sequence of terms then began with the term \"Bodhisattvayāna\" \"bodhisattva-vehicle\", which was given the epithet Mahāyāna \"Great Vehicle\". It was only later, after attitudes toward the bodhisattva teachings had become more critical, that the term Hīnayāna was created as a back-formation, contrasting with the already established term Mahāyāna. The earliest Mahāyāna texts often use the term Mahāyāna as an epithet and synonym for Bodhisattvayāna, but the term Hīnayāna is comparatively rare in early texts, and is usually not found at all in the earliest translations. Therefore, the often-perceived symmetry between Mahāyāna and Hīnayāna can be deceptive, as the terms were not actually coined in relation to one another in the same era.\n\nAccording to Paul Williams, \"the deep-rooted misconception concerning an unfailing, ubiquitous fierce criticism of the Lesser Vehicle by the [Mahāyāna] is not supported by our texts.\" Williams states that while evidence of conflict is present in some cases, there is also substantial evidence demonstrating peaceful coexistence between the two traditions.\n\nAlthough the 18–20 early Buddhist schools are sometimes loosely classified as Hīnayāna in modern times, this is not necessarily accurate. There is no evidence that Mahāyāna ever referred to a separate formal school of Buddhism but rather as a certain set of ideals, and later doctrines. Paul Williams has also noted that the Mahāyāna never had nor ever attempted to have a separate vinaya or ordination lineage from the early Buddhist schools, and therefore bhikṣus and bhikṣuṇīs adhering to the Mahāyāna formally adheres to the vinaya of an early school. This continues today with the Dharmaguptaka ordination lineage in East Asia and the Mūlasarvāstivāda ordination lineage in Tibetan Buddhism. Mahāyāna was never a separate sect of the early schools. From Chinese monks visiting India, we now know that both Mahāyāna and non-Mahāyāna monks in India often lived in the same monasteries side by side.\n\nThe Chinese Buddhist monk and pilgrim Yijing wrote about the relationship between the various \"vehicles\" and the early Buddhist schools in India. He wrote, \"There exist in the West numerous subdivisions of the schools which have different origins, but there are only four principal schools of continuous tradition.\" These schools are the Mahāsāṃghika Nikāya, Sthavira nikāya, Mūlasarvāstivāda Nikāya, and Saṃmitīya Nikāya. Explaining their doctrinal affiliations, he then writes, \"Which of the four schools should be grouped with the Mahāyāna or with the Hīnayāna is not determined.\" That is to say, there was no simple correspondence between a Buddhist school and whether its members learn \"Hīnayāna\" or \"Mahāyāna\" teachings.\n\nTo identify entire schools as \"Hīnayāna\" that contained not only śrāvakas and pratyekabuddhas but also Mahāyāna bodhisattvas would be attacking the schools of their fellow Mahāyānists as well as their own. Instead, what is demonstrated in the definition of \"Hīnayāna\" given by Yijing is that the term referred to individuals based on doctrinal differences.\n\nScholar Isabelle Onians asserts that although \"the Mahāyāna ... very occasionally referred to earlier Buddhism as the Hinayāna, the Inferior Way, [...] the preponderance of this name in the secondary literature is far out of proportion to occurrences in the Indian texts.\" She notes that the term Śrāvakayāna was \"the more politically correct and much more usual\" term used by Mahāyānists. Jonathan Silk has argued that the term \"Hinayana\" was used to refer to whomever one wanted to criticize on any given occasion, and did not refer to any definite grouping of Buddhists.\n\nIn the 7th century, the Chinese Buddhist monk Xuanzang describes the concurrent existence of the Mahāvihara and the Abhayagiri vihāra in Sri Lanka. He refers to the monks of the Mahāvihara as the \"Hīnayāna Sthaviras\" and the monks of Abhayagiri vihāra as the \"Mahāyāna Sthaviras\". Xuanzang further writes, \"The Mahāvihāravāsins reject the Mahāyāna and practice the Hīnayāna, while the Abhayagirivihāravāsins study both Hīnayāna and Mahāyāna teachings and propagate the \"Tripiṭaka\".\"\n\nMahayanists were primarily in philosophical dialectic with the Vaibhāṣika school of Sarvāstivāda, which had by far the most \"comprehensive edifice of doctrinal systematics\" of the nikāya schools. With this in mind it is sometimes argued that the Theravada would not have been considered a \"Hinayana\" school by Mahayanists because, unlike the now-extinct Sarvastivada school, the primary object of Mahayana criticism, the Theravada school does not claim the existence of independent dharmas; in this it maintains the attitude of early Buddhism. Additionally, the concept of the bodhisattva as one who puts off enlightenment rather than reaching awakening as soon as possible, has no roots in Theravada textual or cultural contexts, current or historical. Aside from the Theravada schools being geographically distant from the Mahayana, the Hinayana distinction is used in reference to certain views and practices that had become found within the Mahayana tradition itself. Theravada, as well as Mahayana schools stress the urgency of one's own awakening in order to end suffering. Some contemporary Theravadin figures have thus indicated a sympathetic stance toward the Mahayana philosophy found in the \"Heart Sutra\" and the \"Mūlamadhyamakakārikā\".\n\nThe Mahayanists were bothered by the substantialist thought of the Sarvāstivādins and Sautrāntikins, and in emphasizing the doctrine of śūnyatā, David Kalupahana holds that they endeavored to preserve the early teaching. The Theravadins too refuted the Sarvāstivādins and Sautrāntikins (and followers of other schools) on the grounds that their theories were in conflict with the non-substantialism of the canon. The Theravada arguments are preserved in the \"Kathavatthu\".\n\nMost western scholars regard the Theravada school to be one of the Hinayana schools referred to in Mahayana literature, or regard Hinayana as a synonym for Theravada. These scholars understand the term to refer to schools of Buddhism that did not accept the teachings of the Mahāyāna sūtras as authentic teachings of the Buddha. At the same time, scholars have objected to the pejorative connotation of the term Hinayana and some scholars do not use it for any school.\n\n\n"}
{"id": "14045", "url": "https://en.wikipedia.org/wiki?curid=14045", "title": "Humphrey Bogart", "text": "Humphrey Bogart\n\nHumphrey DeForest Bogart (; December 25, 1899January 14, 1957) was an American film and stage actor. His performances in numerous films from the Classical Hollywood era made him a cultural icon. In 1999, the American Film Institute ranked him as the greatest male star of American cinema.\n\nBogart began acting in Broadway shows after World War I. After the Wall Street Crash of 1929, he began working in films, mostly playing gangsters. He was highly praised for his work in \"The Petrified Forest\" (1936). Bogart had originated the role of Duke Mantee in the 1935 Broadway production, but Warner Bros. wanted to cast the then much better known Edward G. Robinson for the film adaptation; however Leslie Howard, who played the protagonist in both the play and the film, insisted on Bogart being given the part. His breakthrough came in 1941 when his performances in \"High Sierra\" and \"The Maltese Falcon\" made him a star. His first true romantic lead role came in 1942's \"Casablanca\", breaking his typecasting as a gangster. He and Lauren Bacall starred together in \"To Have and Have Not\" (1944). After they married, she also played his love interest in \"The Big Sleep\" (1946), \"Dark Passage\" (1947) and \"Key Largo\" (1948). His other significant films included \"The African Queen\", \"The Caine Mutiny\", \"Sabrina\" and \"The Barefoot Contessa\". Bogart won the Academy Award for Best Actor for \"The African Queen\", and was nominated for \"Casablanca\" and \"The Caine Mutiny\".\n\nBogart was born on Christmas Day 1899 in New York City, the eldest child of Belmont DeForest Bogart (1867–1934) and Maud Humphrey (1868–1940). Belmont was the only child of the unhappy marriage of Adam Watkins Bogart, a Canandaigua, New York innkeeper, and his wife, Julia, a wealthy heiress. The name \"Bogart\" derives from the Dutch surname \"Bogaert\". Belmont and Maud married in June 1898; he was a Presbyterian, of English and Dutch descent, and she was an Episcopalian of English heritage, and a descendant of \"Mayflower\" passenger John Howland. Young Humphrey was raised in the Episcopal faith, but was non-practicing for most of his adult life.\n\nThe precise date of Bogart's birth was long a matter of dispute, but has been cleared up. Warner Bros. listed his birthdate, throughout his career, but Clifford McCarty maintained that the studio publicity department had altered it from January 23, 1900 \"to foster the view that a man born on Christmas Day couldn't really be as villainous as he appeared to be on screen\". The \"corrected\" January birthdate subsequently appeared—and in some cases, remains—in many otherwise authoritative sources. Biographers Ann M. Sperber and Eric Lax documented, however, that Bogart always celebrated his birthday on December 25, and consistently listed it as such on official records, such as his marriage license.\nLauren Bacall confirmed in her autobiography that his birthday was always celebrated on Christmas Day, adding that he joked that he was cheated out of a present every year because of it. Sperber and Lax also noted that a birth announcement, printed in the \"Ontario County Times\" on January 10, 1900, effectively rules out the possibility of a January 23 birthdate; and state and federal census records from 1900 report a Christmas 1899 birthdate as well.\n\nBogart's father, Belmont, was a cardiopulmonary surgeon. His mother, Maud, was a commercial illustrator who received her art training in New York and France, including study with James Abbott McNeill Whistler. Later, she became art director of the fashion magazine \"The Delineator\" and a militant suffragette. She used a drawing of baby Humphrey in a well-known advertising campaign for Mellins Baby Food. In her prime, she made over $50,000 a year, then a vast sum and far more than her husband's $20,000. The Bogarts lived in a fashionable Upper West Side apartment, and had an elegant cottage on a 55-acre estate on Canandaigua Lake in upstate New York. As a youngster, Humphrey's gang of friends at the lake would put on theatricals.\n\nBogart had two younger sisters, Frances (\"Pat\") and Catherine Elizabeth (\"Kay\"). His parents were busy in their careers and frequently fought. Very formal, they showed little emotion towards their children. Maud told her offspring to call her \"Maud\" not \"Mother\", and showed little if any physical affection for them. When pleased she \"[c]lapped you on the shoulder, almost the way a man does\", Bogart recalled. \"I was brought up very unsentimentally but very straightforwardly. A kiss, in our family, was an event. Our mother and father didn't glug over my two sisters and me.\"\n\nAs a boy, Bogart was teased for his curls, tidiness, the \"cute\" pictures his mother had him pose for, the Little Lord Fauntleroy clothes she dressed him in, and even for the name \"Humphrey\". From his father, Bogart inherited a tendency to needle, fondness for fishing, lifelong love of boating, and an attraction to strong-willed women.\n\nBogart attended the private Delancey School until fifth grade, then the prestigious Trinity School. He was an indifferent, sullen student who showed no interest in after-school activities. Later he went to the equally elite boarding school Phillips Academy, where he was admitted based on family connections. His parents hoped he would go on to Yale, but in 1918 Bogart was expelled. Several reasons have been given: one claims that it was for throwing the headmaster (or a groundskeeper) into Rabbit Pond on campus. Another cites smoking, drinking, poor academic performance, and possibly some inappropriate comments made to the staff. A third has him withdrawn by his father for failing to improve his grades. Whatever caused his premature departure, his parents were deeply dismayed and rued their failed plans for his future.\n\nWith no viable career options, Bogart followed his passion for the sea and enlisted in the United States Navy in the spring of 1918. He recalled later, \"At eighteen, war was great stuff. Paris! Sexy French girls! Hot damn!\" Bogart is recorded as a model sailor who spent most of his sea time after the Armistice ferrying troops back from Europe.\n\nBogart may have received his trademark scar and developed his characteristic lisp during his naval stint, though there are several conflicting stories. By one tale, his lip was cut by shrapnel when his ship, the , was shelled (The ship was never shelled), and it is believed Bogart did not make it to sea until after the Armistice had been signed. Another version, which Bogart's longtime friend, author Nathaniel Benchley, believed, is that Bogart was injured while taking a prisoner to Portsmouth Naval Prison in Kittery, Maine. While changing trains in Boston, the handcuffed prisoner allegedly asked Bogart for a cigarette, then while Bogart looked for a match, the prisoner smashed him across the mouth with the cuffs, cutting Bogart's lip and fleeing. Recaptured, the prisoner was taken to jail. An alternative version has Bogart struck in the mouth by a handcuff loosened while freeing his charge, the other still around the prisoner's wrist. By the time Bogart was treated by a doctor, a scar had already formed. David Niven said that when he first asked Bogart about his scar, he said it was caused by a childhood accident. \"Goddamn doctor\", Bogart later told Niven, \"instead of stitching it up, he screwed it up.\" Niven claims the stories that Bogart got the scar during wartime were made up by the studios to inject glamour. His post-service physical makes no mention of the lip scar, even though it mentions many smaller scars. When actress Louise Brooks met Bogart in 1924, he had some scar tissue on his upper lip, which Brooks said that Bogart may have had partially repaired before entering films in 1930. She also said his \"lip wound gave him no speech impediment, either before or after it was mended.\"\n\nBogart returned home to find his father suffering from poor health, his medical practice faltering, and much of the family's wealth lost on bad investments in timber. During his naval days, Bogart's character and values developed independently of family influence, and he began to rebel somewhat against their values. He came to be a liberal who hated pretensions, phonies, and snobs, and at times defied conventional behavior and authority, traits he displayed in both life and the movies. He did not, however, forsake good manners, articulateness, punctuality, modesty, and a dislike of being touched. After his naval service, he worked as a shipper and then bond salesman. He joined the Coast Guard Reserve.\n\nBogart resumed his friendship with Bill Brady, Jr., whose father had show business connections. Bogart got an office job, working for William A. Brady Sr.'s new company, World Films. Bogart wanted to try his hand at screenwriting, directing and production, but excelled at none. For a while he was stage manager for Brady's daughter Alice's play \"A Ruined Lady\". A few months later he made his stage debut as a Japanese butler in Alice's 1921 play \"Drifting\", nervously speaking one line of dialog. Several appearances followed in her subsequent plays.\n\nWhile Bogart had been raised to believe that acting was beneath a gentleman, he liked the late hours actors kept and enjoyed the attention gotten on stage. He stated, \"I was born to be indolent and this was the softest of rackets.\" He spent a lot of his free time in speakeasies and became a heavy drinker. A barroom brawl during this time joins the list of purported causes of Bogart's lip damage, and coincides better with the Brooks account.\n\nPreferring to learn as he went, Bogart never took acting lessons. He was persistent and worked steadily at his craft, appearing in at least seventeen Broadway productions between 1922 and 1935. He played juveniles or romantic second-leads in drawing room comedies, and is said to have been the first actor to ask \"Tennis, anyone?\" on stage. Critic Alexander Woollcott wrote of Bogart's early work that he \"is what is usually and mercifully described as inadequate.\" Some reviews were kinder.\n\nHeywood Broun, reviewing \"Nerves\" wrote, \"Humphrey Bogart gives the most effective performance ... both dry and fresh, if that be possible\". He played juvenile lead, reporter Gregory Brown, in the comedy \"Meet the Wife\", written by Lynn Starling, which had a successful run of 232 performances at the Klaw Theatre from November 1923 through July 1924. Bogart loathed these trivial, effeminate parts he had to play early in his career, calling them \"White Pants Willie\" roles.\n\nEarly in his career, while playing double roles in the play \"Drifting\" at the Playhouse Theatre in 1922, Bogart met actress Helen Menken. They were married on May 20, 1926, at the Gramercy Park Hotel in New York City. Divorced on November 18, 1927, they remained friends. In the divorce filing, Menken avers that Bogart valued his career more than marital happiness, also citing neglect and abuse. On April 3, 1928, he married Mary Philips, whom he'd met when they appeared in the play \"Nerves\" during its very brief run at the Comedy Theatre in September 1924, at her mother's apartment in Hartford, Connecticut.\n\nAfter the stock market crash of 1929, stage production dropped off sharply, and many of the more photogenic actors headed for Hollywood. Bogart's film debut was with Helen Hayes in the 1928 two-reeler \"The Dancing Town\", of which a complete copy has never been found. He also appeared with Joan Blondell and Ruth Etting in a Vitaphone short, \"Broadway's Like That\" (1930) which was re-discovered in 1963.\n\nBogart then signed a contract with the Fox Film Corporation for $750 a week. There he met Spencer Tracy, a serious Broadway actor whom Bogart liked and admired, and they became close friends and drinking companions. It was Tracy, in 1930, who first called him \"Bogie\". Tracy made his film debut in the only film in which he and Bogart appeared together, John Ford's early sound film \"Up the River\" (1930). Both had major roles as inmates. Tracy received top billing and Bogart's face was featured on the film's posters instead of Tracy's.\n\nBogart then had a minor supporting role in \"Bad Sister\" with Bette Davis in 1931. Decades later, Tracy and Bogart planned to make \"The Desperate Hours\" together, but both sought top billing, so Tracy dropped out and was replaced by Fredric March.\n\nBogart shuttled back and forth between Hollywood and the New York stage from 1930 to 1935, suffering long periods without work. His parents had separated, his father dying in 1934 in debt, which Bogart eventually paid off. Bogart inherited his father's gold ring which he always wore, even in many of his films. At his father's deathbed, Bogart finally told him how much he loved him. His second marriage was on the rocks, and he was less than happy with his acting career. He became depressed, irritable and drank heavily.\n\nIn 1934, Bogart had starred in the Broadway play \"Invitation to a Murder\" at the Theatre Masque, which was renamed the John Golden Theatre in 1937. The producer, Arthur Hopkins, heard the play from off-stage and was interested. He sent for Bogart, and offered him the role of escaped murderer Duke Mantee in Robert E. Sherwood's new play, \"The Petrified Forest\". Hopkins later recalled:\n\nAlthough Leslie Howard was the star, \"New York Times\" critic Brooks Atkinson said of the play, \"a peach ... a roaring Western melodrama ... Humphrey Bogart does the best work of his career as an actor.\" Bogart said that the play \"marked my deliverance from the ranks of the sleek, sybaritic, stiff-shirted, swallow-tailed 'smoothies' to which I seemed condemned to life.\" This, however, did not yet mean he felt secure.\n\nWarner Bros. bought the screen rights to \"The Petrified Forest\". The play seemed perfect for the studio, which was famous for its socially realistic, urban, low-budget action pictures, especially for a public entranced by real-life criminals like John Dillinger (whom Bogart resembled) and Dutch Schultz. Bette Davis and Leslie Howard were cast. Howard, who held production rights, made it clear he wanted Bogart to star with him.\n\nThe studio tested several Hollywood veterans for the Duke Mantee role, and chose Edward G. Robinson, who had first-rank star appeal and was due to make a film to fulfill his expensive contract. Bogart cabled news of this to Howard in Scotland, who replied: \"Att: Jack Warner Insist Bogart Play Mantee No Bogart No Deal L.H.\". When Warner Bros. saw Howard would not budge, they gave in and cast Bogart. Jack Warner wanted Bogart to get his stage name, but Bogart declined it.\n\nThe film version of \"The Petrified Forest\" was released in 1936, and Bogart's performance was called \"brilliant\", \"compelling\", and \"superb\". The film was highly successful, earning $500,000 at the box office, and making Bogart a star. He never forgot Howard's favor, and in 1952 named his only daughter \"Leslie Howard Bogart\" after Howard, who had died in World War II when a civilian plane he was flying in was shot down under mysterious circumstances. Robert E. Sherwood remained a close friend of Bogart's.\n\nDespite his success in \"The Petrified Forest,\" an \"A movie\", Bogart received a tepid twenty-six-week contract at $550 per week and was typecast as a gangster in a series of \"B movie\" crime dramas. Bogart was proud of his success, but the fact that it came from playing a gangster weighed on him. He once said: \"I can't get in a mild discussion without turning it into an argument. There must be something in my tone of voice, or this arrogant face—something that antagonizes everybody. Nobody likes me on sight. I suppose that's why I'm cast as the heavy.\"\n\nHis roles were not only repetitive, but physically demanding and draining (studios were not yet air-conditioned), and his regimented, tightly scheduled job at Warners was anything but the indolent and \"peachy\" actor's life he hoped for. However, he was always professional and generally respected by other actors. He used these \"B movie\" years to start developing his enduring film persona—the wounded, stoical, cynical, charming, vulnerable, self-mocking loner with a code of honor.\n\nIn spite of his success, Warner Bros. had no interest in making Bogart a top star. Shooting on a new film might begin days or only hours after the previous one wrapped. The studio system, then at the most entrenched, restricted actors to their home lot, with only occasional loan-outs. Any actor declining a role could be suspended without pay. Bogart disliked the roles chosen for him, but he worked steadily. Between 1936 and 1940, he averaged a film every two months, at times working on two simultaneously.\n\nAmenities at Warners were few compared to the prestigious Metro-Goldwyn-Mayer. Bogart thought that the Warners wardrobe department was cheap, and often wore his own suits in his movies. In \"High Sierra\", Bogart used his own pet dog Zero to play his character's dog, Pard. His disputes with Warner Bros. over roles and money were similar to those the studio waged with other high-spirited, less-than-obedient stars, such as Bette Davis, James Cagney, Errol Flynn and Olivia de Havilland.\n\nThe leading men ahead of Bogart at Warner Bros. included not only such marquee names as James Cagney and Edward G. Robinson, but also less remembered leads like Victor McLaglen, George Raft and Paul Muni. Most of the studio's better movie scripts went to them, leaving Bogart with what was left. He made films like \"San Quentin\" (1937), \"Racket Busters\" (1938), and \"You Can't Get Away with Murder\" (1939). The only substantial leading role he got during this period was in \"Dead End\" (1937), while loaned to Samuel Goldwyn, where he portrayed a gangster modeled after Baby Face Nelson.\n\nBogart played violent roles so often that in Nevil Shute's 1939 novel \"What Happened to the Corbetts\" the protagonist, when asked whether he knows how to operate an automatic weapon, jokes \"I've seen Humphrey Bogart with one often enough\". He did play a variety of interesting supporting roles, such as in \"Angels with Dirty Faces\" (1938) (in which his character got shot by James Cagney's). Bogart was gunned down on film repeatedly by Cagney and Edward G. Robinson, among others. In \"Black Legion\" (1937), for a change, he played a good man caught up and destroyed by a racist organization, a movie Graham Greene described as \"intelligent and exciting, if rather earnest\".\n\nIn 1938, Warner Bros. put Bogart in a \"hillbilly musical\" called \"Swing Your Lady\" as a wrestling promoter; he later apparently considered this his worst film performance. In 1939, Bogart played a mad scientist in \"The Return of Doctor X\", his only horror film. He cracked, \"If it'd been Jack Warner's blood ... I wouldn't have minded so much. The trouble was they were drinking mine and I was making this stinking movie.\" During this time his wife Mary had a stage hit in \"A Touch of Brimstone\" (1935), and refused to give up her Broadway career to go to Hollywood. After the play closed she relented, but insisted on continuing her career and the couple divorced in 1937.\nOn August 21, 1938, Bogart entered into a turbulent third marriage, with actress Mayo Methot, a lively, friendly woman when sober, but paranoid and physical when drunk. She became convinced Bogart was cheating on her (which he eventually would, with Lauren Bacall, when filming \"To Have and Have Not\" in 1944). The more the two drifted apart, the more she drank, in her fury, throwing plants, crockery and anything close at hand at Bogart. She set their house on fire, stabbed him with a knife, and slashed her wrists on several occasions. Bogart, for his part, needled her, and seemed to enjoy confrontation; he was himself sometimes violent as well. The press accurately dubbed them \"the Battling Bogarts\".\n\n\"The Bogart-Methot marriage was the sequel to the Civil War,\" said their friend Julius Epstein. A wag observed that there was \"madness in his Methot.\" During this time, Bogart bought a motor launch, which he named \"Sluggy,\" his nickname for hot-tempered Methot. Bogart acknowledged that \"I like a jealous wife...We get on so well together (because) we don't have illusions about each other...I wouldn't give you two cents for a dame without a temper.\" Louise Brooks stated, \"except for Leslie Howard, no one contributed as much to Humphrey's success as his third wife, Mayo Methot.\" However, Methot's influence was increasingly destructive, and Bogart's own drinking did not help matters.\n\nBogart had a lifelong disgust for the pretentious, fake or phony. Sensitive yet caustic, he was once again disgusted by the inferior movies he was performing in. He rarely saw his own films and avoided premieres. He even issued phony press releases about his private life to satisfy the curiosity of newspapers and the public. When he thought an actor, director, or a movie studio had done something shoddy, he spoke up about it and was willing to be quoted. He advised Robert Mitchum that the only way to stay alive in Hollywood was to be an \"againster\". As a result, he was not the most popular of actors, and some in the Hollywood community shunned him privately to avoid trouble with the studios. Bogart once said:\n\n\"High Sierra\", a 1941 film directed by Raoul Walsh, had a screenplay written by Bogart's friend and drinking partner, John Huston, adapted from the novel by W. R. Burnett (writer of the novel \"Little Caesar\" was based upon). Both Paul Muni and George Raft turned down the lead role, giving Bogart the opportunity to play a character of some depth, although Walsh initially fought the casting of supporting player Bogart as a leading man, much preferring Raft for the part. The film was Bogart's last major film playing a gangster (only a supporting role in 1942's \"The Big Shot\" followed). Bogart worked well with Ida Lupino, and her relationship with him was close, provoking jealousy from Bogart's wife, Mayo.\n\nThe film cemented a strong personal and professional connection between Bogart and Huston. Bogart admired and somewhat envied Huston for his skill as a writer. Though a poor student, Bogart was a lifelong reader. He could quote Plato, Pope, Ralph Waldo Emerson, and over a thousand lines of Shakespeare. He subscribed to the \"Harvard Law Review\". He admired writers, and some of his best friends were screenwriters, including Louis Bromfield, Nathaniel Benchley, and Nunnally Johnson. Bogart enjoyed intense, provocative conversation and stiff drinks, as did Huston. Both were rebellious and liked to play childish pranks. Huston was reported to be easily bored during production, and admired Bogart (also bored easily off-camera) not just for his acting talent but for his intense concentration on the set.\n\nNow regarded as a classic film noir, \"The Maltese Falcon\" (1941) was John Huston's directorial debut. Based on the novel written by Dashiell Hammett, it was first serialized in the pulp magazine \"Black Mask\" in 1929, and had also served as the basis of two earlier movie versions including \"Satan Met a Lady\" (1936) starring Bette Davis. Producer Hal Wallis initially offered the leading man role to George Raft, a more established box-office name than Bogart, whose contract stipulated he did not have to appear in remakes. Fearing it would be no more than a cleaned-up version of the pre-Production Code \"The Maltese Falcon\" (1931), Raft turned it down in order to make \"Manpower\" with director Raoul Walsh and cast members Edward G. Robinson and Marlene Dietrich. Eagerly, Huston accepted Bogart as his Sam Spade.\n\nComplementing Bogart were co-stars Sydney Greenstreet, Peter Lorre, Elisha Cook, Jr., and Mary Astor as the treacherous female foil. Bogart's sharp timing and facial expressions were praised by the cast and director as vital to the quick action and rapid-fire dialogue. The film was a huge hit in theaters and a major triumph for Huston. Bogart was unusually happy with it, remarking, \"it is practically a masterpiece. I don't have many things I'm proud of ... but that's one\".\n\nBogart gained his first real romantic lead in 1942's \"Casablanca\", playing Rick Blaine, a hard-pressed expatriate nightclub owner hiding from a shady past while negotiating a fine line among Nazis, the French underground, the Vichy prefect and unresolved feelings for his ex-girlfriend. The film was directed by Michael Curtiz and produced by Hal Wallis, and featured Ingrid Bergman, Claude Rains, Sydney Greenstreet, Paul Henreid, Conrad Veidt, Peter Lorre and Dooley Wilson. An avid chess player, Bogart reportedly had the idea that Rick Blaine be portrayed as one, a metaphor for the sparring relationship he maintained with friends, enemies, and tenuous allies. In real life Bogart played tournament level chess one division below master, often enjoying games with crew members and cast, but finding his better in the superior Paul Henreid.\n\nThe on-screen magic of Bogart and Bergman was the result of two actors working at their best, not any real-life sparks, though Bogart's perennially jealous wife assumed otherwise. Off the set, the co-stars hardly spoke. Bergman, who had a reputation for affairs with her leading men, later said of Bogart, \"I kissed him but I never knew him.\" Because Bergman was taller, Bogart had blocks attached to his shoes in certain scenes.\n\n\"Casablanca\" won the 1943 Academy Award for Best Picture. Bogart was nominated for an Academy Award Best Actor in a Leading Role, but lost to Paul Lukas for his performance in \"Watch on the Rhine\". The film vaulted Bogart from fourth place to first in the studio's roster, finally overtaking James Cagney. By 1946 he'd more than doubled his annual salary to over $460,000, making him the highest-paid actor in the world.\n\nDuring 1943 and 1944, Bogart went on the United Service Organizations and War Bond tours accompanied by Methot, enduring arduous travels to Italy and North Africa, including Casablanca.\n\nBogart met Lauren Bacall while filming \"To Have and Have Not\" (1944), a loose adaptation of the Ernest Hemingway novel. The movie has many similarities with \"Casablanca\"—the same enemies, the same kind of hero, even a piano player sidekick (played by Hoagy Carmichael). When they met, Bacall was 19 and Bogart 44. He nicknamed her \"Baby.\" She had been a model since 16 and had acted in two failed plays. Bogart was drawn to Bacall's high cheekbones, green eyes, tawny blond hair, and lean body, as well as her maturity, poise and earthy, outspoken honesty. Reportedly he said, \"I just saw your test. We'll have a lot of fun together\".\n\nTheir physical and emotional rapport was very strong from the start, their age difference and disparity in acting experience allowing the dynamic of a mentor-student relationship to emerge. Quite contrary to Hollywood norm, their affair was Bogart's first with a leading lady. He was still married and his early meetings with Bacall were discreet and brief, their separations bridged by ardent love letters. The relationship made it much easier for the newcomer to make her first film, and Bogart did his best to put her at ease with jokes and quiet coaching. He let her steal scenes and even encouraged it. Howard Hawks, for his part, also did his best to boost her performance and highlight her role, and found Bogart easy to direct.\n\nHawks at some point began to disapprove of the pair. He considered himself Bacall's protector and mentor, and Bogart was usurping that role. Married, and not usually drawn to his starlets, he too fell for Bacall, telling her she meant nothing to Bogart and even threatening to send her to Monogram, the worst studio in Hollywood. Bogart calmed her down and then went after Hawks. Jack Warner settled the dispute and filming resumed. Hawks said of Bacall: \"Bogie fell in love with the character she played, so she had to keep playing it the rest of her life.\"\n\nJust months after wrapping the film, Bogart and Bacall were reunited for an encore, the film noir \"The Big Sleep\", based on the novel by Raymond Chandler, again with script help from William Faulkner. Chandler thoroughly admired Bogart's performance: \"Bogart can be tough without a gun. Also, he has a sense of humor that contains that grating undertone of contempt.\" The film was completed and slated for release in 1945, then withdrawn and substantially re-edited to add new, juiced-up scenes exploiting both the box office chemistry that shone between Bogart and Bacall in \"To Have and Have Not\", and the notoriety of their personal relationship.\n\nAt director Howard Hawks' urging, production partner Charles K. Feldman agreed to Bacall's scenes being re-written to heighten the 'insolent' quality that had intrigued critics and audiences in that film. By chance, a 35-mm nitrate composite master positive (fine grain) of the 1945 version survived. The UCLA Film Archive, in association with Turner Entertainment and with funding provided by Hugh Hefner, restored and released it in 1996.\n\nWhile filming, Bogart was still torn between his new love and his sense of duty to his marriage. The mood on the set was tense, the actors both emotionally exhausted as Bogart tried to find a way out of his dilemma. The dialogue, especially in the newly shot scenes, was full of sexual innuendo supplied by Hawks, and Bogart proves convincing and enduring as private detective Philip Marlowe. In the end, the film was successful, though some critics found the plot confusing and overcomplicated. Reportedly a bemused Chandler himself could not answer baffled screenwriters' question over who killed the limousine driver early in the story.\n\nBogart filed for divorce from Methot in February 1945. He and Bacall married in a small ceremony at the country home of Bogart's close friend, Pulitzer Prize-winning author Louis Bromfield, at Malabar Farm near Lucas, Ohio, on May 21, 1945.\n\nBogart and Bacall moved into a $160,000 ($ in ) white brick mansion in an exclusive neighborhood in Los Angeles's Holmby Hills. The marriage proved a happy one, though there were tensions due to their differences. Bogart's drinking sometimes inflamed tensions. He was a homebody and she liked nightlife; he loved the sea, which made her seasick.\n\nIn California in 1945, Bogart bought a sailing yacht, the \"Santana\", from actor Dick Powell. He found the sea a sanctuary, spending about thirty weekends a year on the water, with a particular fondness for sailing around Catalina Island. He once said, \"An actor needs something to stabilize his personality, something to nail down what he really is, not what he is currently pretending to be.\" He also joined the Coast Guard Temporary Reserve offering the use of his own yacht, Santana, for Coast Guard use. It was rumored Bogart attempted to enlist but was turned down because of his age.\n\nThe suspenseful \"Dark Passage\" (1947) was Bogart and Bacall's next pairing. Its first third is shot subjectively, that is from the point-of-view of Bogart's protagonist, with the camera seeing what his character sees. After his plastic surgery, the rest of the film is shot in the usual manner. Bogart is intent on finding the real murderer in a crime for which he was blamed and sentenced to prison.\n\nThe couple next starred in \"Key Largo\" (1948). Directed by John Huston, the film highlighted Edward G. Robinson as gangster \"Johnny Rocco,\" a seething older synthesis of many of his vicious early bad guy roles. The characters are trapped during a spectacular hurricane in a hotel owned by Bacall's screen father-in-law, played by Lionel Barrymore. Claire Trevor won an Academy Award for Best Supporting Actress for her heart-wrenching performance as Rocco's physically abused alcoholic girlfriend.\n\nThough Robinson had always had top billing over Bogart in their previous films together, this time Robinson's name appears to the right of Bogart's, but placed a little higher on the posters and in the film's opening credits, to signify Robinson's near-equal status. Robinson's image was also markedly larger and centered on the original poster, with Bogart relegated to the background. In the film's trailer, Bogart is repeatedly mentioned first, but Robinson's name is listed above Bogart's in a cast list at the trailer's end.\n\nThe enormous success of \"Casablanca\" redefined Bogart's career. For the first time, Bogart could be cast successfully as both a tough, strong man and vulnerable love interest. Despite his elevated standing, he did not yet have a contractual right of script refusal. When he got weak scripts he simply dug in his heels and locked horns again with the front office, as he did on the film \"Conflict\" (1945). Though he submitted to Jack Warner and played the lead, he successfully turned down \"God is My Co-Pilot\" (1945).\n\nRiding high in 1947 with a new contract which provided limited script refusal and the right to form his own production company, Bogart reunited with John Huston for \"The Treasure of the Sierra Madre\", a stark tale of greed played out by three gold prospectors in Mexico. Without either a love interest or happy ending it was deemed a risky project. Bogart later said of co-star (and John Huston's father) Walter Huston, \"He's probably the only performer in Hollywood to whom I'd gladly lose a scene\".\n\nThe film was shot in the heat of summer for greater realism and atmosphere, proving grueling to make. James Agee wrote, \"Bogart does a wonderful job with this character ... miles ahead of the very good work he has done before\". John Huston won the Academy Award for Best Director and screenplay and his father won Best Supporting Actor, but the film had mediocre box office results. Bogart complained, \"An intelligent script, beautifully directed—something different—and the public turned a cold shoulder on it\".\n\nBogart, a liberal Democrat, organized a delegation to Washington, D.C., called the Committee for the First Amendment, against what he perceived to be the House Un-American Activities Committee's harassment of Hollywood screenwriters and actors. He subsequently wrote an article \"I'm No Communist\" in the March 1948 edition of \"Photoplay\" magazine in which he distanced himself from The Hollywood Ten to counter the negative publicity resulting from his appearance. Bogart wrote: \"The ten men cited for contempt by the House Un-American Activities Committee were not defended by us.\"\n\nIn 1948, Bogart created his film company, Santana Productions (named after his yacht with the cabin cruiser in \"Key Largo\"). Earning the right to create his own company had left Jack Warner furious, and afraid other stars would do the same and further erode the major studios' power. In addition to the pressure they were bearing from freelancing actors like Bogart, James Stewart, Henry Fonda and others, they were beginning to buckle from the eroding impact of television and enforcement of anti-trust laws breaking up theater chains. Bogart performed in his final films for Warners, \"Chain Lightning\" (1950) and \"The Enforcer\" (1951).\n\nExcept for \"Beat the Devil\" (1953), originally distributed in the United States by United Artists, the company released its films through Columbia Pictures, though Columbia re-released \"Beat the Devil\" a decade later. Without letting up, Bogart starred in \"Knock on Any Door\" (1949), \"Tokyo Joe\" (1949), \"In a Lonely Place\" (1950), and \"Sirocco\" (1951). Santana made two other films without him: \"And Baby Makes Three\" (1949) and \"The Family Secret\" (1951).\n\nWhile the majority lost money at the box office, ultimately forcing Santana's sale, at least two are well remembered today: \"In a Lonely Place\" is considered by many a high point in film noir. Bogart plays embittered writer Dixon Steele, whose history of violence lands him as top suspect in a murder case. At the same time he falls in love with an alluring but failed actress played by Gloria Grahame. It is considered among his best performances, and many Bogart biographers and actress/writer Louise Brooks feel the role is the closest to the real Bogart of any he played. She wrote that the film \"gave him a role that he could play with complexity, because the film character's pride in his art, his selfishness, drunkenness, lack of energy stabbed with lightning strokes of violence were shared by the real Bogart\". The character even mimics some of Bogart's personal habits, including twice ordering Bogart's favorite meal of ham and eggs.\n\nSomething of a parody of \"The Maltese Falcon\", \"Beat the Devil\" was their final film for Bogart and John Huston. Co-written by Truman Capote, the eccentrically filmed tale follows an amoral group of rogues chasing an unattainable treasure. Bogart sold his interest in Santana to Columbia for over $1 million in 1955.\n\nWorking outside of his own Santana Productions, Bogart starred with Katharine Hepburn in the John Huston directed \"The African Queen\" in 1951. The C.S. Forester novel on which it was based was overlooked and left undeveloped for fifteen years until producer Sam Spiegel and Huston bought the rights. Spiegel sent Katharine Hepburn the book and she suggested Bogart for the male lead, firmly believing that \"he was the only man who could have played that part\". Huston's love of adventure, deep, longstanding friendship–and success–with Bogart, and a chance to work with Hepburn, convinced the actor to leave the comfortable confines of Hollywood for a difficult shoot on location in the Belgian Congo in Africa. Bogart was to get 30% of the profits and Hepburn 10%, plus a relatively small salary for both. The stars met up in London and announced the happy prospect of working together.\n\nBacall came for the four-month-plus duration, leaving their young child to be cared for in Los Angeles. The Bogarts started the trip with a junket through Europe, including a visit with Pope Pius XII. Later, the glamor would be gone and Bacall would make herself useful as a cook, nurse and clothes washer, earning her husband's praise: \"I don't know what we'd have done without her. She Luxed my undies in darkest Africa\". Just about everyone in the cast came down with dysentery except Bogart and Huston, who subsisted on canned food and alcohol. Bogart explained: \"All I ate was baked beans, canned asparagus and Scotch whisky. Whenever a fly bit Huston or me, it dropped dead.\" Hepburn, a teetotaler in and out of character, fared worse in the difficult conditions, losing weight and at one point falling very ill. Bogart resisted Huston's insistence on using real leeches in a key scene where Charlie has to drag his steam launch through an infested marsh, until reasonable fakes were employed. In the end, the crew overcame illness, soldier ant invasions, leaking boats, poor food, attacking hippos, poor water filters, fierce heat, isolation, and a boat fire to complete a memorable film. Despite the discomfort of jumping from the boat into swamps, rivers and marshes the film apparently rekindled Bogart's early love of boats. On his return to California he bought a classic mahogany Hacker-Craft runabout, which he kept until his death.\n\nThe role of cantankerous skipper Charlie Allnutt won Bogart his only Academy Award in three nominations, for Best Actor in a Leading Role in 1951. Bogart considered his performance to be the best of his film career. He had vowed to friends that if he won, his speech would break the convention of thanking everyone in sight. He advised Claire Trevor, when she had been nominated for \"Key Largo\", to \"just say you did it all yourself and don't thank anyone\". But when Bogart won the Academy Award, which he truly coveted despite his well-advertised disdain for Hollywood, he said \"It's a long way from the Belgian Congo to the stage of this theatre. It's nicer to be here. Thank you very much ... No one does it alone. As in tennis, you need a good opponent or partner to bring out the best in you. John and Katie helped me to be where I am now\". Despite the thrilling win and the recognition, Bogart later commented, \"The way to survive an Oscar is never to try to win another one ... too many stars ... win it and then figure they have to top themselves ... they become afraid to take chances. The result: A lot of dull performances in dull pictures\". \"The African Queen\" was the first Technicolor film to star Bogart.\n\nBogart dropped his asking price to get the role of Captain Queeg in Edward Dmytryk's 1954 drama \"The Caine Mutiny\". Though he griped with some of his old bitterness about having to do so, he delivered a strong performance in the lead, earning him his final Oscar nomination as well as being the subject of the cover story in the June 7, 1954 issue of \"TIME\". Yet for all his success, Bogart was still his melancholy old self, grumbling and feuding with the studio, while his health was beginning to deteriorate. The character of Queeg mirrored in some ways those Bogart had played in \"The Maltese Falcon\", \"Casablanca\" and \"The Big Sleep\"–the wary loner who trusts no one—but without either the warmth or humor of those roles. Like his portrayal of Fred C. Dobbs in \"The Treasure of the Sierra Madre\", Bogart played a paranoid, self-pitying character whose small-mindedness eventually destroyed him. Three months before the film's release, Bogart appeared as Queeg on the cover of \"TIME\" magazine, while on Broadway Henry Fonda was starring in the stage version (in a different role), both of which generated strong publicity for the film.\nIn \"Sabrina\", Billy Wilder wished to cast Cary Grant as the older male lead. However, he chose Bogart to play the elder, conservative brother who competes with his younger playboy sibling (William Holden) for the affection of the Cinderella-like Sabrina (Audrey Hepburn). Bogart was lukewarm about the part, but agreed to it on a handshake with Wilder, sans finished script but with the director's assurances he would take good care of Bogart during the filming. Nevertheless, Bogart got on poorly with his director and co-stars. He complained about the script and its last-minute drafting and delivery, and accused Wilder of favoring Hepburn and Holden on and off the set. At the root was Wilder being the opposite of Bogart's ideal director, John Huston, in both style and personality. Bogart groused to the press that Wilder was \"overbearing\" and \"is the kind of Prussian German with a riding crop. He is the type of director I don't like to work with ... the picture is a crock of crap. I got sick and tired of who gets Sabrina.\" Wilder later claimed, \"We parted as enemies but finally made up.\" Despite the acrimony, the film was successful. \"The New York Times\" crowed that Bogart was \"incredibly adroit ... the skill with which this old rock-ribbed actor blends the gags and such duplicities with a manly manner of melting is one of the incalculable joys of the show.\"\n\nJoseph L. Mankiewicz's 1954 film, \"The Barefoot Contessa\", was filmed in Rome. In this Hollywood back-story Bogart is again a broken-down man, the cynical director-narrator who saves his career by making a star of a flamenco dancer modeled on real life film sex goddess Rita Hayworth. Bogart was uneasy with Ava Gardner in the female lead, as she had just split from close \"Rat Pack\" buddy Frank Sinatra and was carrying on an affair with bullfighter Luis Miguel Dominguín. Bogart told her, \"Half the world's female population would throw themselves at Frank's feet and here you are flouncing around with guys who wear capes and little ballerina slippers.\" He was also annoyed by her inexperienced performance. Later, Gardner credited Bogart with helping her both on and offscreen. Bogart's performance was generally praised as the strongest part of the film. During the filming, while Bacall was home, Bogart resumed his discreet affair with Verita Bouvaire-Thompson, his long-time studio assistant, whom he took sailing and enjoyed drinking with. When his wife suddenly arrived on the scene discovering them together, she took it quite well, extracting an expensive shopping spree from her husband, the three traveling together after the shooting.\n\nBogart could be generous with actors, particularly those who were blacklisted, down on their luck, or having personal problems. During the filming of the Edward Dmytryk directed \"The Left Hand of God\" (1955), he noticed his co-star Gene Tierney having a hard time remembering her lines and behaving oddly. He coached Tierney, feeding her lines. He was familiar with mental illness from his sister's bouts of depression, and encouraged Tierney to seek treatment. He also stood behind Joan Bennett and insisted on her as his co-star in Michael Curtiz's \"We're No Angels\" (also 1955) when an ugly public scandal made her persona non grata with Jack Warner.\n\nWhile Bogart rarely performed on television, he and Bacall appeared on Edward R. Murrow's \"Person to Person\" in which they disagreed in answering every question. Bogart was also featured on \"The Jack Benny Show\". The surviving kinescope of the live telecast captures him in his only TV sketch comedy outing. Bogart and Bacall worked together on an early color telecast in 1955, an NBC adaptation of \"The Petrified Forest\" for \"Producers' Showcase\", with Bogart receiving top billing and Henry Fonda playing Leslie Howard's role; a black and white kinescope of the live telecast has also survived. Bogart performed radio adaptations of some of his best known films, such as \"Casablanca\" and \"The Maltese Falcon\". He also recorded a radio series called \"Bold Venture\" with Bacall. In 1995, newly developed digital technology allowed Bogart's image to be inserted in the \"Tales from the Crypt\" television episode \"You, Murderer\" as one of its many \"Casablanca\" references. The \"Ingrid Bergman\" character was played by her daughter Isabella Rossellini.\n\nBogart became a first-time father at age 49 when Bacall gave birth to Stephen Humphrey Bogart on January 6, 1949, during the filming of \"Tokyo Joe\". The name was drawn from Bogart's character's nickname in \"To Have and Have Not\", \"Steve\". Stephen later became an author and biographer, and hosted a television special about his father on Turner Classic Movies. The couple's daughter, Leslie Howard Bogart, was born on August 23, 1952 gaining her forenames from British actor Leslie Howard, Bogart's friend and co-star in \"The Petrified Forest\".\n\nBogart was a founding member and the original leader of the so-called Hollywood Rat Pack. In the spring of 1955, after a long party in Las Vegas attended by Frank Sinatra, Judy Garland, her husband Sidney Luft, Michael Romanoff and wife Gloria, David Niven, Angie Dickinson and others, Bacall surveyed the wreckage and declared, \"You look like a goddamn rat pack.\"\n\nThe name stuck and was made official at Romanoff's in Beverly Hills. Sinatra was tabbed Pack Leader; Bacall, Den Mother; Bogie, Director of Public Relations; and Sid Luft, Acting Cage Manager. When asked by columnist Earl Wilson what the group's purpose was, Bacall stated: \"To drink a lot of bourbon and stay up late.\"\n\nAfter signing a long-term deal with Warner Bros., Bogart predicted with glee that his teeth and hair would fall out before the contract ended. In 1955, though he was well established as an independent producer, his health was failing. In the wake of Santana, Bogart had formed a new company and had eager plans for a film, \"Melville Goodwin, U.S.A.\", in which he would play a general, and Bacall a press magnate. However, his persistent cough and difficulty eating became too serious to ignore, and he dropped the project.\n\nA heavy smoker and drinker, Bogart developed esophageal cancer. He did not speak of his health and visited a doctor in January 1956, after much persistence from Bacall. The disease worsened several weeks later. On March 1, 1956, he underwent a surgical operation in which his entire esophagus, two lymph nodes and a rib were removed. However, the surgery failed, even with chemotherapy. Bogart underwent corrective surgery in November 1956, when the cancer had spread. With time, he grew too weak to walk up and down stairs, fighting the pain yet still able to joke: \"Put me in the dumbwaiter and I'll ride down to the first floor in style.\" It was then altered to accommodate his wheelchair. Sinatra, Katharine Hepburn and Spencer Tracy visited Bogart on January 13, 1957. In an interview, Hepburn said:\n\nBogart fell into a coma and died on the next day. He had just turned 57 twenty days prior and weighed only . His simple funeral was held at All Saints Episcopal Church, with musical selections from favorite composers Johann Sebastian Bach and Claude Debussy. The ceremony was attended by some of Hollywood's biggest stars, including Hepburn, Tracy, Judy Garland, David Niven, Ronald Reagan, James Mason, Bette Davis, Danny Kaye, Joan Fontaine, Marlene Dietrich, James Cagney, Errol Flynn, Gregory Peck, Gary Cooper, Billy Wilder and Jack Warner. Bacall asked Tracy to give the eulogy, but he was too upset, so John Huston spoke instead. He reminded the gathered mourners about Bogart:\n\nBogart's cremated remains were interred in Forest Lawn Memorial Park Cemetery, Glendale, California, in the Garden of Memory, Columbarium of Eternal Light. He was buried with a small, gold whistle once part of a charm bracelet he had given to Lauren Bacall before they had married. On it was inscribed an allusion to a line from the film \"To Have and Have Not\", which Bacall had said to him shortly after their first meeting: \"You know how to whistle, don't you, Steve? You just put your lips together and blow\". The inscription read: \"If you want anything, just whistle.\"\n\nThe probate value of Bogart's estate was $910,146 gross and $737,668 net ($ million and $ million in , respectively).\n\nOn August 21, 1946, Bogart was honored in a ceremony at Grauman's Chinese Theater to record his hand and footprints in cement. On February 8, 1960, he was posthumously inducted into the Hollywood Walk of Fame with a motion pictures star located at 6322 Hollywood Boulevard. Bogart was nominated for several awards, including the BAFTA award for Best Foreign Actor in 1952 for \"The African Queen\" and three Academy Awards.\n\nAfter his death, a \"Bogie Cult\" formed at the Brattle Theatre in Cambridge, Massachusetts, as well as Greenwich Village, Manhattan, New York, and in France, which contributed to his spike in popularity in the late 1950s and 1960s. In 1997, \"Entertainment Weekly\" magazine named Bogart the number one movie legend of all time. In 1999, the American Film Institute ranked him the greatest male screen legend.\n\nJean-Luc Godard's \"Breathless\" (1960) was the first film to pay tribute to Bogart. Later, in Woody Allen's comic paean to Bogart, \"Play It Again, Sam\" (1972), Bogart's ghost comes to the aid of Allen's bumbling character, a movie critic with women troubles whose \"sex life has turned into the 'Petrified Forest'\".\n\nIn 1997, the United States Postal Service honored Bogart with a stamp bearing his image in its \"Legends of Hollywood\" series as the third figure to be recognized. At a formal ceremony attended by Lauren Bacall, and the Bogart children, Stephen and Leslie, Tirso del Junco, the chairman of the governing board of the USPS, provided an eloquent tribute:\n\n\"Today, we mark another chapter in the Bogart legacy. With an image that is small and yet as powerful as the ones he left in celluloid, we will begin today to bring his artistry, his power, his unique star quality, to the messages that travel the world.\"\n\nOn June 24, 2006, a section of 103rd Street, between Broadway and West End Avenue, in New York City was renamed \"Humphrey Bogart Place.\" Lauren Bacall and her son Stephen Bogart were present at the commemorative event. \"Bogie would never have believed it,\" Lauren Bacall expressed to the assembled group of city officials and onlookers in attendance.\n\nBogart's appearance has inspired writers and others:\n\n\n"}
{"id": "14051", "url": "https://en.wikipedia.org/wiki?curid=14051", "title": "History painting", "text": "History painting\n\nHistory painting is a genre in painting defined by its subject matter rather than artistic style. History paintings usually depict a moment in a narrative story, rather than a specific and static subject, as in a portrait. The term is derived from the wider senses of the word \"historia\" in Latin and Italian, meaning \"story\" or \"narrative\", and essentially means \"story painting\". Most history paintings are not of scenes from history, especially paintings from before about 1850.\n\nIn modern English, historical painting is sometimes used to describe the painting of scenes from history in its narrower sense, especially for 19th-century art, excluding religious, mythological and allegorical subjects, which are included in the broader term history painting, and before the 19th century were the most common subjects for history paintings.\n\nHistory paintings almost always contain a number of figures, often a large number, and normally show some type of action that is a moment in a narrative. The genre includes depictions of moments in religious narratives, above all the \"Life of Christ\", as well as narrative scenes from mythology, and also allegorical scenes. These groups were for long the most frequently painted; works such as Michelangelo's Sistine Chapel ceiling are therefore history paintings, as are most very large paintings before the 19th century. The term covers large paintings in oil on canvas or fresco produced between the Renaissance and the late 19th century, after which the term is generally not used even for the many works that still meet the basic definition.\n\nHistory painting may be used interchangeably with historical painting, and was especially so used before the 20th century. Where a distinction is made \"historical painting\" is the painting of scenes from secular history, whether specific episodes or generalized scenes. In the 19th century historical painting in this sense became a distinct genre. In phrases such as \"historical painting materials\", \"historical\" means in use before about 1900, or some earlier date.\n\nHistory paintings were traditionally regarded as the highest form of Western painting, occupying the most prestigious place in the hierarchy of genres, and considered the equivalent to the epic in literature. In his \"De Pictura\" of 1436, Leon Battista Alberti had argued that multi-figure history painting was the noblest form of art, as being the most difficult, which required mastery of all the others, because it was a visual form of history, and because it had the greatest potential to move the viewer. He placed emphasis on the ability to depict the interactions between the figures by gesture and expression.\n\nThis view remained general until the 19th century, when artistic movements began to struggle against the establishment institutions of academic art, which continued to adhere to it. At the same time there was from the latter part of the 18th century an increased interest in depicting in the form of history painting moments of drama from recent or contemporary history, which had long largely been confined to battle-scenes and scenes of formal surrenders and the like. Scenes from ancient history had been popular in the early Renaissance, and once again became common in the Baroque and Rococo periods, and still more so with the rise of Neoclassicism. In some 19th or 20th century contexts, the term may refer specifically to paintings of scenes from secular history, rather than those from religious narratives, literature or mythology.\n\nThe term is generally not used in art history in speaking of medieval painting, although the Western tradition was developing in large altarpieces, fresco cycles, and other works, as well as miniatures in illuminated manuscripts. It comes to the fore in Italian Renaissance painting, where a series of increasingly ambitious works were produced, many still religious, but several, especially in Florence, which did actually feature near-contemporary historical scenes such as the set of three huge canvases on \"The Battle of San Romano\" by Paolo Uccello, the abortive \"Battle of Cascina\" by Michelangelo and the \"Battle of Anghiari\" by Leonardo da Vinci, neither of which were completed. Scenes from ancient history and mythology were also popular. Writers such as Alberti and the following century Giorgio Vasari in his \"Lives of the Artists\", followed public and artistic opinion in judging the best painters above all on their production of large works of history painting (though in fact the only modern (post-classical) work described in \"De Pictura\" is Giotto's huge \"Navicella\" in mosaic). Artists continued for centuries to strive to make their reputation by producing such works, often neglecting genres to which their talents were better suited.\n\nThere was some objection to the term, as many writers preferred terms such as \"poetic painting\" (\"poesia\"), or wanted to make a distinction between the \"true\" \"istoria\", covering history including biblical and religious scenes, and the \"fabula\", covering pagan myth, allegory, and scenes from fiction, which could not be regarded as true. The large works of Raphael were long considered, with those of Michelangelo, as the finest models for the genre.\n\nIn the Raphael Rooms in the Vatican Palace, allegories and historical scenes are mixed together, and the Raphael Cartoons show scenes from the Gospels, all in the Grand Manner that from the High Renaissance became associated with, and often expected in, history painting. In the Late Renaissance and Baroque the painting of actual history tended to degenerate into panoramic battle-scenes with the victorious monarch or general perched on a horse accompanied with his retinue, or formal scenes of ceremonies, although some artists managed to make a masterpiece from such unpromising material, as Velázquez did with his \"The Surrender of Breda\".\n\nAn influential formulation of the hierarchy of genres, confirming the history painting at the top, was made in 1667 by André Félibien, a historiographer, architect and theoretician of French classicism became the classic statement of the theory for the 18th century:Celui qui fait parfaitement des païsages est au-dessus d'un autre qui ne fait que des fruits, des fleurs ou des coquilles. Celui qui peint des animaux vivants est plus estimable que ceux qui ne représentent que des choses mortes & sans mouvement ; & comme la figure de l'homme est le plus parfait ouvrage de Dieu sur la Terre, il est certain aussi que celui qui se rend l'imitateur de Dieu en peignant des figures humaines, est beaucoup plus excellent que tous les autres ... un Peintre qui ne fait que des portraits, n'a pas encore cette haute perfection de l'Art, & ne peut prétendre à l'honneur que reçoivent les plus sçavans. Il faut pour cela passer d'une seule figure à la représentation de plusieurs ensemble ; il faut traiter l'histoire & la fable ; il faut représenter de grandes actions comme les historiens, ou des sujets agréables comme les Poëtes ; & montant encore plus haut, il faut par des compositions allégoriques, sçavoir couvrir sous le voile de la fable les vertus des grands hommes, & les mystères les plus relevez.\n\nHe who produces perfect landscapes is above another who only produces fruit, flowers or seashells. He who paints living animals is more than those who only represent dead things without movement, and as man is the most perfect work of God on the earth, it is also certain that he who becomes an imitator of God in representing human figures, is much more excellent than all the others ... a painter who only does portraits still does not have the highest perfection of his art, and cannot expect the honour due to the most skilled. For that he must pass from representing a single figure to several together; history and myth must be depicted; great events must be represented as by historians, or like the poets, subjects that will please, and climbing still higher, he must have the skill to cover under the veil of myth the virtues of great men in allegories, and the mysteries they reveal\".\n\nBy the late 18th century, with both religious and mytholological painting in decline, there was an increased demand for paintings of scenes from history, including contemporary history. This was in part driven by the changing audience for ambitious paintings, which now increasingly made their reputation in public exhibitions rather than by impressing the owners of and visitors to palaces and public buildings. Classical history remained popular, but scenes from national histories were often the best-received. From 1760 onwards, the Society of Artists of Great Britain, the first body to organize regular exhibitions in London, awarded two generous prizes each year to paintings of subjects from British history. \nThe unheroic nature of modern dress was regarded as a serious difficulty. When, in 1770, Benjamin West proposed to paint \"The Death of General Wolfe\" in contemporary dress, he was firmly instructed to use classical costume by many people. He ignored these comments and showed the scene in modern dress. Although George III refused to purchase the work, West succeeded both in overcoming his critics' objections and inaugurating a more historically accurate style in such paintings. Other artists depicted scenes, regardless of when they occurred, in classical dress and for a long time, especially during the French Revolution, history painting often focused on depictions of the heroic male nude.\n\nThe large production, using the finest French artists, of propaganda paintings glorifying the exploits of Napoleon, were matched by works, showing both victories and losses, from the anti-Napoleonic alliance by artists such as Goya and J.M.W. Turner. Théodore Géricault's \"The Raft of the Medusa\" (1818–1819) was a sensation, appearing to update the history painting for the 19th century, and showing anonymous figures famous only for being victims of what was then a famous and controversial disaster at sea. Conveniently their clothes had been worn away to classical-seeming rags by the point the painting depicts. At the same time the demand for traditional large religious history paintings very largely fell away.\nIn the mid-nineteenth century there arose a style known as historicism, which marked a formal imitation of historical styles and/or artists. Another development in the nineteenth century was the treatment of historical subjects, often on a large scale, with the values of genre painting, the depiction of scenes of everyday life, and anecdote. Grand depictions of events of great public importance were supplemented with scenes depicting more personal incidents in the lives of the great, or of scenes centred on unnamed figures involved in historical events, as in the Troubadour style. At the same time scenes of ordinary life with moral, political or satirical content became often the main vehicle for expressive interplay between figures in painting, whether given a modern or historical setting.\n\nBy the later 19th century, history painting was often explicitly rejected by avant-garde movements such as the Impressionists (except for Édouard Manet) and the Symbolists, and according to one recent writer \"Modernism was to a considerable extent built upon the rejection of History Painting... All other genres are deemed capable of entering, in one form or another, the 'pantheon' of modernity considered, but History Painting is excluded\".\n\nInitially, \"history painting\" and \"historical painting\" were used interchangeably in English, as when Sir Joshua Reynolds in his fourth \"Discourse\" uses both indiscriminately to cover \"history painting\", while saying \"...it ought to be called poetical, as in reality it is\", reflecting the French term \"peinture historique\", one equivalent of \"history painting\". The terms began to separate in the 19th century, with \"historical painting\" becoming a sub-group of \"history painting\" restricted to subjects taken from history in its normal sense. In 1853 John Ruskin asked his audience: \"What do you at present \"mean\" by historical painting? Now-a-days it means the endeavour, by the power of imagination, to portray some historical event of past days.\" So for example Harold Wethey's three-volume catalogue of the paintings of Titian (Phaidon, 1969–75) is divided between \"Religious Paintings\", \"Portraits\", and \"Mythological and Historical Paintings\", though both volumes I and III cover what is included in the term \"History Paintings\". This distinction is useful but is by no means generally observed, and the terms are still often used in a confusing manner. Because of the potential for confusion modern academic writing tends to avoid the phrase \"historical painting\", talking instead of \"historical subject matter\" in history painting, but where the phrase is still used in contemporary scholarship it will normally mean the painting of subjects from history, very often in the 19th century. \"Historical painting\" may also be used, especially in discussion of painting techniques in conservation studies, to mean \"old\", as opposed to modern or recent painting.\n\nIn 19th-century British writing on art the terms \"subject painting\" or \"anecdotic\" painting were often used for works in a line of development going back to William Hogarth of monoscenic depictions of crucial moments in an implied narrative with unidentified characters, such as William Holman Hunt's 1853 painting \"The Awakening Conscience\" or Augustus Egg's \"Past and Present\", a set of three paintings, updating sets by Hogarth such as \"Marriage à-la-mode\".\n\nHistory painting was the dominant form of academic painting in the various national academies in the 18th century, and for most of the 19th, and increasingly historical subjects dominated. During the Revolutionary and Napoleonic periods the heroic treatment of contemporary history in a frankly propagandistic fashion by Antoine-Jean, Baron Gros, Jacques-Louis David, Carle Vernet and others was supported by the French state, but after the fall of Napoleon in 1815 the French governments were not regarded as suitable for heroic treatment and many artists retreated further into the past to find subjects, though in Britain depicting the victories of the Napoleonic Wars mostly occurred after they were over. Another path was to choose contemporary subjects that were oppositional to government either at home and abroad, and many of what were arguably the last great generation of history paintings were protests at contemporary episodes of repression or outrages at home or abroad: Goya's \"The Third of May 1808\" (1814), Théodore Géricault's \"The Raft of the Medusa\" (1818–19), Eugène Delacroix's \"The Massacre at Chios\" (1824) and \"Liberty Leading the People\" (1830). These were heroic, but showed heroic suffering by ordinary civilians.\nRomantic artists such as Géricault and Delacroix, and those from other movements such as the English Pre-Raphaelite Brotherhood continued to regard history painting as the ideal for their most ambitious works. Others such as Jan Matejko in Poland, Vasily Surikov in Russia, José Moreno Carbonero in Spain and Paul Delaroche in France became specialized painters of large historical subjects. The \"style troubadour\" (\"troubadour style\") was a somewhat derisive French term for earlier paintings of medieval and Renaissance scenes, which were often small and depicting moments of anecdote rather than drama; Ingres, Richard Parkes Bonington and Henri Fradelle painted such works. Sir Roy Strong calls this type of work the \"Intimate Romantic\", and in French it was known as the \"peinture de genre historique\" or \"peinture anecdotique\" (\"historical genre painting\" or \"anecdotal painting\").\n\nChurch commissions for large group scenes from the Bible had greatly reduced, and historical painting became very significant. Especially in the early 19th century, much historical painting depicted specific moments from historical literature, with the novels of Sir Walter Scott a particular favourite, in France and other European countries as much as Great Britain. By the middle of the century medieval scenes were expected to be very carefully researched, using the work of historians of costume, architecture and all elements of decor that were becoming available. And example of this is the extensive research of Byzantine architecture, clothing and decoration made in Parisian museums and libraries by Moreno Carbonero for his masterwork \"The Entry of Roger de Flor in Constantinople\". The provision of examples and expertise for artists, as well as revivalist industrial designers, was one of the motivations for the establishment of museums like the Victoria and Albert Museum in London. New techniques of printmaking such as the chromolithograph made good quality monochrome print reproductions both relatively cheap and very widely accessible, and also hugely profitable for artist and publisher, as the sales were so large. Historical painting often had a close relationship with Nationalism, and painters like Matejko in Poland could play an important role in fixing the prevailing historical narrative of national history in the popular mind. In France, \"L'art Pompier\" (\"Fireman art\") was a derisory term for official academic historical painting, and in a final phase, \"History painting of a debased sort, scenes of brutality and terror, purporting to illustrate episodes from Roman and Moorish history, were Salon sensations. On the overcrowded walls of the exhibition galleries, the paintings that shouted loudest got the attention\". Orientalist painting was an alternative genre that offered similar exotic costumes and decor, and at least as much opportunity to depict sex and violence.\n\n\n\n"}
{"id": "14052", "url": "https://en.wikipedia.org/wiki?curid=14052", "title": "Hyperbola", "text": "Hyperbola\n\nIn mathematics, a hyperbola (plural \"hyperbolas\" or \"hyperbolae\") is a type of smooth curve lying in a plane, defined by its geometric properties or by equations for which it is the solution set. A hyperbola has two pieces, called connected components or branches, that are mirror images of each other and resemble two infinite bows. The hyperbola is one of the three kinds of conic section, formed by the intersection of a plane and a double cone. (The other conic sections are the parabola and the ellipse. A circle is a special case of an ellipse.) If the plane intersects both halves of the double cone but does not pass through the apex of the cones, then the conic is a hyperbola.\n\nHyperbolas arise in many ways: \nand so on.\n\nEach branch of the hyperbola has two arms which become straighter (lower curvature) further out from the center of the hyperbola. Diagonally opposite arms, one from each branch, tend in the limit to a common line, called the asymptote of those two arms. So there are two asymptotes, whose intersection is at the center of symmetry of the hyperbola, which can be thought of as the mirror point about which each branch reflects to form the other branch. In the case of the curve formula_1 the asymptotes are the two coordinate axes.\n\nHyperbolas share many of the ellipses' analytical properties such as eccentricity, focus, and directrix. Typically the correspondence can be made with nothing more than a change of sign in some term. Many other mathematical objects have their origin in the hyperbola, such as hyperbolic paraboloids (saddle surfaces), hyperboloids (\"wastebaskets\"), hyperbolic geometry (Lobachevsky's celebrated non-Euclidean geometry), hyperbolic functions (sinh, cosh, tanh, etc.), and gyrovector spaces (a geometry proposed for use in both relativity and quantum mechanics which is not Euclidean).\n\nThe word \"hyperbola\" derives from the Greek , meaning \"over-thrown\" or \"excessive\", from which the English term hyperbole also derives. Hyperbolae were discovered by Menaechmus in his investigations of the problem of doubling the cube, but were then called sections of obtuse cones. The term hyperbola is believed to have been coined by Apollonius of Perga (c. 262–c. 190 BC) in his definitive work on the conic sections, the \"Conics\". \nThe names of the other two general conic sections, the ellipse and the parabola, derive from the corresponding Greek words for \"deficient\" and \"applied\"; all three names are borrowed from earlier Pythagorean terminology which referred to a comparison of the side of rectangles of fixed area with a given line segment. The rectangle could be \"applied\" to the segment (meaning, have an equal length), be shorter than the segment or exceed the segment.\n\nA hyperbola can be defined geometrically as a set of points (locus of points) in the Euclidean plane:\n\nThe midpoint formula_8 of the line segment joining the foci is called the \"center\" of the hyperbola. The line through the foci is called the \"major axis\". It contains the \"vertices\" formula_9, which have distance formula_10 to the center. The distance formula_11 of the foci to the center is called the \"focal distance\" or \"linear eccentricity\". The quotient formula_12 is the \"eccentricity\" formula_13.\n\nThe equation formula_14 can be viewed in a different way (see diagram):\nIf formula_15 is the circle with midpoint formula_16 and radius formula_17, then the distance of a point formula_3 of the right branch to the circle formula_15 equals the distance to the focus formula_20:\nformula_15 is called the \"circular directrix\" (related to focus formula_16) of the hyperbola. In order to get the left branch of the hyperbola, one has to use the circular directrix related to formula_20. This property should not be confused with the definition of a hyperbola with help of a directrix (line) below.\n\nIf Cartesian coordinates are introduced such that the origin is the center of the hyperbola and the \"x\"-axis is the major axis, then the hyperbola is called \"east-west-opening\" and \nFor an arbitrary point formula_27 the distance to the focus formula_28 is \nformula_29 and to the second focus formula_30. Hence the point formula_27 is on the hyperbola if the following condition is fulfilled \nRemove the square roots by suitable squarings and use the relation formula_33 to obtain the equation of the hyperbola:\n\nThis equation is called the \"canonical form\" of a hyperbola, because any hyperbola, regardless of its orientation relative to the Cartesian axes and regardless of the location of its center, can be transformed to this form by a change of variables, giving a hyperbola that is congruent to the original (see below).\n\nThe axes of symmetry or \"principal axes\" are the \"transverse axis\" (containing the segment of length 2\"a\" with endpoints at the vertices) and the \"conjugate axis\" (containing the segment of length 2\"b\" perpendicular to the transverse axis and with midpoint at the hyperbola's center). As opposed to an ellipse, a hyperbola has only two vertices: formula_35. The two points formula_36 on the conjugate axis are \"not\" on the hyperbola.\n\nIt follows from the equation that the hyperbola is \"symmetric\" with respect to both of the coordinate axes and hence symmetric with respect to the origin.\n\nFor a hyperbola in the above canonical form, the eccentricity is given by\n\nTwo hyperbolas are geometrically similar to each other – meaning that they have the same shape, so that one can be transformed into the other by rigid left and right movements, rotation, taking a mirror image, and scaling (magnification) – if and only if they have the same eccentricity.\n\nSolving the equation (above) of the hyperbola for formula_38 yields\nIt follows from this that the hyperbola approaches the two lines \nfor large values of formula_41. These two lines intersect at the center (origin) and are called \"asymptotes\" of the hyperbola formula_42\n\nWith help of the figure one can see that\n\nFrom the Hesse normal form formula_45 of the asymptotes and the equation of the hyperbola one gets:\n\nFrom the equation formula_49 of the hyperbola (above) one can derive:\n\nIn addition, from (2) above it can be shown that\n\nThe length of the chord through one of the foci, perpendicular to the major axis of the hyperbola, is called the \"latus rectum\". One half of it is the \"semi-latus rectum\" formula_54. A calculation shows\nThe semi-latus rectum formula_54 may also be viewed as the \"radius of curvature \" of the osculating circles at the vertices.\n\nThe simplest way to determine the equation of the tangent at a point formula_57 is to implicitly differentiate the equation formula_58 of the hyperbola. Denoting \"dy/dx\" as \"y′\", this produces\nWith respect to formula_60, the equation of the tangent at point formula_57 is\n\nA particular tangent line distinguishes the hyperbola from the other conic sections. Let \"f\" be the distance from the vertex \"V\" (on both the hyperbola and its axis through the two foci) to the nearer focus. Then the distance, along a line perpendicular to that axis, from that focus to a point P on the hyperbola is greater than 2\"f\". The tangent to the hyperbola at P intersects that axis at point Q at an angle ∠PQV of greater than 45°.\n\nIn the case formula_63 the hyperbola is called \"rectangular\" (or \"equilateral\"), because its asymptotes intersect rectangularly (that is, are perpendicular). For this case, the linear eccentricity is formula_64, the eccentricity formula_65 and the semi-latus rectum formula_66.\n\nUsing the hyperbolic sine and cosine functions formula_67, a parametric representation of the hyperbola formula_58 can be obtained, which is similar to the parametric representation of an ellipse:\nwhich satisfies the Cartesian equation because formula_70\n\nFurther parametric representations are given in the section Parametric equations below.\n\nExchange formula_71 and formula_38 to obtain the equation of the conjugate hyperbola (see diagram):\n\nIf the \"xy\"-coordinate system is rotated about the origin by the angle formula_75 and new coordinates formula_76 are assigned, then formula_77. \nThe rectangular hyperbola formula_78 (whose semi-axes are equal) has the new equation formula_79.\nSolving for formula_80 yields formula_81\n\nThus, in an \"xy\"-coordinate system the graph of a function formula_82 with equation\n\nA rotation of the original hyperbola by formula_93 results in a rectangular hyperbola entirely in the second and fourth quadrants, with the same asymptotes, center, semi-latus rectum, radius of curvature at the vertices, linear eccentricity, and eccentricity as for the case of formula_75 rotation, with equation \n\nShifting the hyperbola with equation formula_99 so that the new center is formula_100, yields the new equation \nand the new asymptotes are formula_102 and formula_103. \nThe shape parameters formula_104 remain unchanged.\n\nThe two lines at distance formula_105 and parallel to the minor axis are called directrices of the hyperbola (see diagram).\n\nFor an arbitrary point formula_3 of the hyperbola the quotient of the distance to one focus and to the corresponding directrix (see diagram) is equal to the eccentricity:\nThe proof for the pair formula_108 follows from the fact that formula_109 and formula_110 satisfy the equation\nThe second case is proven analogously.\n\nThe \"inverse statement\" is also true and can be used to define a hyperbola (in a manner similar to the definition of a parabola):\n\nFor any point formula_112 (focus), any line formula_113 (directrix) not through formula_112 and any real number formula_13 with formula_116 the set of points (locus of points), for which the quotient of the distances to the point and to the line is formula_13\n\nLet formula_121 and assume formula_85 is a point on the curve. \nThe directrix formula_113 has equation formula_124. With formula_125, the relation formula_126 produces the equations\nThe substitution formula_129 yields\nThis is the equation of an \"ellipse\" (formula_131) or a \"parabola\" (formula_132) or a \"hyperbola\" (formula_133). All of these non-degenerate conics have, in common, the origin as a vertex (see diagram).\n\nIf formula_133, introduce new parameters formula_135 so that\nformula_136, and then the equation above becomes \nwhich is the equation of a hyperbola with center formula_138, the \"x\"-axis as major axis and\nthe major/minor semi axis formula_135.\n\nThe intersection of an upright double cone by a plane not through the vertex with slope greater than the slope of the lines on the cone is a hyperbola (see diagram: red curve). In order to prove the defining property of a hyperbola (see above) one uses two Dandelin spheres formula_140, which are spheres that touch the cone along circles formula_141 , formula_142 and the intersecting (hyperbola) plane at points formula_20 and formula_16. It turns out: formula_145 are the \"foci\" of the hyperbola.\n\nThe tangent at a point formula_3 bisects the angle between the lines formula_161.\nLet formula_162 be the point on the line formula_155 with the distance formula_17 to the focus formula_16 (see diagram, formula_10 is the semi major axis of the hyperbola). Line formula_167 is the bisector of the angle between the lines formula_161. In order to prove that formula_167 is the tangent line at point formula_3, one checks that any point formula_171 on line formula_167 which is different from formula_3 cannot be on the hyperbola. Hence formula_167 has only point formula_3 in common with the hyperbola and is, therefore, the tangent at point formula_3. \nFrom the diagram and the triangle inequality one recognizes that formula_177 holds, which means: formula_178. But if formula_171 is a point of the hyperbola, the difference should be formula_17.\n\nThe midpoints of parallel chords of a hyperbola lie on a line through the center (see diagram).\n\nThe points of any chord may lie on different branches of the hyperbola.\n\nThe proof of the property on midpoints is best done for the hyperbola formula_181. Because any hyperbola is an affine image of the hyperbola formula_181 (see section below) and an affine transformation preserves parallelism and midpoints of line segments, the property is true for all hyperbolas:\nFor two points formula_183 of the hyperbola formula_181\n\nFor parallel chords the slope is constant and the midpoints of the parallel chords lie on the line formula_187\n\nConsequence: for any pair of points formula_188 of a chord there exists a \"skew reflection\" with an axis (set of fixed points) passing through the center of the hyperbola, which exchanges the points formula_188 and leaves the hyperbola (as a whole) fixed. A skew reflection is a generalization of an ordinary reflection across a line formula_190, where all point-image pairs are on a line perpendicular to formula_190.\n\nBecause a skew reflection leaves the hyperbola fixed, the pair of asymptotes is fixed, too. Hence the midpoint formula_8 of a chord formula_193 divides the related line segment formula_194 between the asymptotes into halves, too. This means that formula_195. This property can be used for the construction of further points formula_171 of the hyperbola if a point formula_3 and the asymptotes are given.\n\nIf the chord degenerates into a \"tangent\", then the touching point divides the line segment between the asymptotes in two halves.\n\nThe following method to construct single points of a hyperbola relies on the Steiner generation of a non degenerate conic section:\n\nFor the generation of points of the hyperbola formula_205 one uses the pencils at the vertices formula_9. Let formula_207 be a point of the hyperbola and formula_208. The line segment formula_209 is divided into n equally-spaced segments and this division is projected parallel with the diagonal formula_210 as direction onto the line segment formula_211 (see diagram). The parallel projection is part of the projective mapping between the pencils at formula_212 and formula_213 needed. The intersection points of any two related lines formula_214 and formula_215 are points of the uniquely defined hyperbola.\n\n\"Remark:\" The subdivision could be extended beyond the points formula_149 and formula_151 in order to get more points, but the determination of the intersection points would become more inaccurate. A better idea is extending the points already constructed by symmetry (see animation).\n\n\"Remark:\"\n\nA hyperbola with equation formula_218 is uniquely determined by three points formula_219 with different \"x\"- and \"y\"-coordinates. A simple way to determine the shape parameters formula_220 uses the \"inscribed angle theorem\" for hyperbolas:\n\nAnalogous to the inscribed angle theorem for circles one gets the\n\nInscribed angle theorem for hyperbolas:,:\n\nA consequence of the inscribed angle theorem for hyperbolas is the\n\n3-point-form of a hyperbola's equation:\n\nFor a hyperbola formula_232 the intersection points of \"orthogonal\" tangents lie on the circle formula_233. \nThis circle is called the \"orthoptic\" of the given hyperbola.\n\nThe tangents may belong to points on different branches of the hyperbola.\n\nIn case of formula_234 there are no pairs of orthogonal tangents.\n\nAny hyperbola can be described in a suitable coordinate system by an equation formula_58. The equation of the tangent at a point formula_236 of the hyperbola is formula_237 If one allows point formula_236 to be an arbitrary point different from the origin, then\n\nThis relation between points and lines is a bijection.\n\nThe inverse function maps\n\nSuch a relation between points and lines generated by a conic is called pole-polar relation or just \"polarity\". The pole is the point, the polar the line. See Pole and polar.\n\nBy calculation one checks the following properties of the pole-polar relation of the hyperbola:\n\n\"Remarks:\"\nPole-polar relations exist for ellipses and parabolas, too.\n\nAnother definition of a hyperbola uses affine transformations:\n\nAn affine transformation of the Euclidean plane has the form formula_257, where formula_149 is a regular matrix (its determinant is not 0) and formula_259 is an arbitrary vector. If formula_260 are the column vectors of the matrix formula_149, the unit hyperbola formula_262 is mapped onto the hyperbola\n\nformula_259 is the center, formula_265 a point of the hyperbola and formula_266 a tangent vector at this point. In general the vectors formula_260 are not perpendicular. That means, in general formula_268 are \"not\" the vertices of the hyperbola. But formula_269 point into the directions of the asymptotes. The tangent vector at point formula_270 is \nBecause at a vertex the tangent is perpendicular to the major axis of the hyperbola one gets the parameter formula_272 of a vertex from the equation \nand hence from\nwhich yields\n\nThe two \"vertices\" of the hyperbola are formula_277\n\nThe advantage of this definition is that one gets a simple parametric representation of an arbitrary hyperbola, even in the space, if the vectors formula_278 are vectors of the Euclidean space.\n\nBecause the unit hyperbola formula_256 is affinely equivalent to the hyperbola formula_181, an arbitrary hyperbola can be considered as the affine image (see previous section) of the hyperbola formula_281\n\nformula_283 is the center of the hyperbola, the vectors formula_284 have the directions of the asymptotes and formula_285 is a point of the hyperbola. The tangent vector is\nAt a vertex the tangent is perpendicular to the major axis. Hence \nand the parameter of a vertex is\n\nformula_289 is equivalent to formula_290 and formula_291 are the vertices of the hyperbola.\n\nThe following properties of a hyperbola are easily proven using the representation of a hyperbola introduced in this section.\n\nThe tangent vector can be rewritten by factorization:\nThis means that\n\nThis property provides a way to construct the tangent at a point on the hyperbola.\n\nThis property of a hyperbola is an affine version of the 3-point-degeneration of Pascal's theorem.\n\nThe area of the grey parallelogram MAPB in the above diagram is\nand hence independent of point P. The last equation follows from a calculation for the case, where P is a vertex and the hyperbola in its canonical form formula_297\n\nFor a hyperbola with parametric representation formula_298 (for simplicity the center is the origin) the following is true:\n\nThe simple proof is a consequence of the equation formula_301.\n\nThis property provides a possibility to construct points of a hyperbola if the asymptotes and one point are given.\n\nThis property of a hyperbola is an affine version of the 4-point-degeneration of Pascal's theorem.\n\nFor simplicity the center of the hyperbola may be the origin and the vectors formula_302 have equal length. If the last assumption is not fulfilled one can first apply a parameter transformation (see above) in order to make the assumption true. Hence formula_303 are the vertices, formula_304 span the minor axis and one gets formula_305 and formula_306.\n\nFor the intersection points of the tangent at point formula_307 with the asymptotes one gets the points \nThe \"area\" of the triangle formula_309 can be calculated by a 2x2-determinant: \n(see rules for determinants).\nformula_311 is the area of the rhombus generated by formula_302. The area of a rhombus is equal to one half of the product of its diagonals. The diagonals are the semi-axes formula_135 of the hyperbola. Hence:\n\nFor pole = focus: \n\nThe polar coordinates used most commonly for the hyperbola are defined relative to the Cartesian coordinate system that has its \"origin in a focus\" and its x-axis pointing towards the origin of the \"canonical coordinate system\" as illustrated in the first diagram.\nIn this case the angle formula_316 is called true anomaly.\n\nRelative to this coordinate system one has that\n\nand\n\nfor pole = center:\n\nWith polar coordinates relative to the \"canonical coordinate system\" (see second diagram)\none has that\n\nFor the right branch of the hyperbola the range of formula_320 is\n\nA hyperbola with equation formula_322 can be described by several parametric equations:\n\nA parametric representation, which uses the slope formula_190 of the tangent at a point of the hyperbola \ncan be obtained analogously to the ellipse case: Replace in the ellipse case formula_327 by formula_328\nand use formulae for the hyperbolic functions. One gets\nformula_330 is the upper and formula_331 the lower half of the hyperbola. The points with vertical tangents (vertices formula_332) are not covered by the representation.\nThe equation of the tangent at point formula_333 is\nThis description of the tangents of a hyperbola is an essential tool for the determination of the orthoptic of a hyperbola.\n\nThe reciprocation of a circle \"B\" in a circle \"C\" always yields a conic section such as a hyperbola. The process of \"reciprocation in a circle \"C\"\" consists of replacing every line and point in a geometrical figure with their corresponding pole and polar, respectively. The \"pole\" of a line is the inversion of its closest point to the circle \"C\", whereas the polar of a point is the converse, namely, a line whose closest point to \"C\" is the inversion of the point.\n\nThe eccentricity of the conic section obtained by reciprocation is the ratio of the distances between the two circles' centers to the radius \"r\" of reciprocation circle \"C\". If B and C represent the points at the centers of the corresponding circles, then\n\nSince the eccentricity of a hyperbola is always greater than one, the center B must lie outside of the reciprocating circle \"C\".\n\nThis definition implies that the hyperbola is both the locus of the poles of the tangent lines to the circle \"B\", as well as the envelope of the polar lines of the points on \"B\". Conversely, the circle \"B\" is the envelope of polars of points on the hyperbola, and the locus of poles of tangent lines to the hyperbola. Two tangent lines to \"B\" have no (finite) poles because they pass through the center C of the reciprocation circle \"C\"; the polars of the corresponding tangent points on \"B\" are the asymptotes of the hyperbola. The two branches of the hyperbola correspond to the two parts of the circle \"B\" that are separated by these tangent points.\n\nA hyperbola can also be defined as a second-degree equation in the Cartesian coordinates (\"x\", \"y\") in the plane,\n\nprovided that the constants \"A\", \"A\", \"A\", \"B\", \"B\", and \"C\" satisfy the determinant condition\n\nThis determinant is conventionally called the discriminant of the conic section.\n\nA special case of a hyperbola—the \"degenerate hyperbola\" consisting of two intersecting lines—occurs when another determinant is zero:\n\nThis determinant Δ is sometimes called the discriminant of the conic section.\n\nGiven the above general parametrization of the hyperbola in Cartesian coordinates, the eccentricity can be found using the formula in Conic section#Eccentricity in terms of parameters of the quadratic form.\n\nThe center (\"x\", \"y\") of the hyperbola may be determined from the formulae\n\nIn terms of new coordinates, and , the defining equation of the hyperbola can be written\n\nThe principal axes of the hyperbola make an angle \"φ\" with the positive \"x\"-axis that is given by\n\nRotating the coordinate axes so that the \"x\"-axis is aligned with the transverse axis brings the equation into its canonical form\n\nThe major and minor semiaxes \"a\" and \"b\" are defined by the equations\n\nwhere λ and λ are the roots of the quadratic equation\n\nFor comparison, the corresponding equation for a degenerate hyperbola (consisting of two intersecting lines) is\n\nThe tangent line to a given point (\"x\", \"y\") on the hyperbola is defined by the equation\n\nwhere \"E\", \"F\" and \"G\" are defined by\n\nThe normal line to the hyperbola at the same point is given by the equation\n\nThe normal line is perpendicular to the tangent line, and both pass through the same point (\"x\", \"y\").\n\nFrom the equation\nthe left focus is formula_354 and the right focus is formula_355 where is the eccentricity. Denote the distances from a point (\"x, y\") to the left and right foci as formula_356 and formula_357 For a point on the right branch,\n\nand for a point on the left branch,\n\nThis can be proved as follows:\n\nIf (\"x\",\"y\") is a point on the hyperbola the distance to the left focal point is\n\nTo the right focal point the distance is\n\nIf (\"x,y\") is a point on the right branch of the hyperbola then formula_362 and\n\nSubtracting these equations one gets\n\nIf (\"x,y\") is a point on the left branch of the hyperbola then formula_366 and\n\nSubtracting these equations one gets\n\nBesides providing a uniform description of circles, ellipses, parabolas, and hyperbolas, conic sections can also be understood as a natural model of the geometry of perspective in the case where the scene being viewed consists of circles, or more generally an ellipse. The viewer is typically a camera or the human eye and the image of the scene a central projection onto an image plane, that is, all projection rays pass a fixed point O, the center. The lens plane is a plane parallel to the image plane at the lens O.\n\nThe image of a circle c is \n\nThese results can be understood if one recognizes that the projection process can be seen in two steps: 1) circle c and point O generate a cone which is 2) cut by the image plane, in order to generate the image.\n\nOne sees a hyperbola whenever catching sight of a portion of a circle cut by one's lens plane. The inability to see very much of the arms of the visible branch, combined with the complete absence of the second branch, makes it virtually impossible for the human visual system to recognize the connection with hyperbolas.\n\nSeveral other curves can be derived from the hyperbola by inversion, the so-called inverse curves of the hyperbola. If the center of inversion is chosen as the hyperbola's own center, the inverse curve is the lemniscate of Bernoulli; the lemniscate is also the envelope of circles centered on a rectangular hyperbola and passing through the origin. If the center of inversion is chosen at a focus or a vertex of the hyperbola, the resulting inverse curves are a limaçon or a strophoid, respectively.\n\nA family of confocal hyperbolas is the basis of the system of elliptic coordinates in two dimensions. These hyperbolas are described by the equation\n\nwhere the foci are located at a distance \"c\" from the origin on the \"x\"-axis, and where θ is the angle of the asymptotes with the \"x\"-axis. Every hyperbola in this family is orthogonal to every ellipse that shares the same foci. This orthogonality may be shown by a conformal map of the Cartesian coordinate system \"w\" = \"z\" + 1/\"z\", where \"z\"= \"x\" + \"iy\" are the original Cartesian coordinates, and \"w\"=\"u\" + \"iv\" are those after the transformation.\n\nOther orthogonal two-dimensional coordinate systems involving hyperbolas may be obtained by other conformal mappings. For example, the mapping \"w\" = \"z\" transforms the Cartesian coordinate system into two families of orthogonal hyperbolas.\n\n\nJust as the trigonometric functions are defined in terms of the unit circle, so also the hyperbolic functions are defined in terms of the unit hyperbola, as shown in this diagram.\n\nHyperbolas may be seen in many sundials. On any given day, the sun revolves in a circle on the celestial sphere, and its rays striking the point on a sundial traces out a cone of light. The intersection of this cone with the horizontal plane of the ground forms a conic section. At most populated latitudes and at most times of the year, this conic section is a hyperbola. In practical terms, the shadow of the tip of a pole traces out a hyperbola on the ground over the course of a day (this path is called the \"declination line\"). The shape of this hyperbola varies with the geographical latitude and with the time of the year, since those factors affect the cone of the sun's rays relative to the horizon. The collection of such hyperbolas for a whole year at a given location was called a \"pelekinon\" by the Greeks, since it resembles a double-bladed axe.\n\nA hyperbola is the basis for solving multilateration problems, the task of locating a point from the differences in its distances to given points — or, equivalently, the difference in arrival times of synchronized signals between the point and the given points. Such problems are important in navigation, particularly on water; a ship can locate its position from the difference in arrival times of signals from a LORAN or GPS transmitters. Conversely, a homing beacon or any transmitter can be located by comparing the arrival times of its signals at two separate receiving stations; such techniques may be used to track objects and people. In particular, the set of possible positions of a point that has a distance difference of 2\"a\" from two given points is a hyperbola of vertex separation 2\"a\" whose foci are the two given points.\n\nThe path followed by any particle in the classical Kepler problem is a conic section. In particular, if the total energy \"E\" of the particle is greater than zero (that is, if the particle is unbound), the path of such a particle is a hyperbola. This property is useful in studying atomic and sub-atomic forces by scattering high-energy particles; for example, the Rutherford experiment demonstrated the existence of an atomic nucleus by examining the scattering of alpha particles from gold atoms. If the short-range nuclear interactions are ignored, the atomic nucleus and the alpha particle interact only by a repulsive Coulomb force, which satisfies the inverse square law requirement for a Kepler problem.\n\nThe hyperbolic trig function formula_371 appears as one solution to the Korteweg–de Vries equation which describes the motion of a soliton wave in a canal.\n\nAs shown first by Apollonius of Perga, a hyperbola can be used to trisect any angle, a well studied problem of geometry. Given an angle, first draw a circle centered at its vertex O, which intersects the sides of the angle at points A and B. Next draw the line segment with endpoints A and B and its perpendicular bisector formula_372. Construct a hyperbola of eccentricity \"e\"=2 with formula_372 as directrix and B as a focus. Let P be the intersection (upper) of the hyperbola with the circle. Angle POB trisects angle AOB.\n\nTo prove this, reflect the line segment OP about the line formula_372 obtaining the point P' as the image of P. Segment AP' has the same length as segment BP due to the reflection, while segment PP' has the same length as segment BP due to the eccentricity of the hyperbola. As OA, OP', OP and OB are all radii of the same circle (and so, have the same length), the triangles OAP', OPP' and OPB are all congruent. Therefore, the angle has been trisected, since 3×POB = AOB.\n\nIn portfolio theory, the locus of mean-variance efficient portfolios (called the efficient frontier) is the upper half of the east-opening branch of a hyperbola drawn with the portfolio return's standard deviation plotted horizontally and its expected value plotted vertically; according to this theory, all rational investors would choose a portfolio characterized by some point on this locus.\n\nHyperbolas appear as plane sections of the following quadrics:\n\n\n"}
{"id": "14055", "url": "https://en.wikipedia.org/wiki?curid=14055", "title": "Humayun", "text": "Humayun\n\nNasir-ud-Din Muḥammad (; 6 March 1508 – 27 January 1556), better known by his regnal name, Humayun (), was the second emperor of the Mughal Empire, who ruled over territory in what is now Afghanistan, Pakistan, Northern India and Bangladesh from 1530–1540 and again from 1555–1556. Like his father, Babur, he lost his kingdom early but regained it with the aid of the Safavid dynasty of Persia, with additional territory. At the time of his death in 1556, the Mughal Empire spanned almost one million square kilometres.\n\nIn December 1530, Humayun succeeded his father to the throne of Delhi as ruler of the Mughal territories in the Indian subcontinent. At the age of 22, Humayun was an inexperienced ruler when he came to power. His half-brother Kamran Mirza inherited Kabul and Kandahar, the northernmost parts of their father's empire. Mirza was to become a bitter rival of Humayun.\n\nHumayun lost Mughal territories to Sher Shah Suri, but regained them 15 years later with Safavid aid. Humayun's return from Persia was accompanied by a large retinue of Persian noblemen and signalled an important change in Mughal court culture. The Central Asian origins of the dynasty were largely overshadowed by the influences of Persian art, architecture, language and literature. There are many stone carvings and thousands of Persian manuscripts in India dating from the time of Humayun.\n\nSubsequently, Humayun further expanded the Empire in a very short time, leaving a substantial legacy for his son, Akbar.\n\nThe decision of Babur to divide the territories of his empire between two of his sons was unusual in India, although it had been a common Central Asian practice since the time of Genghis Khan. Unlike most monarchies, which practised primogeniture, the Timurids followed the example of Genghis and did not leave an entire kingdom to the eldest son. Although under that system only a could claim sovereignty and khanal authority, any male Chinggisid within a given sub-branch had an equal right to the throne (though the Timurids were not Chinggisid in their paternal ancestry). While Genghis Khan's Empire had been peacefully divided between his sons upon his death, almost every Chinggisid succession since had resulted in fratricide.\n\nTimur himself had divided his territories among Pir Muhammad, Miran Shah, Khalil Sultan and Shah Rukh, which resulted in inter-family warfare. Upon Babur's death, Humayun's territories were the least secure. He had ruled only four years, and not all \"umarah\" (nobles) viewed Humayun as the rightful ruler. Indeed, earlier, when Babur had become ill, some of the nobles had tried to install his Brother-in-law, Mahdi Khwaja, as ruler. Although this attempt failed, it was a sign of problems to come.\n\nWhen Humayun came to the throne of the Mughal Empire, several of his brothers revolted against him. Another brother Khalil Mirza (1509–30) supported Humayun but was assassinated. The Emperor commenced construction of a tomb for his brother in 1538, but this was not yet finished when Humayun was forced to flee to Persia. Sher Shah destroyed the structure and no further work was done on it after Humayun's restoration.\n\nHumayun had two major rivals for his lands: Sultan Bahadur of Gujarat to the southwest and Sher Shah Suri (Sher Khan) settled along the river Ganges in Bihar to the east. Humayun's first campaign was to confront Sher Shah Suri. Halfway through this offensive Humayun had to abandon it and concentrate on Gujarat, where a threat from Ahmed Shah had to be met. Humayun was victorious annexing Gujarat, Malwa, Champaner and the great fort of Mandu.\n\nDuring the first five years of Humayun's reign, Bahadur and Sher Khan extended their rule, although Sultan Bahadur faced pressure in the east from sporadic conflicts with the Portuguese. While the Mughals had obtained firearms via the Ottoman Empire, Bahadur's Gujarat had acquired them through a series of contracts drawn up with the Portuguese, allowing the Portuguese to establish a strategic foothold in north western India.\n\nIn 1535 Humayun was made aware that the Sultan of Gujarat was planning an assault on the Mughal territories with Portuguese aid. Humayun gathered an army and marched on Bahadur. Within a month he had captured the forts of Mandu and Champaner. However, instead of pressing his attack, Humayun ceased the campaign and consolidated his newly conquered territory. Sultan Bahadur, meanwhile escaped and took up refuge with the Portuguese.\n\nShortly after Humayun had marched on Gujarat, Sher Shah Suri saw an opportunity to wrest control of Agra from the Mughals. He began to gather his army together hoping for a rapid and decisive siege of the Mughal capital. Upon hearing this alarming news, Humayun quickly marched his troops back to Agra allowing Bahadur to easily regain control of the territories Humayun had recently taken. In February 1537, however, Bahadur was killed when a botched plan to kidnap the Portuguese viceroy ended in a fire-fight that the Sultan lost.\n\nWhilst Humayun succeeded in protecting Agra from Sher Shah, the second city of the Empire, Gaur the capital of the \"vilayat\" of Bengal, was sacked. Humayun's troops had been delayed while trying to take Chunar, a fort occupied by Sher Shah's son, in order to protect his troops from an attack from the rear. The stores of grain at Gauri, the largest in the empire, were emptied, and Humayun arrived to see corpses littering the roads. The vast wealth of Bengal was depleted and brought East, giving Sher Shah a substantial war chest.\n\nSher Shah withdrew to the east, but Humayun did not follow: instead he \"shut himself up for a considerable time in his Harem, and indulged himself in every kind of luxury.\" Hindal, Humayun's 19-year-old brother, had agreed to aid him in this battle and protect the rear from attack, but he abandoned his position and withdrew to Agra, where he decreed himself acting emperor. When Humayun sent the grand \"Mufti\", Sheikh Buhlul, to reason with him; the Sheikh was killed. Further provoking the rebellion, Hindal ordered that the \"Khutba\", or sermon, in the main mosque surrounded.\n\nHumayun's other brother, Kamran Mirza, marched from his territories in the Punjab, ostensibly to aid Humayun. However, his return home had treacherous motives as he intended to stake a claim for Humayun's apparently collapsing empire. He brokered a deal with Hindal providing that his brother would cease all acts of disloyalty in return for a share in the new empire, which Kamran would create once Humayun was deposed.\n\nIn June 1539 Sher Shah met Humayun in the Battle of Chausa on the banks of the Ganges, near Buxar. This was to become an entrenched battle in which both sides spent a lot of time digging themselves into positions. The major part of the Mughal army, the artillery, was now immobile, and Humayun decided to engage in some diplomacy using Muhammad Aziz as ambassador. Humayun agreed to allow Sher Shah to rule over Bengal and Bihar, but only as provinces granted to him by his Emperor, Humayun, falling short of outright sovereignty. The two rulers also struck a bargain in order to save face: Humayun's troops would charge those of Sher Shah whose forces then retreat in feigned fear. Thus honour would, supposedly, be satisfied.\n\nOnce the Army of Humayun had made its charge and Sher Shah's troops made their agreed-upon retreat, the Mughal troops relaxed their defensive preparations and returned to their entrenchments without posting a proper guard. Observing the Mughals' vulnerability, Sher Shah reneged on his earlier agreement. That very night, his army approached the Mughal camp and finding the Mughal troops unprepared with a majority asleep, they advanced and killed most of them. The Emperor survived by swimming across the Ganges using an air filled \"water skin,\" and quietly returned to Agra. Humayun was assisted across the Ganges by Shams al-Din Muhammad.\n\nWhen Humayun returned to Agra, he found that all three of his brothers were present. Humayun once again not only pardoned his brothers for plotting against him, but even forgave Hindal for his outright betrayal. With his armies travelling at a leisurely pace, Sher Shah was gradually drawing closer and closer to Agra. This was a serious threat to the entire family, but Humayun and Kamran squabbled over how to proceed. Kamran withdrew after Humayun refused to make a quick attack on the approaching enemy, instead opting to build a larger army under his own name.\n\nWhen Kamran returned to Lahore, Humayun, with his other brothers Askari and Hindal, marched to meet Sher Shah east of Agra at the battle of Kannauj on 17 May 1540. Humayun was soundly defeated. He retreated to Agra, pursued by Sher Shah, and thence through Delhi to Lahore. Sher Shah's founding of the short-lived Sur Empire, with its capital at Delhi, resulted in Humayun's exile for 15 years in the court of Shah Tahmasp I.\n\nThe four brothers were united in Lahore, but every day they were informed that Sher Shah was getting closer and closer. When he reached Sirhind, Humayun sent an ambassador carrying the message \"I have left you the whole of Hindustan (\"i.e.\" the lands to the East of Punjab, comprising most of the Ganges Valley). Leave Lahore alone, and let Sirhind be a boundary between you and me.\" Sher Shah, however, replied \"I have left you Kabul. You should go there.\" Kabul was the capital of the empire of Humayun's brother Kamran, who was far from willing to hand over any of his territories to his brother. Instead, Kamran approached Sher Shah and proposed that he actually revolt against his brother and side with Sher Shah in return for most of the Punjab. Sher Shah dismissed his help, believing it not to be required, though word soon spread to Lahore about the treacherous proposal, and Humayun was urged to make an example of Kamran and kill him. Humayun refused, citing the last words of his father, Babur, \"Do nothing against your brothers, even though they may deserve it.\"\n\nHumayun decided it would be wise to withdraw still further. He and his army rode out through and across the Thar Desert, when the Hindu ruler Rao Maldeo Rathore allied with Sher Shah Suri against the Mughal Empire. In many accounts Humayun mentions how he and his pregnant wife had to trace their steps through the desert at the hottest time of year. Their rations were low, and they had little to eat; even drinking water was a major problem in the desert. When Hamida Bano's horse died, no one would lend the Queen (who was now eight months pregnant) a horse, so Humayun did so himself, resulting in him riding a camel for six kilometres (four miles), although Khaled Beg then offered him his mount. Humayun was later to describe this incident as the lowest point in his life.\nHumayun asked that his brothers join him as he fell back into Sindh. While the previously rebellious Hindal Mirza remained loyal and was ordered to join his brothers in Kandahar. Kamran Mirza and Askari Mirza instead decided to head to the relative peace of Kabul. This was to be a definitive schism in the family. Humayun headed for Sindh because he expected aid from the Emir of Sindh, Hussein Umrani, whom he had appointed and who owed him his allegiance. Also, his wife Hamida hailed from Sindh; she was the daughter of a prestigious \"pir\" family (a \"pir\" is a Shia or Sufi religious mystic) of Persian heritage long settled in Sindh. En route to the Emir's court, Humayun had to break journey because his pregnant wife Hamida was unable to travel further. Humayun sought refuge with the Hindu ruler of the oasis town of Amarkot (now part of Sindh province).\n\nRana Prasad Rao of Amarkot duly welcomed Humayun into his home and sheltered the refugees for several months. Here, in the household of a Hindu Rajput nobleman, Humayun's wife Hamida Bano, daughter of a Sindhi family, gave birth to the future Emperor Akbar on 15 October 1542. The date of birth is well established because Humayun consulted his astronomer to utilise the astrolabe and check the location of the planets. The infant was the long-awaited heir-apparent to the 34-year-old Humayun and the answer of many prayers. Shortly after the birth, Humayun and his party left Amarkot for Sindh, leaving Akbar behind, who was not ready for the grueling journey ahead in his infancy. He was later adopted by Askari Mirza.\n\nFor a change, Humayun was not deceived in the character of the man on whom he has pinned his hopes. Emir Hussein Umrani, ruler of Sindh, welcomed Humayun's presence and was loyal to Humayun just as he had been loyal to Babur against the renegade Arghuns. While in Sindh, Humayun alongside Emir Hussein Umrani, gathered horses and weapons and formed new alliances that helped regain lost territories. Until finally Humayun had gathered hundreds of Sindhi and Baloch tribesmen alongside his Mughals and then marched towards Kandahar and later Kabul, thousands more gathered by his side as Humayun continually declared himself the rightful Timurid heir of the first Mughal Emperor, Babur.\n\nAfter Humayun set out from his expedition in Sindh, along with 300 camels (mostly wild) and 2000 loads of grain, he set off to join his brothers in Kandahar after crossing the Indus River on 11 July 1543 along with the ambition to regain the Mughal Empire and overthrow the Suri dynasty. Among the tribes that had sworn allegiance to Humayun were the Magsi, Rind and many others.\n\nIn Kamran Mirza's territory, Hindal Mirza had been placed under house arrest in Kabul after refusing to have the \"Khutba\" recited in Kamran Mirza's name. His other brother Askari Mirza was now ordered to gather an army and march on Humayun. When Humayun received word of the approaching hostile army he decided against facing them, and instead sought refuge elsewhere. Akbar was left behind in camp close to Kandahar for, as it was December it would have been too cold and dangerous to include the 14-month-old toddler in the forthcoming march through the dangerous and snowy mountains of the Hindu Kush. Askari Mirza found Akbar in the camp, and embraced him, and allowed his own wife to parent him, she apparently started treating him as her own.\n\nOnce again Humayun turned toward Kandahar where his brother Kamran Mirza was in power, but he received no help and had to seek refuge with the Shah of Persia.\n\nHumayun fled to the refuge of the Safavid Empire in Persia, marching with 40 men, his wife Bega Begum, and her companion through mountains and valleys. Amongst other trials the Imperial party were forced to live on horse meat boiled in the soldiers' helmets. These indignities continued during the month it took them to reach Herat, however after their arrival they were reintroduced to the finer things in life. Upon entering the city his army was greeted with an armed escort, and they were treated to lavish food and clothing. They were given fine accommodations and the roads were cleared and cleaned before them. Shah Tahmasp, unlike Humayun's own family, actually welcomed the Mughal, and treated him as a royal visitor. Here Humayun went sightseeing and was amazed at the Persian artwork and architecture he saw: much of this was the work of the Timurid Sultan Husayn Bayqarah and his ancestor, princess Gauhar Shad, thus he was able to admire the work of his relatives and ancestors at first hand.\n\nHe was introduced to the work of the Persian miniaturists, and Kamaleddin Behzad had two of his pupils join Humayun in his court. Humayun was amazed at their work and asked if they would work for him if he were to regain the sovereignty of Hindustan: they agreed. With so much going on Humayun did not even meet the Shah until July, some six months after his arrival in Persia. After a lengthy journey from Herat the two met in Qazvin where a large feast and parties were held for the event. The meeting of the two monarchs is depicted in a famous wall-painting in the Chehel Sotoun (Forty Columns) palace in Esfahan.\n\nThe Shah urged that Humayun convert from Sunni to Shia Islam, and Humayun eventually accepted, in order to keep himself and several hundred followers alive. Although the Mughals initially disagreed to their conversion they knew that with this outward acceptance of Shi'ism, Shah Tahmasp was eventually prepared to offer Humayun more substantial support. When Humayun's brother, Kamran Mirza, offered to cede Kandahar to the Persians in exchange for Humayun, dead or alive, Shah Tahmasp refused. Instead the Shah staged a celebration for Humayun, with 300 tents, an imperial Persian carpet, 12 musical bands and \"meat of all kinds\". Here the Shah announced that all this, and 12,000 elite cavalry were his to lead an attack on his brother Kamran. All that Shah Tahmasp asked for was that, if Humayun's forces were victorious, Kandahar would be his.\n\nWith this Persian Safavid aid Humayun took Kandahar from Askari Mirza after a two-week siege. He noted how the nobles who had served Askari Mirza quickly flocked to serve him, \"in very truth the greater part of the inhabitants of the world are like a flock of sheep, wherever one goes the others immediately follow\". Kandahar was, as agreed, given to the Shah of Persia who sent his infant son, Murad, as the Viceroy. However, the baby soon died and Humayun thought himself strong enough to assume power.\n\nHumayun now prepared to take Kabul, ruled by his brother Kamran Mirza. In the end, there was no actual siege. Kamran Mirza was detested as a leader and as Humayun's Persian army approached the city hundreds of Kamran Mirza's troops changed sides, flocking to join Humayun and swelling his ranks. Kamran Mirza absconded and began building an army outside the city. In November 1545, Hamida and Humayun were reunited with their son Akbar, and held a huge feast. They also held another, larger, feast in the child's honour when he was circumcised.\n\nHowever, while Humayun had a larger army than his brother and had the upper hand, on two occasions his poor military judgement allowed Kamran Mirza to retake Kabul and Kandahar, forcing Humayun to mount further campaigns for their recapture. He may have been aided in this by his reputation for leniency towards the troops who had defended the cities against him, as opposed to Kamran Mirza, whose brief periods of possession were marked by atrocities against the inhabitants who, he supposed, had helped his brother.\n\nHis youngest brother, Hindal Mirza, formerly the most disloyal of his siblings, died fighting on his behalf. His brother Askari Mirza was shackled in chains at the behest of his nobles and aides. He was allowed go on Hajj, and died en route in the desert outside Damascus.\n\nHumayun's other brother, Kamran Mirza, had repeatedly sought to have Humayun killed. In 1552 Kamran Mirza attempted to make a pact with Islam Shah, Sher Shah's successor, but was apprehended by a Gakhar. The Gakhars were one of the minority of tribal groups who had consistently remained loyal to their oath to the Mughals. Sultan Adam of the Gakhars handed Kamran Mirza over to Humayun. Humayun was inclined to forgive his brother. However he was warned that allowing Kamran Mirza's repeated acts of treachery to go unpunished could foment rebellion amongst his own supporters. So, instead of killing his brother, Humayun had Kamran Mirza blinded which would end any claim by the latter to the throne. Humayun sent Kamran Mirza on Hajj, as he hoped to see his brother thereby absolved of his offences. However Kamran Mirza died close to Mecca in the Arabian Peninsula in 1557.\n\nSher Shah Suri had died in 1545; his son and successor Islam Shah died in 1554. These two deaths left the dynasty reeling and disintegrating. Three rivals for the throne all marched on Delhi, while in many cities leaders tried to stake a claim for independence. This was a perfect opportunity for the Mughals to march back to India.\n\nThe Mughal Emperor Humayun gathered a vast army and attempted the challenging task of retaking the throne in Delhi. Humayun placed the army under the leadership of Bairam Khan, a wise move given Humayun's own record of military ineptitude, and it turned out to be prescient as Bairam proved himself a great tactician. At the Battle of Sirhind on 22 June 1555, the armies of Sikandar Shah Suri were decisively defeated and the Mughal Empire was re-established in India.\n\nThe \"Gazetteer of Ulwur\" states:\n\nBairam Khan led the army through the Punjab virtually unopposed. The fort of Rohtas, which was built in 1541–43 by Sher Shah Suri to crush the Gakhars who were loyal to Humayun, was surrendered without a shot by a treacherous commander. The walls of the Rohtas Fort measure up to 12.5 meters in thickness and up to 18.28 meters in height. They extend for 4 km and feature 68 semi-circular bastions. Its sandstone gates, both massive and ornate, are thought to have exerted a profound influence on Mughal military architecture.\n\nThe only major battle faced by Humayun's armies was against Sikander Suri in Sirhind, where Bairam Khan employed a tactic whereby he engaged his enemy in open battle, but then retreated quickly in apparent fear. When the enemy followed after them they were surprised by entrenched defensive positions and were easily annihilated.\n\nAfter Sirhind, most towns and villages chose to welcome the invading army as it made its way to the capital. On 23 July 1555, Humayun once again sat on Babur's throne in Delhi.\n\nWith all of Humayun's brothers now dead, there was no fear of another usurping his throne during his military campaigns. He was also now an established leader and could trust his generals. With this new-found strength Humayun embarked on a series of military campaigns aimed at extending his reign over areas in eastern and western India. His sojourn in exile seems to have reduced his reliance on astrology, and his military leadership came to imitate the more effective methods that he had observed in Persia.\n\nEdward S. Holden writes; \"He was uniformly kind and considerate to his dependents, devotedly attached to his son Akbar, to his friends, and to his turbulent brothers. The misfortunes of his reign arose in great, from his failure to treat them with rigor.\" He further writes; \"The very defects of his character, which render him less admirable as a successful ruler of nations, make us more fond of him as a man. His renown has suffered in that his reign came between the brilliant conquests of Babur and the beneficent statesmanship of Akbar; but he was not unworthy to be the son of the one and the father of the other.\" Stanley Lane-Poole writes in his book \"\"Medieval India\";\" \"His name meant the winner (Lucky/Conqueror), there is no kind in the history to be named as wrong as Humayun\", he was of a forgiving nature. He further writes, \"He was in fact unfortunate...Scarcely had he enjoyed his throne for six months in Delhi when he slipped down from the polished steps of his palace and died in his forty-ninth year (Jan. 24, 1556). If there was a possibility of falling, Humayun was not the man to miss it. He tumbled through his life and tumbled out of it\".\n\nOn 24 January 1556, Humayun, with his arms full of books, was descending the staircase from his library when the muezzin announced the Azaan (the call to prayer). It was his habit, wherever he heard the summons, to bow his knee in holy reverence. Trying to kneel, he caught his foot in his robe, tumbled down several steps and hit his temple on a rugged stone edge. He died three days later. His body was laid to rest in Purana Quila initially, but, because of an attack by Hemu on Delhi and the capture of Purana Qila, Humayun's body was exhumed by the fleeing army and transferred to Kalanaur in Punjab where Akbar was crowned. His tomb, which was commissioned by his favourite and devoted chief wife, Bega Begum, stands in Delhi, where he was later buried in a grand way.\n\nSome believe that before falling from the staircase once Humayun was very ill and to save him his father (Babur) performed a practice known as Sadkah by which he gave his life to Humayun who was about to die.\n\nHis full title as Emperor of the Mughal Empire was \"Al-Sultan al-'Azam wal Khaqan al-Mukarram, Jam-i-Sultanat-i-haqiqi wa Majazi, Sayyid al-Salatin, Abu'l Muzaffar Nasir ud-din Muhammad Humayun Padshah Ghazi, Zillu'llah\".\n\n\n\n"}
{"id": "14056", "url": "https://en.wikipedia.org/wiki?curid=14056", "title": "Prince-elector", "text": "Prince-elector\n\nThe Prince-electors ( pl. \"Kurfürsten\", , ) of the Holy Roman Empire, or Electors for short, were the members of the electoral college that elected the Holy Roman Emperor.\n\nFrom the 13th century onwards, the Prince-Electors had the privilege of electing the King of the Romans, who would be crowned by the Pope as Holy Roman Emperor. Charles V was the last to be a crowned Emperor (elected 1519, crowned 1530); his successors were elected Emperors directly by the electoral college, each being titled \"Elected Emperor of the Romans\" (; ). In practice, every emperor from 1440 onwards (except for Charles VII and Francis I) came from the Austrian House of Habsburg, and the Electors merely ratified the Habsburg succession.\n\nThe dignity of Elector carried great prestige and was considered to be second only to that of King or Emperor. The Electors had exclusive privileges that were not shared with the other princes of the Empire, and they continued to hold their original titles alongside that of Elector. The heir apparent to a secular prince-elector was known as an electoral prince ().\n\nThe German element \"Kur-\" is based on the Middle High German irregular verb \"kiesen\" and is related etymologically to the English word \"choose\" (cf. Old English \"ceosan\" , participle \"coren\" 'having been chosen' and Gothic \"kiusan\"). In English, the \"s\"/\"r\" mix in the Germanic verb conjugation has been regularized to \"s\" throughout, while German retains the \"r\" in \"Kur-\". There is also a modern German verb \"küren\" which means 'to choose' in a ceremonial sense. \"Fürst\" is German for 'prince', but while the German language distinguishes between the head of a principality (\"der Fürst\") and the son of a monarch (\"der Prinz\"), English uses \"prince\" for both concepts. \"Fürst\" itself is related to English \"first\" and is thus the 'foremost' person in his realm. Note that 'prince' derives from Latin \"princeps\", which carried the same meaning.\n\nElectors were \"reichsstände\" (Imperial Estates), enjoying precedence over the other princes. They were, until the 18th century, exclusively entitled to be addressed with the title \"Durchlaucht\" (Serene Highness). In 1742, the electors became entitled to the superlative \"Durchläuchtigste\" (Most Serene Highness), while other princes were promoted to \"Durchlaucht\".\n\nAs Imperial Estates, the electors enjoyed all the privileges of the other princes enjoying that status, including the right to enter into alliances, autonomy in relation to dynastic affairs and precedence over other subjects. The Golden Bull had granted them the Privilegium de non appellando, which prevented their subjects from lodging an appeal to a higher Imperial court. However, while this privilege, and some others, were automatically granted to Electors, they were not exclusive to them and many of the larger Imperial Estates were also to be individually granted some or all those rights and privileges.\n\nThe electors, like the other princes ruling States of the Empire, were members of the Imperial Diet, which was divided into three \"collegia\": the Council of Electors, the Council of Princes, and the Council of Cities. In addition to being members of the Council of Electors, several lay electors were therefore members of the Council of Princes as well by virtue of other territories they possessed. In many cases, the lay electors ruled numerous States of the Empire, and therefore held several votes in the Council of Princes. In 1792, the King of Bohemia held three votes, the Elector of Bavaria six votes, the Elector of Brandenburg eight votes, and the Elector of Hanover six votes. Thus, of the hundred votes in the Council of Princes in 1792, twenty-three belonged to electors. The lay electors therefore exercised considerable influence, being members of the small Council of Electors and holding a significant number of votes in the Council of Princes. The assent of both bodies was required for important decisions affecting the structure of the Empire, such as the creation of new electorates or States of the Empire.\n\nIn addition to voting by colleges or councils, the Imperial Diet also voted on religious lines, as provided for by the Peace of Westphalia. The Archbishop of Mainz presided over the Catholic body, or \"corpus catholicorum\", while the Elector of Saxony presided over the Protestant body, or \"corpus evangelicorum\". The division into religious bodies was on the basis of the official religion of the state, and not of its rulers. Thus, even when the Electors of Saxony were Catholics during the eighteenth century, they continued to preside over the \"corpus evangelicorum\", since the state of Saxony was officially Protestant.\n\nThe individual chosen by the electors assumed the title \"King of the Romans\", though he actually reigned in Germany. The King of the Romans became Holy Roman Emperor only when crowned by the Pope. On many occasions, a Pope refused to crown a king with whom he was engaged in a dispute, but a lack of a papal coronation deprived a king of only the title Emperor and not of the power to govern (cf Declaration of Rhense). The Habsburg dynasty stopped the practice of papal coronations. After Charles V, all individuals chosen by the electors were merely \"Emperors elect\".\n\nThe electors were originally summoned by the Archbishop of Mainz within one month of an Emperor's death, and met within three months of being summoned. During the \"interregnum\", imperial power was exercised by two imperial vicars. Each vicar, in the words of the Golden Bull, was \"the administrator of the empire itself, with the power of passing judgments, of presenting to ecclesiastical benefices, of collecting returns and revenues and investing with fiefs, of receiving oaths of fealty for and in the name of the holy empire\". The Elector of Saxony was vicar in areas operating under Saxon law (Saxony, Westphalia, Hanover, and northern Germany), while the Elector Palatine was vicar in the remainder of the Empire (Franconia, Swabia, the Rhine, and southern Germany). The Elector of Bavaria replaced the Elector Palatine in 1623, but when the latter was granted a new electorate in 1648, there was a dispute between the two as to which was vicar. In 1659, both purported to act as vicar, but the other vicar recognised the Elector of Bavaria. Later, the two electors made a pact to act as joint vicars, but the Imperial Diet rejected the agreement. In 1711, while the Elector of Bavaria was under the ban of the Empire, the Elector Palatine again acted as vicar, but his cousin was restored to his position upon his restoration three years later. Finally, in 1745, the two agreed to alternate as vicars, with Bavaria starting first. This arrangement was upheld by the Imperial Diet in 1752. In 1777 the question became moot when the Elector Palatine inherited Bavaria. On many occasions, however, there was no interregnum, as a new king had been elected during the lifetime of the previous Emperor.\n\nFrankfurt regularly served as the site of the election from the fifteenth century on, but elections were also held at Cologne (1531), Regensburg (1575 and 1636), and Augsburg (1653 and 1690). An elector could appear in person or could appoint another elector as his proxy. More often, an electoral suite or embassy was sent to cast the vote; the credentials of such representatives were verified by the Archbishop of Mainz, who presided over the ceremony. The deliberations were held at the city hall, but voting occurred in the cathedral. In Frankfurt, a special electoral chapel, or \"Wahlkapelle\", was used for elections. Under the Golden Bull, a majority of electors sufficed to elect a king, and each elector could cast only one vote. Electors were free to vote for whomsoever they pleased (including themselves), but dynastic considerations played a great part in the choice. Electors drafted a \"Wahlkapitulation\", or electoral capitulation, which was presented to the king-elect. The capitulation may be described as a contract between the princes and the king, the latter conceding rights and powers to the electors and other princes. Once an individual swore to abide by the electoral capitulation, he assumed the office of King of the Romans.\n\nIn the 10th and 11th centuries, princes often acted merely to confirm hereditary succession in the Saxon Ottonian dynasty and Franconian Salian dynasty. But with the actual formation of the prince-elector class, elections became more open, starting with the election of Lothair II in 1125. The Staufen dynasty managed to get its sons formally elected in their fathers' lifetimes almost as a formality. After these lines ended in extinction, the electors began to elect kings from different families so that the throne would not once again settle within a single dynasty. For some two centuries, the monarchy was elective both in theory and in practice; the arrangement, however, did not last, since the powerful House of Habsburg managed to secure succession within their dynasty during the fifteenth century. All kings elected from 1438 onwards were from among the Habsburg Archdukes of Austria (and later Kings of Hungary and Bohemia) until 1740, when the archduchy was inherited by a woman, Maria Theresa, sparking the War of the Austrian Succession. A representative of the House of Wittelsbach was elected for a short period of time, but in 1745, Maria Theresa's husband, Francis I of the Habsburg-Lorraine dynasty, became King. All of his successors were also from the same family. Hence, for the greater part of the Empire's history, the role of the electors was largely ceremonial.\n\nEach elector held a \"High Office of the Empire\" (\"Reichserzämter\") and was a member of the (ceremonial) Imperial Household. The three spiritual electors were all Arch-Chancellors (, ): the Archbishop of Mainz was Arch-Chancellor of Germany, the Archbishop of Cologne was Arch-Chancellor of Italy, and the Archbishop of Trier was Arch-Chancellor of Burgundy. The other offices were as follows:\n\nWhen the Duke of Bavaria replaced the Elector Palatine in 1623, he assumed the latter's office of Arch-Steward. When the Count Palatine was granted a new electorate, he assumed the position of Arch-Treasurer of the Empire. When the Duke of Bavaria was banned in 1706, the Elector Palatine returned to the office of Arch-Steward, and in 1710 the Elector of Hanover was promoted to the post of Arch-Treasurer. Matters were complicated by the Duke of Bavaria's restoration in 1714; the Elector of Bavaria resumed the office of Arch-Steward, while the Elector Palatine returned to the post of Arch-Treasurer, and the Elector of Hanover was given the new office of Archbannerbearer. The Electors of Hanover, however, continued to be styled Arch-Treasurers, though the Elector Palatine was the one who actually exercised the office until 1777, when he inherited Bavaria and the Arch-Stewardship. After 1777, no further changes were made to the Imperial Household; new offices were planned for the Electors admitted in 1803, but the Empire was abolished before they could be created. The Duke of Württemberg, however, started to adopt the trappings of the Arch-Bannerbearer.\n\nMany High Officers were entitled to use augmentations on their coats of arms; these augmentations, which were special marks of honour, appeared in the centre of the electors' shields (as shown in the image above) atop the other charges (in heraldic terms, the augmentations appeared in the form of inescutcheons). The Arch-Steward used \"gules an orb Or\" (a gold orb on a red field). The Arch-Marshal utilised the more complicated \"per fess sable and argent, two swords in saltire gules\" (two red swords arranged in the form of a saltire, on a black and white field). The Arch-Chamberlain's augmentation was \"azure a sceptre palewise Or\" (a gold sceptre on a blue field), while the Arch-Treasurer's was \"gules the crown of Charlemagne Or\" (a gold crown on a red field). As noted above, the Elector Palatine and the Elector of Hanover styled themselves Arch-Treasurer from 1714 until 1777; during this time, both electors used the corresponding augmentations. The three Arch-Chancellors and the Arch-Cupbearer did not use any augmentations.\n\nThe electors discharged the ceremonial duties associated with their offices only during coronations, where they bore the crown and regalia of the Empire. Otherwise, they were represented by holders of corresponding \"Hereditary Offices of the Household\". The Arch-Butler was represented by the Butler (Cupbearer) (the Count of Althann), the Arch-Seneschal by the Steward (the Count of Waldburg), the Arch-Chamberlain by the Chamberlain (the Count of Hohenzollern), the Arch-Marshal by the Marshal (the Count of Pappenheim), and the Arch-Treasurer by the Treasurer (the Count of Sinzendorf). The Duke of Württemberg assigned the count of Zeppelin-Aschhausen as hereditary Bannerbearer.\n\nThe German practice of electing monarchs began when ancient Germanic tribes formed \"ad hoc\" coalitions and elected the leaders thereof. Elections were irregularly held by the Franks, whose successor states include France and the Holy Roman Empire. The French monarchy eventually became hereditary, but the Holy Roman Emperors remained elective, at least in theory, although the Habsburgs provided most of the later monarchs. While all free men originally exercised the right to vote in such elections, suffrage eventually came to be limited to the leading men of the realm. In the election of Lothar II in 1125, a small number of eminent nobles chose the monarch and then submitted him to the remaining magnates for their approbation.\n\nSoon, the right to choose the monarch was settled on an exclusive group of princes, and the procedure of seeking the approval of the remaining nobles was abandoned. The college of electors was mentioned in 1152 and again in 1198. The composition of electors at that time is unclear, but appears to have included representatives of the church and the dukes of the four nations of Germany: the Franks (Duchy of Franconia), Swabians (Duchy of Swabia), Saxons (Duchy of Saxony) and Bavarians (Duchy of Bavaria).\n\nThe electoral college is known to have existed by 1152, but its composition is unknown. A letter written by Pope Urban IV in 1265 suggests that by \"immemorial custom\", seven princes had the right to elect the King and future Emperor. The pope wrote that the seven electors were those who had just voted in the election of 1257, which resulted in the election of two kings.\n\n\nThe three Archbishops oversaw the most venerable and powerful sees in Germany, while the other four were supposed to represent the dukes of the four nations. The Count Palatine of the Rhine held most of the former Duchy of Franconia after the last Duke died in 1039. The Margrave of Brandenburg became an Elector when the Duchy of Swabia was dissolved after the last Duke of Swabia was beheaded in 1268. Saxony, even with diminished territory, retained its eminent position.\n\nThe Palatinate and Bavaria were originally held by the same individual, but in 1253, they were divided between two members of the House of Wittelsbach. The other electors refused to allow two princes from the same dynasty to have electoral rights, so a heated rivalry arose between the Count Palatine and the Duke of Bavaria over who should hold the Wittelsbach seat.\n\nMeanwhile, the King of Bohemia, who held the ancient imperial office of Arch-Cupbearer, asserted his right to participate in elections. Sometimes he was challenged on the grounds that his kingdom was not German, though usually he was recognized, instead of Bavaria which after all was just a younger line of Wittelsbachs.\n\nThe Declaration of Rhense issued in 1338 had the effect that election by the majority of the electors automatically conferred the royal title and rule over the empire, without papal confirmation. The Golden Bull of 1356 finally resolved the disputes among the electors. Under it, the Archbishops of Mainz, Trier, and Cologne, as well as the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, and the Margrave of Brandenburg held the right to elect the King.\n\nThe college's composition remained unchanged until the 17th century, although the Electorate of Saxony was transferred from the senior to the junior branch of the Wettin family in 1547, in the aftermath of the Schmalkaldic War.\n\nIn 1621, the Elector Palatine, Frederick V, came under the imperial ban after participating in the Bohemian Revolt (a part of the Thirty Years' War). The Elector Palatine's seat was conferred on the Duke of Bavaria, the head of a junior branch of his family. Originally, the Duke held the electorate personally, but it was later made hereditary along with the duchy. When the Thirty Years' War concluded with the Peace of Westphalia in 1648, a new electorate was created for the Count Palatine of the Rhine. Since the Elector of Bavaria retained his seat, the number of electors increased to eight; the two Wittelsbach lines now sufficiently estranged so as not to pose a combined potential threat.\n\nIn 1685, the religious composition of the College of Electors was disrupted when a Catholic branch of the Wittelsbach family inherited the Palatinate. A new Protestant electorate was created in 1692 for the Duke of Brunswick-Lüneburg, who became known as the Elector of Hanover (the Imperial Diet officially confirmed the creation in 1708). The Elector of Saxony converted to Catholicism in 1697 so that he could become King of Poland, but no additional Protestant electors were created. Although the Elector of Saxony was personally Catholic, the Electorate itself remained officially Protestant, and the Elector even remained the leader of the Protestant body in the Reichstag.\n\nIn 1706, the Elector of Bavaria and Archbishop of Cologne were banned during the War of the Spanish Succession, but both were restored in 1714 after the Peace of Baden. In 1777, the number of electors was reduced to eight when the Elector Palatine inherited Bavaria.\n\nMany changes to the composition of the college were necessitated by Napoleon's aggression during the early 19th century. The Treaty of Lunéville (1801), which ceded territory on the Rhine's left bank to France, led to the abolition of the archbishoprics of Trier and Cologne, and the transfer of the remaining spiritual Elector from Mainz to Regensburg. In 1803, electorates were created for the Duke of Württemberg, the Margrave of Baden, the Landgrave of Hesse-Kassel, and the Duke of Salzburg, bringing the total number of electors to ten. When Austria annexed Salzburg under the Treaty of Pressburg (1805), the Duke of Salzburg moved to the Grand Duchy of Würzburg and retained his electorate. None of the new electors, however, had an opportunity to cast votes, as the Holy Roman Empire was abolished in 1806, and the new electorates were never confirmed by the Emperor.\n\nAfter the abolition of the Holy Roman Empire in August 1806, the Electors continued to reign over their territories, many of them taking higher titles. The Electors of Bavaria, Württemberg, and Saxony styled themselves Kings, while the Electors of Baden, Hesse-Darmstadt, Regensburg, and Würzburg became Grand Dukes. The Elector of Hesse-Kassel, however, retained the meaningless title \"Elector of Hesse\", thus distinguishing himself from other Hessian princes (the Grand Duke of Hesse-Darmstadt and the Landgrave of Hesse-Homburg). Napoleon soon exiled him and Kassel was annexed to the Kingdom of Westphalia, a new creation. The King of Great Britain remained at war with Napoleon and continued to style himself Elector of Hanover, while the Hanoverian government continued to operate in London.\n\nThe Congress of Vienna accepted the Electors of Bavaria, Württemberg, and Saxony as Kings, along with the newly created Grand Dukes. The Elector of Hanover finally joined his fellow Electors by declaring himself the King of Hanover. The restored Elector of Hesse, a Napoleonic creation, tried to be recognized as the King of the Chatti. However, the European powers refused to acknowledge this title at the Congress of Aix-la-Chapelle (1818) and instead listed him with the grand dukes as a \"Royal Highness\". Believing the title of Prince-Elector to be superior in dignity to that of Grand Duke, the Elector of Hesse-Kassel chose to remain an Elector, even though there was no longer a Holy Roman Emperor to elect. Hesse-Kassel remained the only Electorate in Germany until 1866, when the country backed the losing side in the Austro-Prussian War and was absorbed into Prussia.\n\nReligion was a factor in the election of the Holy Roman Emperor, as some Protestant electors would refuse to vote for a Roman Catholic and vice versa. Most of the time, religion played a minor role and was overshadowed by other factors, including dynastic, territorial and other political interests. For example, the Protestant Elector of Saxony voted for Ferdinand II, Archduke of Austria, putting his political interests first even though Ferdinand was a staunch Roman Catholic who would eventually lead the Empire into the Thirty Years' War.\n\nAt the height of the Protestant Reformation, there were times when the electoral college had a Protestant majority. However, all of the Holy Roman Emperors were Catholic. Some historians maintain that Ferdinand III had been touched by the reformed philosophies and was probably the closest the Holy Roman Empire ever came to a Protestant emperor; he remained nominally a Catholic throughout his life, although reportedly he refused last rites on his deathbed. Other historians maintain he was as Catholic as his brother, but tended to see religion as outside the political sphere.\n\n\n\n\n\nCoat of arms of the states granted the electoral dignity:\n\nThree ecclesiastic/spiritual electors (archbishops):\n\nFour secular electors:\n\nElectors added in 17th century:\n\nDuring the collapse of the Holy Roman Empire, between 1803 and 1806:\n\n\n\n"}
{"id": "14059", "url": "https://en.wikipedia.org/wiki?curid=14059", "title": "Howard Hughes", "text": "Howard Hughes\n\nHoward Robard Hughes Jr. (December 24, 1905 – April 5, 1976) was an American business magnate, investor, record-setting pilot, engineer, film director, and philanthropist, known during his lifetime as one of the most financially successful individuals in the world. He first became prominent as a film producer, and then as an influential figure in the aviation industry. Later in life, he became known for his eccentric behavior and reclusive lifestyle—oddities that were caused in part by a worsening obsessive–compulsive disorder (OCD), chronic pain from a near-fatal plane crash, and increasing deafness.\n\nAs a maverick film tycoon, Hughes gained fame in Hollywood beginning in the late 1920s, when he produced big-budget and often controversial films such as \"The Racket\" (1928), \"Hell's Angels\" (1930), and \"Scarface\" (1932). Later he controlled the RKO film studio.\n\nHughes formed the Hughes Aircraft Company in 1932, hiring numerous engineers and designers. He spent the rest of the 1930s and much of the 1940s setting multiple world air speed records and building the Hughes H-1 Racer and H-4 Hercules (the \"Spruce Goose\"). He acquired and expanded Trans World Airlines and later acquired Air West, renaming it Hughes Airwest. Hughes was included in \"Flying\" Magazine's list of the 51 Heroes of Aviation, ranked at 25. Today, his legacy is maintained through the Howard Hughes Medical Institute and the Howard Hughes Corporation.\n\nRecords locate the birthplace of Howard Hughes as either Humble or Houston, Texas. The date remains uncertain due to conflicting dates from various sources. He repeatedly claimed Christmas Eve as his birthday. A 1941 affidavit birth certificate of Hughes, signed by his aunt Annette Gano Lummis and by Estelle Boughton Sharp, states that he was born on December 24, 1905, in Harris County, Texas. However, his certificate of baptism, recorded on October 7, 1906 in the parish register of St. John's Episcopal Church in Keokuk, Iowa, listed his date of birth as September 24, 1905, without any reference to the place of birth.\n\nHughes was the son of Allene Stone Gano and of Howard R. Hughes Sr., a successful inventor and businessman from Missouri. He had English, Welsh and some French Huguenot ancestry, and was a descendant of John Gano (1727-1804), the minister who allegedly baptized George Washington. His father patented (1909) the two-cone roller bit, which allowed rotary drilling for petroleum in previously inaccessible places. The senior Hughes made the shrewd and lucrative decision to commercialize the invention by leasing the bits instead of selling them, obtained several early patents, and founded the Hughes Tool Company in 1909. Hughes' uncle was the famed novelist, screenwriter, and film-director Rupert Hughes.\n\nAt a young age, Hughes showed interest in science and technology. In particular, he had great engineering aptitude and built Houston's first \"wireless\" radio transmitter at age 11. He went on to be one of the first licensed ham-radio operators in Houston, having the assigned callsign W5CY (originally 5CY). At 12, Hughes was photographed in the local newspaper, identified as the first boy in Houston to have a \"motorized\" bicycle, which he had built from parts from his father's steam engine. He was an indifferent student, with a liking for mathematics, flying, and mechanics. He took his first flying lesson at 14, and attended Fessenden School in Massachusetts in 1921.\n\nHe later attended math and aeronautical engineering courses at Caltech. The red-brick house where Hughes lived as a teenager at 3921 Yoakum St., Houston became the headquarters of the Theology Department of the University of St. Thomas.\n\nHis mother Allene died in March 1922 from complications of an ectopic pregnancy. Howard Hughes Sr. died of a heart attack in 1924. Their deaths apparently inspired Hughes to include the establishment of a medical research laboratory in the will that he signed in 1925 at age 19. Howard Sr.'s will had not been updated since Allene's death, and Hughes inherited 75% of the family fortune. On his 19th birthday, Hughes was declared an emancipated minor, enabling him to take full control of his life.\n\nFrom a young age Hughes became a proficient and enthusiastic golfer. He often scored near-par figures, played the game to a two-three handicap during his 20s, and for a time aimed for a professional golf career. He golfed frequently with top players, including Gene Sarazen. Hughes rarely played competitively and gradually gave up his passion for the sport to pursue other interests. Hughes used to play golf every afternoon at LA courses including the Lakeside Golf Club, Wilshire Country Club, or the Bel-Air Country Club. Partners included George Von Elm or Ozzie Carlton. After Hughes hurt himself in the late 1920s, his golfing tapered off, and after his F-11 crash, Hughes was unable to play at all. \n\nHughes withdrew from Rice University shortly after his father's death. On June 1, 1925 he married Ella Botts Rice, daughter of David Rice and Martha Lawson Botts of Houston. They moved to Los Angeles, where he hoped to make a name for himself as a filmmaker.\n\nThey moved into the Ambassador Hotel, and Hughes proceeded to learn to fly a Waco, while simultaneously producing his first motion picture, \"Swell Hogan\".\n\nHughes enjoyed a highly successful business career beyond engineering, aviation, and filmmaking, though many of his career endeavors involved varying entrepreneurial roles. The Summa Corporation was the name adopted for the business interests of Howard Hughes after he sold the tool division of Hughes Tool Company in 1972. The company serves as the principal holding company for Hughes' business ventures and investments. It is primarily involved in aerospace and defense, electronics, mass media, manufacturing, and hospitality industries, but has maintained a strong presence in a wide variety of industries including real estate, petroleum drilling and oilfield services, consulting, entertainment, and engineering. Much of his fortune was later used for philanthropic causes, notably towards health care and medical research.\n\nHis first film, \"Swell Hogan\" directed by Ralph Graves, was a disaster. His next two films, \"Everybody's Acting\" (1926) and \"Two Arabian Knights\" (1927), were financial successes, the latter winning the first Academy Award for Best Director of a comedy picture. \"The Racket\" (1928) and \"The Front Page\" (1931) were also nominated for Academy Awards.\n\nHughes spent $3.5 million to make the flying film \"Hell's Angels\" (1930). \"Hell's Angels\" received one Academy Award nomination for Best Cinematography. \n\nHe produced another hit, \"Scarface (1932 film)\", a production delayed by censors' concern over its violence.\n\n\"The Outlaw\" premiered in 1943, but was not released nationally until 1946. The film featured Jane Russell, who received considerable attention from industry censors, this time owing to Russell's revealing costumes.\n\nDuring the 1940s to the late 1950s, the Hughes Tool Company ventured into the film industry when it obtained partial ownership of the RKO companies which included RKO Pictures, RKO Studios, a chain of movie theaters known as RKO Theatres and a network of radio stations known as the RKO Radio Network.\n\nIn 1948, Hughes gained control of RKO, a struggling major Hollywood studio, by acquiring the 929,000 shares owned by Floyd Odlum's Atlas Corporation, for $8,825,000. Within weeks of acquiring the studio, Hughes dismissed 700 employees. Production dwindled to 9 pictures that first year Hughes was in control, while before, RKO averaged 30 per year. \n\nProduction was shut down for six months during which time investigations were conducted of each employee who remained with RKO as far as their political leanings were concerned. Only after ensuring that the stars under contract to RKO had no suspect affiliations would Hughes approve completed pictures to be sent back for re-shooting. This was especially true of the women who were under contract to RKO at that time. If Hughes felt that his stars did not properly represent the political views of his liking or if a film's anti-communist politics were not sufficiently clear, he pulled the plug. In 1952, an abortive sale to a Chicago-based group connected to the mafia with no experience in the industry also disrupted studio operations at RKO even further.\n\nIn 1953, Hughes was involved with a high profile lawsuit as part of the settlement of the \"United States v. Paramount Pictures, Inc.\" Antitrust Case. As a result of the hearings, the shaky status of RKO became increasingly apparent. A steady stream of lawsuits from RKO's minority shareholders had grown to be extremely annoying to Hughes. They had accused him of financial misconduct and corporate mismanagement. Since Hughes wanted to focus primarily on his aircraft manufacturing and TWA holdings during the Korean War years, Hughes offered to buy out all other stockholders in order to dispense with their distractions.\n\nBy the end of 1954 Hughes had gained near-total control of RKO at a cost of nearly $24 million, becoming the closest thing to a sole owner of a Hollywood studio seen in three decades. Six months later, Hughes sold the studio to the General Tire and Rubber Company for $25 million. Hughes retained the rights to pictures that he had personally produced, including those made at RKO. He also retained Jane Russell's contract. For Howard Hughes, this was the virtual end of his 25-year involvement in the motion picture industry. However, his reputation as a financial wizard emerged unscathed. During that time period, RKO became known as the home of film noir classic productions thanks in part to the limited budgets required to make such films during Hughes' tenure. Hughes reportedly walked away from RKO having made $6.5 million in personal profit. According to Noah Dietrich, Hughes made a $10,000,000 profit from the sale of the theaters, and made a profit of $1,000,000 from his 7 year ownership of RKO.\n\nGeneral Tire was interested mainly in exploiting the value of the RKO library for television programming even though it made some attempts to continue producing films. After a year and a half of mixed success, General Tire shut down film production entirely at RKO at the end of January 1957. The studio lots in Hollywood and Culver City were sold to Desilu Productions later that year for $6.15 million.\n\nAccording to Noah Dietrich, \"Land became a principal asset for the Hughes empire.\" This investment sheltered the profits his companies made. Hughes acquired 1200 acres in Culver City for Hughes Aircraft, bought 7 sections in Tucson for his Falcon missile plant, and purchased 25,000 acres near Las Vegas.\n\nBeyond extending his business prowess in the manufacturing, aviation, entertainment, and hospitality industries, Hughes was a successful real estate investor. Hughes was deeply involved in the American real estate industry where he amassed vast holdings of undeveloped land both in Las Vegas and in the desert surrounding the city that had gone unused during his lifetime. In 1968, the Hughes Tool Company purchased the North Las Vegas Air Terminal.\n\nOriginally known as Summa Corporation, The Howard Hughes Corporation was formed in 1972 when the oil tools business of Hughes Tool Company, then owned by Howard Hughes Jr., was floated on the New York Stock Exchange under the Hughes Tool name. This forced the remaining businesses of the \"original\" Hughes Tool to adopt a new corporate name Summa. The name \"Summa\"Latin for \"highest\"was adopted without the approval of Hughes himself, who preferred to keep his own name on the business, and suggested HRH Properties (for Hughes Resorts and Hotels, and also his own initials). In 1988, Summa announced plans for Summerlin, a master-planned community named for the paternal grandmother of Howard Hughes, Jean Amelia Summerlin.\n\nInitially staying in the Desert Inn, Hughes refused to vacate his room, and instead decided to purchase the entire hotel. Hughes extended his financial empire to include Las Vegas real estate, hotels, and media outlets, spending an estimated $300 million, and using his considerable powers to take-over many of the well known hotels, especially the organized crime connected venues. He quickly became one of the most powerful men in Las Vegas. He was instrumental in changing the image of Las Vegas from its Wild West roots into a more refined cosmopolitan city.\n\nAnother portion of Hughes' business interests lay in aviation, airlines, and the aerospace and defense industries. Hughes was a lifelong aircraft enthusiast and pilot. He survived four airplane accidents: one in a Thomas-Morse Scout while filming \"Hell's Angels\", one while setting the air speed record in the Hughes Racer, one at Lake Mead in 1943, and the near fatal crash of the Hughes XF-11 in 1946. At Rogers Airport in Los Angeles, he learned to fly from pioneer aviators, including Moye Stephens and J.B. Alexander. He set many world records and commissioned the construction of custom aircraft for himself while heading Hughes Aircraft at the airport in Glendale, CA. Operating from there, the most technologically important aircraft he commissioned was the Hughes H-1 Racer. On September 13, 1935, Hughes, flying the H-1, set the landplane airspeed record of over his test course near Santa Ana, California (Giuseppe Motta reached 362 mph in 1929 and George Stainforth reached 407.5 mph in 1931, both in seaplanes). This was the last time in history that the world airspeed record was set in an aircraft built by a private individual. A year and a half later, on January 19, 1937, flying the same H-1 Racer fitted with longer wings, Hughes set a new transcontinental airspeed record by flying non-stop from Los Angeles to Newark in seven hours, 28 minutes, and 25 seconds (beating his own previous record of nine hours, 27 minutes). His average ground speed over the flight was .\n\nThe H-1 Racer featured a number of design innovations: it had retractable landing gear (as Boeing Monomail had five years before), and all rivets and joints set flush into the body of the aircraft to reduce drag. The H-1 Racer is thought to have influenced the design of a number of World War II fighters such as the Mitsubishi A6M Zero, Focke-Wulf Fw 190, and F8F Bearcat, although that has never been reliably confirmed. The H-1 Racer was donated to the Smithsonian.\n\nOn July 14, 1938, Hughes set another record by completing a flight around the world in just 91 hours (three days, 19 hours, 17 minutes), beating the previous record set in 1933 by Wiley Post in a single engine Lockheed Vega by almost four days. Hughes returned home ahead of photographs of his flight. Taking off from New York City, Hughes continued to Paris, Moscow, Omsk, Yakutsk, Fairbanks, Minneapolis, then returning to New York City. For this flight he flew a Lockheed 14 Super Electra (NX18973, a twin-engine transport with a four-man crew) fitted with the latest radio and navigational equipment. Harry Connor was the co-pilot, Thomas Thurlow the navigator, Richard Stoddart the engineer, and Ed Lund the mechanic. Hughes wanted the flight to be a triumph of American aviation technology, illustrating that safe, long-distance air travel was possible. Albert Lodwick of Mystic, Iowa provided organizational skills as the flight operations manager. While he had previously been relatively obscure despite his wealth, being better known for dating Katharine Hepburn, New York City now gave Hughes a ticker-tape parade in the Canyon of Heroes. In 1938, the William P. Hobby Airport in Houston, Texas—known at the time as Houston Municipal Airport—was renamed after Hughes, but the name was changed back after people objected to naming the airport after a living person. \nHughes also had a role in the design and financing of both the Boeing 307 Stratoliner and Lockheed L-049 Constellation.\n\nHe received many awards as an aviator, including the Harmon Trophy in 1936 and 1938, the Collier Trophy and the Bibesco Cup of the Fédération Aéronautique Internationale in 1938, the Octave Chanute Award in 1940, and a special Congressional Gold Medal in 1939 \"in recognition of the achievements of Howard Hughes in advancing the science of aviation and thus bringing great credit to his country throughout the world.\" \n\nPresident Harry S. Truman sent the Congressional medal to Hughes after the F-11 crash. After his around-the-world flight, Hughes had declined to go to the White House to collect it.\n\nThe Hughes D-2 was conceived in 1939 as a bomber with five crew members, powered by 42-cylinder Wright R-2160 Tornado engines. In the end it appeared as two-seat fighter-reconnaissance aircraft designated the D-2A, powered by two Pratt & Whitney R-2800-49 engines. The aircraft was constructed using the Duramold process. The prototype was brought to Harper's Dry Lake California in great secrecy in 1943 and first flew on June 20 of that year. Acting on a recommendation of the president's son, Colonel Elliott Roosevelt, who had become friends with Hughes, in September 1943 the USAAF ordered 100 of a reconnaissance development of the D-2, known as the F-11. Hughes then attempted to get the military to pay for the development of the D-2. In November 1944, the hangar containing the D-2A was reportedly hit by lightning and the aircraft was destroyed. The D-2 design was abandoned, but led to the extremely controversial Hughes XF-11. The XF-11 was a large all-metal, two-seat reconnaissance aircraft, powered by two Pratt & Whitney R-4360-31 engines, each driving a set of contra-rotating propellers. Only the two prototypes were completed; the second one with a single propeller per side.\n\nIn the spring of 1943 Hughes spent nearly a month in Las Vegas, test flying his Sikorsky S-43 amphibian aircraft, practicing touch-and-go landings on Lake Mead in preparation for flying the H-4 Hercules. The weather conditions at the lake during the day were ideal and he enjoyed Las Vegas at night. On May 17, 1943, Hughes flew the Sikorsky from California carrying two CAA aviation inspectors, two of his employees, and actress Ava Gardner. Hughes dropped Gardner off in Las Vegas and proceeded to Lake Mead to conduct qualifying tests in the S-43. The test flight did not go well. The Sikorsky crashed into Lake Mead, killing CAA inspector Ceco Cline and Hughes' employee Richard Felt. Hughes suffered a severe gash on the top of his head when he hit the upper control panel and had to be rescued by one of the others on board. Hughes paid divers $100,000 to raise the aircraft and later spent more than $500,000 restoring it. Hughes sent the plane to Houston, where it sat for many years.\n\nHughes was involved in another near-fatal aircraft accident on July 7, 1946, while performing the first flight of the prototype U.S. Army Air Forces reconnaissance aircraft, the XF-11, near Hughes airfield at Culver City, California. An oil leak caused one of the contra-rotating propellers to reverse pitch, causing the aircraft to yaw sharply and lose altitude rapidly. Hughes attempted to save the aircraft by landing it at the Los Angeles Country Club golf course, but just seconds before reaching the course, the XF-11 started to drop dramatically and crashed in the Beverly Hills neighborhood surrounding the country club.\n\nWhen the XF-11 finally came to a halt after destroying three houses, the fuel tanks exploded, setting fire to the aircraft and a nearby home at 808 North Whittier Drive, owned by Lt Col. Charles E. Meyer. Hughes managed to pull himself out of the flaming wreckage but lay beside the aircraft until he was rescued by Marine Master Sgt. William L. Durkin, who happened to be in the area visiting friends. Hughes sustained significant injuries in the crash, including a crushed collar bone, multiple cracked ribs, crushed chest with collapsed left lung, shifting his heart to the right side of the chest cavity, and numerous third-degree burns. An oft-told story said that Hughes sent a check to the Marine weekly for the remainder of his life as a sign of gratitude. However, Durkin's daughter denied knowing that he received any money from his rescue of Hughes. Yet, Noah Dietrich asserts that Hughes did send Durkin $200 a month.\n\nDespite his physical injuries, Hughes was proud that his mind was still working. As he lay in his hospital bed, he decided that he did not like the bed's design. He called in plant engineers to design a customized bed, equipped with hot and cold running water, built in six sections, and operated by 30 electric motors, with push-button adjustments. The hospital bed was designed by Hughes specifically to alleviate the pain caused by moving with severe burn injuries. Although he never used the bed that he designed, Hughes' bed served as a prototype for the modern hospital bed. Hughes' doctors considered his recovery almost miraculous. Hughes, however, believed that neither miracle nor modern medicine contributed to his recovery, instead asserting the natural life-giving properties of fresh-squeezed orange juice were responsible.\n\nMany attribute his long-term dependence on opiates to his use of codeine as a painkiller during his convalescence. Yet, Noah Dietrich asserts that Hughes recovered the \"hard way - no sleeping pills, no opiates of any kind.\" The trademark mustache he wore afterward was used to hide a scar on his upper lip resulting from the accident.\n\nThe War Production Board (not the military) originally contracted with Henry Kaiser and Hughes to produce the gigantic HK-1 Hercules flying boat for use during World War II to transport troops and equipment across the Atlantic as an alternative to seagoing troop transport ships that were vulnerable to German U-boats. The project was opposed by the military services, thinking it would siphon resources from higher priority programs, but was advocated by Hughes' powerful allies in Washington, D.C. After disputes, Kaiser withdrew from the project and Hughes elected to continue it as the H-4 Hercules. However, the aircraft was not completed until after the end of World War II.\n\nThe Hercules was the world's largest flying boat, the largest aircraft made from wood, and, at , had the longest wingspan of any aircraft (the next largest wingspan was about ). (The Hercules is no longer the longest nor heaviest aircraft ever built; both of those titles are currently held by the Antonov An-225 \"Mriya\".)\n\nThe Hercules flew only once for one mile (1.6 km), and above the water, with Hughes at the controls, on November 2, 1947.\n\nThe Hercules was nicknamed the \"Spruce Goose\" by its critics, but it was actually made largely from birch, not spruce, rather than of aluminum, because the contract required that Hughes build the aircraft of \"non-strategic materials\". It was built in Hughes' Westchester, California, facility. In 1947, Howard Hughes was summoned to testify before the Senate War Investigating Committee to explain why the H-4 development had been so troubled, and why $22 million had produced only two prototypes of the XF-11. General Elliott Roosevelt and numerous other USAAF officers were also called to testify in hearings that transfixed the nation during August and November 1947. In hotly disputed testimony over TWA's route awards and malfeasance in the defense acquisition process, Hughes turned the tables on his main interlocutor, Maine Senator Owen Brewster, and the hearings were widely interpreted as a Hughes victory. After being displayed at the harbor of Long Beach, California, the Hercules was moved to McMinnville, Oregon, where it is now part of the Evergreen Aviation & Space Museum.\n\nOn November 4, 2017, the 70th anniversary of the only flight of the H-4 Hercules was celebrated at the Evergreen Aviation & Space Museum with Hughes' paternal cousin Michael Wesley Summerlin and Brian Palmer Evans, son of Hughes radio technology pioneer Dave Evans, taking their positions in the recreation of a photo that was previously taken of Hughes, Dave Evans and Joe Petrali on board the H-4 Hercules.\n\nHughes Aircraft Company, a division of Hughes Tool Company, was founded by Hughes in 1932, in a rented corner of a Lockheed Aircraft Corporation hangar in Burbank, California, to build the H-1 racer. During and after World War II, Hughes fashioned his company into a major defense contractor. The Hughes Helicopters division started in 1947 when helicopter manufacturer Kellett sold their latest design to Hughes for production. The company was a major American aerospace and defense contractor manufacturing numerous technology related products that include spacecraft vehicles, military aircraft, radar systems, electro-optical systems, the first working laser, aircraft computer systems, missile systems, ion-propulsion engines (for space travel), commercial satellites, and other electronics systems.\n\nIn 1948, Hughes created a new division of the company: the Hughes Aerospace Group. The Hughes Space and Communications Group and the Hughes Space Systems Division were later spun off in 1948 to form their own divisions and ultimately became the Hughes Space and Communications Company in 1961. In 1953, Howard Hughes gave all his stock in the Hughes Aircraft Company to the newly formed Howard Hughes Medical Institute, thereby turning the aerospace and defense contractor into a tax-exempt charitable organization. The Howard Hughes Medical Institute sold Hughes Aircraft in 1985 to General Motors for $5.2 billion. In 1997, General Motors sold Hughes Aircraft to Raytheon and in 2000, sold Hughes Space & Communications to Boeing. A combination of Boeing, GM, and Raytheon acquired the Hughes Research Laboratories, where it focused on advanced developments in microelectronics, information & systems sciences, materials, sensors, and photonics; their workspace spans from basic research to product delivery. It has particularly emphasized capabilities in high performance integrated circuits, high power lasers, antennas, networking, and smart materials.\n\nIn 1939, at the urging of Jack Frye, president of Trans World Airlines (TWA), Hughes began to quietly purchase a majority share of TWA stock, and took a controlling interest in the airline by 1944. Although he never had an official position with TWA, Hughes handpicked the board of directors, which included Noah Dietrich, and often issued orders directly to airline staff. Hughes Tool Co. purchased the first 6 Stratoliners Boeing manufactured. Hughes used one personally, and the other 5 he let TWA operate.\n\nHughes is commonly credited as the driving force behind the Lockheed Constellation airliner, which Hughes and Frye ordered in 1939 as a long-range replacement for TWA's fleet of Boeing 307 Stratoliners, Hughes personally financed TWA's acquisition of 40 Constellations for $18 million, the largest aircraft order in history up to that time. The Constellations were among the highest-performing commercial aircraft of the late 1940s and 1950s, and allowed TWA to pioneer nonstop transcontinental service. During World War II, Hughes leveraged political connections in Washington to obtain rights for TWA to serve Europe, making it the only U.S. carrier with a combination of domestic and transatlantic routes.\n\nAfter the Boeing 707 was announced, Hughes opted to pursue a more unique jet aircraft for TWA and approached Convair in late 1954. Convair proposed two concepts to Hughes, but Hughes was unable to decide which concept to adopt, and Convair eventually abandoned its initial jet project after the mockups of the 707 and Douglas DC-8 were unveiled. Even after competitors such as United Airlines, American Airlines and Pan American World Airways had placed large orders for the 707, Hughes only placed eight orders for 707s through the Hughes Tool Company and forbade TWA from using the aircraft. After finally beginning to reserve 707 orders in 1956, Hughes embarked on a plan to build his own \"superior\" jet aircraft for TWA, applied for CAB permission to sell Hughes aircraft to TWA, and began negotiations with the state of Florida to build a manufacturing plant there. However, he abandoned this plan around 1958, and in the interim, negotiated new contracts for 707 and Convair 880 aircraft and engines totaling $400 million.\n\nThe financing of TWA's jet orders precipitated the end of Hughes' relationship with Noah Dietrich, and ultimately Hughes's ouster from control of TWA. Hughes did not have enough cash on hand or future cash flow to pay for the orders, and did not immediately seek bank financing. Hughes's refusal to heed Dietrich's financing advice led to a major rift between the two by the end of 1956. Hughes believed that Dietrich wished to have Hughes committed as mentally incompetent, although the evidence of this is inconclusive. Dietrich resigned by telephone in May 1957 after repeated requests for stock options, which Hughes refused to grant, and with no further progress on the jet financing. As Hughes's mental state worsened, he ordered various tactics to delay payments to Boeing and Convair; his behavior led TWA's banks to insist that he be removed from management as a condition for further financing.\n\nIn 1960, Hughes was ultimately forced out of management of TWA, although he continued to own 78% of the company. In 1961, TWA filed suit against Hughes Tool Company, claiming that the latter had violated antitrust law by using TWA as a captive market for aircraft trading. The claim was largely dependent upon obtaining testimony from Hughes himself. Hughes went into hiding and refused to testify. A default judgment was issued against Hughes Tool Company for $135 million in 1963, but was overturned by the Supreme Court of the United States in 1973, on the basis that Hughes was immune from prosecution. In 1966, Hughes was forced to sell his TWA shares. The sale of his TWA shares brought Hughes $546,549,771.\n\nHughes acquired control of Boston-based Northeast Airlines in 1962. However, the airline's lucrative route authority between major northeastern cities and Miami was terminated by a CAB decision around the time of the acquisition, and Hughes sold control of the company to a trustee in 1964. Northeast went on to merge with Delta Air Lines in 1972.\n\nIn 1970, Hughes acquired San Francisco-based Air West and renamed it Hughes Airwest. Air West had been formed in 1968 by the merger of Bonanza Air Lines, Pacific Air Lines, and West Coast Airlines, all of which operated in the western U.S. By the late 1970s, Hughes Airwest operated an all-jet fleet of Boeing 727-200, Douglas DC-9-10, and McDonnell Douglas DC-9-30 jetliners serving an extensive route network in the western U.S. with flights to Mexico and western Canada as well. By 1980, the airline's route system reached as far east as Houston (Hobby Airport) and Milwaukee with a total of 42 destinations being served. Hughes Airwest was then acquired by and merged into Republic Airlines (1979–1986) in late 1980. Republic was subsequently acquired by and merged into Northwest Airlines which in turn was ultimately merged into Delta Air Lines in 2008.\n\nHughes had made numerous business partnerships through industrialist and producer, David Charnay. Their friendship and many partnerships began with the film \"The Conqueror\", which was first released to the public in 1956. The film caused many controversies due to its critical flop and radioactive location used in St. George, Utah that eventually led to Hughes buying up nearly every copy of the film he could, only to watch the film at home repeatedly for many nights in a row. Charnay later bought the Four Star, the film and television production company that produced \"The Conqueror.\" Hughes and Charnay's most published dealings were with a contested AirWest leveraged buyout (LBO). Charnay led the LBO buyout group that involved Howard Hughes and their partners acquiring Air West. Hughes, Charnay, as well as three others were indicted. The complexity of this LBO was the first of its kind. The indictment, made by U.S. Attorney DeVoe Heaton, accused the group of conspiring to drive down the stock price of Air West in order to pressure company directors to sell to Hughes. The charges were dismissed after a judge had determined that the indictment had failed to allege an illegal action on the part of Hughes, Charnay, and all the other accused in the indictment. Thompson, the federal judge that made the decision to dismiss the charges called the indictment one of the worst claims that he had ever seen. The charges were filed again, a second time, by U.S. Attorney DeVoe Heaton's assistant, Dean Vernon. The Federal Judge ruled on November 13, 1974 and elaborated to say that the case suggested a \"reprehensible misuse of the power of great wealth\", but in his judicial opinion, \"no crime had been committed.\" The aftermath of the Air West deal was later settled with the SEC by paying former stockholders for alleged losses from the sale of their investment in Air West stock. As noted above, Air West was subsequently renamed Hughes Airwest. During a long pause between the years of the dismissed charges against Hughes, Charnay, and their partners, Howard Hughes had mysteriously died mid-flight while on the way to Houston from Acapulco. No further attempts were made to file any indictments after Hughes had died.\n\nIn 1953, Hughes launched the Howard Hughes Medical Institute in Miami, Florida (currently located in Chevy Chase, Maryland) with the expressed goal of basic biomedical research, including trying to understand, in Hughes' words, the \"genesis of life itself,\" due to his lifelong interest in science and technology. Hughes' first will, which he signed in 1925 at the age of 19, stipulated that a portion of his estate should be used to create a medical institute bearing his name. When a major battle with the IRS loomed ahead, Hughes gave all his stock in the Hughes Aircraft Company to the institute, thereby turning the aerospace and defense contractor into a for-profit entity of a fully tax-exempt charity. Hughes' internist, Verne Mason, who treated Hughes after his 1946 aircraft crash, was chairman of the institute's medical advisory committee. The Howard Hughes Medical Institute's new board of trustees sold Hughes Aircraft in 1985 to General Motors for $5.2 billion, allowing the institute to grow dramatically.\n\nIn 1954, Hughes transferred Hughes Aircraft to the foundation, which paid Hughes Tool Co. $18,000,000 for the assets. The foundation leased the land from Hughes Tool Co., which then subleased it to Hughes Aircraft Corp. The difference in rent, $2,00,000 per year, became the foundation's working capital.\n\nThe deal was the topic of a protracted legal battle between Hughes and the Internal Revenue Service, which Hughes ultimately won. After his death in 1976, many thought that the balance of Hughes' estate would go to the institute, although it was ultimately divided among his cousins and other heirs, given the lack of a will to the contrary. The HHMI was the fourth largest private organization and the largest devoted to biological and medical research, with an endowment of $16.3 billion .\n\nIn 1972, during the cold war era, Hughes was approached by the CIA through his longtime partner, David Charnay, to help secretly recover the Soviet submarine K-129, which had sunk near Hawaii four years earlier. Hughes' involvement provided the CIA with a plausible cover story, conducting expensive civilian marine research at extreme depths and the mining of undersea manganese nodules. The recovery plan used the special-purpose salvage vessel \"Glomar Explorer\". In the summer of 1974, \"Glomar Explorer\" attempted to raise the Soviet vessel. However, during the recovery a mechanical failure in the ship's grapple caused half of the submarine to break off and fall to the ocean floor. This section is believed to have held many of the most sought-after items, including its code book and nuclear missiles. Two nuclear-tipped torpedoes and some cryptographic machines were recovered, along with the bodies of six Soviet submariners who were subsequently given formal burial at sea in a filmed ceremony. The operation, known as Project Azorian (but incorrectly referred to by the press as Project Jennifer), became public in February 1975 after secret documents were released, obtained by burglars of Hughes' headquarters during a burglary in June 1974. Although he lent his name and his company's resources to the operation, Hughes and his companies had no operational involvement in the project. The \"Glomar Explorer\" was eventually acquired by Transocean Inc. (an offshore oil and gas drilling rig company) and was sent to the scrap yard in 2015 during a large decline in oil prices.\n\nIn 1929, Hughes' wife, Ella, returned to Houston and filed for divorce. Hughes dated many famous women, including Billie Dove, Faith Domergue, Bette Davis, Ava Gardner, Olivia de Havilland, Katharine Hepburn, Hedy Lamarr, Ginger Rogers, Janet Leigh, Rita Hayworth, Mamie Van Doren and Gene Tierney. He also proposed to Joan Fontaine several times, according to her autobiography \"No Bed of Roses\". Jean Harlow accompanied him to the premiere of \"Hell's Angels\", but Noah Dietrich wrote many years later that the relationship was strictly professional, as Hughes apparently personally disliked Harlow. In his 1971 book, \"Howard: The Amazing Mr. Hughes\", Dietrich said that Hughes genuinely liked and respected Jane Russell, but never sought romantic involvement with her. According to Russell's autobiography, however, Hughes once tried to bed her after a party. Russell (who was married at the time) refused him, and Hughes promised it would never happen again. The two maintained a professional and private friendship for many years. Hughes remained good friends with Tierney who, after his failed attempts to seduce her, was quoted as saying \"I don't think Howard could love anything that did not have a motor in it.\" Later, when Tierney's daughter Daria was born deaf and blind and with a severe learning disability because of Tierney's being exposed to rubella during her pregnancy, Hughes saw to it that Daria received the best medical care and paid all expenses.\n\nIn 1933, Hughes made a purchase of an unseen luxury steam yacht named the \"Rover\", which was previously owned by British shipping magnate Lord Inchcape. \"I have never seen the \"Rover\" but bought it on the blue prints, photographs and the reports of Lloyd's surveyors. My experience is that the English are the most honest race in the world.\" Hughes renamed the yacht \"Southern Cross\" and later sold her to Swedish entrepreneur Axel Wenner-Gren.\n\nOn July 11, 1936, Hughes struck and killed a pedestrian named Gabriel S. Meyer with his car at the corner of 3rd Street and Lorraine in Los Angeles. After the crash, Hughes was taken to the hospital and certified as sober, but an attending doctor made a note that Hughes had been drinking. A witness to the crash told police that Hughes was driving erratically and too fast, and that Meyer had been standing in the safety zone of a streetcar stop. Hughes was booked on suspicion of negligent homicide and held overnight in jail until his attorney, Neil S. McCarthy, obtained a writ of habeas corpus for his release pending a coroner's inquest. By the time of the coroner's inquiry, however, the witness had changed his story and claimed that Meyer had moved directly in front of Hughes' car. Nancy Bayly (Watts), who was in the car with Hughes at the time of the crash, corroborated this version of the story. On July 16, 1936, Hughes was held blameless by a coroner's jury at the inquest into Meyer's death. Hughes told reporters outside the inquiry, \"I was driving slowly and a man stepped out of the darkness in front of me.\"\n\nDuring his 1954 engagement at the Last Frontier hotel, entertainer Liberace mistook Hughes for his lighting director, instructing him to instantly bring up a blue light should he start to play \"Clair de lune\". Hughes nodded in compliance, before the hotel's entertainment director arrived and introduced Hughes to Liberace.\n\nOn January 12, 1957, Hughes married actress Jean Peters at a small hotel in Tonopah, Nevada. The couple met in the 1940s, before Peters became a film actress. They had a highly publicized romance in 1947 and there was talk of marriage, but she said she could not combine it with her career. Some later claimed that Peters was \"the only woman [Hughes] ever loved,\" and he reportedly had his security officers follow her everywhere even when they were not in a relationship. Such reports were confirmed by actor Max Showalter, who became a close friend of Peters while shooting \"Niagara\" (1953). Showalter told in an interview that because he frequently met with Peters, Hughes' men threatened to ruin his career if he did not leave her alone.\n\nShortly before the 1960 Presidential election, Richard Nixon was alarmed when it was revealed that his brother, Donald, received a $205,000 loan from Hughes. It has long been speculated that Nixon's drive to learn what the Democrats were planning in 1972 was based in part on his belief that the Democrats knew about a later bribe that his friend Bebe Rebozo had received from Hughes after Nixon took office.\n\nIn late 1971, Donald Nixon was collecting intelligence for his brother in preparation for the upcoming presidential election. One of his sources was John H. Meier, a former business adviser of Hughes who had also worked with Democratic National Committee Chair Larry O'Brien.\n\nMeier, in collaboration with former Vice President Hubert Humphrey and others, wanted to feed misinformation to the Nixon campaign. Meier told Donald that he was sure the Democrats would win the election because Larry O'Brien had a great deal of information on Richard Nixon's illicit dealings with Howard Hughes that had never been released; O'Brien did not actually have any such information, but Meier wanted Nixon to think he did. Donald told his brother that O'Brien was in possession of damaging Hughes information that could destroy his campaign. Terry Lenzner, who was the chief investigator for the Senate Watergate Committee, speculates that it was Nixon's desire to know what O'Brien knew about Nixon's dealings with Hughes that may have partially motivated the Watergate break-in.\n\nHughes was eccentric, and suffered from a severe obsessive-compulsive disorder (OCD). \n\nDietrich wrote that Hughes only ate the same thing for dinner, a New York strip steak cooked medium rare, dinner salad, and peas, but only the smaller ones, pushing the larger ones aside. For breakfast, Hughes wanted his eggs cooked the way his family cook, Lily, made them. Hughes had a \"phobia about germs\", and \"his passion for secrecy became a mania.\"\n\nWhile directing \"The Outlaw\", Hughes became fixated on a small flaw in one of Jane Russell's blouses, claiming that the fabric bunched up along a seam and gave the appearance of two nipples on each breast. He wrote a detailed memorandum to the crew on how to fix the problem. Richard Fleischer, who directed \"His Kind of Woman\" with Hughes as executive producer, wrote at length in his autobiography about the difficulty of dealing with the tycoon. In his book, \"Just Tell Me When to Cry\", Fleischer explained that Hughes was fixated on trivial details and was alternately indecisive and obstinate. He also revealed that Hughes' unpredictable mood swings made him wonder if the film would ever be completed.\n\nIn 1958, Hughes told his aides that he wanted to screen some movies at a film studio near his home. He stayed in the studio's darkened screening room for more than four months, never leaving. He ate only chocolate bars and chicken and drank only milk, and was surrounded by dozens of Kleenex boxes that he continuously stacked and re-arranged. He wrote detailed memos to his aides giving them explicit instructions neither to look at him nor speak to him unless spoken to. Throughout this period, Hughes sat fixated in his chair, often naked, continually watching movies. When he finally emerged in the summer of 1958, his hygiene was terrible. He had neither bathed nor cut his hair and nails for weeks; this may have been due to allodynia, which results in a pain response to stimuli that would normally not cause pain.\n\nAfter the screening room incident, Hughes moved into a bungalow at the Beverly Hills Hotel where he also rented rooms for his aides, his wife, and numerous girlfriends. He would sit naked in his bedroom with a pink hotel napkin placed over his genitals, watching movies. This may have been because Hughes found the touch of clothing painful due to allodynia. He may have watched movies to distract himself from his pain—a common practice among patients with intractable pain, especially those who do not receive adequate treatment. In one year, Hughes spent an estimated $11 million at the hotel.\n\nHughes began purchasing all restaurant chains and four star hotels that had been founded within the state of Texas. This included, if for only a short period, many unknown franchises currently out of business. He placed ownership of the restaurants with the Howard Hughes Medical Institute, and all licenses were resold shortly after.\n\nAnother time, he became obsessed with the 1968 film \"Ice Station Zebra\", and had it run on a continuous loop in his home. According to his aides, he watched it 150 times.\n\nHughes insisted on using tissues to pick up objects to insulate himself from germs. He would also notice dust, stains, or other imperfections on people's clothes and demand that they take care of them. Once one of the most visible men in America, Hughes ultimately vanished from public view, although tabloids continued to follow rumors of his behavior and whereabouts. He was reported to be terminally ill, mentally unstable, or even dead.\n\nInjuries from numerous aircraft crashes caused Hughes to spend much of his later life in pain, and he eventually became addicted to codeine, which he injected intramuscularly. Hughes had his hair cut and nails trimmed only once a year, likely due to the pain caused by the RSD/CRPS, which was caused by the plane crashes. He also stored his urine in bottles.\n\nThe wealthy and aging Hughes, accompanied by his entourage of personal aides, began moving from one hotel to another, always taking up residence in the top floor penthouse. In the last ten years of his life, 1966 to 1976, Hughes lived in hotels in many cities—including Beverly Hills, Boston, Las Vegas, Nassau, Freeport, Vancouver, London, Managua, and Acapulco.\n\nOn November 24, 1966 (Thanksgiving Day), Hughes arrived in Las Vegas by railroad car and moved into the Desert Inn. Because he refused to leave the hotel and to avoid further conflicts with the owners, Hughes bought the Desert Inn in early 1967. The hotel's eighth floor became the nerve center of Hughes' empire and the ninth-floor penthouse became his personal residence. Between 1966 and 1968, he bought several other hotel-casinos, including the Castaways, New Frontier, the Landmark Hotel and Casino, and the Sands. He bought the small Silver Slipper casino for the sole purpose of moving its trademark neon silver slipper; visible from Hughes' bedroom, it had apparently kept him awake at night.\n\nAfter Hughes left the Desert Inn, hotel employees discovered that his drapes had not been opened during the time he lived there and had rotted through. \n\nHughes wanted to change the image of Las Vegas to something more glamorous. As Hughes wrote in a memo to an aide, \"I like to think of Las Vegas in terms of a well-dressed man in a dinner jacket and a beautifully jeweled and furred female getting out of an expensive car.\" Hughes bought several local television stations (including KLAS-TV).\n\nHughes' considerable business holdings were overseen by a small panel unofficially dubbed \"The Mormon Mafia\" because of the many Latter-day Saints on the committee, led by Frank William Gay. In addition to supervising day-to-day business operations and Hughes' health, they also went to great pains to satisfy Hughes' every whim. For example, Hughes once became fond of Baskin-Robbins' banana nut ice cream, so his aides sought to secure a bulk shipment for him, only to discover that Baskin-Robbins had discontinued the flavor. They put in a request for the smallest amount the company could provide for a special order, 350 gallons (1,300 L), and had it shipped from Los Angeles. A few days after the order arrived, Hughes announced he was tired of banana nut and wanted only French vanilla ice cream. The Desert Inn ended up distributing free banana nut ice cream to casino customers for a year. In a 1996 interview, ex–Howard Hughes communicator Robert Maheu said, \"There is a rumor that there is still some banana nut ice cream left in the freezer. It is most likely true.\"\n\nAs an owner of several major Las Vegas businesses, Hughes wielded much political and economic influence in Nevada and elsewhere. During the 1960s and early 1970s, he disapproved of underground nuclear testing at the Nevada Test Site. Hughes was concerned about the risk from residual nuclear radiation, and attempted to halt the tests. When the tests finally went through despite Hughes' efforts, the detonations were powerful enough that the entire hotel where he was staying trembled due to the shock waves. In two separate, last-ditch maneuvers, Hughes instructed his representatives to offer million-dollar bribes to both presidents Lyndon B. Johnson and Richard Nixon.\n\nIn 1970, Jean Peters filed for divorce. The two had not lived together for many years. Peters requested a lifetime alimony payment of $70,000 a year, adjusted for inflation, and waived all claims to Hughes' estate. Hughes offered her a settlement of over a million dollars, but she declined it. Hughes did not insist on a confidentiality agreement from Peters as a condition of the divorce. Aides reported that Hughes never spoke ill of her. She refused to discuss her life with Hughes and declined several lucrative offers from publishers and biographers. Peters would state only that she had not seen Hughes for several years before their divorce and had only dealt with him by phone.\n\nHughes was living in the Intercontinental Hotel near Lake Managua in Nicaragua, seeking privacy and security, when a magnitude 6.5 earthquake damaged Managua in December 1972. As a precaution, Hughes moved first to a rather large tent, facing the hotel, then after a few days there to the Nicaraguan National Palace and stayed there as a guest of Anastasio Somoza Debayle before leaving for Florida on a private jet the following day. He subsequently moved into the Penthouse at the Xanadu Princess Resort on Grand Bahama Island, which he had recently purchased. He lived almost exclusively in the penthouse of the Xanadu Beach Resort & Marina for the last four years of his life. Hughes had spent a total of $300 million on his many properties in Las Vegas.\n\nIn 1972, author Clifford Irving caused a media sensation when he claimed he had co-written an authorized autobiography of Hughes. Hughes was so reclusive that he did not immediately publicly refute Irving's statement, leading many to believe the Irving book was genuine. However, before the book's publication, Hughes finally denounced Irving in a teleconference and the entire project was eventually exposed as a hoax. Irving was later convicted of fraud and spent 17 months in prison. In 1974, the Orson Welles film \"F for Fake\" included a section on the Hughes biography hoax, leaving a question open as to whether it was actually Hughes who took part in the teleconference (since so few people had actually heard or seen him in recent years). In 1977, \"The Hoax\" by Clifford Irving was published in the United Kingdom, telling his story of these events. The 2006 film \"The Hoax\", starring Richard Gere, is also based on these events.\n\nHughes was reported to have died on April 5, 1976, at 1:27 p.m. on board an aircraft owned by Robert Graf and piloted by Jeff Abrams. He was en route from his penthouse at the Acapulco Fairmont Princess Hotel in Mexico to the Methodist Hospital in Houston. Other accounts indicate that he died on the flight from Freeport, Grand Bahama, to Houston.\n\nAfter receiving a call, his senior counsel, Frank P. Morse, ordered his staff to get his body on a plane and return him to the United States. It was common that foreign countries would hold a corpse as ransom so that an estate could not be settled. Morse ordered the pilots to announce Hughes' death once they entered U.S. airspace.\n\nHis reclusiveness and possible drug use made him practically unrecognizable. His hair, beard, fingernails, and toenails were long—his tall frame now weighed barely , and the FBI had to use fingerprints to conclusively identify the body. Howard Hughes' alias, John T. Conover, was used when his body arrived at a morgue in Houston on the day of his death.\n\nA subsequent autopsy recorded kidney failure as the cause of death. Hughes was in extremely poor physical condition at the time of his death. He suffered from malnutrition. While his kidneys were damaged, his other internal organs, including his brain, were deemed perfectly healthy. X-rays revealed five broken-off hypodermic needles in the flesh of his arms. To inject codeine into his muscles, Hughes had used glass syringes with metal needles that easily became detached.\n\nHughes is buried next to his parents at Glenwood Cemetery in Houston.\n\nApproximately three weeks after Hughes' death, a handwritten will was found on the desk of an official of The Church of Jesus Christ of Latter-Day Saints in Salt Lake City, Utah. The so-called \"Mormon Will\" gave $1.56 billion to various charitable organizations (including $625 million to the Howard Hughes Medical Institute), nearly $470 million to the upper management in Hughes' companies and to his aides, $156 million to first cousin William Lummis, and $156 million split equally between his two ex-wives Ella Rice and Jean Peters.\n\nIn this will, Hughes left his entire estate to the Hughes Medical Institute, as he had no connection to family and was seriously ill. This is contrary to the many wills that have surfaced after his death. The original will that included payments to aides never surfaced. It was apparently in a home surrounding the Desert Inn Golf Course belonging to the mother of an assistant. He had no desire to leave any money to family, aides or churches, including William Gay and Frank Morse. Hughes was not Mormon and had no reason to leave his estate to that church. Frank P. Morse is still the attorney of record for Hughes.\n\nA further $156 million was endowed to a gas-station owner, Melvin Dummar, who told reporters that in 1967, he found a disheveled and dirty man lying along U.S. Route 95, just north of Las Vegas. The man asked for a ride to Vegas. Dropping him off at the Sands Hotel, Dummar said the man told him that he was Hughes. Dummar later claimed that days after Hughes' death a \"mysterious man\" appeared at his gas station, leaving an envelope containing the will on his desk. Unsure if the will was genuine and unsure of what to do, Dummar left the will at the LDS Church office. In 1978, a Nevada court ruled the Mormon Will a forgery, and officially declared that Hughes had died intestate (without a valid will). Dummar's story was later adapted into Jonathan Demme's film \"Melvin and Howard\" in 1980.\n\nHughes' $2.5 billion estate was eventually split in 1983 among 22 cousins, including William Lummis, who serves as a trustee of the Howard Hughes Medical Institute. The Supreme Court of the United States ruled that Hughes Aircraft was owned by the Howard Hughes Medical Institute, which sold it to General Motors in 1985 for $5.2 billion. The court rejected suits by the states of California and Texas that claimed they were owed inheritance tax. In 1984 Hughes' estate paid an undisclosed amount to Terry Moore, who claimed she and Hughes had secretly married on a yacht in international waters off Mexico in 1949 and never divorced. Moore never produced proof of a marriage, but her book, \"The Beauty and the Billionaire,\" became a bestseller.\n\n\nThe moving image collection of Howard Hughes is held at the Academy Film Archive. The collection consists of over 200 items including 35mm and 16mm elements of feature films, documentaries, and television programs made or accumulated by Hughes.\n\n\n\n\n\n"}
{"id": "14062", "url": "https://en.wikipedia.org/wiki?curid=14062", "title": "Hook of Holland", "text": "Hook of Holland\n\nThe Hook of Holland (, ) is a town in the southwestern corner of Holland (hence the name; \"hoek\" means \"corner\"), at the mouth of the New Waterway shipping canal into the North Sea. The town is administered by the municipality of Rotterdam as a district of that city. Its district covers an area of 16.7 km, of which 13.92 km is land. On 1 January 1999 it had an estimated population of 9,400.\n\nTowns near \"the Hook\" () include Monster, 's-Gravenzande, Naaldwijk and Delft to the northeast, and Maassluis to the southeast. On the other side of the river is the Europort and the Maasvlakte. The wide sandy beach, one section of which is designated for use by naturists, runs for approximately 18 kilometres to Scheveningen and for most of this distance is backed by extensive sand dunes through which there are foot and cycle paths.\n\nOn the north side of the New Waterway, to the west of the town, is a pier part of which is accessible to pedestrians and cyclists.\n\nThe Berghaven is a small harbour on the New Waterway where the Rotterdam and Europort pilots are based. This small harbour is only for the use of the pilot service, government vessels and the Hook of Holland lifeboat.\n\nDuring World War II this was one of the most important places for the Germans to hold because of the harbour.\n\nThe Schiedam–Hoek van Holland railway is a 24-kilometre branch line from Schiedam Centrum station via Vlaardingen and Maassluis. The final two stations on the line are located within the town. Hoek van Holland Haven, the penultimate station, is close to the town centre, adjacent to the ferry terminal and the small harbour, the Berghaven. Hoek van Holland Strand, the terminus, is closest to the beach.\n\nThe railway line opened for service in 1893 and was electrified in 1935. International trains ran from Berlin and Moscow to connect these with London via the ferry service. Services on the line to Rotterdam Centraal station were being operated by NS every half hour during the day until April 2017, when the line was closed for conversion to metro standards. It is expected to reopen in September 2018 as an extension of the Rotterdam Metro, but will not connect directly to Rotterdam Centraal as a change will be necessary.\n\nHoek van Holland is also the location of an international ferry terminal, where service to eastern England has operated from since 1893, uninterrupted except for during the two World Wars. Currently, two routes are being operated: one, a day and night freight and passenger service, to Harwich, Essex and the other, a night, freight-only service to North Killingholme Haven, Lincolnshire. The passenger ferry service is operated by Stena Line as part of the Dutchflyer rail-ferry service between Hook van Holland Haven station and Harwich International station in England, from which Greater Anglia provides service to Liverpool Street station in central London.\n\nA local ferry operated by RET links the Hook with the Maasvlakte part of the Port of Rotterdam.\n\nThe A20 motorway begins approximately 10 kilometres east of Hoek van Holland near Westerlee, heading east towards Rotterdam and Utrecht. It connects to the A4 heading north towards the Hague and Amsterdam 17 kilometres east of the town.\n\n\n"}
{"id": "14063", "url": "https://en.wikipedia.org/wiki?curid=14063", "title": "Hugh Binning", "text": "Hugh Binning\n\nHugh Binning (1627–1653) was a Scottish philosopher and theologian. Binning was born in Scotland during the reign of Charles I, ordained in the (Presbyterian) Church of Scotland and died during the time of Oliver Cromwell and the Commonwealth of England.\n\nA precocious child, Binning at age 13 was admitted to the study of philosophy at the University of Glasgow. By the age of 19, he was appointed regent and professor of philosophy at the University of Glasgow. Three years later, he was called to be minister and presided at a church in Govan, adjacent to the city of Glasgow; a post he held until his untimely death of consumption at the age of 26. He was a follower of James Dalrymple. In later life he was well known as an evangelical Christian.\n\nHugh Binning was born two years after Charles I ascended to the thrones of England, Ireland, and Scotland. At the time, each was an independent country sharing the same monarch. The Acts of Union 1707 integrated Scotland and England to form the Kingdom of Great Britain; the Acts of Union 1800 integrated Ireland to form United Kingdom of Great Britain and Ireland.\n\nThe period was dominated by both political and religious strife between the three independent countries. The religious dispute centered on whether religion was to be dictated by the monarch or was to be the choice of the people; whether people have a direct relationship with God or they needed to use an intermediary. The civil disputes centered on the extent of the king's power, a question of the Divine right of kings; specifically whether the King has right to raise taxes and armed forces without the Consent of the governed. These wars ultimately changed the relationship between king and subjects.\n\nIn 1638 the General Assembly of the Church of Scotland voted to remove bishops and the Book of Common Prayer that had been introduced by Charles I to impose the Anglican model on the Presbyterian Church of Scotland. Public riots occurred. The result was the Wars of the Three Kingdoms, an interrelated series of conflicts that took place in the three countries sharing the same monarch. The first of the conflicts was in 1639, the First of the Bishops' Wars, a single border skirmish between England and Scotland; also known as \"the war the armys did not wanted to fight.\"\n\nTo maintain his English power base Charles I made secret alliances with Catholic Ireland and Presbyterian Scotland to invade Anglican England, promising that each country could establish their own separate state religion. Once these secret entreaties became known to the English Long Parliament, the Congregationalist faction (of which Oliver Cromwell was a primary spokesman) took matters into their own hands and Parliament established an army separate from the King. Then, Charles I was executed in January 1649, which led to the rule of Cromwell and the establishment of the Commonwealth. The conflicts concluded with The English Restoration of the monarchy with the return of Charles II, in 1660.\n\nThe Act of Classes was passed by the Parliament of Scotland on 23 January 1649; the act banned Royalists (people supporting the monarchy) from holding political or military office. In exile, Charles II signed the Treaty of Breda (1650) with the Scottish Parliament; among other things, the treaty established Presbyterianism as the national religion. Charles was crowned King of Scots at Scone in January 1651. By September 1651 Scotland was annexed by England, its legislative institutions abolished, Presbyterianism dis-established, and Charles was forced into exile in France.\n\nThe Scottish Parliament rescinded the Act of Classes in 1651, which produced a split within Scottish Society. The sides of the conflict were called the Resolutioners (who supported the rescission of the act – supported the monarchy and the Scottish House of Stewart) and the Protesters (who supported Cromwell and the Commonwealth); Binning sided with the Protestors.\n\nWhen Cromwell sent troops to Scotland, he was also attempting to dis-establish Presbyterianism and the Church of Scotland, Binning spoke against Cromwell's act. On Saturday 19 April 1651, Cromwell entered Glasgow and the next day he heard a sermon by three ministers who condemned Cromwell for invading Scotland. That evening, Cromwell summoned those ministers and others, to a debate on the issue. At the debate, Rev Hugh Binning is said to have out-debated Cromwell's ministers so completely that he silenced Cromwell's ministers.\n\nHugh Binning political views were based on his theology. Binning was a Covenanter, a movement that began in Scotland at Greyfriars Kirkyard in 1638 with the National Covenant and continued with the 1643 Solemn League and Covenant – in effect a treaty between the English Long Parliament and Scotland for the preservation of the reformed religion in exchange for troops to confront the threat of Irish Catholic troops joining the Royalist army. Binning could also be described as a Protestor; both political positions were taken because of their religious implications. However, he saw the evils of the politics of his day was not a “fomenter of factions” writing “A Treatise of Christian Love” as a response.\n\nBecause of the turmoil time in which Hugh Binning lived, politics and religion were inexorably intertwined. Binning was a Calvinist and follower of John Knox. As a profession, Binning was trained as a Philosopher, and he believed that philosophy was the servant of theology. He thought that both Philosophy and Theology should be taught in parallel. Binning's writing, which are primarily a collection of his sermons, “forms an important bridge between the 17th century, when philosophy in Scotland was heavily dominated by Calvinism, and the 18th century when figures such as Francis Hutcheson re-asserted a greater degree of independence between the two and allied philosophy with the developing human sciences.”\nReligiously, Hugh Binning was, what we would call today, an Evangelical Calvinist. He spoke on the primacy of God's love as the ground of salvation: \n\nWith regards to the extent of the ‘atonement’, Hugh Binning, did not hold that the offer of redemption applied only to the few that are elect but said that “the ultimate ground of faith is in the electing will of God.” In Scotland during the 1600s the questions concerning atonement revolved around the terms in which the offer was expressed.\n\nBinning believed that \"forgiveness is based on Christ's death, understood as a satisfaction and as a sacrifice: 'If he had pardoned sin without any satisfaction what rich grace it had\nbeen! But truly, to provide the Lamb and sacrifice himself, to find out\nthe ransom, and to exact it of his own Son, in our name, is a testimony\nof mercy and grace far beyond that. But then, his justice is very conspicuous\nin this work.'\"\n\nAll of the works of Hugh Binning were published posthumously and were primarily collections of his sermons. Of his speaking style, it was said: \"There is originality without any affectation, a rich imagination, without anything fanciful or extravert, the utmost simplicity, without an thing mean or trifling.\" \n\n\nHugh Binning was the son of John Binning and Margaret M'Kell. Margaret was the daughter of Rev. Matthew M'Kell,\nwho was a minister in the parish of Bothwell, Scotland, and sister of Hugh M'Kell, a minister in Edinburgh.\nHugh Binning was born on the estate of his father in Dalvennan, Straiton, in the shire of Ayr. The family owned other land in the parishes of Straiton and Colmonell as well as Maybole in Carrick. \nIn 1645, James Dalrymple, 1st Viscount of Stair, who was Hugh's master (primary professor) in the study of philosophy, announced he was retiring from the University of Glasgow. After a national search for a replacement on the faculty, three men were selected to compete for the position. Hugh was one of those selected, but was at a disadvantage because of his extreme youth and because he was not of noble birth. However, he had strong support from the existing faculty, who suggested that the candidates speak extemporaneously on any topic of the candidate's choice. After hearing Hugh speak, the other candidates withdrew, making Hugh a regent and professor of philosophy, while he was still 18 years old.\n\nOn 7 February 1648 (at the age of 21) Hugh was appointed an Advocate before the Court of Sessions (an attorney). In the same year he married Barbara Simpson (sometimes called Mary), daughter of Rev. James Simpson a minister in Ireland. Their son, John, was born in 1650.\n\nHugh died around September 1653 and was buried in the churchyard of Govan, where Patrick Gillespie, then principal of the University of Glasgow, ordered a monument inscribed in Latin, roughly translated: \n\nHugh's widow, Barbara (sometimes called Mary), then remarried James Gordon, an Anglican priest at Cumber in Ireland. Together they had a daughter, Jean who married Daniel MacKenzie, who was on the winning side of the Battle of Bothwell Bridge serving as an ensign under Lieutenant-Colonel William Ramsay (who became the third Earl of Dalhousie), in the Earl of Mar's Regiment of Foot.\n\nHugh's son, John Binning, married Hanna Keir, who was born in Ireland. The Binning's were Covenanters, a resistance movement that objected to the return of Charles II (who was received into the Catholic Church on his deathbed). They were on the losing side in the 1679 Battle of Bothwell Bridge. Most of the rebels who were not executed were exiled to the Americas; about 30 Covenanters were exiled to the Carolinas on the Carolina Merchant in 1684. After the battle, John and Hanna were separated. \nIn the aftermath of the battle at Bothwell Bridge, Hugh's widow (now Barbara Gordon) tried to reclaim the family estate at Dalvennan by saying that John and his wife owed his step father a considerable some of money. The legal action was successful and Dalvennan became the possession of John's half sister Jean, and her husband Daniel MacKenzie. In addition, Jean came into possession Hanna Keir's property in Ireland.\n\nBy 1683, Jean was widowed. John Binning was branded a traitor, was sentenced to death and forfeited his property to the Crown. John's wife (Hanna Keir) was branded as a traitor and forfeited her property in Ireland. In 1685 Jean \"donated\" the Binning family's home at Dalvennan and other properties, along with the Keir properties to Roderick MacKenzie, who was a Scottish advocate of James II (James VII of Scotland), and the baillie of Carrick. According to an act of the Scottish Parliament, Roderick MacKenzie was also very effective in “suppressing the rebellious, fanatical party in the western and other shires of this realm, and putting the laws to vigorous execution against them”\n\nSince Bothwell Bridge, Hanna had been hiding from the authorities. In 1685 Hanna was in Edinburgh where she was found during a sweep for subversives and imprisoned in the Tolbooth of Edinburgh, a combination city hall and prison. Those arrested with Hanna were exiled to North America, however she developed Dysentery and remained behind. By 1687, near death, Hanna petitioned the Privy Council of Scotland for her release; she was exiled to her family in Ireland, where she died around 1692.\nIn 1690 the Scottish Parliament rescinded John's fines and forfeiture, but he was not able to recover his family's estates, the courts suggesting that John had relinquished his claim to Dalvennan in exchange for forgiveness of debt, rather than forfeiture.\n\nThere is little documentation about John after his wife's death. John received a small income from royalties on his father Hugh's works after parliament extended copyrights on Hugh's writings to him. However, the income was not significant and John made several petitions to the Scottish parliament for money, the last occurring in 1717. It is thought that John died in Somerset county, in southwestern England. \n\n"}
{"id": "14064", "url": "https://en.wikipedia.org/wiki?curid=14064", "title": "Henry Home, Lord Kames", "text": "Henry Home, Lord Kames\n\nHenry Home, Lord Kames (169627 December 1782) was a Scottish advocate, judge, philosopher, writer and agricultural improver. A central figure of the Scottish Enlightenment, a founder member of the Philosophical Society of Edinburgh, and active in the Select Society, his protégés included David Hume, Adam Smith, and James Boswell.\n\nBorn at Kames House, between Eccles and Birgham, Berwickshire, he was educated at home by a private tutor. He studied law at Edinburgh, was called to the bar in 1724, and became an advocate. He soon acquired reputation by a number of publications on the civil and Scottish law, and was one of the leaders of the Scottish Enlightenment. In 1752, he was \"raised to the bench\", thus acquiring the title of Lord Kames.\n\nHome was on the panel of judges in the Joseph Knight case which ruled that there could be no slavery in Scotland.\n\nHis address in 1775 is shown as New Street on the Canongate.\n\nHe is buried in the Home-Drummond plot at Kincardine-in-Menteith just west of Blair Drummond.\n\nHome wrote much about the importance of property to society. In his \"Essay Upon Several Subjects Concerning British Antiquities\", written just after the Jacobite rising of 1745 he described how the politics of Scotland were not based on loyalty to Kings or Queens as Jacobites had said but on royal land grants given in return for loyalty.\n\nIn \"Historical Law Tracts\" and later in \"Sketches on the History of Man\" he described human history as having four distinct stages. The first was as a hunter-gatherer where people avoided each other out of competition. The second stage he described was a herder of domestic animals which required forming larger societies. No laws were needed at these stages except those given by the head of the family or society. Agriculture was the third stage requiring greater cooperation and new relationships to allow for trade or employment (or slavery). He argued that 'the intimate union among a multitude of individuals, occasioned by agriculture' required a new set of rights and obligations in society. This requires laws and law enforcers. A fourth stage moves from villages and farms to seaports and market towns requiring yet more laws and complexity but also much to benefit from. Kames could see these stages within Scotland itself, with the pastoral/agricultural highlands, the agricultural/industrial lowlands and the growing commercial (\"polite\") towns of Glasgow and Edinburgh.\n\nHome was a polygenist, he believed God had created different races on earth in separate regions. In his book \"Sketches of the History of Man\", in 1774, Home claimed that the environment, climate, or state of society could not account for racial differences, so that the races must have come from distinct, separate stocks.\n\nThe above studies created the genre of the story of civilization and defined the fields of anthropology and sociology and therefore the modern study of history for two hundred years.\n\nIn the popular book \"Elements of Criticism\" (1762) Home interrogated the notion of fixed or arbitrary rules of literary composition, and endeavoured to establish a new theory based on the principles of human nature. The late eighteenth-century tradition of sentimental writing was associated with his notion that 'the genuine rules of criticism are all of them derived from the human heart. Prof Neil Rhodes has argued that Lord Kames played a significant role in the development of English as an academic discipline in the Scottish Universities.\n\nHe enjoyed intelligent conversation and cultivated a large number of intellectual associates, among them John Home, David Hume and James Boswell.. Lord Monboddo was also a frequent debater of Kames, although these two usually had a fiercely competitive and adversarial relationship.\n\n\n\n"}
{"id": "14065", "url": "https://en.wikipedia.org/wiki?curid=14065", "title": "Harwich", "text": "Harwich\n\nHarwich is a town in Essex, England and one of the Haven ports, located on the coast with the North Sea to the east. It is in the Tendring district. Nearby places include Felixstowe to the northeast, Ipswich to the northwest, Colchester to the southwest and Clacton-on-Sea to the south. It is the northernmost coastal town within Essex.\n\nIts position on the estuaries of the Stour and Orwell rivers and its usefulness to mariners as the only safe anchorage between the Thames and the Humber led to a long period of maritime significance, both civil and military. The town became a naval base in 1657 and was heavily fortified, with Harwich Redoubt, Beacon Hill Battery, and Bath Side Battery.\n\nHarwich is the likely launch point of the \"Mayflower\" which carried English Puritans to North America, and is the presumed birthplace of \"Mayflower\" captain Christopher Jones.\n\nHarwich today is contiguous with Dovercourt and the two, along with Parkeston, are often referred to collectively as Harwich.\n\nThe town's name means \"military settlement\", from Old English \"here-wic\".\n\nThe town received its charter in 1238, although there is evidence of earlier settlement – for example, a record of a chapel in 1177, and some indications of a possible Roman presence.\n\nBecause of its strategic position, Harwich was the target for the invasion of Britain by William of Orange on 11 November 1688. However, unfavourable winds forced his fleet to sail into the English Channel instead and eventually land at Torbay. Due to the involvement of the Schomberg family in the invasion, Charles Louis Schomberg was made Marquess of Harwich.\n\nWriter Daniel Defoe devotes a few pages to the town in \"A tour thro' the Whole Island of Great Britain\". Visiting in 1722, he noted its formidable fort and harbour \"of a vast extent\". The town, he recounts, was also known for an unusual chalybeate spring rising on Beacon Hill (a promontory to the north-east of the town), which \"petrified\" clay, allowing it to be used to pave Harwich's streets and build its walls. The locals also claimed that \"the same spring is said to turn wood into iron\", but Defoe put this down to the presence of \"copperas\" in the water. Regarding the atmosphere of the town, he states: \"Harwich is a town of hurry and business, not much of gaiety and pleasure; yet the inhabitants seem warm in their nests and some of them are very wealthy\".\n\nHarwich played an important part in the Napoleonic and more especially the two world wars. Of particular note:\n\n1793-1815—Post Office Station for communication with Europe, one of embarkation and evacuation bases for expeditions to Holland in 1799, 1809 and 1813/14; base for capturing enemy privateers. The dockyard built many ships for the Navy, including HMS \"Conqueror\" which captured the French Admiral Villeneuve at the Battle of Trafalgar. The Redoubt and the now-demolished Ordnance Building date from that era.\n\n1914-18—base for the Royal Navy's Harwich Force light cruisers and destroyers under Commodore Tyrwhitt, and for British submarines. In November 1918 the German U-Boat fleet surrendered to the Royal Navy in the harbour.\n\n1939-1945—one of main East Coast minesweeping and destroyer bases, at one period base for British and French submarines; assembled fleets for Dutch and Dunkirk evacuations and follow-up to D-Day; unusually a target in 1940 for Italian bombers.\n\nHarwich Dockyard was established as a Royal Navy Dockyard in 1652. It ceased to operate as a Royal Dockyard in 1713 (though a Royal Navy presence was maintained until 1829). During the various wars with France and Holland, through to 1815, the dockyard was responsible for both building and repairing numerous warships. HMS \"Conqueror\", a 74-gun ship completed in 1801, captured the French admiral Villeneuve at Trafalgar.\nThe yard was then a semi-private concern, with the actual shipbuilding contracted to Joseph Graham, who was sometimes mayor of the town.\nDuring World War II parts of Harwich were again requisitioned for naval use and ships were based at HMS \"Badger\"; \"Badger\" was decommissioned in 1946, but the Royal Naval Auxiliary Service maintained a headquarters on the site until 1992.\n\nThe Royal Navy no longer has a presence in Harwich but Harwich International Port at nearby Parkeston continues to offer regular ferry services to the Hook of Holland (Hoek van Holland) in the Netherlands. Many operations of the Port of Felixstowe and of Trinity House, the lighthouse authority, are managed from Harwich.\n\nThe port is famous for the phrase \"Harwich for the Continent\", seen on road signs and in London & North Eastern Railway (LNER) advertisements.\n\nAt least three pairs of lighthouses have been built over recent centuries as leading lights, to help guide vessels into Harwich. The earliest pair were wooden structures: the High Light stood on top of the old Town Gate, whilst the Low Light (featured in a painting by Constable) stood on the foreshore. Both were coal-fired.\n\nIn 1818 these were replaced by stone structures, designed by John Rennie Senior, which can still be seen today (they no longer function as lighthouses: one houses the town's maritime museum, the other is (in 2015) also being converted into a museum). They were owned by General Rebow of Wivenhoe Park, who was able to charge 1d per ton on all cargo entering the port, for upkeep of the lights. In 1836 Rebow's lease on the lights was purchased by Trinity House, but in 1863 they were declared redundant due to a change the position of the channel used by ships entering and leaving the port, caused by shifting sands.\n\nThey were in turn replaced by the pair of cast iron lights at nearby Dovercourt; these too remain in situ, but were decommissioned (again due to shifting of the channel) in 1917.\n\nDespite, or perhaps because of, its small size Harwich is highly regarded in terms of architectural heritage, and the whole of the older part of the town, excluding Navyard Wharf, is a conservation area.\n\nThe regular street plan with principal thoroughfares connected by numerous small alleys indicates the town's medieval origins, although many buildings of this period are hidden behind 18th century facades.\nThe extant medieval structures are largely private homes. The house featured in the image of Kings Head St to the left is unique in the town and is an example of a sailmaker's house, thought to have been built circa 1600. Notable public buildings include the parish church of St. Nicholas (1821) in a restrained Gothic style, with many original furnishings, including a somewhat altered organ in the west end gallery. There is also the Guildhall of 1769, the only Grade I listed building in Harwich.\nThe Pier Hotel of 1860 and the building that was the Great Eastern Hotel of 1864 can both been seen on the quayside, both reflecting the town's new importance to travellers following the arrival of the Great Eastern Main Line from Colchester in 1854. In 1923, The Great Eastern Hotel was closed by the newly formed LNER, as the Great Eastern Railway had opened a new hotel with the same name at the new passenger port at Parkeston Quay, causing a decline in numbers.\nThe hotel became the Harwich Town Hall, which included the Magistrates Court and, following changes in local government, was sold and divided into apartments.\n\nAlso of interest are the High Lighthouse (1818), the unusual Treadwheel Crane (late 17th century), the Old Custom Houses on West Street, a number of Victorian shopfronts and the Electric Palace Cinema (1911), one of the oldest purpose-built cinemas to survive complete with its ornamental frontage and original projection room still intact and operational.\nThere is little notable building from the later parts of the 20th century, but major recent additions include the lifeboat station and two new structures for Trinity House. The Trinity House office building, next door to the Old Custom Houses, was completed in 2005. All three additions are influenced by the high-tech style.\n\nHarwich has also historically hosted a number of notable inhabitants, linked with Harwich's maritime past.\n\n\n\nHarwich is home to Harwich & Parkeston F.C.; Harwich and Dovercourt RFC; Harwich Rangers FC; Harwich & Dovercourt Sailing Club; Harwich, Dovercourt & Parkeston Swimming Club; Harwich & Dovercourt Rugby Union Football Club; Harwich & Dovercourt Cricket Club; and Harwich Runners who with support from Harwich Swimming Club host the annual Harwich Triathlons.\n\n\n"}
{"id": "14067", "url": "https://en.wikipedia.org/wiki?curid=14067", "title": "Hendrick Avercamp", "text": "Hendrick Avercamp\n\nHendrick Avercamp (January 27, 1585 (bapt.) – May 15, 1634 (buried)) was a Dutch painter. Avercamp was born in Amsterdam, where he studied with the Danish-born portrait painter Pieter Isaacks (1569–1625), and perhaps also with David Vinckboons. In 1608 he moved from Amsterdam to Kampen in the province of Overijssel. Avercamp was deaf and mute and was known as \"de Stomme van Kampen\" (the mute of Kampen).\n\nAs one of the first landscape painters of the 17th-century Dutch school, he specialized in painting the Netherlands in winter. Avercamp's paintings are colorful and lively, with carefully crafted images of the people in the landscape. Many of Avercamp's paintings feature people ice skating on frozen lakes.\n\nAvercamp's work enjoyed great popularity and he sold his drawings, many of which were tinted with water-color, as finished pictures to be pasted into the albums of collectors. The Royal Collection has an outstanding collection of his works.\n\nAvercamp died in Kampen and was interred there in the Sint Nicolaaskerk.\n\nAvercamp probably painted in his studio on the basis of sketches he had made in the winter.\nAvercamp is famous even abroad for his winter landscapes. The passion for painting skating characters probably came from his childhood: he was practicing this hobby with his parents. The last quarter of the 16th century, during which Avercamp was born, was one of the coldest periods of the Little Ice Age.\n\nThe Flemish painting tradition is mainly expressed in Avercamp's early work. This is consistent with the landscapes of Pieter Bruegel the Elder. Avercamp painted landscapes with a high horizon and many figures who are working on something. The paintings are narrative, with many anecdotes. For instance, naughty details are included in the painting \"Winter landscape with skaters\": a couple making love, buttocks and a peeing male. \n\nLater in his life drawing the atmosphere was also important in his work. The horizon also gradually dropped down under more and more air.\n\nAvercamp used the painting technique of aerial perspective. The depth is suggested by change of color in the distance. To the front objects are painted, such as trees or a boat. This technique strengthens the impression of depth in the painting.\n\nAvercamp has also painted cattle and seascapes.\n\nSometimes Avercamp used paper frames, which were a cheap alternative to oil paintings. He first drew with pen and ink. This work was then covered with finishing paint. The contours of the drawing remained. Even with this technique Avercamp could show the pale wintry colors and nuances of the ice .\n\nAvercamp produced about a hundred paintings. The bulk of his artwork can be seen in the Rijksmuseum in Amsterdam, the Mauritshuis in The Hague and abroad. \nFrom November 20, 2009 to February 15, 2010 the Rijksmuseum presented an exhibition of his work entitled \"Little Ice Age\".\n\n"}
{"id": "14068", "url": "https://en.wikipedia.org/wiki?curid=14068", "title": "Hans Baldung", "text": "Hans Baldung\n\nHans Baldung Grien or Grün ( September 1545) was a German artist in painting and printmaking who was considered the most gifted student of Albrecht Dürer. Throughout his lifetime, Baldung developed a distinctive style, full of color, expression and imagination. His talents were varied, and he produced a great and extensive variety of work including portraits, woodcuts, altarpieces, drawings, tapestries, allegories and mythological motifs.\n\nHans Baldung was born in Swabia, Germany around the year 1484 to a family of intellectuals, academics and professionals. His father was a lawyer and his uncle was a doctor, and many other of his family members maintained professional degrees. In fact, Baldung was the first male in his family not to attend university, but was one of the first German artists to come from an academic family. His earliest training as an artist began around 1500 in the Upper Rhineland by an artist from Strasbourg.\n\nBeginning in 1503, Baldung was an apprentice for the most well renowned German artist of the day: Albrecht Dürer. Here, he may have been given his nickname “Grien.” This name is thought to have come foremost from a preference to the color green: he seems to have worn green clothing. He probably also got this nickname to distinguish him from at least two other Hanses in Dürer's shop, Hans Schäufelein and Hans Suess von Kulmbach. He later included the name \"Grien\" in his monogram, and it has also been suggested that the name came from, or consciously echoed, \"grienhals\", a German word for witch—one of his signature themes. Hans quickly picked up Dürer's influence and style, and they became good friends: Baldung managed Dürer's workshop during the latter's second sojourn in Venice. In his later trip to the Netherlands in 1521 Dürer's diary shows that he took with him and sold prints by Baldung. On Dürer's death Baldung was sent a lock of his hair, which suggests a close friendship. Near the end of his apprenticeship, Grien oversaw the production of stained glass, woodcuts and engravings, and therefore developed an affinity for them.\n\nIn 1509, when Baldung’s apprenticeship was complete, he moved back to Strasbourg and became a citizen there. He became a celebrity of the town, and received many important commissions. The following year he married Margarethe Herlin, a local merchant's daughter, joined the guild \"zur Steltz\", opened a workshop, and began signing his works with the HGB monogram that he used for the rest of his career. His style also became much more deliberately individual—a tendency some art historians have termed \"mannerist.\"\n\nIn addition to traditional religious subjects, Baldung was concerned during these years with the profane theme of the imminence of death and with scenes of sorcery and witchcraft. He helped introduce supernatural and erotic themes into German art, although these were already amply present in his master's work. Most famously, he depicted witches, also a local interest: Strasbourg's humanists studied witchcraft and its bishop was charged with finding and prosecuting witches. His most characteristic paintings are small in scale; a series of puzzling, often erotic allegories and mythological works. The number of Hans Baldung's religious works diminished with the Protestant Reformation, which generally repudiated church art as either wasteful or idolatrous. But earlier, around the same time that he produced Adam and Eve, the artist became interested in themes related to death, the supernatural, witchcraft, sorcery, and the relation between the sexes. Baldung’s fascination with witchcraft lasted to the end of his career.\n\nHans Baldung Grien's work depicting witches was produced in the first half of the 16th century, before witch hunting became a widespread cultural phenomenon in Europe. Thus Baldung's work did not represent cultural beliefs at the time of creation but largely individual choices. Furthermore, Baldung never worked directly with any Reformation leaders to spread religious ideals through his artwork, although living in fervently religious Strasbourg, although he was a supporter of the movement, working on the high altar in the city of Münster, Germany.\n\nBaldung was the first artist to heavily incorporate witches and witchcraft into his artwork (his mentor Albrecht Dürer had sporadically included them but not as prominently as Baldung would). During his lifetime there were minimal witch trials, as well as a lack of witch manuals or witch hunts, therefore, some believe Baldung's depictions of witchcraft to be based on folklore rather than the cultural beliefs of his time. By contrast, throughout the early sixteenth century, humanism became very popular, and within this movement, Latin literature was valorized, particularly poetry and satire. Baldung partook in this culture, producing not only many works depicting Strasbourg humanists and scenes from ancient art and literature, but what some have described as his satirical take on his depiction of witches. Gert von der Osten comments on this aspect of \"Baldung [treating] his witches humorously, an attitude that reflects the dominant viewpoint of the humanists in Strasbourg at this time who viewed witchcraft as 'lustig,' a matter that was more amusing than serious\". Furthermore, his art simultaneously represents ideals presented in ancient Greek and Roman poetry, such as the pre-16th century notion that witches could control the weather, which Baldung is believed to have alluded to in his 1523 oil painting \"Weather Witches\", which showcases two attractive and naked witches in front of a stormy sky.\n\nBaldung also regularly incorporated scenes of witches flying in his art, a characteristic that had been contested centuries before his artwork came into being. Flying was inherently attributed to witches by those who believed in the myth of the Sabbath (without their ability to fly, the myth fragmented), such as Baldung, which he depicted in works like \"Witches Preparing for the Sabbath Flight\" (1514).\n\nThroughout his life, Baldung painted numerous portraits, known for their sharp characterizations. While Dürer rigorously details his models, Baldung's style differs by focusing more on the personality of the represented character, an abstract conception of the model's state of mind. Baldung settled eventually in Strasbourg and then to Freiburg im Breisgau, where he executed what is held to be his masterpiece. Here in painted an eleven-panel altarpiece for the Freiburg Cathedral, still intact today, depicting scenes from the life of the Virgin, including, The Annunciation, The Visitation, The Nativity, The Flight into Egypt, The Crucifixion, Four Saints and The Donators. These depictions were a large part of the artist’s greater body of work containing several renowned pieces of the Virgin.\n\nThe earliest pictures assigned to him by some are altar-pieces with the monogram H. B. interlaced, and the date of 1496, in the monastery chapel of Lichtenthal near Baden-Baden. Another early work is a portrait of the emperor Maximilian, drawn in 1501 on a leaf of a sketch-book now in the print-room at Karlsruhe. \"The Martyrdom of St Sebastian and the Epiphany\" (now Berlin, 1507), were painted for the market-church of Halle in Saxony.\n\nBaldung's prints, though Düreresque, are very individual in style, and often in subject. They show little direct Italian influence. His paintings are less important than his prints. He worked mainly in woodcut, although he made six engravings, one very fine. He joined in the fashion for chiaroscuro woodcuts, adding a tone block to a woodcut of 1510. Most of his hundreds of woodcuts were commissioned for books, as was usual at the time; his \"single-leaf\" woodcuts (i.e. prints not for book illustration) are fewer than 100, though no two catalogues agree as to the exact number.\n\nUnconventional as a draughtsman, his treatment of human form is often exaggerated and eccentric (hence his linkage, in the art historical literature, with European Mannerism), whilst his ornamental style—profuse, eclectic, and akin to the self-consciously \"German\" strain of contemporary limewood sculptors—is equally distinctive. Though Baldung has been commonly called the Correggio of the north, his compositions are a curious medley of glaring and heterogeneous colours, in which pure black is contrasted with pale yellow, dirty grey, impure red and glowing green. Flesh is a mere glaze under which the features are indicated by lines.\n\nHis works are notable for their individualistic departure from the Renaissance composure of his model, Dürer, for the wild and fantastic strength that some of them display, and for their remarkable themes. In the field of painting, his \"Eve, the Serpent and Death\" (National Gallery of Canada) shows his strengths well. There is special force in the \"Death and the Maiden\" panel of 1517 (Basel), in the \"Weather Witches\" (Frankfurt), in the monumental panels of \"Adam\" and \"Eve\" (Madrid), and in his many powerful portraits. Baldung's most sustained effort is the altarpiece of Freiburg, where the Coronation of the Virgin, and the Twelve Apostles, the Annunciation, Visitation, Nativity and Flight into Egypt, and the Crucifixion, with portraits of donors, are executed with some of that fanciful power that Martin Schongauer bequeathed to the Swabian school.\n\nAs a portrait painter he is well known. He drew Charles V, as well as Maximilian; and his bust of Margrave Philip in the Munich Gallery tells us that he was connected with the reigning family of Baden as early as 1514. At a later period he had sittings with Margrave Christopher of Baden, Ottilia his wife, and all their children, and the picture containing these portraits is still in the gallery at Karlsruhe. Like Dürer and Cranach, Baldung supported the Protestant Reformation. He was present at the diet of Augsburg in 1518, and one of his woodcuts represents Luther in quasi-saintly guise, under the protection of (or being inspired by) the Holy Spirit, which hovers over him in the shape of a dove.\n\n\n\n\nAttribution:\n\n\n"}
{"id": "14070", "url": "https://en.wikipedia.org/wiki?curid=14070", "title": "Hammered dulcimer", "text": "Hammered dulcimer\n\nThe hammered dulcimer is a percussion-stringed instrument which consists of strings typically stretched over a trapezoidal resonant sound board. The hammered dulcimer is set before the musician, who, in more traditional styles, may sit cross legged on the floor, or at a more modern style of standing or sitting at a wooden stand on legs. The player holds a small spoon shaped mallet hammer in each hand to strike the strings (\"cf.\" Appalachian dulcimer). The Graeco-Roman \"dulcimer\" (sweet song) derives from the Latin \"dulcis\" (sweet) and the Greek \"melos\" (song). The dulcimer, in which the strings are beaten with small hammers, originated from the psaltery, in which the strings are plucked. \nHammered dulcimers, and other similar instruments, are traditionally played in Iraq, India, Iran, Southwest Asia, China, Korea, and parts of Southeast Asia, Central Europe (Hungary, Slovenia, Romania, Slovakia, Poland, Czech Republic, Switzerland (particularly Appenzell), Austria and Bavaria), the Balkans, Eastern Europe (Ukraine and Belarus) and Scandinavia. The instrument is also played in the United Kingdom (Wales, East Anglia, Northumbria) and the U.S., where its traditional use in folk music saw a notable revival in the late 20th century.\n\nA dulcimer usually has two bridges, a bass bridge near the right and a treble bridge on the left side. The bass bridge holds up bass strings, which are played to the left of the bridge. The treble strings can be played on either side of the treble bridge. In the usual construction, playing them on the left side gives a note a fifth higher than playing them on the right of the bridge.\n\nThe dulcimer comes in various sizes, identified by the number of strings that cross each of the bridges. A 15/14, for example, has 15 strings crossing the treble bridge and 14 crossing the bass bridge, and can span three octaves. The strings of a hammered dulcimer are usually found in pairs, two strings for each note (though some instruments have three or four strings per note). Each set of strings is tuned in unison and is called a course. As with a piano, the purpose of using multiple strings per course is to make the instrument louder, although as the courses are rarely in perfect unison, a chorus effect usually results like a mandolin. A hammered dulcimer, like an autoharp, harp, or piano, requires a tuning wrench for tuning, since the dulcimer's strings are wound around tuning pins with square heads. (Ordinarily, 5 mm \"zither pins\" are used, similar to, but smaller in diameter than piano tuning pins, which come in various sizes ranging upwards from \"1/0\" or 7 mm.)\n\nThe strings of the hammered dulcimer are often tuned according to a circle of fifths pattern. Typically, the lowest note (often a G or D) is struck at the lower right-hand of the instrument, just to the left of the right-hand (bass) bridge. As a player strikes the courses above in sequence, they ascend following a repeating sequence of two whole steps and a half step. With this tuning, a diatonic scale is broken into two tetrachords, or groups of four notes. For example, on an instrument with D as the lowest note, the D major scale is played starting in the lower-right corner and ascending the bass bridge: D – E – F – G. This is the lower tetrachord of the D major scale. At this point the player returns to the bottom of the instrument and shifts to the treble strings to the right of the treble bridge to play the higher tetrachord: A – B – C – D. The player can continue up the scale on the right side of the treble bridge with E – F – G – A – B, but the next note will be C, not C, so he or she must switch to the left side of the treble bridge (and closer to the player) to continue the D major scale. See the drawing on the left above, in which \"DO\" would correspond to D (see Movable do solfège).\n\nThe shift from the bass bridge to the treble bridge is required because the bass bridge's fourth string G is the start of the lower tetrachord of the G scale. The player could go on up a couple notes (G - A - B), but the next note will be a flatted seventh (C natural in this case), because this note is drawn from the G tetrachord. This D major scale with a flatted seventh is the mixolydian mode in D.\n\nThe same thing happens as the player goes up the treble bridge – after getting to La (B in this case), one has to go to the left of the treble bridge. Moving from the left side of the bass bridge to the right side of the treble bridge is analogous to moving from the right side of the treble bridge to the left side of the treble bridge.\n\nThe whole pattern can be shifted up by three courses, so that instead of a D-major scale one would have a G-major scale, and so on. This transposes one equally tempered scale to another. Shifting down three courses transposes the D-major scale to A-major, but of course the first Do-Re-Mi would be shifted off the instrument.\n\nThis tuning results in most, but not all, notes of the chromatic scale being available. To fill in the gaps, many modern dulcimer builders include extra short bridges at the top and bottom of the soundboard, where extra strings are tuned to some or all of the missing pitches. Such instruments are often called \"chromatic dulcimers\" as opposed to the more traditional \"diatonic dulcimers\".\n\nThe tetrachord markers found on the bridges of most hammered dulcimers in the English-speaking world were introduced by the American player and maker Sam Rizzetta in the 1960s.\n\nIn the Alps there are also chromatic dulcimers with crossed strings, which are in a whole tone distance in every row. This chromatic \"Salzburger hackbrett\" was developed in the mid 1930s from the diatonic hammered dulcimer by Tobi Reizer and his son along with Franz Peyer and Heinrich Bandzauner. In the postwar period it was one of the instruments taught in state-sponsored music schools.\n\nHammered dulcimers of non-European descent may have other tuning patterns, and builders of European-style dulcimers sometimes experiment with alternate tuning patterns.\n\nThe instrument is referred to as hammered in reference to the small mallets (referred to as \"hammers\") that players use to strike the strings. Hammers are usually made of wood (most likely hard woods such as maple, cherry, padauk, oak, walnut, or any other hard wood), but can also be made from any material, including metal and plastic. In the Western hemisphere, hammers are usually stiff, but in Asia, flexible hammers are often used. The head of the hammer can be left bare for a sharp attack sound, or can be covered with adhesive tape, leather, or fabric for a softer sound. \nTwo-sided hammers are also available. The heads of two sided hammers are usually oval or round. Most of the time, one side is left as bare wood while the other side may be covered in leather or a softer material such as piano felt.\n\nSeveral traditional players have used hammers that differ substantially from those in common use today. Paul Van Arsdale (1920-2018), a player from upstate New York, uses flexible hammers made from hacksaw blades, with leather-covered wooden blocks attached to the ends (these are modeled after the hammers used by his grandfather, Jesse Martin). The Irish player John Rea (1915–1983) used hammers made of thick steel wire, wound with wool. He made these himself from old bicycle spokes. Billy Bennington (1900–1986), a player from Norfolk in England, used cane hammers bound with wool.\n\nThe hammered dulcimer was extensively used during the Middle Ages in England, France, Italy, Germany, the Netherlands and Spain. Although it had a distinctive name in each country, it was everywhere regarded as a kind of psalterium. The importance of the method of setting the strings in vibration by means of hammers, and its bearing on the acoustics of the instrument, were recognized only when the invention of the pianoforte had become a matter of history. It was then perceived that the psalterium in which the strings were plucked, and the dulcimer in which they were struck, when provided with keyboards, gave rise to two distinct families of instruments, differing essentially in tone quality, in technique and in capabilities: the evolution of the psalterium stopped at the harpsichord, that of the dulcimer gave us the pianoforte.\n\nVersions of the hammered dulcimer are used throughout the world. In Eastern Europe, a larger descendant of the hammered dulcimer called the cimbalom is played and has been used by a number of classical composers, including Zoltán Kodály, Igor Stravinsky and Pierre Boulez. The khim is the name of both the Thai and the Khmer hammered dulcimer.\n\nThe santur or santoor is a type of hammered dulcimer that originated in Mesopotamia and is found in Iran, Iraq and India.\n\n\n\n"}
{"id": "14071", "url": "https://en.wikipedia.org/wiki?curid=14071", "title": "Humanae vitae", "text": "Humanae vitae\n\nHumanae vitae (Latin: \"Of Human Life\") is an encyclical written by Pope Paul VI and dated 25 July 1968. The text was issued at a Vatican press conference on 29 July. Subtitled \"On the Regulation of Birth\", it re-affirmed the orthodox teaching of the Catholic Church regarding married love, responsible parenthood, and the rejection of artificial contraception. In formulating his teaching he explained why he did not accept the conclusions of the Pontifical Commission on Birth Control established by his predecessor, Pope John XXIII, a commission he himself had expanded.\n\nMainly because of its prohibition of artificial contraception (some licit therapeutic procedures with the sole intent to cure bodily diseases are excepted), the encyclical was politically controversial. It affirmed traditional Church moral teaching on the sanctity of life and the procreative and unitive nature of conjugal relations.\n\nIt was the last of Paul's seven encyclicals.\n\nIn this encyclical Paul VI reaffirmed the Catholic Church's orthodox view of marriage and marital relations and a continued condemnation of \"artificial\" birth control. There were two Papal committees and numerous independent experts looking into the latest advancement of science and math on the question of artificial birth control, which were noted by the Pope in his encyclical. The expressed views of Paul VI reflected the teachings of his predecessors, especially Pius XI, Pius XII and John XXIII, all of whom had insisted on the divine obligations of the marital partners in light of their partnership with God the creator.\n\nPaul VI himself, even as commission members issued their personal views over the years, always reaffirmed the teachings of the Church, repeating them more than once in the first years of his Pontificate.\n\nTo Pope Paul VI, as with of all his predecessors, marital relations are much more than a union of two people. In his view, they constitute a union of the loving couple with a loving God, in which the two persons generate the matter for the body, while God creates the unique soul of a person. For this reason, Paul VI teaches in the first sentence of \"Humanae Vitae\", that the \"transmission of human life is a most serious role in which married people collaborate freely and responsibly with God the Creator.\" This is divine partnership, so Paul VI does not allow for arbitrary human decisions, which may limit divine providence. According to Paul VI, marital relations are a source of great joy, but also of difficulties and hardships. The question of human procreation with God, exceeds in the view of Paul VI specific disciplines such as biology, psychology, demography or sociology. According to Paul VI, married love takes its origin from God, who is love, and from this basic dignity, he defines his position:\nThe encyclical opens with an assertion of the competency of the magisterium of the Catholic Church to decide questions of morality. It then goes on to observe that circumstances often dictate that married couples should limit the number of children, and that the sexual act between husband and wife is still worthy even if it can be foreseen not to result in procreation. Nevertheless, it is held that the sexual act must retain its intrinsic relationship to the procreation of human life.\n\nEvery action specifically intended to prevent procreation is forbidden, except in medically necessary circumstances. Therapeutic means necessary to cure diseases are exempted, even if a foreseeable impediment to procreation should result, but only if infertility is not directly intended. This is held to directly contradict the moral order which was established by God. Abortion, even for therapeutic reasons, is absolutely forbidden, as is sterilization, even if temporary. Therapeutic means which induce infertility are allowed (\"e.g.\", hysterectomy), if they are not specifically intended to cause infertility (e.g., the uterus is cancerous, so the preservation of life is intended). If there are well grounded reasons (arising from the physical or psychological condition of husband or wife, or from external circumstances), Natural family planning methods (abstaining from intercourse during certain parts of the menstrual cycle) are allowed, since they take advantage of a faculty provided by nature.\n\nThe acceptance of artificial methods of birth control is then claimed to result in several negative consequences, among them a general lowering of moral standards resulting from sex without consequences, and the danger that men may reduce women to being a mere instrument for the satisfaction of [their] own desires; finally, abuse of power by public authorities, and a false sense of autonomy.\n\nPublic authorities should oppose laws which undermine natural law; scientists should further study effective methods of natural birth control; doctors should further familiarize themselves with this teaching, in order to be able to give advice to their patients, priests must spell out clearly and completely the Church's teaching on marriage. The encyclical acknowledges that \"perhaps not everyone will easily accept this particular teaching\", but that \"...it comes as no surprise to the church that she, no less than her Divine founder is destined to be a sign of contradiction.\" Noted is the duty of proclaiming the entire moral law, \"both natural and evangelical.\" The encyclical also points out that the Roman Catholic Church cannot \"declare lawful what is in fact unlawful\", because she is concerned with \"safeguarding the holiness of marriage, in order to guide married life to its full human and Christian perfection.\" This is to be the priority for his fellow bishops and priests and lay people. The Pope predicts that future progress in social cultural and economic spheres will make marital and family life more joyful, provided God's design for the world is faithfully followed. The encyclical closes with an appeal to observe the natural laws of the Most High God. \"These laws must be wisely and lovingly observed.\"\n\nThere had been a long-standing general Christian prohibition on contraception and abortion, with such Church Fathers as Clement of Alexandria and Saint Augustine condemning the practices. It was not until the 1930 Lambeth Conference that the Anglican Communion allowed for contraception in limited circumstances. Mainline Protestant denominations have since removed prohibitions against artificial contraception. In a partial reaction, Pope Pius XI wrote the encyclical \"Casti connubii\" (\"On Christian Marriage\") in 1930, reaffirming the Catholic Church's belief in various traditional Christian teachings on marriage and sexuality, including the prohibition of artificial birth control even within marriage. \"Casti connubii\" is against contraception and regarding natural family planning allowed married couples to use their nuptial rights \"in the proper manner\" when because of either time or defects, new life could not be brought forth.\n\nWith the appearance of the first oral contraceptives in 1960, dissenters in the Church argued for a reconsideration of the Church positions. In 1963 Pope John XXIII established a commission of six European non-theologians to study questions of birth control and population. It met once in 1963 and twice in 1964. As Vatican Council II was concluding, Pope Paul VI enlarged it to fifty-eight members, including married couples, laywomen, theologians and bishops. The last document issued by the council (\"Gaudium et spes\") contained a section titled \"Fostering the Nobility of Marriage\" (1965, nos. 47-52), which discussed marriage from the personalist point of view. The \"duty of responsible parenthood\" was affirmed, but the determination of licit and illicit forms of regulating birth was reserved to Pope Paul VI. In the spring of 1966, following the close of the council, the commission held its fifth and final meeting, having been enlarged again to include sixteen bishops as an executive committee. The commission was only consultative but it submitted a report approved by a majority of 64 members to Paul VI. It proposed he approve at least some form of contraception for married couples. A minority of four members opposed this report and issued a parallel report to the Pope. After two more years of study and consultation, the pope issued \"Humanae vitae\", which removed any doubt that the Church views hormonal anti-ovulants as contraceptive. He explained why he did not accept the opinion of the majority report of the commission (1968, #6). \n\nArguments were raised in the decades that followed that his decision has never passed the condition of \"reception\" to become church doctrine.\n\nIn his role as Theologian of the Pontifical Household Mario Luigi Ciappi advised Pope Paul VI during the drafting of \"Humanae vitae\". Ciappi, a doctoral graduate of the \"Pontificium Athenaeum Internationale Angelicum\", the future Pontifical University of Saint Thomas Aquinas, \"Angelicum\", served as professor of dogmatic theology there and was Dean of the \"Angelicum's\" Faculty of Theology from 1935 to 1955.\n\nAccording to George Weigel, Paul VI named Archbishop Karol Wojtyła (later Pope John Paul II) to the commission, but Polish government authorities would not permit him to travel to Rome. Wojtyła had earlier defended the church's position from a philosophical standpoint in his 1960 book \"Love and Responsibility\". Wojtyła's position was strongly considered and it was reflected in the final draft of the encyclical, although much of his language and arguments were not incorporated. Weigel attributes much of the poor reception of the encyclical to the omission of many of Wojtyła's arguments.\n\nIn 2017, anticipating the 50th anniversary of the encyclical, four theologians led by Mgr. Gilfredo Marengo, a professor of theological anthropology at the Pontifical John Paul II Institute for Studies on Marriage and Family, launched a research project he called \"a work of historical-critical investigation without any aim other than reconstructing as well as possible the whole process of composing the encyclical\". Using the resources of the Vatican Secret Archives and the Congregation for the Doctrine of the Faith, they hope to detail the writing process and the interaction between the commission, publicity surrounding the commission's work, and Paul's own authorship.\n\n13. Men rightly observe that a conjugal act imposed on one's partner without regard to his or her condition or personal and reasonable wishes in the matter, is no true act of love, and therefore offends the moral order in its particular application to the intimate relationship of husband and wife. If they further reflect, they must also recognize that an act of mutual love which impairs the capacity to transmit life which God the Creator, through specific laws, has built into it, frustrates His design which constitutes the norm of marriage, and contradicts the will of the Author of life. Hence to use this divine gift while depriving it, even if only partially, of its meaning and purpose, is equally repugnant to the nature of man and of woman, and is consequently in opposition to the plan of God and His holy will. But to experience the gift of married love while respecting the laws of conception is to acknowledge that one is not the master of the sources of life but rather the minister of the design established by the Creator. Just as man does not have unlimited dominion over his body in general, so also, and with more particular reason, he has no such dominion over his specifically sexual faculties, for these are concerned by their very nature with the generation of life, of which God is the source. \"Human life is sacred—all men must recognize that fact,\" Our predecessor Pope John XXIII recalled. \"From its very inception it reveals the creating hand of God.\"\n\n15. ...the Church does not consider at all illicit the use of those therapeutic means necessary to cure bodily diseases, even if a foreseeable impediment to procreation should result therefrom — provided such impediment is not directly intended.\n\n16. ...If therefore there are well-grounded reasons for spacing births, arising from the physical or psychological condition of husband or wife, or from external circumstances, the Church teaches that married people may then take advantage of the natural cycles immanent in the reproductive system and engage in marital intercourse only during those times that are infertile, thus controlling birth in a way which does not in the least offend the moral principles which We have just explained.\n\n18. It is to be anticipated that perhaps not everyone will easily accept this particular teaching. There is too much clamorous outcry against the voice of the Church, and this is intensified by modern means of communication. But it comes as no surprise to the Church that it, no less than its divine Founder, is destined to be a \"sign of contradiction.\") The Church does not, because of this, evade the duty imposed on it of proclaiming humbly but firmly the entire moral law, both natural and evangelical. Since the Church did not make either of these laws, it cannot be their arbiter—only their guardian and interpreter. It could never be right for the Church to declare lawful what is in fact unlawful, since that, by its very nature, is always opposed to the true good of man. In preserving intact the whole moral law of marriage, the Church is convinced that it is contributing to the creation of a truly human civilization. The Church urges man not to betray his personal responsibilities by putting all his faith in technical expedients. In this way it defends the dignity of husband and wife. This course of action shows that the Church, loyal to the example and teaching of the divine Savior, is sincere and unselfish in its regard for men whom it strives to help even now during this earthly pilgrimage \"to share God's life as sons of the living God, the Father of all men\".\n\n23. We are fully aware of the difficulties confronting the public authorities in this matter, especially in the developing countries. In fact, We had in mind the justifiable anxieties which weigh upon them when We published Our encyclical letter \"Populorum Progressio\". But now We join Our voice to that of Our predecessor John XXIII of venerable memory, and We make Our own his words: \"No statement of the problem and no solution to it is acceptable which does violence to man's essential dignity; those who propose such solutions base them on an utterly materialistic conception of man himself and his life. The only possible solution to this question is one which envisages the social and economic progress both of individuals and of the whole of human society, and which respects and promotes true human values.\" No one can, without being grossly unfair, make divine Providence responsible for what clearly seems to be the result of misguided governmental policies, of an insufficient sense of social justice, of a selfish accumulation of material goods, and finally of a culpable failure to undertake those initiatives and responsibilities which would raise the standard of living of peoples and their children.\n\nCardinal Leo Joseph Suenens, a moderator of the ecumenical council, questioned, \"whether moral theology took sufficient account of scientific progress, which can help determine, what is according to nature. I beg you my brothers let us avoid another Galileo affair. One is enough for the Church.\" In an interview in \"Informations Catholiques Internationales\" on 15 May 1969, he criticized the Pope’s decision again as frustrating the collegiality defined by the Council, calling it a non-collegial or even an anti-collegial act. He was supported by Vatican II theologians such as Karl Rahner, Hans Küng, several Episcopal conferences, e.g. the Episcopal Conference of Austria, Germany, and Switzerland, as well as several bishops, including Christopher Butler, who called it one of the most important contributions to contemporary discussion in the Church.\n\nThe publication of the encyclical marks the first time in the twentieth century that open dissent from the laity about teachings of the Church was voiced widely and publicly. The teaching has been criticized by development organizations and others who claim that it limits the methods available to fight worldwide population growth and struggle against HIV/AIDS. Within two days of the encyclical's release, a group of dissident theologians, led by Rev. Charles Curran, then of The Catholic University of America, issued a statement stating, \"spouses may responsibly decide according to their conscience that artificial contraception in some circumstances is permissible and indeed necessary to preserve and foster the value and sacredness of marriage.\n\nTwo months later, the controversial \"Winnipeg Statement\" issued by the Canadian Conference of Catholic Bishops stated that those who cannot accept the teaching should not be considered shut off from the Catholic Church, and that individuals can in good conscience use contraception as long as they have first made an honest attempt to accept the difficult directives of the encyclical.\n\nThe Dutch Catechism of 1966, based on the Dutch bishops' interpretation of the just completed Vatican Council, and the first post-Council comprehensive Catholic catechism, noted the lack of mention of artificial contraception in the Council. \"As everyone can ascertain nowadays, there are several methods of regulating births. The Second Vatican Council did not speak of any of these concrete methods… This is a different standpoint than that taken under Pius XI some thirty years which was also maintained by his successor ... we can sense here a clear development in the Church, a development, which is also going on outside the Church.\"\n\nIn the Soviet Union, \"Literaturnaja Gazeta\", a publication of Soviet intellectuals, included an editorial and statement by Russian physicians against the encyclical.\n\nEcumenical reactions were mixed. Liberal and Moderate Lutherans and the World Council of Churches were disappointed. Eugene Carson Blake criticised the concepts of nature and natural law, which, in his view, still dominated Catholic theology, as outdated. This concern dominated several articles in Catholic and non-Catholic journals at the time. Patriarch Athenagoras I stated his full agreement with Pope Paul VI: “He could not have spoken in any other way.”\n\nIn Latin America, much support developed for the Pope and his encyclical. As World Bank President Robert McNamara declared at the 1968 Annual Meeting of the International Monetary Fund and the World Bank Group that countries permitting birth control practices will get preferential access to resources, doctors in La Paz, Bolivia, called it insulting that money should be exchanged for the conscience of a Catholic nation. In Colombia, Cardinal Anibal Muñoz Duque declared, if American conditionality undermines Papal teachings, we prefer not to receive one cent. The Senate of Bolivia passed a resolution, stating that \"Humanae vitae\" can be discussed in its implications on individual consciences, but, it is of greatest significance, because the papal document defends the rights of developing nations to determine their own population policies. The Jesuit Journal \"Sic\" dedicated one edition to the encyclical with supportive contributions. However, against eighteen insubordinate priests, professors of theology at Pontifical Catholic University of Chile, and the ensuing conspiracy of silence practiced by the Chilean Episcopate, which had to be censured by the Nuncio in Santiago at the behest of Cardinal Gabriel-Marie Garrone, prefect of the Congregation for Catholic Education, triggering eventually a media conflict with , Plinio Corrêa de Oliveira expressed his affliction with the lamentations of Jeremiah: \"O ye all that pass through the way…\" ().\n\nIn the book \"Nighttime conversations in Jerusalem. On the risk of faith.\" well-known liberal Cardinal Carlo Maria Martini accused Paul VI of deliberately concealing the truth, leaving it to theologians and pastors to fix things by adapting precepts to practice:\n\"I knew Paul VI well. With the encyclical, he wanted to express consideration for human life. He explained his intention to some of his friends by using a comparison: although one must not lie, sometimes it is not possible to do otherwise; it may be necessary to conceal the truth, or it may be unavoidable to tell a lie. It is up to the moralists to explain where sin begins, especially in the cases in which there is a higher duty than the transmission of life.\" \n\nPope Paul VI was troubled by the encyclical's reception in the West. Acknowledging the controversy, Paul VI in a letter to the Congress of German Catholics (30 August 1968), stated: \"May the lively debate aroused by our encyclical lead to a better knowledge of God’s will.\" In March 1969, he had a meeting with one of the main critics of \"Humanae vitae\", Cardinal Leo Joseph Suenens. Paul heard him out and said merely, \"Yes, pray for me; because of my weaknesses, the Church is badly governed.\" And to jog the memory of his critics, he put in their minds the experience of no less a figure than Pope Saint Peter: \"[n]ow I understand St Peter: he came to Rome twice, the second time to be crucified\", — herewith directing their attention to his rejoicing in glorifying the Lord. Increasingly convinced, that \"the smoke of Satan entered the temple of God from some fissure\", Paul VI reaffirmed, on 23 June 1978, weeks before his death, in an address to the College of Cardinals, his \"Humanae vitae\": \"following the confirmations of serious science\", and which sought to affirm the principle of respect for the laws of nature and of \"a conscious and ethically responsible paternity\".\n\nAlthough polls show that many Catholics dissent from church teaching on contraception, there has nevertheless been a resurgence of support for it among most practising Catholics, from Roman Catholic theologians such as, Germain Grisez, Janet E. Smith, Mary Shivanandan, Scott and his wife Kimberly Hahn. They along with numerous Catholic authors and speakers such as such as Christopher West, Matt Fradd, Jason Evert, and Leah Darrow are currently advancing a deeper appreciation and understanding of the Church's teaching regarding sex and marriage. At the official level, Catholicism’s commitment to \"Humanae Vitae\" is more stable than ever. According to John L. Allen, Jr., \"In addition, three decades of bishops’ appointments by John Paul II and Benedict XVI, both unambiguously committed to \"Humanae Vitae\", mean that senior leaders in Catholicism these days are far less inclined than they were in 1968 to distance themselves from the ban on birth control, or to soft-pedal it. Some Catholic bishops have brought out documents of their own defending \"Humanae Vitae\". Also, developments in fertility awareness since the 1960s have given rise to natural family planning organizations such as the Billings Ovulation Method, Couple to Couple League and the Creighton Model FertilityCare System, which actively provide formal instruction on the use and reliability of natural methods of birth control.\n\nAlbino Luciani's views on \"Humanae vitae\" have been debated. Journalist John L. Allen, Jr. claims that \"it's virtually certain that John Paul I would not have reversed Paul VI’s teaching, particularly since he was no doctrinal radical. Moreover, as Patriarch in Venice some had seen a hardening of his stance on social issues as the years went by.\" According to Allen \"...it is reasonable to assume that John Paul I would not have insisted upon the negative judgment in \"Humanae Vitae\" as aggressively and publicly as John Paul II did, and probably would not have treated it as a quasi-infallible teaching. It would have remained a more 'open' question\". Other sources take a different view and note that during his time as Patriarch of Venice that \"Luciani was intransigent with his upholding of the teaching of the Church and severe with those, through intellectual pride and disobedience paid no attention to the Church's prohibition of contraception\", though while not condoning the sin, he was tolerant of those who sincerely tried and failed to live up to the Church's teaching. The book states that \"...if some people think that his compassion and gentleness in this respect implies he was against Humane Vitae one can only infer it was wishful thinking on their part and an attempt to find an ally in favor of artificial contraception.\"\n\nAfter he became pope in 1978, John Paul II continued on the Catholic Theology of the Body of his predecessors with a series of lectures, entitled \"Theology of the Body\", in which he talked about an \"original unity between man and women\", purity of heart (on the Sermon on the Mount), marriage and celibacy and reflections on \"Humanae vitae\", focusing largely on responsible parenthood and marital chastity.\n\nIn 1981, the Pope's Apostolic exhortation, Familiaris consortio restated the Church's opposition to artificial birth control stated previously in Humanae vitae.\n\nJohn Paul II readdressed some of the same issues in his 1993 encyclical \"Veritatis splendor\". He reaffirmed much of \"Humanae vitae\", and specifically described the practice of artificial contraception as an act not permitted by Catholic teaching in any circumstances. The same encyclical also clarifies the use of conscience in arriving at moral decisions, including in the use of contraception. However, John Paul also said, “It is not right then to regard the moral conscience of the individual and the magisterium of the Church as two contenders, as two realities in conflict. The authority which the magisterium enjoys by the will of Christ exists so that the moral conscience can attain the truth with security and remain in it.” John Paul quoted \"Humanae vitae\" as a compassionate encyclical, \"Christ has come not to judge the world but to save it, and while he was uncompromisingly stern towards sin, he was patient and rich in mercy towards sinners\".\n\nPope John Paul's 1995 encyclical, \"Evangelium vitae\" (\"The Gospel of Life\"), affirmed the Church's position on contraception and multiple topics related to the culture of life.\n\nOn 12 May 2008, Benedict XVI accepted an invitation to talk to participants in the International Congress organized by the Pontifical Lateran University on the 40th anniversary of \"Humanae vitae\". He put the encyclical in the broader view of love in a global context, a topic he called \"so controversial, yet so crucial for humanity's future.\" \"Humanae vitae\" became \"a sign of contradiction but also of continuity of the Church's doctrine and tradition... What was true yesterday is true also today.\" The Church continues to reflect \"in an ever new and deeper way on the fundamental principles that concern marriage and procreation.\" The key message of \"Humanae vitae\" is love. Benedict states, that the fullness of a person is achieved by a unity of soul and body, but neither spirit nor body alone can love, only the two together. If this unity is broken, if only the body is satisfied, love becomes a commodity.\n\nOn 16 January 2015, Pope Francis said to a meeting with families in Manila, insisting on the need to protect the family: \"The family is ...threatened by growing efforts on the part of some to redefine the very institution of marriage, by relativism, by the culture of the ephemeral, by a lack of openness to life. I think of Blessed Paul VI. At a time when the problem of population growth was being raised, he had the courage to defend openness to life in families. He knew the difficulties that are there in every family, and so in his Encyclical he was very merciful towards particular cases, and he asked confessors to be very merciful and understanding in dealing with particular cases. But he also had a broader vision: he looked at the peoples of the earth and he saw this threat of the destruction of the family through the privation of children [original Spanish: destrucción de la familia por la privación de los hijos]. Paul VI was courageous; he was a good pastor and he warned his flock of the wolves who were coming.\"\n\nA year before, on 1 May 2014, Pope Francis, in an interview given to Italian newspaper \"Corriere della Sera\", expressed his opinion and praise for \"Humanae Vitae\": \"Everything depends on how \"Humanae Vitae\" is interpreted. Paul VI himself, in the end, urged confessors to be very merciful and pay attention to concrete situations. But his genius was prophetic, he had the courage to take a stand against the majority, to defend moral discipline, to exercise a cultural restraint, to oppose present and future neo-Malthusianism. The question is not of changing doctrine, but of digging deep and making sure that pastoral care takes into account situations and what it is possible for persons to do.\"\n\n\n"}
{"id": "14072", "url": "https://en.wikipedia.org/wiki?curid=14072", "title": "History of Wikipedia", "text": "History of Wikipedia\n\nWikipedia began with its launch on 15 January 2001, two days after the domain was registered by Jimmy Wales and Larry Sanger. Its technological and conceptual underpinnings predate this; the earliest known proposal for an online encyclopedia was made by Rick Gates in 1993, but the concept of a free-as-in-freedom online encyclopedia (as distinct from mere open source) was proposed by Richard Stallman in December 2000.\n\nCrucially, Stallman's concept specifically included the idea that no central organization should control editing. This characteristic was in stark contrast to contemporary digital encyclopedias such as Microsoft Encarta, \"Encyclopædia Britannica\", and even Bomis's Nupedia, which was Wikipedia's direct predecessor. In 2001, the license for Nupedia was changed to GFDL, and Wales and Sanger launched Wikipedia using the concept and technology of a wiki pioneered in 1995 by Ward Cunningham. Initially, Wikipedia was intended to complement Nupedia, an online encyclopedia project edited solely by experts, by providing additional draft articles and ideas for it. In practice, Wikipedia quickly overtook Nupedia, becoming a global project in multiple languages and inspiring a wide range of other online reference projects.\n\nAccording to Alexa Internet, , Wikipedia is the world's fifth-most-popular website in terms of overall visitor traffic. Wikipedia's worldwide monthly readership is approximately 495 million. Worldwide in September 2018, WMF Labs tallied 15.5 billion page views for the month. According to comScore, Wikipedia receives over 117 million monthly unique visitors from the United States alone.\n\nThe concept of compiling the world's knowledge in a single location dates back to the ancient Libraries of Alexandria and Pergamum, but the modern concept of a general-purpose, widely distributed, printed encyclopedia originated with Denis Diderot and the 18th-century French encyclopedists. The idea of using automated machinery beyond the printing press to build a more useful encyclopedia can be traced to Paul Otlet's 1934 book \"Traité de documentation\"; Otlet also founded the Mundaneum, an institution dedicated to indexing the world's knowledge, in 1910. This concept of a machine-assisted encyclopedia was further expanded in H. G. Wells' book of essays \"World Brain\" (1938) and Vannevar Bush's future vision of the microfilm-based Memex in his essay \"As We May Think\" (1945). Another milestone was Ted Nelson's hypertext design Project Xanadu, which was begun in 1960.\n\nAdvances in information technology in the late 20th century led to changes in the form of encyclopedias. While previous encyclopedias, notably the \"Encyclopædia Britannica\", were book-based, Microsoft's Encarta, published in 1993, was available on CD-ROM and hyperlinked. The development of the World Wide Web led to many attempts to develop internet encyclopedia projects. An early proposal for an online encyclopedia was Interpedia in 1993 by Rick Gates; this project died before generating any encyclopedic content. Free software proponent Richard Stallman described the usefulness of a \"Free Universal Encyclopedia and Learning Resource\" in 1999. His published document \"aims to lay out what the free encyclopedia needs to do, what sort of freedoms it needs to give the public, and how we can get started on developing it.\" On Wednesday 17 January 2001, two days after the founding of Wikipedia, the Free Software Foundation's (FSF) GNUPedia project went online, competing with Nupedia, but today the FSF encourages people \"to visit and contribute to [Wikipedia]\".\n\nWikipedia was initially conceived as a feeder project for the Wales-founded Nupedia, an earlier project to produce a free online encyclopedia, volunteered by Bomis, a web-advertising firm owned by Jimmy Wales, Tim Shell and Michael E. Davis. Nupedia was founded upon the use of highly qualified volunteer contributors and an elaborate multi-step peer review process. Despite its mailing list of interested editors, and the presence of a full-time editor-in-chief, Larry Sanger, a graduate philosophy student hired by Wales, the writing of content for Nupedia was extremely slow, with only 12 articles written during the first year.\n\nWales and Sanger discussed various ways to create content more rapidly. The idea of a wiki-based complement originated from a conversation between Larry M. Sanger and Ben Kovitz. Ben Kovitz was a computer programmer and regular on Ward Cunningham's revolutionary wiki \"the WikiWikiWeb\". He explained to Sanger what wikis were, at that time a difficult concept to understand, over a dinner on Tuesday 2 January 2001. Wales first stated, in October 2001, that \"Larry had the idea to use Wiki software\", though he later stated in December 2005 that Jeremy Rosenfeld, a Bomis employee, introduced him to the concept. Sanger thought a wiki would be a good platform to use, and proposed on the Nupedia mailing list that a wiki based upon UseModWiki (then v. 0.90) be set up as a \"feeder\" project for Nupedia. Under the subject \"Let's make a wiki\", he wrote:\nWales set one up and put it online on Wednesday 10 January 2001.\n\nThere was considerable resistance on the part of Nupedia's editors and reviewers to the idea of associating Nupedia with a wiki-style website. Sanger suggested giving the new project its own name, \"Wikipedia\", and Wikipedia was soon launched on its own domain, wikipedia.com, on Monday 15 January 2001. The bandwidth and server (located in San Diego) used for these initial projects were donated by Bomis. Many former Bomis employees later contributed content to the encyclopedia: notably Tim Shell, co-founder and later CEO of Bomis, and programmer Jason Richey.\n\nWales stated in December 2008 that he made Wikipedia's first edit, a test edit with the text \"Hello, World!\", but this edit may have been to an old version of Wikipedia which soon after was scrapped and replaced by a restart; see . The oldest article still preserved is the article UuU, created on Tuesday 16 January 2001, at 21:08 UTC. The existence of the project was formally announced and an appeal for volunteers to engage in content creation was made to the Nupedia mailing list on 17 January 2001.\nThe project received many new participants after being mentioned on the Slashdot website in July 2001, having already earned two minor mentions in March 2001. It then received a prominent pointer to a story on the community-edited technology and culture website Kuro5hin on 25 July. Between these relatively rapid influxes of traffic, there had been a steady stream of traffic from other sources, especially Google, which alone sent hundreds of new visitors to the site every day. Its first major mainstream media coverage was in \"The New York Times\" on Thursday 20 September 2001.\n\nThe project gained its 1,000th article around Monday 12 February 2001, and reached 10,000 articles around 7 September. In the first year of its existence, over 20,000 encyclopedia entries were created – a rate of over 1,500 articles per month. On Friday 30 August 2002, the article count reached 40,000.\n\nWikipedia's earliest edits were long believed lost, since the original UseModWiki software deleted old data after about a month. On Tuesday 14 December 2010, developer Tim Starling found backups on SourceForge containing every change made to Wikipedia from its creation in January 2001 to 17 August 2001. It showed the first edit as being to HomePage on 15 January 2001, reading \"This is the new WikiPedia!\".\n\nThe first three edits that were known of before Tim Starling's discovery, are:\nFor more information see .\n\nEarly in Wikipedia's development, it began to expand internationally, with the creation of new namespaces, each with a distinct set of usernames. The first subdomain created for a non-English Wikipedia was \"deutsche.wikipedia.com\" (created on Friday 16 March 2001, 01:38 UTC), followed after a few hours by \"Catalan.wikipedia.com\" (at 13:07 UTC). The Japanese Wikipedia, started as nihongo.wikipedia.com, was created around that period, and initially used only Romanized Japanese. For about two months Catalan was the one with the most articles in a non-English language, although statistics of that early period are imprecise. The French Wikipedia was created on or around 11 May 2001, in a wave of new language versions that also included Chinese, Dutch, Esperanto, Hebrew, Italian, Portuguese, Russian, Spanish, and Swedish. These languages were soon joined by Arabic and Hungarian. In September 2001, an announcement pledged commitment to the multilingual provision of Wikipedia, notifying users of an upcoming roll-out of Wikipedias for all major languages, the establishment of core standards, and a push for the translation of core pages for the new wikis. At the end of that year, when international statistics first began to be logged, Afrikaans, Norwegian, and Serbian versions were announced.\n\nIn January 2002, 90% of all Wikipedia articles were in English. By January 2004, fewer than 50% were English, and this internationalization has continued to increase as the encyclopedia grows. , about 85.5% of all Wikipedia articles are contained within non-English Wikipedia versions.\n\nIn March 2002, following the withdrawal of funding by Bomis during the dot-com bust, Larry Sanger left both Nupedia and Wikipedia. By 2002, Sanger and Wales differed in their views on how best to manage open encyclopedias. Both still supported the open-collaboration concept, but the two disagreed on how to handle disruptive editors, specific roles for experts, and the best way to guide the project to success.\n\nWales went on to establish self-governance and bottom-up self-direction by editors on Wikipedia. He made it clear that he would not be involved in the community's day-to-day management, but would encourage it to learn to self-manage and find its own best approaches. , Wales mostly restricts his own role to occasional input on serious matters, executive activity, advocacy of knowledge, and encouragement of similar reference projects.\n\nSanger says he is an \"inclusionist\" and is open to almost anything. He proposed that experts still have a place in the Web 2.0 world. He returned briefly to academia, then joined the Digital Universe Foundation. In 2006, Sanger founded Citizendium, an open encyclopedia that used real names for contributors in an effort to reduce disruptive editing, and hoped to facilitate \"gentle expert guidance\" to increase the accuracy of its content. Decisions about article content were to be up to the community, but the site was to include a statement about \"family-friendly content\". He stated early on that he intended to leave Citizendium in a few years, by which time the project and its management would presumably be established.\n\nThe Wikipedia project has grown rapidly in the course of its life, at several levels. Content has grown organically through the addition of new articles, new wikis have been added in English and non-English languages, and entire new projects replicating these growth methods in other related areas (news, quotations, reference books and so on) have been founded as well. Wikipedia itself has grown, with the creation of the Wikimedia Foundation to act as an umbrella body and the growth of software and policies to address the needs of the editorial community. These are documented below:\n\nIn March 2000, the Nupedia project was started. Its intention was to publish articles written by experts which would be licensed as free content. Nupedia was founded by Jimmy Wales, with Larry Sanger as editor-in-chief, and funded by the web-advertising company Bomis.\n\nIn January 2001, Wikipedia began as a side-project of Nupedia, to allow collaboration on articles prior to entering the peer-review process. The name was suggested by Sanger on 11 January 2001. The \"wikipedia.com\" and \"wikipedia.org\" domain names were registered on 12 and 13 January, respectively, with \"wikipedia.org\" being brought online on the same day. The project formally opened on 15 January (\"\"), with the first international Wikipedias – the French, German, Catalan, Swedish, and Italian editions – being created between March and May. The \"neutral point of view\" (NPOV) policy was officially formulated at this time, and Wikipedia's first slashdotter wave arrived on 26 July. The first media report about Wikipedia appeared in August 2001 in the newspaper \"Wales on Sunday\". The September 11 attacks spurred the appearance of breaking news stories on the homepage, as well as information boxes linking related articles.\n\n2002 saw the end of funding for Wikipedia from Bomis and the departure of Larry Sanger. The forking of the Spanish Wikipedia also took place with the establishment of the \"Enciclopedia Libre\". The first portable MediaWiki software went live on 25 January. Bots were introduced, Jimmy Wales confirmed that Wikipedia would never run commercial advertising, and the first sister project (Wiktionary) and first formal Manual of Style were launched. A separate board of directors to supervise the project was proposed and initially discussed at Meta-Wikipedia.\n\nThe English Wikipedia passed 100,000 articles in 2003, while the next largest edition, the German Wikipedia, passed 10,000. The Wikimedia Foundation was established, and Wikipedia adopted its jigsaw world logo. Mathematical formulae using TeX were reintroduced to the website. The took place in Munich, Germany, in October. The basic principles of Wikipedia's (known colloquially as \"ArbCom\") were developed, mostly by , and other early Wikipedians.\n\nWikisource was created as a separate project on 24 November 2003, to host free textual sources.\n\nThe worldwide Wikipedia article pool continued to grow rapidly in 2004, doubling in size in 12 months, from under 500,000 articles in late 2003 to over 1 million in over 100 languages by the end of 2004. The English Wikipedia accounted for just under half of these articles. The website's server farms were moved from California to Florida, and CSS style configuration sheets were introduced, and the first attempt to block Wikipedia occurred, with the website being blocked in China for two weeks in June. The formal election of a board and Arbitration Committee began. The first formal projects were proposed to deliberately balance content and seek out systemic bias arising from Wikipedia's community structure.\n\n\"Bourgeois v. Peters\", (11th Cir. 2004), a court case decided by the United States Court of Appeals for the Eleventh Circuit was one of the earliest . It stated: \"We also reject the notion that the Department of Homeland Security's threat advisory level somehow justifies these searches. Although the threat level was 'elevated' at the time of the protest, 'to date, the threat level has stood at yellow (elevated) for the majority of its time in existence. It has been raised to orange (high) six times.\"\n\nWikimedia Commons was created on 7 September 2004 to host media files for Wikipedia in all languages.\n\nIn 2005, Wikipedia became the most popular reference website on the Internet, according to Hitwise, with the English Wikipedia alone exceeding 750,000 articles. Wikipedia's first multilingual and subject portals were established in 2005. A formal fundraiser held in the first quarter of the year raised almost US$100,000 for system upgrades to handle growing demand. China again blocked Wikipedia in October 2005.\n\nThe first major Wikipedia scandal, the Seigenthaler incident, occurred in 2005, when a well-known figure was found to have a vandalized biography which had gone unnoticed for months. In the wake of this and other concerns, the first policy and system changes specifically designed to counter this form of abuse were established. These included a new privilege policy update to assist in sock puppetry investigations, a new feature called , a more strict policy on biographies of living people and the tagging of such articles for stricter review. A restriction of new article creation to registered users only was put in place in December 2005.\nWikimania 2005, the first Wikimania conference, was held from 4 to 8 August 2005 at the \"Haus der Jugend\" in Frankfurt, Germany, attracting about 380 attendees.\n\nThe English Wikipedia gained its one-millionth article, Jordanhill railway station, on 1 March 2006. The first approved Wikipedia article selection was made freely available to download, and \"Wikipedia\" became registered as a trademark of the Wikimedia Foundation. The congressional aides biography scandals – multiple incidents in which congressional staffers and a campaign manager were caught trying to covertly alter Wikipedia biographies – came to public attention, leading to the resignation of the campaign manager. Nonetheless, Wikipedia was rated as one of the top five global brands of 2006.\n\nJimmy Wales indicated at Wikimania 2006 that Wikipedia had achieved sufficient volume and called for an emphasis on quality, perhaps best expressed in the call for . A new privilege, \"oversight\", was created, allowing specific versions of archived pages with unacceptable content to be marked as non-viewable. Semi-protection against anonymous vandalism, introduced in 2005, proved more popular than expected, with over 1,000 pages being semi-protected at any given time in 2006.\n\nWikipedia continued to grow rapidly in 2007, possessing over 5 million registered editor accounts by 13 August. The 250 language editions of Wikipedia contained a combined total of 7.5 million articles, totalling 1.74 billion words, by 13 August. The English Wikipedia gained articles at a steady rate of 1,700 a day, with the wikipedia.org domain name ranked the 10th-busiest in the world. Wikipedia continued to garner visibility in – the Essjay controversy broke when a prominent member of Wikipedia was found to have lied about his credentials. Citizendium, a competing online encyclopedia, launched publicly. A new trend developed in Wikipedia, with the encyclopedia addressing people whose notability stemmed from being a participant in a news story by adding a redirect from their name to the larger story, rather than creating a distinct biographical article. On 9 September 2007, the English Wikipedia gained its two-millionth article, El Hormiguero. There was some controversy in late 2007 when the Volapük Wikipedia jumped from 797 to over 112,000 articles, briefly becoming the 15th-largest Wikipedia edition, due to automated stub generation by an enthusiast for the Volapük constructed language.\n\nAccording to the \"MIT Technology Review\", the number of regularly active editors on the English-language Wikipedia peaked in 2007 at more than 51,000, and has since been declining.\n\nVarious in many areas continued to expand and refine article contents within their scope. In April 2008, the 10-millionth Wikipedia article was created, and by the end of the year the English Wikipedia exceeded 2.5 million articles.\n\nOn 25 June 2009 at 3:15 pm PDT (22:15 UTC), following pop icon Michael Jackson's death, the website temporarily crashed.\n\nThe Wikimedia Foundation reported nearly a million visitors to Jackson's biography within one hour, probably the most visitors in a one-hour period to any article in Wikipedia's history. By late August 2009, the number of articles in all Wikipedia editions had exceeded 14 million. The three-millionth article on the English Wikipedia, Beate Eriksen, was created on 17 August 2009 at 04:05 UTC. On 27 December 2009, the German Wikipedia exceeded one million articles, becoming the second edition after the English Wikipedia to do so. A \"TIME\" article listed Wikipedia among 2009's best websites.\n\nWikipedia content became licensed under Creative Commons in 2009.\n\nOn 24 March, the European Wikipedia servers went offline due to an overheating problem. Failover to servers in Florida turned out to be broken, causing DNS resolution for Wikipedia to fail across the world. The problem was resolved quickly, but due to DNS caching effects, some areas were slower to regain access to Wikipedia than others.\n\nOn 13 May, the site released a new interface. New features included an updated logo, new navigation tools, and a link wizard. However, the classic interface remained available for those who wished to use it. On 12 December, the English Wikipedia passed the 3.5-million-article mark, while the French Wikipedia's millionth article was created on 21 September. The 1-billionth Wikimedia project edit was performed on 16 April.\n\nWikipedia and its users held hundreds of celebrations worldwide to commemorate the site's 10th anniversary on 15 January. The site began efforts to expand its growth in India, holding its first Indian conference in Mumbai in November 2011. The English Wikipedia passed the 3.6-million-article mark on 2 April, and reached 3.8 million articles on 18 November. On 7 November 2011, the German Wikipedia exceeded 100 million page edits, becoming the second language edition to do so after the English edition, which attained 500 million page edits on 24 November 2011. The Dutch Wikipedia exceeded 1 million articles on 17 December 2011, becoming the fourth Wikipedia edition to do so.\n\nThe \"Wikimania 2011 – Haifa, Israel\" stamp was issued by Israel Post on 2 August 2011. This was the first-ever stamp dedicated to a Wikimedia-related project.\n\nBetween 4 and 6 October 2011, the Italian Wikipedia became intentionally inaccessible in protest against the Italian Parliament's proposed DDL intercettazioni law, which, if approved, would allow any person to force websites to remove information that is perceived as untrue or offensive, without the need to provide evidence.\n\nAlso in October 2011, Wikimedia announced the launch of Wikipedia Zero, an initiative to enable free mobile access to Wikipedia in developing countries through partnerships with mobile operators.\n\nOn 16 January, Wikipedia co-founder Jimmy Wales announced that the English Wikipedia would shut down for 24 hours on 18 January as part of a protest meant to call public attention to the proposed Stop Online Piracy Act and PROTECT IP Act, two anti-piracy laws under debate in the United States Congress. Calling the blackout a \"community decision\", Wales and other opponents of the laws believed that they would endanger free speech and online innovation. A similar blackout was staged on 10 July by the Russian Wikipedia, in protest against a proposed Russian internet regulation law.\n\nIn late March 2012, the announced Wikidata, a universal platform for sharing data between all Wikipedia language editions. The US$1.7-million Wikidata project was partly funded by Google, the Gordon and Betty Moore Foundation, and the Allen Institute for Artificial Intelligence. Wikimedia Deutschland assumed responsibility for the first phase of Wikidata, and initially planned to make the platform available to editors by December 2012. Wikidata's first phase became fully operational in March 2013.\nIn April 2012, Justin Knapp became the first single contributor to make over one million edits to Wikipedia. Jimmy Wales congratulated Knapp for his work and presented him with the site's \"Special Barnstar\" medal and the \"Golden Wiki\" award for his achievement. Wales also declared that 20 April would be \"Justin Knapp Day\".\n\nOn 13 July 2012, the English Wikipedia gained its 4-millionth article, Izbat al-Burj. In October 2012, historian and Wikipedia editor Richard J. Jensen opined that the English Wikipedia was \"nearing completion\", noting that the number of regularly active editors had fallen significantly since 2007, despite Wikipedia's rapid growth in article count and readership.\n\nAccording to Alexa Internet, Wikipedia was the world's sixth-most-popular website as of November 2012. Dow Jones ranked Wikipedia fifth worldwide as of December 2012.\n\nOn 22 January 2013, the Italian Wikipedia became the fifth language edition of Wikipedia to exceed 1 million articles, while the Russian and Spanish Wikipedias gained their millionth articles on 11 and 16 May respectively. On 15 July the Swedish and on 24 September the Polish Wikipedias gained their millionth articles, becoming the eighth and ninth Wikipedia editions to do so.\n\nOn 27 January, the main belt asteroid 274301 was officially renamed \"Wikipedia\" by the Committee for Small Body Nomenclature.\n\nThe first phase of the Wikidata database, automatically providing interlanguage links and other data, became available for all language editions in March 2013.\n\nIn April 2013, the French secret service was accused of attempting to censor Wikipedia by threatening a Wikipedia volunteer with arrest unless \"classified information\" about a military radio station was deleted.\nIn July, the VisualEditor editing system was launched, forming the first stage of an effort to allow articles to be edited with a word processor-like interface instead of using wikimarkup. An editor specifically designed for smartphones and other mobile devices was also launched.\n\nIn February 2014, a project to make a print edition of the English Wikipedia, consisting of 1,000 volumes and over 1,100,000 pages, was launched by German Wikipedia contributors. The project sought funding through Indiegogo, and was intended to honor the contributions of Wikipedia's editors. On 22 October 2014, the first monument to Wikipedia was unveiled in the Polish town of Slubice.\n\nOn 8 June, 15 June and 16 July 2014, the Waray Wikipedia, the Vietnamese Wikipedia and the Cebuano Wikipedia exceeded the one million article mark respectively. These were the tenth, eleventh and twelfth Wikipedias to reach that milestone. Despite having very few active users, the Waray and Cebuano Wikipedias had a high number of automatically generated articles created by bots.\n\nIn mid-2015, Wikipedia was the world's seventh-most-popular website according to Alexa Internet, down one place from the position it held in November 2012. At the start of 2015, Wikipedia remained the largest general-knowledge encyclopedia online, with a combined total of over 36 million mainspace articles across all 291 language editions. On average, Wikipedia receives a total of 10 billion global pageviews from around 495 million unique visitors every month, including 85 million visitors from the United States alone, where it is the sixth-most-popular site.\n\"Print Wikipedia\" was an art project by Michael Mandiberg that printed out the 7473 volumes of Wikipedia as it existed on 7 April 2015. Each volume has 700 pages.\n\nOn 1 November 2015, the English Wikipedia reached 5,000,000 articles with the creation of an article on \"Persoonia terminalis\", a type of shrub.\n\nOn 19 January 2016, the Japanese Wikipedia exceeded the one million article mark, becoming the thirteenth Wikipedia to reach that milestone. The millionth article was (a World War II submarine of the Imperial Japanese Navy).\n\nIn mid-2016, Wikipedia was once again the world's sixth-most-popular website according to Alexa Internet, up one place from the position it held in the previous year.\n\nIn October 2016, the mobile version of Wikipedia got a new look.\n\nIn mid-2017, Wikipedia was listed as the world's fifth-most-popular website according to Alexa Internet, rising one place from the position it held in the previous year. Wikipedia Zero was made available in Iraq and Afghanistan.\n\nOn 29 April 2017, the Turkish authorities blocked online access to Wikipedia in all languages across Turkey. The encrypted Japanese Wikipedia has been blocked in China since 28 December 2017.\n\nDuring 2018, Wikipedia retained its listing as the world's fifth-most-popular website according to Alexa Internet. One notable development was the use of Artificial Intelligence to create draft articles on overlooked topics.\n\nOn 13 April 2018, the number of Chinese Wikipedia articles exceeded 1 million, becoming the fourteenth Wikipedia to reach that milestone. The Chinese Wikipedia has been blocked in Mainland China since May 2015. Later in the year, on 26 June, the Portuguese Wikipedia exceeded the one million article mark, becoming the fifteenth Wikipedia to reach that milestone. The millionth article was \"\" (the Pardon of Richard Nixon).\n\n\n\n\n\n\nEvery year, Wikipedia runs a fundraising campaign to support its operations.\n\n\nBecause Wikipedia biographies are often updated as soon as new information comes to light, they are often used as a reference source on the lives of . This has led to attempts to manipulate and falsify Wikipedia articles for promotional or defamatory purposes (see Controversies). It has also led to novel uses of the biographical material provided. Some notable people's lives are being affected by their Wikipedia biography.\n\nSanger played an important role in the early stages of creating Wikipedia. Wales says that Sanger was his subordinate employee. Sanger initially brought the wiki concept to Wales and suggested it be applied to Nupedia and then, after some initial skepticism, Wales agreed to try it. It was Jimmy Wales, along with other people, who came up with the broader idea of an open-source, collaborative encyclopedia that would accept contributions from ordinary people and it was Wales who invested in it. Wales stated in October 2001 that \"Larry had the idea to use Wiki software.\" Sanger coined the portmanteau \"Wikipedia\" as the project name. In review, Larry Sanger conceived of a wiki-based encyclopedia as a strategic solution to Nupedia's inefficiency problems. In terms of project roles, Sanger spearheaded and pursued the project as its leader in its first year, and did most of the early work in formulating policies (including \"Ignore all rules\" and \"Neutral point of view\") and building up the community. Upon departure in March 2002, Sanger emphasized the main issue was purely the cessation of Bomis' funding for his role, which was not viable part-time, and his changing personal priorities; however, by 2004, the two had drifted apart and Sanger became more critical. Two weeks after the launch of Citizendium, Sanger criticized Wikipedia, describing the latter as \"broken beyond repair.\" By 2005 Wales began to dispute Sanger's role in the project, three years after Sanger left.\n\nIn 2005, Wales described himself simply as the founder of Wikipedia; however, according to Brian Bergstein of the Associated Press, \"Sanger has long been cited as a co-founder.\" There is evidence that Sanger was called co-founder, along with Wales, as early as 2001, and he is referred to as such in early Wikipedia press releases and Wikipedia articles and in a September 2001 \"New York Times\" article for which both were interviewed. In 2006, Wales said, \"He used to work for me [...] I don't agree with calling him a co-founder, but he likes the title\"; nonetheless, before January 2004, Wales did not dispute Sanger's status as co-founder and, indeed, identified himself as \"co-founder\" as late as August 2002. In Sanger's introductory message to the Nupedia mailing list, he said that \"Jimmy Wales contacted me and asked me to apply as editor-in-chief of Nupedia. Apparently, Bomis, Inc. (which owns Nupedia)... who could manage this sort of long-term project, he thought I would be perfect for the job. This is indeed my dream job\". Sanger said \"He [Wales] had had the idea for Nupedia since at least last fall\".\n\nAs of March 2007: Wales emphasized this employer–employee relationship and his ultimate authority, terming himself Wikipedia's sole founder; and Sanger emphasized their statuses as co-founders, referencing earlier versions of Wikipedia pages (2004, 2006), press releases (2002–2004), and media coverage from the time of his involvement routinely terming them in this manner.\n\n\n\nThe goals which led to GNUpedia were published at least as early as 18 December 2000, and these exact goals were finalized on the 12th and 13th of January 2001, albeit with a copyright of 1999, from when Stallman had first started considering the problem. The only sentence added between 18 December and the unveiling of GNUpedia the week of 12–16 January was this: \"The GNU Free Documentation License would be a good license to use for courses.\"\n\nGNUpedia was \"formally\" announced on the \"slashdot\" website, on 16 January, the same day that their mailing list first went online with a test-message. Wales posted to the list on 17 January, the first full day of messages, explaining the discussions with Stallman concerning the change in Nupedia content-licensing, and suggesting cooperation. Stallman himself first posted on 19 January, and, in his second post on 22 January, mentioned that discussions about merging Wikipedia and GNUpedia were ongoing. Within a couple of months, Wales had changed his email signature from the open source encyclopedia to the free encyclopedia; both Nupedia and Wikipedia had adopted the GFDL; and the merger of GNUpedia into Wikipedia was effectively accomplished.\n\nIn a separate but similar incident, the campaign manager for Cathy Cox, Morton Brilliant, resigned after being found to have added negative information to the Wikipedia entries of political opponents. Following media publicity, the incidents tapered off around August 2006.\n\nThere are a number of . Other sites also use the MediaWiki software and concept, popularized by Wikipedia. No list of them is maintained.\n\nSpecialized foreign language forks using the Wikipedia concept include Enciclopedia Libre (Spanish), \"Wikiweise\" (German), WikiZnanie (Russian), Susning.nu (Swedish), and Baidu Baike (Chinese). Some of these (such as \"Enciclopedia Libre\") use GFDL or compatible licenses as used by Wikipedia, leading to exchange of material with their respective language Wikipedias.\n\nIn 2006, Larry Sanger founded Citizendium, based upon a modified version of MediaWiki. The site said it aimed 'to improve on the Wikipedia model with \"gentle expert oversight\", among other things'. (See also Nupedia).\n\nThe German Wikipedia was the first to be partly published also using other media (rather than online on the internet), including releases on CD in November 2004 and more extended versions on CDs or DVD in April 2005 and December 2006. In December 2005, the publisher Zenodot Verlagsgesellschaft mbH, a sister company of Directmedia, published a 139-page book explaining Wikipedia, its history and policies, which was accompanied by a 7.5 GB DVD containing 300,000 articles and 100,000 images from the German Wikipedia. Originally, Directmedia also announced plans to print the German Wikipedia in its entirety, in 100 volumes of 800 pages each. Publication was due to begin in October 2006, and finish in 2010. In March 2006, however, this project was called off.\n\nIn September 2008, Bertelsmann published a 1000 pages volume with a selection of popular German Wikipedia articles. Bertelsmann paid voluntarily 1 Euro per sold copy to Wikimedia Deutschland.\n\nThe first CD version containing a selection of articles from the English Wikipedia was published in April 2006 by as the \"2006 Wikipedia CD Selection\". In April 2007, \"Wikipedia Version 0.5\", a CD containing around 2000 articles selected from the online encyclopedia was published by the Wikimedia Foundation and Linterweb. The selection of articles included was based on both the quality of the online version and the importance of the topic to be included. This CD version was created as a test-case in preparation for a DVD version including far more articles. The CD version can be purchased online, downloaded as a DVD image file or , or accessed online at the project's website.\n\nA free software project has also been launched to make a static version of Wikipedia available for use on iPods. The \"Encyclopodia\" project was started around March 2006 and can currently be used on 1st to 4th generation iPods.\n\nIn limited ways, the Wikimedia Foundation is protected by Section 230 of the Communications Decency Act. In the defamation action \"Bauer et al. v. Glatzer et al.\", it was held that Wikimedia had no case to answer because of this section. A similar law in France caused a lawsuit to be dismissed in October 2007. In 2013, a German appeals court (the Higher Regional Court of Stuttgart) ruled that Wikipedia is a \"service provider\" not a \"content provider\", and as such is immune from liability as long as it takes down content that is accused of being illegal.\n\n\nHistorical summaries\n\nSize and statistics\n\nDiscussion and debate archives\n\nOther\n"}
{"id": "14073", "url": "https://en.wikipedia.org/wiki?curid=14073", "title": "Hydropower", "text": "Hydropower\n\nHydropower or water power (from , \"water\") is power derived from the energy of falling water or fast running water, which may be harnessed for useful purposes. Since ancient times, hydropower from many kinds of watermills has been used as a renewable energy source for irrigation and the operation of various mechanical devices, such as gristmills, sawmills, textile mills, trip hammers, dock cranes, domestic lifts, and ore mills. A trompe, which produces compressed air from falling water, is sometimes used to power other machinery at a distance.\n\nIn the late 19th century, hydropower became a source for generating electricity. Cragside in Northumberland was the first house powered by hydroelectricity in 1878 and the first commercial hydroelectric power plant was built at Niagara Falls in 1879. In 1881, street lamps in the city of Niagara Falls were powered by hydropower.\n\nSince the early 20th century, the term has been used almost exclusively in conjunction with the modern development of hydroelectric power. International institutions such as the World Bank view hydropower as a means for economic development without adding substantial amounts of carbon to the atmosphere,\nbut dams can have significant negative social and environmental impacts.\n\nIn India, water wheels and watermills were built, possibly as early as the 4th century BC, although records of that era are spotty at best.\n\nIn the Roman Empire, water-powered mills produced flour from grain, and were also used for sawing timber and stone; in China, watermills were widely used since the Han dynasty. In China and the rest of the Far East, hydraulically operated \"pot wheel\" pumps raised water into crop or irrigation canals.\n\nThe power of a wave of water released from a tank was used for extraction of metal ores in a method known as hushing. The method was first used at the Dolaucothi Gold Mines in Wales from 75 AD onwards, but had been developed in Spain at such mines as Las Médulas. Hushing was also widely used in Britain in the Medieval and later periods to extract lead and tin ores. It later evolved into hydraulic mining when used during the California Gold Rush.\n\nIn the Middle Ages, Islamic mechanical engineer Al-Jazari described designs for 50 devices, many of them water powered, in his book, \"The Book of Knowledge of Ingenious Mechanical Devices\", including clocks, a device to serve wine, and five devices to lift water from rivers or pools, though three are animal-powered and one can be powered by animal or water. These include an endless belt with jugs attached, a cow-powered shadoof, and a reciprocating device with hinged valves.\n\nIn 1753, French engineer Bernard Forest de Bélidor published \"Architecture Hydraulique\" which described vertical- and horizontal-axis hydraulic machines. By the late nineteenth century, the electric generator was developed by a team led by project managers and prominent pioneers of renewable energy Jacob S. Gibbs and Brinsley Coleberd and could now be coupled with hydraulics. The growing demand for the Industrial Revolution would drive development as well.\n\nHydraulic power networks used pipes to carry pressurized water and transmit mechanical power from the source to end users. The power source was normally a head of water, which could also be assisted by a pump. These were extensive in Victorian cities in the United Kingdom. A hydraulic power network was also developed in Geneva, Switzerland. The world-famous Jet d'Eau was originally designed as the over-pressure relief valve for the network.\n\nAt the beginning of the Industrial Revolution in Britain, water was the main source of power for new inventions such as Richard Arkwright's water frame. Although the use of water power gave way to steam power in many of the larger mills and factories, it was still used during the 18th and 19th centuries for many smaller operations, such as driving the bellows in small blast furnaces (e.g. the Dyfi Furnace) and gristmills, such as those built at Saint Anthony Falls, which uses the 50-foot (15 m) drop in the Mississippi River.\n\nIn the 1830s, at the early peak in the US canal-building, hydropower provided the energy to transport barge traffic up and down steep hills using inclined plane railroads. As railroads overtook canals for transportation, canal systems were modified and developed into hydropower systems; the history of Lowell, Massachusetts is a classic example of commercial development and industrialization, built upon the availability of water power.\n\nTechnological advances had moved the open water wheel into an enclosed turbine or water motor. In 1848 James B. Francis, while working as head engineer of Lowell's Locks and Canals company, improved on these designs to create a turbine with 90% efficiency. He applied scientific principles and testing methods to the problem of turbine design. His mathematical and graphical calculation methods allowed the confident design of high-efficiency turbines to exactly match a site's specific flow conditions. The Francis reaction turbine is still in wide use today. In the 1870s, deriving from uses in the California mining industry, Lester Allan Pelton developed the high efficiency Pelton wheel impulse turbine, which utilized hydropower from the high head streams characteristic of the mountainous California interior.\n\nA hydropower resource can be evaluated by its available power. Power is a function of the hydraulic head and rate of fluid flow. The head is the energy per unit weight (or unit mass) of water. The static head is proportional to the difference in height through which the water falls. Dynamic head is related to the velocity of moving water. Each unit of water can do an amount of work equal to its weight times the head.\n\nThe power available from falling water can be calculated from the flow rate and density of water, the height of fall, and the local acceleration due to gravity.\nIn SI units, the power is:\n\nformula_1\n\nwhere\n\nTo illustrate, power is calculated for a turbine that is 85% efficient, with water at 1000 kg/cubic metre (62.5 pounds/cubic foot) and a flow rate of 80 cubic-meters/second (2800 cubic-feet/second), gravity of 9.81 metres per second squared and with a net head of 145 m (480 ft).\n\nIn SI units:\n\nIn English units, the density is given in pounds per cubic foot so acceleration due to gravity is inherent in the unit of weight. A conversion factor is required to change from foot lbs/second to kilowatts:\n\nOperators of hydroelectric stations will compare the total electrical energy produced with the theoretical potential energy of the water passing through the turbine to calculate efficiency. Procedures and definitions for calculation of efficiency are given in test codes such as ASME PTC 18 and IEC 60041. Field testing of turbines is used to validate the manufacturer's guaranteed efficiency. Detailed calculation of the efficiency of a hydropower turbine will account for the head lost due to flow friction in the power canal or penstock, rise in tail water level due to flow, the location of the station and effect of varying gravity, the temperature and barometric pressure of the air, the density of the water at ambient temperature, and the altitudes above sea level of the forebay and tailbay. For precise calculations, errors due to rounding and the number of significant digits of constants must be considered.\n\nSome hydropower systems such as water wheels can draw power from the flow of a body of water without necessarily changing its height. In this case, the available power is the kinetic energy of the flowing water. Over-shot water wheels can efficiently capture both types of energy.\nThe water flow in a stream can vary widely from season to season. Development of a hydropower site requires analysis of flow records, sometimes spanning decades, to assess the reliable annual energy supply. Dams and reservoirs provide a more dependable source of power by smoothing seasonal changes in water flow. However reservoirs have significant environmental impact, as does alteration of naturally occurring stream flow. The design of dams must also account for the worst-case, \"probable maximum flood\" that can be expected at the site; a spillway is often included to bypass flood flows around the dam. A computer model of the hydraulic basin and rainfall and snowfall records are used to predict the maximum flood.\n\nWhere there is a plentiful head of water it can be made to generate compressed air directly without moving parts. In these designs, a falling column of water is purposely mixed with air bubbles generated through turbulence or a venturi pressure reducer at the high-level intake. This is allowed to fall down a shaft into a subterranean, high-roofed chamber where the now-compressed air separates from the water and becomes trapped. The height of the falling water column maintains compression of the air in the top of the chamber, while an outlet, submerged below the water level in the chamber allows water to flow back to the surface at a lower level than the intake. A separate outlet in the roof of the chamber supplies the compressed air. A facility on this principle was built on the Montreal River at Ragged Shutes near Cobalt, Ontario in 1910 and supplied 5,000 horsepower to nearby mines.\n\nHydroelectricity is the application of hydropower to generate electricity. \nIt is the primary use of hydropower today.\nHydroelectric power plants can include a reservoir (generally created by a dam) to exploit the energy of falling water, or can use the kinetic energy of water as in run-of-the-river hydroelectricity.\nHydroelectric plants can vary in size from small community sized plants (micro hydro) to very large plants supplying power to a whole country. \nAs of 2019, the five largest power stations in the world are conventional hydroelectric power stations with dams.\n\nHydroelectricity can also be used to store energy in the form of potential energy between two reservoirs at different heights with pumped-storage hydroelectricity. \nWater is pumped uphill into reservoirs during periods of low demand to be released for generation when demand is high or system generation is low.\n\nOther forms of electricity generation with hydropower include tidal stream generators using energy from tidal power generated from oceans, rivers, and human-made canal systems to generating electricity. \n\n"}
{"id": "14076", "url": "https://en.wikipedia.org/wiki?curid=14076", "title": "Horse breed", "text": "Horse breed\n\nA horse breed is a selectively bred population of domesticated horses, often with pedigrees recorded in a breed registry. However, the term is sometimes used in a very broad sense to define landrace animals, or naturally selected horses of a common phenotype located within a limited geographic region. Depending on definition, hundreds of \"breeds\" exist today, developed for many different uses. Horse breeds are loosely divided into three categories based on general temperament: spirited \"hot bloods\" with speed and endurance; \"cold bloods,\" such as draft horses and some ponies, suitable for slow, heavy work; and \"warmbloods,\" developed from crosses between hot bloods and cold bloods, often focusing on creating breeds for specific riding purposes, particularly in Europe. \n\nHorse breeds are groups of horses with distinctive characteristics that are transmitted consistently to their offspring, such as conformation, color, performance ability, or disposition. These inherited traits are usually the result of a combination of natural crosses and artificial selection methods aimed at producing horses for specific tasks. Certain breeds are known for certain talents. For example, Standardbreds are known for their speed in harness racing. Some breeds have been developed through centuries of crossings with other breeds, while others, such as Tennessee Walking Horses and Morgans, developed from a single sire from which all current breed members descend. More than 300 horse breeds exist in the world today.\n\nModern horse breeds developed in response to a need for \"form to function\", the necessity to develop certain physical characteristics to perform a certain type of work. Thus, powerful but refined breeds such as the Andalusian or the Lusitano developed in the Iberian peninsula as riding horses that also had a great aptitude for dressage, while heavy draft horses such as the Clydesdale and the Shire developed out of a need to perform demanding farm work and pull heavy wagons. Ponies of all breeds originally developed mainly from the need for a working animal that could fulfill specific local draft and transportation needs while surviving in harsh environments. However, by the 20th century, many pony breeds had Arabian and other blood added to make a more refined pony suitable for riding. Other horse breeds developed specifically for light agricultural work, heavy and light carriage and road work, various equestrian disciplines, or simply as pets.\n\nHorses have been selectively bred since their domestication. Today, over 300 breeds of horses are known in the world. However, the concept of purebred bloodstock and a controlled, written breed registry only became of significant importance in modern times. Today, the standards for defining and registration of different breeds vary. Sometimes, purebred horses are called Thoroughbreds, which is incorrect; \"Thoroughbred\" is a specific breed of horse, while a \"purebred\" is a horse (or any other animal) with a defined pedigree recognized by a breed registry. \n\nAn early example of people who practiced selective horse breeding were the Bedouin, who had a reputation for careful breeding practices, keeping extensive pedigrees of their Arabian horses and placing great value upon pure bloodlines. Though these pedigrees were originally transmitted by an oral tradition, written pedigrees of Arabian horses can be found that date to the 14th century. In the same period of the early Renaissance, the Carthusian monks of southern Spain bred horses and kept meticulous pedigrees of the best bloodstock; the lineage survives to this day in the Andalusian horse. One of the earliest formal registries was General Stud Book for Thoroughbreds, which began in 1791 and traced back to the Arabian stallions imported to England from the Middle East that became the foundation stallions for the breed.\n\nSome breed registries have a closed stud book, where registration is based on pedigree, and no outside animals can gain admittance. For example, a registered Thoroughbred or Arabian must have two registered parents of the same breed. \n\nOther breeds have a partially closed stud book, but still allow certain infusions from other breeds. For example, the modern Appaloosa must have at least one Appaloosa parent, but may also have a Quarter Horse, Thoroughbred, or Arabian parent, so long as the offspring exhibits appropriate color characteristics. The Quarter Horse normally requires both parents to be registered Quarter Horses, but allows \"Appendix\" registration of horses with one Thoroughbred parent, and the horse may earn its way to full registration by completing certain performance requirements.\nOpen stud books exist for horse breeds that either have not yet developed a rigorously defined standard phenotype, or for breeds that register animals that conform to an ideal via the process of passing a studbook selection process. Most of the warmblood breeds used in sport horse disciplines have open stud books to varying degrees. While pedigree is considered, outside bloodlines are admitted to the registry if the horses meet the set standard for the registry. These registries usually require a studbook selection process involving judging of an individual animal's quality, performance, and conformation before registration is finalized. A few \"registries,\" particularly some color breed registries, are very open and will allow membership of all horses that meet limited criteria, such as coat color and species, regardless of pedigree or conformation.\n\nBreed registries also differ as to their acceptance or rejection of breeding technology. For example, all Jockey Club Thoroughbred registries require that a registered Thoroughbred be a product of a natural mating, so-called \"live cover\". A foal born of two Thoroughbred parents, but by means of artificial insemination or embryo transfer, cannot be registered in the Thoroughbred studbook. However, since the advent of DNA testing to verify parentage, most breed registries now allow artificial insemination, embryo transfer, or both. The high value of stallions has helped with the acceptance of these techniques because they allow a stallion to breed more mares with each \"collection\" and greatly reduce the risk of injury during mating. Cloning of horses is highly controversial, and at the present time most mainstream breed registries will not accept cloned horses, though several cloned horses and mules have been produced. Such restrictions have led to legal challenges in the United States, sometime based on state law and sometimes based on antitrust laws.\n\nHorses can crossbreed with other equine species to produce hybrids. These hybrid types are not breeds, but they resemble breeds in that crosses between certain horse breeds and other equine species produce characteristic offspring. The most common hybrid is the mule, a cross between a \"jack\" (male donkey) and a mare. A related hybrid, the hinny, is a cross between a stallion and a jenny (female donkey). Most other hybrids involve the zebra (see Zebroid). With rare exceptions, most equine hybrids are sterile and cannot reproduce. A notable exception is hybrid crosses between horses and \"Equus ferus przewalskii\", commonly known as Przewalski's horse.\n"}
{"id": "14078", "url": "https://en.wikipedia.org/wiki?curid=14078", "title": "Halfbakery", "text": "Halfbakery\n\nHalfbakery is a community-based ideas bank used by people who wish to propose and develop (not always serious) half-baked inventions. It has distinguished itself by minimalism, irreverence, and a cast of regulars whose takes on suggested inventions are often funnier than the original submission. It was created in 1999.\n\nHalfbakery can be read by anyone, but only logged-in users can contribute. A user with an account can submit new \"ideas\" (the inventions) and add \"links\" and \"annotations\" to existing ideas. An account is currently\ngained by e-mailing the \"bakesperson,\" an e-mail address provided on the site. Logged in users can also vote \"for\" or \"against\" a particular idea. Users are able to edit and delete their ideas, links, annotations, votes, and even their whole account. A few selected users can illustrate ideas, and the illustrations are linked to on the idea's page.\n\nThe site is run by the bakesperson, jutta, and a small group of volunteer moderators who can contribute ideas themselves and have rights to delete ideas, annotations and links provided by other users. Moderators, however, must adhere to guidelines and are generally forbidden from deleting the links or annotations of other users. Moderators are unable to see who cast votes or alter votes other than their own.\n\nHalfbakery has a variety of mechanisms for creating and discussing ideas.\n\nAn idea is initially created with the following components:\n\nOnce created, an idea can be discussed by other users. Users can add annotations, include links to other Halfbaked ideas, and vote on the idea. All user comments, links, and votes can be changed or removed by the users who posted them, and comments and links can also be removed by the idea creator.\n\nThe style of writing on the Halfbakery is distinctive. Close attention is paid to grammatical, semantical and spelling mistakes, in contrast to other online forums. Writing is seldom overly formal, but too much slang or contraction is frowned upon. Ideas can be either serious or satirical, but ideas written too formally are not well received. Lack of paragraph breaks usually draws criticism concerning the perceived readability. A common occurrence is a user giving a negative vote, promising to retract it once the offending mistakes have been removed.\n\nThere is a lot of Halfbakery jargon, due to its communal nature. Here are a few examples:\n\n\nThe Halfbakery has a number of in-jokes. These mostly take the form of humorous misspellings, prodigious reference to things, or reference to several of the regular users. A few in-jokes are listed here, although the only way to know all of them is to be a regular user of the Halfbakery for some time.\n\n\n\n"}
{"id": "14082", "url": "https://en.wikipedia.org/wiki?curid=14082", "title": "Horse breeding", "text": "Horse breeding\n\nHorse breeding is reproduction in horses, and particularly the human-directed process of selective breeding of animals, particularly purebred horses of a given breed. Planned matings can be used to produce specifically desired characteristics in domesticated horses. Furthermore, modern breeding management and technologies can increase the rate of conception, a healthy pregnancy, and successful foaling.\n\nThe male parent of a horse, a stallion, is commonly known as the \"sire\" and the female parent, the mare, is called the \"dam\". Both are genetically important, as each parent provides half of the genetic makeup of the ensuing offspring, called a foal. Contrary to popular misuse, \"colt\" refers to a young male horse only; \"filly\" is a young female. Though many horse owners may simply breed a family mare to a local stallion in order to produce a companion animal, most professional breeders use selective breeding to produce individuals of a given phenotype, or breed. Alternatively, a breeder could, using individuals of differing phenotypes, create a new breed with specific characteristics.\n\nA horse is \"bred\" where it is foaled (born). Thus a colt conceived in England but foaled in the United States is regarded as being bred in the US. In some cases, most notably in the Thoroughbred breeding industry, American- and Canadian-bred horses may also be described by the state or province in which they are foaled. Some breeds denote the country, or state, where conception took place as the origin of the foal.\n\nSimilarly, the \"breeder\", is the person who owned or leased the mare at the time of foaling. That individual may not have had anything to do with the mating of the mare. It is important to review each breed registry's rules to determine which applies to any specific foal.\n\nIn the horse breeding industry, the term \"half-brother\" or \"half-sister\" only describes horses which have the same dam, but different sires. Horses with the same sire but different dams are simply said to be \"by the same sire\", and no sibling relationship is implied. \"Full\" (or \"own\") siblings have both the same dam and the same sire. The terms paternal half-sibling, and maternal half-sibling are also often used. Three-quarter siblings are horses out of the same dam, and are by sires that are either half-brothers (i.e. same dam) or who are by the same sire.\n\nThoroughbreds and Arabians are also classified through the \"distaff\" or direct female line, known as their \"family\" or \"tail female\" line, tracing back to their taproot foundation bloodstock or the beginning of their respective stud books. The female line of descent always appears at the bottom of a tabulated pedigree and is therefore often known as the \"bottom line\". In addition, the maternal grandfather of a horse has a special term: damsire.\n\n\"Linebreeding\" technically is the duplication of fourth generation or more distant ancestors. However, the term is often used more loosely, describing horses with duplication of ancestors closer than the fourth generation. It also is sometimes used as a euphemism for the practice of inbreeding, a practice that is generally frowned upon by horse breeders, though used by some in an attempt to fix certain traits.\n\nThe estrous cycle (also spelled oestrous) controls when a mare is sexually receptive toward a stallion, and helps to physically prepare the mare for conception. It generally occurs during the spring and summer months, although some mares may be sexually receptive into the late fall, and is controlled by the photoperiod (length of the day), the cycle first triggered when the days begin to lengthen. The estrous cycle lasts about 19–22 days, with the average being 21 days. As the days shorten, the mare returns to a period when she is not sexually receptive, known as anestrus. Anestrus – occurring in the majority of, but not all, mares – prevents the mare from conceiving in the winter months, as that would result in her foaling during the harshest part of the year, a time when it would be most difficult for the foal to survive.\n\nThis cycle contains 2 phases:\n\nDepending on breed, on average, 16% of mares have double ovulations, allowing them to twin, though this does not affect the length of time of estrus or diestrus.\n\nChanges in hormone levels can have great effects on the physical characteristics of the reproductive organs of the mare, thereby preparing, or preventing, her from conceiving.\n\nThe cycle is controlled by several hormones which regulate the estrous cycle, the mare's behavior, and the reproductive system of the mare. The cycle begins when the increased day length causes the pineal gland to reduce the levels of melatonin, thereby allowing the hypothalamus to secrete GnRH.\n\nWhile horses in the wild mate and foal in mid to late spring, in the case of horses domestically bred for competitive purposes, especially horse racing, it is desirable that they be born as close to January 1 in the northern hemisphere or August 1 in the southern hemisphere as possible, so as to be at an advantage in size and maturity when competing against other horses in the same age group. When an early foal is desired, barn managers will put the mare \"under lights\" by keeping the barn lights on in the winter to simulate a longer day, thus bringing the mare into estrus sooner than she would in nature. Mares signal estrus and ovulation by urination in the presence of a stallion, raising the tail and revealing the vulva. A stallion, approaching with a high head, will usually nicker, nip and nudge the mare, as well as sniff her urine to determine her readiness for mating.\n\nOnce fertilized, the oocyte (egg) remains in the oviduct for approximately 5.5 more days, and then descends into the uterus. The initial single cell combination is already dividing and by the time of entry into the uterus, the egg might have already reached the blastocyst stage.\n\nThe gestation period lasts for about eleven months, or about 340 days (normal average range 320–370 days). During the early days of pregnancy, the conceptus is mobile, moving about in the uterus until about day 16 when \"fixation\" occurs. Shortly after fixation, the embryo proper (so called up to about 35 days) will become visible on trans-rectal ultrasound (about day 21) and a heartbeat should be visible by about day 23. After the formation of the endometrial cups and early placentation is initiated (35–40 days of gestation) the terminology changes, and the embryo is referred to as a fetus. True implantation – invasion into the endometrium of any sort – does not occur until about day 35 of pregnancy with the formation of the endometrial cups, and true placentation (formation of the placenta) is not initiated until about day 40-45 and not completed until about 140 days of pregnancy. The fetus sex can be determined by day 70 of the gestation using ultrasound. Halfway through gestation the fetus is the size of between a rabbit and a beagle. The most dramatic fetal development occurs in the last 3 months of pregnancy when 60% of fetal growth occurs.\n\nColts are carried on average about 4 days longer than fillies.\n\nDomestic mares receive specific care and nutrition to ensure that they and their foals are healthy. Mares are given vaccinations against diseases such as the Rhinopneumonitis (EHV-1) virus (which can cause abortions) as well as vaccines for other conditions that may occur in a given region of the world. Pre-foaling vaccines are recommended 4–6 weeks prior to foaling to maximize the immunoglobulin content of the colostrum in the first milk. Mares are dewormed a few weeks prior to foaling, as the mare is the primary source of parasites for the foal.\n\nMares can be used for riding or driving during most of their pregnancy. Exercise is healthy, though should be moderated when a mare is heavily in foal. Exercise in excessively high temperatures has been suggested as being detrimental to pregnancy maintenance during the embryonic period; however ambient temperatures encountered during the research were in the region of 100 degrees F and the same results may not be encountered in regions with lower ambient temperatures.\n\nDuring the first several months of pregnancy, the nutritional requirements do not increase significantly since the rate of growth of the fetus is very slow. However, during this time, the mare may be provided supplemental vitamins and minerals, particularly if forage quality is questionable. During the last 3–4 months of gestation, rapid growth of the fetus increases the mare's nutritional requirements. Energy requirements during these last few months, and during the first few months of lactation are similar to those of a horse in full training. Trace minerals such as copper are extremely important, particularly during the tenth month of pregnancy, for proper skeletal formation. Many feeds designed for pregnant and lactating mares provide the careful balance required of increased protein, increased calories through extra fat as well as vitamins and minerals. Overfeeding the pregnant mare, particularly during early gestation, should be avoided, as excess weight may contribute to difficulties foaling or fetal/foal related problems.\n\nMares due to foal are usually separated from other horses, both for the benefit of the mare and the safety of the soon-to-be-delivered foal. In addition, separation allows the mare to be monitored more closely by humans for any problems that may occur while giving birth. In the northern hemisphere a special foaling stall that is large and clutter free is frequently used, particularly by major breeding farms. Originally, this was due in part to a need for protection from the harsh winter climate present when mares foal early in the year, but even in moderate climates, such as Florida, foaling stalls are still common because they allow closer monitoring of mares. Smaller breeders often use a small pen with a large shed for foaling, or they may remove a wall between two box stalls in a small barn to make a large stall. In the milder climates seen in much of the southern hemisphere, most mares foal outside, often in a paddock built specifically for foaling, especially on the larger stud farms. Many stud farms worldwide employ technology to alert human managers when the mare is about to foal, including webcams, closed-circuit television, or assorted types of devices that alert a handler via a remote alarm when a mare lies down in a position to foal.\n\nOn the other hand, some breeders, particularly those in remote areas or with extremely large numbers of horses, may allow mares to foal out in a field amongst a herd, but may also see higher rates of foal and mare mortality in doing so.\n\nMost mares foal at night or early in the morning, and prefer to give birth alone when possible. Labor is rapid, often no more than 30 minutes, and from the time the feet of the foal appear to full delivery is often only about 15 to 20 minutes. Once the foal is born, the mare will lick the newborn foal to clean it and help blood circulation. In a very short time, the foal will attempt to stand and get milk from its mother. A foal should stand and nurse within the first hour of life.\n\nTo create a bond with her foal, the mare licks and nuzzles the foal, enabling her to distinguish the foal from others. Some mares are aggressive when protecting their foals, and may attack other horses or unfamiliar humans that come near their newborns.\n\nAfter birth, a foal's navel is dipped in antiseptic to prevent infection, it is sometimes given an enema to help clear the meconium from its digestive tract, and the newborn is monitored to ensure that it stands and nurses without difficulty. While most horse births happen without complications, many owners have first aid supplies prepared and a veterinarian on call in case of a birthing emergency. People who supervise foaling should also watch the mare to be sure that she passes the placenta in a timely fashion, and that it is complete with no fragments remaining in the uterus, where retained fetal membranes could cause a serious inflammatory condition (endometritis) and/or infection. If the placenta is not removed from the stall after it is passed, a mare will often eat it, an instinct from the wild, where blood would attract predators.\n\nFoals develop rapidly, and within a few hours a wild foal can travel with the herd. In domestic breeding, the foal and dam are usually separated from the herd for a while, but within a few weeks are typically pastured with the other horses. A foal will begin to eat hay, grass and grain alongside the mare at about 4 weeks old; by 10–12 weeks the foal requires more nutrition than the mare's milk can supply. Foals are typically weaned at 4–8 months of age, although in the wild a foal may nurse for a year.\n\nBeyond the appearance and conformation of a specific type of horse, breeders aspire to improve physical performance abilities. This concept, known as matching \"form to function,\" has led to the development of not only different breeds, but also families or bloodlines within breeds that are specialists for excelling at specific tasks.\n\nFor example, the Arabian horse of the desert naturally developed speed and endurance to travel long distances and survive in a harsh environment, and domestication by humans added a trainable disposition to the animal's natural abilities. In the meantime, in northern Europe, the locally adapted heavy horse with a thick, warm coat was domesticated and put to work as a farm animal that could pull a plow or wagon. This animal was later adapted through selective breeding to create a strong but rideable animal suitable for the heavily armored knight in warfare.\n\nThen, centuries later, when people in Europe wanted faster horses than could be produced from local horses through simple selective breeding, they imported Arabians and other oriental horses to breed as an outcross to the heavier, local animals. This led to the development of breeds such as the Thoroughbred, a horse taller than the Arabian and faster over the distances of a few miles required of a European race horse or light cavalry horse. Another cross between oriental and European horses produced the Andalusian, a horse developed in Spain that was powerfully built, but extremely nimble and capable of the quick bursts of speed over short distances necessary for certain types of combat as well as for tasks such as bullfighting.\n\nLater, the people who settled the Americas needed a hardy horse that was capable of working with cattle. Thus, Arabians and Thoroughbreds were crossed on Spanish horses, both domesticated animals descended from those brought over by the Conquistadors, and feral horses such as the Mustangs, descended from the Spanish horse, but adapted by natural selection to the ecology and climate of the west. These crosses ultimately produced new breeds such as the American Quarter Horse and the Criollo of Argentina.\n\nIn modern times, these breeds themselves have since been selectively bred to further specialize at certain tasks. One example of this is the American Quarter Horse. Once a general-purpose working ranch horse, different bloodlines now specialize in different events. For example, larger, heavier animals with a very steady attitude are bred to give competitors an advantage in events such as team roping, where a horse has to start and stop quickly, but also must calmly hold a full-grown steer at the end of a rope. On the other hand, for an event known as cutting, where the horse must separate a cow from a herd and prevent it from rejoining the group, the best horses are smaller, quick, alert, athletic and highly trainable. They must learn quickly, have conformation that allows quick stops and fast, low turns, and the best competitors have a certain amount of independent mental ability to anticipate and counter the movement of a cow, popularly known as \"cow sense.\"\n\nAnother example is the Thoroughbred. While most representatives of this breed are bred for horse racing, there are also specialized bloodlines suitable as show hunters or show jumpers. The hunter must have a tall, smooth build that allows it to trot and canter smoothly and efficiently. Instead of speed, value is placed on appearance and upon giving the equestrian a comfortable ride, with natural jumping ability that shows bascule and good form.\n\nA show jumper, however, is bred less for overall form and more for power over tall fences, along with speed, scope, and agility. This favors a horse with a good galloping stride, powerful hindquarters that can change speed or direction easily, plus a good shoulder angle and length of neck. A jumper has a more powerful build than either the hunter or the racehorse.\n\nThe history of horse breeding goes back millennia. Though the precise date is in dispute, humans could have domesticated the horse as far back as approximately 4500 BCE. However, evidence of planned breeding has a more blurry history. It is well known, for example, that the Romans did breed horses and valued them in their armies, but little is known regarding their breeding and husbandry practices: all that remains are statues and artwork. Mankind has plenty of equestrian statues of Roman emperors, horses are mentioned in the Odyssey by Homer, and hieroglyphics and paintings left behind by Egyptians tell stories of pharaohs hunting elephants from chariots. Nearly nothing is known of what became of the horses they bred for hippodromes, for warfare, or even for farming.\n\nOne of the earliest people known to document the breedings of their horses were the Bedouin of the Middle East, the breeders of the Arabian horse. While it is difficult to determine how far back the Bedouin passed on pedigree information via an oral tradition, there were written pedigrees of Arabian horses by CE 1330. The Akhal-Teke of West-Central Asia is another breed with roots in ancient times that was also bred specifically for war and racing. The nomads of the Mongolian steppes bred horses for several thousand years as well, and the Caspian horse is believed to be a very close relative of Ottoman horses from the earliest origins of the Turks in Central Asia.\n\nThe types of horse bred varied with culture and with the times. The uses to which a horse was put also determined its qualities, including smooth amblers for riding, fast horses for carrying messengers, heavy horses for plowing and pulling heavy wagons, ponies for hauling cars of ore from mines, packhorses, carriage horses and many others.\n\nMedieval Europe bred large horses specifically for war, called destriers. These horses were the ancestors of the great heavy horses of today, and their size was preferred not simply because of the weight of the armor, but also because a large horse provided more power for the knight's lance. Weighing almost twice as much as a normal riding horse, the destrier was a powerful weapon in battle meant to act like a giant battering ram that could quite literally run down men on an enemy line.\n\nOn the other hand, during this same time, lighter horses were bred in northern Africa and the Middle East, where a faster, more agile horse was preferred. The lighter horse suited the raids and battles of desert people, allowing them to outmaneuver rather than overpower the enemy. When Middle Eastern warriors and European knights collided in warfare, the heavy knights were frequently outmaneuvered. The Europeans, however, responded by crossing their native breeds with \"oriental\" type horses such as the Arabian, Barb, and Turkoman horse This cross-breeding led both to a nimbler war horse, such as today's Andalusian horse, but also created a type of horse known as a Courser, a predecessor to the Thoroughbred, which was used as a message horse.\n\nDuring the Renaissance, horses were bred not only for war, but for haute ecole riding, derived from the most athletic movements required of a war horse, and popular among the elite nobility of the time. Breeds such as the Lipizzan and the now extinct Neapolitan horse were developed from Spanish-bred horses for this purpose, and also became the preferred mounts of cavalry officers, who were derived mostly from the ranks of the nobility. It was during this time that firearms were developed, and so the light cavalry horse, a faster and quicker war horse, was bred for \"shoot and run\" tactics rather than the shock action as in the Middle Ages. Fine horses usually had a well muscled, curved neck, slender body, and sweeping mane, as the nobility liked to show off their wealth and breeding in paintings of the era.\n\nAfter Charles II retook the British throne in 1660, horse racing, which had been banned by Cromwell, was revived. The Thoroughbred was developed 40 years later, bred to be the ultimate racehorse, through the lines of three foundation Arabian stallions and one Turkish horse.\n\nIn the 18th century, James Burnett, Lord Monboddo noted the importance of selecting appropriate parentage to achieve desired outcomes of successive generations. Monboddo worked more broadly in the abstract thought of species relationships and evolution of species. The Thoroughbred breeding hub in Lexington, Kentucky was developed in the late 18th century, and became a mainstay in American racehorse breeding.\n\nThe 17th and 18th centuries saw more of a need for fine carriage horses in Europe, bringing in the dawn of the warmblood. The warmblood breeds have been exceptionally good at adapting to changing times, and from their carriage horse beginnings they easily transitioned during the 20th century into a sport horse type. Today's warmblood breeds, although still used for competitive driving, are more often seen competing in show jumping or dressage.\n\nThe Thoroughbred continues to dominate the horse racing world, although its lines have been more recently used to improve warmblood breeds and to develop sport horses. The French saddle horse is an excellent example as is the Irish Sport Horse, the latter being an unusual combination between a Thoroughbred and a draft breed.\n\nThe American Quarter Horse was developed early in the 18th century, mainly for quarter racing (racing ¼ of a mile). Colonists did not have racetracks or any of the trappings of Europe that the earliest Thoroughbreds had at their disposal, so instead the owners of Quarter Horses would run their horses on roads that lead through town as a form of local entertainment. As the USA expanded West, the breed went with settlers as a farm and ranch animal, and \"cow sense\" was particularly valued: their use for herding cattle increased on rough, dry terrain that often involved sitting in the saddle for long hours. \n\nHowever, this did not mean that the original ¼-mile races that colonists held ever went out of fashion, so today there are three types: the stock horse type, the racer, and the more recently evolving sport type. The racing type most resembles the finer-boned ancestors of the first racing Quarter Horses, and the type is still used for ¼-mile races. The stock horse type, used in western events and as a farm and patrol animal is bred for a shorter stride, an ability to stop and turn quickly, and an unflappable attitude that remains calm and focused even in the face of an angry charging steer. The first two are still to this day bred to have a combination of explosive speed that exceeds the Thoroughbred on short distances clocked as high as 55 mph, but they still retain the gentle, calm, and kindly temperament of their ancestors that makes them easily handled.\n\nThe Canadian horse's origin corresponds to shipments of French horses, some of which came from Louis XIV's own stable and most likely were Baroque horses meant to be gentlemen's mounts. These were ill suited to farm work and to the hardscrabble life of the New World, so like the Americans, early Canadians crossed their horses with natives escapees. In time they evolved along similar lines as the Quarter Horse to the South as both the USA and Canada spread westward and needed a calm and tractable horse versatile enough to carry the farmer's son to school but still capable of running fast and running hard as a cavalry horse, a stockhorse, or a horse to pull a conestoga wagon. \n\nOther horses from North America retained a hint of their mustang origins by being either derived from stock that Native Americans bred that came in a rainbow of color, like the Appaloosa and American Paint Horse. with those East of the Mississippi River increasingly bred to impress and mimic the trends of the upper classes of Europe: The Tennessee Walking Horse and Saddlebred were originally plantation horses bred for their gait and comfortable ride in the saddle as a plantation master would survey his vast lands like an English lord.\n\nHorses were needed for heavy draft and carriage work until replaced by the automobile, truck, and tractor. After this time, draft and carriage horse numbers dropped significantly, though light riding horses remained popular for recreational pursuits. Draft horses today are used on a few small farms, but today are seen mainly for pulling and plowing competitions rather than farm work. Heavy harness horses are now used as an outcross with lighter breeds, such as the Thoroughbred, to produce the modern warmblood breeds popular in sport horse disciplines, particularly at the Olympic level.\n\nBreeding a horse is an endeavor where the owner, particularly of the mare, will usually need to invest considerable time and money. For this reason, a horse owner needs to consider several factors, including:\n\nThere are value judgements involved in considering whether an animal is suitable breeding stock, hotly debated by breeders. Additional personal beliefs may come into play when considering a suitable level of care for the mare and ensuing foal, the potential market or use for the foal, and other tangible and intangible benefits to the owner.\n\nIf the breeding endeavor is intended to make a profit, there are additional market factors to consider, which may vary considerably from year to year, from breed to breed, and by region of the world. In many cases, the low end of the market is saturated with horses, and the law of supply and demand thus allows little or no profit to be made from breeding unregistered animals or animals of poor quality, even if registered.\n\nThe minimum cost of breeding for a mare owner includes the stud fee, and the cost of proper nutrition, management and veterinary care of the mare throughout gestation, parturition, and care of both mare and foal up to the time of weaning. Veterinary expenses may be higher if specialized reproductive technologies are used or health complications occur.\n\nMaking a profit in horse breeding is often difficult. While some owners of only a few horses may keep a foal for purely personal enjoyment, many individuals breed horses in hopes of making some money in the process.\n\nA rule of thumb is that a foal intended for sale should be worth three times the cost of the stud fee if it were sold at the moment of birth. From birth forward, the costs of care and training are added to the value of the foal, with a sale price going up accordingly. If the foal wins awards in some form of competition, that may also enhance the price.\n\nOn the other hand, without careful thought, foals bred without a potential market for them may wind up being sold at a loss, and in a worst-case scenario, sold for \"salvage\" value—a euphemism for sale to slaughter as horsemeat.\n\nTherefore, a mare owner must consider their reasons for breeding, asking hard questions of themselves as to whether their motivations are based on either emotion or profit and how realistic those motivations may be.\n\nThe stallion should be chosen to complement the mare, with the goal of producing a foal that has the best qualities of both animals, yet avoids having the weaker qualities of either parent. Generally, the stallion should have proven himself in the discipline or sport the mare owner wishes for the \"career\" of the ensuing foal. Mares should also have a competition record showing that they also have suitable traits, though this does not happen as often.\n\nSome breeders consider the quality of the sire to be more important than the quality of the dam. However, other breeders maintain that the mare is the most important parent. Because stallions can produce far more offspring than mares, a single stallion can have a greater overall impact on a breed. However, the mare may have a greater influence on an individual foal because its physical characteristics influence the developing foal in the womb and the foal also learns habits from its dam when young. Foals may also learn the \"language of intimidation and submission\" from their dam, and this imprinting may affect the foal's status and rank within the herd. Many times, a mature horse will achieve status in a herd similar to that of its dam; the offspring of dominant mares become dominant themselves.\nA purebred horse is usually worth more than a horse of mixed breeding, though this matters more in some disciplines than others. The breed of the horse is sometimes secondary when breeding for a sport horse, but some disciplines may prefer a certain breed or a specific phenotype of horse. Sometimes, purebred bloodlines are an absolute requirement: For example, most racehorses in the world must be recorded with a breed registry in order to race.\n\nBloodlines are often considered, as some bloodlines are known to cross well with others. If the parents have not yet proven themselves by competition or by producing quality offspring, the bloodlines of the horse are often a good indicator of quality and possible strengths and weaknesses. Some bloodlines are known not only for their athletic ability, but could also carry a conformational or genetic defect, poor temperament, or for a medical problem. Some bloodlines are also fashionable or otherwise marketable, which is an important consideration should the mare owner wish to sell the foal.\n\nHorse breeders also consider conformation, size and temperament. All of these traits are heritable, and will determine if the foal will be a success in its chosen discipline. The offspring, or \"get\", of a stallion are often excellent indicators of his ability to pass on his characteristics, and the particular traits he actually passes on. Some stallions are fantastic performers but never produce offspring of comparable quality. Others sire fillies of great abilities but not colts. At times, a horse of mediocre ability sires foals of outstanding quality.\n\nMare owners also look into the question of if the stallion is fertile and has successfully \"settled\" (i.e. impregnated) mares. A stallion may not be able to breed naturally, or old age may decrease his performance. Mare care boarding fees and semen collection fees can be a major cost.\n\nBreeding a horse can be an expensive endeavor, whether breeding a backyard competition horse or the next Olympic medalist. Costs may include:\n\nStud fees are determined by the quality of the stallion, his performance record, the performance record of his get (offspring), as well as the sport and general market that the animal is standing for.\n\nThe highest stud fees are generally for racing Thoroughbreds, which may charge from two to three thousand dollars for a breeding to a new or unproven stallion, to several hundred thousand dollars for a breeding to a proven producer of stakes winners. Stallions in other disciplines often have stud fees that begin in the range of $1,000 to $3,000, with top contenders who produce champions in certain disciplines able to command as much as $20,000 for one breeding. The lowest stud fees to breed to a grade horse or an animal of low-quality pedigree may only be $100–$200, but there are trade-offs: the horse will probably be unproven, and likely to produce lower-quality offspring than a horse with a stud fee that is in the typical range for quality breeding stock.\n\nAs a stallion's career, either performance or breeding, improves, his stud fee tends to increase in proportion. If one or two offspring are especially successful, winning several stakes races or an Olympic medal, the stud fee will generally greatly increase. Younger, unproven stallions will generally have a lower stud fee earlier on in their careers.\n\nTo help decrease the risk of financial loss should the mare die or abort the foal while pregnant, many studs have a live foal guarantee (LFG) – also known as \"no foal, free return\" or \"NFFR\" - allowing the owner to have a free breeding to their stallion the next year. However, this is not offered for every breeding.\n\nThere are two general ways to \"cover\" or breed the mare:\n\nAfter the mare is bred or artificially inseminated, she is checked using ultrasound 14–16 days later to see if she \"took\", and is pregnant. A second check is usually performed at 28 days. If the mare is not pregnant, she may be bred again during her next cycle.\n\nIt is considered safe to breed a mare to a stallion of much larger size. Because of the mare's type of placenta and its attachment and blood supply, the foal will be limited in its growth within the uterus to the size of the mare's uterus, but will grow to its genetic potential after it is born. Test breedings have been done with draft horse stallions bred to small mares with no increase in the number of difficult births.\n\nWhen breeding live cover, the mare is usually boarded at the stud. She may be \"teased\" several times with a stallion that will not breed to her, usually with the stallion being presented to the mare over a barrier. Her reaction to the teaser, whether hostile or passive, is noted. A mare that is in heat will generally tolerate a teaser (although this is not always the case), and may present herself to him, holding her tail to the side. A veterinarian may also determine if the mare is ready to be bred, by ultrasound or palpating daily to determine if ovulation has occurred. Live cover can also be done in liberty on a paddock or on pasture, although due to safety and efficacy concerns, it is not common at professional breeding farms.\n\nWhen it has been determined that the mare is ready, both the mare and intended stud will be cleaned. The mare will then be presented to the stallion, usually with one handler controlling the mare and one or more handlers in charge of the stallion. Multiple handlers are preferred, as the mare and stallion can be easily separated should there be any trouble.\n\nThe Jockey Club, the organization that oversees the Thoroughbred industry in the United States, requires all registered foals to be bred through live cover. Artificial insemination, listed below, is not permitted. Similar rules apply in other countries.\n\nBy contrast, the U.S. standardbred industry allows registered foals to be bred by live cover, or by artificial insemination (AI) with fresh or frozen (not dried) semen. No other artificial fertility treatment is allowed. In addition, foals bred via AI of frozen semen may only be registered if the stallion's sperm was collected during his lifetime, and used no later than the calendar year of his death or castration.\n\nArtificial insemination (AI) has several advantages over live cover, and has a very similar conception rate:\n\nA stallion is usually trained to mount a phantom (or dummy) mare, although a live mare may be used, and he is most commonly collected using an artificial vagina (AV) which is heated to simulate the vagina of the mare. The AV has a filter and collection area at one end to capture the semen, which can then be processed in a lab. The semen may be chilled or frozen and shipped to the mare owner or used to breed mares \"on-farm\". When the mare is in heat, the person inseminating introduces the semen directly into her uterus using a syringe and pipette.\n\nOften an owner does not want to take a valuable competition mare out of training to carry a foal. This presents a problem, as the mare will usually be quite old by the time she is retired from her competitive career, at which time it is more difficult to impregnate her. Other times, a mare may have physical problems that prevent or discourage breeding. However, there are now several options for breeding these mares. These options also allow a mare to produce multiple foals each breeding season, instead of the usual one. Therefore, mares may have an even greater value for breeding.\n\n\n"}
{"id": "14084", "url": "https://en.wikipedia.org/wiki?curid=14084", "title": "Heterosexuality", "text": "Heterosexuality\n\nHeterosexuality is romantic attraction, sexual attraction or sexual behavior between persons of the opposite sex or gender. As a sexual orientation, heterosexuality is \"an enduring pattern of emotional, romantic, and/or sexual attractions\" to persons of the opposite sex; it \"also refers to a person's sense of identity based on those attractions, related behaviors, and membership in a community of others who share those attractions.\"\n\nAlong with bisexuality and homosexuality, heterosexuality is one of the three main categories of sexual orientation within the heterosexual–homosexual continuum. Someone who is heterosexual is commonly referred to as \"straight.\"\n\nThe term \"heterosexual\" or \"heterosexuality\" is usually applied to humans, but heterosexual behavior is observed in all mammals and in other animals.\n\n\"Hetero-\" comes from the Greek word \"ἕτερος\" [héteros], meaning \"other party\" or \"another\", used in science as a prefix meaning \"different\"; and the Latin word for sex (that is, characteristic sex or sexual differentiation). The term \"\"heterosexual\"\" was first published in 1892 in C.G. Chaddock's translation of Krafft-Ebing's \"Psychopathia Sexualis\". The noun came into use from the early 1920s, but did not enter common use until the 1960s. The colloquial shortening \"hetero\" is attested from 1933. The abstract noun \"heterosexuality\" is first recorded in 1900. The word \"\"heterosexual\"\" was first listed in Merriam-Webster's \"New International Dictionary\" as a medical term for \"morbid sexual passion for one of the opposite sex\"; however, in 1934 in their \"Second Edition Unabridged\" it is defined as a \"manifestation of sexual passion for one of the opposite sex; normal sexuality\".\nThe adjective \"heterosexual\" is used for intimate relationships or sexual relations between male and female.\n\nThe current use of the term \"heterosexual\" has its roots in the broader 19th century tradition of personality taxonomy. It continues to influence the development of the modern concept of sexual orientation, and can be used to describe individuals' sexual orientation, sexual history, or self-identification. Some reject the term \"heterosexual\", as they feel that the word only refers to one's sexual behavior and does not refer to non-sexual romantic feelings. The term \"heterosexual\" is suggested to have come into use as a neologism after, and opposite to, the word \"homosexual\" by Karl Maria Kertbeny in 1868. In LGBT slang, the term \"breeder\" has been used as a denigrating phrase to deride heterosexuals. Hyponyms of heterosexual include \"heteroflexible\".\n\nThe word can be informally shortened to \"hetero\". The term \"straight\" originated as a mid-20th century gay slang term for heterosexuals, ultimately coming from the phrase \"to go straight\" (as in \"straight and narrow\"), or stop engaging in homosexual sex. One of the first uses of the word in this way was in 1941 by author G. W. Henry. Henry's book concerned conversations with homosexual males and used this term in connection with people who are identified as ex-gays. It is now simply a colloquial term for \"heterosexual\", having changed in primary meaning over time. Some object to usage of the term \"straight\" because it implies that non-heteros are crooked.\n\nHeterosexual symbolism dates back to the earliest artifacts of humanity, with gender symbols, ritual fertility carvings, and primitive art. This was later expressed in the symbolism of fertility rites and polytheistic worship, which often included images of human reproductive organs, such as lingam in Hinduism. Modern symbols of heterosexuality in societies derived from European traditions still reference symbols used in these ancient beliefs. One such image is a combination of the symbol for Mars, the Roman god of war, as the definitive male symbol of masculinity, and Venus, the Roman goddess of love and beauty, as the definitive female symbol of femininity. The unicode character for this combined symbol is ⚤ (U+26A4).\n\nThe Judeo-Christian tradition has several scriptures related to heterosexuality. The Genesis states that God created man because \"it is not good that the man should be alone; I will make him an help meet for him.\" () Genesis then contains a commandment stating \"Therefore shall a man leave his father and his mother, and shall cleave unto his wife: and they shall be one flesh\" () In 1 Corinthians, Christians are advised:\n\nFor the most part, religious traditions in the world reserve marriage to heterosexual unions, but there are exceptions including certain Buddhist and Hindu traditions, Unitarian Universalist, Metropolitan Community Church and some Anglican dioceses and some Quaker, United Church of Canada and Reform and Conservative Jewish congregations.\n\nAlmost all religions believe that lawful sex between a man and a woman is allowed, but there are a few that believe that it is a sin, such as The Shakers, The Harmony Society, and The Ephrata Cloister. These religions tend to view all sexual relations as sinful, and promote celibacy. Other religions view heterosexual relationships as being inferior to celibacy. Some religions require celibacy for certain roles, such as Catholic priests; however, the Catholic Church also views heterosexual marriage as sacred and necessary.\n\nThe demographics of sexual orientation are difficult to establish due to a lack of reliable data. However, the history of human sexuality shows that attitudes and behavior have varied across societies. According to major studies, 89% to 98% of people have had only heterosexual contact within their lifetime; but this percentage falls to 79–84% when either or both same-sex attraction and behavior are reported. In a 2006 study, 80% of respondents anonymously reported heterosexual feelings, although 97–98% identified themselves as heterosexual. A 1992 study reported that 93.9% of males in Britain have always had heterosexual experience, while in France the number was reported at 95.9%.\n\nIn the United States, according to a Williams Institute report in April 2011, 96% or approximately 250 million of the adult population are heterosexual.\n\nAccording to a 2008 poll, 85% of Britons have only opposite-sex sexual contact while only 94% of Britons identify themselves as heterosexual. Similarly, a survey by the UK Office for National Statistics (ONS) in 2010 found that 95% of Britons identified as heterosexual, 1.5% of Britons identified themselves as homosexual or bisexual, and the last 3.5% gave more vague answers such as \"don't know\", \"other\", or did not respond to the question.\n\nAn October 2012 Gallup poll provided unprecedented demographic information about those who identify as heterosexual, arriving at the conclusion that 96.6%, with a margin of error of ±1%, of all U.S. adults identify as heterosexual.\n\nIn a 2015 Yougov survey of 1,632 adults of the United Kingdom, 88.7% identified as heterosexual, 5.5% as homosexual and 2.1% as bisexual. Asked to place themselves on the Kinsey scale, 72% of all adults, and 46% of adults aged 18–24 years, picked a score of zero, meaning that they identify as totally heterosexual. 4% of the total sample, and 6% of young adults, picked a score of six, meaning a totally homosexual identity.\n\nIn another Yougov survey of 1,000 adults of the United States, 89% of the sample identified as heterosexual, 4% as homosexual (among 2% as homosexual male and 2% as homosexual female) and 4% as bisexual (of either sex).\n\nThe relationship between biology and sexual orientation is a subject of research. No simple and singular determinant for sexual orientation has been conclusively demonstrated; various studies point to different, even conflicting positions, but scientists hypothesize that a combination of genetic, hormonal, and social factors determine sexual orientation. Biological theories for explaining the causes of sexual orientation are more popular, and biological factors may involve a complex interplay of genetic factors and the early uterine environment, or biological and social factors. These factors, which may be related to the development of heterosexual or other orientation, include genes, prenatal hormones, and brain structure and their interaction with the environment.\n\nThe neurobiology of the masculinization of the brain is fairly well understood. Estradiol and testosterone, which is catalyzed by the enzyme 5α-reductase into dihydrotestosterone, act upon androgen receptors in the brain to masculinize it. If there are few androgen receptors (people with androgen insensitivity syndrome) or too much androgen (females with congenital adrenal hyperplasia), there can be physical and psychological effects. It has been suggested that both male and female heterosexuality are results of variation in this process. In these studies heterosexuality in females is linked to a lower amount of masculinization than is found in lesbian females, though when dealing with male heterosexuality there are results supporting both higher and lower degrees of masculinization than homosexual males.\n\nMost sexual reproduction in the animal world is facilitated through opposite-sex sexual activity, although there are also animals that reproduce asexually, including protozoa and lower invertebrates.\n\nReproductive sex does not necessarily require a heterosexual orientation, since orientation refers to a long-term enduring pattern of sexual and emotional attraction leading often to long-term social bonding, while reproductive sex requires only the basic act of intercourse only to fertile the ovum by sperm, often done one time only.\n\nAt the beginning of the 20th century, early theoretical discussions in the field of psychoanalysis posited original bisexuality in human psychological development. Quantitative studies by Alfred Kinsey in the 1940s and Dr. Fritz Klein's sexual orientation grid in the 1980s find distributions similar to those postulated by their predecessors.\n\nAccording to \"Sexual Behavior in the Human Male\" by Alfred Kinsey and several other modern studies, the majority of humans have had both heterosexual and homosexual experiences or sensations and are bisexual. Kinsey himself, along with current sex therapists, focused on the historicity and fluidity of sexual orientation. Kinsey's studies consistently found sexual orientation to be something that evolves in many directions over a person's lifetime; rarely, but not necessarily, including forming attractions to a new sex. Rarely do individuals radically reorient their sexualities rapidly—and still less do they do so volitionally—but often sexualities expand, shift, and absorb new elements over decades. For example, socially normative \"age-appropriate\" sexuality requires a shifting object of attraction (especially in the passage through adolescence). Contemporary queer theory, incorporating many ideas from social constructionism, tends to look at sexuality as something that has meaning only within a given historical framework. Sexuality, then, is seen as a participation in a larger social discourse and, though in some sense fluid, not as something strictly determinable by the individual.\n\nOther studies have disputed Kinsey's methodology. \"His figures were undermined when it was revealed that he had disproportionately interviewed homosexuals and prisoners (many sex offenders).\"\n\nSexologists have attributed discrepancies in some findings to negative societal attitudes towards a particular sexual orientation. For example, people may state different sexual orientations depending on whether their immediate social environment is public or private. Reluctance to disclose one's actual sexual orientation is often referred to as \"being in the closet.\" Individuals capable of enjoyable sexual relations with both sexes or one sex may feel inclined to restrict themselves to heterosexual or homosexual relations in societies that stigmatize same-sex or opposite-sex relations.\n\nThe considerable \"nature and nurture\" debate exists over whether predominantly biological or psychological factors produce sexual orientation in humans, or whether both significantly factor into sexual orientation. Candidate factors include genes, the exposure of fetuses to certain hormones (or lack thereof) and environmental factors.\n\nThe studies performed in order to find the origin of sexual orientation have been criticized for being too limited in scope, mostly for focusing only on heterosexuality and homosexuality as two diametrically opposite poles with no orientation in between. It is also asserted that scientific studies focus too much on the search for a biological explanation for sexual orientation, and not enough on the combined effects of both biology and psychology.\n\nIn a brief by the Council for Responsible Genetics, it was stated that sexual orientation is not fixed either way, and on the discourse over sexual orientation: \"Noticeably missing from this debate is the notion, championed by Kinsey, that human sexual expression is as variable among people as many other complex traits. Yet just like intelligence, sexuality is a complex human feature that modern science is attempting to explain with genetics. Research on brain size, hormone levels, finger length, and other biological traits have yet to yield evidence for this, however. It is important to note that traits such as these result from a combination of gene expression and developmental and other environmental factors. Well-known biologist and social theorist, Anne Fausto-Sterling advocates in her book Sexing the Body, for what scientists term a “systems approach” to be applied to our understanding of sexual preference. Rather than determining that this results from purely biological processes, a trait evolves from developmental processes that include both biological and social elements.\" According to the American Psychological Association (APA), there are numerous theories about the origins of a person's sexual orientation, but some believe that \"sexual orientation is most likely the result of a complex interaction of environmental, cognitive and biological factors,\" and that genetic factors play a \"significant role\" in determining a person's sexuality.\n\nOften, sexual orientation and sexual orientation identity are not distinguished, which can impact accurately assessing sexual identity and whether or not sexual orientation is able to change; sexual orientation identity can change throughout an individual's life, and may or may not align with biological sex, sexual behavior or actual sexual orientation.<ref name=\"Concordance/discordance in SO\"></ref> While the Centre for Addiction and Mental Health and American Psychiatric Association state that sexual orientation is innate, continuous or fixed throughout their lives for some people, but is fluid or changes over time for others, the American Psychological Association distinguishes between sexual orientation (an innate attraction) and sexual orientation identity (which may change at any point in a person's life).\n\nA 2012 study found that 2% of a sample of 2,560 adult participants reported a change of sexual orientation identity after a 10-year period. For men, a change occurred in 0.78% of those who had identified as heterosexual, 9.52% of homosexuals, and 47% of bisexuals. For women, a change occurred in 1.36% of heterosexuals, 63.6% of lesbians, and 64.7% of bisexuals. The researchers suggested that heterosexuality may be a more stable identity because of its normative status.\n\nA 2-year study by Lisa M. Diamond on a sample of 80 non-heterosexual female adolescents (age 16-23) reported that half of the participants had changed sexual-minority identities more than once, one third of them during the 2-year follow-up. Diamond concluded that \"although sexual attractions appear fairly stable, sexual identities and behaviors are more fluid.\"\n\nIn a 2004 study, the female subjects (both gay and straight women) became strongly sexually aroused when they viewed heterosexual as well as lesbian erotic films. Among the male subjects, however, the straight men were more turned on by erotic films with women, the gay ones more by those with men. The study's senior researcher said that women's sexual desire is less rigidly directed toward a particular sex, as compared with men's, and it is more changeable over time. However, the study did note that on average all men, regardless of sexual orientation, showed significantly more genital arousal to their non-preferred sex compared to neutral stimuli. Gay men showed some level of genital arousal to female stimuli and straight men showed some level of genital arousal to male stimuli.\n\nHeteroflexibility is a form of a sexual orientation or situational sexual behavior characterized by minimal homosexual activity in an otherwise primarily heterosexual orientation that is considered to distinguish it from bisexuality. It has been characterized as \"mostly straight\".\n\nSexual orientation change efforts are methods that aim to change sexual orientation, used to try to convert homosexual and bisexual people to heterosexuality. Scientists and mental health professionals generally do not believe that sexual orientation is a choice. There are no studies of adequate scientific rigor that conclude that sexual orientation change efforts work to change a person's sexual orientation. Those efforts have been controversial due to tensions between the values held by some faith-based organizations, on the one hand, and those held by LGBT rights organizations and professional and scientific organizations and other faith-based organizations, on the other. The longstanding consensus of the behavioral and social sciences and the health and mental health professions is that homosexuality \"per se\" is a normal and positive variation of human sexual orientation, and therefore not a mental disorder.\n\nNo major mental health professional organization has sanctioned efforts to change sexual orientation and virtually all of them have adopted policy statements cautioning the profession and the public about treatments that purport to change sexual orientation. These include the American Psychiatric Association, American Psychological Association, American Counseling Association, National Association of Social Workers in the US, the Royal College of Psychiatrists, and the Australian Psychological Society. The American Psychological Association states that \"sexual orientation is not a choice that can be changed at will\", and \"sexual orientation identity—not sexual orientation—appears to change via psychotherapy, support groups, and life events.\" The American Psychiatric Association says \"individuals maybe become aware at different points in their lives that they are heterosexual, gay, lesbian, or bisexual\". While opposing conversion therapy, they encourage gay affirmative psychotherapy and \"encourages mental health professionals to avoid misrepresenting the efficacy of sexual orientation change efforts by promoting or promising change in sexual orientation when providing assistance to individuals distressed by their own or others' sexual orientation and concludes that the benefits reported by participants in sexual orientation change efforts can be gained through approaches that do not attempt to change sexual orientation\". The American Psychological Association and the Royal College of Psychiatrists expressed concerns that the positions espoused by NARTH are not supported by the science and create an environment in which prejudice and discrimination can flourish.\n\nSince the 1960s and 1970s, a large body of research has provided evidence and analysis of the extent to which heterosexuality and homosexuality are socially organized and historically changing. This work challenges the assumption that heterosexuality, homosexuality, and sexualities of all varieties, can be understood as primarily biological and psychological phenomena.\n\nA heterosexual couple, a man and woman in an intimate relationship, form the core of a nuclear family.\nMany societies throughout history have insisted that a marriage take place before the couple settle down, but enforcement of this rule or compliance with it has varied considerably. In some jurisdictions, when an unmarried man and woman live together long enough, they are deemed to have established a common-law marriage.\n\nThere was no real need to coin a term such as \"heterosexual\" until there was something else to contrast and compare it with. In “The Invention of Heterosexuality,” Jonathon Ned Katz dates the definition of heterosexuality, as it is used today, to the late 19th century. In the Victorian era, sex was seen as a means to achieve reproduction, relations between the sexes were not believed to be overtly sexual. The body was thought of as a tool for procreation, “human energy, though of as a closed and severely limited system, was to be used in producing children and in work, not wasted in libidinous pleasures.” Modern ideas of sexuality and eroticism began to develop in America and Germany in the later 19th century. The changing economy and the “transformation of the family from producer to consumer” resulted in shifting values. The Victorian work ethic had changed, pleasure became more highly valued and this allowed ideas of human sexuality to change. Consumer culture had created a market for the erotic, pleasure became commoditized. At the same time medical doctors began to acquire more power and influence. They developed the medical model of Normal Love in which healthy men and women enjoyed sex as part of a “new ideal of male-female relationships that included.. an essential, necessary, normal eroticism.” This ‘Normal Sexual’ ideal also had a counterpart, the Victorian Sex Pervert, anyone who failed to meet the norm. The basic oppositeness of the sexes was the basis for normal, healthy sexual attraction. “The attention paid the sexual abnormal created a need to name the sexual normal, the better to distinguish the average him and her from the deviant it.” The creation term ‘heterosexual’ consolidated the social existence of the pre-existing heterosexual experience and created a sense of ensured and validated normalcy within it.\n\nHeteronormativity denotes or relates to a world view that promotes heterosexuality as the normal or preferred sexual orientation for people to have. It can assign strict gender roles to males and females. The term was popularized by Michael Warner in 1991. Many gender and sexuality scholars argue that compulsory heterosexuality, a continual and repeating reassertion of heterosexual norms, is facet of heterosexism. Compulsory heterosexuality is the idea that female heterosexuality is both assumed and enforced by a patriarchal society. Heterosexuality is then viewed as the natural inclination or obligation by both sexes. Consequently, anyone who differs from the normalcy of heterosexuality is deemed deviant or abhorrent.\n\nHeterosexism is a form of bias or discrimination in favor of opposite-sex sexuality and relationships. It may include an assumption that everyone is heterosexual and may involve a varied level of discrimination against gays, lesbians, bisexuals, heteroflexibles, or transgender individuals.\n\nStraight pride is a slogan that arose in the late 1980s and early 1990s and has been used primarily by social conservative groups as a political stance and strategy. The term is described as a response to gay pride adopted by various LGBT groups in the early 1970s or to the accommodations provided to gay pride initiatives.\n\n\n\n"}
{"id": "14086", "url": "https://en.wikipedia.org/wiki?curid=14086", "title": "Hopewell Centre (Hong Kong)", "text": "Hopewell Centre (Hong Kong)\n\nHopewell Centre () is a , 64-storey skyscraper at 183 Queen's Road East, in Wan Chai, Hong Kong Island in Hong Kong. The tower is the first circular skyscraper in Hong Kong. It is named after Hong Kong-listed property firm Hopewell Holdings Limited, which constructed the building. Hopewell Holdings Limited's headquarters are in the building and its Chief executive officer, Gordon Wu, has his office on the top floor.\n\nConstruction started in 1977 and was completed in 1980. Upon completion, Hopewell Centre surpassed Jardine House as Hong Kong's tallest building. It was also the second tallest building in Asia at the time. It kept its title in Hong Kong until 1989, when the Bank of China Tower was completed. The building is now the 20th tallest building in Hong Kong.\n\nThe building has a circular floor plan. Although the front entrance is on the 'ground floor', commuters are taken through a set of escalators to the 3rd floor lift lobby. Hopewell Centre stands on the slope of a hill so steep that the building has its back entrance on the 17th floor towards Kennedy Road. There is a circular private swimming pool on the roof of the building built for feng shui reasons.\n\nA revolving restaurant located on the 62nd floor, called \"Revolving 66\", overlooks other tall buildings below and the harbour. It was originally called Revolving 62, but soon changed its name as locals kept calling it Revolving 66. It completes a 360-degree rotation each hour. Passengers take either office lifts (faster) or the scenic lifts (with a view) to the 56/F, where they transfer to smaller lifts up to the 62/F. The restaurant is now named The Grand Buffet.\n\nThe building comprises several groups of lifts. Lobbies are on the 3rd and 17th floor, and are connected to Queen's Road East and Kennedy Road respectively. A mini-skylobby is on the 56th floor and serves as a transfer floor for diners heading to the 60/F and 62/F restaurants. The building's white 'bumps' between the windows have built in window-washer guide rails.\n\nThis skyscraper was the filming location for R&B group Dru Hill's music video for \"How Deep Is Your Love,\" directed by Brett Ratner, who also directed the movie Rush Hour, whose soundtrack features the song. The circular private swimming pool is well visible in this music video. This swimming pool has also featured in an Australian television advertisement by one of that country's major gaming companies, Tattersall's Limited, promoting a weekly lottery competition.\n\n\n\n"}
{"id": "14089", "url": "https://en.wikipedia.org/wiki?curid=14089", "title": "Harwich, Massachusetts", "text": "Harwich, Massachusetts\n\nHarwich ( ) is a New England town on Cape Cod, in Barnstable County in the state of Massachusetts in the United States. At the 2010 census it had a population of 12,243. The town is a popular vacation spot, located near the Cape Cod National Seashore. Harwich's beaches are on the Nantucket Sound side of Cape Cod. Harwich has three active harbors. Saquatucket, Wychmere and Allen Harbors are all in Harwich Port. The town of Harwich includes the villages of Pleasant Lake, West Harwich, East Harwich, Harwich Port, Harwich Center, North Harwich and South Harwich. Harwich is also home to the exclusive Wequassett Resort and Golf Club.\n\nHarwich was first settled by Europeans in 1670 as part of Yarmouth. The town was officially incorporated in 1694, and originally included the lands of the current town of Brewster. Early industry involved fishing and farming. The town is considered by some to be the birthplace of the cranberry industry, with the first commercial operation opened in 1846. There are still many bogs in the town, although the economy is now more centered on tourism and as a residential community. The town is also the site of the start/finish line of the \"Sail Around the Cape\", which rounds the Cape counter-clockwise, returning via the Cape Cod Canal.\n\nSince 1976, the town has hosted the annual Harwich Cranberry Festival, noted for its fireworks display, in September.\n\nIn the summer, the town is host to the Harwich Mariners of the Cape Cod Baseball League. The Mariners were the 2008 league champions. The team plays at Whitehouse Field.\n\nThe Harwich Antique Center West Harwich is a large group shop that features over 40 dealers. They feature Victorian furniture, primitive items, vintage and collectables, ephemera, coins, jewelry, lamps, military items, postcards and much more. \n\nThe Patriot Square Shopping Center in neighboring South Dennis is convenient for residents of North Harwich and West Harwich. The plaza contains a Stop & Shop supermarket and other stores around it. Supermarkets in Harwich include a Shaw's Star Market on the Harwich Port/West Harwich border and another Stop & Shop in East Harwich.\n\nAccording to the United States Census Bureau, the town has a total area of , of which is land and , or 36.97%, is water. The seven villages of Harwich are West Harwich, North Harwich, East Harwich, South Harwich, Harwich Center, Harwich Port and Pleasant Lake. These are also referred to as the Harwiches.\n\nHarwich is on the southern side of Cape Cod, just west of the southeastern corner. It is bordered by Dennis to the west, Brewster to the north, Orleans to the northeast, Chatham to the east, and Nantucket Sound to the south. Harwich is approximately east of Barnstable, east of the Cape Cod Canal, south of Provincetown, and southeast of Boston.\n\nThe town shares the largest lake on the Cape, called Long Pond, with the town of Brewster. Long Pond serves as a private airport for planes with the ability to land on water. The village of Pleasant Lake is at the southwest corner of the lake. Numerous other smaller bodies of water dot the town. Sand Pond, a public beach and swimming area, is located off Great Western Road in North Harwich.\n\nThe shore is home to several harbors and rivers, including the Herring River, Allens Harbor, Wychmere Harbor, Saquatucket Harbor, and the Andrews River. The town is also the home to the Hawksnest State Park, as well as a marina and several beaches, including two on Long Pond. There are also many beaches in West Harwich and South Harwich.\n\nAs of the census of 2000, there were 12,386 people, 5,471 households, and 3,545 families residing in the town. The population density was 588.6 people per square mile (227.3/km²). There were 9,450 housing units at an average density of 449.1 per square mile (173.4/km²). The racial makeup of the town was 95.41% White, 0.71% Black or African American, 0.19% Native American, 0.22% Asian, 0.05% Pacific Islander, 2.03% from other races, and 1.40% from two or more races. 0.96% of the population were Hispanic or Latino of any race.\n\nThere were 5,471 households out of which 21.3% had children under the age of 18 living with them, 53.4% were married couples living together, 9.0% had a female householder with no husband present, and 35.2% were non-families. 29.8% of all households were made up of individuals and 16.9% had someone living alone who was 65 years of age or older. The average household size was 2.20 and the average family size was 2.72.\n\nIn the town, the population was spread out with 18.3% under the age of 18, 4.2% from 18 to 24, 22.1% from 25 to 44, 25.8% from 45 to 64, and 29.6% who were 65 years of age or older. The median age was 49 years. For every 100 females, there were 84.5 males. For every 100 females age 18 and over, there were 79.7 males.\n\nThe median income for a household in the town was $41,552, and the median income for a family was $51,070. Males had a median income of $38,948 versus $27,439 for females. The per capita income for the town was $23,063. About 2.9% of families and 15.5% of the population were below the poverty line, including 8.4% of those under age 18 and 8.1% of those age 65 or over.\n\nThe town of Harwich contains several smaller census-designated places (CDPs) for which the U.S. Census reports more focused geographic and demographic information. The CDPs in Harwich are Harwich Center, Harwich Port (including South Harwich), East Harwich and Northwest Harwich (including West Harwich, North Harwich, and Pleasant Lake).\n\nHarwich is represented in the Massachusetts House of Representatives as a part of the Fourth Barnstable district, which includes (with the exception of Brewster) all the towns east and north of Harwich on the Cape. The town is represented in the Massachusetts Senate as a part of the Cape and Islands District, which includes all of Cape Cod, Martha's Vineyard and Nantucket except the towns of Bourne, Falmouth, Sandwich and a portion of Barnstable. The town is patrolled by the Second (Yarmouth) Barracks of Troop D of the Massachusetts State Police.\n\nOn the national level, Harwich is a part of Massachusetts's 9th congressional district, and is currently represented by William R. Keating. The state's senior member of the United States Senate is Elizabeth Warren, elected in 2012. The junior senator is Ed Markey, elected in 2013.\n\nHarwich is governed by the open town meeting form of government, led by a town administrator and a board of selectmen.\n\nThere are three libraries in the town. The municipal library, the Brooks Free Library in Harwich Center, is the largest and is a member of the Cape Libraries Automated Materials Sharing (CLAMS) library network. There are two smaller non-municipal libraries – the Chase Library on Route 28 in West Harwich at the Dennis town line, and the Harwich Port Library on Lower Bank Street in Harwich Port.\n\nHarwich is the site of the Long Pond Medical Center, which serves the southeastern Cape region.\n\nHarwich has police and fire departments, with one fire and police station headquarters, and Station 2 in East Harwich.\n\nThere are post offices in Harwich Port, South Harwich, West Harwich, and East Harwich.\n\nHarwich's schools are part of the Monomoy Regional School District. Harwich Elementary School serves students from pre-school through fourth grade, Monomoy Regional Middle School which serves both Harwich and its joining town, Chatham. This middle school serves grades 5–7, and Monomoy Regional High School serves grades 8–12 for both Harwich and Chatham. Monomoy's teams are known as the Sharks. Harwich is known for its excellent boys basketball, girls basketball, girls field hockey, softball and baseball teams.\n\nThe Lighthouse Charter School recently moved into where the Harwich Cinema building was located.\n\nHarwich is the site of Cape Cod Regional Technical High School, a grades 9–12 high school which serves most of Cape Cod. The town is also home to Holy Trinity PreSchool, a Catholic pre-school which serves pre-kindergarten in West Harwich.\n\nTwo of Massachusetts major routes, U.S. Route 6 and Massachusetts Route 28, cross the town. The town has the southern termini of Routes 39 and 124, and a portion of Route 137 passes through the town. Route 39 leads east through East Harwich to Orleans. Route 28 passes through West Harwich and Harwich Port, connecting the towns of Dennis and Chatham. Route 124 leads from Harwich Center to Brewster, and Route 137 cuts through East Harwich leading from Chatham to Brewster.\n\nA portion of the Cape Cod Rail Trail, as well as several other bicycle routes, are in town. There is no rail service in town, but the Cape Cod Rail Trail rotary is located in North Harwich near Main Street.\n\nOther than the occasional sea plane landing on the pond, the nearest airport is in neighboring Chatham; the nearest regional service is at Barnstable Municipal Airport; and the nearest national and international air service is at Logan International Airport in Boston.\n\nIn recent years parts of Cape Cod have introduced bus service, especially during the summer to help cut down on traffic.\n\n\n"}
{"id": "14090", "url": "https://en.wikipedia.org/wiki?curid=14090", "title": "Hull classification symbol", "text": "Hull classification symbol\n\nThe United States Navy, United States Coast Guard, and United States National Oceanic and Atmospheric Administration (NOAA) use a hull classification symbol (sometimes called hull code or hull number) to identify their ships by type and by individual ship within a type. The system is analogous to the pennant number system that the Royal Navy and other European and Commonwealth navies use.\n\nThe U.S. Navy began to assign unique Naval Registry Identification Numbers to its ships in the 1890s. The system was a simple one in which each ship received a number which was appended to its ship type, fully spelled out, and added parenthetically after the ship's name when deemed necessary to avoid confusion between ships. Under this system, for example, the battleship \"Indiana\" was USS \"Indiana\" (Battleship No. 1), the cruiser \"Olympia\" was USS \"Olympia\" (Cruiser No. 6), and so on. Beginning in 1907, some ships also were referred to alternatively by single-letter or three-letter codes—for example, USS \"Indiana\" (Battleship No. 1) could be referred to as USS \"Indiana\" (B-1) and USS \"Olympia\" (Cruiser No. 6) could also be referred to as USS \"Olympia\" (C-6), while USS \"Pennsylvania\" (Armored Cruiser No. 4) could be referred to as USS \"Pennsylvania\" (ACR-4). However, rather than replacing it, these codes coexisted and were used interchangeably with the older system until the modern system was instituted on 17 July 1920.\n\nDuring World War I, the U.S. Navy acquired large numbers of privately owned and commercial ships and craft for use as patrol vessels, mine warfare vessels, and various types of naval auxiliary ships, some of them with identical names. To keep track of them all, the Navy assigned unique identifying numbers to them. Those deemed appropriate for patrol work received section patrol numbers (SP), while those intended for other purposes received \"identification numbers\", generally abbreviated \"Id. No.\" or \"ID;\" some ships and craft changed from an SP to an ID number or vice versa during their careers, without their unique numbers themselves changing, and some ships and craft assigned numbers in anticipation of naval service never were acquired by the Navy. The SP/ID numbering sequence was unified and continuous, with no SP number repeated in the ID series or vice versa so that there could not be, for example, both an \"SP-435\" and an \"Id. No 435\". The SP and ID numbers were used parenthetically after each boat's or ship's name to identify it; although this system pre-dated the modern hull classification system and its numbers were not referred to at the time as \"hull codes\" or \"hull numbers,\" it was used in a similar manner to today's system and can be considered its precursor.\n\nThe United States Revenue Cutter Service, which merged with the United States Lifesaving Service in January 1915 to form the modern United States Coast Guard, began following the Navy's lead in the 1890s, with its cutters having parenthetical numbers called Naval Registry Identification Numbers following their names, such as (Cutter No. 1), etc. This persisted until the Navy's modern hull classification system's introduction in 1920, which included Coast Guard ships and craft.\n\nLike the U.S. Navy, the United States Coast and Geodetic Survey – a uniformed seagoing service of the United States Government and a predecessor of the National Oceanic and Atmospheric Administration (NOAA) – adopted a hull number system for its fleet in the 20th century. Its largest vessels, \"Category I\" oceanographic survey ships, were classified as \"ocean survey ships\" and given the designation \"OSS\". Intermediate-sized \"Category II\" oceanographic survey ships received the designation \"MSS\" for \"medium survey ship,\" and smaller \"Category III\" oceanographic survey ships were given the classification \"CSS\" for \"coastal survey ship.\" A fourth designation, \"ASV\" for \"auxiliary survey vessel,\" included even smaller vessels. In each case, a particular ship received a unique designation based on its classification and a unique hull number separated by a space rather than a hyphen; for example, the third Coast and Geodetic Survey ship named \"Pioneer\" was an ocean survey ship officially known as USC&GS \"Pioneer\" (OSS 31). The Coast and Geodetic Surveys system persisted after the creation of NOAA in 1970, when NOAA took control of the Surveys fleet, but NOAA later changed to its modern hull classification system.\n\nThe U.S. Navy instituted its modern hull classification system on 17 July 1920, doing away with section patrol numbers, \"identification numbers\", and the other numbering systems described above. In the new system, all hull classification symbols are at least two letters; for basic types the symbol is the first letter of the type name, doubled, except for aircraft carriers.\n\nThe combination of symbol and hull number identifies a modern Navy ship uniquely. A heavily modified or re-purposed ship may receive a new symbol, and either retain the hull number or receive a new one. For example, the heavy gun cruiser was converted to a gun/missile cruiser, changing the hull number to CAG-1. Also, the system of symbols has changed a number of times both since it was introduced in 1907 and since the modern system was instituted in 1920, so ships' symbols sometimes change without anything being done to the physical ship.\n\nHull numbers are assigned by classification. Duplication between, but not within, classifications is permitted. Hence, CV-1 was the aircraft carrier and BB-1 was the battleship .\n\nShip types and classifications have come and gone over the years, and many of the symbols listed below are not presently in use. The Naval Vessel Register maintains an online database of U.S. Navy ships showing which symbols are presently in use.\n\nAfter World War II until 1975, the U.S. Navy defined a \"frigate\" as a type of surface warship larger than a destroyer and smaller than a cruiser. In other navies, such a ship generally was referred to as a \"flotilla leader\", or \"destroyer leader\". Hence the U.S. Navy's use of \"DL\" for \"frigate\" prior to 1975, while \"frigates\" in other navies were smaller than destroyers and more like what the U.S. Navy termed a \"destroyer escort\", \"ocean escort\", or \"DE\". The United States Navy 1975 ship reclassification of cruisers, frigates, and ocean escorts brought U.S. Navy classifications into line with other nations' classifications, at least cosmetically in terms of terminology, and eliminated the perceived \"cruiser gap\" with the Soviet Navy by redesignating the former \"frigates\" as \"cruisers\".\n\nIf a U.S. Navy ship's hull classification symbol begins with \"T-\", it is part of the Military Sealift Command, has a primarily civilian crew, and is a United States Naval Ship (USNS) in non-commissioned service – as opposed to a commissioned United States Ship (USS) with an all-military crew.\n\nIf a ship's hull classification symbol begins with \"W\", it is a ship of the United States Coast Guard. Until 1965, the Coast Guard used U.S. Navy hull classification codes, prepending a \"W\" to their beginning. In 1965, it retired some of the less mission-appropriate Navy-based classifications and developed new ones of its own, most notably WHEC for \"high endurance cutter\" and WMEC for \"medium endurance cutter\".\n\nThe National Oceanic and Atmospheric Administration (NOAA), a component of the United States Department of Commerce, includes the National Oceanic and Atmospheric Administration Commissioned Officer Corps (or \"NOAA Corps\"), one of the seven uniformed services of the United States, and operates a fleet of seagoing research and survey ships. The NOAA fleet also uses a hull classification symbol system, which it also calls \"hull numbers,\" for its ships.\n\nAfter NOAA took over the former Coast and Geodetic Survey fleet in 1970 along with research vessels of other government agencies, it adopted a new system of ship classification. In its system, the NOAA fleet is divided into two broad categories, research ships and survey ships. The research ships, which include oceanographic and fisheries research vessels, are given hull numbers beginning with \"R\", while the survey ships, generally hydrographic survey vessels, receive hull numbers beginning with \"S\". The letter is followed by a three-digit number; the first digit indicates the NOAA \"class\" (i.e., size) of the vessel, which NOAA assigns based on the ship's gross tonnage and horsepower, while the next two digits combine with the first digit to create a unique three-digit identifying number for the ship.\n\nGenerally, each NOAA hull number is written with a space between the letter and the three-digit number, as in, for example, or .\n\nUnlike the Navy, once an older NOAA ship leaves service, a newer one can be given the same hull number; for example, \"S 222\" was assigned to , then assigned to NOAAS \"Thomas Jefferson\" (S 222), which entered NOAA service after \"Mount Mitchell\" was stricken.\n\nThe U.S. Navy's system of alpha-numeric ship designators, and its associated hull numbers, have been for several decades a unique method of categorizing ships of all types: combatants, auxiliaries and district craft. Though considerably changed in detail and expanded over the years, this system remains essentially the same as when formally implemented in 1920. It is a very useful tool for organizing and keeping track of naval vessels, and also provides the basis for the identification numbers painted on the bows (and frequently the sterns) of most U.S. Navy ships.\n\nThe ship designator and hull number system's roots extend back to the late 1880s, when ship type serial numbers were assigned to most of the new-construction warships of the emerging \"Steel Navy\". During the course of the next thirty years, these same numbers were combined with filing codes used by the Navy's clerks to create an informal version of the system that was put in place in 1920. Limited usage of ship numbers goes back even earlier, most notably to the \"Jeffersonian Gunboats\" of the early 1800s and the \"Tinclad\" river gunboats of the Civil War Mississippi Squadron.\n\nIt is important to understand that hull number letter prefixes are not acronyms, and should not be carelessly treated as abbreviations of ship type classifications. Thus, \"DD\" does not stand for anything more than \"Destroyer\". \"SS\" simply means \"Submarine\". And \"FF\" is the post-1975 type code for \"Frigate.\"\n\nThe hull classification codes for ships in active duty in the United States Navy are governed under Secretary of the Navy Instruction 5030.8B (SECNAVINST 5030.8B).\n\nWarships are designed to participate in combat operations.\n\nThe origin of the 2 letter code derives from the need to distinguish various cruiser subtypes.\nAircraft carriers are ships designed primarily for the purpose of conducting combat operations by aircraft which engage in attacks against airborne, surface, sub-surface and shore targets. Contrary to popular belief, the \"CV\" hull classification symbol does not stand for \"carrier vessel\". \"CV\" derives from the cruiser designation, with the v for French \"voler\", \"to fly\". Aircraft carriers are designated in two sequences: the first sequence runs from CV-1 USS \"Langley\" to the very latest ships, and the second sequence, \"CVE\" for escort carriers, ran from CVE-1 \"Long Island\" to CVE-127 \"Okinawa\" before being discontinued.\n\nSurface combatants are ships which are designed primarily to engage enemy forces on the high seas. The primary surface combatants are battleships, cruisers and destroyers. Battleships are very heavily armed and armored; cruisers moderately so; destroyers and smaller warships, less so. Before 1920, ships were called \"<type> no. X\", with the type fully pronounced. The types were commonly abbreviated in ship lists to \"B-X\", \"C-X\", \"D-X\" et cetera—for example, before 1920, would have been called \"USS \"Minnesota\", Battleship number 22\" orally and \"USS \"Minnesota\", B-22\" in writing. After 1920, the ship's name would have been both written and pronounced \"USS \"Minnesota\" (BB-22)\". In generally decreasing size, the types are:\n\nSubmarines are all self-propelled submersible types (usually started with SS) regardless of whether employed as combatant, auxiliary, or research and development vehicles which have at least a residual combat capability. While some classes, including all diesel-electric submarines, are retired from USN service, non-U.S. navies continue to employ SS, SSA, SSAN, SSB, SSC, SSG, SSM, and SST types. With the advent of new Air Independent Propulsion/Power (AIP) systems, both SSI and SSP are used to distinguish the types within the USN, but SSP has been declared the preferred term. SSK, retired by the USN, continues to be used colloquially and interchangeably with SS for diesel-electric attack/patrol submarines within the USN, and, more formally, by the Royal Navy and British firms such as Jane's Information Group.\n\n\nPatrol combatants are ships whose mission may extend beyond coastal duties and whose characteristics include adequate endurance and sea keeping, providing a capability for operations exceeding 48 hours on the high seas without support. This notably included Brown Water Navy/Riverine Forces during the Vietnam War. Few of these ships are in service today.\n\nAmphibious warfare vessels include all ships having organic capability for amphibious warfare and which have characteristics enabling long duration operations on the high seas. There are two classifications of craft: amphibious warfare ships which are built to cross oceans, and landing craft, which are designed to take troops from ship to shore in an invasion.\n\nShips\n\nLanding Craft\n\nOperated by Military Sealift Command, have ship prefix \"USNS\", hull code begins with \"T-\".\n\nShips which have the capability to provide underway replenishment to fleet units.\n\nMine warfare ships are those ships whose primary function is mine warfare on the high seas.\n\nCoastal defense ships are those whose primary function is coastal patrol and interdiction.\n\nMobile logistics ships have the capability to provide direct material support to other deployed units operating far from home ports.\n\nAn auxiliary ship is designed to operate in any number of roles supporting combatant ships and other naval operations.\n\nAlthough technically an aircraft, pre-World War II rigid airships (e.g., zeppelins) were treated like commissioned surface warships and submarines, flew the U.S. ensign from their stern and carried a United States Ship (USS) designation. Non-rigid airships (e.g., blimps) continued to fly the U.S. ensign from their stern, but were always considered to be primarily aircraft.\n\nSupport ships are not designed to participate in combat, and are generally not armed. For ships with civilian crews (owned by and/or operated for Military Sealift Command and the Maritime Administration), the prefix T- is placed at the front of the hull classification.\n\nSupport ships are designed to operate in the open ocean in a variety of sea states to provide general support to either combatant forces or shore based establishments. They include smaller auxiliaries which, by the nature of their duties, leave inshore waters.\n\nService craft are navy-subordinated craft (including non-self-propelled) designed to provide general support to either combatant forces or shore-based establishments. The suffix \"N\" refers to non-self-propelled variants.\n\nPrior to 1965, U.S. Coast Guard ships used the same designation as naval ships, but preceded by a \"W\" to indicate Coast Guard subordination.\n\nUnited States Navy Designations (Temporary) are a form of U.S. Navy ship designation, intended for temporary identification use. Such designations usually occur during periods of sudden mobilization, such as that which occurred prior to, and during, World War II or the Korean War, when it was determined that a sudden temporary need arose for a ship for which there was no official Navy designation.\n\nDuring World War II, for example, a number of commercial vessels were requisitioned, or acquired, by the U.S. Navy to meet the sudden requirements of war. A yacht acquired by the U.S. Navy during the start of World War II might seem desirable to the Navy whose use for the vessel might not be fully developed or explored at the time of acquisition.\n\nOn the other hand, a U.S. Navy vessel, such as the yacht in the example above, already in commission or service, might be desired, or found useful, for another need or purpose for which there is no official designation.\n\nNumerous other U.S. Navy vessels were launched with a temporary, or nominal, designation, such as YMS or PC, since it could not be determined, at time of construction, what they should be used for. Many of these were vessels in the 150 to 200 feet length class with powerful engines, whose function could be that of a minesweeper, patrol craft, submarine chaser, seaplane tender, tugboat, or other. Once their destiny, or capability, was found or determined, such vessels were reclassified with their actual designation.\n\n\nThe letter is paired with a three-digit number. The first digit of the number is determined by the ships \"power tonnage,\" defined as the sum of its shaft horsepower and gross international tonnage, as follows:\n\nThe second and third digits are assigned to create a unique three-digit hull number.\n\n\n\n"}
{"id": "14091", "url": "https://en.wikipedia.org/wiki?curid=14091", "title": "Habeas corpus", "text": "Habeas corpus\n\nHabeas corpus (; Medieval Latin meaning literally \"that you have the body\") is a recourse in law through which a person can report an unlawful detention or imprisonment to a court and request that the court order the custodian of the person, usually a prison official, to bring the prisoner to court, to determine whether the detention is lawful.\n\nThe writ of \"habeas corpus\" is known as \"the great and efficacious writ in all manner of illegal confinement\". It is a summons with the force of a court order; it is addressed to the custodian (a prison official, for example) and demands that a prisoner be taken before the court, and that the custodian present proof of authority, allowing the court to determine whether the custodian has lawful authority to detain the prisoner. If the custodian is acting beyond his or her authority, then the prisoner must be released. Any prisoner, or another person acting on his or her behalf, may petition the court, or a judge, for a writ of \"habeas corpus\". One reason for the writ to be sought by a person other than the prisoner is that the detainee might be held incommunicado. Most civil law jurisdictions provide a similar remedy for those unlawfully detained, but this is not always called \"habeas corpus\". For example, in some Spanish-speaking nations, the equivalent remedy for unlawful imprisonment is the \"amparo de libertad\" (\"protection of freedom\").\n\n\"Habeas corpus\" has certain limitations. Though a writ of right, it is not a writ of course. It is technically only a procedural remedy; it is a guarantee against any detention that is forbidden by law, but it does not necessarily protect other rights, such as the entitlement to a fair trial. So if an imposition such as internment without trial is permitted by the law, then \"habeas corpus\" may not be a useful remedy. In some countries, the writ has been temporarily or permanently suspended under the pretext of war or state of emergency.\n\nThe right to petition for a writ of \"habeas corpus\" has nonetheless long been celebrated as the most efficient safeguard of the liberty of the subject. The jurist Albert Venn Dicey wrote that the British Habeas Corpus Acts \"declare no principle and define no rights, but they are for practical purposes worth a hundred constitutional articles guaranteeing individual liberty\".\n\nThe writ of \"habeas corpus\" is one of what are called the \"extraordinary\", \"common law\", or \"prerogative writs\", which were historically issued by the English courts in the name of the monarch to control inferior courts and public authorities within the kingdom. The most common of the other such prerogative writs are \"quo warranto\", \"prohibito\", \"mandamus\", \"procedendo\", and \"certiorari\". The due process for such petitions is not simply civil or criminal, because they incorporate the presumption of non-authority. The official who is the respondent must prove his authority to do or not do something. Failing this, the court must decide for the petitioner, who may be any person, not just an interested party. This differs from a motion in a civil process in which the movant must have standing, and bears the burden of proof.\n\nFrom Latin \"habeas\", 2nd person singular present subjunctive active of \"habere\", \"to have\", \"to hold\"; and \"corpus\", accusative singular of \"corpus\", \"body\". In reference to more than one person, \"habeas corpora\".\n\nLiterally, the phrase means \"[we command] that you should have the [detainee's] body [brought to court]\". The complete phrase \"habeas corpus ad subjiciendum\" means \"that you have the person for the purpose of subjecting him/her to (examination)\". These are the opening words of writs in 14th century Anglo-French documents requiring a person to be brought before a court or judge, especially to determine if that person is being legally detained.\n\nThe full name of the writ is often used to distinguish it from similar ancient writs, also named \"habeas corpus\". These include:\n\n\"Habeas corpus\" originally stems from the Assize of Clarendon, a re-issuance of rights during the reign of Henry II of England. In the 17th century, the foundations for \"habeas corpus\" were \"wrongly thought\" to have originated in Magna Carta. This charter declared that:\n\nWilliam Blackstone cites the first recorded usage of \"habeas corpus ad subjiciendum\" in 1305, during the reign of King Edward I. However, other writs were issued with the same effect as early as the reign of Henry II in the 12th century. Blackstone explained the basis of the writ, saying \"[t]he king is at all times entitled to have an account, why the liberty of any of his subjects is restrained, wherever that restraint may be inflicted.\" The procedure for issuing a writ of \"habeas corpus\" was first codified by the Habeas Corpus Act 1679, following judicial rulings which had restricted the effectiveness of the writ. A previous law (the Habeas Corpus Act 1640) had been passed forty years earlier to overturn a ruling that the command of the King was a sufficient answer to a petition of \"habeas corpus\". The cornerstone purpose of the <nowiki>\"writ of habeas corpus\" was to limit the King's Chancery's ability to undermine the surety of law by allowing courts of justice decisions to be overturned in favor and application of \"equity\", a process managed by the Chancelor (a bishop) with the King'</nowiki>s authority.\n\nThe 1679 codification of \"habeas corpus\" took place in the context of a sharp confrontation between King Charles II and the Parliament, which was dominated by the then sharply oppositional, nascent Whig Party. The Whig leaders had good reasons to fear the King moving against them through the courts (as indeed happened in 1681) and regarded \"habeas corpus\" as safeguarding their own persons. The short-lived Parliament which made this enactment came to be known as the \"Habeas Corpus Parliament\" - being dissolved by the King immediately afterwards.\n\nThen, as now, the writ of \"habeas corpus\" was issued by a superior court in the name of the Sovereign, and commanded the addressee (a lower court, sheriff, or private subject) to produce the prisoner before the royal courts of law. A \"habeas corpus\" petition could be made by the prisoner him or herself or by a third party on his or her behalf and, as a result of the Habeas Corpus Acts, could be made regardless of whether the court was in session, by presenting the petition to a judge. Since the 18th century the writ has also been used in cases of unlawful detention by private individuals, most famously in \"Somersett's Case\" (1772), where the black slave Somersett was ordered to be freed. During that case, these famous words are said to have been uttered: \"The air of England has long been too pure for a slave, and every man is free who breathes it\". During the Seven Years' War and later conflicts, the Writ was used on behalf of soldiers and sailors pressed into military and naval service. The Habeas Corpus Act 1816 introduced some changes and expanded the territoriality of the legislation.\n\nThe privilege of \"habeas corpus\" has been suspended or restricted several times during English history, most recently during the 18th and 19th centuries. Although internment without trial has been authorised by statute since that time, for example during the two World Wars and the Troubles in Northern Ireland, the \"habeas corpus\" procedure has in modern times always technically remained available to such internees. However, as \"habeas corpus\" is only a procedural device to examine the lawfulness of a prisoner's detention, so long as the detention is in accordance with an Act of Parliament, the petition for \"habeas corpus\" is unsuccessful. Since the passage of the Human Rights Act 1998, the courts have been able to declare an Act of Parliament to be incompatible with the European Convention on Human Rights, but such a declaration of incompatibility has no legal effect unless and until it is acted upon by the government.\n\nThe wording of the writ of \"habeas corpus\" implies that the prisoner is brought to the court for the legality of the imprisonment to be examined. However, rather than issuing the writ immediately and waiting for the return of the writ by the custodian, modern practice in England is for the original application to be followed by a hearing with both parties present to decide the legality of the detention, without any writ being issued. If the detention is held to be unlawful, the prisoner can usually then be released or bailed by order of the court without having to be produced before it. With the development of modern public law, applications for habeas corpus have been to some extent discouraged, in favour of applications for judicial review. The writ, however, maintains its vigour, and was held by the UK Supreme Court to be available in respect of a prisoner captured by British forces in Afghanistan, albeit that the Secretary of State made a valid return to the writ justifying the detention of the claimant.\n\nThe writ of \"habeas corpus\" as a procedural remedy is part of Australia's English law inheritance. In 2005, the Australian parliament passed the Australian Anti-Terrorism Act 2005. Some legal experts questioned the constitutionality of the act, due in part to limitations it placed on \"habeas corpus\".\n\n\"Habeas corpus\" rights are part of the British legal tradition inherited by Canada. The rights exist in the common law but have been enshrined in the Constitution Act 1982, under Section Ten of the Charter of Rights and Freedoms. This states that \"Everyone has the right on arrest or detention ... (c) to have the validity of the detention determined by way of \"habeas corpus\" and to be released if the detention is not lawful\".\n\nSuspension of the writ in Canadian history occurred famously during the October Crisis, during which the War Measures Act was invoked by the Governor General of Canada on the constitutional advice of Prime Minister Pierre Trudeau, who had received a request from the Quebec Cabinet. The Act was also used to justify German, Slavic, and Ukrainian Canadian internment during the First World War, and the internment of German-Canadians, Italian-Canadians and Japanese-Canadians during the Second World War. The writ was suspended for several years following the Battle of Fort Erie (1866) during the Fenian Rising, though the suspension was only ever applied to suspects in the Thomas D'Arcy McGee assassination.\n\nThe writ is available where there is no other adequate remedy. However, a superior court always has the discretion to grant the writ even in the face of an alternative remedy (see \"May v Ferndale Institution\"). Under the Criminal Code the writ is largely unavailable if a statutory right of appeal exists, whether or not this right has been exercised.\n\nA fundamental human right in the \"1789 Declaration of the Rights of Man\" drafted by Lafayette in cooperation with Thomas Jefferson, the guarantees against arbitrary detention are enshrined in the French Constitution and regulated by the Penal Code. The safeguards are equivalent to those found under the Habeas-Corpus provisions found in Germany, the United States and several Commonwealth countries. The French system of accountability prescribes severe penalties for ministers, police officers and civil and judiciary authorities who either violate or fail to enforce the law.\n\n\"Article 7 of [1789] Declaration also provides that 'No individual may be accused, arrested, or detained except where the law so prescribes, and in accordance with the procedure it has laid down.' ... The Constitution further states that 'No one may be arbitrarily detained. The judicial authority, guardian of individual liberty, ensures the observance of this principle under the condition specified by law.' Its article 5 provides that everyone has the right to liberty and sets forth permissible circumstances under which people may be deprived of their liberty and procedural safeguards in case of detention. In particular, it states that 'anyone deprived of his liberty by arrest or detention shall be entitled to take proceedings by which the lawfulness of his detention shall be decided speedily by a court and his release ordered if the detention is not lawful'.\"\n\nFrance and the United States played a synergistic role in the international team, led by Eleanor Roosevelt, which crafted the Universal Declaration of Human Rights. The French judge and Nobel Peace Laureate René Cassin produced the first draft and argued against arbitrary detentions. René Cassin and the French team subsequently championed the \"habeas corpus\" provisions enshrined in the European Convention for the Protection of Human Rights and Fundamental Freedoms.\n\nGermany has constitutional guarantees against improper detention and these have been implemented in statutory law in a manner that can be considered as equivalent to writs of habeas corpus.\n\nArticle 104, paragraph 1 of the Basic Law for the Federal Republic of Germany provides that deprivations of liberty may be imposed only on the basis of a specific enabling statute that also must include procedural rules. Article 104, paragraph 2 requires that any arrested individual be brought before a judge by the end of the day following the day of the arrest. For those detained as criminal suspects, article 104, paragraph 3 specifically requires that the judge must grant a hearing to the suspect in order to rule on the detention.\n\nRestrictions on the power of the authorities to arrest and detain individuals also emanate from article 2 paragraph 2 of the Basic Law which guarantees liberty and requires a statutory authorization for any deprivation of liberty. In addition, several other articles of the Basic Law have a bearing on the issue. The most important of these are article 19, which generally requires a statutory basis for any infringements of the fundamental rights guaranteed by the Basic Law while also guaranteeing judicial review; article 20, paragraph 3, which guarantees the rule of law; and article 3 which guarantees equality.\n\nIn particular, a constitutional obligation to grant remedies for improper detention is required by article 19, paragraph 4 of the Basic Law, which provides as follows: \"Should any person's right be violated by public authority, he may have recourse to the courts. If no other jurisdiction has been established, recourse shall be to the ordinary courts.\"\n\nThe Indian judiciary, in a catena of cases, has effectively resorted to the writ of \"habeas corpus\" to secure release of a person from illegal detention. For example, in October 2009, the Karnataka High Court heard a \"habeas corpus\" petition filed by the parents of a girl who married a Muslim boy from Kannur district and was allegedly confined in a \"madrasa\" in Malapuram town. Usually, in most other jurisdictions, the writ is directed at police authorities. The extension to non-state authorities has its grounds in two cases: the 1898 Queen's Bench case of \"Ex Parte Daisy Hopkins\", wherein the Proctor of Cambridge University did detain and arrest Hopkins without his jurisdiction, and Hopkins was released, and that of \"Somerset v Stewart\", in which an African slave whose master had moved to London was freed by action of the writ.\n\nThe Indian judiciary has dispensed with the traditional doctrine of \"locus standi\", so that if a detained person is not in a position to file a petition, it can be moved on his behalf by any other person. The scope of \"habeas\" relief has expanded in recent times by actions of the Indian judiciary.\n\nIn 1976, the \"habeas\" writ was used in the Rajan case, a student victim of torture in local police custody during the nationwide Emergency in India. On 12 March 2014, Subrata Roy's counsel approached the Chief Justice moving a \"habeas corpus\" petition. It was also filed by the Panthers Party to protest the imprisonment of Anna Hazare, a social activist.\n\nIn the Republic of Ireland, the writ of \"habeas corpus\" is available at common law and under the Habeas Corpus Acts of 1782 and 1816. A remedy equivalent to \"habeas corpus\" is also guaranteed by Article 40 of the 1937 constitution.\n\nThe article guarantees that \"no citizen shall be deprived of his personal liberty save in accordance with law\" and outlines a specific procedure for the High Court to enquire into the lawfulness of any person's detention. It does not mention the Latin term, \"habeas corpus\", but includes the English phrase \"produce the body\".\n\nArticle 40.4.2° provides that a prisoner, or anyone acting on his behalf, may make a complaint to the High Court (or to any High Court judge) of unlawful detention. The court must then investigate the matter \"forthwith\" and may order that the defendant bring the prisoner before the court and give reasons for his detention. The court must immediately release the detainee unless it is satisfied that he is being held lawfully. The remedy is available not only to prisoners of the state, but also to persons unlawfully detained by any private party. However the constitution provides that the procedure is not binding on the Defence Forces during a state of war or armed rebellion.\n\nThe full text of Article 40.4.2° is as follows: \n\nThe writ of \"habeas corpus\" continued as part of the Irish law when the state seceded from the United Kingdom in 1922. A remedy equivalent to \"habeas corpus\" was also guaranteed by Article 6 of the Constitution of the Irish Free State, enacted in 1922. That article used similar wording to Article 40.4 of the current constitution, which replaced it 1937.\n\nThe relationship between the Article 40 and the Habeas Corpus Acts of 1782 and 1816 is ambiguous, and Forde and Leonard write that \"The extent if any to which Art 40.4 has replaced these Acts has yet to be determined\". In \"The State (Ahern) v Cotter\" (1982) Walsh J opined that the ancient writ referred to in the Habeas Corpus Acts remains in existence in Irish law as a separate remedy from that provided for in Article 40.\n\nIn 1941, the Article 40 procedure was restricted by the Second Amendment. Prior to the amendment, a prisoner had the constitutional right to apply to any High Court judge for an enquiry into her detention, and to as many High Court judges as she wished. If the prisoner successfully challenged her detention before the High Court she was entitled to immediate, unconditional release.\n\nThe Second Amendment provided that a prisoner has only the right to apply to a single judge, and, once a writ has been issued, the President of the High Court has authority to choose the judge or panel of three judges who will decide the case. If the High Court finds that the prisoner's detention is unlawful due to the unconstitutionality of a law the judge must refer the matter to the Supreme Court, and until the Supreme's Court's decision is rendered the prisoner may be released only on bail.\n\nThe power of the state to detain persons prior to trial was extended by the Sixteenth Amendment, in 1996. In 1965, the Supreme Court ruled in the \"O'Callaghan\" case that the constitution required that an individual charged with a crime could be refused bail only if she was likely to flee or to interfere with witnesses or evidence. Since the Sixteenth Amendment, it has been possible for a court to take into account whether a person has committed serious crimes while on bail in the past.\n\nThe right to freedom from arbitrary detention is guaranteed by Article 13 of the Constitution of Italy, which states: \n\nIn Malaysia, the remedy of \"habeas corpus\" is guaranteed by the federal constitution, although not by name. Article 5(2) of the Constitution of Malaysia provides that \"Where complaint is made to a High Court or any judge thereof that a person is being unlawfully detained the court shall inquire into the complaint and, unless satisfied that the detention is lawful, shall order him to be produced before the court and release him\".\n\nAs there are several statutes, for example, the Internal Security Act 1960, that still permit detention without trial, the procedure is usually effective in such cases only if it can be shown that there was a procedural error in the way that the detention was ordered.\n\nIn New Zealand, \"habeas corpus\" may be invoked against the government or private individuals. In 2006, a child was allegedly kidnapped by his maternal grandfather after a custody dispute. The father began \"habeas corpus\" proceedings against the mother, the grandfather, the grandmother, the great grandmother, and another person alleged to have assisted in the kidnap of the child. The mother did not present the child to the court and so was imprisoned for contempt of court. She was released when the grandfather came forward with the child in late January 2007.\n\nIssuance of a writ is an exercise of an extraordinary jurisdiction of the superior courts in Pakistan. A writ of habeas corpus may be issued by any High Court of a province in Pakistan. Article 199 of the 1973 Constitution of the Islamic Republic of Pakistan, specifically provides for the issuance of a writ of habeas corpus, empowering the courts to exercise this prerogative. Subject to the Article 199 of the Constitution, \"A High Court may, if it is satisfied that no other adequate remedy is provided by law, on the application of any person, make an order that a person in custody within the territorial jurisdiction of the Court be brought before it so that the Court may satisfy itself that he is not being held in custody without a lawful authority or in an unlawful manner\". The hallmark of extraordinary constitutional jurisdiction is to keep various functionaries of State within the ambit of their authority. Once a High Court has assumed jurisdiction to adjudicate the matter before it, justiciability of the issue raised before it is beyond question. The Supreme Court of Pakistan has stated clearly that the use of words \"in an unlawful manner\" implies that the court may examine, if a statute has allowed such detention, whether it was a colorable exercise of the power of authority. Thus, the court can examine the malafides of the action taken.\n\nIn the Bill of Rights of the Philippine constitution, \"habeas corpus\" is guaranteed in terms almost identically to those used in the U.S. Constitution. in Article 3, Section 15 of the Constitution of the Philippines states that \"The privilege of the writ of \"habeas corpus\" shall not be suspended except in cases of invasion or rebellion when the public safety requires it\".\n\nIn 1971, after the Plaza Miranda bombing, the Marcos administration, under Ferdinand Marcos, suspended \"habeas corpus\" in an effort to stifle the oncoming insurgency, having blamed the Filipino Communist Party for the events of August 21. Many considered this to be a prelude to martial law. After widespread protests, however, the Arroyo administration decided to reintroduce the writ. In December 2009, \"habeas corpus\" was suspended in Maguindanao as the province was placed under martial law. This occurred in response to the Maguindanao massacre.\n\nIn 2016, President Rodrigo Duterte said he was planning on suspending the habeas corpus.\n\nOn May 23, 2017 at 10 pm Philippine time, President Rodrigo Duterte declared martial law in the whole island of Mindanao including Sulu and Tawi-tawi for the period of 60 days due to the series of attacks mounted by the Maute group, an ISIS-linked terrorist organization. The declaration suspends the writ.\n\nThe Parliament of Scotland passed a law to have the same effect as \"habeas corpus\" in the 18th century. This is now known as the Criminal Procedure Act 1701 c.6. It was originally called \"the Act for preventing wrongful imprisonment and against undue delays in trials\". It is still in force although certain parts have been repealed.\n\nThe present Constitution of Spain states that \"A \"habeas corpus\" procedure shall be provided for by law to ensure the immediate handing over to the judicial authorities of any person illegally arrested\". The statute which regulates the procedure is the \"Law of Habeas Corpus of 24 May 1984\", which provides that a person imprisoned may, on her or his own or through a third person, allege that she or he is imprisoned unlawfully and request to appear before a judge. The request must specify the grounds on which the detention is considered to be unlawful, which can be, for example, that the custodian holding the prisoner does not have the legal authority, that the prisoner's constitutional rights have been violated, or that he has been subjected to mistreatment. The judge may then request additional information if needed, and may issue a \"habeas corpus\" order, at which point the custodian has 24 hours to bring the prisoner before the judge.\n\nHistorically, many of the territories of Spain had remedies equivalent to the \"habeas corpus\", such as the privilege of \"manifestación\" in the Crown or Aragon or the right of the Tree in Biscay.\n\nThe United States inherited \"habeas corpus\" from the English common law. In England, the writ was issued in the name of the monarch. When the original thirteen American colonies declared independence, and became a republic based on popular sovereignty, any person, in the name of the people, acquired authority to initiate such writs. The U.S. Constitution specifically includes the \"habeas\" procedure in the Suspension Clause (Clause 2), located in Article One, Section 9. This states that \"The privilege of the writ of \"habeas corpus\" shall not be suspended, unless when in cases of rebellion or invasion the public safety may require it\".\n\nThe writ of \"habeas corpus ad subjiciendum\" is a civil, not criminal, \"ex parte\" proceeding in which a court inquires as to the legitimacy of a prisoner's custody. Typically, \"habeas corpus\" proceedings are to determine whether the court that imposed sentence on the defendant had jurisdiction and authority to do so, or whether the defendant's sentence has expired. \"Habeas corpus\" is also used as a legal avenue to challenge other types of custody such as pretrial detention or detention by the United States Bureau of Immigration and Customs Enforcement pursuant to a deportation proceeding.\n\nPresidents Abraham Lincoln and Ulysses Grant suspended \"habeas corpus\" during the Civil War and Reconstruction for some places or types of cases. During World War II, President Franklin D. Roosevelt suspended habeas corpus. Following the September 11 attacks, President George W. Bush attempted to place Guantanamo Bay detainees outside of the jurisdiction of \"habeas corpus\", but the Supreme Court of the United States overturned this action in \"Boumediene v. Bush\".\n\nIn 1526, the \"Fuero Nuevo of the Señorío de Vizcaya\" (\"New Charter of the Lordship of Biscay\") established a form of \"habeas corpus\" in the territory of the \"Señorío de Vizcaya\", nowadays part of Spain. This revised version of the \"Fuero Viejo\" (Old Charter) of 1451 codified the medieval custom whereby no person could be arbitrarily detained without being summoned first to the Oak of Gernika, an ancestral oak tree located in the outskirts of Gernika under which all laws of the Lordship of Biscay were passed.\n\nThe New Charter formalised that no one could be detained without a court order (Law 26 of Chapter 9) nor due to debts (Law 3 of Chapter 16). It also established that no one could be arrested without previously having been summoned to the Oak of Gernika and given 30 days to answer the said summon, and that upon presenting themselves under the Tree, they had to be provided with all evidence and accusations so that they could defend themselves (Law 7 of Chapter 9). No one could be sent to prison or deprived of their freedom until being formally trialed, and no one could be accused of a different crime until their current court trial was over (Law 5 of Chapter 5). Those fearing they were being arrested illegally could appeal to the \"Regimiento General\" that their rights could be upheld. The \"Regimiento\" (the executive arm of the Juntas Generales of Biscay) would demand the prisoner be handed over to them, and thereafter the prisoner would be released and placed under the protection of the Regimiento while awaiting for trial.\n\nThe Crown of Aragon also had a remedy equivalent to the \"habeas corpus\" called the \"manifestación de personas\" (literally, \"demonstration of persons\"). According to the right of \"manifestación\", the Justicia de Aragon (lit. \"Justice of Aragon\", an Aragonese judiciary figure similar to an ombudsman, but with far reaching executive powers) could require a judge, a court of justice, or any other official that they handed over to the \"Justicia\" (i.e., that they \"demonstrated\") anyone being prosecuted so as to guarantee that this person's rights were upheld, and that no violence would befall this person prior to him being sentenced. Furthermore, the \"Justicia\" retained the right to examine the judgement and decide whether it satisfied the conditions of a fair trial; if the \"Justicia\" was not satisfied, he could refuse to hand the accused back to the authorities. The right of \"manifestación\" acted like an habeas corpus: knowing that the appeal to the \"Justicia\" would immediately follow any unlawful detention, these were effectively illegal. Equally, torture (which had been banned since 1325 in Aragon) could never take place. In some cases, people exerting their right of manifestación were kept under the Justicia's watch in \"manifestación\" prisons (famous for their mild and easy conditions) or house arrest; more generally however, the person was released from confinement and placed under the \"Justicia's protection\", awaiting trial. The \"Justicia\" always granted the right of \"manifestación\" by default, but they only really had to act in extreme cases, as for instance famously happened in 1590 when Antonio Pérez, the disgraced secretary to Philip II of Spain, fled from Castile to Aragon and used his Aragonese ascendency to appeal to the \"Justicia\" for manifestación right, and therefore prevent his arrest at the King's behest.\n\nThe right of \"manifestación\" was codified in 1325 in the Declaratio Privilegii generalis passed by the Aragonese Corts under king James II of Aragon. It had been practiced since the inception of the kingdom of Aragon in the 11th century, and therefore predates the \"habeas corpus\" itself.\n\nIn 1430, King Władysław II Jagiełło of Poland granted the Privilege of Jedlnia, which proclaimed, \"Neminem captivabimus nisi iure victum\" (\"We will not imprison anyone except if convicted by law\"). This revolutionary innovation in civil libertarianism gave Polish citizens due process-style rights that did not exist in any other European country for another 250 years. Originally, the Privilege of Jedlnia was restricted to the nobility (the szlachta), but it was extended to cover townsmen in the 1791 Constitution. Importantly, social classifications in the Polish–Lithuanian Commonwealth were not as rigid as in other European countries; townspeople and Jews were sometimes ennobled. The Privilege of Jedlnia provided broader coverage than many subsequently enacted habeas corpus laws because Poland's nobility constituted an unusually large percentage of the country's total population, which was Europe's largest. As a result, by the 16th century, it was protecting the liberty of between five hundred thousand and a million Poles.\n\nIn South Africa and other countries whose legal systems are based on Roman-Dutch law, the \"interdictum de homine libero exhibendo\" is the equivalent of the writ of \"habeas corpus\". In South Africa, it has been entrenched in the Bill of Rights, which provides in section 35(2)(d) that every detained person has the right to challenge the lawfulness of the detention in person before a court and, if the detention is unlawful, to be released.\n\nIn the 1950s, American lawyer Luis Kutner began advocating an international writ of \"habeas corpus\" to protect individual human rights. In 1952, he filed a petition for a \"United Nations Writ of Habeas Corpus\" on behalf of William N. Oatis, an American journalist jailed the previous year by the Communist government of Czechoslovakia. Alleging that Czechoslovakia had violated Oatis's rights under the United Nations Charter and the Universal Declaration of Human Rights and that the United Nations General Assembly had \"inherent power\" to fashion remedies for human rights violations, the petition was filed with the United Nations Commission on Human Rights. The Commission forwarded the petition to Czechoslovakia, but no other United Nations action was taken. Oatis was released in 1953. Kutner went on to publish numerous articles and books advocating the creation of an \"International Court of Habeas Corpus\".\n\nArticle 3 of the Universal Declaration of Human Rights provides that \"everyone has the right to life, liberty and security of person\". Article 5 of the European Convention on Human Rights goes further and calls for persons detained to have the right to challenge their detention, providing at article 5.4: \n\n\n"}
{"id": "14092", "url": "https://en.wikipedia.org/wiki?curid=14092", "title": "Prince Henry the Navigator", "text": "Prince Henry the Navigator\n\nInfante D. Henrique of Portugal, Duke of Viseu (4 March 1394 – 13 November 1460), better known as Prince Henry the Navigator (), was a central figure in the early days of the Portuguese Empire and in the 15th-century European maritime discoveries and maritime expansion. Through his administrative direction, he is regarded as the main initiator of what would be known as the Age of Discovery. Henry was the fourth child of the Portuguese king John I and responsible for the early development of Portuguese exploration and maritime trade with other continents through the systematic exploration of Western Africa, the islands of the Atlantic Ocean, and the search for new routes.\n\nKing John I founded the House of Aviz. Henry encouraged his father to conquer Ceuta (1415), the Muslim port on the North African coast across the Straits of Gibraltar from the Iberian Peninsula. He learned of the opportunities offered by the Saharan trade routes that terminated there, and became fascinated with Africa in general; he was most intrigued by the Christian legend of Prester John and the expansion of Portuguese trade. Henry is regarded as the patron of Portuguese exploration.\n\nHenry was the third surviving son of King John I and his wife Philippa, sister of King Henry IV of England. He was baptized in Porto, and may have been born there, probably when the royal couple was living in the city's old mint, now called Casa do Infante (Prince's House), or in the region nearby. Another possibility is that he was born at the Monastery of Leça do Bailio, in Leça de Palmeira, during the same period of the royal couple's residence in the city of Porto.\n\nHenry was 21 when he and his father and brothers captured the Moorish port of Ceuta in northern Morocco. Ceuta had long been a base for Barbary pirates who raided the Portuguese coast, depopulating villages by capturing their inhabitants to be sold in the African slave trade. Following this success, Henry began to explore the coast of Africa, most of which was unknown to Europeans. His objectives included finding the source of the West African gold trade and the legendary Christian kingdom of Prester John, and stopping the pirate attacks on the Portuguese coast.\n\nAt that time, the ships of the Mediterranean were too slow and too heavy to make these voyages. Under his direction, a new and much lighter ship was developed, the caravel, which could sail further and faster, and, above all, was highly maneuverable and could sail much nearer the wind, or \"into the wind\". This made the caravel largely independent of the prevailing winds. \nWith the caravel, Portuguese mariners explored rivers and shallow waters as well as the open ocean with wide autonomy. In fact, the invention of the caravel was what made Portugal poised to take the lead in transoceanic exploration.\n\nIn 1419, Henry's father appointed him governor of the province of the Algarve.\n\nOn 25 May 1420, Henry gained appointment as the Grand Master of the Military Order of Christ, the Portuguese successor to the Knights Templar, which had its headquarters at Tomar, in central Portugal. Henry held this position for the remainder of his life, and the Order was an important source of funds for Henry's ambitious plans, especially his persistent attempts to conquer the Canary Islands, which the Portuguese had claimed to have discovered before the year 1346.\n\nIn 1425, his second brother the Infante Peter, Duke of Coimbra, made a tour of Europe. While largely a diplomatic mission, among his goals was to seek out geographic material for his brother Henry. Peter returned from Venice with a current world map drafted by a Venetian cartographer.\n\nIn 1431, he donated houses for the \"Estudo Geral\" to reunite all the sciences—grammar, logic, rhetoric, arithmetic, music, and astronomy—into what would later become the University of Lisbon. For other subjects like medicine or philosophy, he ordered that each room should be decorated according to each subject that was being taught.\n\nHenry also had other resources. When John I died in 1433, Henry's eldest brother Edward of Portugal became king. He granted Henry all profits from trading within the areas he discovered as well as the sole right to authorize expeditions beyond Cape Bojador. Henry also held a monopoly on tuna fishing in the Algarve. When Edward died eight years later, Henry supported his brother Peter, Duke of Coimbra for the regency during the minority of Edward's son Afonso V, and in return received a confirmation of this levy.\n\nHenry functioned as a primary organizer of the disastrous expedition to Tangier in 1437. Henry's younger brother Ferdinand was given as a hostage to guarantee that the Portuguese would fulfill the terms of the peace agreement that had been made with Çala Ben Çala. The Portuguese Cortes refused to approve the return of Ceuta in exchange for the Infante Ferdinand who remained in captivity until his death six years later.\n\nPrince Regent Peter had an important role and responsibility in the Portuguese maritime expansion in the Atlantic Ocean and Africa during his administration. Henry promoted the colonization of the Azores during Peter's regency (1439–1448).\n\nFor most of the latter part of his life, Henry concentrated on his maritime activities, or on Portuguese court politics.\n\nAccording to João de Barros, in the Algarve he repopulated a village that he called Terçanabal (from \"terça nabal\" or \"tercena nabal\"). This village was situated in a strategic position for his maritime enterprises and was later called Vila do Infante (\"Estate or Town of the Prince\").\n\nIt is traditionally suggested that Henry gathered at his villa on the Sagres peninsula a school of navigators and map-makers. However modern historians hold this to be a misconception. He did employ some cartographers to chart the coast of Mauritania after the voyages he sent there, but there was no center of navigation science or observatory in the modern sense of the word, nor was there an organized navigational center.\n\nReferring to Sagres, sixteenth-century Portuguese mathematician and cosmographer Pedro Nunes remarked, \"from it our sailors went out well taught and provided with instruments and rules which all map makers and navigators should know.\"\n\nThe view that Henry's court rapidly grew into the technological base for exploration, with a naval arsenal and an observatory, etc., although repeated in popular culture, has never been established. Henry did possess geographical curiosity, and employed cartographers. Jehuda Cresques, a noted cartographer, has been said to have accepted an invitation to come to Portugal to make maps for the infante. This last incident probably accounts for the legend of the School of Sagres, which is now discredited.\n\nThe first contacts with the African slave market were made by expeditions to ransom Portuguese subjects enslaved by pirate attacks on Portuguese ships or villages. As Sir Peter Russell remarks in his biography, \"In Henryspeak, conversion and enslavement were interchangeable terms.\"\n\nHenry sponsored voyages, collecting a 20% tax (\"o quinto\") on the profits made by naval expeditions, which was the usual practice in the Iberian states of that time. The nearby port of Lagos provided a convenient harbor from which these expeditions left. The voyages were made in very small ships, mostly the caravel, a light and maneuverable vessel. The caravel used the lateen sail, the prevailing rig in Christian Mediterranean navigation since late antiquity. Most of the voyages sent out by Henry consisted of one or two ships that navigated by following the coast, stopping at night to tie up along some shore.\n\nDuring Prince Henry's time and after, the Portuguese navigators discovered and perfected the North Atlantic \"Volta do Mar\" (the \"turn of the sea\" or \"return from the sea\"): the dependable pattern of trade winds blowing largely from the east near the equator and the returning westerlies in the mid-Atlantic. This was a major step in the history of navigation, when an understanding of oceanic wind patterns was crucial to Atlantic navigation, from Africa and the open ocean to Europe, and enabled the main route between the New World and Europe in the North Atlantic in future voyages of discovery. Although the lateen sail allowed sailing upwind to some extent, it was worth even major extensions of course to have a faster and calmer following wind for most of a journey. Portuguese mariners who sailed south and southwest towards the Canary Islands and West Africa would afterwards sail far to the northwest — that is, away from continental Portugal, and seemingly in the wrong direction—before turning northeast near the Azores islands and finally east to Europe in order to have largely following winds for their full journey. Christopher Columbus used this on his transatlantic voyages.\n\nThe first explorations followed not long after the capture of Ceuta in 1415. Henry was interested in locating the source of the caravans that brought gold to the city. During the reign of his father, John I, João Gonçalves Zarco and Tristão Vaz Teixeira were sent to explore along the African coast. Zarco, a knight in service to Prince Henry, had commanded the caravels guarding the coast of Algarve from the incursions of the Moors. He had also been at Ceuta.\n\nIn 1418, Zarco and Teixeira were blown off-course by a storm while making the \"volta do mar\" westward swing to return to Portugal. They found shelter at an island they named Porto Santo. Henry directed that Porto Santo be colonized. The move to claim the Madeiran islands was probably a response to Castile's efforts to claim the Canary Islands. In 1420, settlers then moved to the nearby island of Madeira.\n\nA chart drawn by the Catalan cartographer, Gabriel de Vallseca of Mallorca, has been interpreted to indicate that the Azores were first discovered by Diogo de Silves in 1427. In 1431, Gonçalo Velho was dispatched with orders to determine the location of \"islands\" first identified by de Silves. Velho apparently got a far as the Formigas, in the eastern archipelago, before having to return to Sagres, probably due to bad weather.\n\nBy this time the Portuguese navigators had also reached the Sargasso Sea (western North Atlantic region), naming it after the Sargassum seaweed growing there (\"sargaço\" / \"sargasso\" in Portuguese).\n\nUntil Henry's time, Cape Bojador remained the most southerly point known to Europeans on the desert coast of Africa. Superstitious seafarers held that beyond the cape lay sea monsters and the edge of the world. In 1434, Gil Eanes, the commander of one of Henry's expeditions, became the first European known to pass Cape Bojador.\n\nUsing the new ship type, the expeditions then pushed onwards. Nuno Tristão and Antão Gonçalves reached Cape Blanco in 1441. The Portuguese sighted the Bay of Arguin in 1443 and built an important fort there around the year 1448. Dinis Dias soon came across the Senegal River and rounded the peninsula of Cap-Vert in 1444. By this stage the explorers had passed the southern boundary of the desert, and from then on Henry had one of his wishes fulfilled: the Portuguese had circumvented the Muslim land-based trade routes across the western Sahara Desert, and slaves and gold began arriving in Portugal. This rerouting of trade devastated Algiers and Tunis, but made Portugal rich. By 1452, the influx of gold permitted the minting of Portugal's first gold \"cruzado\" coins. A cruzado was equal to 400 reis at the time. From 1444 to 1446, as many as forty vessels sailed from Lagos on Henry's behalf, and the first private mercantile expeditions began.\n\nAlvise Cadamosto explored the Atlantic coast of Africa and discovered several islands of the Cape Verde archipelago between 1455 and 1456. In his first voyage, which started on 22 March 1455, he visited the Madeira Islands and the Canary Islands. On the second voyage, in 1456, Cadamosto became the first European to reach the Cape Verde Islands. António Noli later claimed the credit. By 1462, the Portuguese had explored the coast of Africa as far as present-day Sierra Leone. Twenty-eight years later, Bartolomeu Dias proved that Africa could be circumnavigated when he reached the southern tip of the continent, now known as the Cape of Good Hope. In 1498, Vasco da Gama became the first European sailor to reach India by sea.\n\nNo one used the nickname \"Navigator\" to refer to prince Henry during his lifetime or in the following three centuries. The term was coined by two nineteenth-century German historians: Heinrich Schaefer and Gustave de Veer. Later on it was made popular by two British authors who included it in the titles of their biographies of the prince: Henry Major in 1868 and Raymond Beazley in 1895. In Portuguese, even in modern times, it is uncommon to call him by this epithet; the preferred use is \"Infante D. Henrique\".\n\n\n\n"}
{"id": "14094", "url": "https://en.wikipedia.org/wiki?curid=14094", "title": "Human cloning", "text": "Human cloning\n\nHuman cloning is the creation of a genetically identical copy (or clone) of a human. The term is generally used to refer to artificial human cloning, which is the reproduction of human cells and tissue. It does not refer to the natural conception and delivery of identical twins. The possibility of human cloning has raised controversies. These ethical concerns have prompted several nations to pass laws regarding human cloning and its legality.\n\nTwo commonly discussed types of theoretical human cloning are: \"therapeutic cloning\" and \"reproductive cloning\". Therapeutic cloning would involve cloning cells from a human for use in medicine and transplants, and is an active area of research, but is not in medical practice anywhere in the world, . Two common methods of therapeutic cloning that are being researched are somatic-cell nuclear transfer and, more recently, pluripotent stem cell induction. Reproductive cloning would involve making an entire cloned human, instead of just specific cells or tissues.\n\nAlthough the possibility of cloning humans had been the subject of speculation for much of the 20th century, scientists and policy makers began to take the prospect seriously in the mid-1960s.\n\nNobel Prize-winning geneticist Joshua Lederberg advocated cloning and genetic engineering in an article in The American Naturalist in 1966 and again, the following year, in The Washington Post. He sparked a debate with conservative bioethicist Leon Kass, who wrote at the time that \"the programmed reproduction of man will, in fact, dehumanize him.\" Another Nobel Laureate, James D. Watson, publicized the potential and the perils of cloning in his Atlantic Monthly essay, \"Moving Toward the Clonal Man\", in 1971.\n\nWith the cloning of a sheep known as Dolly in 1996 by somatic cell nuclear transfer (SCNT), the idea of human cloning became a hot debate topic. Many nations outlawed it, while a few scientists promised to make a clone within the next few years. The first hybrid human clone was created in November 1998, by Advanced Cell Technology. It was created using SCNT - a nucleus was taken from a man's leg cell and inserted into a cow's egg from which the nucleus had been removed, and the hybrid cell was cultured, and developed into an embryo. The embryo was destroyed after 12 days.\n\nIn 2004 and 2005, Hwang Woo-suk, a professor at Seoul National University, published two separate articles in the journal \"Science\" claiming to have successfully harvested pluripotent, embryonic stem cells from a cloned human blastocyst using somatic-cell nuclear transfer techniques. Hwang claimed to have created eleven different patent-specific stem cell lines. This would have been the first major breakthrough in human cloning. However, in 2006 \"Science\" retracted both of his articles on clear evidence that much of his data from the experiments was fabricated.\n\nIn January 2008, Dr. Andrew French and Samuel Wood of the biotechnology company Stemagen announced that they successfully created the first five mature human embryos using SCNT. In this case, each embryo was created by taking a nucleus from a skin cell (donated by Wood and a colleague) and inserting it into a human egg from which the nucleus had been removed. The embryos were developed only to the blastocyst stage, at which point they were studied in processes that destroyed them. Members of the lab said that their next set of experiments would aim to generate embryonic stem cell lines; these are the \"holy grail\" that would be useful for therapeutic or reproductive cloning.\n\nIn 2011, scientists at the New York Stem Cell Foundation announced that they had succeeded in generating embryonic stem cell lines, but their process involved leaving the oocyte's nucleus in place, resulting in triploid cells, which would not be useful for cloning.\n\nIn 2013, a group of scientists led by Shoukhrat Mitalipov published the first report of embryonic stem cells created using SCNT. In this experiment, the researchers developed a protocol for using SCNT in human cells, which differs slightly from the one used in other organisms. Four embryonic stem cell lines from human fetal somatic cells were derived from those blastocysts. All four lines were derived using oocytes from the same donor, ensuring that all mitochondrial DNA inherited was identical. A year later, a team led by Robert Lanza at Advanced Cell Technology reported that they had replicated Mitalipov's results and further demonstrated the effectiveness by cloning adult cells using SCNT.\n\nIn 2018, the first successful cloning of primates using somatic cell nuclear transfer, the same method as \"Dolly\" the sheep, with the birth of two live female clones (crab-eating macaques named \"Zhong Zhong\" and \"Hua Hua\") was reported.\n\nIn somatic cell nuclear transfer (\"SCNT\"), the nucleus of a somatic cell is taken from a donor and transplanted into a host egg cell, which had its own genetic material removed previously, making it an enucleated egg. After the donor somatic cell genetic material is transferred into the host oocyte with a micropipette, the somatic cell genetic material is fused with the egg using an electric current. Once the two cells have fused, the new cell can be permitted to grow in a surrogate or artificially. This is the process that was used to successfully clone Dolly the sheep (see section on History in this article).\n\nCreating induced pluripotent stem cells (\"iPSCs\") is a long and inefficient process. Pluripotency refers to a stem cell that has the potential to differentiate into any of the three germ layers: endoderm (interior stomach lining, gastrointestinal tract, the lungs), mesoderm (muscle, bone, blood, urogenital), or ectoderm (epidermal tissues and nervous tissue). A specific set of genes, often called \"reprogramming factors\", are introduced into a specific adult cell type. These factors send signals in the mature cell that cause the cell to become a pluripotent stem cell. This process is highly studied and new techniques are being discovered frequently on how to better this induction process.\n\nDepending on the method used, reprogramming of adult cells into iPSCs for implantation could have severe limitations in humans. If a virus is used as a reprogramming factor for the cell, cancer-causing genes called oncogenes may be activated. These cells would appear as rapidly dividing cancer cells that do not respond to the body's natural cell signaling process. However, in 2008 scientists discovered a technique that could remove the presence of these oncogenes after pluripotency induction, thereby increasing the potential use of iPSC in humans.\n\nBoth the processes of SCNT and iPSCs have benefits and deficiencies. Historically, reprogramming methods were better studied than SCNT derived embryonic stem cells (ESCs). However, more recent studies have put more emphasis on developing new procedures for SCNT-ESCs. The major advantage of SCNT over iPSCs at this time is the speed with which cells can be produced. iPSCs derivation takes several months while SCNT would take a much shorter time, which could be important for medical applications. New studies are working to improve the process of iPSC in terms of both speed and efficiency with the discovery of new reprogramming factors in oocytes. Another advantage SCNT could have over iPSCs is its potential to treat mitochondrial disease, as it utilizes a donor oocyte. No other advantages are known at this time in using stem cells derived from one method over stem cells derived from the other.\n\nWork on cloning techniques has advanced our basic understanding of developmental biology in humans. Observing human pluripotent stem cells grown in culture provides great insight into human embryo development, which otherwise cannot be seen. Scientists are now able to better define steps of early human development. Studying signal transduction along with genetic manipulation within the early human embryo has the potential to provide answers to many developmental diseases and defects. Many human-specific signaling pathways have been discovered by studying human embryonic stem cells. Studying developmental pathways in humans has given developmental biologists more evidence toward the hypothesis that developmental pathways are conserved throughout species.\n\niPSCs and cells created by SCNT are useful for research into the causes of disease, and as model systems used in drug discovery.\n\nCells produced with SCNT, or iPSCs could eventually be used in stem cell therapy, or to create organs to be used in transplantation, known as regenerative medicine. Stem cell therapy is the use of stem cells to treat or prevent a disease or condition. Bone marrow transplantation is a widely used form of stem cell therapy. No other forms of stem cell therapy are in clinical use at this time. Research is underway to potentially use stem cell therapy to treat heart disease, diabetes, and spinal cord injuries. Regenerative medicine is not in clinical practice, but is heavily researched for its potential uses. This type of medicine would allow for autologous transplantation, thus removing the risk of organ transplant rejection by the recipient. For instance, a person with liver disease could potentially have a new liver grown using their same genetic material and transplanted to remove the damaged liver. In current research, human pluripotent stem cells have been promised as a reliable source for generating human neurons, showing the potential for regenerative medicine in brain and neural injuries.\n\nIn bioethics, the ethics of cloning refers to a variety of ethical positions regarding the practice and possibilities of cloning, especially human cloning. While many of these views are religious in origin, the questions raised by cloning are faced by secular perspectives as well. Human therapeutic and reproductive cloning are not commercially used; animals are currently cloned in laboratories and in livestock production.\n\nAdvocates support development of therapeutic cloning in order to generate tissues and whole organs to treat patients who otherwise cannot obtain transplants, to avoid the need for immunosuppressive drugs, and to stave off the effects of aging. Advocates for reproductive cloning believe that parents who cannot otherwise procreate should have access to the technology.\n\nOpposition to therapeutic cloning mainly centers around the status of embryonic stem cells, which has connections with the abortion debate.\n\nSome opponents of reproductive cloning have concerns that technology is not yet developed enough to be safe - for example, the position of the American Association for the Advancement of Science , while others emphasize that reproductive cloning could be prone to abuse (leading to the generation of humans whose organs and tissues would be harvested), and have concerns about how cloned individuals could integrate with families and with society at large.\n\nReligious groups are divided, with some opposing the technology as usurping God's role in creation and, to the extent embryos are used, destroying a human life; others support therapeutic cloning's potential life-saving benefits.\n\nIn 2015 it was reported that about 70 countries had banned human cloning.\n\nHuman cloning is banned by the Presidential Decree 200/97 of 7 March 1997.\n\nAustralia has prohibited human cloning, though , a bill legalizing therapeutic cloning and the creation of human embryos for stem cell research passed the House of Representatives. Within certain regulatory limits, and subject to the effect of state legislation, therapeutic cloning is now legal in some parts of Australia.\n\nCanadian law prohibits the following: cloning humans, cloning stem cells, growing human embryos for research purposes, and buying or selling of embryos, sperm, eggs or other human reproductive material. It also bans making changes to human DNA that would pass from one generation to the next, including use of animal DNA in humans. Surrogate mothers are legally allowed, as is donation of sperm or eggs for reproductive purposes. Human embryos and stem cells are also permitted to be donated for research.\n\nThere have been consistent calls in Canada to ban human reproductive cloning since the 1993 Report of the Royal Commission on New Reproductive Technologies. Polls have indicated that an overwhelming majority of Canadians oppose human reproductive cloning, though the regulation of human cloning continues to be a significant national and international policy issue. The notion of \"human dignity\" is commonly used to justify cloning laws. The basis for this justification is that reproductive human cloning necessarily infringes notions of human dignity.\n\nHuman cloning is prohibited in Article 133 of the Colombian Penal Code.\n\nThe European Convention on Human Rights and Biomedicine prohibits human cloning in one of its additional protocols, but this protocol has been ratified only by Greece, Spain and Portugal. The Charter of Fundamental Rights of the European Union explicitly prohibits reproductive human cloning. The charter is legally binding for the institutions of the European Union under the Treaty of Lisbon and for member states of the Union implementing EU law.\n\nIndia does not have specific law regarding cloning but has guidelines prohibiting whole human cloning or reproductive cloning. India allows therapeutic cloning and the use of embryonic stem cells for research proposes.\n\nThe Federal Assembly of Russia introduced the Federal Law N 54-FZ \"On the temporary ban on human cloning\" in April 19, 2002. On May 20, 2002 President Vladimir Putin signed this moratorium on the implementation of human cloning. On March 29, 2010 The Federal Assembly introduced second revision of this law without time limit.\n\nHuman cloning is explicitly prohibited in Article 24, \"Right to Life\" of the 2006 Constitution of Serbia.\n\nIn terms of section 39A of the Human Tissue Act 65 of 1983, genetic manipulation of gametes or zygotes outside the human body is absolutely prohibited. A zygote is the cell resulting from the fusion of two gametes; thus the fertilised ovum. Section 39A thus prohibits human cloning.\n\nOn January 14, 2001 the British government passed The Human Fertilisation and Embryology (Research Purposes) Regulations 2001 to amend the Human Fertilisation and Embryology Act 1990 by extending allowable reasons for embryo research to permit research around stem cells and cell nuclear replacement, thus allowing therapeutic cloning. However, on November 15, 2001, a pro-life group won a High Court legal challenge, which struck down the regulation and effectively left all forms of cloning unregulated in the UK. Their hope was that Parliament would fill this gap by passing prohibitive legislation. Parliament was quick to pass the Human Reproductive Cloning Act 2001 which explicitly prohibited reproductive cloning. The remaining gap with regard to therapeutic cloning was closed when the appeals courts reversed the previous decision of the High Court.\n\nThe first license was granted on August 11, 2004 to researchers at the University of Newcastle to allow them to investigate treatments for diabetes, Parkinson's disease and Alzheimer's disease. The Human Fertilisation and Embryology Act 2008, a major review of fertility legislation, repealed the 2001 Cloning Act by making amendments of similar effect to the 1990 Act. The 2008 Act also allows experiments on hybrid human-animal embryos.\n\nOn December 13, 2001, the United Nations General Assembly began elaborating an international convention against the reproductive cloning of humans. A broad coalition of States, including Spain, Italy, the Philippines, the United States, Costa Rica and the Holy See sought to extend the debate to ban all forms of human cloning, noting that, in their view, therapeutic human cloning violates human dignity. Costa Rica proposed the adoption of an international convention to ban all forms of human cloning. Unable to reach a consensus on a binding convention, in March 2005 a non-binding United Nations Declaration on Human Cloning, calling for the ban of all forms of human cloning contrary to human dignity, was adopted.\n\nThe Patients First Act of 2017 (HR 2918, 115th Congress) aims to promote stem cell research, using cells that are “ethically obtained”, that could contribute to a better understanding of diseases and therapies, and promote the “derivation of pluripotent stem cell lines without the creation of human embryos…”.\n\nIn 1998, 2001, 2004, 2005, 2007 and 2009, the US Congress voted whether to ban all human cloning, both reproductive and therapeutic (see Stem Cell Research Enhancement Act). Each time, divisions in the Senate, or an eventual veto from the sitting President (President George W. Bush in 2005 and 2007), over therapeutic cloning prevented either competing proposal (a ban on both forms or on reproductive cloning only) from being passed into law. On March 10, 2010 a bill (HR 4808) was introduced with a section banning federal funding for human cloning. Such a law, if passed, would not have prevented research from occurring in private institutions (such as universities) that have both private and federal funding. However, the 2010 law was not passed.\n\nThere are currently no federal laws in the United States which ban cloning completely. Fifteen American states (Arkansas, California, Connecticut, Iowa, Indiana, Massachusetts, Maryland, Michigan, North Dakota, New Jersey, Rhode Island, South Dakota, Florida, Georgia, and Virginia) ban reproductive cloning and three states (Arizona, Maryland, and Missouri) prohibit use of public funds for such activities.\n\nScience fiction has used cloning, most commonly and specifically human cloning, due to the fact that it brings up controversial questions of identity. Humorous fiction, such as \"Multiplicity\" (1996) and the Maxwell Smart feature \"The Nude Bomb\" (1980), have featured human cloning. A recurring sub-theme of cloning fiction is the use of clones as a supply of organs for transplantation. Robin Cook's 1997 novel \"Chromosome 6\" and Michael Bay's \"The Island\" are examples of this; \"Chromosome 6\" also features genetic manipulation and xenotransplantation. There is also a series named Orphan Black which follows human clones' stories and experiences as they deal with issues and react to being the property of a chain of scientific institutions.\n\n\n"}
{"id": "14097", "url": "https://en.wikipedia.org/wiki?curid=14097", "title": "History of Asia", "text": "History of Asia\n\nThe history of Asia can be seen as the collective history of several distinct peripheral coastal regions such as, East Asia, South Asia, and the Middle East linked by the interior mass of the Eurasian steppe.\n\nThe coastal periphery was the home to some of the world's earliest known civilizations, with each of the three regions developing early civilizations around fertile river valleys. These valleys were fertile because the soil there was rich and could bear many root crops. The civilizations in Mesopotamia, India, and China shared many similarities and likely exchanged technologies and ideas such as mathematics and the wheel. Other notions such as that of writing likely developed individually in each area. Cities, states and then empires developed in these lowlands.\n\nThe steppe region had long been inhabited by mounted nomads, and from the central steppes they could reach all areas of the Asian continent. The northern part of the continent, covering much of Siberia was also inaccessible to the steppe nomads due to the dense forests and the tundra. These areas in Siberia were very sparsely populated.\n\nThe centre and periphery were kept separate by mountains and deserts. The Caucasus, Himalaya, Karakum Desert, and Gobi Desert formed barriers that the steppe horsemen could only cross with difficulty. While technologically and culturally the city dwellers were more advanced, they could do little militarily to defend against the mounted hordes of the steppe. However, the lowlands did not have enough open grasslands to support a large horsebound force. Thus the nomads who conquered states in the Middle East were soon forced to adapt to the local societies.\n\nAsia's history would feature major developments seen in other parts of the world, as well as events that would affect those other regions. These include the trade of the Silk Road, which spread cultures, languages, religion, and disease throughout Afro-Eurasian trade. Another major advancement was the innovation of gunpowder in medieval China, which led to advanced warfare through the use of guns.\n\nA report by archaeologist Rakesh Tewari on Lahuradewa, India shows new C14 datings that range between 9000 and 8000 BCE associated with rice, making Lahuradewa the earliest Neolithic site in entire South Asia.\n\nThe prehistoric Beifudi site near Yixian in Hebei Province, China, contains relics of a culture contemporaneous with the Cishan and Xinglongwa cultures of about 8000–7000 BCE, neolithic cultures east of the Taihang Mountains, filling in an archaeological gap between the two Northern Chinese cultures. The total excavated area is more than 1,200 square meters and the collection of neolithic findings at the site consists of two phases.\n\nAround 5500 BCE the Halafian culture appeared in Lebanon, Israel, Syria, Anatolia, and northern Mesopotamia, based upon dryland agriculture.\n\nIn southern Mesopotamia were the alluvial plains of Sumer and Elam. Since there was little rainfall, irrigation systems were necessary. The Ubaid culture flourished from 5500 BCE.\n\nThe Chalcolithic period (or Copper Age) began about 4500 BCE, then the Bronze Age began about 3500 BCE, replacing the Neolithic cultures.\n\nThe Indus Valley Civilization (IVC) was a Bronze Age civilization (3300–1300 BCE; mature period 2600–1900 BCE) which was centered mostly in the western part of the Indian Subcontinent; it is considered that an early form of Hinduism was performed during this civilization. Some of the great cities of this civilization include Harappa and Mohenjo-daro, which had a high level of town planning and arts. The cause of the destruction of these regions around 1700 BCE is debatable, although evidence suggests it was caused by natural disasters (especially flooding). This era marks Vedic period in India, which lasted from roughly 1500 to 500 BCE. During this period, the Sanskrit language developed and the Vedas were written, epic hymns that told tales of gods and wars. This was the basis for the Vedic religion, which would eventually sophisticate and develop into Hinduism.\n\nChina and Vietnam were also centres of metalworking. Dating back to the Neolithic Age, the first bronze drums, called the Dong Son drums have been uncovered in and around the Red River Delta regions of Vietnam and Southern China. These relate to the prehistoric Dong Son Culture of Vietnam.\nSong Da bronze drum's surface, Dong Son culture, Vietnam\n\nIn Ban Chiang, Thailand (Southeast Asia), bronze artifacts have been discovered dating to 2100 BCE.\n\nIn Nyaunggan, Burma bronze tools have been excavated along with ceramics and stone artifacts. Dating is still currently broad (3500–500 BCE).\n\nThe Iron Age saw the widespread use of iron tools, weaponry, and armor throughout the major civilizations of Asia.\n\nThe Achaemenid dynasty of the Persian Empire, founded by Cyrus the Great, ruled an area from Greece and Turkey to the Indus River and Central Asia during the 6th to 4th centuries BCE. Persian politics included a tolerance for other cultures, a highly centralized government, and significant infrastructure developments. Later, in Darius the Great's rule, the territories were integrated, a bureaucracy was developed, nobility were assigned military positions, tax collection was carefully organized, and spies were used to ensure the loyalty of regional officials. The primary religion of Persia at this time was Zoroastrianism, developed by the philosopher Zoroaster. It introduced an early form of monotheism to the area. The religion banned animal sacrifice and the use of intoxicants in rituals; and introduced the concept of spiritual salvation through personal moral action, an end time, and both general and Particular judgment with a heaven or hell. These concepts would heavily influence later emperors and the masses. More importantly, Zoroastrianism would be an important precursor for the Abrahamic religions such as Christianity, Islam, or Judaism. The Persian Empire was successful in establishing peace and stability throughout the Middle East and were a major influence in art, politics (affecting Hellenistic leaders), and religion.\n\nAlexander the Great conquered this dynasty in the 4th century BCE, creating the brief Hellenistic period. He was unable to establish stability and after his death, Persia broke into small, weak dynasties including the Seleucid Empire, followed by the Parthian Empire. By the end of the Classical age, Persia had been reconsolidated into the Sassanid Empire, also known as the second Persian Empire.\n\nThe Roman Empire would later control parts of Western Asia. The Seleucid, Parthian and Sassanid dynasties of Persia dominated Western Asia for centuries.\n\nThe Maurya and Gupta empires are called the Golden Age of India and were marked by extensive inventions and discoveries in science, technology, art, religion, and philosophy that crystallized the elements of what is generally known as Indian culture. The religions of Hinduism and Buddhism, which began in Indian sub-continent, were an important influence on South, East and Southeast Asia.\n\nBy 600 BCE, India had been divided into 17 regional states that would occasionally feud amongst themselves. In 327 BCE, Alexander the Great came to India with a vision of conquering the whole world. He crossed northwestern India and created the province Bactria but could not move further because his army wanted to go back to their family. Shortly prior, the soldier Chandragupta Maurya began to take control of the Ganges river and soon established the Maurya Empire. The Maurya Empire (Sanskrit: मौर्य राजवंश, Maurya Rājavanśha) was the geographically extensive and powerful empire in ancient India, ruled by the Mauryan dynasty from 321 to 185 BCE. It was one of the world's largest empires in its time, stretching to the Himalayas in the north, what is now Assam in the east, probably beyond modern Pakistan in the west, and annexing Balochistan and much of what is now Afghanistan, at its greatest extent. South of Mauryan empire was the Tamilakam an independent country dominated by three dynasties, the Pandyans, Cholas and Cheras. The government established by Chandragupta was led by an autocratic king, who primarily relied on the military to assert his power. It also applied the use of a bureaucracy and even sponsored a postal service. Chandragupta's grandson, Ashoka, greatly extended the empire by conquering most of modern-day India (save for the southern tip). He eventually converted to Buddhism, though, and began a peaceful life where he promoted the religion as well as humane methods throughout India. The Maurya Empire would disintegrate soon after Ashoka's death and was conquered by the Kushan invaders from the northwest, establishing the Kushan Empire. Their conversion to Buddhism caused the religion to be associated with foreigners and therefore a decline in its popularity occurred.\n\nThe Kushan Empire would fall apart by 220 CE, creating more political turmoil in India. Then in 320, the Gupta Empire (Sanskrit: गुप्त राजवंश, Gupta Rājavanśha) was established and covered much of the Indian Subcontinent. Founded by Maharaja Sri-Gupta, the dynasty was the model of a classical civilization. Gupta kings united the area primarily through negotiation of local leaders and families as well as strategical intermarriage. Their rule covered less land than the Maurya Empire, but established the greatest stability. In 535, the empire ended when India was overrun by the Huns.\n\nSince 1029 BCE, the Zhou Dynasty ( ), had existed in China and it would continue to until 258 BCE. The Zhou dynasty had been using a feudal system by giving power to local nobility and relying on their loyalty in order to control its large territory. As a result, the Chinese government at this time tended to be very decentralized and weak, and there was often little the emperor could do to resolve national issues. Nonetheless, the government was able to retain its position with the creation of the Mandate of Heaven, which could establish an emperor as divinely chosen to rule. The Zhou additionally discouraged the human sacrifice of the preceding eras and unified the Chinese language. Finally, the Zhou government encouraged settlers to move into the Yangtze River valley, thus creating the Chinese Middle Kingdom.\n\nBut by 500 BCE, its political stability began to decline due to repeated nomadic incursions and internal conflict derived from the fighting princes and families. This was lessened by the many philosophical movements, starting with the life of Confucius. His philosophical writings (called Confucianism) concerning the respect of elders and of the state would later be popularly used in the Han Dynasty. Additionally, Laozi's concepts of Taoism, including yin and yang and the innate duality and balance of nature and the universe, became popular throughout this period. Nevertheless, the Zhou Dynasty eventually disintegrated as the local nobles began to gain more power and their conflict devolved into the Warring States period, from 402 to 201 BCE.\n\nOne leader eventually came on top, Qin Shi Huang (, \"Shǐ Huángdì\"), who overthrew the last Zhou emperor and established the Qin dynasty. The Qin Dynasty (Chinese: 秦朝; pinyin: Qín Cháo) was the first ruling dynasty of Imperial China, lasting from 221 to 207 BCE. The new Emperor abolished the feudal system and directly appointed a bureaucracy that would rely on him for power. Huang's imperial forces crushed any regional resistance, and they furthered the Chinese empire by expanding down to the South China Sea and northern Vietnam. Greater organization brought a uniform tax system, a national census, regulated road building (and cart width), standard measurements, standard coinage, and an official written and spoken language. Further reforms included new irrigation projects, the encouragement of silk manufacturing, and (most famously) the beginning of the construction of the Great Wall of China—designed to keep out the nomadic raiders who'd constantly badger the Chinese people. However, Shi Huang was infamous for his tyranny, forcing laborers to build the Wall, ordering heavy taxes, and severely punishing all who opposed him. He oppressed Confucians and promoted Legalism, the idea that people were inherently evil, and that a strong, forceful government was needed to control them. Legalism was infused with realistic, logical views and rejected the pleasures of educated conversation as frivolous. All of this made Shi Huang extremely unpopular with the people. As the Qin began to weaken, various factions began to fight for control of China.\n\nThe Han Dynasty (simplified Chinese: 汉朝; traditional Chinese: 漢朝; pinyin: Hàn Cháo; 206 BCE – 220 CE) was the second imperial dynasty of China, preceded by the Qin Dynasty and succeeded by the Three Kingdoms (220–265 CE). Spanning over four centuries, the period of the Han Dynasty is considered a golden age in Chinese history. One of the Han Dynasty's greatest emperors, Emperor Wu of Han, established a peace throughout China comparable to the Pax Romana seen in the Mediterranean a hundred years later. To this day, China's majority ethnic group refers to itself as the \"Han people\". The Han Dynasty was established when two peasants succeeded in rising up against Shi Huang's significantly weaker successor-son. The new Han government retained the centralization and bureaucracy of the Qin, but greatly reduced the repression seen before. They expanded their territory into Korea, Vietnam, and Central Asia, creating an even larger empire than the Qin.\n\nThe Han developed contacts with the Persian Empire in the Middle East and the Romans, through the Silk Road, with which they were able to trade many commodities—primarily silk. Many ancient civilizations were influenced by the Silk Road, which connected China, India, the Middle East and Europe. Han emperors like Wu also promoted Confucianism as the national \"religion\" (although it is debated by theologians as to whether it is defined as such or as a philosophy). Shrines devoted to Confucius were built and Confucian philosophy was taught to all scholars who entered the Chinese bureaucracy. The bureaucracy was further improved with the introduction of an examination system that selected scholars of high merit. These bureaucrats were often upper-class people educated in special schools, but whose power was often checked by the lower-class brought into the bureaucracy through their skill. The Chinese imperial bureaucracy was very effective and highly respected by all in the realm and would last over 2,000 years. The Han government was highly organized and it commanded the military, judicial law (which used a system of courts and strict laws), agricultural production, the economy, and the general lives of its people. The government also promoted intellectual philosophy, scientific research, and detailed historical records.\n\nHowever, despite all of this impressive stability, central power began to lose control by the turn of the Common Era. As the Han Dynasty declined, many factors continued to pummel it into submission until China was left in a state of chaos. By 100 CE, philosophical activity slowed, and corruption ran rampant in the bureaucracy. Local landlords began to take control as the scholars neglected their duties, and this resulted in heavy taxation of the peasantry. Taoists began to gain significant ground and protested the decline. They started to proclaim magical powers and promised to save China with them; the Taoist Yellow Turban Rebellion in 184 (led by rebels in yellow scarves) failed but was able to weaken the government. The aforementioned Huns combined with diseases killed up to half of the population and officially ended the Han Dynasty by 220. The ensuing period of chaos was so terrible it lasted for three centuries, where many weak regional rulers and dynasties failed to establish order in China. This period of chaos and attempts at order is commonly known as that of the Six Dynasties. The first part of this included the Three Kingdoms which started in 220 and describes the brief and weak successor \"dynasties\" that followed the Han. In 265, the Jin dynasty of China was started and this soon split into two different empires in control of northwestern and southeastern China. In 420, the conquest and abdication of those two dynasties resulted in the first of the Southern and Northern Dynasties. The Northern and Southern Dynasties passed through until finally, by 557, the Northern Zhou Dynasty ruled the north and the Chen Dynasty ruled the south.\n\nDuring this period, the Eastern world empires continued to expand through trade, migration and conquests of neighboring areas. Gunpowder was widely used as early as the 11th century and they were using moveable type printing five hundred years before Gutenberg created his press. Buddhism, Taoism, Confucianism were the dominant philosophies of the Far East during the Middle Ages. Marco Polo was not the first Westerner to travel to the Orient and return with amazing stories of this different culture, but his accounts published in the late 13th and early 14th centuries were the first to be widely read throughout Europe.\n\nThe Arabian peninsula and the surrounding Middle East and Near East regions saw dramatic change during the Medieval era caused primarily by the spread of Islam and the establishment of the Arabian Empires.\n\nIn the 5th century, the Middle East was separated into small, weak states; the two most prominent were the Sasanian Empire of the Persians in what is now Iran and Iraq, and the Byzantine Empire in Anatolia (modern-day Turkey). The Byzantines and Sasanians fought with each other continually, a reflection of the rivalry between the Roman Empire and the Persian Empire seen during the previous five hundred years. The fighting weakened both states, leaving the stage open to a new power. Meanwhile, the nomadic Bedouin tribes who dominated the Arabian desert saw a period of tribal stability, greater trade networking and a familiarity with Abrahamic religions or monotheism.\n\nWhile the Byzantine Roman and Sassanid Persian empires were both weakened by the Byzantine–Sasanian War of 602–628, a new power in the form of Islam grew in the Middle East under Muhammad in Medina. In a series of rapid Muslim conquests, the Rashidun army, led by the Caliphs and skilled military commanders such as Khalid ibn al-Walid, swept through most of the Middle East, taking more than half of Byzantine territory in the Arab–Byzantine wars and completely engulfing Persia in the Muslim conquest of Persia. It would be the Arab Caliphates of the Middle Ages that would first unify the entire Middle East as a distinct region and create the dominant ethnic identity that persists today. These Caliphates included the Rashidun Caliphate, Umayyad Caliphate, Abbasid Caliphate, and later the Seljuq Empire.\n\nAfter Muhammad introduced Islam, it jump-started Middle Eastern culture into an Islamic Golden Age, inspiring achievements in architecture, the revival of old advances in science and technology, and the formation of a distinct way of life. Muslims saved and spread Greek advances in medicine, algebra, geometry, astronomy, anatomy, and ethics that would later finds it way back to Western Europe.\n\nThe dominance of the Arabs came to a sudden end in the mid-11th century with the arrival of the Seljuq Turks, migrating south from the Turkic homelands in Central Asia. They conquered Persia, Iraq (capturing Baghdad in 1055), Syria, Palestine, and the Hejaz. This was followed by a series of Christian Western Europe invasions. The fragmentation of the Middle East allowed joined forces, mainly from England, France, and the emerging Holy Roman Empire, to enter the region. In 1099 the knights of the First Crusade captured Jerusalem and founded the Kingdom of Jerusalem, which survived until 1187, when Saladin retook the city. Smaller crusader fiefdoms survived until 1291. In the early 13th century, a new wave of invaders, the armies of the Mongol Empire, swept through the region, sacking Baghdad in the Siege of Baghdad (1258) and advancing as far south as the border of Egypt in what became known as the Mongol conquests. The Mongols eventually retreated in 1335, but the chaos that ensued throughout the empire deposed the Seljuq Turks. In 1401, the region was further plagued by the Turko-Mongol, Timur, and his ferocious raids. By then, another group of Turks had arisen as well, the Ottomans.\n\nThe Mongol Empire conquered a large part of Asia in the 13th century, an area extending from China to Europe. Medieval Asia was the kingdom of the Khans. Never before had any person controlled as much land as Genghis Khan. He built his power unifying separate Mongol tribes before expanding his kingdom south and west. He and his grandson, Kublai Khan, controlled lands in China, Burma, Central Asia, Russia, Iran, the Middle East, and Eastern Europe. Estimates are that the Mongol armies reduced the population of China by nearly a third. Genghis Khan was a pagan who tolerated nearly every religion, and their culture often suffered the harshest treatment from Mongol armies. The Khan armies pushed as far west as Jerusalem before being defeated in 1260.\n\nThe Indian early medieval age, 600 to 1200, is defined by regional kingdoms and cultural diversity. When Harsha of Kannauj, who ruled much of the Indo-Gangetic Plain from 606 to 647, attempted to expand southwards, he was defeated by the Chalukya ruler of the Deccan. When his successor attempted to expand eastwards, he was defeated by the Pala king of Bengal. When the Chalukyas attempted to expand southwards, they were defeated by the Pallavas from farther south, who in turn were opposed by the Pandyas and the Cholas from still farther south. The Cholas could under the rule of Raja Raja Chola defeat their rivals and rise to a regional power. Cholas expanded northward and defeated Eastern Chalukya, Kalinga and the Pala. Under Rajendra Chola the Cholas created the first notable navy of Indian subcontinent. The Chola navy extended the influence of Chola empire to southeast asia. During this time, pastoral peoples whose land had been cleared to make way for the growing agricultural economy were accommodated within caste society, as were new non-traditional ruling classes.\n\nThe Muslim conquest in the Indian subcontinent mainly took place from the 12th century onwards, though earlier Muslim conquests made limited inroads into the region, beginning during the period of the ascendancy of the Rajput Kingdoms in North India, although Sindh and Multan were captured in 8th century.\n\nChina saw the rise and fall of the Sui, Tang, Song, and Yuan dynasties and therefore improvements in its bureaucracy, the spread of Buddhism, and the advent of Neo-Confucianism. It was an unsurpassed era for Chinese ceramics and painting. Medieval architectural masterpieces the Great South Gate in Todaiji, Japan, and the Tien-ning Temple in Peking, China are some of the surviving constructs from this era.\n\nA new powerful dynasty began to rise in the 580s, amongst the divided factions of China. This was started when an aristocrat named Yang Jian married his daughter into the Northern Zhou Dynasty. He proclaimed himself Emperor Wen of Sui and appeased the nomadic military by abandoning the Confucian scholar-gentry. Emperor Wen soon led the conquest of the southern Chen Dynasty and united China once more under the Sui Dynasty. The emperor lowered taxes and constructed granaries that he used to prevent famine and control the market. Later Wen's son would murder him for the throne and declare himself Emperor Yang of Sui. Emperor Yang revived the Confucian scholars and the bureaucracy, much to anger of the aristocrats and nomadic military leaders. Yang became an excessive leader who overused China's resources for personal luxury and perpetuated exhaustive attempts to reconquer Korea. His military failures and neglect of the empire forced his own ministers to assassinate him in 618, ending the Sui Dynasty.\n\nFortunately, one of Yang's most respectable advisors, Li Yuan, was able to claim the throne quickly, preventing a chaotic collapse. He proclaimed himself Emperor Gaozu, and established the Tang dynasty in 623. The Tang saw expansion of China through conquest to Tibet in the west, Vietnam in the south, and Manchuria in the north. Tang emperors also improved the education of scholars in the Chinese bureaucracy. A Ministry of Rites was established and the examination system was improved to better qualify scholars for their jobs. In addition, Buddhism became popular in China with two different strains between the peasantry and the elite, the Pure Land and Zen strains, respectively. Greatly supporting the spread of Buddhism was Empress Wu, who additionally claimed an unofficial \"Zhou Dynasty\" and displayed China's tolerance of a woman ruler, which was rare at the time. However, Buddhism would also experience some backlash, especially from Confucianists and Taoists. This would usually involve criticism about how it was costing the state money, since the government was unable to tax Buddhist monasteries, and additionally sent many grants and gifts to them.\n\nThe Tang dynasty began to decline under the rule of Emperor Xuanzong, who began to neglect the economy and military and caused unrest amongst the court officials due to the excessive influence of his concubine, Yang Guifei, and her family. This eventually sparked a revolt in 755. Although the revolt failed, subduing it required involvement with the unruly nomadic tribes outside of China and distributing more power to local leaders—leaving the government and economy in a degraded state. The Tang dynasty officially ended in 907 and various factions led by the aforementioned nomadic tribes and local leaders would fight for control of China in the Five Dynasties and Ten Kingdoms period.\n\nBy 960, most of China proper had been reunited under the Song dynasty, although it lost territories in the north and could not defeat one of the nomadic tribes there—the Liao dynasty of the highly sinicized Khitan people. From then on, the Song would have to pay tribute to avoid invasion and thus set the precedent for other nomadic kingdoms to oppress them. The Song also saw the revival of Confucianism in the form of Neo-Confucianism. This had the effect of putting the Confucian scholars at a higher status than aristocrats or Buddhists and also intensified the reduction of power in women. The infamous practice of foot binding developed in this period as a result. Eventually the Liao dynasty in the north was overthrown by the Jin dynasty of the Manchu-related Jurchen people. The new Jin kingdom invaded northern China, leaving the Song to flee farther south and creating the Southern Song dynasty in 1126. There, cultural life flourished.\n\nBy 1227, the Mongols had conquered the Western Xia kingdom northwest of China. Soon the Mongols incurred upon the Jin empire of the Jurchens. Chinese cities were soon besieged by the Mongol hordes that showed little mercy for those who resisted and the Southern Song Chinese were quickly losing territory. In 1271 the current great khan, Kublai Khan, claimed himself Emperor of China and officially established the Yuan Dynasty. By 1290, all of China was under control of the Mongols, marking the first time they were ever completely conquered by a foreign invader; the new capital was established at Khanbaliq (modern-day Beijing). Kublai Khan segregated Mongol culture from Chinese culture by discouraging interactions between the two peoples, separating living spaces and places of worship, and reserving top administrative positions to Mongols, thus preventing Confucian scholars to continue the bureaucratic system. Nevertheless, Kublai remained fascinated with Chinese thinking, surrounding himself with Chinese Buddhist, Taoist, or Confucian advisors.\n\nMongol women displayed a contrasting independent nature compared to the Chinese women who continued to be suppressed. Mongol women often rode out on hunts or even to war. Kublai's wife, Chabi, was a perfect example of this; Chabi advised her husband on several political and diplomatic matters; she convinced him that the Chinese were to be respected and well-treated in order to make them easier to rule. However this was not enough to affect Chinese women's position, and the increasingly Neo-Confucian successors of Kublai further repressed Chinese and even Mongol women.\n\nThe Black Death, which would later ravage Western Europe, had its beginnings in Asia, where it wiped out large populations in China in 1331.\n\nJapan's medieval history began with the Asuka period, from around 600 to 710. The time was characterized by the Taika Reform and imperial centralization, both of which were a direct result of growing Chinese contact and influences. In 603, Prince Shōtoku of the Yamato dynasty began significant political and cultural changes. He issued the Seventeen-article constitution in 604, centralizing power towards the emperor (under the title \"tenno\", or heavenly sovereign) and removing the power to levy taxes from provincial lords. Shōtoku was also a patron of Buddhism and he encouraged building temples competitively.\n\nShōtoku's reforms transitioned Japan to the Nara period (c. 710 to c. 794), with the moving of the Japanese capital to Nara in Honshu. This period saw the culmination of Chinese-style writing, etiquette, and architecture in Japan along with Confucian ideals to supplement the already present Buddhism. Peasants revered both Confucian scholars and Buddhist monks. However, Buddhism gained the status of state religion, and the government ordered the construction of Buddhist temples, monasteries, and statues. The lavish spending combined with the fact that many aristocrats did not pay taxes, put a heavy burden on peasantry that caused poverty and famine. Eventually the Buddhist position got out of control, threatening to seize imperial power and causing Emperor Kanmu to move the capital to Heian-kyō to avoid a Buddhist takeover. This marked the beginning of the Heian period and the end of Taika reform.\n\nWith the Heian period (from 794 to 1185) came a decline of imperial power. Chinese influence also declined, as a result of its correlation with imperial centralization and the heavenly mandate, which came to be regarded as ineffective. By 838, the Japanese court discontinued its embassies in China; only traders and Buddhist monks continued to travel to China. Buddhism itself came to be considered more Japanese than Chinese, and persisted to be popular in Japan. Buddhists monks and monasteries continued their attempts to gather personal power in courts, along with aristocrats. One particular noble family that dominated influence in the imperial bureaucracy was the Fujiwara clan. During this time cultural life in the imperial court flourished. There was a focus on beauty and social interaction and writing and literature was considered refined. Noblewomen were cultured the same as noblemen, dabbling in creative works and politics. A prime example of both Japanese literature and women's role in high-class culture at this time was \"The Tale of Genji\", written by the lady-in-waiting Murasaki Shikibu. Popularization of wooden palaces and shōji sliding doors amongst the nobility also occurred.\n\nLoss of imperial power also led to the rise of provincial warrior elites. Small lords began to function independently. They administered laws, supervised public works projects, and collected revenue for themselves instead of the imperial court. Regional lords also began to build their own armies. These warriors were loyal only their local lords and not the emperor, although the imperial government increasingly called them in to protect the capital. The regional warrior class developed into the samurai, which created its own culture: including specialized weapons such as the katana and a form of chivalry, bushido. The imperial government's loss of control in the second half of the Heian period allowed banditry to grow, requiring both feudal lords and Buddhist monasteries to procure warriors for protection. As imperial control over Japan declined, feudal lords also became more independent and seceded from the empire. These feudal states squandered the peasants living in them, reducing the farmers to an almost serfdom status. Peasants were also rigidly restricted from rising to the samurai class, being physically set off by dress and weapon restrictions. As a result of their oppression, many peasants turned to Buddhism as a hope for reward in the afterlife for upright behavior.\n\nWith the increase of feudalism, families in the imperial court began to depend on alliances with regional lords. The Fujiwara clan declined from power, replaced by a rivalry between the Taira clan and the Minamoto clan. This rivalry grew into the Genpei War in the early 1180s. This war saw the use of both samurai and peasant soldiers. For the samurai, battle was ritual and they often easily cut down the poorly trained peasantry. The Minamoto clan proved successful due to their rural alliances. Once the Taira was destroyed, the Minamoto established a military government called the shogunate (or bakufu), centered in Kamakura.\n\nThe end of the Genpei War and the establishment of the Kamakura shogunate marked the end of the Heian period and the beginning of the Kamakura period in 1185, solidifying feudal Japan.\n\nKorea was fought between the three local kingdoms: Silla, Baekje, and Goguryeo. This continued until the Silla allied with Tang China to conquer all of Korea. Attempts at sinicization occurred.\n\nThe Russian Empire began to expand into Asia from the 17th century, and would eventually take control of all of Siberia and most of Central Asia by the end of the 19th century. The Ottoman Empire controlled Anatolia, the Middle East, North Africa and the Balkans from the 16th century onwards. In the 17th century, the Manchu conquered China and established the Qing Dynasty. In the 16th century, the Mughal Empire controlled much of India and initiated the second golden age for India. China was the largest economy in the world for much of the time, followed by India until the 18th century.\n\nBy 1368, Zhu Yuanzhang had claimed himself Hongwu Emperor and established the Ming Dynasty of China. Immediately, the new emperor and his followers drove the Mongols and their culture out of China and beyond the Great Wall. The new emperor was somewhat suspicious of the scholars that dominated China's bureaucracy, for he had been born a peasant and was uneducated. Nevertheless, Confucian scholars were necessary to China's bureaucracy and were reestablished as well as reforms that would improve the exam systems and make them more important in entering the bureaucracy than ever before. The exams became more rigorous, cut down harshly on cheating, and those who excelled were more highly appraised. Finally, Hongwu also directed more power towards the role of emperor so as to end the corrupt influences of the bureaucrats.\n\nThe Hongwu emperor, perhaps for his sympathy of the common-folk, had built many irrigation systems and other public projects that provided help for the peasant farmers. They were also allowed to cultivate and claim unoccupied land without having to pay any taxes and labor demands were lowered. However, none of this was able to stop the rising landlord class that gained many privileges from the government and slowly gained control of the peasantry. Moneylenders foreclosed on peasant debt in exchange for mortgages and bought up farmer land, forcing them to become the landlords' tenants or to wander elsewhere for work. Also during this time, Neo-Confucianism intensified even more than the previous two dynasties (the Song and Yuan). Focus on the superiority of elders over youth, men over women, and teachers over students resulted in minor discrimination of the \"inferior\" classes. The fine arts grew in the Ming era, with improved techniques in brush painting that depicted scenes of court, city or country life; people such as scholars or travelers; or the beauty of mountains, lakes, or marshes. The Chinese novel fully developed in this era, with such classics written such as \"Water Margin\", \"Journey to the West\", and \"Jin Ping Mei\".\n\nEconomics grew rapidly in the Ming Dynasty as well. The introduction of American crops such as maize, sweet potatoes, and peanuts allowed for cultivation of crops in infertile land and helped prevent famine. The population boom that began in the Song dynasty accelerated until China's population went from 80 or 90 million to 150 million in three centuries, culminating in 1600. This paralleled the market economy that was growing both internally and externally. Silk, tea, ceramics, and lacquer-ware were produced by artisans that traded them in Asia and to Europeans. Westerners began to trade (with some Chinese-assigned limits), primarily in the port-towns of Macau and Canton. Although merchants benefited greatly from this, land remained the primary symbol of wealth in China and traders' riches were often put into acquiring more land. Therefore, little of these riches were used in private enterprises that could've allowed for China to develop the market economy that often accompanied the highly-successful Western countries.\n\nIn the interest of national glory, the Chinese began sending impressive junk ships across the South China Sea and the Indian Ocean. From 1403 to 1433, the Yongle Emperor commissioned expeditions led by the admiral Zheng He, a Muslim eunuch from China. Chinese junks carrying hundreds of soldiers, goods, and animals for zoos, traveled to Southeast Asia, Persia, southern Arabia, and east Africa to show off Chinese power. Their prowess exceeded that of current Europeans at the time, and had these expeditions not ended, the world economy may be different from today. In 1433, the Chinese government decided that the cost of a navy was an unnecessary expense. The Chinese navy was slowly dismantled and focus on interior reform and military defense began. It was China's longstanding priority that they protect themselves from nomads and they have accordingly returned to it. The growing limits on the Chinese navy would leave them vulnerable to foreign invasion by sea later on.\n\nAs was inevitable, Westerners arrived on the Chinese east coast, primarily Jesuit missionaries which reached the mainland in 1582. They attempted to convert the Chinese people to Christianity by first converting the top of the social hierarchy and allowing the lower classes to subsequently convert. To further gain support, many Jesuits adopted Chinese dress, customs, and language. Some Chinese scholars were interested in certain Western teachings and especially in Western technology. By the 1580s, Jesuit scholars like Matteo Ricci and Adam Schall amazed the Chinese elite with technological advances such as European clocks, improved calendars and cannons, and the accurate prediction of eclipses. Although some the scholar-gentry converted, many were suspicious of the Westerners whom they called \"barbarians\" and even resented them for the embarrassment they received at the hand of Western correction. Nevertheless, a small group of Jesuit scholars remained at the court to impress the emperor and his advisors.\n\nNear the end of the 1500s, the extremely centralized government that gave so much power to the emperor had begun to fail as more incompetent rulers took the mantle. Along with these weak rulers came increasingly corrupt officials who took advantage of the decline. Once more the public projects fell into disrepair due to neglect by the bureaucracy and resulted in floods, drought, and famine that rocked the peasantry. The famine soon became so terrible that some peasants resorted to selling their children to slavery to save them from starvation, or to eating bark, the feces of geese, or other people. Many landlords abused the situation by building large estates where desperate farmers would work and be exploited. In turn, many of these farmers resorted to flight, banditry, and open rebellion.\n\nAll of this corresponded with the usual dynastic decline of China seen before, as well as the growing foreign threats. In the mid-16th century, Japanese and ethnic Chinese pirates began to raid the southern coast, and neither the bureaucracy nor the military were able to stop them. The threat of the northern Manchu people also grew. The Manchu were an already large state north of China, when in the early 17th century a local leader named Nurhaci suddenly united them under the Eight Banners—armies that the opposing families were organized into. The Manchus adopted many Chinese customs, specifically taking after their bureaucracy. Nevertheless, the Manchus still remained a Chinese vassal. In 1644 Chinese administration became so weak, the 16th and last emperor, the Chongzhen Emperor, did not respond to the severity of an ensuing rebellion by local dissenters until the enemy had invaded the Forbidden City (his personal estate). He soon hanged himself in the imperial gardens. For a brief amount of time, the Shun Dynasty was claimed, until a loyalist Ming official called support from the Manchus to put down the new dynasty. The Shun Dynasty ended within a year and the Manchu were now within the Great Wall. Taking advantage of the situation, the Manchus marched on the Chinese capital of Beijing. Within two decades all of China belonged to the Manchu and the Qing Dynasty was established.\n\nBy 1644, the northern Manchu people had conquered China and established a foreign dynasty—the Qing Dynasty—once more. The Manchu Qing emperors, especially Confucian scholar Kangxi, remained largely conservative—retaining the bureaucracy and the scholars within it, as well as the Confucian ideals present in Chinese society. However, changes in the economy and new attempts at resolving certain issues occurred too. These included increased trade with Western countries that brought large amounts of silver into the Chinese economy in exchange for tea, porcelain, and silk textiles. This allowed for a new merchant-class, the compradors, to develop. In addition, repairs were done on existing dikes, canals, roadways, and irrigation works. This, combined with the lowering of taxes and government-assigned labor, was supposed to calm peasant unrest. However, the Qing failed to control the growing landlord class which had begun to exploit the peasantry and abuse their position.\n\nBy the late 18th century, both internal and external issues began to arise in Qing China's politics, society, and economy. The exam system with which scholars were assigned into the bureaucracy became increasingly corrupt; bribes and other forms of cheating allowed for inexperienced and inept scholars to enter the bureaucracy and this eventually caused rampant neglect of the peasantry, military, and the previously mentioned infrastructure projects. Poverty and banditry steadily rose, especially in rural areas, and mass migrations looking for work throughout China occurred. The perpetually conservative government refused to make reforms that could resolve these issues.\n\nChina saw its status reduced by what it perceived as parasitic trade with Westerners. Originally, European traders were at a disadvantage because the Chinese cared little for their goods, while European demand for Chinese commodities such as tea and porcelain only grew. In order to tip the trade imbalance in their favor, British merchants began to sell Indian opium to the Chinese. Not only did this sap Chinese bullion reserves, it also led to widespread drug addiction amongst the bureaucracy and society in general. A ban was placed on opium as early as 1729 by the Yongzheng Emperor, but little was done to enforce it. By the early 19th century, under the new Daoguang Emperor, the government began serious efforts to eradicate opium from Chinese society. Leading this endeavour were respected scholar-officials including Imperial Commissioner Lin Zexu.\n\nAfter Lin destroyed more than 20,000 chests of opium in the summer of 1839, Europeans demanded compensation for what they saw as unwarranted Chinese interference in their affairs. When it was not paid, the British declared war later the same year, starting what became known as the First Opium War. The outdated Chinese junks were no match for the advanced British gunboats, and soon the Yangzi River region came under threat of British bombardment and invasion. The emperor had no choice but to sue for peace, resulting in the exile of Lin and the making of the Treaty of Nanking, which ceded the British control of Hong Kong and opened up trade and diplomacy with other European countries, including Germany, France, and the USA.\n\nThe European powers had control of other parts of Asia by the early 20th century, such as British India, French Indochina, Spanish East Indies, and Portuguese Macau and Goa. The Great Game between Russia and Britain was the struggle for power in the Central Asian region in the nineteenth century. The Trans-Siberian Railway, crossing Asia by train, was complete by 1916. Parts of Asia remained free from European control, although not influence, such as Persia, Thailand and most of China. In the twentieth century, Imperial Japan expanded into China and Southeast Asia during the Second World War. After the war, many Asian countries became independent from European powers. During the Cold War, the northern parts of Asia were communist controlled with the Soviet Union and People's Republic of China, while western allies formed pacts such as CENTO and SEATO. Conflicts such as the Korean War, Vietnam War and Soviet invasion of Afghanistan were fought between communists and anti-communists. In the decades after the Second World War, a massive restructuring plan drove Japan to become the world's second-largest economy, a phenomenon known as the Japanese post-war economic miracle. The Arab–Israeli conflict has dominated much of the recent history of the Middle East. After the Soviet Union's collapse in 1991, there were many new independent nations in Central Asia.\n\nPrior to World War II, China faced a civil war between Mao Zedong's Communist party and Chiang Kai-shek's nationalist party; the nationalists appeared to be in the lead. However, once the Japanese invaded in 1937, the two parties were forced to form a temporary cease-fire in order to defend China. The nationalists faced many military failures that caused them to lose territory and subsequently, respect from the Chinese masses. In contrast, the communists' use of guerilla warfare (led by Lin Biao) proved effective against the Japanese's conventional methods and put the Communist Party on top by 1945. They also gained popularity for the reforms they were already applying in controlled areas, including land redistribution, education reforms, and widespread health care. For the next four years, the nationalists would be forced to retreat to the small island east of China, known as Taiwan (formerly known as Formosa), where they remain today. In mainland China, the People's Republic of China was established by the Communist Party, with Mao Zedong as its state chairman.\n\nThe communist government in China was defined by the party cadres. These hard-line officers controlled the People's Liberation Army, which itself controlled large amounts of the bureaucracy. This system was further controlled by the Central Committee, which additionally supported the state chairman who was considered the head of the government. The People's Republic's foreign policies included the repressing of secession attempts in Mongolia and Tibet and supporting of North Korea and North Vietnam in the Korean War and Vietnam War, respectively. Additionally, by 1960 China began to cut off its connections with the Soviet Union due to border disputes and an increasing Chinese sense of superiority, especially the personal feeling of Mao over the Russian premier, Nikita Khrushchev.\n\nToday China, India, South Korea, Japan and Russia play important roles in world economics and politics. China today is the world's second largest economy and the second fastest growing economy. Indian economy is the seventh-largest in the world by nominal GDP and the third-largest by purchasing power parity and is the fastest growing economy.\n\n\n"}
{"id": "14098", "url": "https://en.wikipedia.org/wiki?curid=14098", "title": "History of the Americas", "text": "History of the Americas\n\nThe prehistory of the Americas (North, South, and Central America, and the Caribbean) begins with people migrating to these areas from Asia during the height of an Ice Age. These groups are generally believed to have been isolated from peoples of the \"Old World\" until the coming of Europeans in the 10th century from Iceland led by Leif Erikson and with the voyages of Christopher Columbus in 1492.\n\nThe ancestors of today's American Indigenous peoples were the Paleo-Indians; they were hunter-gatherers who migrated into North America. The most popular theory asserts that migrants came to the Americas via Beringia, the land mass now covered by the ocean waters of the Bering Strait. Small lithic stage peoples followed megafauna like bison, mammoth (now extinct), and caribou, thus gaining the modern nickname \"big-game hunters.\" Groups of people may also have traveled into North America on shelf or sheet ice along the northern Pacific coast.\n\nCultural traits brought by the first immigrants later evolved and spawned such cultures as Iroquois on North America and Pirahã of South America. These cultures later developed into civilizations. In many cases, these cultures expanded at a later date than their Old World counterparts. Cultures that may be considered advanced or civilized include Norte Chico, Cahokia, Zapotec, Toltec, Olmec, Maya, Aztec, Chimor, Mixtec, Moche, Mississippian, Puebloan, Totonac, Teotihuacan, Huastec people, Purépecha, Izapa, Mazatec, Muisca, and the Inca.After the voyages of Christopher Columbus in 1492, Spanish, Portuguese and later English, French and Dutch colonial expeditions arrived in the New World, conquering and settling the discovered lands, which led to a transformation of the cultural and physical landscape in the Americas. Spain colonized most of the Americas from present-day Southwestern United States, Florida and the Caribbean to the southern tip of South America. Portugal settled in what is mostly present-day Brazil while England established colonies on the Eastern coast of the United States, as well as the North Pacific coast and in most of Canada. France settled in Quebec and other parts of Eastern Canada and claimed an area in what is today the central United States. The Netherlands settled New Netherland (administrative centre New Amsterdam - now New York), some Caribbean islands and parts of Northern South America.\n\nEuropean colonization of the Americas led to the rise of new cultures, civilizations and eventually states, which resulted from the fusion of Native American and European traditions, peoples and institutions. The transformation of American cultures through colonization is evident in architecture, religion, gastronomy, the arts and particularly languages, the most widespread being Spanish (376 million speakers), English (348 million) and Portuguese (201 million). The colonial period lasted approximately three centuries, from the early 16th to the early 19th centuries, when Brazil and the larger Hispanic American nations declared independence. The United States obtained independence from England much earlier, in 1776, while Canada formed a federal dominion in 1867. Others remained attached to their European parent state until the end of the 19th century, such as Cuba and Puerto Rico which were linked to Spain until 1898. Smaller territories such as Guyana obtained independence in the mid-20th century, while certain Caribbean islands and French Guiana remain part of a European power to this day.\n\n \nThe specifics of Paleo-Indian migration to and throughout the Americas, including the exact dates and routes traveled, are subject to ongoing research and discussion. The traditional theory has been that these early migrants moved into the Beringia land bridge between eastern Siberia and present-day Alaska around 40,000 – 17,000 years ago, when sea levels were significantly lowered due to the Quaternary glaciation. These people are believed to have followed herds of now-extinct Pleistocene megafauna along \"ice-free corridors\" that stretched between the Laurentide and Cordilleran ice sheets. Another route proposed is that, either on foot or using primitive boats, they migrated down the Pacific Northwest coast to South America. Evidence of the latter would since have been covered by a sea level rise of a hundred meters following the last ice age.\n\nArchaeologists contend that the Paleo-Indian migration out of Beringia (eastern Alaska), ranges from 40,000 to around 16,500 years ago. This time range is a hot source of debate. The few agreements achieved to date are the origin from Central Asia, with widespread habitation of the Americas during the end of the last glacial period, or more specifically what is known as the late glacial maximum, around 16,000 – 13,000 years before present.\n\nThe American Journal of Human Genetics released an article in 2007 stating \"Here we show, by using 86 complete mitochondrial genomes, that all Indigenous American haplogroups, including Haplogroup X (mtDNA), were part of a single founding population.\" Amerindian groups in the Bering Strait region exhibit perhaps the strongest DNA or mitochondrial DNA relations to Siberian peoples. The genetic diversity of Amerindian indigenous groups increase with distance from the assumed entry point into the Americas. Certain genetic diversity patterns from West to East suggest, particularly in South America, that migration proceeded first down the west coast, and then proceeded eastward. Geneticists have variously estimated that peoples of Asia and the Americas were part of the same population from 42,000 to 21,000 years ago.\n\nNew studies shed light on the founding population of indigenous Americans, suggesting that their ancestry traced to both east Asian and western Eurasians who migrated to North America directly from Siberia. A 2013 study in the journal Nature reported that DNA found in the 24,000-year-old remains of a young boy in Mal’ta Siberia suggest that up to one-third of the indigenous Americans may have ancestry that can be traced back to western Eurasians, who may have \"had a more north-easterly distribution 24,000 years ago than commonly thought\" Professor Kelly Graf said that \"Our findings are significant at two levels. First, it shows that Upper Paleolithic Siberians came from a cosmopolitan population of early modern humans that spread out of Africa to Europe and Central and South Asia. Second, Paleoindian skeletons with phenotypic traits atypical of modern-day Native Americans can be explained as having a direct historical connection to Upper Paleolithic Siberia.\" A route through Beringia is seen as more likely than the Solutrean hypothesis.\n\nOn October 3, 2014, the Oregon cave where the oldest DNA evidence of human habitation in North America was found was added to the National Register of Historic Places. The DNA, radiocarbon dated to 14,300 years ago, was found in fossilized human coprolites uncovered in the Paisley Five Mile Point Caves in south central Oregon.\n\nThe Lithic stage or \"Paleo-Indian period\", is the earliest classification term referring to the first stage of human habitation in the Americas, covering the Late Pleistocene epoch. The time period derives its name from the appearance of \"Lithic flaked\" stone tools. Stone tools, particularly projectile points and scrapers, are the primary evidence of the earliest well known human activity in the Americas. Lithic reduction stone tools are used by archaeologists and anthropologists to classify cultural periods.\n\nSeveral thousand years after the first migrations, the first complex civilizations arose as hunter-gatherers settled into semi-agricultural communities. Identifiable sedentary settlements began to emerge in the so-called Middle Archaic period around 6000 BCE. Particular archaeological cultures can be identified and easily classified throughout the Archaic period.\n\nIn the late Archaic, on the north-central coastal region of Peru, a complex civilization arose which has been termed the Norte Chico civilization, also known as Caral-Supe. It is the oldest known civilization in the Americas and one of the five sites where civilization originated independently and indigenously in the ancient world, flourishing between the 30th and 18th centuries BC. It pre-dated the Mesoamerican Olmec civilization by nearly two millennia. It was contemporaneous with the Egypt following the unification of its kingdom under Narmer and the emergence of the first Egyptian hieroglyphics.\n\nMonumental architecture, including earthwork platform mounds and sunken plazas have been identified as part of the civilization. Archaeological evidence points to the use of textile technology and the worship of common god symbols. Government, possibly in the form of theocracy, is assumed to have been required to manage the region. However, numerous questions remain about its organization. In archaeological nomenclature, the culture was pre-ceramic culture of the pre-Columbian Late Archaic period. It appears to have lacked ceramics and art.\n\nOngoing scholarly debate persists over the extent to which the flourishing of Norte Chico resulted from its abundant maritime food resources, and the relationship that these resources would suggest between coastal and inland sites.\n\nThe role of seafood in the Norte Chico diet has been a subject of scholarly debate. In 1973, examining the Aspero region of Norte Chico, Michael E. Moseley contended that a maritime subsistence (seafood) economy had been the basis of society and its early flourishing. This theory, later termed \"maritime foundation of Andean Civilization\" was at odds with the general scholarly consensus that civilization arose as a result of intensive grain-based agriculture, as had been the case in the emergence of civilizations in northeast Africa (Egypt) and southwest Asia (Mesopotamia).\n\nWhile earlier research pointed to edible domestic plants such as squash, beans, lucuma, guava, pacay, and camote at Caral, publications by Haas and colleagues have added avocado, achira, and corn (Zea Mays) to the list of foods consumed in the region. In 2013, Haas and colleagues reported that maize was a primary component of the diet throughout the period of 3000 to 1800 BC.\n\nCotton was another widespread crop in Norte Chico, essential to the production of fishing nets and textiles. Jonathan Haas noted a mutual dependency, whereby \"The prehistoric residents of the Norte Chico needed the fish resources for their protein and the fishermen needed the cotton to make the nets to catch the fish.\"\n\nIn the 2005 book \"\", journalist Charles C. Mann surveyed the literature at the time, reporting a date \"sometime before 3200 BC, and possibly before 3500 BC\" as the beginning date for the formation of Norte Chico. He notes that the earliest date securely associated with a city is 3500 BC, at Huaricanga in the (inland) Fortaleza area.\n\nThe Norte Chico civilization began to decline around 1800 BC as more powerful centers appeared to the south and north along its coast, and to the east within the Andes Mountains.\n\nAfter the decline of the Norte Chico civilization, several large, centralized civilizations developed in the Western Hemisphere: Chavin, Nazca, Moche, Huari, Quitus, Cañaris, Chimu, Pachacamac, Tiahuanaco, Aymara and Inca in the Central Andes (Ecuador, Peru and Bolivia); Muisca in Colombia ; Taínos in Dominican Republic (Hispaniola, Española) and part of Caribbean; and the Olmecs, Maya, Toltecs, Mixtecs, Zapotecs, Aztecs and Purepecha in southern North America (Mexico, Guatemala).\n\nThe Olmec civilization was the first Mesoamerican civilization, beginning around 1600-1400 BC and ending around 400 BC. Mesoamerica is considered one of the six sites around the globe in which civilization developed independently and indigenously. This civilization is considered the mother culture of the Mesoamerican civilizations. The Mesoamerican calendar, numeral system, writing, and much of the Mesoamerican pantheon seem to have begun with the Olmec.\n\nSome elements of agriculture seem to have been practiced in Mesoamerica quite early. The domestication of maize is thought to have begun around 7,500 to 12,000 years ago. The earliest record of lowland maize cultivation dates to around 5100 BC. Agriculture continued to be mixed with a hunting-gathering-fishing lifestyle until quite late compared to other regions, but by 2700 BC, Mesoamericans were relying on maize, and living mostly in villages. Temple mounds and classes started to appear. By 1300/ 1200 BC, small centres coalesced into the Olmec civilization, which seems to have been a set of city-states, united in religious and commercial concerns. The Olmec cities had ceremonial complexes with earth/clay pyramids, palaces, stone monuments, aqueducts and walled plazas. The first of these centers was at San Lorenzo (until 900 bc). La Venta was the last great Olmec centre. Olmec artisans sculpted jade and clay figurines of Jaguars and humans. Their iconic giant heads - believed to be of Olmec rulers - stood in every major city.\n\nThe Olmec civilization ended in 400 BC, with the defacing and destruction of San Lorenzo and La Venta, two of the major cities. It nevertheless spawned many other states, most notably the Mayan civilization, whose first cities began appearing around 700-600 BC. Olmec influences continued to appear in many later Mesoamerican civilizations.\n\nCities of the Aztecs, Mayas, and Incas were as large and organized as the largest in the Old World, with an estimated population of 200,000 to 350,000 in Tenochtitlan, the capital of the Aztec empire. The market established in the city was said to have been the largest ever seen by the conquistadors when they arrived. The capital of the Cahokians, Cahokia, located near modern East St. Louis, Illinois, may have reached a population of over 20,000. At its peak, between the 12th and 13th centuries, Cahokia may have been the most populous city in North America. Monk's Mound, the major ceremonial center of Cahokia, remains the largest earthen construction of the prehistoric New World.\n\nThese civilizations developed agriculture as well, breeding maize (corn) from having ears 2–5 cm in length to perhaps 10–15 cm in length. Potatoes, tomatoes, pumpkins, beans, avocados, and chocolate are now the most popular of the pre-Columbian agricultural products. The civilizations did not develop extensive livestock as there were few suitable species, although alpacas and llamas were domesticated for use as beasts of burden and sources of wool and meat in the Andes. By the 15th century, maize was being farmed in the Mississippi River Valley after introduction from Mexico. The course of further agricultural development was greatly altered by the arrival of Europeans.\n\n\nCahokia was a major regional chiefdom, with trade and tributary chiefdoms located in a range of areas from bordering the Great Lakes to the Gulf of Mexico.\n\n\nThe Iroquois League of Nations or \"People of the Long House\", based in present-day upstate and western New York, had a confederacy model from the mid-15th century. It has been suggested that their culture contributed to political thinking during the development of the later United States government. Their system of affiliation was a kind of federation, different from the strong, centralized European monarchies.\n\nLeadership was restricted to a group of 50 sachem chiefs, each representing one clan within a tribe; the Oneida and Mohawk people had nine seats each; the Onondagas held fourteen; the Cayuga had ten seats; and the Seneca had eight. Representation was not based on population numbers, as the Seneca tribe greatly outnumbered the others. When a sachem chief died, his successor was chosen by the senior woman of his tribe in consultation with other female members of the clan; property and hereditary leadership were passed matrilineally. Decisions were not made through voting but through consensus decision making, with each sachem chief holding theoretical veto power. The Onondaga were the \"firekeepers\", responsible for raising topics to be discussed. They occupied one side of a three-sided fire (the Mohawk and Seneca sat on one side of the fire, the Oneida and Cayuga sat on the third side.)\n\nElizabeth Tooker, an anthropologist, has said that it was unlikely the US founding fathers were inspired by the confederacy, as it bears little resemblance to the system of governance adopted in the United States. For example, it is based on inherited rather than elected leadership, selected by female members of the tribes, consensus decision-making regardless of population size of the tribes, and a single group capable of bringing matters before the legislative body.\n\nLong-distance trading did not prevent warfare and displacement among the indigenous peoples, and their oral histories tell of numerous migrations to the historic territories where Europeans encountered them. The Iroquois invaded and attacked tribes in the Ohio River area of present-day Kentucky and claimed the hunting grounds. Historians have placed these events as occurring as early as the 13th century, or in the 17th century Beaver Wars.\n\nThrough warfare, the Iroquois drove several tribes to migrate west to what became known as their historically traditional lands west of the Mississippi River. Tribes originating in the Ohio Valley who moved west included the Osage, Kaw, Ponca and Omaha people. By the mid-17th century, they had resettled in their historical lands in present-day Kansas, Nebraska, Arkansas and Oklahoma. The Osage warred with Caddo-speaking Native Americans, displacing them in turn by the mid-18th century and dominating their new historical territories.\n\n\nThe Pueblo people of what is now the Southwestern United States and northern Mexico, living conditions were that of large stone apartment like adobe structures. They live in Arizona, New Mexico, Utah, Colorado, and possibly surrounding areas.\n\nChichimeca was the name that the Mexica (Aztecs) generically applied to a wide range of semi-nomadic peoples who inhabited the north of modern-day Mexico, and carried the same sense as the European term \"barbarian\". The name was adopted with a pejorative tone by the Spaniards when referring especially to the semi-nomadic hunter-gatherer peoples of northern Mexico.\n\nThe Zapotec emerged around 1500 years BCE. Their writing system influenced the later Olmec. They left behind the great city Monte Alban.\n\nThe Olmec civilization emerged around 1200 BCE in Mesoamerica and ended around 400 BCE. Olmec art and concepts influenced surrounding cultures after their downfall. This civilization was thought to be the first in America to develop a writing system. After the Olmecs abandoned their cities for unknown reasons, the Maya, Zapotec and Teotihuacan arose.\n\nThe Purepecha civilization emerged around 1000 CE in Mesoamerica . They flourished from 1100 CE to 1530 CE. They continue to live on in the state of Michoacán. Fierce warriors, they were never conquered and in their glory years, successfully sealed off huge areas from Aztec domination.\n\n\nMaya history spans 3,000 years. The Classic Maya may have collapsed due to changing climate in the end of the 10th century.\n\nThe Toltec were a nomadic people, dating from the 10th - 12th century, whose language was also spoken by the Aztecs.\n\nTeotihuacan (4th century BCE - 7/8th century CE) was both a city, and an empire of the same name, which, at its zenith between 150 and the 5th century, covered most of Mesoamerica.\n\nThe Aztec having started to build their empire around 14th century found their civilization abruptly ended by the Spanish conquistadors. They lived in Mesoamerica, and surrounding lands. Their capital city Tenochtitlan was one of the largest cities of all time.\n\nThe oldest known civilization of the Americas was established in the Norte Chico region of modern Peru. Complex society emerged in the group of coastal valleys, between 3000 and 1800 BCE. The Quipu, a distinctive recording device among Andean civilizations, apparently dates from the era of Norte Chico's prominence.\n\nThe Chavín established a trade network and developed agriculture by as early as (or late compared to the Old World) 900 BCE according to some estimates and archaeological finds. Artifacts were found at a site called Chavín in modern Peru at an elevation of 3,177 meters. Chavín civilization spanned from 900 BCE to 300 BCE.\n\nHolding their capital at the great city of Cusco, the Inca civilization dominated the Andes region from 1438 to 1533.\nKnown as \"Tahuantinsuyu\", or \"the land of the four regions\", in Quechua, the Inca culture was highly distinct and developed. Cities were built with precise, unmatched stonework, constructed over many levels of mountain terrain. Terrace farming was a useful form of agriculture. There is evidence of excellent metalwork and even successful trepanation of the skull in Inca civilization.\n\nAround 1000, the Vikings established a short-lived settlement in Newfoundland, now known as L'Anse aux Meadows. Speculations exist about other Old World discoveries of the New World, but none of these are generally or completely accepted by most scholars.\n\nSpain sponsored a major exploration led by Italian explorer Christopher Columbus in 1492; it quickly led to extensive European colonization of the Americas. The Europeans brought Old World diseases which are thought to have caused catastrophic epidemics and a huge decrease of the native population. Columbus came at a time in which many technical developments in sailing techniques and communication made it possible to report his voyages easily and to spread word of them throughout Europe. It was also a time of growing religious, imperial and economic rivalries that led to a competition for the establishment of colonies.\n\n15th to 19th century colonies in the New World:\n\nThe formation of sovereign states in the New World began with the United States Declaration of Independence of 1776. The American Revolutionary War lasted through the period of the Siege of Yorktown — its last major campaign — in the early autumn of 1781, with peace being achieved in 1783.\nThe Spanish colonies won their independence in the first quarter of the 19th century, in the Spanish American wars of independence. Simón Bolívar and José de San Martín, among others, led their independence struggle. Although Bolivar attempted to keep the Spanish-speaking parts of Latin America politically allied, they rapidly became independent of one another as well, and several further wars were fought, such as the Paraguayan War and the War of the Pacific. (See Latin American integration.) In the Portuguese colony Dom Pedro I (also Pedro IV of Portugal), son of the Portuguese king Dom João VI, proclaimed the country's independence in 1822 and became Brazil's first Emperor. This was peacefully accepted by the crown in Portugal, upon compensation.\n\nSlavery has had a significant role in the economic development of the New World after the colonization of the Americas by the Europeans. The cotton, tobacco, and sugar cane harvested by slaves became important exports for the United States and the Caribbean countries.\n\nAs a part of the British Empire, Canada immediately entered World War I when it broke out in 1914. Canada bore the brunt of several major battles during the early stages of the war, including the use of poison gas attacks at Ypres. Losses became grave, and the government eventually brought in conscription, despite the fact this was against the wishes of the majority of French Canadians. In the ensuing Conscription Crisis of 1917, riots broke out on the streets of Montreal. In neighboring Newfoundland, the new dominion suffered a devastating loss on July 1, 1916, the First day on the Somme.\n\nThe United States stayed out of the conflict until 1917, when it joined the Entente powers. The United States was then able to play a crucial role at the Paris Peace Conference of 1919 that shaped interwar Europe. Mexico was not part of the war, as the country was embroiled in the Mexican Revolution at the time.\n\nThe 1920s brought an age of great prosperity in the United States, and to a lesser degree Canada. But the Wall Street Crash of 1929 combined with drought ushered in a period of economic hardship in the United States and Canada. From 1936 to 1949, there was a popular uprising against the anti-Catholic Mexican government of the time, set off specifically by the anti-clerical provisions of the Mexican Constitution of 1917.\n\nOnce again, Canada found itself at war before its neighbors, however even Canadian contributions were slight before the Japanese attack on Pearl Harbor. The entry of the United States into the war helped to tip the balance in favour of the allies. Two Mexican tankers, transporting oil to the United States, were attacked and sunk by the Germans in the Gulf of Mexico waters, in 1942. The incident happened in spite of Mexico's neutrality at that time. This led Mexico to enter the conflict with a declaration of war on the Axis nations. The destruction of Europe wrought by the war vaulted all North American countries to more important roles in world affairs, especially the United States, which emerged as a \"superpower\".\n\nThe early Cold War era saw the United States as the most powerful nation in a Western coalition of which Mexico and Canada were also a part. In Canada, Quebec was transformed by the Quiet Revolution and the emergence of Quebec nationalism. Mexico experienced an era of huge economic growth after World War II, a heavy industrialization process and a growth of its middle class, a period known in Mexican history as \"\"El Milagro Mexicano\"\" (the Mexican miracle). The Caribbean saw the beginnings of decolonization, while on the largest island the Cuban Revolution introduced Cold War rivalries into Latin America.\n\nThe civil rights movement in the U.S. ended Jim Crow and empowered black voters in the 1960s, which allowed black citizens to move into high government offices for the first time since Reconstruction. However, the dominant New Deal coalition collapsed in the mid 1960s in disputes over race and the Vietnam War, and the conservative movement began its rise to power, as the once dominant liberalism weakened and collapsed. Canada during this era was dominated by the leadership of Pierre Elliot Trudeau. In 1982, at the end of his tenure, Canada enshrined a new constitution.\n\nCanada's Brian Mulroney not only ran on a similar platform but also favored closer trade ties with the United States. This led to the Canada-United States Free Trade Agreement in January 1989. Mexican presidents Miguel de la Madrid, in the early 1980s and Carlos Salinas de Gortari in the late 1980s, started implementing liberal economic strategies that were seen as a good move. However, Mexico experienced a strong economic recession in 1982 and the Mexican peso suffered a devaluation. In the United States president Ronald Reagan attempted to move the United States back towards a hard anti-communist line in foreign affairs, in what his supporters saw as an attempt to assert moral leadership (compared to the Soviet Union) in the world community. Domestically, Reagan attempted to bring in a package of privatization and regulation to stimulate the economy.\n\nThe end of the Cold War and the beginning of the era of sustained economic expansion coincided during the 1990s. On January 1, 1994, Canada, Mexico and the United States signed the North American Free Trade Agreement, creating the world's largest free trade area. In 2000, Vicente Fox became the first non-PRI candidate to win the Mexican presidency in over 70 years. The optimism of the 1990s was shattered by the 9/11 attacks of 2001 on the United States, which prompted military intervention in Afghanistan, which also involved Canada. Canada did not support the United States' later move to invade Iraq, however.\n\nIn the U.S. the Reagan Era of conservative national policies, deregulation and tax cuts took control with the election of Ronald Reagan in 1980. By 2010, political scientists were debating whether the election of Barack Obama in 2008 represented an end of the Reagan Era, or was only a reaction against the bubble economy of the 2000s (decade), which burst in 2008 and became the Late-2000s recession with prolonged unemployment.\n\nDespite the failure of a lasting political union, the concept of Central American reunification, though lacking enthusiasm from the leaders of the individual countries, rises from time to time. In 1856–1857 the region successfully established a military coalition to repel an invasion by United States adventurer William Walker. Today, all five nations fly flags that retain the old federal motif of two outer blue bands bounding an inner white stripe. (Costa Rica, traditionally the least committed of the five to regional integration, modified its flag significantly in 1848 by darkening the blue and adding a double-wide inner red band, in honor of the French tricolor).\n\nIn 1907, a Central American Court of Justice was created. On December 13, 1960, Guatemala, El Salvador, Honduras, and Nicaragua established the Central American Common Market (\"CACM\"). Costa Rica, because of its relative economic prosperity and political stability, chose not to participate in the CACM. The goals for the CACM were to create greater political unification and success of import substitution industrialization policies. The project was an immediate economic success, but was abandoned after the 1969 \"Football War\" between El Salvador and Honduras. A Central American Parliament has operated, as a purely advisory body, since 1991. Costa Rica has repeatedly declined invitations to join the regional parliament, which seats deputies from the four other former members of the Union, as well as from Panama and the Dominican Republic.\n\nIn the 1960s and 1970s, the governments of Argentina, Brazil, Chile, and Uruguay were overthrown or displaced by U.S.-aligned military dictatorships. These dictatorships detained tens of thousands of political prisoners, many of whom were tortured and/or killed (on inter-state collaboration, see Operation Condor). Economically, they began a transition to neoliberal economic policies. They placed their own actions within the United States Cold War doctrine of \"National Security\" against internal subversion. Throughout the 1980s and 1990s, Peru suffered from an internal conflict (see Túpac Amaru Revolutionary Movement and Shining Path). Revolutionary movements and right-wing military dictatorships have been common, but starting in the 1980s a wave of democratization came through the continent, and democratic rule is widespread now. Allegations of corruption remain common, and several nations have seen crises which have forced the resignation of their presidents, although normal civilian succession has continued.\n\nInternational indebtedness became a notable problem, as most recently illustrated by Argentina's default in the early 21st century. In recent years, South American governments have drifted to the left, with socialist leaders being elected in Chile, Bolivia, Brazil, Venezuela, and a leftist president in Argentina and Uruguay. Despite the move to the left, South America is still largely capitalist. With the founding of the Union of South American Nations, South America has started down the road of economic integration, with plans for political integration in the European Union style.\n\n"}
