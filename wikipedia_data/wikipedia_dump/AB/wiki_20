{"id": "14750", "url": "https://en.wikipedia.org/wiki?curid=14750", "title": "Iodine", "text": "Iodine\n\nIodine is a chemical element with symbol I and atomic number 53. The heaviest of the stable halogens, it exists as a lustrous, purple-black non-metallic solid at standard conditions that sublimes readily to form a violet gas. The elemental form was discovered by the French chemist Bernard Courtois in 1811. It was named two years later by Joseph Louis Gay-Lussac from this property, after the Greek \"ἰώδης\" \"violet-coloured\".\n\nIodine occurs in many oxidation states, including iodide (I), iodate (), and the various periodate anions. It is the least abundant of the stable halogens, being the sixty-first most abundant element. It is the heaviest essential mineral nutrient. Iodine is essential in the synthesis of thyroid hormones. Iodine deficiency affects about two billion people and is the leading preventable cause of intellectual disabilities.\n\nThe dominant producers of iodine today are Chile and Japan. Iodine and its compounds are primarily used in nutrition. Due to its high atomic number and ease of attachment to organic compounds, it has also found favour as a non-toxic radiocontrast material. Because of the specificity of its uptake by the human body, radioactive isotopes of iodine can also be used to treat thyroid cancer. Iodine is also used as a catalyst in the industrial production of acetic acid and some polymers.\n\nIn 1811, iodine was discovered by French chemist Bernard Courtois, who was born to a manufacturer of saltpetre (an essential component of gunpowder). At the time of the Napoleonic Wars, saltpetre was in great demand in France. Saltpetre produced from French nitre beds required sodium carbonate, which could be isolated from seaweed collected on the coasts of Normandy and Brittany. To isolate the sodium carbonate, seaweed was burned and the ash washed with water. The remaining waste was destroyed by adding sulfuric acid. Courtois once added excessive sulfuric acid and a cloud of purple vapour rose. He noted that the vapour crystallised on cold surfaces, making dark crystals. Courtois suspected that this material was a new element but lacked funding to pursue it further.\n\nCourtois gave samples to his friends, Charles Bernard Desormes (1777–1838) and Nicolas Clément (1779–1841), to continue research. He also gave some of the substance to chemist Joseph Louis Gay-Lussac (1778–1850), and to physicist André-Marie Ampère (1775–1836). On 29 November 1813, Desormes and Clément made Courtois' discovery public. They described the substance to a meeting of the Imperial Institute of France. On 6 December, Gay-Lussac announced that the new substance was either an element or a compound of oxygen. It was Gay-Lussac who suggested the name \"\"iode\"\", from the Greek word (\"ioeidēs\") for violet (because of the colour of iodine vapor). Ampère had given some of his sample to English chemist Humphry Davy (1778–1829), who experimented on the substance and noted its similarity to chlorine. Davy sent a letter dated 10 December to the Royal Society of London stating that he had identified a new element. Arguments erupted between Davy and Gay-Lussac over who identified iodine first, but both scientists acknowledged Courtois as the first to isolate the element.\n\nIn early periodic tables, iodine is often given the symbol \"J\", for \"jod\", its name in German.\n\nIodine is the fourth halogen, being a member of group 17 in the periodic table, below fluorine, chlorine, and bromine; it is the heaviest stable member of its group. (The scarce and fugitive fifth halogen, the radioactive astatine, is not well-studied due to its expense and inaccessibility in large quantities, but appears to show various unusual properties due to relativistic effects.) Iodine has an electron configuration of [Kr]4d5s5p, with the seven electrons in the fifth and outermost shell being its valence electrons. Like the other halogens, it is one electron short of a full octet and is hence a strong oxidising agent, reacting with many elements in order to complete its outer shell, although in keeping with periodic trends, it is the weakest oxidising agent among the stable halogens: it has the lowest electronegativity among them, just 2.66 on the Pauling scale (compare fluorine, chlorine, and bromine at 3.98, 3.16, and 2.96 respectively; astatine continues the trend with an electronegativity of 2.2). Elemental iodine hence forms diatomic molecules with chemical formula I, where two iodine atoms share a pair of electrons in order to each achieve a stable octet for themselves; at high temperatures, these diatomic molecules reversibly dissociate a pair of iodine atoms. Similarly, the iodide anion, I, is the strongest reducing agent among the stable halogens, being the most easily oxidised back to diatomic I. (Astatine goes further, being indeed unstable as At and readily oxidised to At or At, although the existence of At is not settled.)\n\nThe halogens darken in colour as the group is descended: fluorine is a very pale yellow gas, chlorine is greenish-yellow, and bromine is a reddish-brown volatile liquid. Iodine conforms to the prevailing trend, being a shiny black crystalline solid that melts at 114 °C and boils at 183 °C to form a violet gas. This trend occurs because the wavelengths of visible light absorbed by the halogens increase down the group (though astatine may not conform to it, depending on how metallic it turns out to be). Specifically, the violet colour of iodine gas results from the electron transition between the highest occupied antibonding \"π\" molecular orbital and the lowest vacant antibonding \"σ\" molecular orbital.\n\nElemental iodine is slightly soluble in water, with one gram dissolving in 3450 ml at 20 °C and 1280 ml at 50 °C; potassium iodide may be added to increase solubility via formation of triiodide ions, among other polyiodides. Nonpolar solvents such as hexane and carbon tetrachloride provide a higher solubility. Polar solutions, such as aqueous solutions, are brown, reflecting the role of these solvents as Lewis bases; on the other hand, nonpolar solutions are violet, the color of iodine vapour. Charge-transfer complexes form when iodine is dissolved in polar solvents, hence changing the colour. Iodine is violet when dissolved in carbon tetrachloride and saturated hydrocarbons but deep brown in alcohols and amines, solvents that form charge-transfer adducts.\n\nThe melting and boiling points of iodine are the highest among the halogens, conforming to the increasing trend down the group, since iodine has the largest electron cloud among them that is the most easily polarised, resulting in its molecules having the strongest van der Waals interactions among the halogens. Similarly, iodine is the least volatile of the halogens. Because it has the largest atomic radius among the halogens, iodine has the lowest first ionisation energy, lowest electron affinity, lowest electronegativity and lowest reactivity of the halogens.\nThe interhalogen bond in diiodine is the weakest of all the halogens. As such, 1% of a sample of gaseous iodine at atmospheric pressure is dissociated into iodine atoms at 575 °C. Temperatures greater than 750 °C are required for fluorine, chlorine, and bromine to dissociate to a similar extent. Most bonds to iodine are weaker than the analogous bonds to the lighter halogens. Gaseous iodine is composed of I molecules with an I–I bond length of 266.6 pm. The I–I bond is one of the longest single bonds known. It is even longer (271.5 pm) in solid orthorhombic crystalline iodine, which has the same crystal structure as chlorine and bromine. (The record is held by iodine's neighbour xenon: the Xe–Xe bond length is 308.71 pm.) As such, within the iodine molecule, significant electronic interactions occur with the two next-nearest neighbours of each atom, and these interactions give rise, in bulk iodine, to a shiny appearance and semiconducting properties. Iodine is a two-dimensional semiconductor with a band gap of 1.3 eV (125 kJ/mol): it is a semiconductor in the plane of its crystalline layers and an insulator in the perpendicular direction.\n\nOf the thirty-seven known isotopes of iodine, only one occurs in nature, iodine-127. The others are radioactive and have half-lives too short to be primordial. As such, iodine is monoisotopic and its atomic weight is known to great precision, as it is a constant of nature.\n\nThe longest-lived of the radioactive isotopes of iodine is iodine-129, which has a half-life of 15.7 million years, decaying via beta decay to stable xenon-129. Some iodine-129 was formed along with iodine-127 before the formation of the Solar System, but it has by now completely decayed away, making it an extinct radionuclide that is nevertheless still useful in dating the history of the early Solar System or very old groundwaters, due to its mobility in the environment. Its former presence may be determined from an excess of its daughter xenon-129. Traces of iodine-129 still exist today, as it is also a cosmogenic nuclide, formed from cosmic ray spallation of atmospheric xenon: these traces make up 10 to 10 of all terrestrial iodine. It also occurs from open-air nuclear testing, and is not hazardous because of its incredibly long half-life, the longest of all fission products. At the peak of thermonuclear testing in the 1960s and 1970s, iodine-129 still made up only about 10 of all terrestrial iodine. Excited states of iodine-127 and iodine-129 are often used in Mössbauer spectroscopy.\n\nThe other iodine radioisotopes have much shorter half-lives, no longer than days. Some of them have medical applications involving the thyroid gland, where the iodine that enters the body is stored and concentrated. Iodine-123 has a half-life of thirteen hours and decays by electron capture to tellurium-123, emitting gamma radiation; it is used in nuclear medicine imaging, including single photon emission computed tomography (SPECT) and X-ray computed tomography (X-Ray CT) scans. Iodine-125 has a half-life of fifty-nine days, decaying by electron capture to tellurium-125 and emitting low-energy gamma radiation; the second-longest-lived iodine radioisotope, it has uses in biological assays, nuclear medicine imaging and in radiation therapy as brachytherapy to treat a number of conditions, including prostate cancer, uveal melanomas, and brain tumours. Finally, iodine-131, with a half-life of eight days, beta decays to an excited state of stable xenon-131 that then converts to the ground state by emitting gamma radiation. It is a common fission product and thus is present in high levels in radioactive fallout. It may then be absorbed through contaminated food, and will also accumulate in the thyroid. As it decays, it may cause damage to the thyroid. The primary risk from exposure to high levels of iodine-131 is the chance occurrence of radiogenic thyroid cancer in later life. Other risks include the possibility of non-cancerous growths and thyroiditis.\n\nThe usual means of protection against the negative effects of iodine-131 is by saturating the thyroid gland with stable iodine-127 in the form of potassium iodide tablets, taken daily for optimal prophylaxis. However, iodine-131 may also be used for medicinal purposes in radiation therapy for this very reason, when tissue destruction is desired after iodine uptake by the tissue. Iodine-131 is also used as a radioactive tracer.\n\nThough it is the least reactive of the halogens, iodine is still one of the more reactive elements. For example, while chlorine gas will halogenate carbon monoxide, nitric oxide, and sulfur dioxide (to phosgene, nitrosyl chloride, and sulfuryl chloride respectively), iodine will not do so. Furthermore, iodination of metals tends to result in lower oxidation states than chlorination or bromination; for example, rhenium metal reacts with chlorine to form rhenium hexachloride, but with bromine it forms only rhenium pentabromide and iodine can achieve only rhenium tetraiodide. By the same token, however, since iodine has the lowest ionisation energy among the halogens and is the most easily oxidised of them, it has a more significant cationic chemistry and its higher oxidation states are rather more stable than those of bromine and chlorine, for example in iodine heptafluoride.\n\nThe simplest compound of iodine is hydrogen iodide, HI. It is a colourless gas that reacts with oxygen to give water and iodine. Although it is useful in iodination reactions in the laboratory, it does not have large-scale industrial uses, unlike the other hydrogen halides. Commercially, it is usually made by reacting iodine with hydrogen sulfide or hydrazine:\nAt room temperature, it is a colourless gas, like all of the hydrogen halides except hydrogen fluoride, since hydrogen cannot form strong hydrogen bonds to the large and only mildly electronegative iodine atom. It melts at −51.0 °C and boils at −35.1 °C. It is an endothermic compound that can exothermically dissociate at room temperature, although the process is very slow unless a catalyst is present: the reaction between hydrogen and iodine at room temperature to give hydrogen iodide does not proceed to completion. The H–I bond dissociation energy is likewise the smallest of the hydrogen halides, at 295 kJ/mol.\n\nAqueous hydrogen iodide is known as hydroiodic acid, which is a strong acid. Hydrogen iodide is exceptionally soluble in water: one litre of water will dissolve 425 litres of hydrogen iodide, and the saturated solution has only four water molecules per molecule of hydrogen iodide. Commercial so-called \"concentrated\" hydroiodic acid usually contains 48–57% HI by mass; the solution forms an azeotrope with boiling point 126.7 °C at 56.7 g HI per 100 g solution. Hence hydroiodic acid cannot be concentrated past this point by evaporation of water.\n\nUnlike hydrogen fluoride, anhydrous liquid hydrogen iodide is difficult to work with as a solvent, because its boiling point is low, it has a small liquid range, its dielectric constant is low and it does not dissociate appreciably into HI and ions – the latter, in any case, are much less stable than the bifluoride ions () due to the very weak hydrogen bonding between hydrogen and iodine, though its salts with very large and weakly polarising cations such as Cs and (R = Me, Et, Bu) may still be isolated. Anhydrous hydrogen iodide is a poor solvent, able to dissolve only small molecular compounds such as nitrosyl chloride and phenol, or salts with very low lattice energies such as tetraalkylammonium halides.\n\nNearly all elements in the periodic table form binary iodides. The exceptions are decidedly in the minority and stem in each case from one of three causes: extreme inertness and reluctance to participate in chemical reactions (the noble gases); extreme nuclear instability hampering chemical investigation before decay and transmutation (many of the heaviest elements beyond bismuth); and having an electronegativity higher than iodine's (oxygen, nitrogen, and the first three halogens), so that the resultant binary compounds are formally not iodides but rather oxides, nitrides, or halides of iodine. (Nonetheless, nitrogen triiodide is named as an iodide as it is analogous to the other nitrogen trihalides.)\n\nGiven the large size of the iodide anion and iodine's weak oxidising power, high oxidation states are difficult to achieve in binary iodides, the maximum known being in the pentaiodides of niobium, tantalum, and protactinium. Iodides can be made by reaction of an element or its oxide, hydroxide, or carbonate with hydroiodic acid, and then dehydrated by mildly high temperatures combined with either low pressure or anhydrous hydrogen iodide gas. These methods work best when the iodide product is stable to hydrolysis; otherwise, the possibilities include high-temperature oxidative iodination of the element with iodine or hydrogen iodide, high-temperature iodination of a metal oxide or other halide by iodine, a volatile metal halide, carbon tetraiodide, or an organic iodide. For example, molybdenum(IV) oxide reacts with aluminium(III) iodide at 230 °C to give molybdenum(II) iodide. An example involving halogen exchange is given below, involving the reaction of tantalum(V) chloride with excess aluminium(III) iodide at 400 °C to give tantalum(V) iodide:\n\nLower iodides may be produced either through thermal decomposition or disproportionation, or by reducing the higher iodide with hydrogen or a metal, for example:\n\nMost of the iodides of the pre-transition metals (groups 1, 2, and 3, along with the lanthanides and actinides in the +2 and +3 oxidation states) are mostly ionic, while nonmetals tend to form covalent molecular iodides, as do metals in high oxidation states from +3 and above. Ionic iodides MI tend to have the lowest melting and boiling points among the halides MX of the same element, because the electrostatic forces of attraction between the cations and anions are weakest for the large iodide anion. In contrast, covalent iodides tend to instead have the highest melting and boiling points among the halides of the same element, since iodine is the most polarisable of the halogens and, having the most electrons among them, can contribute the most to van der Waals forces. Naturally, exceptions abound in intermediate iodides where one trend gives way to the other. Similarly, solubilities in water of predominantly ionic iodides (e.g. potassium and calcium) are the greatest among ionic halides of that element, while those of covalent iodides (e.g. silver) are the lowest of that element. In particular, silver iodide is very insoluble in water and its formation is often used as a qualitative test for iodine.\n\nThe halogens form many binary, diamagnetic interhalogen compounds with stoichiometries XY, XY, XY, and XY (where X is heavier than Y), and iodine is no exception. Iodine forms all three possible diatomic interhalogens, a trifluoride and trichloride, as well as a pentafluoride and, exceptionally among the halogens, a heptafluoride. Numerous cationic and anionic derivatives are also characterised, such as the wine-red or bright orange compounds of and the dark brown or purplish black compounds of ICl. Apart from these, some pseudohalides are also known, such as cyanogen iodide (ICN), iodine thiocyanate (ISCN), and iodine azide (IN).\nIodine monofluoride (IF) is unstable at room temperature and disproportionates very readily and irreversibly to iodine and iodine pentafluoride, and thus cannot be obtained pure. It can be synthesised from the reaction of iodine with fluorine gas in trichlorofluoromethane at −45 °C, with iodine trifluoride in trichlorofluoromethane at −78 °C, or with silver(I) fluoride at 0 °C. Iodine monochloride (ICl) and iodine monobromide (IBr), on the other hand, are moderately stable. The former, a volatile red-brown compound, was discovered independently by Joseph Louis Gay-Lussac and Humphry Davy in 1813–4 not long after the discoveries of chlorine and iodine, and it mimics the intermediate halogen bromine so well that Justus von Liebig was misled into mistaking bromine (which he had found) for iodine monochloride. Iodine monochloride and iodine monobromide may be prepared simply by reacting iodine with chlorine or bromine at room temperature and purified by fractional crystallisation. Both are quite reactive and attack even platinum and gold, though not boron, carbon, cadmium, lead, zirconium, niobium, molybdenum, and tungsten. Their reaction with organic compounds depends on conditions. Iodine chloride vapour tends to chlorinate phenol and salicyclic acid, since when iodine chloride undergoes homolytic dissociation, chlorine and iodine are produced and the former is more reactive. However, iodine chloride in tetrachloromethane solution results in iodination being the main reaction, since now heterolytic fission of the I–Cl bond occurs and I attacks phenol as an electrophile. However, iodine monobromide tends to brominate phenol even in tetrachloromethane solution because it tends to dissociate into its elements in solution, and bromine is more reactive than iodine. When liquid, iodine monochloride and iodine monobromide dissociate into and anions (X = Cl, Br); thus they are significant conductors of electricity and can be used as ionising solvents.\n\nIodine trifluoride (IF) is an unstable yellow solid that decomposes above −28 °C. It is thus little-known. It is difficult to produce because fluorine gas would tend to oxidise iodine all the way to the pentafluoride; reaction at low temperature with xenon difluoride is necessary. Iodine trichloride, which exists in the solid state as the planar dimer ICl, is a bright yellow solid, synthesised by reacting iodine with liquid chlorine at −80 °C; caution is necessary during purification because it easily dissociates to iodine monochloride and chlorine and hence can act as a strong chlorinating agent. Liquid iodine trichloride conducts electricity, possibly indicating dissociation to and ions.\n\nIodine pentafluoride (IF), a colourless, volatile liquid, is the most thermodynamically stable iodine fluoride, and can be made by reacting iodine with fluorine gas at room temperature. It is a fluorinating agent, but is mild enough to store in glass apparatus. Again, slight electrical conductivity is present in the liquid state because of dissociation to and . The pentagonal bipyramidal iodine heptafluoride (IF) is an extremely powerful fluorinating agent, behind only chlorine trifluoride, chlorine pentafluoride, and bromine pentafluoride among the interhalogens: it reacts with almost all the elements even at low temperatures, fluorinates Pyrex glass to form iodine(VII) oxyfluoride (IOF), and sets carbon monoxide on fire.\n\nIodine oxides are the most stable of all the halogen oxides, because of the strong I–O bonds resulting from the large electronegativity difference between iodine and oxygen, and they have been known for the longest time. The stable, white, hygroscopic iodine pentoxide (IO) has been known since its formation in 1813 by Gay-Lussac and Davy. It is most easily made by the dehydration of iodic acid (HIO), of which it is the anhydride. It will quickly oxidise carbon monoxide completely to carbon dioxide at room temperature, and is thus a useful reagent in determining carbon monoxide concentration. It also oxidises nitrogen oxide, ethylene, and hydrogen sulfide. It reacts with sulfur trioxide and peroxydisulfuryl difluoride (SOF) to form salts of the iodyl cation, [IO], and is reduced by concentrated sulfuric acids to iodosyl salts involving [IO]. It may be fluorinated by fluorine, bromine trifluoride, sulfur tetrafluoride, or chloryl fluoride, resulting iodine pentafluoride, which also reacts with iodine pentoxide, giving iodine(V) oxyfluoride, IOF. A few other less stable oxides are known, notably IO and IO; their structures have not been determined, but reasonable guesses are I(IO) and [IO][IO] respectively.\nMore important are the four oxoacids: hypoiodous acid (HIO), iodous acid (HIO), iodic acid (HIO), and periodic acid (HIO or HIO). When iodine dissolves in aqueous solution, the following reactions occur:\n\nHypoiodous acid is unstable to disproportionation. The hypoiodite ions thus formed disproportionate immediately to give iodide and iodate:\n\nIodous acid and iodite are even less stable and exist only as a fleeting intermediate in the oxidation of iodide to iodate, if at all. Iodates are by far the most important of these compounds, which can be made by oxidising alkali metal iodides with oxygen at 600 °C and high pressure, or by oxidising iodine with chlorates. Unlike chlorates, which disproportionate very slowly to form chloride and perchlorate, iodates are stable to disproportionation in both acidic and alkaline solutions. From these, salts of most metals can be obtained. Iodic acid is most easily made by oxidation of an aqueous iodine suspension by electrolysis or fuming nitric acid. Iodate has the weakest oxidising power of the halates, but reacts the quickest.\n\nMany periodates are known, including not only the expected tetrahedral , but also square-pyramidal , octahedral orthoperiodate , [IO(OH)], [IO(OH)], and . They are usually made by oxidising alkaline sodium iodate electrochemically (with lead(IV) oxide as the anode) or by chlorine gas:\n\nThey are thermodymically and kinetically powerful oxidising agents, quickly oxidising Mn to , and cleaving glycols, α-diketones, α-ketols, α-aminoalcohols, and α-diamines. Orthoperiodate especially stabilises high oxidation states among metals because of its very high negative charge of −5. Orthoperiodic acid, HIO, is stable, and dehydrates at 100 °C in a vacuum to metaperiodic acid, HIO. Attempting to go further does not result in the nonexistent iodine heptoxide (IO), but rather iodine pentoxide and oxygen. Periodic acid may be protonated by sulfuric acid to give the cation, isoelectronic to Te(OH) and , and giving salts with bisulfate and sulfate.\n\nWhen iodine dissolves in strong acids, such as fuming sulfuric acid, a bright blue paramagnetic solution including cations is formed. A solid salt of the diiodine cation may be obtained by oxidising iodine with antimony pentafluoride:\nThe salt ISbF is dark blue, and the blue tantalum analogue ITaF is also known. Whereas the I–I bond length in I is 267 pm, that in is only 256 pm as the missing electron in the latter has been removed from an antibonding orbital, making the bond stronger and hence shorter. In fluorosulfuric acid solution, deep-blue reversibly dimerises below −60 °C, forming red rectangular diamagnetic . Other polyiodine cations are not as well-characterised, including bent dark-brown or black and centrosymmetric \"C\" green or black , known in the and salts among others.\n\nThe only important polyiodide anion in aqueous solution is linear triiodide, . Its formation explains why the solubility of iodine in water may be increased by the addition of potassium iodide solution:\nMany other polyiodides may be found when solutions containing iodine and iodide crystallise, such as , , , and , whose salts with large, weakly polarising cations such as Cs may be isolated.\n\nOrganoiodine compounds have been fundamental in the development of organic synthesis, such as in the Hofmann elimination of amines, the Williamson ether synthesis, the Wurtz coupling reaction, and in Grignard reagents.\n\nThe carbon–iodine bond is a common functional group that forms part of core organic chemistry; formally, these compounds may be thought of as organic derivatives of the iodide anion. The simplest organoiodine compounds, alkyl iodides, may be synthesised by the reaction of alcohols with phosphorus triiodide; these may then be used in nucleophilic substitution reactions, or for preparing Grignard reagents. The C–I bond is the weakest of all the carbon–halogen bonds due to the minuscule difference in electronegativity between carbon (2.55) and iodine (2.66). As such, iodide is the best leaving group among the halogens, to such an extent that many organoiodine compounds turn yellow when stored over time due to decomposition into elemental iodine; as such, they are commonly used in organic synthesis, because of the easy formation and cleavage of the C–I bond. They are also significantly denser than the other organohalogen compounds thanks to the high atomic weight of iodine. A few organic oxidising agents like the iodanes contain iodine in a higher oxidation state than −1, such as 2-iodoxybenzoic acid, a common reagent for the oxidation of alcohols to aldehydes, and iodobenzene dichloride (PhICl), used for the selective chlorination of alkenes and alkynes. One of the more well-known uses of organoiodine compounds is the so-called iodoform test, where iodoform (CHI) is produced by the exhaustive iodination of a methyl ketone (or another compound capable of being oxidised to a methyl ketone), as follows:\n\nSome drawbacks of using organoiodine compounds as compared to organochlorine or organobromine compounds is the greater expense and toxicity of the iodine derivatives, since iodine is expensive and organoiodine compounds are stronger alkylating agents. For example, iodoacetamide and iodoacetic acid denature proteins by irreversibly alkylating cysteine residues and preventing the reformation of disulfide linkages.\n\nHalogen exchange to produce iodoalkanes by the Finkelstein reaction is slightly complicated by the fact that iodide is a better leaving group than chloride or bromide. The difference is nevertheless small enough that the reaction can be driven to completion by exploiting the differential solubility of halide salts, or by using a large excess of the halide salt. In the classic Finkelstein reaction, an alkyl chloride or an alkyl bromide is converted to an alkyl iodide by treatment with a solution of sodium iodide in acetone. Sodium iodide is soluble in acetone and sodium chloride and sodium bromide are not. The reaction is driven toward products by mass action due to the precipitation of the insoluble salt.\n\nIodine is the least abundant of the stable halogens, comprising only 0.46 parts per million of Earth's crustal rocks (compare: fluorine 544 ppm, chlorine 126 ppm, bromine 2.5 ppm). Among the eighty-four elements which occur in significant quantities (elements 1–42, 44–60, 62–83, and 90–92), it ranks sixty-first in abundance. Iodide minerals are rare, and most deposits that are concentrated enough for economical extraction are iodate minerals instead. Examples include lautarite, Ca(IO), and dietzeite, 7Ca(IO)·8CaCrO. These are the minerals that occur as trace impurities in the caliche, found in Chile, whose main product is sodium nitrate. In total, they can contain at least 0.02% and at most 1% iodine by weight. Sodium iodate is extracted from the caliche and reduced to iodide by sodium bisulfite. This solution is then reacted with freshly extracted iodate, resulting in comproportionation to iodine, which may be filtered off.\n\nThe caliche was the main source of iodine in the 19th century and continues to be important today, replacing kelp (which is no longer an economically viable source), but in the late 20th century brines emerged as a comparable source. The Japanese Minami Kanto gas field east of Tokyo and the American Anadarko Basin gas field in northwest Oklahoma are the two largest such sources. The brine is hotter than 60 °C from the depth of the source. The brine is first purified and acidified using sulfuric acid, then the iodide present is oxidised to iodine with chlorine. An iodine solution is produced, but is dilute and must be concentrated. Air is blown into the solution to evaporate the iodine, which is passed into an absorbing tower where sulfur dioxide reduces the iodine. The hydrogen iodide (HI) is reacted with chlorine to precipitate the iodine. After filtering and purification the iodine is packed.\n\nThese sources ensure that Chile and Japan are the largest producers of iodine today. Alternatively, the brine may be treated with silver nitrate to precipitate out iodine as silver iodide, which is then decomposed by reaction with iron to form metallic silver and a solution of iron(II) iodide. The iodine may then be liberated by displacement with chlorine.\n\nUnlike chlorine and bromine, which have one significant main use dwarfing all others, iodine is used in many applications of varying importance. About half of all produced iodine goes into various organoiodine compounds; another 15% remains as the pure element, another 15% is used to form potassium iodide, and another 15% for other inorganic iodine compounds. The remaining 5% is for minor uses. Among the major uses of iodine compounds are catalysts, animal feed supplements, stabilisers, dyes, colourants and pigments, pharmaceutical, sanitation (from tincture of iodine), and photography; minor uses include smog inhibition, cloud seeding, and various uses in analytical chemistry.\n\nPotassium tetraiodomercurate(II), KHgI, is also known as Nessler's reagent. It is often used as a sensitive spot test for ammonia. Similarly, CuHgI is used as a precipitating reagent to test for alkaloids. The iodide and iodate anions are often used for quantitative volumetric analysis, for example in iodometry and the iodine clock reaction (in which iodine also serves as a test for starch, forming a dark blue complex), and aqueous alkaline iodine solution is used in the iodoform test for methyl ketones. The iodine test for starch is still used to detect counterfeit banknotes printed on starch-containing paper.\n\nThe spectra of the iodine molecule, I, consists of (not exclusively) tens of thousands of sharp spectral lines in the wavelength range 500-700 nm. It is therefore a commonly used wavelength reference (secondary standard). By measuring with a spectroscopic Doppler-free technique while focusing on one of these lines, the hyperfine structure of the iodine molecule reveals itself. A line is now resolved such that either 15 components, (from even rotational quantum numbers, J), or 21 components (from odd rotational quantum numbers, J) are measurable.\n\nElemental iodine is used as a disinfectant either as the element, or as the water-soluble triiodide anion I generated \"in situ\" by adding iodide to poorly water-soluble elemental iodine (the reverse chemical reaction makes some free elemental iodine available for antisepsis). Elemental iodine may also be used to treat iodine deficiency.\n\nIn the alternative, iodine may be produced from iodophors, which contain iodine complexed with a solubilizing agent (iodide ion may be thought of loosely as the iodophor in triiodide water solutions). Examples of such preparations include:\n\nThe antimicrobial action of iodine is quick and works at low concentrations, and thus it is used in operating theatres. Its specific mode of action is unknown. It penetrates into microorganisms and attacks particular amino acids (such as cysteine and methionine), nucleotides, and fatty acids, ultimately resulting in cell death. It also has an antiviral action, but nonlipid viruses and parvoviruses are less sensitive than lipid enveloped viruses. Iodine probably attacks surface proteins of enveloped viruses, and it may also destabilise membrane fatty acids by reacting with unsaturated carbon bonds.\n\nIn medicine, a saturated solution of potassium iodide is used to treat acute thyrotoxicosis. It is also used to block uptake of iodine-131 in the thyroid gland (see isotopes section above), when this isotope is used as part of radiopharmaceuticals (such as iobenguane) that are not targeted to the thyroid or thyroid-type tissues.\n\nIodine-131 (usually as iodide) is a component of nuclear fallout, and is particularly dangerous owing to the thyroid gland's propensity to concentrate ingested iodine and retain it for periods longer than this isotope's radiological half-life of eight days. For this reason, people at risk of exposure to environmental radioactive iodine (iodine-131) in fallout may be instructed to take non-radioactive potassium iodide tablets. The typical adult dose is one 130 mg tablet per 24 hours, supplying 100 mg (100,000 micrograms) of ionic iodine. (The typical daily dose of iodine for normal health is of order 100 micrograms; see \"Dietary Intake\" below.) Ingestion of this large dose of non-radioactive iodine minimises the uptake of radioactive iodine by the thyroid gland.\nAs an element with high electron density and atomic number, iodine absorbs X-rays weaker than 33.3 keV due to the photoelectric effect of the innermost electrons. Organoiodine compounds are used with intravenous injection as X-ray radiocontrast agents. This application is often in conjunction with advanced X-ray techniques such as angiography and CT scanning. At present, all water-soluble radiocontrast agents rely on iodine.\n\nThe production of ethylenediamine dihydroiodide, provided as a nutritional supplement for livestock, consumes a large portion of available iodine. Another significant use is a catalyst for the production of acetic acid by the Monsanto and Cativa processes. In these technologies, which support the world's demand for acetic acid, hydroiodic acid converts the methanol feedstock into methyl iodide, which undergoes carbonylation. Hydrolysis of the resulting acetyl iodide regenerates hydroiodic acid and gives acetic acid.\n\nInorganic iodides find specialised uses. Titanium, zirconium, hafnium, and thorium are purified by the van Arkel process, which involves the reversible formation of the tetraiodides of these elements. Silver iodide is a major ingredient to traditional photographic film. Thousands of kilograms of silver iodide are used annually for cloud seeding to induce rain.\n\nThe organoiodine compound erythrosine is an important food coloring agent. Perfluoroalkyl iodides are precursors to important surfactants, such as perfluorooctanesulfonic acid.\n\nIodine is an essential element for life and, at atomic number \"Z\" = 53, is the heaviest element commonly needed by living organisms. (Lanthanum and the other lanthanides, as well as tungsten with \"Z\" = 74, are used by a few microorganisms.) It is required for the synthesis of the growth-regulating thyroid hormones thyroxine and triiodothyronine (T and T respectively, named after their number of iodine atoms). A deficiency of iodine leads to decreased production of T and T and a concomitant enlargement of the thyroid tissue in an attempt to obtain more iodine, causing the disease known as simple goitre. The major form of thyroid hormone in the blood is thyroxine (T), which has a longer half-life than T. In humans, the ratio of T to T released into the blood is between 14:1 and 20:1. T is converted to the active T (three to four times more potent than T) within cells by deiodinases (5'-iodinase). These are further processed by decarboxylation and deiodination to produce iodothyronamine (Ta) and thyronamine (Ta'). All three isoforms of the deiodinases are selenium-containing enzymes; thus dietary selenium is essential for T production.\n\nIodine accounts for 65% of the molecular weight of T and 59% of T. Fifteen to 20 mg of iodine is concentrated in thyroid tissue and hormones, but 70% of all iodine in the body is found in other tissues, including mammary glands, eyes, gastric mucosa, fetal thymus, cerebro-spinal fluid and choroid plexus, arterial walls, the cervix, and salivary glands. In the cells of those tissues, iodide enters directly by sodium-iodide symporter (NIS). The action of iodine in mammary tissue is related to fetal and neonatal development, but in the other tissues, it is (at least) partially unknown.\n\nRecommendations by the United States Institute of Medicine are between 110 and 130 µg for infants up to 12 months, 90 µg for children up to eight years, 130 µg for children up to 13 years, 150 µg for adults, 220 µg for pregnant women and 290 µg for lactation. The Tolerable Upper Intake Level (UL) for adults is 1,100 μg/day. This upper limit was assessed by analyzing the effect of supplementation on thyroid-stimulating hormone.\n\nThe thyroid gland needs no more than 70 μg/day to synthesise the requisite daily amounts of T4 and T3. The higher recommended daily allowance levels of iodine seem necessary for optimal function of a number of body systems, including lactating breast, gastric mucosa, salivary glands, brain cells, choroid plexus, thymus, and arterial walls.\n\nNatural sources of dietary iodine include seafood, such as fish, seaweeds (such as kelp) and shellfish, dairy products and eggs so long as the animals received enough iodine, and plants grown on iodine-rich soil. Iodised salt is fortified with iodine in the form of sodium iodide.\n\nAs of 2000, the median intake of iodine from food in the United States was 240 to 300 μg/day for men and 190 to 210 μg/day for women. The general US population has adequate iodine nutrition, with women of childbearing age and pregnant women having a possible mild risk of deficiency. In Japan, consumption was considered much higher, ranging between 5,280 μg/day to 13,800 μg/day from dietary seaweed or kombu kelp, often in the form of Kombu Umami extracts for soup stock and potato chips. However, new studies suggest that Japan's consumption is closer to 1,000–3,000 μg/day. The adult UL in Japan was last revised to 3,000 µg/day in 2015.\n\nAfter iodine fortification programs such as iodisation of salt have been implemented, some cases of iodine-induced hyperthyroidism have been observed (so-called Jod-Basedow phenomenon). The condition seems to occur mainly in people over forty, and the risk appears higher when iodine deficiency is severe and the initial rise in iodine intake is high.\n\nIn areas where there is little iodine in the diet, typically remote inland areas and semi-arid equatorial climates where no marine foods are eaten, iodine deficiency gives rise to hypothyroidism, symptoms of which are extreme fatigue, goitre, mental slowing, depression, weight gain, and low basal body temperatures. Iodine deficiency is the leading cause of preventable intellectual disability, a result that occurs primarily when babies or small children are rendered hypothyroidic by a lack of the element. The addition of iodine to table salt has largely eliminated this problem in the wealthier nations, but iodine deficiency remains a serious public health problem today in the developing world. Iodine deficiency is also a problem in certain areas of Europe. Information processing, fine motor skills, and visual problem solving are improved by iodine repletion in moderately iodine-deficient children.\n\nElemental iodine (I) is toxic if taken orally undiluted. The lethal dose for an adult human is 30 mg/kg, which is about 2.1–2.4 grams for a human weighing 70 to 80 kg (even if experiments on rats demonstrated that these animals could survive after eating a 14000 mg/kg dose). Excess iodine can be more cytotoxic in the presence of selenium deficiency. Iodine supplementation in selenium-deficient populations is, in theory, problematic, partly for this reason. The toxicity derives from its oxidizing properties, through which it denaturates proteins (including enzymes).\n\nElemental iodine is also a skin irritant, and direct contact with skin can cause damage and solid iodine crystals should be handled with care. Solutions with high elemental iodine concentration, such as tincture of iodine and Lugol's solution, are capable of causing tissue damage if used in prolonged cleaning or antisepsis; similarly, liquid Povidone-iodine (Betadine) trapped against the skin resulted in chemical burns in some reported cases.\n\nPeople can be exposed to iodine in the workplace by inhalation, ingestion, skin contact, and eye contact. The Occupational Safety and Health Administration (OSHA) has set the legal limit (Permissible exposure limit) for iodine exposure in the workplace at 0.1 ppm (1 mg/m) during an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a Recommended exposure limit (REL) of 0.1 ppm (1 mg/m) during an 8-hour workday. At levels of 2 ppm, iodine is immediately dangerous to life and health.\n\nSome people develop a hypersensitivity to products and foods containing iodine. Applications of tincture of iodine or Betadine can cause rashes, sometimes severe. Parenteral use of iodine-based contrast agents (see above) can cause reactions ranging from a mild rash to fatal anaphylaxis. Such reactions have led to the misconception (widely held, even among physicians) that some people are allergic to iodine itself; even allergies to iodine-rich seafood have been so construed. In fact, there has never been a confirmed report of a true iodine allergy, and an allergy to elemental iodine or simple iodide salts is theoretically impossible. Hypersensitivity reactions to products and foods containing iodine are apparently related to their other molecular components; thus, a person who has demonstrated an allergy to one food or product containing iodine may not have an allergic reaction to another. Patients with various food allergies (shellfish, egg, milk, etc.) or asthma are more likely to suffer reactions to contrast media containing iodine. As with all medications, the patient's allergy history should be questioned and consulted before any containing iodine are administered.\n"}
{"id": "14751", "url": "https://en.wikipedia.org/wiki?curid=14751", "title": "IKEA", "text": "IKEA\n\nIKEA (, ) is a Swedish-founded multinational group that designs and sells , kitchen appliances and home accessories, among other useful goods and occasionally home services. It has been the world's largest furniture retailer since at least 2008. It was founded in Sweden in 1943 by 17-year-old carpenter, Ingvar Kamprad, who was listed by \"Forbes\" in 2015 as one of the ten richest people in the world, worth more than $40 billion. The company's name is an acronym that consists of the initials of Ingvar Kamprad (name of founder), Elmtaryd (the farm where he grew up), and Agunnaryd (his hometown in Småland, southern Sweden).\n\nThe company is known for its modernist designs for various types of appliances and furniture, and its interior design work is often associated with an eco-friendly simplicity. In addition, the firm is known for its attention to cost control, operational details, and continuous product development, corporate attributes that allowed IKEA to lower its prices by an average of two to three percent over the decade to 2010 during a period of global expansion. The IKEA group has a complex corporate structure, which members of the European Parliament have alleged was designed to avoid over €1 billion in tax payments over the 2009-2014 period. It is controlled by several foundations based in the Netherlands, and Liechtenstein.\n\n, IKEA owns and operates 415 stores in 49 countries. In fiscal year 2016, €36.4 billion (US$42.4 billion) worth of goods were sold, a total that represented a 7.6 percent increase over 2015. The IKEA website contains about 12,000 products and is the closest representation of the entire IKEA range. There were over 2.1 billion visitors to IKEA's websites in the year from September 2015 to August 2016. The company is responsible for approximately 1% of world commercial-product wood consumption, making it one of the largest users of wood in the retail sector.\n\nMost of IKEA's stores and factories were previously owned by INGKA, a holding company controlled by the Stichting INGKA Foundation, one of the 40 wealthiest foundations in the world.\n\nIngvar Kamprad founded IKEA in 1943 as a mostly mail-order sales business. It began to sell furniture five years later. The first Möbel-IKÉA store was opened in Älmhult, Småland, in 1958 (Möbel means \"furniture\" in Swedish). The first stores outside Sweden were opened in Norway (1963) and Denmark (1969). The stores spread to other parts of Europe in the 1970s, with the first store outside Scandinavia opening in Switzerland (1973), followed by West Germany (1974).\nAmid a high level of success, the company's West German executives accidentally opened a store in Konstanz in 1973 instead of Koblenz. Later that decade, stores opened in other parts of the world, such as Japan (1974), Australia, Canada, Hong Kong (1975), and Singapore (1978). IKEA further expanded in the 1980s, opening stores in countries such as France and Spain (1981), Belgium (1984), the United States (1985), the United Kingdom (1987), and Italy (1989). The company later expanded into more countries in the 1990s and 2000s. Germany, with 53 stores, is IKEA's biggest market, followed by the United States, with 50 stores. At the end of the 2009 financial year, the IKEA group operated 267 stores in 25 countries. The first IKEA store in Latin America opened on 17 February 2010 in Santo Domingo, Dominican Republic. , the company's presence in developing countries remains minimal.\nIn December 2014, the world's largest IKEA store at , opened near the KTX Gwangmyeong Station, located at the heart of South Korea's Seoul Capital Area. It opened the world's fourth largest store (and the largest standalone store in the world) in Goyang, Gyeonggi on October 2017 at 52,199 square meters. IKEA plans to open two more stores of such scale in the Seoul Capital Area, along with a store in Daejeon and Busan by 2020.\n\nThe largest store in the Southern Hemisphere is located in Tempe, Sydney, Australia with an area of . The biggest store in North America is located in Montreal, in the province of Quebec, Canada. The store was opened in 1986 in the Ville-St-Laurent area, and was completely renovated and expanded in 2012-2013. Built in 1986, the store's initial area was , while the renovated store now measures .\n\nIn March 2013, IKEA opened its first outlet in Qatar, after a delay of several months. Like others in the Gulf Cooperation Council, the Doha outlet is operated by the Al-Futtaim Group. In August 2013, the first store in the Baltic States was opened in the Vilnius region of Lithuania. Construction of the store commenced in 2011 and the store employs over 200 people. It is the biggest furniture-selling mall in the Baltic states.\n\nIn 2014, IKEA opened its first warehouse in Croatia, near Zagreb. The warehouse opened its doors on 21 August 2014. The shopping center in Zagreb with an area of is one of the five biggest in Europe and among the 10 biggest IKEA stores in the world.\n\nOn 26 March 2015, a set of 19 storage buildings holding various film and TV props, owned by Western Studio Services, were demolished in favor of construction of the largest IKEA in the United States. Located in Burbank, California, this store replaced Burbank's existing IKEA located less than a mile away from the new construction site, which was nearly double the size of the existing store (456,000 sq ft). The existing store ceased operations on 4 February 2017, and the grand opening of the new store took place on 8 February 2017.\n\nIKEA began constructing its first store in India on 11 August 2016. The 400,000 sq ft store in Hyderabad was built at a cost of , and opened on 9 August 2018. IKEA purchased 610,000 sq ft of land in Bengaluru, Karnataka next to a Namma Metro station where the company plans on opening their third store in India later the same year. The store in Bengaluru will be IKEA's biggest in Asia. The company began construction of its second Indian store at Navi Mumbai, Maharashtra on 18 May 2017 and it is scheduled to open in January 2019. IKEA plans to open 5 stores in the state of Maharashtra and also build a distribution centre in Pune. Per Indian regulations, IKEA will have to locally source at least 30% of the products sold at its Indian stores. The company plans to open 25 stores across 8 cities in the country by 2025. It predicts that Hyderabad, Delhi, Mumbai and Bangalore will be the company's largest markets, while Chennai, Pune, Ahmedabad, Surat and smaller cities will also receive IKEA stores. On 1 November 2017 IKEA bought 10 acres of land in Gurugram to expand operations in Northern India.\n\nOn 31 January 2017, IKEA announced that it will open a new store in Latvia. It will be the second store to open in the Baltic states. The store will be located near Riga and is planned to open in August 2018.\n\nOn 10 August 2017, IKEA opened its first store in Serbia and 400th store overall. IKEA invested €70 million, and plans to open a second store in Belgrade in the future.\n\nOn 16 November 2017, IKEA opened its third store in Malaysia in Johor Bahru, Malaysia. It was the largest store in Southeast Asia, spanning 502,815 sq ft.\n\nOn 15 March 2018, IKEA opened its second store in Thailand in Bangkok, Thailand. It is now the largest store in Southeast Asia ahead of Johor Bahru, Malaysia, with a total area of 50,278 m and 1900 car park spaces. It's also the first store with cashiers installed on all floors.\n\nOn September 5 2018 IKEA opened its first store in the Kingdom of Bahrain. The store is located in Salmabad.\n\nIKEA was awarded the Nordic Language Award of 2017 for introducing Scandinavian language and culture to a global audience.\n\nFounder Ingvar Kamprad died on 27 January 2018.\n\nIn 2020, IKEA plans to open its largest store in the world in Manila, Philippines, which will have an area of .\n\nIKEA will enter Chile in 2020, Colombia and Peru in 2021 after reaching an agreement with the Chilean company Falabella.\n\nOlder IKEA stores are usually blue buildings with yellow accents (also Sweden's national colours). They are often designed in a one-way layout, leading customers counter clockwise along what IKEA calls \"the long natural way\" designed to encourage the customer to see the store in its entirety (as opposed to a traditional retail store, which allows a customer to go directly to the section where the desired goods and services are displayed). There are often shortcuts to other parts of the showroom. Newer IKEA stores, like the one in Mönchengladbach, Germany, make more use of glass, both for aesthetics and functionality. Skylights are also now common in the self-serve warehouses; natural lighting reduces energy costs, improves worker morale and gives a better impression of the products.\n\nThe sequence first involves going through the furniture showrooms making note of selected items. The customer then collects a shopping cart and proceeds to an open-shelf \"Market Hall\" warehouse for smaller items, then visits the self-service furniture warehouse to collect previously noted showroom products in flat pack form. Sometimes, they are directed to collect products from an external warehouse on the same site or at a site nearby after purchase. Finally, customers pay for their products at a cash register.\n\nToday, most stores follow the same layout of having the showroom upstairs with the marketplace and self-service warehouse downstairs. Some stores are single level, while others have separate warehouses to allow more stock to be kept on-site. Single-level stores are found predominantly in areas where the cost of land would be less than the cost of building a 2-level store, such as the Saarlouis, Germany and Haparanda, Sweden locations. Some stores have dual-level warehouses with machine-controlled silos to allow large quantities of stock to be accessed throughout the selling day.\n\nMost IKEA stores offer an \"as-is\" area at the end of the warehouse, just before the cash registers. Returned, damaged and formerly showcased products are displayed here and sold with a significant discount, but also with a no-returns policy. Most IKEA stores communicate the IKEA policy on environmental issues in this part of the store. The area, which is painted red, is named according to local customs, in the United Kingdom this is referred to as \"Bargain Corner\", in Sweden \"FYND\" (Bargains) and in Denmark, \"Rodebutikken\" (Rummage boutique).\n\nIKEA uses a sales technique called \"bulla bulla\" in which a bunch of items are purposefully jumbled in bins, to create the impression of volume, and therefore, inexpensiveness.\n\nIKEA's own restaurant are all over the world and the taste is cross-cultural. Every store includes a restaurant serving traditional Swedish food, including potatoes with Swedish meatballs. In Kuala Lumpur, Malaysia, the usual boiled or mashed potatoes have been replaced with French fries; meanwhile in Indonesia, the usual Swedish Meatballs recipe are changed to accommodate the country's Halal requirements. Besides these Swedish foods, hot dogs and drinks are also sold, along with a few varieties of the local cuisine, and beverages such as lingonberry juice. Also items such as \"prinsesstårta\" (princess cake) are sold as desserts. Stores in Israel sell kosher food with under rabbinical supervision. The kosher restaurants are separated into dairy and meat areas; falafel and non-dairy ice cream are available at the exit. IKEA stores in Saudi Arabia, Kuwait, Qatar and the United Arab Emirates serve chicken shawarma at the exit café as well as beef hot dogs, while in United Kingdom, a Quorn hot dog is available in the exit café. Coffee, soft drinks, and tea refills are free, as like in Sweden within store premises. All of the stores are equipped with Nordic fruit drinks since 2017, replacing Coca-Cola and Pepsi.\n\nIn many locations, the IKEA restaurants open daily before the rest of the store and serve an inexpensive breakfast.\n\nEvery store also has a Swedish Food Market that, until 2011, sold branded Swedish prepared specialist foods, such as meatballs, packages of gravy, lingonberry jam, various biscuits and crackers, and salmon and fish roe spread. Later, IKEA replaced most of the branded foods and extended its product range with the introduction of the IKEA food label. The new label has a variety of items including chocolates, meatballs, jams, pancakes, salmon, along with various drinks. All food products are based on Swedish recipes and traditions.\n\nEvery store has a kids play area, named Småland (Swedish for \"small lands\"; it is also the Swedish province where Kamprad was born). Parents drop off their children at a gate to the playground, and pick them up after they arrive at another entrance. In some stores, parents are given free pagers by the on-site staff, which the staff can use to summon parents whose children need them earlier than expected; in others, staff summon parents through announcements over the in-store public address system or by calling them on their cellphones.\n\nThe vast majority of IKEA stores are located outside of city centers, primarily because of land cost and traffic access. Several smaller store formats have been unsuccessfully tested in the past (the \"midi\" concept in the early '90s, which was tested in Ottawa and Heerlen with , or a \"boutique\" shop in Manhattan). A new format for a full-size, city centre store was introduced with the opening of the Manchester (United Kingdom) store, situated in Ashton-under-Lyne in 2006. Another store, in Coventry opened in December 2007. The store has seven floors and a different flow from other IKEA stores. IKEA's Southampton store which opened in February 2009 is also in the city centre and built in an urban style similar to the Coventry store. IKEA built these stores in response to UK government restrictions blocking retail establishment outside city centres.\n\nIn Hong Kong, where shop space is limited and costly, IKEA has opened three outlets in the city, most of which have the one-way layout. They are part of shopping malls, and while being tiny compared to common store design, are huge by Hong Kong standards.\n\nIn 2015, IKEA announced that it would be attempting a smaller store design at several locations in Canada. This modified store will feature only a display gallery and small warehouse. One location planned for Kitchener is in the place formerly occupied by a Sears Home store. The warehouses will not keep furniture stocked, and so customers will not be able to drop in to purchase and leave with furniture the same day. Instead, they will purchase the furniture in advance online or in store and order the furniture delivered to one of the new stores, for a greatly reduced rate. IKEA claims that this new model will allow them to expand quickly into new markets rather than spending years opening a full-size store.\n\nRather than being sold pre-assembled, much of IKEA's furniture is designed to be assembled by the customer. The company claims that this helps reduce costs and use of packaging by not shipping air; the volume of a bookcase, for example, is considerably less if it is shipped unassembled rather than assembled. This is also more practical for customers using public transport, because flat packs can be more easily carried.\n\nIKEA contends that it has been a pioneering force in sustainable approaches to mass consumer culture. Kamprad calls this \"democratic design,\" meaning that the company applies an integrated approach to manufacturing and design (see also environmental design). In response to the explosion of human population and material expectations in the 20th and 21st centuries, the company implements economies of scale, capturing material streams and creating manufacturing processes that hold costs and resource use down, such as the extensive use of Medium-Density Fiberboard (\"MDF\"), also called \"particle board.\" It is an engineered wood fibre glued under heat and pressure to create a building material of superior strength which is resistant to warp. IKEA uses cabinet-grade and furniture-grade MDF in all of its MDF products, such as PAX wardrobes and kitchen cupboards. IKEA also uses wood, plastic, and other materials for furniture and other products. The intended result is flexible, adaptable home furnishings, scalable both to smaller homes and dwellings as well as large houses.\nNot all furniture is stocked at the store level, such as particular sofa colours needing to be shipped from a warehouse to the customer's home (for a delivery charge). The item can also be shipped from the warehouse to the store. Some stores charge an extra fee for this service, but not all.\n\nNotable items of IKEA furniture include the Poäng armchair, the Billy bookcase and the Klippan sofa, all of which have sold by the tens of millions since the late 1970s.\n\nIKEA products are identified by one-word (rarely two-word) names. Most of the names are Scandinavian in origin. Although there are some exceptions, most product names are based on a special naming system developed by IKEA. Company founder Kamprad was dyslexic and found that naming the furniture with proper names and words, rather than a product code, made the names easier to remember.\nFor example, \"DUKTIG\" (meaning: clever, well-behaved) is a line of children's toys, \"OSLO\" is a name of a bed, \"BILLY\" (a Swedish masculine name) is a popular bookcase, \"DINERA\" (meaning: (to) dine) for tableware, \"KASSETT\" (meaning: cassette) for media storage. One range of office furniture is named \"EFFEKTIV\" (meaning: efficient, effective), \"SKÄRPT\" (meaning: sharp or clever) is a line of kitchen knives.\n\nA notable exception is the \"IVAR\" shelving system, which dates back to the early 1970s. This item is named after the item's designer.\n\nSome of IKEA's Swedish product names have amusing or unfortunate connotations in other languages, sometimes resulting in the names being withdrawn in certain countries. Notable examples for English include the \"Jerker\" computer desk (discontinued several years ago ), \"Fukta\" plant spray, \"Fartfull\" workbench, and \"Lyckhem\" (meaning bliss). Kitchen legs are called FAKTUM (called AKURUM in the United States). The latest addition is the new \"Askholmen\" outdoor suite. Similar blunders happen with other multinational companies.\n\nIn 2016 IKEA started a move into the smart home business. The IKEA TRÅDFRI smart lighting kit was one of the first ranges signalling this change. IKEA's media team has confirmed that smart home project will be a big move. They have also started a partnership with Philips Hue. The wireless charging furniture, integrating wireless Qi charging into everyday furniture, is another strategy for the smart home business.\n\nA collaboration to build Sonos' smart speaker technology into furniture sold by IKEA was announced in December 2017. The first products resulting from the collaboration will launch in 2019.\n\nIKEA has also expanded its product base to include flat-pack houses and apartments, in an effort to cut prices involved in a first-time buyer's home. (This practice is not new; the defunct Canadian retailer Eaton's sold houses in a similar fashion), The IKEA product, named BoKlok was launched in Sweden in 1996 in a joint venture with Skanska. Now working in the Nordic countries and in the UK, sites confirmed in England include London, Ashton-under-Lyne, Leeds, Gateshead, Warrington and Liverpool.\n\nAt the end of September 2013, the company announced that solar panel packages, so-called \"residential kits\", for houses will be sold at 17 UK stores by mid-2014. The decision followed a successful pilot project at the Lakeside IKEA store, whereby one photovoltaic system was sold almost every day. The solar CIGS panels are manufactured by Solibro, a German-based subsidiary of the Chinese company Hanergy. By the end of 2014, IKEA began to sell Solibro's solar residential kits in the Netherlands and in Switzerland.\n\nIn November 2015 IKEA ended its contract with Hanergy and in April 2016 started working with Solarcentury\n\nIKEA announced in April 2016, that it was doing a second attempt with SolarCity to sell solar panels in the United Kingdom. It allows users to be able to order them online and starting with three stores and by the end of summer available in all United Kingdom stores.\n\nIKEA owns and operates the MEGA Family Shopping Centre chain in Russia.\n\nOn 8 August 2008, IKEA UK launched a virtual mobile phone network called IKEA Family Mobile, which ran on T-Mobile. At launch it was the cheapest pay-as-you-go network in the UK.\nIn June 2015 the network announced that its services would cease to operate from 31 August 2015.\n\n, IKEA is in joint venture with TCL to provide Uppleva integrated HDTV and entertainment system product.\n\nIn mid-August 2012, the company announced that it will establish a chain of 100 economy hotels in Europe but, unlike its few existing hotels in Scandinavia, they will not carry the IKEA name, nor will they use IKEA furniture and furnishings – they will be operated by an unnamed international group of hoteliers.\n\nIn September 2017, IKEA announced they would be acquiring San Francisco-based TaskRabbit. The deal should be completed by the end of October 2017 and TaskRabbit will remain an independent company.\n\nIKEA is owned and operated by a complicated array of not-for-profit and for-profit corporations. The corporate structure is divided into two main parts: operations and franchising.\n\nThe ownership of Inter IKEA Systems is exceedingly complicated and not publicly known. Inter IKEA Systems is owned by Inter IKEA Holding, a company registered in Luxembourg. The Inter IKEA Holding, in turn, is owned by the Interogo Foundation, based in Liechtenstein. In 2016, the INGKA Holding sold its design, manufacturing and logistics subsidiaries to the Inter IKEA Holding.\n\nIn June 2013, Ingvar Kamprad resigned from the board of Inter IKEA Holding SA and his youngest son Mathias Kamprad replaced Per Ludvigsson as the chairman of the holding company. Following his decision to step down, the 87-year-old founder explained, \"I see this as a good time for me to leave the board of Inter IKEA Group. By that we are also taking another step in the generation shift that has been ongoing for some years.\" After the 2016 company restructure, Inter IKEA Holding SA no longer exists. Mathias Kamprad became board member of the Inter IKEA Group and the Interogo Foundation. Mathias and his two older brothers, who also have leadership roles at IKEA, work on the corporation's overall vision and long-term strategy.\n\nAlong with helping IKEA make non-taxable profit, IKEA's complicated corporate structure allowed Kamprad to maintain tight control over the operations of INGKA Holding, and thus the operation of most IKEA stores. The INGKA Foundation's five-person executive committee was chaired by Kamprad. It appoints board of INGKA Holding, approves any changes to INGKA Holding's bylaws, and has the right to preempt new share issues. If a member of the executive committee quits or dies, the other four members appoint his or her replacement.\n\nIn Kamprad's absence the foundation's bylaws include specific provisions requiring it to continue operating the INGKA Holding group and specifying that shares can be sold only to another foundation with the same objectives as the INGKA Foundation.\n\nThe net profit of IKEA Group (which does not include Inter IKEA systems) in fiscal year 2009 (after paying franchise fees to Inter IKEA systems) was €2.538 billion on sales of €21.846 billion. Because INGKA Holding is owned by the nonprofit INGKA Foundation, none of this profit is taxed. The foundation's nonprofit status also means that the Kamprad family cannot reap these profits directly, but the Kamprads do collect a portion of IKEA sales profits through the franchising relationship between INGKA Holding and Inter IKEA Systems.\n\nInter IKEA Systems collected €631 million of franchise fees in 2004, but reported pre-tax profits of only €225 million in 2004. One of the major pre-tax expenses that Inter IKEA systems reported was €590 million of \"other operating charges\". IKEA has refused to explain these charges, but Inter IKEA Systems appears to make large payments to I.I. Holding, another Luxembourg-registered group that, according to \"The Economist,\" \"is almost certain to be controlled by the Kamprad family.\" I.I. Holding made a profit of €328 million in 2004.\n\nIn 2004, the Inter IKEA group of companies and I.I. Holding reported combined profits of €553m and paid €19m in taxes, or approximately 3.5 percent. In 2013 the \"Daily Mail\" media publication reported that the IKEA subsidiary Swedwood had grown between 20-30% per year since its inception in 1991.\n\nPublic Eye (formerly known as Erklärung von Bern, literally \"The Berne Declaration\"), a non-profit organisation in Switzerland that promotes corporate responsibility, has formally criticised IKEA for its tax avoidance strategies. In 2007, the organisation nominated IKEA for one of its Public Eye \"awards\", which highlight corporate irresponsibility and are announced during the World Economic Forum in Davos, Switzerland.\n\nIn a company statement emailed on 14 October 2013, IKEA's full-year sales rose 3.1 percent due in part to growth in Russia and China. IKEA's revenue total rose to US$37.9 billion (27.9 billion euros), with significant growth also recorded in North America.\n\nIn February 2016, the Greens / EFA group in the European Parliament issued a report entitled \"IKEA: Flat Pack Tax Avoidance\" on the tax planning strategies of IKEA and their possible use to avoid tax in several European countries. The report was sent to Pierre Moscovici, the European Commissioner for Economic and Financial Affairs, Taxation and Customs, and Margrethe Vestager, the European Commissioner for Competition, expressing the hope that it would be of use to them in their respective roles \"to advance the fight for tax justice in Europe.\"\n. Sales jumped 17 per cent to almost €132 million in the 12 months to the end of August 2015 \n\nAlthough IKEA household products and furniture are designed in Sweden, they are largely manufactured in developing countries to keep costs down. For most of its products, the final assembly is performed by the end-user (consumer).\n\nSwedwood, an IKEA subsidiary, handles production of all of the company's wood-based products, with the largest Swedwood factory located in Southern Poland. According to the subsidiary, over 16,000 employees across 50 sites in 10 countries manufacture the 100 million pieces of furniture that IKEA sells annually. IKEA furniture uses the hardwood alternative particle board. Hultsfred, a factory in southern Sweden, is the company's sole supplier.\n\nIn September 2018, The United States Consumer Product Safety Commission advised the public about IKEA CALYPSO Ceiling Lamps due to impact and laceration hazards.\n\nDuring the 1980s, IKEA kept its costs down by using production facilities in East Germany. A portion of the workforce at those factories consisted of political prisoners. This fact, revealed in a report by Ernst & Young commissioned by the company, resulted from intermingling of criminals and political dissidents in the state-owned production facilities IKEA contracted with, a practice which was generally known in West Germany. IKEA was one of a number of companies, including West German firms, which benefited from this practice. The investigation resulted from attempts by former political prisoners to obtain compensation. In November 2012, IKEA admitted being aware at the time of the possibility of use of forced labor and failing to exercise sufficient control to identify and avoid it. A summary of the Ernst & Young report was released on 16 November 2012.\n\nIKEA was named one of the 100 Best Companies for Working Mothers in 2004 and 2005 by \"Working Mothers\" magazine. It ranked 80 in Fortune's 200 Best Companies to Work For in 2006 and in October 2008, IKEA Canada LP was named one of \"Canada's Top 100 Employers\" by Mediacorp Canada Inc.\n\nIn 2012, IKEA in France was accused by the independent newspaper \"Le Canard enchaîné\" and the investigative website \"Mediapart\" of spying on its employees and clients by illegally accessing French police records. The head of risk management at IKEA feared his employees were anti-globalists or potential ecoterrorists.\n\nAfter initial environmental issues like the highly publicized formaldehyde scandals in the early 1980s and 1992, IKEA took a proactive stance on environmental issues and tried to prevent future incidents through a variety of measures. In 1990, IKEA invited Karl-Henrik Robèrt, founder of the Natural Step, to address its board of directors. Robert's system conditions for sustainability provided a strategic approach to improving the company's environmental performance. In 1990, IKEA adopted the Natural Step framework as the basis for its environmental plan. This led to the development of an Environmental Action Plan, which was adopted in 1992. The plan focused on structural change, allowing IKEA to \"maximize the impact of resources invested and reduce the energy necessary to address isolated issues.\" The environmental measures taken include the following:\n\n\nIn 2000 IKEA introduced its code of conduct for suppliers that covers social, safety and environmental questions. Today IKEA has around 60 auditors who perform hundreds of supplier audits every year. The main purpose of these audits is to make sure that the IKEA suppliers follow the law in each country where they are based. Most IKEA suppliers fulfill the law today with exceptions for some special issues, one being excessive working hours in Asia, in countries such as China and India.\nMore recently, IKEA has stopped providing plastic bags to customers, but offers reusable bags for sale. The IKEA restaurants also only offer reusable plates, knives, forks, spoons, etc. Toilets in some IKEA WC-rooms have been outfitted with dual-function flushers. IKEA has recycling bins for compact fluorescent lamps (CFLs), energy saving bulbs and batteries.\nIn 2001 IKEA was one of the first companies to operate its own cross-border goods trains through several countries in Europe.\n\nIn August 2008, IKEA also announced that it had created IKEA GreenTech, a €50 million venture capital fund. Located in Lund (a university town in Sweden), it will invest in 8–10 companies in the coming five years with focus on solar panels, alternative light sources, product materials, energy efficiency and water saving and purification. The aim is to commercialise green technologies for sale in IKEA stores within 3–4 years.\n\nTo make IKEA a more sustainable company, a product life cycle was created. For the idea stage, products should be flat-packed so that more items can be shipped at once; products should also be easier to dismantle and recycle. Raw materials are used, and since wood and cotton are two of IKEA's most important manufacturing products, the company works with environmentally friendly forests and cotton, whereby the excessive use of chemicals and water is avoided.\n\nIKEA stores recycle waste and many run on renewable energy. All employees are trained in environmental and social responsibility, while public transit is one of the priorities when the location of stores is considered. Also, the coffee and chocolate served at IKEA stores is UTZ Certified.\n\nThe last stage of the life cycle is the end of life. Most IKEA stores recycle light bulbs and drained batteries, and the company is also exploring the recycling of sofas and other home furnishing products. According to IKEA's 2012 \"Sustainability Report\", 23% of all wood that the company uses meets the standards of the Forest Stewardship Council, and the report states that IKEA aims to double this percentage by 2017. The report also states that IKEA does not accept illegally logged wood and supports 13 World Wide Fund for Nature (WWF) projects.\nOn 17 February 2011, IKEA announced its plans to develop a wind farm in Dalarna County, Sweden, furthering its goal of using only renewable energy to fuel its operations. , 17 United States IKEA stores are powered by solar panels, with 22 additional installations in progress, and IKEA owns the 165 MW Cameron Wind farm in Cameron County on the South Texas coast and a 42 MW coastal wind farm in Finland.\n\nIn 2011, the company examined its wood consumption and noticed that almost half of its global pine and spruce consumption was for the fabrication of pallets. The company consequently started a transition to the use of paper pallets and the \"Optiledge system\". The OptiLedge product is totally recyclable, made from 100% virgin high-impact copolymer polypropylene (PP). The system is a \"unit load alternative to the use of a pallet. The system consists of the OptiLedge (usually used in pairs), aligned and strapped to the bottom carton to form a base layer upon which to stack more product. Corner boards are used when strapping to minimize the potential for package compression.\" The conversion began in Germany and Japan, before its introduction into the rest of Europe and North America. The system has been marketed to other companies, and IKEA has formed the OptiLedge company to manage and sell the product.\n\nIKEA has expanded its sustainability plan in the UK to include electric car charge points for customers at all locations by the end of 2013. The effort will include Nissan and Ecotricity and promise to deliver an 80% charge in 30 minutes.\n\nIn February 2014, IKEA in the UK announced that from 2016 they will only sell energy-efficient LED lightbulbs, lamps and light fixtures. LED lightbulbs use as much as only 15% of the power of a regular incandescent light bulb.\n\n, IKEA has signed on with 25 other companies to participate in the British Retail Consortium's Better Retail Better World initiative, which challenges companies to meet objectives outlined by the United Nations Sustainable Development Goals.\n\nThe INGKA Foundation is officially dedicated to promoting \"innovations in architecture and interior design.\" The net worth of the foundation exceeded the net worth of the much better known Bill & Melinda Gates Foundation (now the largest private foundation in the world) for a period. However, most of the Group's profit is spent on investment.\n\nIKEA is involved in several international charitable causes, particularly in partnership with UNICEF, including:\n\nIKEA also supports American Forests to restore forests and reduce pollution.\n\nIn September 2005, IKEA Social Initiative was formed to manage the company's social involvements on a global level. IKEA Social Initiative is headed by Marianne Barner.\n\nThe main partners of IKEA Social Initiative are UNICEF and Save the Children.\n\nOn 23 February 2009, at the ECOSOC event in New York, UNICEF announced that IKEA Social Initiative has become the agency's largest corporate partner, with total commitments of more than US$180 million.\n\nExamples of involvements:\n\nIn 2009, Sweden's largest television station, SVT, revealed that IKEA's money—the three per cent collection from each store—does not actually go to a charitable foundation in the Netherlands, as IKEA has said. Inter IKEA is owned by a foundation in Liechtenstein, called Interogo, which has amassed $12 billion, and is controlled by the Kamprad family.\n\nIKEA publishes an annual catalogue, first published in Swedish in 1951. IKEA published 197 million catalogues in 2010, in twenty languages and sixty-one editions. It is considered to be the main marketing tool of the retail giant, consuming 70% of the company's annual marketing budget.\n\nThe catalogue is distributed both in stores and by mail, with most of it being produced by IKEA Communications AB in IKEA's hometown of Älmhult, Sweden where IKEA operates the largest photo studio in northern Europe at . The catalogue itself is printed on chlorine-free paper of 10–15% post-consumer waste, and prints approximately 175 million copies worldwide annually, more than 3 times as much as the Bible.\n\nThe 2013 catalogue is smartphone compatible, containing videos and photo galleries that can be accessed via an app by scanning the catalogue's pages, while the 2014 catalog incorporates an augmented reality app that projects an item into a real-time photograph image of the user's room. The augmented reality app also provides an indication of the scale of IKEA objects in relation to the user's living environment.\n\nIn May 2017, IKEA introduced an online shopping interactive catalog, as a shopping virtual-assistant intelligent user interface web application, developed by the software house Netguru.\n\nIn 1994, IKEA ran a commercial in the United States widely thought to be the first to feature a homosexual couple; it aired for several weeks before being pulled after calls for a boycott and a bomb threat directed at IKEA stores. Other IKEA commercials appeal to the wider LGBTQ community, one featuring a transgender woman.\nIn 2002, the inaugural television component of the \"Unböring\" campaign, titled \"Lamp\", went on to win several awards, including a Grand Clio, Golds at the London International Awards and the ANDY Awards, and the Grand Prix at the Cannes Lions International Advertising Festival, the most prestigious awards ceremony in the advertising community.\n\nIKEA launched a UK-wide \"Home is the Most Important Place in the World\" advertising campaign in September 2007 using estate agent signs with the term \"Not For Sale\" written on them as part of the wider campaign. After the campaign appeared in the Metro newspaper London the business news website www.mad.co.uk remarked that the IKEA campaign had amazing similarities with the marketing activity of UK home refurbishment company Onis living who had launched its own Not For Sale advertising campaign two years prior and was awarded the Interbuild 2006 Construction Marketing Award for best campaign under £25,000.\n\nA debate ensued between Fraser Patterson, Chief Executive of Onis and Andrew McGuinness, partner at Beattie McGuinness Bungay (BMB), the advertising and PR agency awarded the £12m IKEA account. The essence of the debate was that BMB claimed to be unaware of Onis's campaign as Onis was not an advertising agency. Onis's argument was that its advertising could be seen in prominent landmarks throughout London, having been already accredited, showing concern about the impact IKEA's campaign would have on the originality of its own. BMB and IKEA subsequently agreed to provide Onis with a feature page on the IKEA campaign site linking through to Onis's website for a period of 1 year.\nIn 2008, IKEA paired up with the makers of video game \"The Sims 2\" to make a stuff pack called \"IKEA Home Stuff\", featuring many IKEA products. It was released on 24 June 2008 in North America and 26 June 2008 in Europe. It is the second stuff pack with a major brand, the first being \"The Sims 2 H&M Fashion Stuff\".\n\nIKEA took over the title sponsorship of Philadelphia's annual Thanksgiving Day parade in 2008, replacing Boscov's, which filed for bankruptcy in August 2008.\n\nIn November 2008, a subway train decorated in IKEA style was introduced in Novosibirsk, Russia. Four cars were turned into a mobile showroom of the Swedish design. The redesigned train, which features colourful seats and fancy curtains, carried passengers until 6 June 2009.\n\nOyster cards (the ticket-free system for the London Underground) were for given with wallets sponsored by IKEA in 2008-09. IKEA also sponsored the tube map.\nIn January 2009, just before the new store opened in Southampton, of Red Funnel was re-painted in an entirely yellow and blue livery to celebrate the opening of the new IKEA store in Southampton. This is the first time a Red Funnel ferry has been re-painted out of its own red and white colour scheme. It stayed in these colours for 12 months as part of a deal between Red Funnel and IKEA to provide home delivery services to the Isle of Wight. It was repainted with Red Funnel's red and white livery when the deal ended in January 2010.\n\nIn March 2010, IKEA developed an event in four important Metro stations in Paris, in which furniture collections are displayed in high-traffic spots, giving potential customers a chance to check out the brand's products. The Metro walls were also filled with prints that showcase IKEA interiors.\n\nIn September 2010, IKEA launched an advertisement for UK and Ireland called \"Happy Inside\" which had 100 cats lying on IKEA furniture in the flagship IKEA store in Wembley, London.\n\nIn April 2011, an advertising campaign was launched aiming at discovering whether men or women are messier in the home. Created by Mother, the campaign will begin with a TV advert shot in front of a live audience, featuring four stand-up comedians, two men and two women, debating which gender is messier. The idea behind the campaign is that domestic clutter leads to arguments, and thus to an unhappy home, a conflict that IKEA wants to show can be avoided with better storage. Viewers will be directed to a new Facebook page for the brand, where they are able to vote on who they believe is messier, and submit evidence using videos and photos through an app created especially for the campaign. Meanwhile, online display banners will allow other users the opportunity to vote, with online adverts promoting IKEA products demonstrating the problems confronting people, and offering solutions.\n\nIn 2016, in conjunction with Stockholm ad agency Åkestam Holst, IKEA released the \"Where Life Happens\" video campaign. The series focused on taboo issues like divorce and adoption, and was filmed in a non-traditional 4:3 aspect ratio. The campaign won an Epica gold award in Amsterdam.\n\nIn September 2017, IKEA launched the \"IKEA Human Catalogue\" campaign in which memory champion Yanjaa Wintersoul memorized all 328 pages of the catalogue in minute detail in just a week before its launch. To prove the legitimacy and accuracy of the campaign, live demonstrations were held at press conferences in IKEA stores across Malaysia, Singapore, Thailand as well as a Facebook Live event held at the Facebook Singapore headquarters and talk show demonstrations in the US with Steve Harvey among others. The advertising campaign was hugely successful winning numerous industry awards including the Webby award 2018 for best social media campaign, an Ogilvy award and is currently a contender for the Cannes Lions 2018.\n\nIn common with some other retailers, IKEA launched a loyalty card called \"IKEA Family\". The card is free of charge and can be used to obtain discounts on certain products found in-store. It is available worldwide. In conjunction with the card, IKEA also publishes and sells a printed quarterly magazine titled \"IKEA Family Live\" which supplements the card and catalogue. The magazine is already printed in thirteen languages and an English edition for the United Kingdom was launched in February 2007. It is expected to have a subscription of over 500,000.\n\nIn September 12, 2017, IKEA announced the augmented reality app, IKEA Place, following by Apple's release of its ARkit technology and iOS 11. IKEA Place helps consumers to visualize true to scale IKEA products into real environment.\n\nIKEA's goals of sustainability and environmental design in its merchandise have sometimes been at odds with the impact a new IKEA store can have on a community. In particular, the size of proposed IKEA stores has often seen significant opposition from members of such communities. The following are a list of issues which have received negative media attention, both regarding the size of IKEA's stores and other controversies:\n\n\n\nIKEA has been criticised by Citytv in Canada for charging up to twice as much in their Canadian stores as for the same items sold in their American stores, despite the Canadian dollar reaching parity with the U.S. dollar.\n\nWithin the days after the launch of the South Korean edition of the official website, complaints arose from a group of consumers on IKEA's pricing policy in the country: the prices of certain products were higher than other countries. On 24 November 2014, Jang Duck-jin, head of the Fair Trade Commission's consumer policy bureau, told the media that the Commission was planning to commission a consumer group to compare IKEA's product prices by country, and on 19 March 2015, the Consumers Union of Korea published a report comparing the prices of 49 IKEA products in South Korea and other countries.\n\n\nIn February 2013, IKEA announced it had pulled 17,000 portions of Swedish meatballs containing beef and pork from stores in Europe after testing in the Czech Republic found traces of horsemeat in the product. The company removed the Swedish meatballs from stores' shelves on 25 February 2013, but only made the announcement public after Swedish newspaper Svenska Dagbladet uncovered what happened. In a March 2013 media report, an IKEA representative stated that the corporation had forced Familjen Dafgård, its main meatball supplier, to cease business with eight of its 15 suppliers and would reduce the number of purchasing countries. The discovered horsemeat was traced to a Polish abattoir.\n\nIn July 2015, IKEA, with the U.S. Consumer Product Safety Commission, through the company's Safer Homes Together advertising campaign, issued a warning in the United States, the United Kingdom, and Ireland to customers to secure the Malm chests of drawers and wardrobes firmly to the wall using free kits distributed by the company, after two deaths of young children in the U.S. in February and June 2014 when the furniture pieces tipped over on them. There were three other deaths, from 1989, from other, similar appliance models tipping over, and 14 incidents of Malm chests tipping over, resulting in four injuries. The company sent out free kits on request for customers to anchor the furniture to the wall. In June 2016, after a third toddler died in the U.S., IKEA recalled all Malm dressers as well as several similar models which posed a tipping danger if not secured to the wall with the supplied kit. On July 12, 2016, bowing to two weeks of rising pressure in China, IKEA announced that it was extending this recall to that country, which - along with Europe - was initially excluded from the recall. Over 29 million dressers have been recalled. IKEA has settled wrongful death lawsuits for over $50 million in compensation to the families of the three children who were killed.\n\nIn 2014, documents were found at the Securitate archives in Bucharest which indicated that IKEA's open purchase of Romanian lumber throughout the 1980s was part of a complex scheme (codenamed \"Scandinavica\") to fund the Securitate and allow the accumulation of foreign currency: the Romanian lumber company Tehnoforestexport would regularly overcharge IKEA, transfer the overpayments into private Securitate bank accounts, wait for interest to accrue, and then reimburse IKEA the principal. IKEA has denied complicity in Scandinavica, but has begun an internal investigation to learn more.\n\nIKEA has over 400 stores around the world. The countries with the most IKEA stores are Germany and the United States.\n\n"}
{"id": "14752", "url": "https://en.wikipedia.org/wiki?curid=14752", "title": "Iridium", "text": "Iridium\n\nIridium is a chemical element with symbol Ir and atomic number 77. A very hard, brittle, silvery-white transition metal of the platinum group, iridium is the second-densest metal (after osmium) with a density of as defined by experimental X-ray crystallography. However at room temperature and standard atmospheric pressure, iridium has a density of , higher than osmium measured the same way. It is the most corrosion-resistant metal, even at temperatures as high as 2000 °C. Although only certain molten salts and halogens are corrosive to solid iridium, finely divided iridium dust is much more reactive and can be flammable.\n\nIridium was discovered in 1803 among insoluble impurities in natural platinum. Smithson Tennant, the primary discoverer, named iridium for the Greek goddess Iris, personification of the rainbow, because of the striking and diverse colors of its salts. Iridium is one of the rarest elements in Earth's crust, with annual production and consumption of only three tonnes. Ir and Ir are the only two naturally occurring isotopes of iridium, as well as the only stable isotopes; the latter is the more abundant of the two.\n\nThe most important iridium compounds in use are the salts and acids it forms with chlorine, though iridium also forms a number of organometallic compounds used in industrial catalysis, and in research. Iridium metal is employed when high corrosion resistance at high temperatures is needed, as in high-performance spark plugs, crucibles for recrystallization of semiconductors at high temperatures, and electrodes for the production of chlorine in the chloralkali process. Iridium radioisotopes are used in some radioisotope thermoelectric generators.\n\nIridium is found in meteorites in much higher abundance than in the Earth's crust. For this reason, the unusually high abundance of iridium in the clay layer at the Cretaceous–Paleogene boundary gave rise to the Alvarez hypothesis that the impact of a massive extraterrestrial object caused the extinction of dinosaurs and many other species 66 million years ago. Similarly, an iridium anomaly in core samples from the Pacific Ocean suggested the Eltanin impact of about 2.5 million years ago.\n\nIt is thought that the total amount of iridium in the planet Earth is much higher than that observed in crustal rocks, but as with other platinum-group metals, the high density and tendency of iridium to bond with iron caused most iridium to descend below the crust when the planet was young and still molten.\n\nA member of the platinum group metals, iridium is white, resembling platinum, but with a slight yellowish cast. Because of its hardness, brittleness, and very high melting point, solid iridium is difficult to machine, form, or work; thus powder metallurgy is commonly employed instead. It is the only metal to maintain good mechanical properties in air at temperatures above . It has the 10th highest boiling point among all elements and becomes a superconductor at temperatures below 0.14 K.\n\nIridium's modulus of elasticity is the second-highest among the metals, only being surpassed by osmium. This, together with a high shear modulus and a very low figure for Poisson's ratio (the relationship of longitudinal to lateral strain), indicate the high degree of stiffness and resistance to deformation that have rendered its fabrication into useful components a matter of great difficulty. Despite these limitations and iridium's high cost, a number of applications have developed where mechanical strength is an essential factor in some of the extremely severe conditions encountered in modern technology.\n\nThe measured density of iridium is only slightly lower (by about 0.12%) than that of osmium, the densest metal known. Some ambiguity occurred regarding which of the two elements was denser, due to the small size of the difference in density and difficulties in measuring it accurately, but, with increased accuracy in factors used for calculating density X-ray crystallographic data yielded densities of 22.56 g/cm for iridium and 22.59 g/cm for osmium.\n\nIridium is the most corrosion-resistant metal known: it is not attacked by almost any acid, aqua regia, molten metals, or silicates at high temperatures. It can, however, be attacked by some molten salts, such as sodium cyanide and potassium cyanide, as well as oxygen and the halogens (particularly fluorine) at higher temperatures. Iridium also reacts directly with sulfur at atmospheric pressure to yield iridium disulfide.\n\nIridium forms compounds in oxidation states between −3 and +9; the most common oxidation states are +3 and +4. Well-characterized examples of the high +6 oxidation state are rare, but include and two mixed oxides and . In addition, it was reported in 2009 that iridium(VIII) oxide () was prepared under matrix isolation conditions (6 K in Ar) by UV irradiation of an iridium-peroxo complex. This species, however, is not expected to be stable as a bulk solid at higher temperatures. The highest oxidation state (+9), which is also the highest recorded for \"any\" element, is only known in one cation, ; it is only known as gas-phase species and is not known to form any salts.\n\nIridium dioxide, , a blue black solid, is the only well-characterized oxide of iridium. A sesquioxide, , has been described as a blue-black powder which is oxidized to by . The corresponding disulfides, diselenides, sesquisulfides, and sesquiselenides are known, and has also been reported. Iridium also forms iridates with oxidation states +4 and +5, such as and , which can be prepared from the reaction of potassium oxide or potassium superoxide with iridium at high temperatures.\n\nAlthough no binary hydrides of iridium, are known, complexes are known that contain and , where iridium has the +1 and +3 oxidation states, respectively. The ternary hydride is believed to contain both the and the 18-electron anion.\n\nNo monohalides or dihalides are known, whereas trihalides, , are known for all of the halogens. For oxidation states +4 and above, only the tetrafluoride, pentafluoride and hexafluoride are known. Iridium hexafluoride, , is a volatile and highly reactive yellow solid, composed of octahedral molecules. It decomposes in water and is reduced to , a crystalline solid, by iridium black. Iridium pentafluoride has similar properties but it is actually a tetramer, , formed by four corner-sharing octahedra. Iridium metal dissolves in molten alkali-metal cyanides to produce the (hexacyanoiridate) ion.\nHexachloroiridic(IV) acid, , and its ammonium salt are the most important iridium compounds from an industrial perspective. They are involved in the purification of iridium and used as precursors for most other iridium compounds, as well as in the preparation of anode coatings. The ion has an intense dark brown color, and can be readily reduced to the lighter-colored and vice versa. Iridium trichloride, , which can be obtained in anhydrous form from direct oxidation of iridium powder by chlorine at 650 °C, or in hydrated form by dissolving in hydrochloric acid, is often used as a starting material for the synthesis of other Ir(III) compounds. Another compound used as a starting material is ammonium hexachloroiridate(III), . Iridium(III) complexes are diamagnetic (low-spin) and generally have an octahedral molecular geometry.\n\nOrganoiridium compounds contain iridium–carbon bonds where the metal is usually in lower oxidation states. For example, oxidation state zero is found in tetrairidium dodecacarbonyl, , which is the most common and stable binary carbonyl of iridium. In this compound, each of the iridium atoms is bonded to the other three, forming a tetrahedral cluster. Some organometallic Ir(I) compounds are notable enough to be named after their discoverers. One is Vaska's complex, , which has the unusual property of binding to the dioxygen molecule, . Another one is Crabtree's catalyst, a homogeneous catalyst for hydrogenation reactions. These compounds are both square planar, d complexes, with a total of 16 valence electrons, which accounts for their reactivity.\n\nAn iridium-based organic LED material has been documented, and found to be much brighter than DPA or PPV, so could be the basis for flexible OLED lighting in the future.\n\nIridium has two naturally occurring, stable isotopes, Ir and Ir, with natural abundances of 37.3% and 62.7%, respectively. At least 37 radioisotopes have also been synthesized, ranging in mass number from 164 to 202. Ir, which falls between the two stable isotopes, is the most stable radioisotope, with a half-life of 73.827 days, and finds application in brachytherapy and in industrial radiography, particularly for nondestructive testing of welds in steel in the oil and gas industries; iridium-192 sources have been involved in a number of radiological accidents. Three other isotopes have half-lives of at least a day—Ir, Ir, and Ir. Isotopes with masses below 191 decay by some combination of β decay, α decay, and (rare) proton emission, with the exceptions of Ir, which decays by electron capture. Synthetic isotopes heavier than 191 decay by β decay, although Ir also has a minor electron capture decay path. All known isotopes of iridium were discovered between 1934 and 2008, with the most recent discoveries being Ir.\n\nAt least 32 metastable isomers have been characterized, ranging in mass number from 164 to 197. The most stable of these is Ir, which decays by isomeric transition with a half-life of 241 years, making it more stable than any of iridium's synthetic isotopes in their ground states. The least stable isomer is Ir with a half-life of only 2 µs. The isotope Ir was the first one of any element to be shown to present a Mössbauer effect. This renders it useful for Mössbauer spectroscopy for research in physics, chemistry, biochemistry, metallurgy, and mineralogy.\n\nThe discovery of iridium is intertwined with that of platinum and the other metals of the platinum group. Native platinum used by ancient Ethiopians and by South American cultures always contained a small amount of the other platinum group metals, including iridium. Platinum reached Europe as \"platina\" (\"silverette\"), found in the 17th century by the Spanish conquerors in a region today known as the department of Chocó in Colombia. The discovery that this metal was not an alloy of known elements, but instead a distinct new element, did not occur until 1748.\n\nChemists who studied platinum dissolved it in aqua regia (a mixture of hydrochloric and nitric acids) to create soluble salts. They always observed a small amount of a dark, insoluble residue. Joseph Louis Proust thought that the residue was graphite. The French chemists Victor Collet-Descotils, Antoine François, comte de Fourcroy, and Louis Nicolas Vauquelin also observed the black residue in 1803, but did not obtain enough for further experiments.\n\nIn 1803, British scientist Smithson Tennant (1761–1815) analyzed the insoluble residue and concluded that it must contain a new metal. Vauquelin treated the powder alternately with alkali and acids and obtained a volatile new oxide, which he believed to be of this new metal—which he named \"ptene\", from the Greek word \"ptēnós\", \"winged\". Tennant, who had the advantage of a much greater amount of residue, continued his research and identified the two previously undiscovered elements in the black residue, iridium and osmium. He obtained dark red crystals (probably of ]·\"n\") by a sequence of reactions with sodium hydroxide and hydrochloric acid. He named iridium after Iris (), the Greek winged goddess of the rainbow and the messenger of the Olympian gods, because many of the salts he obtained were strongly colored. Discovery of the new elements was documented in a letter to the Royal Society on June 21, 1804.\n\nBritish scientist John George Children was the first to melt a sample of iridium in 1813 with the aid of \"the greatest galvanic battery that has ever been constructed\" (at that time). The first to obtain high-purity iridium was Robert Hare in 1842. He found it had a density of around 21.8 g/cm and noted the metal is nearly immalleable and very hard. The first melting in appreciable quantity was done by Henri Sainte-Claire Deville and Jules Henri Debray in 1860. They required burning more than 300 liters of pure and gas for each kilogram of iridium.\n\nThese extreme difficulties in melting the metal limited the possibilities for handling iridium. John Isaac Hawkins was looking to obtain a fine and hard point for fountain pen nibs, and in 1834 managed to create an iridium-pointed gold pen. In 1880, John Holland and William Lofland Dudley were able to melt iridium by adding phosphorus and patented the process in the United States; British company Johnson Matthey later stated they had been using a similar process since 1837 and had already presented fused iridium at a number of World Fairs. The first use of an alloy of iridium with ruthenium in thermocouples was made by Otto Feussner in 1933. These allowed for the measurement of high temperatures in air up to 2000 °C.\n\nIn Munich, Germany in 1957 Rudolf Mössbauer, in what has been called one of the \"landmark experiments in twentieth-century physics\", discovered the resonant and recoil-free emission and absorption of gamma rays by atoms in a solid metal sample containing only Ir. This phenomenon, known as the Mössbauer effect (which has since been observed for other nuclei, such as Fe), and developed as Mössbauer spectroscopy, has made important contributions to research in physics, chemistry, biochemistry, metallurgy, and mineralogy. Mössbauer received the Nobel Prize in Physics in 1961, at the age 32, just three years after he published his discovery. In 1986 Rudolf Mössbauer was honored for his achievements with the Albert Einstein Medal and the Elliot Cresson Medal.\n\nIridium is one of the nine least abundant stable elements in Earth's crust, having an average mass fraction of 0.001 ppm in crustal rock; platinum is 10 times more abundant, gold is 40 times more abundant, and silver and mercury are 80 times more abundant. Tellurium is about as abundant as iridium. In contrast to its low abundance in crustal rock, iridium is relatively common in meteorites, with concentrations of 0.5 ppm or more. The overall concentration of iridium on Earth is thought to be much higher than what is observed in crustal rocks, but because of the density and siderophilic (\"iron-loving\") character of iridium, it descended below the crust and into Earth's core when the planet was still molten.\n\nIridium is found in nature as an uncombined element or in natural alloys; especially the iridium–osmium alloys, osmiridium (osmium-rich), and iridosmium (iridium-rich). In the nickel and copper deposits, the platinum group metals occur as sulfides (i.e. (Pt,Pd)S), tellurides (i.e. PtBiTe), antimonides (PdSb), and arsenides (i.e. ). In all of these compounds, platinum is exchanged by a small amount of iridium and osmium. As with all of the platinum group metals, iridium can be found naturally in alloys with raw nickel or raw copper. A number of iridium-dominant minerals, with iridium as the species-forming element, are known. They are exceedingly rare and often represent the iridium analogues of the above-given ones. The examples are irarsite and cuproiridsite, to mention some.\n\nWithin Earth's crust, iridium is found at highest concentrations in three types of geologic structure: igneous deposits (crustal intrusions from below), impact craters, and deposits reworked from one of the former structures. The largest known primary reserves are in the Bushveld igneous complex in South Africa, (near the largest known impact crater, the Vredefort crater) though the large copper–nickel deposits near Norilsk in Russia, and the Sudbury Basin (also an impact crater) in Canada are also significant sources of iridium. Smaller reserves are found in the United States. Iridium is also found in secondary deposits, combined with platinum and other platinum group metals in alluvial deposits. The alluvial deposits used by pre-Columbian people in the Chocó Department of Colombia are still a source for platinum-group metals. As of 2003, world reserves have not been estimated.\n\nThe [Cretaceous–Paleogene boundary] of 66 million years ago, marking the temporal border between the Cretaceous and Paleogene periods of geological time, was identified by a thin stratum of iridium-rich clay. A team led by Luis Alvarez proposed in 1980 an extraterrestrial origin for this iridium, attributing it to an asteroid or comet impact. Their theory, known as the Alvarez hypothesis, is now widely accepted to explain the extinction of the non-avian dinosaurs. A large buried impact crater structure with an estimated age of about 66 million years was later identified under what is now the Yucatán Peninsula (the Chicxulub crater). Dewey M. McLean and others argue that the iridium may have been of volcanic origin instead, because Earth's core is rich in iridium, and active volcanoes such as Piton de la Fournaise, in the island of Réunion, are still releasing iridium.\n\nIridium is also obtained commercially as a by-product from nickel and copper mining and processing. During electrorefining of copper and nickel, noble metals such as silver, gold and the platinum group metals as well as selenium and tellurium settle to the bottom of the cell as \"anode mud\", which forms the starting point for their extraction. To separate the metals, they must first be brought into solution. Several separation methods are available depending on the nature of the mixture; two representative methods are fusion with sodium peroxide followed by dissolution in aqua regia, and dissolution in a mixture of chlorine with hydrochloric acid.\n\nAfter the mixture is dissolved, iridium is separated from the other platinum group metals by precipitating ammonium hexachloroiridate () or by extracting with organic amines. The first method is similar to the procedure Tennant and Wollaston used for their separation. The second method can be planned as continuous liquid–liquid extraction and is therefore more suitable for industrial scale production. In either case, the product is reduced using hydrogen, yielding the metal as a powder or \"sponge\" that can be treated using powder metallurgy techniques.\n\nIridium prices have fluctuated over a considerable range. With a relatively small volume in the world market (compared to other industrial metals like aluminium or copper), the iridium price reacts strongly to instabilities in production, demand, speculation, hoarding, and politics in the producing countries.\nAs a substance with rare properties, its price has been particularly influenced by changes in modern technology:\nThe gradual decrease between 2001 and 2003 has been related to an oversupply of Ir crucibles used for industrial growth of large single crystals.\nLikewise the prices above 1000 USD/oz between 2010 and 2014 have been explained with the installation of production facilities for single crystal sapphire used in LED backlights for TVs.\n\nThe demand for iridium surged from 2.5 tonnes in 2009 to 10.4 tonnes in 2010, mostly because of electronics-related applications that saw a rise from 0.2 to 6 tonnes – iridium crucibles are commonly used for growing large high-quality single crystals, demand for which has increased sharply. This increase in iridium consumption is predicted to saturate due to accumulating stocks of crucibles, as happened earlier in the 2000s. Other major applications include spark plugs that consumed 0.78 tonnes of iridium in 2007, electrodes for the chloralkali process (1.1 t in 2007) and chemical catalysts (0.75 t in 2007).\n\nThe high melting point, hardness and corrosion resistance of iridium and its alloys determine most of its applications. Iridium (or sometimes platinum alloys or osmium) and mostly iridium alloys have a low wear and are used, for example, for multi-pored spinnerets, through which a plastic polymer melt is extruded to form fibers, such as rayon. Osmium–iridium is used for compass bearings and for balances.\n\nTheir resistance to arc erosion makes iridium alloys ideal for electrical contacts for spark plugs, and iridium-based spark plugs are particularly used in aviation.\n\nPure iridium is extremely brittle, to the point of being hard to weld because the heat-affected zone cracks, but it can be made more ductile by addition of small quantities of titanium and zirconium (0.2% of each apparently works well)\n\nCorrosion and heat resistance makes iridium an important alloying agent. Certain long-life aircraft engine parts are made of an iridium alloy, and an iridium–titanium alloy is used for deep-water pipes because of its corrosion resistance. Iridium is also used as a hardening agent in platinum alloys. The Vickers hardness of pure platinum is 56 HV, whereas platinum with 50% of iridium can reach over 500 HV.\n\nDevices that must withstand extremely high temperatures are often made from iridium. For example, high-temperature crucibles made of iridium are used in the Czochralski process to produce oxide single-crystals (such as sapphires) for use in computer memory devices and in solid state lasers. The crystals, such as gadolinium gallium garnet and yttrium gallium garnet, are grown by melting pre-sintered charges of mixed oxides under oxidizing conditions at temperatures up to 2100 °C.\n\nIridium compounds are used as catalysts in the Cativa process for carbonylation of methanol to produce acetic acid.\n\nThe radioisotope iridium-192 is one of the two most important sources of energy for use in industrial γ-radiography for non-destructive testing of metals. Additionally, Ir is used as a source of gamma radiation for the treatment of cancer using brachytherapy, a form of radiotherapy where a sealed radioactive source is placed inside or next to the area requiring treatment. Specific treatments include high-dose-rate prostate brachytherapy, bilary duct brachytherapy, and intracavitary cervix brachytherapy.\n\nIridium is a good catalyst for the decomposition of hydrazine (into hot nitrogen and ammonia), and this is used in practice in low-thrust rocket engines; there are more details in the monopropellant rocket article.\n\nAn alloy of 90% platinum and 10% iridium was used in 1889 to construct the International Prototype Metre and kilogram mass, kept by the International Bureau of Weights and Measures near Paris. The meter bar was replaced as the definition of the fundamental unit of length in 1960 by a line in the atomic spectrum of krypton, but the kilogram prototype is still the international standard of mass (until 20 May 2019).\n\nIridium has been used in the radioisotope thermoelectric generators of unmanned spacecraft such as the \"Voyager\", \"Viking\", \"Pioneer\", \"Cassini\", \"Galileo\", and \"New Horizons\". Iridium was chosen to encapsulate the plutonium-238 fuel in the generator because it can withstand the operating temperatures of up to 2000 °C and for its great strength.\n\nAnother use concerns X-ray optics, especially X-ray telescopes. The mirrors of the Chandra X-ray Observatory are coated with a layer of iridium 60 nm thick. Iridium proved to be the best choice for reflecting X-rays after nickel, gold, and platinum were also tested. The iridium layer, which had to be smooth to within a few atoms, was applied by depositing iridium vapor under high vacuum on a base layer of chromium.\n\nIridium is used in particle physics for the production of antiprotons, a form of antimatter. Antiprotons are made by shooting a high-intensity proton beam at a \"conversion target\", which needs to be made from a very high density material. Although tungsten may be used instead, iridium has the advantage of better stability under the shock waves induced by the temperature rise due to the incident beam.\nCarbon–hydrogen bond activation (C–H activation) is an area of research on reactions that cleave carbon–hydrogen bonds, which were traditionally regarded as unreactive. The first reported successes at activating C–H bonds in saturated hydrocarbons, published in 1982, used organometallic iridium complexes that undergo an oxidative addition with the hydrocarbon.\n\nIridium complexes are being investigated as catalysts for asymmetric hydrogenation. These catalysts have been used in the synthesis of natural products and able to hydrogenate certain difficult substrates, such as unfunctionalized alkenes, enantioselectively (generating only one of the two possible enantiomers).\n\nIridium forms a variety of complexes of fundamental interest in triplet harvesting.\n\nIridium–osmium alloys were used in fountain pen nib tips. The first major use of iridium was in 1834 in nibs mounted on gold. Since 1944, the famous Parker 51 fountain pen was fitted with a nib tipped by a ruthenium and iridium alloy (with 3.8% iridium). The tip material in modern fountain pens is still conventionally called \"iridium\", although there is seldom any iridium in it; other metals such as ruthenium, osmium and tungsten have taken its place.\n\nAn iridium–platinum alloy was used for the touch holes or vent pieces of cannon. According to a report of the Paris Exhibition of 1867, one of the pieces being exhibited by Johnson and Matthey \"has been used in a Withworth gun for more than 3000 rounds, and scarcely shows signs of wear yet. Those who know the constant trouble and expense which are occasioned by the wearing of the vent-pieces of cannon when in active service, will appreciate this important adaptation\".\n\nThe pigment \"iridium black\", which consists of very finely divided iridium, is used for painting porcelain an intense black; it was said that \"all other porcelain black colors appear grey by the side of it\".\n\nIridium in bulk metallic form is not biologically important or hazardous to health due to its lack of reactivity with tissues; there are only about 20 parts per trillion of iridium in human tissue. Like most metals, finely divided iridium powder can be hazardous to handle, as it is an irritant and may ignite in air.\nVery little is known about the toxicity of iridium compounds, because they are used in very small amounts, but soluble salts, such as the iridium halides, could be hazardous due to elements other than iridium or due to iridium itself. However, most iridium compounds are insoluble, which makes absorption into the body difficult.\n\nA radioisotope of iridium, , is dangerous, like other radioactive isotopes. The only reported injuries related to iridium concern accidental exposure to radiation from used in brachytherapy. High-energy gamma radiation from can increase the risk of cancer. External exposure can cause burns, radiation poisoning, and death. Ingestion of Ir can burn the linings of the stomach and the intestines. Ir, Ir, and Ir tend to deposit in the liver, and can pose health hazards from both gamma and beta radiation.\n\n"}
{"id": "14753", "url": "https://en.wikipedia.org/wiki?curid=14753", "title": "IOC (disambiguation)", "text": "IOC (disambiguation)\n\nIOC most commonly refers to the International Olympic Committee.\n\nIOC may also refer to:\n\n\n"}
{"id": "14761", "url": "https://en.wikipedia.org/wiki?curid=14761", "title": "International Phonetic Alphabet", "text": "International Phonetic Alphabet\n\nThe International Phonetic Alphabet (IPA) is an alphabetic system of phonetic notation based primarily on the Latin alphabet. It was devised by the International Phonetic Association in the late 19th century as a standardized representation of the sounds of spoken language. The IPA is used by lexicographers, foreign language students and teachers, linguists, speech-language pathologists, singers, actors, constructed language creators and translators.\n\nThe IPA is designed to represent only those qualities of speech that are part of oral language: phones, phonemes, intonation and the separation of words and syllables. To represent additional qualities of speech, such as tooth gnashing, lisping, and sounds made with a cleft lip and cleft palate, an extended set of symbols, the extensions to the International Phonetic Alphabet, may be used.\n\nIPA symbols are composed of one or more elements of two basic types, letters and diacritics. For example, the sound of the English letter may be transcribed in IPA with a single letter, , or with a letter plus diacritics, , depending on how precise one wishes to be. Often, slashes are used to signal broad or phonemic transcription; thus, is less specific than, and could refer to, either or , depending on the context and language.\n\nOccasionally letters or diacritics are added, removed or modified by the International Phonetic Association. As of the most recent change in 2005, there are 107 letters, 52 diacritics and four prosodic marks in the IPA. These are shown in the current IPA chart, posted below in this article and at the website of the IPA.\n\nIn 1886, a group of French and British language teachers, led by the French linguist Paul Passy, formed what would come to be known from 1897 onwards as the International Phonetic Association (in French, \"\"). Their original alphabet was based on a spelling reform for English known as the Romic alphabet, but in order to make it usable for other languages, the values of the symbols were allowed to vary from language to language. For example, the sound (the \"sh\" in \"shoe\") was originally represented with the letter in English, but with the digraph in French. However, in 1888, the alphabet was revised so as to be uniform across languages, thus providing the base for all future revisions. The idea of making the IPA was first suggested by Otto Jespersen in a letter to Paul Passy. It was developed by Alexander John Ellis, Henry Sweet, Daniel Jones, and Passy.\n\nSince its creation, the IPA has undergone a number of revisions. After revisions and expansions from the 1890s to the 1940s, the IPA remained primarily unchanged until the Kiel Convention in 1989. A minor revision took place in 1993 with the addition of four letters for mid central vowels and the removal of letters for voiceless implosives. The alphabet was last revised in May 2005 with the addition of a letter for a labiodental flap. Apart from the addition and removal of symbols, changes to the IPA have consisted largely of renaming symbols and categories and in modifying typefaces.\n\nExtensions to the International Phonetic Alphabet for speech pathology were created in 1990 and officially adopted by the International Clinical Phonetics and Linguistics Association in 1994.\n\nThe general principle of the IPA is to provide one letter for each distinctive sound (speech segment), although this practice is not followed if the sound itself is complex. This means that:\n\nAmong the symbols of the IPA, 107 letters represent consonants and vowels, 31 diacritics are used to modify these, and 19 additional signs indicate suprasegmental qualities such as length, tone, stress, and intonation. These are organized into a chart; the chart displayed here is the\nofficial chart as posted at the website of the IPA.\n\nThe letters chosen for the IPA are meant to harmonize with the Latin alphabet. For this reason, most letters are either Latin or Greek, or modifications thereof. Some letters are neither: for example, the letter denoting the glottal stop, , has the form of a dotless question mark, and derives originally from an apostrophe. A few letters, such as that of the voiced pharyngeal fricative, , were inspired by other writing systems (in this case, the Arabic letter \"\").\nDespite its preference for harmonizing with the Latin script, the International Phonetic Association has occasionally admitted other letters. For example, before 1989, the IPA letters for click consonants were , , , and , all of which were derived either from existing IPA letters, or from Latin and Greek letters. However, except for , none of these letters were widely used among Khoisanists or Bantuists, and as a result they were replaced by the more widespread symbols , , , , and at the IPA Kiel Convention in 1989.\n\nAlthough the IPA diacritics are fully featural, there is little systemicity in the letter forms. A retroflex articulation is consistently indicated with a right-swinging tail, as in , and implosion by a top hook, , but other pseudo-featural elements are due to haphazard derivation and coincidence. For example, all nasal consonants but uvular are based on the form : . However, the similarity between and is a historical accident; and are derived from ligatures of \"gn\" and \"ng,\" and is an \"ad hoc\" imitation of .\n\nSome of the new letters were ordinary Latin letters turned 180 degrees, such as (turned ). This was easily done in the era of mechanical typesetting, and had the advantage of not requiring the casting of special type for IPA symbols.\nFull capital letters are not used as IPA symbols. They are, however, often used for archiphonemes and for natural classes of phonemes (that is, as wildcards). Such usage is not part of the IPA or even standardized, and may be ambiguous between authors, but it is commonly used in conjunction with the IPA. (The extIPA chart, for example, uses wildcards in its illustrations.) Capital letters are also basic to the Voice Quality Symbols sometimes used in conjunction with the IPA.\n\nAs wildcards, for {consonant} and for {vowel} are ubiquitous. Other common capital-letter symbols are for {tone/accent} (tonicity), for {nasal}, for {plosive}, for {fricative}, for {sibilant}, for {glide/approximant}, for {liquid}, for {rhotic} or {resonant} (sonorant), for {click}, for {open, front, back, close vowel} and for {labial}, {alveolar}, {post-alveolar/palatal}, {velar}, {uvular}, {pharyngeal} and {glottal}, respectively, and for anything. For example, the possible syllable shapes of Mandarin can be abstracted as ranging from (atonic vowel) to (consonant-vowel-nasal syllable with tone). The letters can be modified with IPA diacritics, for example for {ejective}, for {implosive}, or for {prenasalized consonant}, for {nasal vowel}, for {voiced sibilant}, for {voiceless nasal}, or for {affricate}, for {palatalized consonant} and for {dental consonant}. In speech pathology, capital letters represent indeterminate sounds, and may be superscripted to indicate they are weakly articulated: e.g. is a weak indeterminate alveolar, a weak indeterminate velar.\n\nTypical examples of archiphonemic use of capital letters are for the Turkish harmonic vowel set } and for the conflated flapped middle consonant of American English \"writer\" and \"rider\".\n\n, and have different meanings as Voice Quality Symbols, where they stand for \"voice\", \"falsetto\" and \"creak\". They may take diacritics that indicate what kind of voice quality an utterance has, and may be used to extract a suprasegmental feature that occurs on all susceptible segments in a stretch of IPA. For instance, the transcription of Scottish Gaelic 'cat' and 'cats' (Islay dialect) can be made more economical by extracting the suprasegmental labialization of the words: and .\n\nThe International Phonetic Alphabet is based on the Latin alphabet, using as few non-Latin forms as possible. The Association created the IPA so that the sound values of most consonant letters taken from the Latin alphabet would correspond to \"international usage\". Hence, the letters , , , (hard) , (non-silent) , (unaspirated) , , , , (unaspirated) , (voiceless) , (unaspirated) , , , and have the values used in English; and the vowel letters from the Latin alphabet (, , , , ) correspond to the (long) sound values of Latin: is like the vowel in \"machne\", is as in \"rle\", etc. Other letters may differ from English, but are used with these values in other European languages, such as , , and .\n\nThis inventory was extended by using small-capital and cursive forms, diacritics and rotation. There are also several symbols derived or taken from the Greek alphabet, though the sound values may differ. For example, is a vowel in Greek, but an only indirectly related consonant in the IPA. For most of these, subtly different glyph shapes have been devised for the IPA, namely , , , , , , and , which are encoded in Unicode separately from their parent Greek letters, though one of them – – is not, while Greek and are generally used for and .\n\nThe sound values of modified Latin letters can often be derived from those of the original letters. For example, letters with a rightward-facing hook at the bottom represent retroflex consonants; and small capital letters usually represent uvular consonants. Apart from the fact that certain kinds of modification to the shape of a letter generally correspond to certain kinds of modification to the sound represented, there is no way to deduce the sound represented by a symbol from its shape (as for example in Visible Speech) nor even any systematic relation between signs and the sounds they represent (as in Hangul).\n\nBeyond the letters themselves, there are a variety of secondary symbols which aid in transcription. Diacritic marks can be combined with IPA letters to transcribe modified phonetic values or secondary articulations. There are also special symbols for suprasegmental features such as stress and tone that are often employed.\n\nThere are two principal types of brackets used to set off IPA transcriptions:\nFor example, while the sounds of \"pin\" and \"spin\" are pronounced slightly differently in English (and this difference would be meaningful in some languages), the difference is not meaningful in English. Thus \"phonemically\" the words are and , with the same phoneme. However, to capture the difference between them (the allophones of ), they can be transcribed phonetically as and .\n\nOther conventions are less commonly seen:\n\nIPA letters have cursive forms designed for use in manuscripts and when taking field notes.\n\nIn the early stages of the alphabet, the typographic variants of \"g\", opentail () and looptail (), represented different values, but are now regarded as equivalents. Opentail has always represented a voiced velar plosive, while was distinguished from and represented a voiced velar fricative from 1895 to 1900. Subsequently, represented the fricative, until 1931 when it was replaced again by .\n\nIn 1948, the Council of the Association recognized and as typographic equivalents, and this decision was reaffirmed in 1993. While the 1949 \"Principles of the International Phonetic Association\" recommended the use of for a velar plosive and for an advanced one for languages where it is preferable to distinguish the two, such as Russian, this practice never caught on. The 1999 \"Handbook of the International Phonetic Association\", the successor to the \"Principles\", abandoned the recommendation and acknowledged both shapes as acceptable variants.\n\nThe International Phonetic Alphabet is occasionally modified by the Association. After each modification, the Association provides an updated simplified presentation of the alphabet in the form of a chart. (See History of the IPA.) Not all aspects of the alphabet can be accommodated in a chart of the size published by the IPA. The alveolo-palatal and epiglottal consonants, for example, are not included in the consonant chart for reasons of space rather than of theory (two additional columns would be required, one between the retroflex and palatal columns and the other between the pharyngeal and glottal columns), and the lateral flap would require an additional row for that single consonant, so they are listed instead under the catchall block of \"other symbols\". The indefinitely large number of tone letters would make a full accounting impractical even on a larger page, and only a few examples are shown.\n\nThe procedure for modifying the alphabet or the chart is to propose the change in the \"Journal of the IPA.\" (See, for example, August 2008 on an open central unrounded vowel and August 2011 on central approximants.) Reactions to the proposal may be published in the same or subsequent issues of the Journal (as in August 2009 on the open central vowel). A formal proposal is then put to the Council of the IPA – which is elected by the membership – for further discussion and a formal vote.\n\nOnly changes to the alphabet or chart that have been approved by the Council can be considered part of the official IPA. Nonetheless, many users of the alphabet, including the leadership of the Association itself, make personal changes or additions in their own practice, either for convenience in working on a particular language (see \"Illustrations of the IPA\" for individual languages in the \"Handbook\", which for example may use for ), or because they object to some aspect of the official version.\n\nAlthough the IPA offers over 160 symbols for transcribing speech, only a relatively small subset of these will be used to transcribe any one language. It is possible to transcribe speech with various levels of precision. A precise phonetic transcription, in which sounds are described in a great deal of detail, is known as a \"narrow transcription\". A coarser transcription which ignores some of this detail is called a \"broad transcription.\" Both are relative terms, and both are generally enclosed in square brackets. Broad phonetic transcriptions may restrict themselves to easily heard details, or only to details that are relevant to the discussion at hand, and may differ little if at all from phonemic transcriptions, but they make no theoretical claim that all the distinctions transcribed are necessarily meaningful in the language.\nFor example, the English word \"little\" may be transcribed broadly using the IPA as , and this broad (imprecise) transcription is a more or less accurate description of many pronunciations. A narrower transcription may focus on individual or dialectical details: in General American, in Cockney, or in Southern US English.\n\nIt is customary to use simpler letters, without many diacritics, in phonemic transcriptions. The choice of IPA letters may reflect the theoretical claims of the author, or merely be a convenience for typesetting. For instance, in English, either the vowel of \"pick\" or the vowel of \"peak\" may be transcribed as (for the pairs or ), and neither is identical to the vowel of the French word \"\" which is also generally transcribed . That is, letters between slashes do not have absolute values, something true of broader phonetic approximations as well. A narrow transcription may, however, be used to distinguish them: , , .\n\nAlthough IPA is popular for transcription by linguists, American linguists often alternate use of the IPA with Americanist phonetic notation or use the IPA together with some nonstandard symbols, for reasons including reducing the error rate on reading handwritten transcriptions or avoiding perceived awkwardness of IPA in some situations. The exact practice may vary somewhat between languages and even individual researchers, so authors are generally encouraged to include a chart or other explanation of their choices.\n\nSome language study programs use the IPA to teach pronunciation. For example, in Russia (and earlier in the Soviet Union) and mainland China, textbooks for children and adults for studying English and French consistently use the IPA. English teachers and textbooks in Taiwan tend to use the Kenyon and Knott system, a slight typographical variant of the IPA first used in the 1944 \"Pronouncing Dictionary of American English\".\n\nMany British dictionaries, including the Oxford English Dictionary and some learner's dictionaries such as the \"Oxford Advanced Learner's Dictionary\" and the \"Cambridge Advanced Learner's Dictionary\", now use the International Phonetic Alphabet to represent the pronunciation of words. However, most American (and some British) volumes use one of a variety of pronunciation respelling systems, intended to be more comfortable for readers of English. For example, the respelling systems in many American dictionaries (such as \"Merriam-Webster\") use for IPA and for IPA , reflecting common representations of those sounds in written English, using only letters of the English Roman alphabet and variations of them. (In IPA, represents the sound of the French (as in \"\"), and represents the pair of sounds in \"graopper\".)\nThe IPA is also not universal among dictionaries in languages other than English. Monolingual dictionaries of languages with generally phonemic orthographies generally do not bother with indicating the pronunciation of most words, and tend to use respelling systems for words with unexpected pronunciations. Dictionaries produced in Israel use the IPA rarely and sometimes use the Hebrew alphabet for transcription of foreign words. Monolingual Hebrew dictionaries use pronunciation respelling for words with unusual spelling; for example, the \"Even-Shoshan Dictionary\" respells as because this word uses kamatz katan. Bilingual dictionaries that translate from foreign languages into Russian usually employ the IPA, but monolingual Russian dictionaries occasionally use pronunciation respelling for foreign words; for example, Sergey Ozhegov's dictionary adds нэ́ in brackets for the French word пенсне (\"\") to indicate that the final е does not iotate the preceding н.\n\nThe IPA is more common in bilingual dictionaries, but there are exceptions here too. Mass-market bilingual Czech dictionaries, for instance, tend to use the IPA only for sounds not found in the Czech language.\n\nIPA letters have been incorporated into the alphabets of various languages, notably via the Africa Alphabet in many sub-Saharan languages such as Hausa, Fula, Akan, Gbe languages, Manding languages, Lingala, etc. This has created the need for capital variants. For example, Kabiyè of northern Togo has Ɖ ɖ, Ŋ ŋ, Ɣ ɣ, Ɔ ɔ, Ɛ ɛ, Ʋ ʋ. These, and others, are supported by Unicode, but appear in Latin ranges other than the IPA extensions.\n\nIn the IPA itself, however, only lower-case letters are used. The 1949 edition of the IPA handbook indicated that an asterisk may be prefixed to indicate that a word is a proper name, but this convention was not included in the 1999 \"Handbook\".\n\nIPA has widespread use among classical singers during preparation as they are frequently required to sing in a variety of foreign languages, in addition to being taught by vocal coach in order to perfect the diction of their students and to globally improve tone quality and tuning. Opera librettos are authoritatively transcribed in IPA, such as Nico Castel's volumes and Timothy Cheek's book \"Singing in Czech\". Opera singers' ability to read IPA was used by the site \"Visual Thesaurus\", which employed several opera singers \"to make recordings for the 150,000 words and phrases in VT's lexical database ... for their vocal stamina, attention to the details of enunciation, and most of all, knowledge of IPA\".\n\nThe International Phonetic Association organizes the letters of the IPA into three categories: pulmonic consonants, non-pulmonic consonants, and vowels.\n\nPulmonic consonant letters are arranged singly or in pairs of voiceless (tenuis) and voiced sounds, with these then grouped in columns from front (labial) sounds on the left to back (glottal) sounds on the right. In official publications by the IPA, two columns are omitted to save space, with the letters listed among 'other symbols', and with the remaining consonants arranged in rows from full closure (occlusives: stops and nasals), to brief closure (vibrants: trills and taps), to partial closure (fricatives) and minimal closure (approximants), again with a row left out to save space. In the table below, a slightly different arrangement is made: All pulmonic consonants are included in the pulmonic-consonant table, and the vibrants and laterals are separated out so that the rows reflect the common lenition pathway of \"stop → fricative → approximant,\" as well as the fact that several letters pull double duty as both fricative and approximant; affricates may be created by joining stops and fricatives from adjacent cells. Shaded cells represent articulations that are judged to be impossible.\n\nVowel letters are also grouped in pairs—of unrounded and rounded vowel sounds—with these pairs also arranged from front on the left to back on the right, and from maximal closure at top to minimal closure at bottom. No vowel letters are omitted from the chart, though in the past some of the mid central vowels were listed among the 'other symbols'.\n\nEach character is assigned a number, to prevent confusion between similar characters (such as and , and , or and ) in such situations as the printing of manuscripts. The categories of sounds are assigned different ranges of numbers.\n\nThe numbers are assigned to sounds and to symbols, e.g. 304 is the open front unrounded vowel, 415 is the centralization diacritic. Together, they form a symbol that represents the open central unrounded vowel, .\n\nA pulmonic consonant is a consonant made by obstructing the glottis (the space between the vocal cords) or oral cavity (the mouth) and either simultaneously or subsequently letting out air from the lungs. Pulmonic consonants make up the majority of consonants in the IPA, as well as in human language. All consonants in the English language fall into this category.\n\nThe pulmonic consonant table, which includes most consonants, is arranged in rows that designate manner of articulation, meaning how the consonant is produced, and columns that designate place of articulation, meaning where in the vocal tract the consonant is produced. The main chart includes only consonants with a single place of articulation.\nNotes\n\nNon-pulmonic consonants are sounds whose airflow is not dependent on the lungs. These include clicks (found in the Khoisan languages of Africa), implosives (found in languages such as Sindhi, Saraiki, Swahili and Vietnamese), and ejectives (found in many Amerindian and Caucasian languages).\nNotes\n\nAffricates and co-articulated stops are represented by two letters joined by a tie bar, either above or below the letters. The six most common affricates are optionally represented by ligatures, though this is no longer official IPA usage, because a great number of ligatures would be required to represent all affricates this way. Alternatively, a superscript notation for a consonant release is sometimes used to transcribe affricates, for example for , paralleling ~ . The letters for the palatal plosives and are often used as a convenience for and or similar affricates, even in official IPA publications, so they must be interpreted with care.\nNote\n\nCo-articulated consonants are sounds that involve two simultaneous places of articulation (are pronounced using two parts of the vocal tract). In English, the in \"went\" is a coarticulated consonant, being pronounced by rounding the lips and raising the back of the tongue. Similar sounds are and .\nNotes\n\nThe IPA defines a vowel as a sound which occurs at a syllable center. Below is a chart depicting the vowels of the IPA. The IPA maps the vowels according to the position of the tongue.\nThe vertical axis of the chart is mapped by vowel height. Vowels pronounced with the tongue lowered are at the bottom, and vowels pronounced with the tongue raised are at the top. For example, (the first vowel in \"father\") is at the bottom because the tongue is lowered in this position. However, (the vowel in \"meet\") is at the top because the sound is said with the tongue raised to the roof of the mouth.\n\nIn a similar fashion, the horizontal axis of the chart is determined by vowel backness. Vowels with the tongue moved towards the front of the mouth (such as , the vowel in \"met\") are to the left in the chart, while those in which it is moved to the back (such as , the vowel in \"but\") are placed to the right in the chart.\n\nIn places where vowels are paired, the right represents a rounded vowel (in which the lips are rounded) while the left is its unrounded counterpart.\n\nDiphthongs are typically specified with a non-syllabic diacritic, as in or , or with a superscript for the on- or off-glide, as in or . Sometimes a tie bar is used, especially if it is difficult to tell if the diphthong is characterized by an on-glide, an off-glide or is variable: .\n\nNotes\n\nDiacritics are used for phonetic detail. They are added to IPA letters to indicate a modification or specification of that letter's normal pronunciation.\n\nBy being made superscript, any IPA letter may function as a diacritic, conferring elements of its articulation to the base letter. (See secondary articulation for a list of superscript IPA letters supported by Unicode.) Those superscript letters listed below are specifically provided for by the IPA; others include ( with fricative release), ( with affricate onset), (prenasalized ), ( with breathy voice), (glottalized ), ( with a flavor of ), ( with diphthongization), (compressed ). Superscript diacritics placed after a letter are ambiguous between simultaneous modification of the sound and phonetic detail at the end of the sound. For example, labialized may mean either simultaneous and or else with a labialized release. Superscript diacritics placed before a letter, on the other hand, normally indicate a modification of the onset of the sound ( glottalized , with a glottal onset).\n\nNotes\n\nSubdiacritics (diacritics normally placed below a letter) may be moved above a letter to avoid conflict with a descender, as in voiceless . The raising and lowering diacritics have optional forms , that avoid descenders.\n\nThe state of the glottis can be finely transcribed with diacritics. A series of alveolar plosives ranging from an open to a closed glottis phonation are:\n\nAdditional diacritics are provided by the Extensions to the IPA for speech pathology.\n\nThese symbols describe the features of a language above the level of individual consonants and vowels, such as prosody, tone, length, and stress, which often operate on syllables, words, or phrases: that is, elements such as the intensity, pitch, and gemination of the sounds of a language, as well as the rhythm and intonation of speech. Although most of these symbols indicate distinctions that are phonemic at the word level, symbols also exist for intonation on a level greater than that of the word. Various ligatures of tone letters are used in the IPA \"Handbook\" despite not being found on the simplified official IPA chart.\nFiner distinctions of tone may be indicated by combining the tone diacritics and tone letters shown above, though not all IPA fonts support this. The four additional rising and falling tones supported by diacritics are high/mid rising , low rising , high falling , and low/mid falling . That is, tone diacritics only support contour tones across three levels (high, mid, low), despite supporting five levels for register tones. For other contour tones, tone letters must be used: , etc. For more complex (peaking and dipping) tones, though it is theoretically possible to combine the three tone diacritics in any permutation, in practice only generic peaking and dipping combinations are used. For finer detail, tone letters are again required (, etc.) The correspondence between tone diacritics and tone letters is therefore only approximate.\n\nA work-around for diacritics sometimes seen when a language has more than one rising or falling tone, and the author wishes to avoid the poorly legible diacritics but does not wish to completely abandon the IPA, is to restrict generic rising and falling to the higher-pitched of the rising and falling tones, say and , and to use the old (retired) IPA subscript diacritics and for the lower-pitched rising and falling tones, say and . When a language has four or six level tones, the two mid tones are sometimes transcribed as high-mid (non-standard) and low-mid .\n\nA stress mark typically appears before the stressed syllable, and thus marks the syllable break as well as stress. Where the syllable onset is a geminate consonant, e.g. in Italian, the consonant is commonly split by the stress mark, which means that the length sign is not used for gemination. (Thus not *, *, or *.) However, occasionally the stress mark is placed immediately before the stressed vowel, after any syllable onset ( or ). In such transcriptions, the stress mark does not function as a mark of the syllable boundary.\n\nTone letters generally appear after each syllable, for a language with syllable tone (), or after the phonological word, for a language with word tone (). However, in older versions of the IPA, \"ad hoc\" tone marks were placed before the syllable, the same position as used to mark stress, and this convention is still sometimes seen (, ).\n\nThere are three boundary markers, for a syllable break, for a minor prosodic break and for a major prosodic break. The tags 'minor' and 'major' are intentionally ambiguous. Depending on need, 'minor' may vary from a foot break to a continuing–prosodic-unit boundary (equivalent to a comma), and while 'major' is often any intonation break, it may be restricted to a final–prosodic-unit boundary (equivalent to a period). Although not part of the IPA, the following boundary symbols are often used in conjunction with the IPA: for a mora or mora boundary, for a syllable or syllable boundary, for a word boundary, for a phrase or intermediate boundary and for a prosodic boundary. For example, C# is a word-final consonant, %V a post-pausa vowel, and T% an IU-final tone (edge tone).\n\nIPA diacritics may be doubled to indicate an extra degree of the feature indicated. This is a productive process, but apart from extra-high and extra-low tones being marked by doubled high- and low-tone diacritics, and the major prosodic break being marked as a double minor break , it is not specifically regulated by the IPA. (Note that transcription marks are similar: double slashes indicate extra (morpho)-phonemic, double square brackets especially precise, and double parentheses especially unintelligible.) \n\nFor example, the stress mark may be doubled to indicate an extra degree of stress, such as prosodic stress in English. An example in French, with a single stress mark for normal prosodic stress at the end of each prosodic unit (marked as a minor prosodic break), and a double stress mark for contrastive/emphatic stress: \".\" Similarly, a doubled secondary stress mark is commonly used for tertiary stress.\n\nLength is commonly extended by repeating the length mark, as in English \"shhh!\" , or for \"overlong\" segments in Estonian:\n(Normally additional degrees of length are handled by the extra-short or half-long diacritics, but in the Estonian examples, the first two cases are analyzed as simply short and long.)\n\nOccasionally other diacritics are doubled:\n\nThe IPA once had parallel symbols from alternative proposals, but in most cases eventually settled on one for each sound. The rejected symbols are now considered obsolete. An example is the vowel letter , rejected in favor of . Letters for affricates and sounds with inherent secondary articulation have also been mostly rejected, with the idea that such features should be indicated with tie bars or diacritics: for is one. In addition, the rare voiceless implosives, , have been dropped and are now usually written . A retired set of click letters, , is still sometimes seen, as the official pipe letters may cause problems with legibility, especially when used with brackets ([ ] or / /), the letter , or the prosodic marks (for this reason, some publications which use the current IPA pipe letters disallow IPA brackets).\n\nIndividual non-IPA letters may find their way into publications that otherwise use the standard IPA. This is especially common with:\n\nIn addition, there are typewriter substitutions for when IPA support is not available, such as capital for .\n\nThe \"Extensions to the IPA\", often abbreviated as \"extIPA\" and sometimes called \"Extended IPA\", are symbols whose original purpose was to accurately transcribe disordered speech. At the Kiel Convention in 1989, a group of linguists drew up the initial extensions, which were based on the previous work of the PRDS (Phonetic Representation of Disordered Speech) Group in the early 1980s. The extensions were first published in 1990, then modified, and published again in 1994 in the \"Journal of the International Phonetic Association\", when they were officially adopted by the ICPLA. While the original purpose was to transcribe disordered speech, linguists have used the extensions to designate a number of unique sounds within standard communication, such as hushing, gnashing teeth, and smacking lips. The extensions have also been used to record certain peculiarities in an individual's voice, such as nasalized voicing.\n\nThe Extensions to the IPA do not include symbols used for voice quality (Voice Quality Symbols), such as whispering.\n\nThe remaining blank cells on the IPA chart can be filled without too much difficulty if the need arises. Some \"ad hoc\" letters have appeared in the literature for the retroflex lateral flap, the voiceless lateral fricatives, the epiglottal trill, and the labiodental plosives. (See the grey letters in the PDF chart.) Diacritics can supply much of the remainder. If a sound cannot be transcribed, an asterisk may be used, either as a letter or as a diacritic (as in sometimes seen for the Korean \"fortis\" velar).\n\nRepresentations of consonant sounds outside of the core set are created by adding diacritics to letters with similar sound values. The Spanish bilabial and dental approximants are commonly written as lowered fricatives, and respectively. Similarly, voiced lateral fricatives would be written as raised lateral approximants, . A few languages such as Banda have a bilabial flap as the preferred allophone of what is elsewhere a labiodental flap. It has been suggested that this be written with the labiodental flap letter and the advanced diacritic, .\n\nSimilarly, a labiodental trill would be written (bilabial trill and the dental sign), and labiodental stops rather than with the \"ad hoc\" letters sometimes found in the literature. Other taps can be written as extra-short plosives or laterals, e.g. , though in some cases the diacritic would need to be written below the letter. A retroflex trill can be written as a retracted , just as retroflex fricatives sometimes are. The remaining consonants, the uvular laterals ( \"etc.\") and the palatal trill, while not strictly impossible, are very difficult to pronounce and are unlikely to occur even as allophones in the world's languages.\n\nThe vowels are similarly manageable by using diacritics for raising, lowering, fronting, backing, centering, and mid-centering. For example, the unrounded equivalent of can be transcribed as mid-centered , and the rounded equivalent of as raised or lowered . True mid vowels are lowered or raised , while centered and (or, less commonly, ) are near-close and open central vowels, respectively. The only known vowels that cannot be represented in this scheme are vowels with unexpected roundedness, which would require a dedicated diacritic, such as and (or and ).\n\nAn IPA symbol is often distinguished from the sound it is intended to represent, since there is not necessarily a one-to-one correspondence between letter and sound in broad transcription, making articulatory descriptions such as 'mid front rounded vowel' or 'voiced velar stop' unreliable. While the \"Handbook of the International Phonetic Association\" states that no official names exist for its symbols, it admits the presence of one or two common names for each. The symbols also have nonce names in the Unicode standard. In some cases, the Unicode names and the IPA names do not agree. For example, IPA calls \"epsilon\", but Unicode calls it \"small letter open E\".\n\nThe traditional names of the Latin and Greek letters are usually used for unmodified letters. Letters which are not directly derived from these alphabets, such as , may have a variety of names, sometimes based on the appearance of the symbol or on the sound that it represents. In Unicode, some of the letters of Greek origin have Latin forms for use in IPA; the others use the letters from the Greek section.\n\nFor diacritics, there are two methods of naming. For traditional diacritics, the IPA notes the name in a well known language; for example, is \"acute\", based on the name of the diacritic in English and French. Non-traditional diacritics are often named after objects they resemble, so is called \"bridge\".\n\nGeoffrey Pullum and William Ladusaw list a variety of names in use for IPA symbols, both current and retired, in addition to names of many other non-IPA phonetic symbols. Their collection is extensive enough that the Unicode Consortium used it in the development of Unicode.\n\nIPA typeface support is increasing, and is now included in several typefaces such as the Times New Roman versions that come with various recent computer operating systems. Diacritics are not always properly rendered, however. IPA typefaces that are freely available online include Gentium, several from the SIL (such as Charis SIL, and Doulos SIL), Dehuti, DejaVu Sans, and TITUS Cyberbit, which are all freely available; as well as commercial typefaces such as Brill, available from Brill Publishers, and Lucida Sans Unicode and Arial Unicode MS, shipping with various Microsoft products. These all include several ranges of characters in addition to the IPA. Modern Web browsers generally do not need any configuration to display these symbols, provided that a typeface capable of doing so is available to the operating system.\n\nSeveral systems have been developed that map the IPA symbols to ASCII characters. Notable systems include Kirshenbaum, ARPABET, SAMPA, and X-SAMPA. The usage of mapping systems in on-line text has to some extent been adopted in the context input methods, allowing convenient keying of IPA characters that would be otherwise unavailable on standard keyboard layouts.\n\nOnline IPA keyboard utilities are available, and they cover the complete range of IPA symbols and diacritics.\n\n\n"}
{"id": "14762", "url": "https://en.wikipedia.org/wiki?curid=14762", "title": "Inspector Morse", "text": "Inspector Morse\n\nDetective Chief Inspector Endeavour Morse GM is the eponymous fictional character in the series of detective novels by British author Colin Dexter. On television, he appears in the 33-episode drama series \"Inspector Morse\" (1987–2000), in which John Thaw played the character, as well as the 2012 prequel series \"Endeavour\", portrayed by Shaun Evans. The older Morse is a senior CID (Criminal Investigation Department) officer with the Thames Valley Police force in Oxford, England and, in the prequel, Morse is a young graduate detective constable rising through the ranks with the Oxford City Police. \n\nMorse presents, to some, a reasonably sympathetic personality, despite his sullen and snobbish temperament, with a classic Jaguar car (a Lancia in the early novels), a thirst for English real ale, and a love of classical music (especially opera and Wagner), poetry, art and cryptic crossword puzzles. In his later career he is usually assisted by Sergeant Robbie Lewis. Morse's partnership and formal friendship with Lewis is fundamental to the series.\n\nMorse's father was a taxi driver, and Morse likes to explain the origin of his additional private income by saying that he \"used to drive the Aga Khan\". In the episode \"Cherubim and Seraphim\", it is revealed that Morse's parents divorced when he was 12. He remained with his mother until her death three years later, upon which he had to return to his father. Morse had a dreadful relationship with his stepmother Gwen. He claims that he only read poetry to annoy her, and that her petty bullying almost drove him to suicide. He has a half-sister named Joyce with whom he is on better terms. Morse was devastated when Joyce's daughter Marilyn took her own life.\n\nMorse prefers to use only his surname, and is generally evasive when asked about his first name, sometimes joking that it is \"Inspector\". In \"The Wench Is Dead\" it was stated that his initial was E. At the end of \"Death Is Now My Neighbour\", it is revealed to be \"Endeavour\". Two-thirds of the way through the television episode based on the book, he gives the cryptic clue \"My whole life's effort has revolved around Eve\". In the series, it is noted that Morse's reluctance to use his Christian name led to his receiving the nickname \"Pagan\" while attending Stamford School (which Colin Dexter, the author of the Morse novels, attended). In the novels, Morse's first name came from the vessel HMS \"Endeavour\"; his mother was a member of the Religious Society of Friends (Quakers) who have a tradition of \"virtue names\", and his father admired Captain James Cook.\n\nDexter was a fan of cryptic crosswords and named Morse after champion setter Jeremy Morse, one of Dexter's arch-rivals in writing crossword clues. Dexter used to walk along the bank of the River Thames at Oxford, opposite the boathouse belonging to 22nd Oxford Sea Scout Group; the building is named \"T.S. Endeavour\".\n\nAlthough details of Morse's career are deliberately kept vague, it is hinted that he won a scholarship to study at St John's College, Oxford. He lost the scholarship as the result of poor academic performance stemming from a failed love affair, which is mentioned in the Series 3, Episode 2, \"The Last Enemy\", and recounted in detail in the novel \"The Riddle of the Third Mile\", Chapter 7.\n\nAfter university, he entered the army, serving in the Royal Signal Corps, and, upon leaving, joined the police, based at Newtown before Oxford. He often reflects on such renowned scholars as A. E. Housman who, like himself, failed to get an academic degree from Oxford. He was awarded the George Medal in the last episode of Endeavour Series 4.\n\nMorse is ostensibly the embodiment of white, male, middle-class Englishness, with a set of prejudices and assumptions to match (even though as the son of a taxi driver his background was thoroughly working class). As a result, he may be considered a late example of the gentleman detective, a staple of British detective fiction. This is in sharp contrast to the working-class lifestyle of his assistant Lewis (named after another rival clue-writer Mrs. B. Lewis); in the novels, Lewis is Welsh, but in the TV series this is altered to a Tyneside (Geordie) background, appropriately for the actor Kevin Whately. Morse is in his forties at the start of the books (\"Service of all the Dead\", Chapter Six: \"… a bachelor still, forty-seven years old …\"), and Lewis slightly younger (eg \"The Secret of Annexe 3\", Chapter Twenty-Six: \"a slightly younger man – another policeman, and one also in plain clothes\"). John Thaw was 45 at the beginning of shooting the TV series and Kevin Whately was 36.\n\nMorse's relationships with authority, the establishment, bastions of power and the status quo, are markedly ambiguous, as are some of his relations with women. He is frequently portrayed as patronising female characters, and once stereotyped the female sex as not naturally prone to crime, being caring and non-violent, but also often empathises with women. He is not shy to show his liking for attractive women and often dates those involved in cases. Indeed a woman he falls in love with sometimes turns out to be the culprit.\n\nMorse is highly intelligent. He is a crossword addict and dislikes spelling and grammatical errors; in every personal or private document that he receives, he manages to point out at least one mistake. He claims that his approach to crime-solving is deductive, and one of his key tenets is that \"there is a 50 per cent chance that the person who finds the body is the murderer\". Morse uses immense intuition and his fantastic memory to get to the killer.\n\nAmong Morse's conservative tastes are that he likes to drink real ale and whisky, and in the early novels, drives a Lancia. In the television and radio productions, this is altered to a suitably British vintage Jaguar Mark 2. His favourite music is opera, which is echoed in the soundtracks to the television series, along with original music by Barrington Pheloung.\n\nThe novels in the series are:\n\nInspector Morse also appears in several stories in Dexter's short story collection, \"Morse's Greatest Mystery and Other Stories\" (1993, expanded edition 1994).\n\nIn Dexter's last book, \"The Remorseful Day\", Morse dies in hospital from a heart attack.\n\nThe Inspector Morse novels were made into a TV series (also called \"Inspector Morse\") for the British commercial TV network ITV. The series was made by Zenith Productions for Central (a company later acquired by Carlton) and comprises 33 two-hour episodes (100 minutes excluding commercials)—20 more episodes than there are novels—produced between 1987 and 2000. The last episode was adapted from the final novel \"The Remorseful Day\", in which Morse dies.\n\nA spin-off series based on the television incarnation of Lewis was titled \"Lewis\" and began airing in 2006 and appeared until 2015.\n\nIn August 2011, ITV announced plans to film a prequel drama called \"Endeavour\", with author Colin Dexter's participation. English actor Shaun Evans was cast as a young Morse in his university days and early career. The drama was broadcast on 2 January 2012 on ITV 1. Four new episodes were televised from 14 April 2013, showing Morse's early cases working for DI Fred Thursday and with Jim Strange, his later boss, and pathologist Max De Bryn. A second series of four episodes followed, screening in March and April 2014. In January 2016, the third series aired, also containing four episodes. A fourth series was aired, with four episodes, in January 2017. Filming of a fifth series of six episodes began in Spring 2017 with the first episode aired on 4 February 2018.\n\nAn adaptation by Melville Jones of Last Bus to Woodstock featured in BBC Radio 4's Saturday Night Theatre series in June 1985, with Andrew Burt as Morse and Christopher Douglas as Lewis.\n\nIn the 1990s, an occasional BBC Radio 4 series (for \"The Saturday Play\") was made starring the voices of John Shrapnel as Morse and Robert Glenister as Lewis. The series was written by Guy Meredith and directed by Ned Chaillet. Episodes included: \"The Wench is Dead\" (23 March 1992); \"Last Seen Wearing\" (28 May 1994); and \"The Silent World of Nicholas Quinn\" (10 February 1996).\n\nAn Inspector Morse stage play appeared in 2010, written by Alma Cullen (author of four Morse screenplays for ITV). The part of Morse was played by Colin Baker. The play, entitled \"Morse—House of Ghosts\", saw DCI Morse looking to his past, when an old acquaintance becomes the lead suspect in a murder case that involves the on-stage death of a young actress. The play toured the UK from August to December 2010. It was broadcast by BBC Radio 4 on 25 March 2017 with Neil Pearson playing Morse and Lee Ingleby playing Lewis.\n\n\n"}
{"id": "14763", "url": "https://en.wikipedia.org/wiki?curid=14763", "title": "History of the Isle of Man", "text": "History of the Isle of Man\n\nThe Isle of Man had become separated from Britain and Ireland by 6500 BC. It appears that colonisation took place by sea sometime during the Mesolithic era (about 6500 BC). The island has been visited by various raiders and trading peoples over the years. After being settled by people from Ireland in the first millennium, the Isle of Man was converted to Christianity and then suffered raids by Vikings from Norway. After becoming subject to Norwegian suzerainty as part of the Kingdom of Mann and the Isles, the Isle of Man later became a possession of the Scottish and then the English crowns.\n\nSince 1866, the Isle of Man has been a Crown Dependency and has democratic self-government.\n\nThe Isle of Man effectively became an island around 8,500 years ago at around the time when rising sea levels caused by the melting glaciers cut Mesolithic Britain off from continental Europe for the last time. A land bridge had earlier existed between the Isle of Man and Cumbria, but the location and opening of the land bridge remain poorly understood.\n\nThe earliest traces of people on the Isle of Man date back to the Mesolithic Period, also known as the Middle Stone Age. The first residents lived in small natural shelters, hunting, gathering and fishing for their food. They used small tools made of flint or bone, examples of which have been found near the coast. Representatives of these artifacts are kept at the Manx National Heritage museum.\n\nThe Neolithic Period marked the coming of farming, improved stone tools and pottery. During this period megalithic monuments began to appear around the island. Examples are found at Cashtal yn Ard near Maughold, King Orry's Grave in Laxey, Meayll Circle near Cregneash, and Ballaharra Stones in St John's. The builders of the megaliths were not the only culture during this time; there are also remains of the local Ronaldsway culture (lasting from the late Neolithic into the Bronze Age)\n\nThe Iron Age marked the beginning of Celtic cultural influence. Large hill forts appeared on hill summits and smaller promontory forts along the coastal cliffs, whilst large timber-framed roundhouses were built.\n\nIt is likely that the first Celts to inhabit the Island were Brythonic tribes from mainland Britain. The secular history of the Isle of Man during the Brythonic period remains mysterious. It is not known if the Romans ever made a landing on the island; if they did, little evidence has been discovered; however there is evidence for contact with Roman Britain as an amphora was discovered at the settlement on the South Barrule; it is hypothesised this may have been trade goods or plunder. It has been speculated that the island may have become a haven for Druids and other refugees from Anglesey after the sacking of Mona in AD 60.\n\nIt is generally assumed that Irish invasion or immigration formed the basis of the modern Manx language; Irish migration to the island probably began in the 5th century AD. This is evident in the change in language used in Ogham inscriptions. The transition between \"Manx Brythonic\" (a Brythonic language like modern Welsh) and \"Manx Gaelic\" (a Goidelic language like modern Irish Gaelic and Scottish Gaelic) may have been gradual. One question is whether the present-day Manx language survives from pre-Norse days or reflects a linguistic reintroduction after the Norse invasion. The island lends its name to \"Manannán\", the Brythonic and Gaelic sea god who is said in myth to have once ruled the island.\n\nTradition attributes the island's conversion to Christianity to St Maughold (Maccul), an Irish missionary who gives his name to a parish. There are the remains of around 200 tiny early chapels called keeils scattered across the island. Evidence such as radiocarbon dating and magnetic drift points to many of these being built around AD 550-600.\n\nThe Brythonic culture of \"Manaw\" appears throughout early British tradition and later Welsh writings. The family origins of Gwriad ap Elidyr (father of Merfyn Frych and grandfather of Rhodri the Great) are attributed to a \"Manaw\" and he is sometimes named as \"Gwriad Manaw\". The 1896 discovery of a cross inscribed \"Crux Guriat\" (Cross of Gwriad) and dated to the 8th or 9th century greatly supports this theory.\n\nThe best record of any event before the incursions of the Northmen is attributed to Báetán mac Cairill, king of Ulster, who (according to the \"Annals of Ulster\") led an expedition to Man in 577-578, imposing his authority on the island (though some have thought this event may refer to Manau Gododdin between the Firths of Clyde and Forth, rather than the Isle of Man). After Báetán's death in 581, his rival Áedán mac Gabráin, king of Dál Riata, is said to have taken the island in 582.\n\nEven if the supposed conquest of the Menavian islands – Mann and Anglesey – by Edwin of Northumbria, in 616, did take place, it could not have led to any permanent results, for when the English were driven from the coasts of Cumberland and Lancashire soon afterwards, they could not well have retained their hold on the island to the west of these coasts. One can speculate, however, that when Ecgfrið's Northumbrians laid Ireland waste from Dublin to Drogheda in 684, they temporarily occupied Mann.\n\nThe period of Scandinavian domination is divided into two main epochs – before and after the conquest of Mann by Godred Crovan in 1079. Warfare and unsettled rule characterise the earlier epoch; the later saw comparatively more peace.\n\nBetween about AD 800 and 815 the Vikings came to Mann chiefly for plunder; between about 850 and 990, when they settled there, the island fell under the rule of the Scandinavian Kings of Dublin; and between 990 and 1079, it became subject to the powerful Earls of Orkney.\n\nThere was a mint producing coins on Mann between c. 1025 and c. 1065. These Manx coins were minted from an imported type 2 Hiberno-Norse penny die from Dublin. Hiberno-Norse coins were first minted under Sihtric, King of Dublin. This illustrates that Mann may have been under the thumb of Dublin at this time.\n\nThe conqueror Godred Crovan was evidently a remarkable man, though little is known about him. According to the \"Chronicon Manniae\" he subdued Dublin, and a great part of Leinster, and held the Scots in such subjection that supposedly no one who set out to build a vessel dared to insert more than three bolts. The memory of such a ruler would be likely to survive in tradition, and it seems probable therefore that he is the person commemorated in Manx legend under the name of King Gorse or Orry. He created the Kingdom of Mann and the Isles in around 1079; it included the south-western islands of Scotland until 1164, when two separate kingdoms were formed from it. In 1154, what was later to be known as the Diocese of Sodor and Man was formed by the Catholic Church.\n\nThe islands which were under his rule were called the \"Suðr-eyjar\" (south isles, in contradistinction to the \"Norðr-eyjar\", or the \"north isles\", i.e. Orkney and Shetland), and they consisted of the Hebrides, and of all the smaller western islands of Scotland, and Mann. At a later date his successors took the title of (King of Mann and of the Isles). The kingdom's capital was on St Patrick's Isle, where Peel Castle was built on the site of a Celtic monastery.\n\nOlaf, Godred's son, exercised considerable power, and according to the Chronicle, maintained such close alliance with the kings of Ireland and Scotland that no one ventured to disturb the Isles during his time (1113–1152). In 1156, his son, Godred (reigned 1153–1158), who for a short period ruled over Dublin also, lost the smaller islands off the coast of Argyll as a result of a quarrel with Somerled (the ruler of Argyll). An independent sovereignty thus appeared between the two divisions of his kingdom.\n\nIn the 1130s the Catholic Church sent a small mission to establish the first bishopric on the Isle of Man, and appointed Wimund as the first bishop. He soon afterwards embarked with a band of followers on a career of murder and looting throughout Scotland and the surrounding islands.\n\nDuring the whole of the Scandinavian period, the Isles remained nominally under the suzerainty of the Kings of Norway, but the Norwegians only occasionally asserted it with any vigour. The first such king to assert control over the region was likely Magnus Barelegs, at the turn of the 12th century. It was not until Hakon Hakonarson's 1263 expedition that another king returned to the Isles.\n\nFrom the middle of the 12th century until 1217 the suzerainty had remained of a very shadowy character; Norway had become a prey to civil dissensions. But after that date it became a reality, and Norway consequently came into collision with the growing power of the kingdom of Scotland.\n\nEarly in the 13th century, when Ragnald (reigned 1187–1229) paid homage to King John of England (reigned 1199–1216), we hear for the first time of English intervention in the affairs of Mann. But a period of Scots domination would precede the establishment of full English control.\n\nFinally, in 1261, Alexander III of Scotland sent envoys to Norway to negotiate for the cession of the isles, but their efforts led to no result. He therefore initiated a war, which ended in the indecisive Battle of Largs against the Norwegian fleet in 1263. However, the Norwegian king Haakon Haakonsson died the following winter, and this allowed King Alexander to bring the war to a successful conclusion. Magnus Olafsson, King of Mann and the Isles (reigned 1252–1265), who had campaigned on the Norwegian side, had to surrender all the islands over which he had ruled, except Mann, for which he did homage. Two years later Magnus died and in 1266 King Magnus VI of Norway ceded the islands, including Mann, to Scotland in the Treaty of Perth in consideration of the sum of 4,000 marks (known as in Scotland) and an annuity of 100 marks. But Scotland's rule over Mann did not become firmly established till 1275, when the Manx suffered defeat in the decisive Battle of Ronaldsway, near Castletown.\n\nIn 1290 King Edward I of England sent Walter de Huntercombe to seize possession of Mann, and it remained in English hands until 1313, when Robert Bruce took it after besieging Castle Rushen for five weeks. In about 1333 King Edward III of England granted Mann to William de Montacute, 3rd Baron Montacute (later the 1st Earl of Salisbury), as his absolute possession, without reserving any service to be rendered to him. \n\nThen, in 1346, the Battle of Neville's Cross decided the long struggle between England and Scotland in England's favour. King David II of Scotland, Robert Bruce's last male heir, had been captured in the Battle of Neville's cross and ransomed; however, when Scotland was unable to raise one of the ransom installments, David made a secret agreement with King Edward III of England to cancel it, in return for transferring the Scottish kingdom to an English prince.\n\nFollowing the secret agreement, there followed a confused period when Mann sometimes suffered English rule and sometimes Scottish. In 1388 the island was \"ravaged\" by Sir William Douglas of Nithsdale on his way home from the destruction of the town of Carlingford. \n\nIn 1392 William de Montacute's son sold the island, including sovereignty, to Sir William le Scrope. In 1399 Henry Bolinbroke brought about the beheading of Le Scrope, who had taken the side of Richard II when Bolinbroke usurped the throne and appointed himself \"Henry IV\". The island then came into the de facto possession of Henry, who granted it to Henry Percy, 1st Earl of Northumberland; but following the latter's later attainder, Henry IV, in 1405, made a lifetime grant of it, with the patronage of the bishopric, to Sir John Stanley. In 1406 this grant was extended – on a feudatory basis under the English Crown – to Sir John's heirs and assigns, the feudal fee being the service of rendering homage and two falcons to all future Kings of England on their coronations.\n\nWith the accession of the Stanleys to the throne there begins a more settled epoch in Manx history. Though the island's new rulers rarely visited its shores, they placed it under governors, who, in the main, seem to have treated it with the justice of the time. Of the thirteen members of the family who ruled in Mann, the second Sir John Stanley (1414–1432), James, the 7th Earl (1627–1651), and the 10th Earl of the same name (1702–1736) had the most important influence on it. They first curbed the power of the spiritual barons, introduced trial by jury, which superseded trial by battle, and ordered the laws to be written. The second, known as the Great Stanley, and his wife, Charlotte de la Tremoille (or Tremouille), are probably the most striking figures in Manx history.\n\nIn 1643 Charles I ordered James Stanley, 7th Earl of Derby to go to Mann, where the people, no doubt influenced by events in England, threatened to revolt.\n\nStanley's arrival, with English soldiers, soon put a stop to anything of this kind. He conciliated the people by his affability, brought in Englishmen to teach various handicrafts and tried to help the farmers by improving the breed of Manx horses, and, at the same time, he restricted the exactions of the Church. But the Manx also lost much of their liberty under his rule: they were heavily taxed; troops were quartered upon them; and they also had the more lasting grievance of being compelled to accept leases for three lifetimes instead of holding their land by the straw tenure, which they considered to be equivalent to a customary inheritance.\n\nSix months after the death of Charles I (on 30 January 1649), Stanley received a summons from General Ireton to surrender the island, but he declined to do so. In August 1651 Stanley went to England with some of his troops, among whom were 300 Manxmen, to join King Charles II. Charles was decisively defeated at the Battle of Worcester and Stanley was captured, imprisoned in Chester Castle and then tried by court-martial and executed at Bolton.\n\nSoon after Stanley's death, the Manx Militia, under the command of William Christian (known by his Manx name of Illiam Dhone), rose against the Countess and captured all the insular forts except Rushen and Peel. They were then joined by a Parliamentary force under Colonel Duckenfield, to whom the Countess surrendered after a brief resistance.\n\nOliver Cromwell had appointed Thomas Fairfax \"Lord of Mann and the Isles\" in September 1651, so that Mann continued under a monarchical government and remained in the same relation to England as before.\n\nThe restoration of Stanley government in 1660 therefore caused as little friction and alteration as its temporary cessation had. One of the first acts of the new Lord, Charles Stanley, 8th Earl of Derby, was to order Christian to be tried. He was found guilty and executed. Of the other persons implicated in the rebellion only three were excepted from the general amnesty. But by Order in Council, Charles II pardoned them, and the judges responsible for the sentence on Christian were punished.\n\nCharles Stanley's next act was to dispute the permanency of the tenants' holdings, which they had not at first regarded as being affected by the acceptance of leases, a proceeding which led to an almost open rebellion against his authority and to the neglect of agriculture, in lieu of which the people devoted themselves to the fisheries and to contraband trade.\n\nCharles Stanley, who died in 1672, was succeeded first by his son William Richard George Stanley, 9th Earl of Derby until his death in 1702.\n\nThe agrarian question subsided only in 1704, when James Stanley, 10th Earl of Derby, William's brother and successor, largely through the influence of Bishop Wilson, entered into a compact with his tenants, which became embodied in an Act, called the Act of Settlement. Their compact secured the tenants in the possession of their estates in perpetuity subject only to a fixed rent, and a small fine on succession or alienation. From the great importance of this act to the Manx people it has been called their \"Magna Carta\". As time went on, and the value of the estates increased, the rent payable to the Lord became so small in proportion as to be almost nominal, being extinguished by purchase in 1916.\n\nJames died in 1736, and the suzerainty of the isle passed to James Murray, 2nd Duke of Atholl, his first cousin and heir-male. In 1764 he was succeeded by his only surviving child Charlotte, Baroness Strange, and her husband, John Murray, who (in right of his wife) became Lord of Mann. In about 1720 the contraband trade had greatly increased. In 1726 Parliament had checked it somewhat for a time, but during the last ten years of the Atholl regime (1756–1765) it assumed such proportions that, in the interests of the Imperial revenue, it became necessary to suppress it. With a view to so doing, Parliament passed the Isle of Man Purchase Act 1765 (commonly called the \"Revestment Act\" by the Manx), under which it purchased the rights of the Atholls as Lords of Mann, including the customs revenues of the island, for the sum of £70,000 sterling, and granted an annuity to the Duke and Duchess. The Atholls still retained their manorial rights, the patronage of the bishopric, and certain other perquisites, until they sold them for the sum of £417,144 in 1828.\nUp to the time of the revestment, Tynwald had passed laws concerning the government of the island in all respects and had control over its finances, subject to the approval of the Lord of Mann. After the revestment, or rather after the passage of the Smuggling Act 1765 (commonly called the Mischief Act by the Manx), the Parliament at Westminster legislated with respect to customs, harbours and merchant shipping, and, in measures of a general character, it occasionally inserted clauses permitting the enforcement in the island of penalties in contravention of the Acts of which they formed part. It also assumed the control of the insular customs duties. Such changes, rather than the transference of the full suzerainty to the King of Great Britain and Ireland, modified the (unwritten) constitution of the Isle of Man. Its ancient laws and tenures remained untouched, but in many ways the revestment affected it adversely. The hereditary Lords of Mann had seldom, if ever, functioned as model rulers, but most of them had taken some personal share in its government, and had interested themselves in the well-being of the inhabitants. But now the whole direction of its affairs became the work of officials who regarded the island as a pestilent nest of smugglers, from which it seemed their duty to extract as much revenue as possible.\n\nThere was some alleviation of this state of things between 1793 and 1826, when John Murray, 4th Duke of Atholl served as Governor, since, though he quarrelled with the House of Keys and unduly cared for his own pecuniary interests, he did occasionally exert himself to promote the welfare of the island. After his departure the English officials resumed their sway, but they showed more consideration than before. Moreover, since smuggling, which the Isle of Man Purchase Act had only checked – not suppressed – had by that time almost disappeared, and since the Manx revenue had started to produce a large and increasing surplus, the authorities looked more favourably on the Isle of Man, and, thanks to this fact and to the representations of the Manx people to British ministers in 1837, 1844 and 1853, it obtained a somewhat less stringent customs tariff and an occasional dole towards erecting its much neglected public works.\n\nSince 1866, when the Isle of Man obtained a nominal measure of Home Rule, the Manx people have made remarkable progress, and currently form a prosperous community, with a thriving offshore financial centre, a tourist industry (albeit smaller than in the past) and a variety of other industries.\n\nThe Isle of Man was a base for alien civilian internment camps in both the First World War (1914–18) and the Second World War (1939–45). During the First World War there were two camps: one a requisitioned holiday camp in Douglas and the other the purpose-built Knockaloe camp near Peel in the parish of Patrick. During the Second World War there were a number of smaller camps in Douglas, Peel, Port Erin and Ramsey. The (now disbanded) Manx Regiment was raised in 1938 and saw action during the Second World War.\n\nOn 2 August 1973, a flash fire killed between 50 and 53 people at the Summerland amusement centre in Douglas.\n\nThe early-20th century saw a revival of music and dance, and a limited revival of the Manx language - although the last \"native\" speaker of Manx Gaelic died in the 1970s. In the middle of the 20th century the Taoiseach of the Republic of Ireland, Éamon de Valera, visited, and was so dissatisfied with the lack of support for Manx that he immediately had two recording vans sent over. During the 20th century the Manx tourist economy declined, as the English and Irish started flying to Spain for package holidays. The Manx Government responded to this by successfully promoting the island, with its low tax-rates, as an offshore financial centre, although Man has avoided a place on a recent UK blacklist of tax havens. The financial centre has had its detractors who have pointed to the potential for money laundering.\n\nIn 1949 an Executive Council, chaired by the Lieutenant-Governor and including members of Tynwald, was established. This marked the start of a transfer of executive power from the un-elected Lieutenant-Governor to democratically elected Manx politicians. Finance and the police passed to Manx control between 1958 and 1976. In 1980 a chairman elected by Tynwald replaced the Lieutenant-Governor as Chairman of the Executive Council. Following legislation in 1984, the Executive Council was reconstituted in 1985 to include the chairmen of the eight principal Boards; in 1986 they were given the title of Minister and the chairman was re-titled \"Chief Minister\". In 1986 Sir Miles Walker CBE became the first Chief Minister of the Isle of Man. In 1990 the Executive Council was renamed the \"Council of Ministers\".\n\nThe 1960s also saw a rise in Manx nationalism, spawning the parties Mec Vannin and the Manx National Party, as well as the now defunct (literally \"Underground\"), which mounted a direct-action campaign of spray-painting and attempted house-burning.\n\nOn 5 July 1973 control of the postal service passed from the UK General Post Office to the new Isle of Man Post, which began to issue its own postage stamps.\n\nThe 1990s and early 21st century have seen a greater recognition of indigenous Manx culture, including the opening of the first Manx-language primary school, as well as a general re-evaluation of the island's economy.\n\nSince 1983 the Isle of Man government has designated more than 250 historic structures as Registered Buildings of the Isle of Man.\n\n\n\n"}
{"id": "14764", "url": "https://en.wikipedia.org/wiki?curid=14764", "title": "Geography of the Isle of Man", "text": "Geography of the Isle of Man\n\nThe Isle of Man is an island in the Irish Sea, between Great Britain and Ireland in Western Europe, with a population of almost 85,000. It is a British Crown dependency. It has a small islet, the Calf of Man, to its south. It is located at .\n\nArea:\n\n<br>\"Land:\"\n\n<br>\"Water:\"\n<br>\"Total:\"\nThis makes it:\n\nThe Isle of Man has a coastline of , and a territorial sea extending to a maximum of 12 nm from the coast, or the midpoint between other countries. The total territorial sea area is about 4000 km or 1500 sq miles, which is about 87% of the total area of the jurisdiction of the Isle of Man. The Isle of Man only holds exclusive fishing rights in the first 3 nm. The territorial sea is managed by the Isle of Man Government Department of Infrastructure.\n\nThe Raad ny Foillan long distance footpath runs around the Manx coast.\n\nThe Isle of Man enjoys a temperate climate, with cool summers and mild winters. Average rainfall is high compared to the majority of the British Isles, due to its location to the western side of Great Britain and sufficient distance from Ireland for moisture to be accumulated by the prevailing south-westerly winds. Average rainfall is highest at Snaefell, where it is around a year. At lower levels it can fall to around a year.\n\nTemperatures remain fairly cool, with the recorded maximum being at Ronaldsway.\n\nThe island's terrain is varied. There are two mountainous areas divided by a central valley which runs between Douglas and Peel. The highest point in the Isle of Man, Snaefell, is in the northern area and reaches above sea level. The northern end of the island is a flat plain, consisting of glacial tills and marine sediments. To the south the island is more hilly, with distinct valleys. There is no land below sea level.\n\n\nThere are few severe natural hazards, the most common being high winds, rough seas and dense fog. In recent years there has been a marked increase in the frequency of high winds, heavy rains, summer droughts and flooding both from heavy rain and from high seas. Snow fall has decreased significantly over the past century while temperatures are increasing year round with rainfall decreasing.\n\nAir pollution, marine pollution and waste disposal are issues in the Isle of Man.\n\nIn order of importance, international first, non-statutory last.\n\n\n\n\nThere are 21 ASSIs on the Isle of Man as of 01/09/16. One additional ASSI has been rescinded (Ramsey Harbour).\n\n\nA marine nature reserve was designated in Ramsey Bay in Oct 2011.\n\n\n\nThe Isle of Man had 45 non-statutory wildlife sites as of 30 January 2009, covering about 195 ha (0.75 sq miles) of land and an additional of inter-tidal coast. The Manx Wildlife Trust also manages 24 nature reserves, along with the Calf of Man, as of September 2016:\n\n\n\n\"Main article Geology of the Isle of Man\"\n\nThe majority of the island is formed from highly faulted and folded sedimentary rocks of the Ordovician period. There is a belt of younger Silurian rocks along the west coast between Niarbyl and Peel, and a small area of Devonian sandstones around Peel.\nA band of Carboniferous period rocks underlies part of the northern plain, but is nowhere seen at the surface; however similar age rocks do outcrop in the south between Castletown, Silverdale and Port St Mary. Permo-Triassic age rocks are known to lie beneath the Point of Ayre but, as with the rest of the northern plain, these rocks are concealed by substantial thicknesses of superficial deposits.\n\nThe island has significant deposits of copper, lead and silver, zinc, iron, and plumbago (a mix of graphite and clay). There are also quarries of black marble, limestone flags, clay schist, and granite. These are all modern, and there was no noticeable exploitation of metals or minerals prior to the modern era.\n\nThe island has a census-estimated population of 84,497 according to the most recent 2011 census: up from 79,805 in 2006 and 76,315 in 2001.\n\nThe island's largest town and administrative centre is Douglas, whose population is 23,000 — over a quarter of the population of the island. Neighbouring Onchan, Ramsey in the north, Peel in the west and the three southern ports of Castletown, Port Erin and Port St Mary are the island's other main settlements. Almost all its population lives on or very near the coast.\n\n\n"}
{"id": "14765", "url": "https://en.wikipedia.org/wiki?curid=14765", "title": "Demographics of the Isle of Man", "text": "Demographics of the Isle of Man\n\nThis article is about the demographic features of the population of the Isle of Man, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population. The UN estimate of population as at mid- is .\n\nThe following demographic statistics are from the CIA World Factbook, unless otherwise indicated.\n\nAnglican, The Church of Jesus Christ of Latter-day Saints Roman Catholic, Methodist, Baptist, Presbyterian, Religious Society of Friends, Jehovah's Witnesses, Pentecostalism, Atheism, Agnosticism.\n\nThe Church of England is the established church.\n\n"}
{"id": "14766", "url": "https://en.wikipedia.org/wiki?curid=14766", "title": "Politics of the Isle of Man", "text": "Politics of the Isle of Man\n\nThe government of the Isle of Man is a parliamentary representative democracy. As a Crown Dependency, it is not subordinate to the government of the United Kingdom. That government, however, is responsible for defence and external affairs and could intervene in the domestic affairs of the island under its residual responsibilities to guarantee \"good government\" in all Crown dependencies. The Monarch of the United Kingdom is also the head of state of the Isle of Man, and generally referred to as \"The Queen, Lord of Mann\". Legislation of the Isle of Man defines \"the Crown in right of the Isle of Man\" as separate from the \"Crown in right of the United Kingdom\". Her representative on the island is the Lieutenant Governor of the Isle of Man, but his role is mostly ceremonial, though he does have the power to grant Royal Assent (the withholding of which is the same as a veto).\n\nAlthough the Isle of Man is not part of the United Kingdom, its people are British citizens under UK law — there is no separate Manx citizenship. The United Kingdom is responsible for all the island's external affairs, including citizenship, defence, good governance, and foreign relations. The island has no representation at either the UK or EU parliaments.\n\nThe legislative power of the government is vested in a bicameral (sometimes called tricameral) parliament called Tynwald (said to be the world's oldest \"continuously existing\" parliament), which consists of the directly-elected House of Keys and the indirectly chosen Legislative Council. After every House of Keys general election, the members of Tynwald elect from amongst themselves the Chief Minister of the Isle of Man, who serves as the head of government for five years (until the next general election). Executive power is vested in the Lieutenant Governor (as Governor-in-Council), the Chief Minister, and the Isle of Man's Council of Ministers. The judiciary is independent of the executive and the legislature.\n\nDouglas, the largest town on the Isle of Man, is its capital and seat of government, where the Government offices and the parliament chambers (Tynwald) are located.\n\nThe Head of State is the Lord of Mann, which is a hereditary position held by the British monarch (currently Queen Elizabeth II). The Lieutenant Governor is appointed by the Queen, on the advice of the UK's Secretary of State for Justice, for a five-year term and nominally exercises executive power on behalf of the Queen. The Chief Minister is elected by Tynwald following every House of Keys general election and serves for five years until the next general election.\n\nWhen acting as Lord of Mann, the Queen acts on the advice of the Secretary of State for Justice and Lord Chancellor of the United Kingdom having prime responsibility as Privy Counsellor for Manx affairs.\n\nThe executive branch under the Chief Minister is referred to as \"the Government\" or the \"Civil Service\", and consists of the Council of Ministers, nine Departments, ten Statutory Boards and three Offices. Each Department is run by a Minister who reports directly to the Council of Ministers. The Civil Service has more than 2000 employees and the total number of public sector employees including the Civil Service, teachers, nurses, police, etc. is about 9000 people. This is somewhat more than 10% of the population of the Island, and a full 23% of the working population. This does not include any military forces, as defence is the responsibility of the United Kingdom.\n\nThe Manx legislature is Tynwald, which consists of two chambers. The House of Keys has 24 members, elected for a five-year term in two-seat constituencies by the whole island. The minimum voting age is 16. The Legislative Council has eleven members: the President of Tynwald, the Bishop of Sodor and Man, the Attorney General (non-voting) and eight other members elected by the House of Keys for a five-year term, with four retiring at a time. (In the past they have often already been Members of the House of Keys, but must leave the Keys if elected to the Council.) There are also joint sittings of the Tynwald Court (the two houses together).\n\nIn the 2016 Manx general election, on 22 September, the Liberal Vannin Party won three seats, tying their 2011 results; all 21 remaining seats were won by independents. However one of those three members now sits as an independent. 12 of the 24 MHKs were newly elected to office. Turnout slightly improved from 2011 with 56% of eligible voters turning out, ranging from 40% in Douglas East to 65% in Ayre & Michael.\n\nMost Manx politicians stand for election as independents rather than as representatives of political parties. Though political parties do exist, their influence is not nearly as strong as in the United Kingdom. Consequently, much Manx legislation develops through consensus among the members of Tynwald, which contrasts with the much more adversarial nature of the British Parliament.\n\nThe largest political party is the Liberal Vannin Party, which promotes liberalism, greater Manx independence and more accountability in Government.\n\nA Manx Labour Party also exists, unaffiliated to the British Labour Party. Its candidates won a combined 1.4% of the overall vote in 2016, however it holds 2 seats on the Legislative Council.\n\nA political pressure group Mec Vannin advocates the establishment of a sovereign republic.\n\nThe Isle of Man Green Party, which was founded in 2016, holds 2 local government seats and promotes Green politics.\n\nThe island also formerly had a Manx National Party. There are Manx members in the Celtic League, a political pressure group that advocates greater co-operation between and political autonomy for the Celtic nations.\n\nThe main political issues include the Island's relationship with the finance sector, housing prices and shortages, and the Manx language.\n\nThe UK Parliament has paramount power to legislate for the Isle of Man on all matters, but it is a long-standing convention that it does not do so on domestic (\"insular\") matters without Tynwald's consent.\n\nOccasionally, the UK Parliament acts against the wishes of Tynwald: the most recent example was the Marine etc. Broadcasting (Offences) Act 1967, which banned pirate radio stations from operating in Manx waters. Legislation to accomplish this was defeated on its second reading in the House of Keys, prompting Westminster to legislate directly.\n\nThe UK's secondary legislation (regulations and Statutory Instruments) cannot be extended to apply to the Isle of Man.\n\nThe Isle of Man is subject to certain European Union laws, by virtue of a being a territory for which the UK has responsibility in international law. These laws are those for areas not covered by the Protocol 3 opt-out that the UK obtained for the Isle of Man in its accession treaty: the excluded areas are free movement of persons, services and capital, and taxation and social policy harmonisation.\n\nThe UK has had several disputes with the European Court of Human Rights about the Isle of Man's laws concerning birching (corporal punishment) and sodomy.\n\nThe lowest courts in the Isle of Man are presided over by the High Bailiff and the Deputy High Bailiff, along with lay Justices of the Peace. The High Court of Justice consists of three civil divisions and is presided over by a Deemster. Appeals are dealt with by the Staff of Government Division with final appeal to the Judicial Committee of the Privy Council in the United Kingdom. The head of the Judiciary is the First Deemster and Clerk of the Rolls. The other High and Appeal Court Judges are the Second Deemster, Deputy Deemster and Judge of Appeal, all of whom are appointed by the Lieutenant Governor.\n\nThe Court of General Gaol Delivery is the criminal court for serious offences (effectively the equivalent of a Crown Court in England). It is theoretically not part of the High Court, but is effectively the criminal division of the court. The Second Deemster normally sits as the judge in this court. In 1992, His Honour Deemster Callow passed the last-ever sentence of death in a court in the British Islands (which was commuted to life imprisonment). Capital punishment in the Isle of Man was formally abolished by Tynwald in 1993 (although the last execution on the island took place in 1872).\n\n\n"}
{"id": "14767", "url": "https://en.wikipedia.org/wiki?curid=14767", "title": "Economy of the Isle of Man", "text": "Economy of the Isle of Man\n\nThe Isle of Man, one of the Crown dependencies, is a low-tax economy and offshore financial centre. Located in the Irish Sea, it is within the British Isles but does not form part of the United Kingdom or the European Communities. \n\nInsurance, online gambling operators and developers, ICT, and Offshore banking form key sectors of the island's economy.\n\nAs of 2016, the World Bank assessed the island's Gross National Income (GNI) per capita at US$89,970. The Isle of Man Government's own National Income Report shows the largest sectors of the economy are insurance and eGaming with 17% of GNI each, followed by ICT and banking with 9% each, with tourist accommodation in the lowest sector at 0.3%.\n\nAfter 32 years of continued Gross Domestic Product (GDP) growth, the financial year 2015/16 showed the first drop in GDP, of 0.9%, triggered by decline in eGaming revenues.\n\nThe unemployment rate remains low at around 1%.\n\nProperty prices are flat or declining, but recent figures also show an increase in resident income tax payers.\n\nThe government's policy of offering incentives to high-technology companies and financial institutions to locate on the island has expanded employment opportunities in high-income industries. Agriculture, fishing, and the hospitality industry, once the mainstays of the economy, now make declining contributions to the island's GNP. The hospitality sector contributed just of 0.3% of GNP in 2015/16, and 629 jobs in 2016. eGaming and ICT contribute the great bulk of GNP. The stability of the island's government and its openness for business make the Isle of Man an attractive alternative jurisdiction (DAW Index ranked 3).\n\nIn the Vision2020 the Isle of Man government lays out the national strategy of economic growth, seeking an increase of the economically active population an promoting the Island as an <nowiki>'Enterprise Island, \"Tech Isle', 'Manufacturing centre of excellence', 'Offshore energy hub', 'Destination Island' and for 'Distinctive local food and drink'</nowiki>.\n\nThe government has published its national economic strategies for several emerging sectors: aerospace, biomed, digital media, ICT.\n\nThe Isle of Man is a low-tax economy with no capital gains tax, wealth tax, stamp duty, or inheritance tax; and a top rate of income tax of 20%. A tax cap is in force: the maximum amount of tax payable by an individual is £125,000; or £250,000 for couples if they choose to have their incomes jointly assessed. Personal income is assessed and taxed on a total worldwide income basis rather than on a remittance basis. This means that all income earned throughout the world is assessable for Manx tax, rather than only income earned in or brought into the Island.\n\nThe standard rate of corporation tax for residents and non-residents is 0%; retail business profits above £500,000 and banking business income are taxed at 10%, and rental (or other) income from land and buildings situated on the Isle of Man is taxed at 20%.\n\nTrade is mostly with the United Kingdom. The Isle of Man has free access to European Union markets for goods, but only has restricted access for services, people, or financial products.\n\nThe Isle of Man as an offshore financial centre has been repeatedly featured in the press as a tax haven, most recently in the wake of the Paradise Papers. \n\nThe Organisation for Economic Co-operation and Development's (OECD) Global Forum on Transparency and Exchange of Information for Tax Purposes has rated the Isle of Man as 'top compliant' for a second time: a status which only three jurisdictions in the world have achieved so far. The island has become the second nation after Austria to ratify a multilateral convention with the OECD to implement measures to prevent Base Erosion and Profit Shifting (BEPS). \n\nIn a report the European Council lists the Isle of Man together with the other two Crown Dependencies (Guernsey and Jersey) as well as Bermuda, the Cayman Islands and Vanuatu, as committed to addressing the Council's concerns of \"Existence of tax regimes that facilitate offshore structures which attract profits without real economic activity\" by 2018.\n\nThe Isle of Man's Department for Enterprise manages the diversified economy in twelve key sectors. The largest individual sectors by GNI are insurance and eGaming with 17% of GNI each, followed by ICT and banking with 9% each. The 2016 census lists 41,636 total employed. The largest sectors by employment are \"medical and health\", \"financial and business services\", construction, retail and public administration. Manufacturing, focused on aerospace and the food and drink industry, employs almost 2000 workers and contributes about 5% of Gross Domestic Product(GDP). The sector provides laser optics, industrial diamonds, electronics, plastics and aerospace precision engineering.\n\nInsurance, banking (includes retail banking, offshore banking and other banking services), other finance and business services, and corporate service providers together contribute the most to the GNI and most of the jobs, with 10,057 people employed in 2016. \n\nAmong the largest employers of the Island's private sector are eGaming (online gambling) companies like The Stars Group, Microgaming, Newfield, and Playtech. The Manx eGaming Association MEGA is representing the sector. Licenses are issued by the Gambling Supervision Commission.\n\nIn 2005 PokerStars, one of the world's largest online poker sites, relocated its headquarters to the Isle of Man from Costa Rica. In 2006, RNG Gaming a large gaming software developer of P2P tournaments and Get21, a multiplayer online blackjack site, based their corporate offices on the island.\n\nThe Isle of Man Government Lottery operated from 1986 to 1997. Since 2 December 1999 the island has participated in the United Kingdom National Lottery. The island is the only jurisdiction outside the United Kingdom where it is possible to play the UK National Lottery. Since 2010 it has also been possible for projects in the Isle of Man to receive national lottery Good Causes Funding. The good causes funding is distributed by the Manx Lottery Trust. Tynwald receives the 12p lottery duty for tickets sold in the Island.\n\nThe shortage of workers with ICT skills is tackled by several initiatives, like an IT and education campus, a new cyber security degree at the University College of Man, a Code Club, and a work permit waiver for skilled immigrants.\n\nSince 1995 Isle of Man Film has co-financed and co-produced over 100 feature film and television dramas which have all filmed on the Island. \n\nAmong the most successful productions funded in part by Isle of Man Film agency were \"Waking Ned\", where the Manx countryside stood in for rural Ireland, and films like \"Stormbreaker\", \"Shergar\", \"Tom Brown's Schooldays\", \"I Capture the Castle\", \"The Libertine\", \"Island at War\" (TV series), \"Five Children and It\", \"Colour Me Kubrick\", \"Sparkle\", and others. Other films that have been filmed on the Isle of Man include \"Thomas and the Magic Railroad\", \"Harry Potter and the Chamber of Secrets\", \"Keeping Mum and Mindhorn.\"\n\n2011 Isle of Man Film Oxford Economics was commissioned by Isle of Man Film Ltd to conduct a study into the economic impact of the film industry on the Isle of. Man. The recommendation of this report for Isle of Man Film was to partner with a more established film institution in the UK to source more Isle of Man film production opportunities. This led to the investment of the Isle of Man Government to take shares in Pinewood Shepperton Plc which were sold later with profit.\n\nOnce one of the busiest areas of film production in the British Isles, the Isle of Man hopes to use its strong foundation in film to grow its television and new digital media industry. In a recent Isle of Man Department of Economic Development strategic review, the Island's over 2,000 jobs counting digital sector features 'digital media' and the creative industries, and embraces partnerships with the industry and its individual sector bodies like the Isle of Media, a new media cluster. \n\nHosting of motorsports events, like the Isle of Man Car Rally and the more-prominent TT motorcycle races, contributes to the tourism economy. \n\nTourism in the Isle of Man developed from advances in transport to the island. In 1819 the first steamship \"Robert Bruce\" came to the island, only seven years after the first steam vessel in the UK. In the 1820s, tourism was growing due to improved transport. The island government's own report for the financial years 2014/15-2015/16 shows tourist accommodation to be in the lowest sector at 0.3%, ranking slightly above 'mining and quarrying' (0.1%).\n\nSince 1999, the Isle of Man has received electricity through the world's longest submarine AC cable, the 90 kV Isle of Man to England Interconnector, as well as from a natural gas power station in Douglas, an oil power station in Peel and a small hydro-electric power station in Sulby Glen.\n\nThe Island is connected with five submarine cables to the UK and Ireland.\n\nWhile the Isle of Man Communications Commission refers to Akamai’s recent State of the Internet Report for Q1 2017, with \"the Island ranked 8th in the world for percentage of broadband connections with >4 Mb/s connectivity, with 96% of users connecting at speeds greater than 4Mb/s\", an \"international league table of broadband speeds puts the Isle of Man at 50th in the world\". Manx Telecom recently announced to roll out Fibre-to-the-Home (FTTH) superfast broadband with download speeds of up to 1Gigabit per second. \n\nRonaldsway Airport links the Isle of Man with six airlines to eleven UK and Irish scheduled flight destinations. \n\nThe Steam Packet Company provides ferry services to Liverpool, Heysham, Belfast and Dublin.\n\nLabour force—by occupation:\nagriculture, forestry and fishing 3%, manufacturing 11%, construction 10%, transport and communication 8%, wholesale and retail distribution 11%, professional and scientific services 18%, public administration 6%, banking and finance 18%, tourism 2%, entertainment and catering 3%, miscellaneous services 10%\n\nUnemployment rate:\nnominally 2.0% (January 2016)\n\nIndustries:\nfinancial services, light manufacturing, tourism\n\nAgriculture—products:\ncereals, vegetables, cattle, sheep, pigs, poultry\n\nExports:\n$NA\n\nExports—commodities:\ntweeds, herring, processed shellfish, beef, lamb\n\nExports—partners:\nUK\n\nImports:\n$NA\n\nImports—commodities:\ntimber, fertilizers, fish\n\nImports—partners:\nUK\n\nDebt—external:\n$NA\n\nEconomic aid—recipient:\n$NA\n\nCurrency:\n1 Isle of Man pound = 100 pence\n\nExchange rates:\nthe Manx pound is at par with the British pound\n\nFiscal year:\n1 April – 31 March\n\n"}
{"id": "14768", "url": "https://en.wikipedia.org/wiki?curid=14768", "title": "Communications in the Isle of Man", "text": "Communications in the Isle of Man\n\nThe Isle of Man has an extensive communications infrastructure consisting of telephone cables, submarine cables, and an array of television and mobile phone transmitters and towers.\n\nThe history of Manx telecommunications starts in 1859, when the Isle of Man Electric Telegraph Company was formed on the island with the intention of connecting across the island by telegraph, and allowing messages to be sent onwards to the UK. In August 1859, a long cable was commissioned from Glass, Elliot and Company of Greenwich and laid from Cranstal (north of Ramsey) to St Bees in Cumbria using the chartered cable ship \"Resolute\". The cable was single-core, with gutta-percha insulation.\n\nTwenty miles of overhead cable were also erected from Cranstal south to Ramsey, and on to Douglas. In England, the telegraph was connected to Whitehaven and the circuits of the Electric Telegraph Company.\n\nThe telegraph offices were located at 64 Athol Street, Douglas (also the company's head office) and at East Quay, Ramsey (now Marina House).\n\nOn 10 August 1860 the company was statutorily incorporated by an Act of Tynwald with a capital of £5,500.\n\nThe currents at Cranstal proved too strong, and in 1864 the cable was taken up and relaid further south, at Port-e-Vullen in Ramsey Bay. It was later relaid to land even further south at Port Cornaa.\n\nFollowing the 1869 finalisation of UK telegraph nationalisation into a General Post Office monopoly, the Isle of Man Telegraph Company was nationalised in 1870 under the Telegraph Act 1870 (an Act of Parliament) at a cost to the British Government of £16,106 (paid in 1872 following arbitration proceedings over the value). Prior to nationalisation, the island's telegraph operations had been performing poorly and the company's share price valued it at around £100.\n\nSubsequent to nationalisation, operations were taken over by the GPO. The internal telegraph system was extended within a year to Castletown and Peel, however by then the previous lack of modern communications in Castletown had already started the Isle of Man Government on its move to Douglas.\n\nDue to increasing usage in the years following nationalisation, further cables between Port Cornaa and St Bees were laid in 1875 and 1885.\n\nBy 1883 Smith's Directory listed several telegraph offices operated by the Post Office, in addition to those at Douglas, Ramsey, Castletown and Peel the telegraph was also available at Laxey, Ballaugh, and Port St. Mary.\n\nThroughout the First World War, the cable landing station at Port Cornaa was guarded by the Isle of Man Volunteer Corps.\n\nThe undersea telegraph cables have been disused since the 1950s, but remain in place.\n\nA Teleport, with several earth stations, is currently under construction on the Isle of Man. SES Satellite Leasing, the entrepreneurial investment arm of SES. The teleport is expected to enter into service in 2017. It will be a state-of-the-art facility providing satellite telemetry, tracking and commanding (TT&C) facilities and capacity management, together with a wide range of teleport services such as uplink, downlink, and contribution services for broadcasters and data centres.\n\nThe main telephone provider on the Isle of Man today is Manx Telecom.\n\nIn 1889 George Gillmore, formerly an electrician for the GPO's Manx telegraph operations, was granted a licence by the Postmaster General to operate the Isle of Man's first telephone service. Based in an exchange in Athol Street, early customers of Gilbert's telephone service included the Isle of Man Steam Packet Company and the Isle of Man Railway. Not having the resources to fund expansion or a link to England, Gillmore sold his licence to the National Telephone Company and stayed on as their manager on the island.\n\nBy 1901 there were 600 subscribers, and the telephone system had been extended to Ramsey, Castletown, Peel, Port Erin, Port St. Mary and Onchan.\n\nOn 1 January 1912 the National Telephone Company was nationalised and merged into the General Post Office by the Telephone Transfer Act 1911. Only Guernsey, Portsmouth and Hull remained outside of the GPO.\n\nIn 1922, the General Post Office offered to sell the island's telephone service to the Manx government, but the offer was not taken up. A similar arrangement in Jersey for that island's telephone service was concluded in 1923.\n\nThe first off-island telephone link was established in 1929, with the laying of a cable by the \"CS Faraday\" between Port Erin and Ballyhornan in Northern Ireland, a distance of 57 km, and then between Port Grenaugh and Blackpool, primarily to provide a link to Northern Ireland. The cable was completed on 6 June 1929 and the first call between the Isle of Man and the outside world was made on 28 June 1929 by Lieutenant Governor Sir Claude Hill in Douglas to the Postmaster General in Liverpool. The cable initially carried only two trunk circuits.\n\nIn 1942, a pioneering VHF frequency-modulated radio-link was established between Creg-na-Baa and the UK to provide an alternative to the sub-sea cable. This has since been discontinued.\n\nThis was augmented on 24 June 1943 by a long cable between Cemaes Bay in Anglesey and Port Erin, which had the world's first submerged repeater, laid by \"HMCS Iris\". The repeater doubled the possible number of circuits on the cable, and although it failed after only five months, its replacement worked for seven years.\n\nIn 1962 a further undersea cable was laid by \"HMTS Ariel\" between Colwyn Bay and the Island.\n\nHistorically, the telephone system on the Isle of Man had been run as a monopoly by the British General Post Office, and later British Telecommunications, and operated as part of the Liverpool telephone district.\n\nBy 1985 the privatised British Telecom had inherited the telephone operations of the GPO, including those on the Isle of Man. At this time the Manx Government announced that it would award a 20-year licence to operate the telephone system in a tender process. As part of this process, in 1986 British Telecom created a Manx-registered subsidiary company, Manx Telecom, to bid for the tender. It was believed that a local identity and management would be more politically acceptable in the tendering process as they competed with Cable & Wireless to win the licence. Manx Telecom won the tender, and commenced operations under the new identity from 1 January 1987.\n\nOn 28 March 1988 an 8,000 telephone circuit fibre optic cable, the longest unregenerated system in Europe, was inaugurated. In links Port Grenaugh to Silecroft in Cumbria, and was laid in September 1987. The cable was buried in the seabed along its entire length.\n\nA further fibre optic cable, known as BT-MT1 was laid in October 1990 between Millom in Cumbria and Douglas, a distance of . Jointly operated by BT and Manx Telecom, it provides six channels each with a bandwidth of 140 Mbit/s. This cable remains in use today.\n\nIn July 1992, Mercury Communications laid the LANIS fibre-optic cables. LANIS-1 runs for between Port Grenaugh and Blackpool, and LANIS-2 runs for between the Isle of Man and Northern Ireland. They have six channels each with a bandwidth of 565 Mbit/s. The LANIS cables are now operated by Cable & Wireless. The LANIS-1 cable was damaged 600 m off Port Grenaugh on 27 November 2006, causing loss of the link and resulting in temporary Internet access issues for some Manx customers whilst it was awaiting repair.\n\nOn 17 November 2001 Manx Telecom became part of mmO following the demerger of BT Wireless's operations from BT Group, and the company was owned by Telefónica. On 4 June 2010 Manx Telecom was sold by Telefónica to UK private equity investor HgCapital (who were buying the majority stake), alongside telecoms management company CPS Partners\n\nIn December 2007, the Manx Electricity Authority and its telecoms subsidiary, e-llan Communications, commissioned the lighting of a new undersea fibre-optic link. It was laid in 1999 between Blackpool and Douglas as part of the Isle of Man to England Interconnector which connects the Manx electricity system to the UK's National Grid.\n\nIn March 2009, BlueWave Communications installed microwave links to Ireland and the UK. These were the first off-island microwave links.\n\nAccording to the CIA World Factbook, in 1999 there were 51,000 fixed telephone lines in use in the Isle of Man.\n\nThe Isle of Man is included within the UK telephone numbering system, and is accessed externally via UK area codes, rather than by its own country calling code. The area codes currently in use are: +44 1624 (landlines) and +44 7425 / +44 7624 / +44 7924 (mobiles).\n\n\nSubmarine cables in Manx waters are governed by the Submarine Cables Act 2003 (an Act of Tynwald).\n\n\nIt is also rumoured that various online gaming companies operate their own networks outside of these providers, although they do not resell that service.\n\nThe mobile phone network operated by Manx Telecom has been used by O as an environment for developing and testing new products and services prior to wider rollout. In December 2001, the company became the first telecommunications operator in Europe to launch a live 3G network. In November 2005, the company became the first in Europe to offer its customers an HSDPA (3.5G) service.\n\nSure built their own mobile network on the island in 2007 and following various upgrades now deliver 2G/3G and 4G services\n\nIn 1996 the Isle of Man government obtained permission to use the .im national top level domain (TLD) and has ultimate responsibility for its use. The domain is managed on a daily basis by Domicilium (IOM) Limited, an island based Internet service provider. Broadband Internet services are available through five local providers which are Manx Telecom, Sure, Wi-Manx, Domicilium, and BlueWave Communications.\n\nThe public-service commercial radio station for the island is Manx Radio. Manx Radio is part funded by government grant, and partly by advertising. There are two other Manx-based FM radio stations, Energy FM and 3 FM.\n\nBBC national radio stations are also relayed locally via a transmitter located to the south of Douglas, relayed from Sandale transmitting station in Cumbria, as well as a signal feed from the Holme Moss transmitting station in West Yorkshire. The Douglas transmitter also broadcasts the BBC's DAB digital radio services and Classic FM.\n\nManx Radio is the only local service to broadcast on AM medium wave. No UK services are relayed via local AM transmitters. No longwave stations operate from the Island, although one (Musicmann279) was proposed. There are currently no proposals to broadcast any of the three insular FM stations on DAB.\n\n\nThere is no Island-specific television service. Local transmitters retransmit UK Freeview broadcasts. The BBC region is BBC North West and the ITV region is Granada.\n\nMany TV services are available by satellite, such as Sky, and Freesat from the Astra 2/Eurobird 1 group, as well as services from a range of other satellites around Europe such as Astra 1 and Hot Bird.\n\nManx ViaSat-IOM, ManSat, Telesat-IOM companies uses the first communications satellite ViaSat-1 that launched in 2011 and positioned at the Isle of Man registered 115.1 degrees West longitude geostationary orbit point. In some areas, terrestrial television directly from the United Kingdom or Ireland can also be received.\n\nAnalogue television transmission ceased between 2008 and 2009, when limited local transmission of digital terrestrial television commenced. The UK's television licence regime extends to the Island.\n\nThere is no Island-specific opt-out of the BBC regional news programme \"North West Tonight\", in the way that the Channel Islands get their own version of \"Spotlight\".\n\nTelevision was first received on the Isle of Man from the Holme Moss transmitter which started broadcasting BBC Television from 12 October 1951. Signals from Holme Moss were easily received on the Isle of Man.\n\nITV television has been available on parts of the east of the Isle of Man on 3 May 1956 when Granada Television transmissions started from the Winter Hill transmitting station, and to parts of the west of the island on 1 October 1959 from the Black Mountain transmitting station in Northern Ireland which broadcast Ulster Television. Parts of the north of the island received Border Television since 1 September 1961, initially directly from the Caldbeck transmitting station in Cumberland. On 26 March 1965 Border Television commenced relay of their signal through a local transmitter on Richmond Hill, above sea level and from the centre of Douglas. The site allowed reliable reception of the Caldbeck signal, which is rebroadcast on a different frequency. The high transmission tower was re-sited from London, where it had been used for early ITV transmissions. Richmond Hill was decommissioned after the close of 405 line broadcasts, although the 200 ft tower remained in use for radio with Manx Radio transmitting on 96.9 MHz and then 97.3 MHz until 1989. Manx Radio moved their FM service to the Carnane site and the frequency changed to the current 97.2 MHz.\n\nThe television broadcasts are now transmitted from a high transmitter on a hill to the south of Douglas. The transmitter is operated by Arqiva and is directly fed using a fibre optic cable. There are further sub-relay transmitters across the island. Following a realignment of ITV regional services and the digital switchover, the Douglas relay switched ITV broadcasts to Granada Television on Thursday 17 July 2009.\n\nThe Broadcasting Act 1993 (An Act of Tynwald) allows for the establishment of local television services. Only one application for a licence to run such a service was received by the Communications Commission. That application was rejected.\n\nAccording to the CIA World Factbook, in 1999 there were 27,490 televisions in use in the Isle of Man.\n\n\nIsle of Man Post issues its own stamps for use within the island and for sending post off-island. Only Manx stamps are valid for sending mail using the postal system. The Isle of Man adopted postcodes in 1993 using the prefix IM to fit in with the already established UK postcode system.\n\n\n"}
{"id": "14769", "url": "https://en.wikipedia.org/wiki?curid=14769", "title": "Transport in the Isle of Man", "text": "Transport in the Isle of Man\n\nThere are a number of transport services around the Isle of Man, mostly consisting of paved roads, public transport, rail services, sea ports and an airport.\n\nThe island has a total of of public roads, all of which are paved. Roads are numbered using a numbering scheme similar to the numbering schemes of Great Britain and Northern Ireland; each road is assigned a letter, which represents the road's category, followed by a 1 or 2 digit number. \"A\" roads are the main roads of the island whilst roads labelled \"B\", \"C\", \"D\" or \"U\" decrease in size and/or quality. (The C, D and U numbers are not marked on most maps or on signposts.) There is no national speed limit - some roads may be driven at any speed which is safe and appropriate. Careless and dangerous driving laws still apply, so one may not drive at absolutely any speed, and there are local speed limits on many roads. Many unrestricted roads have frequent bends which even the most experienced driver cannot see round. Measured travel speeds (see table below) are often relatively low. Drivers are limited to in the first two years after passing their driving test (Isle of Man citizens are permitted to start driving at the age of sixteen) and some are not used to having to make progress in the same way as on a larger road network such as that in the UK: even a cautious driver can get from anywhere in the island to anywhere else in ninety minutes).\n\nSet against this is a strong culture of motor sport enthusiasm (pinnacled in the TT, but there are many events during the year) and many residents familiar with the roads are well used to traversing country roads at speeds illegal on similar roads elsewhere. This leads to a very diverse spread of both driving competence and speed. In an official survey in 2006 the introduction of blanket speed limits was refused by the population, suggesting that a large number appreciate the freedom.\n\nThere is a comprehensive bus network, operated by Bus Vannin, a department of the Isle of Man Government, with most routes originating or terminating in Douglas.\n\nThe island has a total of of railway. There are seven separate public rail or tram systems on the island:\n\nTo be reduced in 2019 due to works on the promenade.\n\nAll of these routes are seasonal.\n\nThe only commercial airport on the island is the Isle of Man Airport at Ronaldsway. Scheduled services operate to and from various cities in the United Kingdom and Ireland, operated by several different airlines.\n\nThe island's other paved runways are at Jurby and Andreas. Jurby remains in Isle of Man Government ownership and is used for motorsport events and, previously, airshows, while Andreas is privately owned and used by a local glider club. The old Hall Caine Airport, a grass field near Ramsey, is no longer used.\n\nThe Isle of Man Aircraft Register became operational on 1 May 2007. The register is open to all non-commercial aircraft and is intended to be of particular interest to professionally flown corporate operators.\nAs of November 2012 a total of 537 corporate and private aircraft had been registered.\n\nThere are ports at Castletown, Douglas, Peel, Port St Mary and Ramsey. Douglas is served by frequent ferries to/from England and occasional ferries to/from Ireland; the sole operator is the Isle of Man Steam Packet Company, with exclusive use of the Isle of Man Sea Terminal and the Douglas port linkspans under the conditions of the user agreement with the Isle of Man Government.\n\nThe Isle of Man register comprised 404 merchant ships of 1,000 GT or over at the end of 2017.\n\n"}
{"id": "14773", "url": "https://en.wikipedia.org/wiki?curid=14773", "title": "Information theory", "text": "Information theory\n\nInformation theory studies the quantification, storage, and communication of information. It was originally proposed by Claude E. Shannon in 1948 to find fundamental limits on signal processing and communication operations such as data compression, in a landmark paper entitled \"A Mathematical Theory of Communication\". Applications of fundamental topics of information theory include lossless data compression (e.g. ZIP files), lossy data compression (e.g. MP3s and JPEGs), and channel coding (e.g. for DSL). Its impact has been crucial to the success of the Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones, the development of the Internet, the study of linguistics and of human perception, the understanding of black holes, and numerous other fields.\n\nA key measure in information theory is \"entropy\". Entropy quantifies the amount of uncertainty involved in the value of a random variable or the outcome of a random process. For example, identifying the outcome of a fair coin flip (with two equally likely outcomes) provides less information (lower entropy) than specifying the outcome from a roll of a (with six equally likely outcomes). Some other important measures in information theory are mutual information, channel capacity, error exponents, and relative entropy.\n\nThe field is at the intersection of mathematics, statistics, computer science, physics, neurobiology, information engineering, and electrical engineering. The theory has also found applications in other areas, including statistical inference, natural language processing, cryptography, neurobiology, human vision, the evolution and function of molecular codes (bioinformatics), model selection in statistics, thermal physics, quantum computing, linguistics, plagiarism detection, pattern recognition, and anomaly detection. Important sub-fields of information theory include source coding, channel coding, algorithmic complexity theory, algorithmic information theory, information-theoretic security, and measures of information.\n\nInformation theory studies the transmission, processing, extraction, and utilization of information. Abstractly, information can be thought of as the resolution of uncertainty. In the case of communication of information over a noisy channel, this abstract concept was made concrete in 1948 by Claude Shannon in his paper \"A Mathematical Theory of Communication\", in which \"information\" is thought of as a set of possible messages, where the goal is to send these messages over a noisy channel, and then to have the receiver reconstruct the message with low probability of error, in spite of the channel noise. Shannon's main result, the noisy-channel coding theorem showed that, in the limit of many channel uses, the rate of information that is asymptotically achievable is equal to the channel capacity, a quantity dependent merely on the statistics of the channel over which the messages are sent.\n\nInformation theory is closely associated with a collection of pure and applied disciplines that have been investigated and reduced to engineering practice under a variety of rubrics throughout the world over the past half century or more: adaptive systems, anticipatory systems, artificial intelligence, complex systems, complexity science, cybernetics, informatics, machine learning, along with systems sciences of many descriptions. Information theory is a broad and deep mathematical theory, with equally broad and deep applications, amongst which is the vital field of coding theory.\n\nCoding theory is concerned with finding explicit methods, called \"codes\", for increasing the efficiency and reducing the error rate of data communication over noisy channels to near the channel capacity. These codes can be roughly subdivided into data compression (source coding) and error-correction (channel coding) techniques. In the latter case, it took many years to find the methods Shannon's work proved were possible. A third class of information theory codes are cryptographic algorithms (both codes and ciphers). Concepts, methods and results from coding theory and information theory are widely used in cryptography and cryptanalysis. \"See the article ban (unit) for a historical application.\"\n\nInformation theory is also used in information retrieval, intelligence gathering, gambling, statistics, and even in musical composition.\n\nThe landmark event that \"established\" the discipline of information theory and brought it to immediate worldwide attention was the publication of Claude E. Shannon's classic paper \"A Mathematical Theory of Communication\" in the \"Bell System Technical Journal\" in July and October 1948.\n\nPrior to this paper, limited information-theoretic ideas had been developed at Bell Labs, all implicitly assuming events of equal probability. Harry Nyquist's 1924 paper, \"Certain Factors Affecting Telegraph Speed\", contains a theoretical section quantifying \"intelligence\" and the \"line speed\" at which it can be transmitted by a communication system, giving the relation (recalling Boltzmann's constant), where \"W\" is the speed of transmission of intelligence, \"m\" is the number of different voltage levels to choose from at each time step, and \"K\" is a constant. Ralph Hartley's 1928 paper, \"Transmission of Information\", uses the word \"information\" as a measurable quantity, reflecting the receiver's ability to distinguish one sequence of symbols from any other, thus quantifying information as , where \"S\" was the number of possible symbols, and \"n\" the number of symbols in a transmission. The unit of information was therefore the decimal digit, which has since sometimes been called the hartley in his honor as a unit or scale or measure of information. Alan Turing in 1940 used similar ideas as part of the statistical analysis of the breaking of the German second world war Enigma ciphers.\n\nMuch of the mathematics behind information theory with events of different probabilities were developed for the field of thermodynamics by Ludwig Boltzmann and J. Willard Gibbs. Connections between information-theoretic entropy and thermodynamic entropy, including the important contributions by Rolf Landauer in the 1960s, are explored in \"Entropy in thermodynamics and information theory\".\n\nIn Shannon's revolutionary and groundbreaking paper, the work for which had been substantially completed at Bell Labs by the end of 1944, Shannon for the first time introduced the qualitative and quantitative model of communication as a statistical process underlying information theory, opening with the assertion that\n\nWith it came the ideas of\n\nInformation theory is based on probability theory and statistics. Information theory often concerns itself with measures of information of the distributions associated with random variables. Important quantities of information are entropy, a measure of information in a single random variable, and mutual information, a measure of information in common between two random variables. The former quantity is a property of the probability distribution of a random variable and gives a limit on the rate at which data generated by independent samples with the given distribution can be reliably compressed. The latter is a property of the joint distribution of two random variables, and is the maximum rate of reliable communication across a noisy channel in the limit of long block lengths, when the channel statistics are determined by the joint distribution.\n\nThe choice of logarithmic base in the following formulae determines the unit of information entropy that is used. A common unit of information is the bit, based on the binary logarithm. Other units include the nat, which is based on the natural logarithm, and the decimal digit, which is based on the common logarithm.\n\nIn what follows, an expression of the form is considered by convention to be equal to zero whenever . This is justified because formula_1 for any logarithmic base.\n\nBased on the probability mass function of each source symbol to be communicated, the Shannon entropy , in units of bits (per symbol), is given by\nwhere is the probability of occurrence of the -th possible value of the source symbol. This equation gives the entropy in the units of \"bits\" (per symbol) because it uses a logarithm of base 2, and this base-2 measure of entropy has sometimes been called the \"shannon\" in his honor. Entropy is also commonly computed using the natural logarithm (base , where is Euler's number), which produces a measurement of entropy in \"nats\" per symbol and sometimes simplifies the analysis by avoiding the need to include extra constants in the formulas. Other bases are also possible, but less commonly used. For example, a logarithm of base will produce a measurement in bytes per symbol, and a logarithm of base 10 will produce a measurement in decimal digits (or hartleys) per symbol.\n\nIntuitively, the entropy of a discrete random variable is a measure of the amount of \"uncertainty\" associated with the value of when only its distribution is known.\n\nThe entropy of a source that emits a sequence of symbols that are independent and identically distributed (iid) is bits (per message of symbols). If the source data symbols are identically distributed but not independent, the entropy of a message of length will be less than .\n\nIf one transmits 1000 bits (0s and 1s), and the value of each of these bits is known to the receiver (has a specific value with certainty) ahead of transmission, it is clear that no information is transmitted. If, however, each bit is independently equally likely to be 0 or 1, 1000 shannons of information (more often called bits) have been transmitted. Between these two extremes, information can be quantified as follows. If 𝕏 is the set of all messages that could be, and is the probability of some formula_3, then the entropy, , of is defined:\n\n(Here, is the self-information, which is the entropy contribution of an individual message, and is the expected value.) A property of entropy is that it is maximized when all the messages in the message space are equiprobable ; i.e., most unpredictable, in which case .\n\nThe special case of information entropy for a random variable with two outcomes is the \"binary entropy function\", usually taken to the logarithmic base 2, thus having the shannon (Sh) as unit:\n\nThe \"joint entropy\" of two discrete random variables and is merely the entropy of their pairing: . This implies that if and are independent, then their joint entropy is the sum of their individual entropies.\n\nFor example, if represents the position of a chess piece — the row and the column, then the joint entropy of the row of the piece and the column of the piece will be the entropy of the position of the piece.\n\nDespite similar notation, joint entropy should not be confused with \"cross entropy\".\n\nThe \"conditional entropy\" or \"conditional uncertainty\" of given random variable (also called the \"equivocation\" of about ) is the average conditional entropy over :\n\nBecause entropy can be conditioned on a random variable or on that random variable being a certain value, care should be taken not to confuse these two definitions of conditional entropy, the former of which is in more common use. A basic property of this form of conditional entropy is that:\n\n\"Mutual information\" measures the amount of information that can be obtained about one random variable by observing another. It is important in communication where it can be used to maximize the amount of information shared between sent and received signals. The mutual information of relative to is given by:\n\nwhere (\"S\"pecific mutual \"I\"nformation) is the pointwise mutual information.\n\nA basic property of the mutual information is that\nThat is, knowing \"Y\", we can save an average of bits in encoding \"X\" compared to not knowing \"Y\".\n\nMutual information is symmetric:\n\nMutual information can be expressed as the average Kullback–Leibler divergence (information gain) between the posterior probability distribution of \"X\" given the value of \"Y\" and the prior distribution on \"X\":\nIn other words, this is a measure of how much, on the average, the probability distribution on \"X\" will change if we are given the value of \"Y\". This is often recalculated as the divergence from the product of the marginal distributions to the actual joint distribution:\n\nMutual information is closely related to the log-likelihood ratio test in the context of contingency tables and the multinomial distribution and to Pearson's χ test: mutual information can be considered a statistic for assessing independence between a pair of variables, and has a well-specified asymptotic distribution.\n\nThe \"Kullback–Leibler divergence\" (or \"information divergence\", \"information gain\", or \"relative entropy\") is a way of comparing two distributions: a \"true\" probability distribution \"p(X)\", and an arbitrary probability distribution \"q(X)\". If we compress data in a manner that assumes \"q(X)\" is the distribution underlying some data, when, in reality, \"p(X)\" is the correct distribution, the Kullback–Leibler divergence is the number of average additional bits per datum necessary for compression. It is thus defined\n\nAlthough it is sometimes used as a 'distance metric', KL divergence is not a true metric since it is not symmetric and does not satisfy the triangle inequality (making it a semi-quasimetric).\n\nAnother interpretation of the KL divergence is the \"unnecessary surprise\" introduced by a prior from the truth: suppose a number \"X\" is about to be drawn randomly from a discrete set with probability distribution \"p(x)\". If Alice knows the true distribution \"p(x)\", while Bob believes (has a prior) that the distribution is \"q(x)\", then Bob will be more surprised than Alice, on average, upon seeing the value of \"X\". The KL divergence is the (objective) expected value of Bob's (subjective) surprisal minus Alice's surprisal, measured in bits if the \"log\" is in base 2. In this way, the extent to which Bob's prior is \"wrong\" can be quantified in terms of how \"unnecessarily surprised\" it is expected to make him.\n\nOther important information theoretic quantities include Rényi entropy (a generalization of entropy), differential entropy (a generalization of quantities of information to continuous distributions), and the conditional mutual information.\n\nCoding theory is one of the most important and direct applications of information theory. It can be subdivided into source coding theory and channel coding theory. Using a statistical description for data, information theory quantifies the number of bits needed to describe the data, which is the information entropy of the source.\n\n\nThis division of coding theory into compression and transmission is justified by the information transmission theorems, or source–channel separation theorems that justify the use of bits as the universal currency for information in many contexts. However, these theorems only hold in the situation where one transmitting user wishes to communicate to one receiving user. In scenarios with more than one transmitter (the multiple-access channel), more than one receiver (the broadcast channel) or intermediary \"helpers\" (the relay channel), or more general networks, compression followed by transmission may no longer be optimal. Network information theory refers to these multi-agent communication models.\n\nAny process that generates successive messages can be considered a \"source\" of information. A memoryless source is one in which each message is an independent identically distributed random variable, whereas the properties of ergodicity and stationarity impose less restrictive constraints. All such sources are stochastic. These terms are well studied in their own right outside information theory.\n\nInformation \"rate\" is the average entropy per symbol. For memoryless sources, this is merely the entropy of each symbol, while, in the case of a stationary stochastic process, it is\n\nthat is, the conditional entropy of a symbol given all the previous symbols generated. For the more general case of a process that is not necessarily stationary, the \"average rate\" is\n\nthat is, the limit of the joint entropy per symbol. For stationary sources, these two expressions give the same result.\n\nIt is common in information theory to speak of the \"rate\" or \"entropy\" of a language. This is appropriate, for example, when the source of information is English prose. The rate of a source of information is related to its redundancy and how well it can be compressed, the subject of \"source coding\".\n\nCommunications over a channel—such as an ethernet cable—is the primary motivation of information theory. As anyone who's ever used a telephone (mobile or landline) knows, however, such channels often fail to produce exact reconstruction of a signal; noise, periods of silence, and other forms of signal corruption often degrade quality.\n\nConsider the communications process over a discrete channel. A simple model of the process is shown below:\n\nHere \"X\" represents the space of messages transmitted, and \"Y\" the space of messages received during a unit time over our channel. Let be the conditional probability distribution function of \"Y\" given \"X\". We will consider to be an inherent fixed property of our communications channel (representing the nature of the \"noise\" of our channel). Then the joint distribution of \"X\" and \"Y\" is completely determined by our channel and by our choice of , the marginal distribution of messages we choose to send over the channel. Under these constraints, we would like to maximize the rate of information, or the \"signal\", we can communicate over the channel. The appropriate measure for this is the mutual information, and this maximum mutual information is called the \"channel capacity\" and is given by:\nThis capacity has the following property related to communicating at information rate \"R\" (where \"R\" is usually bits per symbol). For any information rate \"R < C\" and coding error ε > 0, for large enough \"N\", there exists a code of length \"N\" and rate ≥ R and a decoding algorithm, such that the maximal probability of block error is ≤ ε; that is, it is always possible to transmit with arbitrarily small block error. In addition, for any rate \"R > C\", it is impossible to transmit with arbitrarily small block error.\n\n\"Channel coding\" is concerned with finding such nearly optimal codes that can be used to transmit data over a noisy channel with a small coding error at a rate near the channel capacity.\n\n\n\nInformation theoretic concepts apply to cryptography and cryptanalysis. Turing's information unit, the ban, was used in the Ultra project, breaking the German Enigma machine code and hastening the end of World War II in Europe. Shannon himself defined an important concept now called the unicity distance. Based on the redundancy of the plaintext, it attempts to give a minimum amount of ciphertext necessary to ensure unique decipherability.\n\nInformation theory leads us to believe it is much more difficult to keep secrets than it might first appear. A brute force attack can break systems based on asymmetric key algorithms or on most commonly used methods of symmetric key algorithms (sometimes called secret key algorithms), such as block ciphers. The security of all such methods currently comes from the assumption that no known attack can break them in a practical amount of time.\n\nInformation theoretic security refers to methods such as the one-time pad that are not vulnerable to such brute force attacks. In such cases, the positive conditional mutual information between the plaintext and ciphertext (conditioned on the key) can ensure proper transmission, while the unconditional mutual information between the plaintext and ciphertext remains zero, resulting in absolutely secure communications. In other words, an eavesdropper would not be able to improve his or her guess of the plaintext by gaining knowledge of the ciphertext but not of the key. However, as in any other cryptographic system, care must be used to correctly apply even information-theoretically secure methods; the Venona project was able to crack the one-time pads of the Soviet Union due to their improper reuse of key material.\n\nPseudorandom number generators are widely available in computer language libraries and application programs. They are, almost universally, unsuited to cryptographic use as they do not evade the deterministic nature of modern computer equipment and software. A class of improved random number generators is termed cryptographically secure pseudorandom number generators, but even they require random seeds external to the software to work as intended. These can be obtained via extractors, if done carefully. The measure of sufficient randomness in extractors is min-entropy, a value related to Shannon entropy through Rényi entropy; Rényi entropy is also used in evaluating randomness in cryptographic systems. Although related, the distinctions among these measures mean that a random variable with high Shannon entropy is not necessarily satisfactory for use in an extractor and so for cryptography uses.\n\nOne early commercial application of information theory was in the field of seismic oil exploration. Work in this field made it possible to strip off and separate the unwanted noise from the desired seismic signal. Information theory and digital signal processing offer a major improvement of resolution and image clarity over previous analog methods.\n\nSemioticians and Winfried Nöth both considered Charles Sanders Pierce as having created a theory of information in his works on semiotics. Nauta defined semiotic information theory as the study of \"the internal processes of coding, filtering, and information processing.\"\n\nConcepts from information theory such as redundancy and code control have been used by semioticians such as Umberto Eco and to explain ideology as a form of message transmission whereby a dominant social class emits its message by using signs that exhibit a high degree of redundancy such that only one message is decoded among a selection of competing ones.\n\nInformation theory also has applications in gambling and investing, black holes, and bioinformatics.\n\n\n\n\n"}
{"id": "14774", "url": "https://en.wikipedia.org/wiki?curid=14774", "title": "Information explosion", "text": "Information explosion\n\nThe information explosion is the rapid increase in the amount of published information or data and the effects of this abundance. As the amount of available data grows, the problem of managing the information becomes more difficult, which can lead to information overload. The Online Oxford English Dictionary indicates use of the phrase in a March 1964 \"New Statesman\" article. \"The New York Times\" first used the phrase in its editorial content in an article by Walter Sullivan on June 7, 1964, in which he described the phrase as \"much discussed\". (p11.) The earliest use of the phrase seems to have been in an IBM advertising supplement to the New York Times published on April 30, 1961, and by Frank Fremont-Smith, Director of the American Institute of Biological Sciences Interdisciplinary Conference Program, in an April 1961 article in the AIBS Bulletin (p18.) \n\nMany sectors are seeing this rapid increase in the amount of information available such as healthcare, supermarkets, and even governments with birth certificate informations and immunization records. Another sector that is being affected by this phenomenon is journalism. Such profession, which in the past was responsible for the dissemination of information, may be suppressed by so many sources of information today.\n\nTechniques to gather knowledge from an overabundance of electronic information (e.g., data fusion may help in data mining) have existed since the 1970s. Another common technique to deal with such amount of information is qualitative research. Such approach aims at organizing the information, synthesizing, categorizing and systematizing in order to be more usable and easier to search.\n\n\nA new metric that is being used in an attempt to characterize the growth in person-specific information, is the disk storage per person (DSP), which is measured in megabytes/person (where megabytes is 10 bytes and is abbreviated MB). Global DSP (GDSP) is the total rigid disk drive space (in MB) of new units sold in a year divided by the world population in that year. The GDSP metric is a crude measure of how much disk storage could possibly be used to collect person-specific data on the world population. \nIn 1983, one million fixed drives with an estimated total of 90 terabytes were sold worldwide; 30MB drives had the largest market segment. In 1996, 105 million drives, totaling 160,623 terabytes were sold with 1 and 2 gigabyte drives leading the industry. By the year 2000, with 20GB drive leading the industry, rigid drives sold for the year are projected to total 2,829,288 terabytes Rigid disk drive sales to top $34 billion in 1997.\n\nAccording to Latanya Sweeney, there are three trends in data gathering today:\n\nType 1. Expansion of the number of fields being collected, known as the “collect more” trend.\n\nType 2. Replace an existing aggregate data collection with a person-specific one, known as the “collect specifically” trend.\n\nType 3. Gather information by starting a new person-specific data collection, known as the “collect it if you can” trend.\n\nSince \"information\" in electronic media is often used synonymously with \"data\", the term \"information explosion\" is closely related to the concept of \"data flood\" (also dubbed \"data deluge\"). Sometimes the term \"information flood\" is used as well. All of those basically boil down to the ever-increasing amount of electronic data exchanged per time unit. The awareness about non-manageable amounts of data grew along with the advent of ever more powerful data processing since the mid-1960s.\n\nEven though the abundance of information can be beneficial in several levels, some problems may be of concern such as privacy, legal and ethical guidelines, filtering and data accuracy. Filtering refers to finding useful information in the middle of so much data, which relates to the job of data scientists. A typical example of a necessity of data filtering (data mining) is in healthcare since in the next years is due to have EHRs (Electronic Health Records) of patients available. With so much information available, the doctors will need to be able to identify patterns and select important data for the diagnosis of the patient. On the other hand, according to some experts, having so much public data available makes it difficult to provide data that is actually anonymous.\nAnother point to take into account is the legal and ethical guidelines, which relates to who will be the owner of the data and how frequently he/she is obliged to the release this and for how long.\nWith so many sources of data, another problem will be accuracy of such. An untrusted source may be challenged by others, by ordering a new set of data, causing a repetition in the information.\nAccording to Edward Huth, another concern is the accessibility and cost of such information. The accessibility rate could be improved by either reducing the costs or increasing the utility of the information. The reduction of costs according to the author, could be done by associations, which should assess which information was relevant and gather it in a more organized fashion.\n\nAs of August 2005, there were over 70 million web servers. there were over 135 million web servers.\n\nAccording to Technorati, the number of blogs doubles about every 6 months with a total of 35.3 million blogs . This is an example of the early stages of logistic growth, where growth is approximately exponential, since blogs are a recent innovation. As the number of blogs approaches the number of possible producers (humans), saturation occurs, growth declines, and the number of blogs eventually stabilizes.\n\n\n"}
{"id": "14775", "url": "https://en.wikipedia.org/wiki?curid=14775", "title": "Inch", "text": "Inch\n\nThe inch (abbreviation: in or ″) is a unit of length in the (British) imperial and United States customary systems of measurement. It is equal to yard or of a foot. Derived from the Roman uncia (\"twelfth\"), the word \"inch\" is also sometimes used to translate similar units in other measurement systems, usually understood as deriving from the width of the human thumb. Standards for the exact length of an inch have varied in the past, but since the adoption of the international yard during the 1950s and 1960s it has been based on the metric system and defined as exactly 2.54cm.\n\nThe English word \"inch\" () was an early borrowing from Latin \"\" (\"one-twelfth; Roman inch; Roman ounce\") not present in other Germanic languages. The vowel change from Latin to Old English (which became Modern English ) is known as umlaut. The consonant change from the Latin (spelled \"c\") to English is palatalisation. Both were features of Old English phonology; see and for more information.\n\n\"Inch\" is cognate with \"ounce\" (), whose separate pronunciation and spelling reflect its reborrowing in Middle English from Anglo-Norman \"unce\" and \"ounce\".\n\nIn many other European languages, the word for \"inch\" is the same as or derived from the word for \"thumb\", as a man's thumb is about an inch wide (and this was even sometimes used to define the inch). Examples include ; (\"inch\") and ' (\"thumb\"); (\"thumb\"); Danish and (\"inch\") ' (\"thumb\"); ; ; ; ; (\"inch\") and ' (\"thumb\"); (\"thumb\"); (\"inch\") and ' (\"thumb\"); and (\"inch\") and \"tumme\" (\"thumb\") and Russian: дюйм (\"duim\").\n\nThe inch is a commonly used customary unit of length in the United States, Canada, and the United Kingdom. It is also used in Japan for electronic parts, especially display screens. In most of continental Europe, the inch is also used informally as a measure for display screens. For the United Kingdom, guidance on public sector use states that, since 1 October 1995, without time limit, the inch (along with the foot) is to be used as a primary unit for road signs and related measurements of distance (with the possible exception of clearance heights and widths) and may continue to be used as a secondary or supplementary indication following a metric measurement for other purposes.\n\nThe international standard symbol for inch is in (see ISO 31-1, Annex A) but traditionally the inch is denoted by a double prime, which is often approximated by double quotes, and the foot by a prime, which is often approximated by an apostrophe. For example, can be written as 3′ 2″. (This is akin to how the first and second \"cuts\" of the hour and degree are likewise indicated by prime and double prime symbols.) Subdivisions of an inch are typically written using dyadic fractions with odd number numerators; for example, would be written as ″ and not as 2.375″ nor as ″.\n\n1 international inch is equal to:\n\nThe earliest known reference to the inch in England is from the \"Laws of Æthelberht\" dating to the early 7th century, surviving in a single manuscript, the \"Textus Roffensis\" from 1120. Paragraph LXVII sets out the fine for wounds of various depths: one inch, one shilling, two inches, two shillings, etc.\n\nAn Anglo-Saxon unit of length was the barleycorn. After 1066, 1 inch was equal to 3 barleycorns, which continued to be its legal definition for several centuries, with the barleycorn being the base unit. One of the earliest such definitions is that of 1324, where the legal definition of the inch was set out in a statute of Edward II of England, defining it as \"three grains of barley, dry and round, placed end to end, lengthwise\".\n\nSimilar definitions are recorded in both English and Welsh medieval law tracts. One, dating from the first half of the 10th century, is contained in the Laws of Hywel Dda which superseded those of Dyfnwal, an even earlier definition of the inch in Wales. Both definitions, as recorded in \"Ancient Laws and Institutes of Wales\" (vol i., pp. 184, 187, 189), are that \"three lengths of a barleycorn is the inch\".\n\nKing David I of Scotland in his Assize of Weights and Measures (c. 1150) is said to have defined the Scottish inch as the width of an average man's thumb at the base of the nail, even including the requirement to calculate the average of a small, a medium, and a large man's measures. However, the oldest surviving manuscripts date from the early 14th century and appear to have been altered with the inclusion of newer material.\n\nIn 1814, Charles Butler, a mathematics teacher at Cheam School, recorded the old legal definition of the inch to be \"three grains of sound ripe barley being taken out the middle of the ear, well dried, and laid end to end in a row\", and placed the barleycorn, not the inch, as the base unit of the English Long Measure system, from which all other units were derived. John Bouvier similarly recorded in his 1843 law dictionary that the barleycorn was the fundamental measure. Butler observed, however, that \"[a]s the length of the barley-corn cannot be fixed, so the inch according to this method will be uncertain\", noting that a standard inch measure was now (by his time) kept in the Exchequer chamber, Guildhall, and \"that\" was the legal definition of the inch. This was a point also made by George Long in his 1842 Penny Cyclopædia, observing that standard measures had since surpassed the barleycorn definition of the inch, and that to recover the inch measure from its original definition, in the event that the standard measure were destroyed, would involve the measurement of large numbers of barleycorns and taking their average lengths. He noted that this process would not perfectly recover the standard, since it might introduce errors of anywhere between one hundredth and one tenth of an inch in the definition of a yard.\n\nBefore the adoption of the international yard and pound, various definitions were in use. In the United Kingdom and most countries of the British Commonwealth, the inch was defined in terms of the Imperial Standard Yard. The United States adopted the conversion factor 1 metre = 39.37 inches by an act in 1866. In 1893, Mendenhall ordered the physical realization of the inch to be based on the international prototype metres numbers 21 and 27, which had been received from the CGPM, together with the previously adopted conversion factor.\n\nIn 1930, the British Standards Institution adopted an inch of exactly 25.4 mm. The American Standards Association followed suit in 1933. By 1935, industry in 16 countries had adopted the \"industrial inch\" as it came to be known.\n\nIn 1946, the Commonwealth Science Congress recommended a yard of exactly 0.9144 metres for adoption throughout the British Commonwealth. This was adopted by Canada in 1951, the United States on 1 July 1959, Australia in 1961, effective 1 January 1964, and the United Kingdom in 1963, effective on 1 January 1964. The new standards gave an inch of exactly 25.4 mm, 1.7 millionths of an inch longer than the old imperial inch and 2 millionths of an inch shorter than the old US inch.\n\nThe United States retains the -metre definition for survey purposes, producing a 2 millionth part difference between standard and US survey inches. This is approximately  inch per mile. In fact, 12.7 kilometres is exactly standard inches and exactly survey inches. This difference is significant when doing calculations in State Plane Coordinate Systems with coordinate values in the hundreds of thousands or millions of feet.\n\nBefore the adoption of the metric system, several European countries had customary units whose name translates into \"inch\". The French \"pouce\" measured 2.70 cm, at least when applied to describe the calibre of artillery pieces. The Amsterdam foot (\"voet\") consisted of 11 Amsterdam inches (\"duim\"). The Amsterdam foot is about 8% shorter than an English foot.\n\nThe now obsolete Scottish inch (), of a Scottish foot, was about 1.0016 imperial inches (about ). It was used in the popular expression \"\", in English \"Give him an inch and he'll take an ell\", first published as \"For when I gave you an inch, you tooke an ell\" by John Heywood in 1546. (The ell, equal to 37 inches (about 94 cm), was in use in England until 1685.) Modern versions of the saying include \"Give him an inch and he'll take a mile\" and \"Give him an inch and he'll take a yard\".\n\n\n"}
{"id": "14776", "url": "https://en.wikipedia.org/wiki?curid=14776", "title": "Inn", "text": "Inn\n\nInns are generally establishments or buildings where travelers can seek lodging and usually food and drink. They are typically located in the country or along a highway; before the advent of motorized transportation they also provided accommodation for horses.\n\nInns in Europe were possibly first established when the Romans built their system of Roman roads two millennia ago. Some inns in Europe are several centuries old. In addition to providing for the needs of travelers, inns traditionally acted as community gathering places.\n\nHistorically, inns in Europe provided not only food and lodging, but also stabling and fodder for the travelers' horses. Famous London examples of inns include the George and the Tabard. There is however no longer a formal distinction between an inn and other kinds of establishment. Many pubs use the name \"inn\", either because they are long established and may have been formerly coaching inns, or to summon up a particular kind of image.\n\nInns were like bed and breakfasts, with a community dining room which was also used for town meetings or rented for wedding parties. The front, facing the road was ornamental and welcoming for travelers. The back also usually had at least one livery barn for travelers to keep their horses. There were not lobbies as in modern inns; but the innkeeper would answer the door for each visitor and judge the people whom he decided to allow to come in. Many inns were simply large estates that had extra rooms for renting.\n\nDuring the 19th century the inn played a major role in the growing transportation system of England. Industry was on the rise and people were traveling more in order to keep and maintain business. The English Inn was considered an important part of English infrastructure as it helped maintain a smooth flow of travel throughout the country.\n\nAs modes of transport have evolved, tourist lodging has adapted to serve each generation of traveller. A stagecoach made frequent stops at roadside coaching inns for water, food and horses. A passenger train stops only at designated stations in the city centre, around which were built grand railway hotels. Motorcar traffic on old-style two-lane highways may pause at any camp, cabin court or motel along the way, while freeway traffic is restricted to access from designated off-ramps to side roads which quickly become crowded with hotel chain operators.\n\nThe original functions of an inn are now usually split among separate establishments, such as hotels, lodges, and motels, all of which might provide the traditional functions of an inn but which focus more on lodging customers than on other services; public houses, which are primarily alcohol-serving establishments; and restaurants and taverns, which serve food and drink. (Hotels often contain restaurants serving full breakfasts and meals, thus providing all of the functions of traditional inns. Economy, limited service properties, however, claim at most an included continental breakfast as there is no kitchen and no bar.)\n\nThe lodging aspect of the word \"inn\" lives on in hotel brand names like Holiday Inn, and in some laws that refer to lodging operators as \"innkeepers\". The Inns of Court in London were once accommodations for members of the legal profession.\n\nOther forms of inn exist throughout the world. Among them are the honjin and ryokan of Japan, caravanserai of the Ottoman Empire, and Jiuguan in ancient China.\n\nIn Asia Minor, during the periods of rule by the Seljuq and Ottoman Turks, impressive structures functioning as inns () were built because it was thought that inns were socially significant. These inns provided accommodation for people and their vehicles or animals and served as a resting place for people, whether travelling on foot or by other means.\n\nThese inns were built between towns if the distance between them was too far for one day's travel. These structures were called caravansarais which were inns with large courtyards with ample supplies of water for both drinking and other uses. They would also routinely contain a café in addition to supplies of food and fodder. After the caravans traveled a while they would take a break at these caravansarais, and spend the night there to rest both themselves and their animals.\n\nThe term \"inn\" historically characterized a rural hotel which provided lodging, food and refreshments, and accommodations for travelers' horses. To capitalize on this nostalgic image many typically lower end and middling modern motor hotel operators seek to distance themselves from similar motels by styling themselves \"inns\", regardless of services and accommodations provided. Examples are Premier Inn, Holiday Inn, Comfort Inn, Days Inn and Knights Inn.\n\nThe term inn is also retained in its historic use in many laws governing motels and hotels, often known as \"innkeeper's acts\", or refer to hôteliers and motel operators as \"innkeepers\" in the body of the legislation These laws typically define the innkeepers' liability for valuables entrusted to them by clients and determine whether an innkeeper holds any lien against such goods. In some jurisdictions, an offence named as \"defrauding an innkeeper\" prohibits fraudulently obtaining \"food, lodging, or other accommodation at any hotel, inn, boarding house, or eating house\"; in this context, the term is often an anachronism as the majority of modern restaurants are free-standing and not attached to coaching inns or tourist lodging.\n\n\n"}
{"id": "14777", "url": "https://en.wikipedia.org/wiki?curid=14777", "title": "International Olympiad in Informatics", "text": "International Olympiad in Informatics\n\nThe International Olympiad in Informatics (IOI) is an annual competitive programming competition for secondary school students. It is the second largest olympiad, after International Mathematical Olympiad, in terms of number of participating countries (83 at IOI 2017). The first IOI was held in 1989 in Pravetz, Bulgaria.\n\nThe contest consists of two days of computer programming and problem-solving of algorithmic nature. To deal with problems involving very large amounts of data, it is necessary to have not only programmers, \"but also creative coders, who can dream up what it is that the programmers need to tell the computer to do. The hard part isn't the programming, but the mathematics underneath it.\" Students at the IOI compete on an individual basis, with up to four students competing from each participating country (with 81 countries in 2012). Students in the national teams are selected through national computing contests, such as the Australian Informatics Olympiad, British Informatics Olympiad, Indian Computing Olympiad or Bundeswettbewerb Informatik (Germany).\n\nThe International Olympiad in Informatics is one of the most prestigious computer science competitions in the world. UNESCO and IFIP are patrons.\n\nOn each of the two competition days, the students are typically given three problems which they have to solve in five hours. Each student works on his/her own, with only a computer and no other help allowed, specifically no communication with other contestants, books etc. Usually to solve a task the contestant has to write a computer program (in C, C++, Pascal, or Java) and submit it before the five-hour competition time ends. The program is graded by being run with secret test data. From IOI 2010, tasks are divided into subtasks with graduated difficulty, and points are awarded only when all tests for a particular subtask yield correct results, within specific time and memory limits. In some cases, the contestant's program has to interact with a secret computer library, which allows problems where the input is not fixed, but depends on the program's actions – for example in game problems. Another type of problem has known inputs which are publicly available already during the five hours of the contest. For these, the contestants have to submit an output file instead of a program, and it is up to them whether they obtain the output files by writing a program (possibly exploiting special characteristics of the input), or by hand, or by a combination of these means. Pascal will have been removed as an available programming language by 2019.\n\nIOI 2010 for the first time had a live web scoreboard with real-time provisional results. Submissions will be scored as soon as possible during the contest, and the results posted. Contestants will be aware of their scores, but not others', and may resubmit to improve their scores. Starting from 2012, IOI has been using the Contest Management System (CMS) for developing and monitoring the contest.\n\nThe scores from the two competition days and all problems are summed up separately for each contestant. At the awarding ceremony, contestants are awarded medals depending on their relative total score. The top 50% of the contestants are awarded medals, such that the relative number of gold : silver : bronze : no medal is approximately 1:2:3:6 (thus 1/12 of the contestants get a gold medal).\n\nPrior to IOI 2010, students who did not receive medals did not have their scores published, making it impossible for a country to be ranked by adding together scores of its competitors unless each wins a medal. From IOI 2010, although the scores of students who did not receive medals are still not available in the official results, they are known from the live web scoreboard. In IOI 2012 the top 3 nations ranked by aggregate score (Russia, China and USA) were subsequently awarded during the closing ceremony.\n\nAnalysis of female performance shows 77.9 % of women obtain no medal, while 49.2 % of men obtain no medal. \"The average female participation was 4.4% in 1989–1994 and 2.2% in 1996–2014.\" It also suggests women participate much more on the national level, claiming sometimes a double-digit percentage of women participate on the first stage. President of the IOI, Richard Forster, says the competition has difficulty attracting women and that in spite of trying to solve it, \"none of us have hit on quite what the problem is, let alone the solution.\"\n\nIn IOI 2017 held in Iran, due to not being able to participate in Iran, the Israeli students participated in an offsite competition organized by IOI in Russia. Due to visa issues, the full USA team was unable to attend, although one contestant Zhezheng Luo was able to attend by traveling with the Chinese team and winning gold medal and 3rd place in standings.\n\nThe following is a list of the top performers in the history of the IOI. The sign indicates a perfect score, a rare achievement in IOI history. The sign indicates an unofficial participation, where a contestant participated in a host's second team. Also, first (I), second (II) and third (III) places among gold medalists are indicated where appropriate. This list includes only those countries where the national selection contest allows the same participant to go multiple times to the IOI.\n\nMost participating countries use feeder competitions to select their team. A number of these are listed below:\n\n"}
{"id": "14779", "url": "https://en.wikipedia.org/wiki?curid=14779", "title": "Iota", "text": "Iota\n\nIota (; uppercase Ι, lowercase ι; ) is the ninth letter of the Greek alphabet. It was derived from the Phoenician letter Yodh. Letters that arose from this letter include the Latin I and J, the Cyrillic І (І, і), Yi (Ї, ї), and Je (Ј, ј), and iotated letters (e.g. Yu (Ю, ю)).\nIn the system of Greek numerals, iota has a value of 10.\n\nIota represents the sound . In ancient Greek it occurred in both long and short versions, but this distinction was lost in Koine Greek.\n\nIota participated as the second element in falling diphthongs, with both long and short vowels as the first element. Where the first element was long, the iota was lost in pronunciation at an early date, and was written in polytonic orthography as iota subscript, in other words as a very small ι under the main vowel. Examples include ᾼ ᾳ ῌ ῃ ῼ ῳ. The former diphthongs became digraphs for simple vowels in Koine Greek.\n\nThe word is used in a common English phrase, \"not one iota\", meaning \"not the slightest amount\", in reference to a phrase in the New Testament (Matthew 5:18): \"until heaven and earth pass away, not an iota, not a dot, (King James Version: '[not] one jot or one tittle') will pass from the Law until all is accomplished.\" () This refers to iota, the smallest letter, or possibly Yodh, י, the smallest letter in the Hebrew alphabet.\n\nThe word 'jot' (or \"iot\") derives from iota.\n\nThe German, Portuguese and Spanish name for the letter J (Jot / jota) is derived from iota.\n\n\n\n\n\n\n\n\nThese characters are used only as mathematical symbols. Stylized Greek text should be encoded using the normal Greek letters, with markup and formatting to indicate text style.\n"}
{"id": "14780", "url": "https://en.wikipedia.org/wiki?curid=14780", "title": "ISP (disambiguation)", "text": "ISP (disambiguation)\n\nISP often refers to Internet Service Provider. ISP may also refer to:\n\n\n\n\n\n"}
{"id": "14783", "url": "https://en.wikipedia.org/wiki?curid=14783", "title": "Erectile dysfunction", "text": "Erectile dysfunction\n\nErectile dysfunction (ED), also known as impotence, is a type of sexual dysfunction characterized by the inability to develop or maintain an erection of the penis during sexual activity. Erectile dysfunction can have psychological consequences as it can be tied to relationship difficulties and self-image.\nA physical cause can be identified in about 80% of cases. These include cardiovascular disease, diabetes mellitus, neurological problems such as following prostatectomy, hypogonadism, and drug side effects. Psychological impotence is where erection or penetration fails due to thoughts or feelings; this is somewhat less frequent, in the order of about 10% of cases. In psychological impotence, there is a strong response to placebo treatment.\nTreatment involves addressing the underlying causes, lifestyle modifications, and addressing psychosocial issues. In many cases, a trial of pharmacological therapy with a PDE5 inhibitor, such as sildenafil, can be attempted. In some cases, treatment can involve inserting prostaglandin pellets into the urethra, injecting smooth muscle relaxants and vasodilators into the penis, a penile prosthesis, a penis pump, or vascular reconstructive surgery. It is the most common sexual problem in men.\n\nErectile dysfunction is characterized by the regular or repeated inability to achieve or maintain an erection of sufficient rigidity to accomplish sexual activity.\n\nIt is defined as the \"persistent or recurrent inability to achieve and maintain a penile erection of sufficient rigidity to permit satisfactory sexual activity for at least 3 months.\"\n\n\nSurgical intervention for a number of conditions may remove anatomical structures necessary to erection, damage nerves, or impair blood supply. Erectile dysfunction is a common complication of treatments for prostate cancer, including prostatectomy and destruction of the prostate by external beam radiation, although the prostate gland itself is not necessary to achieve an erection. As far as inguinal hernia surgery is concerned, in most cases, and in the absence of postoperative complications, the operative repair can lead to a recovery of the sexual life of people with preoperative sexual dysfunction, while, in most cases, it does not affect people with a preoperative normal sexual life.\n\nED can also be associated with bicycling due to both neurological and vascular problems due to compression. The increase risk appears to be about 1.7-fold.\n\nConcerns that use of pornography can cause erectile dysfunction have not been substantiated in epidemiological studies according to a 2015 literature review. \n\nPenile erection is managed by two mechanisms: the reflex erection, which is achieved by directly touching the penile shaft, and the psychogenic erection, which is achieved by erotic or emotional stimuli. The former uses the peripheral nerves and the lower parts of the spinal cord, whereas the latter uses the limbic system of the brain. In both cases, an intact neural system is required for a successful and complete erection. Stimulation of the penile shaft by the nervous system leads to the secretion of nitric oxide (NO), which causes the relaxation of smooth muscles of corpora cavernosa (the main erectile tissue of penis), and subsequently penile erection. Additionally, adequate levels of testosterone (produced by the testes) and an intact pituitary gland are required for the development of a healthy erectile system. As can be understood from the mechanisms of a normal erection, impotence may develop due to hormonal deficiency, disorders of the neural system, lack of adequate penile blood supply or psychological problems. Spinal cord injury causes sexual dysfunction including ED. Restriction of blood flow can arise from impaired endothelial function due to the usual causes associated with coronary artery disease, but can also be caused by prolonged exposure to bright light.\n\nIn many cases, the diagnosis can be made based on the person's history of symptoms. In other cases, a physical examination and laboratory investigations are done to rule out more serious causes such as hypogonadism or prolactinoma.\n\nOne of the first steps is to distinguish between physiological and psychological ED. Determining whether involuntary erections are present is important in eliminating the possibility of psychogenic causes for ED. Obtaining full erections occasionally, such as nocturnal penile tumescence when asleep (that is, when the mind and psychological issues, if any, are less present), tends to suggest that the physical structures are functionally working. Similarly, performance with manual stimulation, as well as any performance anxiety or acute situational ED, may indicate a psychogenic component to ED.\n\nOther factors leading to erectile dysfunction are diabetes mellitus, which is a well-known cause of neuropathy). ED is also related to generally poor physical health, poor dietary habits, obesity, and most specifically cardiovascular disease, such as coronary artery disease and peripheral vascular disease. Screening for cardiovascular risk factors, such as smoking, dyslipidemia, hypertension, and alcoholism is helpful. \n\nIn some particular cases, the simple search for a previously undetected groin hernia can prove useful since it can affect sexual functions in men and is relatively easily curable.\n\nThe current diagnostic and statistical manual of mental diseases (DSM-IV) has included a listing for ED.\n\n\n\n\n\n\n\n\nTreatment depends on the underlying cause. In general, exercise, particularly of the aerobic type, is effective for preventing ED during midlife. Exercise as a treatment is under investigation. For tobacco smokers, cessation often results in a significant improvement. Oral pharmacotherapy and vacuum erection devices are first-line treatments, followed by injections of drugs into the penis, as well as penile implants. Vascular reconstructive surgeries are beneficial in certain groups. \n\nThe PDE5 inhibitors sildenafil (Viagra), vardenafil (Levitra) and tadalafil (Cialis) are prescription drugs which are taken orally. Additionally, a cream combining alprostadil with the permeation enhancer DDAIP has been approved in Canada as a first line treatment for erectile dysfunction. Penile injections, on the other hand, can involve one of the following medications: papaverine, phentolamine, and prostaglandin E1.\n\nA vacuum erection device helps draw blood into the penis by applying negative pressure. This type of device is sometimes referred to as penis pump and may be used just prior to sexual intercourse. Several types of FDA approved vacuum therapy devices are available under prescription. When pharmacological methods fail, a purpose-designed external vacuum pump can be used to attain erection, with a separate compression ring fitted to the base of the penis to maintain it. These pumps should be distinguished from other penis pumps (supplied without compression rings) which, rather than being used for temporary treatment of impotence, are claimed to increase penis length if used frequently, or vibrate as an aid to masturbation. More drastically, inflatable or rigid penile implants may be fitted surgically.\n\nOften, as a last resort if other treatments have failed, the most common procedure is prosthetic implants which involves the insertion of artificial rods into the penis. Some sources show that vascular reconstructive surgeries are viable options for some people.\n\nThe Food and Drug Administration (FDA) does not recommend alternative therapies to treat sexual dysfunction. Many products are advertised as \"herbal viagra\" or \"natural\" sexual enhancement products, but no clinical trials or scientific studies support the effectiveness of these products for the treatment of ED, and synthetic chemical compounds similar to sildenafil have been found as adulterants in many of these products. The FDA has warned consumers that any sexual enhancement product that claims to work as well as prescription products is likely to contain such a contaminant.\n\nDuring the late 16th and 17th centuries in France, male impotence was considered a crime, as well as legal grounds for a divorce. The practice, which involved inspection of the complainants by court experts, was declared obscene in 1677.\n\nJohn R. Brinkley initiated a boom in male impotence cures in the U.S. in the 1920s and 1930s. His radio programs recommended expensive goat gland implants and \"mercurochrome\" injections as the path to restored male virility, including operations by surgeon Serge Voronoff.\n\nModern drug therapy for ED made a significant advance in 1983, when British physiologist Giles Brindley dropped his trousers and demonstrated to a shocked Urodynamics Society audience his papaverine-induced erection. The drug Brindley injected into his penis was a non-specific vasodilator, an alpha-blocking agent, and the mechanism of action was clearly corporal smooth muscle relaxation. The effect that Brindley discovered established the fundamentals for the later development of specific, safe, and orally effective drug therapies.\n\nThe Latin term \"impotentia coeundi\" describes simple inability to insert the penis into the vagina; it is now mostly replaced by more precise terms, such as \"erectile dysfunction\" (ED). The study of ED within medicine is covered by andrology, a sub-field within urology. Research indicates that ED is common, and it is suggested that approximately 40% of males experience symptoms compatible with ED, at least occasionally. The condition is also on occasion called \"phallic impotence\". Its antonym, or opposite condition, is priapism.\n\n"}
{"id": "14787", "url": "https://en.wikipedia.org/wiki?curid=14787", "title": "Iran–Contra affair", "text": "Iran–Contra affair\n\nThe Iran–Contra Scandal (, ), also referred to as Irangate, Contragate or the Iran–Contra affair, was a political scandal in the United States that occurred during the second term of the Reagan Administration. Senior administration officials secretly facilitated the sale of arms to Iran, which was the subject of an arms embargo. The administration hoped to use the proceeds of the arms sale to fund the Contras in Nicaragua. Under the Boland Amendment, further funding of the Contras by the government had been prohibited by Congress.\n\nThe official justification for the arms shipments was that they were part of an operation to free seven American hostages being held in Lebanon by Hezbollah, a paramilitary group with Iranian ties connected to the Islamic Revolutionary Guard Corps. The plan was for Israel to ship weapons to Iran, for the United States to resupply Israel, and for Israel to pay the United States. The Iranian recipients promised to do everything in their power to achieve the release of the hostages. However, as documented by a congressional investigation, the first Reagan-sponsored secret arms sales to Iran began in 1981 before any of the American hostages had been taken in Lebanon. This fact ruled out the \"arms for hostages\" explanation by which the Reagan administration sought to excuse its behavior.\n\nThe plan was later complicated in late 1985, when Lieutenant Colonel Oliver North of the National Security Council diverted a portion of the proceeds from the Iranian weapon sales to fund the Contras, a group of anti-Sandinista rebel fighters, in their struggle against the socialist government of Nicaragua. While President Ronald Reagan was a vocal supporter of the Contra cause, the evidence is disputed as to whether he personally authorized the diversion of funds to the Contras. Handwritten notes taken by Defense Secretary Caspar Weinberger on 7 December 1985 indicate that Reagan was aware of potential hostage transfers with Iran, as well as the sale of Hawk and TOW missiles to \"moderate elements\" within that country. Weinberger wrote that Reagan said \"he could answer to charges of illegality but couldn't answer to the charge that 'big strong President Reagan passed up a chance to free the hostages. After the weapon sales were revealed in November 1986, Reagan appeared on national television and stated that the weapons transfers had indeed occurred, but that the United States did not trade arms for hostages. The investigation was impeded when large volumes of documents relating to the affair were destroyed or withheld from investigators by Reagan administration officials. On 4 March 1987, Reagan made a further nationally televised address, taking full responsibility for the affair and stating that \"what began as a strategic opening to Iran deteriorated, in its implementation, into trading arms for hostages\".\n\nThe affair was investigated by the U.S. Congress and by the three-person, Reagan-appointed Tower Commission. Neither investigation found evidence that President Reagan himself knew of the extent of the multiple programs. In the end, fourteen administration officials were indicted, including then-Secretary of Defense Caspar Weinberger. Eleven convictions resulted, some of which were vacated on appeal. The rest of those indicted or convicted were all pardoned in the final days of the presidency of George H. W. Bush, who had been Vice President at the time of the affair. The Iran–Contra affair and the ensuing deception to protect senior administration officials (including President Reagan) has been cast as an example of post-truth politics.\n\nThe United States was the largest seller of arms to Iran under Mohammad Reza Pahlavi, and the vast majority of the weapons that the Islamic Republic of Iran inherited in January 1979 were American-made. To maintain this arsenal, Iran required a steady supply of spare parts to replace those broken and worn out. After Iranian students stormed the American embassy in Tehran in November 1979 and took 52 Americans hostage, U.S. President Jimmy Carter imposed an arms embargo on Iran. After Iraq invaded Iran in September 1980, Iran desperately needed weapons and spare parts for its current weapons. After Ronald Reagan took office as President on 20 January 1981, he vowed to continue Carter's policy of blocking arms sales to Iran on the grounds that Iran supported terrorism.\n\nA group of senior Reagan administration officials in the Senior Interdepartmental Group conducted a secret study on 21 July 1981, and concluded that the arms embargo was ineffective because Iran could always buy arms and spare parts for its American weapons elsewhere, while at the same time the arms embargo opened the door for Iran to fall into the Soviet sphere of influence as the Kremlin could sell Iran weapons if the United States would not. The conclusion was that the United States should start selling Iran arms as soon as it was politically possible to keep Iran from falling into the Soviet sphere of influence. At the same time, the openly declared goal of Ayatollah Khomeini to export his Islamic revolution all over the Middle East and overthrow the governments of Iraq, Kuwait, Saudi Arabia and the other states around the Persian Gulf led to the Americans perceiving Khomeini as a major threat to the United States.\n\nIn the spring of 1983, the United States launched Operation Staunch, a wide-ranging diplomatic effort to persuade other nations all over the world not to sell arms or spare parts for weapons to Iran. At least part of the reason the Iran–Contra affair proved so humiliating for the United States when the story first broke in November 1986 that the US was selling arms to Iran was that American diplomats, as part of Operation Staunch had, from the spring of 1983 on, been lecturing other nations about how morally wrong it was to sell arms to the Islamic Republic of Iran and applying strong pressure to prevent these arms sales to Iran.\n\nAt the same time that the American government was considering their options on selling arms to Iran, Contra militants based in Honduras were waging a guerrilla war to topple the Sandinista National Liberation Front (FSLN) revolutionary government of Nicaragua. Almost from the time he took office in 1981, a major goal of the Reagan administration was the overthrow of the left-wing Sandinista government in Nicaragua and to support the \"Contra\" rebels. The Reagan administration's policy towards Nicaragua produced a major clash between the executive and legislative arms as Congress sought to limit, if not curb altogether, the ability of the White House to support the \"Contras\". Direct U.S. funding of the Contras insurgency was made illegal through the Boland Amendment, the name given to three U.S. legislative amendments between 1982 and 1984 aimed at limiting U.S. government assistance to Contra militants. Funding ran out for the Contras by July 1984, and in October a total ban was placed in effect. The second Boland Amendment, in effect from 3 October 1984 to 3 December 1985, stated:During the fiscal year 1985 no funds available to the Central Intelligence Agency, the Department of Defense or any other agency or entity of the United States involved in intelligence activities may be obligated or expended for the purpose of or which may have the effect of supporting directly or indirectly military or paramilitary operations in Nicaragua by any nation, organization, group, movement, or individual. In violation of the Boland Amendment, senior officials of the Reagan administration continued to secretly arm and train the Contras and provide arms to Iran, an operation they called \"the Enterprise\". As the \"Contras\" were heavily dependent upon U.S. military and financial support, the second Boland amendment threatened to break the \"Contra\" movement and led to President Reagan in 1984 to order the National Security Council (NSC) to \"keep the \"Contras\" together 'body and soul'\", no matter what Congress voted for.\n\nA major legal debate at the center of the Iran–Contra affair concerned the question of whether the NSC was one of the \"any other agency or entity of the United States involved in intelligence activities\" covered by the Boland amendment. The Reagan administration argued it was not, and many in Congress argued that it was. The majority of constitutional scholars have asserted the NSC did indeed fall within the purview of the second Boland amendment, though the amendment did not mention the NSC by name. The broader constitutional question at stake was the power of Congress versus the power of the presidency. The Reagan administration argued that because the constitution assigned the right to conduct foreign policy to the executive, its efforts to overthrow the government of Nicaragua were a presidential prerogative that Congress had no right to try to halt via the Boland amendments. By contrast congressional leaders argued that the constitution had assigned Congress control of the budget, and Congress had every right to use that power not to fund projects like attempting to overthrow the government of Nicaragua that they disapproved of. As part of the effort to circumvent the Boland amendment, the NSC established \"the Enterprise\", an arms-smuggling network headed by a retired U.S. Air Force officer turned arms dealer Richard Secord that supplied arms to the \"Contras\". It was ostensibly a private sector operation, but in fact was controlled by the NSC. To fund \"the Enterprise\", the Reagan administration was constantly on the look-out for funds that came from outside the U.S. government in order not to explicitly violate the letter of the Boland amendment, though the efforts to find alternative funding for the \"Contras\" violated the spirit of the Boland amendment. Ironically, military aid to the Contras was reinstated with Congressional consent in October 1986, a month before the scandal broke.\n\nA common narrative of the Iran-Contra affair has the US-sponsored arms sales to Iran beginning in the year 1985. That date is important to the official justifications of the Reagan administration because the government claimed that the secret arms shipments were in exchange for Iranian cooperation with the release of hostages held in Lebanon by Hezbollah, where the first hostage was taken in 1982. But if an agreement to send secret arms shipments to Iran, and the fact of those shipments, both began before 1982, then the release of the hostages cannot be the reason for the arms shipments. As reported in \"The New York Times\" in 1991, \"continuing allegations that Reagan campaign officials made a deal with the Iranian Government of Ayatollah Ruhollah Khomeini in the fall of 1980\" led to \"limited investigations.\" However \"limited,\" those investigations established that \"Soon after taking office in 1981, the Reagan Administration secretly and abruptly changed United States policy.\" Secret Israeli arms sales and shipments to Iran began in that year, even as, in public, \"the Reagan Administration\" presented a different face, and \"aggressively promoted a public campaign... to stop worldwide transfers of military goods to Iran.\" \"The New York Times\" explains: \"Iran at that time was in dire need of arms and spare parts for its American-made arsenal to defend itself against Iraq, which had attacked it in September 1980,\" while \"Israel [a U.S. ally] was interested in keeping the war between Iran and Iraq going to insure that these two potential enemies remained preoccupied with each other.\" The official documents 'establishing' the beginning of this policy as dating to 1985, therefore, may perhaps be interpreted as part of a paper trail to establish the 'arms-for-hostages' cover story, in case the secret arms shipments to Iran were discovered.\n\nOn 17 June 1985, National Security Adviser Robert McFarlane wrote a National Security Decision Directive which called for the United States to begin a rapprochement with the Islamic Republic of Iran. The paper read:\n\nDynamic political evolution is taking place inside Iran. Instability caused by the pressures of the Iraq-Iran war, economic deterioration and regime in-fighting create the potential for major changes inside Iran. The Soviet Union is better positioned than the U.S. to exploit and benefit from any power struggle that results in changes from the Iranian regime ... The U.S should encourage Western allies and friends to help Iran meet its import requirements so as to reduce the attractiveness of Soviet assistance ... This includes provision of selected military equipment.\n\nDefense Secretary Caspar Weinberger was highly negative, writing on his copy of McFarlane's paper: \"This is almost too absurd to comment on ... like asking Qaddafi to Washington for a cozy chat.\" Secretary of State George Shultz was also opposed, stating that having designated Iran a State Sponsor of Terrorism in January 1984, how could the United States possibly sell arms to Iran? Only the Director of the Central Intelligence Agency William Casey supported McFarlane's plan to start selling arms to Iran.\n\nIn early July 1985, the historian Michael Ledeen, a consultant of National Security Adviser Robert McFarlane, requested assistance from Israeli Prime Minister Shimon Peres for help in the sale of arms to Iran. Having talked to an Israeli diplomat David Kimche and Ledeen, McFarlane learned that the Iranians were prepared to have Hezbollah release American hostages in Lebanon in exchange for Israelis shipping Iran American weapons. Having been designated a State Sponsor of Terrorism since January 1984, Iran was in the midst of the Iran–Iraq War and could find few Western nations willing to supply it with weapons. The idea behind the plan was for Israel to ship weapons through an intermediary (identified as Manucher Ghorbanifar) to the Islamic republic as a way of aiding a supposedly moderate, politically influential faction within the regime of Ayatollah Khomeini who was believed to be seeking a rapprochement with the United States; after the transaction, the United States would reimburse Israel with the same weapons, while receiving monetary benefits. McFarlane in a memo to Shultz and Weinberger wrote:\n\nThe short term dimension concerns the seven hostages; the long term dimension involves the establishment of a private dialogue with Iranian officials on the broader relations ... They sought specifically the delivery from Israel of 100 TOW missiles ...\n\nThe plan was discussed with President Reagan on 18 July 1985 and again on 6 August 1985. Shultz at the latter meeting warned Reagan that \"we were just falling into the arms-for-hostages business and we shouldn't do it.\"\n\nThe Americans believed that there was a moderate faction in the Islamic republic headed by Akbar Hashemi Rafsanjani, the powerful speaker of the \"Majlis\" who was seen as a leading potential successor to Khomeini and who was alleged to want a rapprochement with the United States. The Americans believed that Rafsanjani had the power to order Hezbollah to free the American hostages and establishing a relationship with him by selling Iran arms would ultimately place Iran back within the American sphere of influence. It remains unclear if Rafsanjani really wanted a rapprochement with the United States or was just deceiving Reagan administration officials who were willing to believe that he was a moderate who would effect a rapprochement. Rafsanjani, whose nickname is \"the Shark\" was described by the British journalist Patrick Brogan as a man of great charm and formidable intelligence known for his subtlety and ruthlessness whose motives in the Iran–Contra affair remain completely mysterious. The Israeli government required that the sale of arms meet high level approval from the United States government, and when McFarlane convinced them that the U.S. government approved the sale, Israel obliged by agreeing to sell the arms.\n\nIn 1985, President Reagan entered Bethesda Naval Hospital for colon cancer surgery. While the President was recovering in the hospital, McFarlane met with him and told him that representatives from Israel had contacted the National Security Agency to pass on confidential information from what Reagan later described as the \"moderate\" Iranian faction headed by Rafsanjani opposed to the Ayatollah's hardline anti-American policies. According to Reagan, these Iranians sought to establish a quiet relationship with the United States, before establishing formal relationships upon the death of the aging Ayatollah. In Reagan's account, McFarlane told Reagan that the Iranians, to demonstrate their seriousness, offered to persuade the Hezbollah militants to release the seven U.S. hostages. McFarlane met with the Israeli intermediaries; Reagan claimed that he allowed this because he believed that establishing relations with a strategically located country, and preventing the Soviet Union from doing the same, was a beneficial move. Although Reagan claims that the arms sales were to a \"moderate\" faction of Iranians, the Walsh Iran/Contra Report states that the arms sales were \"to Iran\" itself, which was under the control of the Ayatollah.\n\nFollowing the Israeli–U.S. meeting, Israel requested permission from the United States to sell a small number of BGM-71 TOW antitank missiles to Iran, claiming that this would aid the \"moderate\" Iranian faction, by demonstrating that the group actually had high-level connections to the U.S. government. Reagan initially rejected the plan, until Israel sent information to the United States showing that the \"moderate\" Iranians were opposed to terrorism and had fought against it. Now having a reason to trust the \"moderates\", Reagan approved the transaction, which was meant to be between Israel and the \"moderates\" in Iran, with the United States reimbursing Israel. In his 1990 autobiography \"An American Life\", Reagan claimed that he was deeply committed to securing the release of the hostages; it was this compassion that supposedly motivated his support for the arms initiatives. The president requested that the \"moderate\" Iranians do everything in their capability to free the hostages held by Hezbollah. Reagan always insisted in public after the scandal broke in late 1986 that purpose behind the arms-for-hostages trade was to establish a working relationship with the \"moderate\" faction associated with Rafsanjani to facilitate the reestablishment of the American-Iranian alliance after the soon to be expected death of Khomeini, to end the Iran-Iraq war and end Iranian support for Islamic terrorism while downplaying the importance of freeing the hostages in Lebanon as a secondary issue. By contrast, when testifying before the Tower Commission, Reagan declared that hostage issue was the main reason for selling arms to Iran.\n\nThe following arms were supplied to Iran:\n\nThe first arms sales to Iran began in 1981, though the official paper trail has them beginning in 1985 (see above). On 20 August 1985, Israel sent 96 American-made TOW missiles to Iran through an arms dealer Manucher Ghorbanifar. Subsequently, on 14 September 1985, 408 more TOW missiles were delivered. On 15 September 1985, following the second delivery, Reverend Benjamin Weir was released by his captors, the Islamic Jihad Organization. On 24 November 1985, 18 Hawk anti-aircraft missiles were delivered.\n\nRobert McFarlane resigned on 4 December 1985, stating that he wanted to spend more time with his family, and was replaced by Admiral John Poindexter. Two days later, Reagan met with his advisors at the White House, where a new plan was introduced. This called for a slight change in the arms transactions: instead of the weapons going to the \"moderate\" Iranian group, they would go to \"moderate\" Iranian army leaders. As each weapons delivery was made from Israel by air, hostages held by Hezbollah would be released. Israel would continue to be reimbursed by the United States for the weapons. Though staunchly opposed by Secretary of State George Shultz and Secretary of Defense Caspar Weinberger, the plan was authorized by Reagan, who stated that, \"We were \"not\" trading arms for hostages, nor were we negotiating with terrorists\". In his notes of a meeting held in the White House on 7 December 1985, Weinberger wrote he told Reagan that this plan was illegal, writing: I argued strongly that we have an embargo that makes arms sales to Iran illegal and President couldn't violate it and that 'washing' transactions thru Israel wouldn't make it legal. Shultz, Don Regan agreed. Weinberger's notes have Reagan saying he \"could answer charges of illegality but he couldn't answer charge that 'big strong President Reagan' passed up a chance to free hostages.\" Now retired National Security Advisor McFarlane flew to London to meet with Israelis and Ghorbanifar in an attempt to persuade the Iranian to use his influence to release the hostages before any arms transactions occurred; this plan was rejected by Ghorbanifar.\n\nOn the day of McFarlane's resignation, Oliver North, a military aide to the United States National Security Council (NSC), proposed a new plan for selling arms to Iran, which included two major adjustments: instead of selling arms through Israel, the sale was to be direct, and a portion of the proceeds would go to Contras, or Nicaraguan paramilitary fighters waging guerrilla warfare against the democratically elected Sandinista government, at a markup. The dealings with the Iranians were conducted via the NSC with Admiral Poindexter and his deputy Colonel North, with the American historians Malcolm Byrne and Peter Kornbluh writing that Poindexter granted much power to North \"...who made the most of the situation, often deciding important matters on his own, striking outlandish deals with the Iranians, and acting in the name of the president on issues that were far beyond his competence. All of these activities continued to take place within the framework of the president's broad authorization. Until the press reported on the existence of the operation, nobody in the administration questioned the authority of Poindexter's and North's team to implement the president's decisions\". North proposed a $15 million markup, while contracted arms broker Ghorbanifar added a 41% markup of his own. Other members of the NSC were in favor of North's plan; with large support, Poindexter authorized it without notifying President Reagan, and it went into effect. At first, the Iranians refused to buy the arms at the inflated price because of the excessive markup imposed by North and Ghorbanifar. They eventually relented, and in February 1986, 1,000 TOW missiles were shipped to the country. From May to November 1986, there were additional shipments of miscellaneous weapons and parts.\n\nBoth the sale of weapons to Iran and the funding of the Contras attempted to circumvent not only stated administration policy, but also the Boland Amendment. Administration officials argued that regardless of Congress restricting funds for the Contras, or any affair, the President (or in this case the administration) could carry on by seeking alternative means of funding such as private entities and foreign governments. Funding from one foreign country, Brunei, was botched when North's secretary, Fawn Hall, transposed the numbers of North's Swiss bank account number. A Swiss businessman, suddenly $10 million richer, alerted the authorities of the mistake. The money was eventually returned to the Sultan of Brunei, with interest.\n\nOn 7 January 1986, John Poindexter proposed to Reagan a modification of the approved plan: instead of negotiating with the \"moderate\" Iranian political group, the United States would negotiate with \"moderate\" members of the Iranian government. Poindexter told Reagan that Ghorbanifar had important connections within the Iranian government, so with the hope of the release of the hostages, Reagan approved this plan as well. Throughout February 1986, weapons were shipped directly to Iran by the United States (as part of Oliver North's plan), but none of the hostages were released. Retired National Security Advisor McFarlane conducted another international voyage, this one to Tehran – bringing with him a gift of a bible with a handwritten inscription by Ronald Reagan and, according to George Cave, a cake baked in the shape of a key. Howard Teicher described the cake as a joke between North and Ghorbanifar. McFarlane met directly with Iranian officials associated with Rafsanjani, who sought to establish U.S.-Iranian relations in an attempt to free the four remaining hostages. \n\nThe American delegation comprised McFarlane, North, Cave (a retired CIA agent who worked in Iran in the 1960s–70s), Teicher, Israeli diplomat Amiram Nir and a CIA translator. They arrived in Tehran in an Israeli plane carrying forged Irish passports on 25 May 1986. This meeting also failed. Much to McFarlane's disgust, he did not meet ministers, and instead met in his words \"third and fourth level officials\". At one point, an angry McFarlane shouted: \"As I am a Minister, I expect to meet with decision-makers. Otherwise, you can work with my staff.\" The Iranians requested concessions such as Israel's withdrawal from the Golan Heights, which the United States rejected. More importantly, McFarlane refused to ship spare parts for the Hawk missiles until the Iranians had Hezbollah release the American hostages, whereas the Iranians wanted to reverse that sequence with the spare parts being shipped first before the hostages were freed. The differing negotiating positions led to McFarlane's mission going home after four days. After the failure of the secret visit to Tehran, McFarlane advised Reagan not to talk to the Iranians anymore, advice that was disregarded.\n\nOn 26 July 1986, Hezbollah freed the American hostage Father Lawrence Jenco, former head of Catholic Relief Services in Lebanon. Following this, William Casey, head of the CIA, requested that the United States authorize sending a shipment of small missile parts to Iranian military forces as a way of expressing gratitude. Casey also justified this request by stating that the contact in the Iranian government might otherwise lose face or be executed, and hostages might be killed. Reagan authorized the shipment to ensure that those potential events would not occur. North used this release to persuade Reagan to switch over to a \"sequential\" policy of freeing the hostages one by one, instead of the \"all or nothing\" policy that the Americans had pursued until then. By this point, the Americans had grown tired of Ghobanifar who had proven himself a dishonest intermediary who played off both sides to his own commercial advantage. In August 1986, the Americans had established a new contact in the Iranian government, Ali Hashemi Bahramani, the nephew of Rafsanjani and an officer in the Revolutionary Guard. The fact that the Revolutionary Guard was deeply involved in international terrorism seemed only to attract the Americans more to Bahramani, who was seen as someone with the influence to change Iran's policies. Richard Secord, an American arms dealer, who was being used as a contact with Iran, wrote to North: \"My judgment is that we have opened up a new and probably better channel into Iran\". North was so impressed with Bahramani that he arranged for him to secretly visit Washington D.C and gave him a guided tour at midnight of the White House.\n\nNorth frequently met with Bahramani in the summer and fall of 1986 in West Germany, discussing arms sales to Iran, the freeing of hostages held by Hezbollah and how best to overthrow President Saddam Hussein of Iraq and the establishment of \"a non-hostile regime in Baghdad\". In September and October 1986 three more Americans—Frank Reed, Joseph Cicippio, and Edward Tracy—were abducted in Lebanon by a separate terrorist group, who referred to them simply as \"G.I. Joe,\" after the popular American toy. The reasons for their abduction are unknown, although it is speculated that they were kidnapped to replace the freed Americans. One more original hostage, David Jacobsen, was later released. The captors promised to release the remaining two, but the release never happened.\n\nDuring a secret meeting in Frankfurt in October 1986, North told Bahramani that: \"Saddam Hussein must go\". North also claimed that Reagan had told him to tell Bahramani that: \"Saddam Hussein is an asshole.\" Behramani during a secret meeting in Mainz informed North that Rafsanjani \"for his own politics ... decided to get all the groups involved and give them a role to play.\" Thus, all the factions in the Iranian government would be jointly responsible for the talks with the Americans and \"there would not be an internal war\". This demand of Behramani caused much dismay on the American side as it made clear to them that they would not be dealing solely with a \"moderate\" faction in the Islamic Republic, as the Americans liked to pretend to themselves, but rather with all the factions in the Iranian government - including those who were very much involved in terrorism. Despite this the talks were not broken off.\n\nAfter a leak by Mehdi Hashemi, a senior official in the Islamic Revolutionary Guard Corps, the Lebanese magazine \"Ash-Shiraa\" exposed the arrangement on 3 November 1986. The leak may have been orchestrated by a covert team led by Arthur S. Moreau Jr., assistant to the chairman of the United States Joint Chiefs of Staff, due to fears the scheme had grown out of control.\n\nThis was the first public report of the weapons-for-hostages deal. The operation was discovered only after an airlift of guns (Corporate Air Services HPF821) was downed over Nicaragua. Eugene Hasenfus, who was captured by Nicaraguan authorities after surviving the plane crash, initially alleged in a press conference on Nicaraguan soil that two of his coworkers, Max Gomez and Ramon Medina, worked for the Central Intelligence Agency. He later said he did not know whether they did or not. The Iranian government confirmed the \"Ash-Shiraa\" story, and ten days after the story was first published, President Reagan appeared on national television from the Oval Office on 13 November, stating:\n\nMy purpose was ... to send a signal that the United States was prepared to replace the animosity between [the U.S. and Iran] with a new relationship ... At the same time we undertook this initiative, we made clear that Iran must oppose all forms of international terrorism as a condition of progress in our relationship. The most significant step which Iran could take, we indicated, would be to use its influence in Lebanon to secure the release of all hostages held there.\n\nThe scandal was compounded when Oliver North destroyed or hid pertinent documents between 21 November – 25 November 1986. During North's trial in 1989, his secretary, Fawn Hall, testified extensively about helping North alter, shred, and remove official United States National Security Council (NSC) documents from the White House. According to \"The New York Times\", enough documents were put into a government shredder to jam it. North's explanation for destroying some documents was to protect the lives of individuals involved in Iran and Contra operations. It was not until 1993, years after the trial, that North's notebooks were made public, and only after the National Security Archive and Public Citizen sued the Office of the Independent Counsel under the Freedom of Information Act.\n\nDuring the trial, North testified that on 21, 22 November, or 24, he witnessed Poindexter destroy what may have been the only signed copy of a presidential covert-action finding that sought to authorize CIA participation in the November 1985 Hawk missile shipment to Iran. U.S. Attorney General Edwin Meese admitted on 25 November that profits from weapons sales to Iran were made available to assist the Contra rebels in Nicaragua. On the same day, John Poindexter resigned, and President Reagan fired Oliver North. Poindexter was replaced by Frank Carlucci on 2 December 1986.\n\nWhen the story broke, many legal and constitutional scholars expressed dismay that the NSC, which was supposed to be just an advisory body to assist the President with formulating foreign policy had \"gone operational\" by becoming an executive body covertly executing foreign policy on its own. The National Security Act of 1947, which created the NSC, gave it the vague right to perform \"such other functions and duties related to the intelligence as the National Security Council may from time to time direct.\" However, the NSC had usually, although not always, acted as an advisory agency until the Reagan administration when the NSC had \"gone operational\", a situation that was condemned by both the Tower commission and by Congress as a departure from the norm. The American historian James Canham-Clyne asserted that Iran–Contra affair and the NSC \"going operational\" were not departures from the norm, but were the logical and natural consequence of existence of the \"national security state\", the plethora of shadowy government agencies with multi-million dollar budgets operating with little oversight from Congress, the courts or the media, and for whom upholding national security justified almost everything. Canham-Clyne argued that for the \"national security state\", the law was an obstacle to be surmounted rather than something to uphold and that the Iran–Contra affair was just \"business as usual\", something he asserted that the media missed by focusing on the NSC having \"gone operational.\"\n\nIn \"Veil: The Secret Wars of the CIA 1981–1987\", journalist Bob Woodward chronicled the role of the CIA in facilitating the transfer of funds from the Iran arms sales to the Nicaraguan Contras spearheaded by Oliver North. According to Woodward, then–Director of the CIA William J. Casey admitted to him in February 1987 that he was aware of the diversion of funds to the Contras. The controversial admission occurred while Casey was hospitalized for a stroke, and, according to his wife, was unable to communicate. On 6 May 1987, William Casey died the day after Congress began public hearings on Iran–Contra. Independent Counsel, Lawrence Walsh later wrote: \"Independent Counsel obtained no documentary evidence showing Casey knew about or approved the diversion. The only direct testimony linking Casey to early knowledge of the diversion came from [Oliver] North.\" Gust Avrakodos, who was responsible for the arms supplies to the Afghans at this time, was aware of the operation as well and strongly opposed it, in particular the diversion of funds allotted to the Afghan operation. According to his Middle Eastern experts the operation was pointless because the moderates in Iran were not in a position to challenge the fundamentalists. However, he was overruled by Clair George.\n\nOn 25 November 1986, President Reagan announced the creation of a Special Review Board to look into the matter; the following day, he appointed former Senator John Tower, former Secretary of State Edmund Muskie, and former National Security Adviser Brent Scowcroft to serve as members. This Presidential Commission took effect on 1 December and became known as the Tower Commission. The main objectives of the commission were to inquire into \"the circumstances surrounding the Iran-Contra matter, other case studies that might reveal strengths and weaknesses in the operation of the National Security Council system under stress, and the manner in which that system has served eight different presidents since its inception in 1947\". The Tower Commission was the first presidential commission to review and evaluate the National Security Council.\n\nPresident Reagan appeared before the Tower Commission on 2 December 1986, to answer questions regarding his involvement in the affair. When asked about his role in authorizing the arms deals, he first stated that he had; later, he appeared to contradict himself by stating that he had no recollection of doing so. In his 1990 autobiography, \"An American Life\", Reagan acknowledges authorizing the shipments to Israel.\n\nThe report published by the Tower Commission was delivered to the president on 26 February 1987. The Commission had interviewed 80 witnesses to the scheme, including Reagan, and two of the arms trade middlemen: Manucher Ghorbanifar and Adnan Khashoggi. The 200-page report was the most comprehensive of any released, criticizing the actions of Oliver North, John Poindexter, Caspar Weinberger, and others. It determined that President Reagan did not have knowledge of the extent of the program, especially about the diversion of funds to the Contras, although it argued that the president ought to have had better control of the National Security Council staff. The report heavily criticized Reagan for not properly supervising his subordinates or being aware of their actions. A major result of the Tower Commission was the consensus that Reagan should have listened to his National Security Advisor more, thereby placing more power in the hands of that chair.\n\nIn January 1987, Congress announced it was opening an investigation into the Iran–Contra affair. Depending upon one's political perspective, the Congressional investigation into the Iran–Contra affair was either an attempt by the legislative arm to gain control over an out-of-control executive arm, a partisan \"witch hunt\" by the Democrats against a Republican administration or a feeble effort by Congress that did far too little to rein in the \"imperial presidency\" that had run amok by breaking numerous laws. The Democratic-controlled United States Congress issued its own report on 18 November 1987, stating that \"If the president did not know what his national security advisers were doing, he should have.\" The congressional report wrote that the president bore \"ultimate responsibility\" for wrongdoing by his aides, and his administration exhibited \"secrecy, deception and disdain for the law\". It also read that \"the central remaining question is the role of the President in the Iran–Contra affair. On this critical point, the shredding of documents by Poindexter, North and others, and the death of Casey, leave the record incomplete\".\n\nReagan expressed regret regarding the situation in a nationally televised address from the Oval Office on 4 March 1987, and in two other speeches; Reagan had not spoken to the American people directly for three months amidst the scandal, and he offered the following explanation for his silence:\n\nThe reason I haven't spoken to you before now is this: You deserve the truth. And as frustrating as the waiting has been, I felt it was improper to come to you with sketchy reports, or possibly even erroneous statements, which would then have to be corrected, creating even more doubt and confusion. There's been enough of that.\n\nReagan then took full responsibility for the acts committed:\nFirst, let me say I take full responsibility for my own actions and for those of my administration. As angry as I may be about activities undertaken without my knowledge, I am still accountable for those activities. As disappointed as I may be in some who served me, I'm still the one who must answer to the American people for this behavior.\n\nFinally, the president acknowledged that his previous assertions that the U.S. did not trade arms for hostages were incorrect:\nA few months ago I told the American people I did not trade arms for hostages. My heart and my best intentions still tell me that's true, but the facts and the evidence tell me it is not. As the Tower board reported, what began as a strategic opening to Iran deteriorated, in its implementation, into trading arms for hostages. This runs counter to my own beliefs, to administration policy, and to the original strategy we had in mind.\n\nTo this day, Reagan's role in these transactions is not definitively known. It is unclear exactly what Reagan knew and when, and whether the arms sales were motivated by his desire to save the U.S. hostages. Oliver North wrote that \"Ronald Reagan knew of and approved a great deal of what went on with both the Iranian initiative and private efforts on behalf of the contras and he received regular, detailed briefings on both...I have no doubt that he was told about the use of residuals for the Contras, and that he approved it. Enthusiastically.\" Handwritten notes by Defense Secretary Weinberger indicate that the President was aware of potential hostage transfers with Iran, as well as the sale of Hawk and TOW missiles to what he was told were \"moderate elements\" within Iran. Notes taken on 7 December 1985, by Weinberger record that Reagan said that \"he could answer charges of illegality but he couldn't answer charge that 'big strong President Reagan passed up a chance to free hostages'\". The Republican-written \"Report of the Congressional Committees Investigating the Iran-Contra Affair\" made the following conclusion: There is some question and dispute about precisely the level at which he chose to follow the operation details. There is no doubt, however, ... [that] the President set the US policy towards Nicaragua, with few if any ambiguities, and then left subordinates more or less free to implement it.\n\nDomestically, the affair precipitated a drop in President Reagan's popularity. His approval ratings saw \"the largest single drop for any U.S. president in history\", from 67% to 46% in November 1986, according to a \"The New York Times\"/CBS News poll. The \"Teflon President\", as Reagan was nicknamed by critics, survived the affair, however, and his approval rating recovered.\n\nInternationally, the damage was more severe. Magnus Ranstorp wrote, \"U.S. willingness to engage in concessions with Iran and the Hezbollah not only signaled to its adversaries that hostage-taking was an extremely useful instrument in extracting political and financial concessions for the West but also undermined any credibility of U.S. criticism of other states' deviation from the principles of no-negotiation and no concession to terrorists and their demands.\"\n\nIn Iran, Mehdi Hashemi, the leaker of the scandal, was executed in 1987, allegedly for activities unrelated to the scandal. Though Hashemi made a full video confession to numerous serious charges, some observers find the coincidence of his leak and the subsequent prosecution highly suspicious.\n\n\nOliver North and John Poindexter were indicted on multiple charges on 16 March 1988. North, indicted on 16 counts, was found guilty of three felony counts. The convictions were vacated on appeal on the grounds that North's Fifth Amendment rights may have been violated by the indirect use of his testimony to Congress, which had been given under a grant of immunity. In 1990, Poindexter was convicted on several felony counts of conspiracy, lying to Congress, obstruction of justice, and altering and destroying documents pertinent to the investigation. His convictions were also overturned on appeal on similar grounds. Arthur L. Liman served as chief counsel to the Senate committee investigating the Iran–Contra affair.\n\nThe Independent Counsel, Lawrence E. Walsh, chose not to re-try North or Poindexter. In total, several dozen people were investigated by Walsh's office.\n\nDuring his election campaign in 1988, Vice President Bush denied any knowledge of the Iran–Contra affair by saying he was \"out of the loop\". Though his diaries included that he was \"one of the few people that know fully the details\", he repeatedly refused to discuss the incident and won the election.\n\nA book published in 2008 by Israeli journalist and terrorism expert Ronen Bergman asserts that Bush was also personally and secretly briefed on the affair by Amiram Nir, a counterterrorism adviser to the then Israeli prime minister, Yitzhak Shamir, when Bush was on a visit to Israel. \"Nir could have incriminated the incoming President. The fact that Nir was killed in a mysterious chartered airplane crash in Mexico in December 1988 has given rise to numerous conspiracy theories\", writes Bergman.\n\nOn 24 December 1992, nearing the end of his term in office, President George H. W. Bush pardoned five administration officials who had been found guilty on charges relating to the affair. They were: \nBush also pardoned Caspar Weinberger, who had not yet come to trial.\n\nIn response to these Bush pardons, Independent Counsel Lawrence E. Walsh, who headed the investigation of Reagan Administration officials' criminal conduct in the Iran-Conra scandal, stated that \"the Iran-Contra cover-up, which has continued for more than six years, has now been completed.\" Walsh noted that in issuing the pardons Bush appears to have been preempting being implicated himself in the crimes of Iran-Contra by evidence that was to come to light during the Weinberger trial, and noted that there was a pattern of \"deception and obstruction\" by Bush, Weinberger and other senior Reagan administration officials.\n\nIn Poindexter's hometown of Odon, Indiana, a street was renamed to John Poindexter Street. Bill Breeden, a former minister, stole the street's sign in protest of the Iran–Contra affair. He claimed that he was holding it for a ransom of $30 million, in reference to the amount of money given to Iran to transfer to the Contras. He was later arrested and confined to prison, making him, as satirically noted by Howard Zinn, \"the only person to be imprisoned as a result of the Iran–Contra Scandal\".\n\nThe 100th Congress formed a joint committee (Congressional Committees Investigating The Iran-Contra Affair) and held hearings in mid-1987. Transcripts were published as: \"Iran-Contra Investigation: Joint Hearings Before the Senate Select Committee on Secret Military Assistance to Iran and the Nicaraguan Opposition and the House Select Committee to Investigate Covert Arms Transactions with Iran\" (U.S. GPO 1987–88). A closed Executive Session heard classified testimony from North and Poindexter; this transcript was published in a redacted format. The joint committee's final report was \"Report of the Congressional Committees Investigating the Iran-Contra Affair With Supplemental, Minority, and Additional Views\" (U.S. GPO 17 November 1987). The records of the committee are at the National Archives, but many are still non-public.\n\nTestimony was also heard before the House Foreign Affairs Committee, House Permanent Select Committee on Intelligence, and Senate Select Committee on Intelligence and can be found in the Congressional Record for those bodies. The Senate Intelligence Committee produced two reports: \"Preliminary Inquiry into the Sale of Arms to Iran and Possible Diversion of Funds to the Nicaraguan Resistance\" (2 February 1987) and \"Were Relevant Documents Withheld from the Congressional Committees Investigating the Iran-Contra Affair?\" (June 1989).\n\nThe Tower Commission Report was published as the \"Report of the President's Special Review Board\". U.S. GPO 26 February 1987. It was also published as \"The Tower Commission Report\", Bantam Books, 1987, \n\nThe Office of Independent Counsel/Walsh investigation produced four interim reports to Congress. Its final report was published as the \"Final Report of the Independent Counsel for Iran/Contra Matters\". Walsh's records are available at the National Archives.\n\n\n\n"}
{"id": "14788", "url": "https://en.wikipedia.org/wiki?curid=14788", "title": "Infocom", "text": "Infocom\n\nInfocom was a software company based in Cambridge, Massachusetts that produced numerous works of interactive fiction. They also produced one notable business application, a relational database called \"Cornerstone\".\n\nInfocom was founded on June 22, 1979 by staff and students of Massachusetts Institute of Technology, and lasted as an independent company until 1986, when it was bought by Activision. Activision shut down the Infocom division in 1989, although they released some titles in the 1990s under the Infocom \"Zork\" brand. Activision abandoned the Infocom trademark in 2002.\n\nInfocom games are text adventures where users direct the action by entering short strings of words to give commands when prompted. Generally the program will respond by describing the results of the action, often the contents of a room if the player has moved within the virtual world. The user reads this information, decides what to do, and enters another short series of words. Examples include \"go west\" or \"take flashlight\".\n\nInfocom games were written using a roughly LISP-like programming language called \"ZIL\" (Zork Implementation Language or Zork Interactive Language—it was referred to as both) that compiled into a byte code able to run on a standardized virtual machine called the Z-machine. As the games were text based and used variants of the same Z-machine interpreter, the interpreter had to be ported to new computer architectures only once per architecture, rather than once per game. Each game file included a sophisticated parser which allowed the user to type complex instructions to the game. Unlike earlier works of interactive fiction which only understood commands of the form 'verb noun', Infocom's parser could understand a wider variety of sentences. For instance one might type \"open the large door, then go west\", or \"go to festeron\".\n\nWith the Z-machine, Infocom was able to release most of their games for most popular home computers of the day simultaneously—the Apple II family, Atari 800, IBM PC compatibles, Amstrad CPC/PCW (one disc worked on both machines), Commodore 64, Commodore Plus/4, Commodore 128, Kaypro CP/M, Texas Instruments TI-99/4A, the Mac, Atari ST, the Commodore Amiga and the Radio Shack TRS-80. The company was also known for shipping creative props, or \"feelies\" (and even \"smellies\"), with its games.\n\nInspired by \"Colossal Cave\", Marc Blank and Dave Lebling created what was to become the first Infocom game, \"Zork\", in 1977 at MIT's Laboratory for Computer Science. Despite the development of a revolutionary virtual memory system that allowed games to be much larger than the average personal computer's normal capacity, the enormous mainframe-developed game had to be split into three roughly equal parts. \"Zork I\" was released originally for the TRS-80 in 1980. Infocom was founded on June 22, 1979; the founding members were Tim Anderson, Joel Berez, Marc Blank, Mike Broos, Scott Cutler, Stu Galley, Dave Lebling, J. C. R. Licklider, Chris Reeve and Al Vezza.\n\nLebling and Blank each authored several more games and additional game writers (or \"Implementors\") were hired, notably including Steve Meretzky. Other popular and inventive titles included a number of sequels and spinoff games in the \"Zork\" series, \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, and \"A Mind Forever Voyaging\".\n\nIn its first few years of operation, text adventures proved to be a huge revenue stream for the company. Whereas most computer games of the era would achieve initial success and then suffer a significant drop-off in sales, Infocom titles continued to sell for years and years. Employee Tim Anderson said of their situation, \"It was phenomenal – we had a basement that just printed money.\" By 1983 Infocom was perhaps the most dominant computer-game company; for example, all ten of its games were on the \"Softsel\" top 40 list of best-selling computer games for the week of December 12, 1983, with \"Zork\" in first place and two others in the top ten. In late 1984, management declined an offer by publisher Simon & Schuster to acquire Infocom for $28 million, far more than the board of directors's valuation of $10–12 million. In 1993 \"Computer Gaming World\" described this era as the \"Cambridge Camelot, where the Great Underground Empire was formed\".\n\nInfocom games were popular, \"InfoWorld\" said in 1984, in part because \"in offices all over America (more than anyone realizes) executives and managers are playing games on their computers\". Infocom stated that year that 75% of players were over 25 years old and that 80% were men; more women played its games than other companies', especially the mysteries. Most players enjoyed reading books; in 1987 president Joel Berez stated, \"[Infocom's] audience tends to be composed of heavy readers. We sell to the minority that does read\". A 1996 article in \"Next Generation\" said Infocom's \"games were noted for having more depth than any other adventure games, before or since.\" Three components proved key to Infocom's success: marketing strategy, rich storytelling and feelies. Whereas most game developers sold their games mainly in software stores, Infocom also distributed their games via bookstores. Infocom's products appealed more to those with expensive computers, such as the Apple Macintosh, IBM PC, and Commodore Amiga. Berez stated that \"there is no noticeable correlation between graphics machines and our penetration. There is a high correlation between the price of the machine and our sales ... people who are putting more money into their machines tend to buy more of our software\". Since their games were text-based, patrons of bookstores were drawn to the Infocom games as they were already interested in reading. Unlike most computer software, Infocom titles were distributed under a no-returns policy, which allowed them to make money from a single game for a longer period of time.\n\nNext, Infocom titles featured strong storytelling and rich descriptions, eschewing the inherent restrictions of graphic displays and allowing users to use their own imaginations for the lavish and exotic locations the games described. Infocom's puzzles were unique in that they were usually tightly integrated into the storyline, and rarely did gamers feel like they were being made to jump through one arbitrary hoop after another, as was the case in many of the competitors' games. The puzzles were generally logical but also required close attention to the clues and hints given in the story, causing many gamers to keep copious notes as they went along.\n\nSometimes, though, Infocom threw in puzzles just for the humor of it—if the user never ran into these, they could still finish the game. But discovering these early Easter Eggs was satisfying for some fans of the games. For example, one popular Easter egg was in the \"Enchanter\" game, which involves collecting magic spells to use in accomplishing the quest. One of these is a summoning spell, which the player needs to use to summon certain characters at different parts of the game. At one point the game mentions the \"Implementers\" who were responsible for creating the land of Zork. If the player tries to summon the Implementers, the game produces a vision of Dave Lebling and Marc Blank at their computers, surprised at this \"bug\" in the game and working feverishly to fix it.\n\nThird, the inclusion of \"feelies\"—imaginative props and extras tied to the game's theme—provided copy protection against copyright infringement. Some games were unsolvable without the extra content provided with the boxed game. And because of the cleverness and uniqueness of the feelies, users rarely felt like they were an intrusion or inconvenience, as was the case with most of the other copy-protection schemes of the time.\n\nAlthough Infocom started out with \"Zork\", and although the \"Zork\" world was the centerpiece of their product line throughout the \"Zork\" and \"Enchanter\" series, the company quickly branched out into a wide variety of story lines: fantasy, science-fiction, mystery, horror, historical adventure, children's stories, and others that defied easy categorization. In an attempt to reach out to female customers, Infocom also produced \"Plundered Hearts\", which cast the gamer in the role of the heroine of a swashbuckling adventure on the high seas, and which required the heroine to use more feminine tactics to win the game, since hacking-and-slashing was not a very ladylike way to behave. And to compete with the \"Leisure Suit Larry\" style games that were also appearing, Infocom also came out with \"Leather Goddesses of Phobos\" in 1986, which featured \"tame\", \"suggestive\", and \"lewd\" playing modes. It included among its \"feelies\" a \"scratch-and-sniff\" card with six odors that corresponded to cues given to the player during the game.\n\nOriginally, hints for the game were provided as a \"pay-per-hint\" service created by Mike Dornbrook, called the Zork Users Group (ZUG). Dornbrook also started Infocom's customer newsletter, called \"The New Zork Times\", to discuss game hints and preview and showcase new products.\n\nThe pay-per-hint service eventually led to the development of InvisiClues: books with hints, maps, clues and solutions for puzzles in the games. The answers to the puzzles were printed in invisible ink that only became visible when rubbed with a special marker that was provided with each book. Usually, two or more answers were given for each question that a gamer might have. The first answer would provide a subtle hint, the second a less subtle hint, and so forth until the last one gave an explicit walkthrough. Gamers could thus reveal only the hints that they needed to have to play the game. To prevent the mere questions (printed in normal ink) from giving away too much information about the game, a certain number of misleading fake questions were included in every InvisiClues book. Answers to these questions would start by giving misleading or impossible to carry out answers, before the final answer revealed that the question was a fake (and usually admonishing the player that revealing random clues from the book would spoil their enjoyment of the game). The InvisiClues books were regularly ranked in near the top of best seller lists for computer books.\n\nIn the Solid Gold line of re-releases, InvisiClues were integrated into the game. By typing \"HINT\" twice the player would open up a screen of possible topics where they could then reveal one hint at a time for each puzzle, just like the books.\n\nInfocom also released a small number of \"interactive fiction paperbacks\" (gamebooks), which were based on the games and featured the ability to choose a different path through the story. Similar to the \"Choose Your Own Adventure\" series, every couple of pages the book would give the reader the chance to make a choice, such as which direction they wanted to go or how they wanted to respond to another character. The reader would then choose one of the given answers and turn to the appropriate page. These books, however, never did sell particularly well, and quickly disappeared from the bookshelves.\n\nDespite their success with computer games, Vezza and other company founders hoped to produce successful business programs like Lotus Development, also founded by people from MIT and located in the same building as Infocom. Lotus released its first product, 1-2-3, in January 1983; within a year it had earned $53 million, compared to Infocom's $6 million. In 1982 Infocom started putting resources into a new division to produce business products. In 1985 they released a database product, \"Cornerstone\", aimed at capturing the then booming database market for small business. Though this application was hailed upon its release for ease of use, it sold only 10,000 copies; not enough to cover the development expenses.\n\nThe program failed for a number of reasons. Although it was packaged in a slick hard plastic carrying case and was a very good database for personal and home use, it was originally priced at USD$495 per copy and used copy-protected disks. Another serious miscalculation was that the program did not include any kind of scripting language, so it was not promoted by any of the database consultants that small businesses typically hired to create and maintain their DB applications. Reviewers were also consistently disappointed that Infocom—noted for the natural language syntax of their games—did not include a natural language query ability, which had been the most anticipated feature for this database application. In a final disappointment, \"Cornerstone\" was available only for IBM PCs; while \"Cornerstone\" had been programmed with its own virtual machine for maximum portability, it was not ported to any of the other platforms that Infocom supported for their games, so that feature had become essentially irrelevant. And because Cornerstone used this virtual machine for its processing, it suffered from slow, lackluster performance.\n\nInfocom's games' sales benefited significantly from the portability offered by running on top of a virtual machine. \"InfoWorld\" wrote in 1984 that \"the company always sells games for computers you don't normally think of as game machines, such as the DEC Rainbow or the Texas Instruments Professional Computer. This is one of the key reasons for the continued success of old titles such as Zork.\" Dornbrook estimated that year that of the 1.8 million home computers in America, one half million homes had Infocom games (\"all, if you count the pirated games\"). Computer companies sent prototypes of new systems to encourage Infocom to port Z-machine to them; the virtual machine supported more than 20 different systems, including orphaned computers for which Infocom games were among the only commercial products. The company produced the only third-party games available for the Macintosh at launch, and Berlyn promised that all 13 of its games would be available for the Atari ST within one month of its release.\n\nThe virtual machine significantly slowed \"Cornerstone\"s execution speed, however. Businesses were moving \"en masse\" to the IBM PC platform by that time, so portability was no longer a significant differentiator. Infocom had sunk much of the money from games sales into \"Cornerstone\"; this, in addition to a slump in computer game sales, left the company in a very precarious financial position. By the time Infocom removed the copy-protection and reduced the price to less than $100, it was too late, and the market had moved on to other database solutions.\n\nBy 1982 the market was moving to graphic adventures. Infocom was interested in producing them, that year proposing to Penguin Software that Antonio Antiochia, author of its \"Transylvania\", provide artwork. Within Infocom the game designers tended to oppose graphics, while marketing and business employees supported using them for the company to remain competitive. The partnership negotiations failed, in part because of the difficulty of adding graphics to the Z-machine, and Infocom instead began a series of advertisements mocking graphical games as \"graffiti\" compared to the human imagination. The marketing campaign was very successful, and Infocom's success led to other companies like Broderbund and Electronic Arts also releasing their own text games.\n\nAfter Cornerstone's failure, Infocom laid off half of its 100 employees, and Activision acquired the company on June 13, 1986 for $7.5 million. Berez stated that although the two companies' headquarters and product lines would remain separate, \"One of the effects of the merger will be for both of us to broaden our horizons\". He said that \"We're looking at graphics a lot\", while Activision was reportedly interested in using Infocom's parser. While relations were cordial between the two companies at first, the departure of Jim Levy from Activision left Bruce Davis in charge. Davis believed that his company had paid too much for Infocom and initiated a lawsuit against them to recoup some of the cost, along with changing the way Infocom was run. For example:\n\nBy 1988, rumors spread of disputes between Activision and Infocom. Infocom employees reportedly believed that Activision gave poorer-quality games to Infocom, such as Tom Snyder Productions' unsuccessful \"Infocomics\". Activision moved Infocom development to California in 1989, and the company was now just a publishing label. Rising costs and falling profits, exacerbated by the lack of new products in 1988 and technical issues with its DOS products, caused Activision to close Infocom in 1989, after which some of the remaining Infocom designers such as Steve Meretzky moved to the company Legend Entertainment, founded by Bob Bates and Mike Verdu, to continue creating games in the Infocom tradition.\n\nFor a few years, Activision continued to market Infocom's classic games in collections (usually by genre, such as the Science Fiction collection); in 1991, they published \"The Lost Treasures of Infocom\", followed in 1992 by \"The Lost Treasures of Infocom II\". These compilations featured nearly every game produced by Infocom before 1988. (\"Leather Goddesses of Phobos\" was not included in either bundle, but could be ordered via a coupon included with \"Lost Treasures II\".) The compilations lacked the \"feelies\" that came with each game, but in some cases included photographs of them. In 1996, the first bundles were followed by \"Classic Text Adventure Masterpieces of Infocom\", a single CD-ROM which contained the works of both collections. This release, however, was missing \"The Hitchhiker's Guide to the Galaxy\" and \"Shogun\" because the licenses from Douglas Adams' and James Clavell's estates had expired.\n\nIn 2008 a back-up with the source code of all Infocom's video games appeared from an anonymous source and was archived by Internet Archive's Jason Scott.\n\nIn 2012, Activision released \"Lost Treasures of Infocom\" for iOS devices. In-app purchases provide access for 27 of the titles. It also lacks \"Shogun\" and \"The Hitchhiker's Guide to the Galaxy\" as well as \"Beyond Zork\", \"Zork Zero\" and \"Nord and Bert\".\n\nThe brand name was registered by Oliver Klaeffling of Germany in 2007, then was abandoned the following year. The Infocom trademark was then held by Pete Hottelet's Omni Consumer Products, who registered the name around the same time as Klaeffling in 2007. As of March 2017, the trademark is owned by infocom.xyz, according to Bob Bates.\n\n\n\n\nWith the exception of \"The Hitchhiker's Guide to the Galaxy\" and \"Shogun\", the copyrights to the Infocom games are believed to be still held by Activision. \"Dungeon\", the mainframe precursor to the commercial Zork trilogy, is believed to be free for non-commercial use. but prohibited commercial use. It was this copy that the popular Fortran mainframe version was based on. The C version was based on the Fortran version. and is available from The Interactive Fiction Archive as original FORTRAN source code, a Z-machine story file and as various native source ports. Many Infocom titles can be downloaded via the Internet, but only in violation of the copyright. Activision did at one point release the original trilogy for free-of-charge download as a promotion but prohibited redistribution and have since discontinued this. There are currently at least four Infocom sampler and demos available from the IF Archive as Z-machine story files which require a Z-machine interpreter to play. Interpreters are available for most computer platforms, the most widely used being the Frotz, Zip, and Nitfol interpreters.\n\nFive games (\"Zork I\", \"Planetfall\", \"The Hitchhiker's Guide to the Galaxy\", \"Wishbringer\" and \"Leather Goddesses of Phobos\") were re-released in Solid Gold format. The Solid Gold versions of those games include a built-in InvisiClues hint system.\n\n\"Zork\" made a cameo appearance as an easter egg in Activision and Treyarch's \"\". It can be accessed during the main menu and runs much like a DOS program.\n\n\n\n\n"}
{"id": "14789", "url": "https://en.wikipedia.org/wiki?curid=14789", "title": "Interactive fiction", "text": "Interactive fiction\n\nInteractive fiction, often abbreviated IF, is software simulating environments in which players use text commands to control characters and influence the environment. Works in this form can be understood as literary narratives, either in the form of Interactive narratives or Interactive narrations. These works can also be understood as a form of video game, either in the form of an adventure game or role-playing game. In common usage, the term refers to text adventures, a type of adventure game where the entire interface can be \"text-only\", however, graphical text adventure games, where the text is accompanied by graphics (still images, animations or video) still fall under the text adventure category if the main way to interact with the game is by typing text. Some users of the term distinguish between interactive fiction, known as \"Puzzle-free\", that focuses on narrative, and \"text adventures\" that focus on puzzles.\n\nDue to their text-only nature, they sidestepped the problem of writing for widely divergent graphics architectures. This feature meant that interactive fiction games were easily ported across all the popular platforms at the time, including CP/M (not known for gaming or strong graphics capabilities). The number of interactive fiction works is increasing steadily as new ones are produced by an online community, using freely available development systems.\n\nThe term can also be used to refer to digital versions of literary works that are not read in a linear fashion, known as gamebooks, where the reader is instead given choices at different points in the text; these decisions determine the flow and outcome of the story. The most famous example of this form of printed fiction is the \"Choose Your Own Adventure\" book series, and the collaborative \"\" format has also been described as a form of interactive fiction. The term “interactive fiction” is sometimes used also to refer to visual novels, a type of interactive narrative software popular in Japan.\n\nText adventures are one of the oldest types of computer games and form a subset of the adventure genre. The player uses text input to control the game, and the game state is relayed to the player via text output. Interactive fiction usually relies on reading from a screen and on typing input, although text-to-speech synthesizers allow blind and visually impaired users to play interactive fiction titles as audio games.\n\nInput is usually provided by the player in the form of simple sentences such as \"get key\" or \"go east\", which are interpreted by a text parser. Parsers may vary in sophistication; the first text adventure parsers could only handle two-word sentences in the form of verb-noun pairs. Later parsers, such as those built on ZIL (Zork Implementation Language), could understand complete sentences. Later parsers could handle increasing levels of complexity parsing sentences such as \"open the red box with the green key then go north\". This level of complexity is the standard for works of interactive fiction today.\n\nDespite their lack of graphics, text adventures include a physical dimension where players move between rooms. Many text adventure games boasted their total number of rooms to indicate how much gameplay they offered. These games are unique in that they may create an \"illogical space\", where going north from area A takes you to area B, but going south from area B did not take you back to area A. This can create mazes that do not behave as players expect, and thus players must maintain their own map. These illogical spaces are much more rare in today's era of 3D gaming, and the Interactive Fiction community in general decries the use of mazes entirely, claiming that mazes have become arbitrary 'puzzles for the sake of puzzles' and that they can, in the hands of inexperienced designers, become immensely frustrating for players to navigate.\n\nInteractive fiction shares much in common with Multi-User Dungeons ('MUDs'). MUDs, which became popular in the mid-1980s, rely on a textual exchange and accept similar commands from players as do works of IF; however, since interactive fiction is single player, and MUDs, by definition, have multiple players, they differ enormously in gameplay styles. MUDs often focus gameplay on activities that involve communities of players, simulated political systems, in-game trading, and other gameplay mechanics that are not possible in a single player environment.\n\nInteractive fiction features two distinct modes of writing: the player input and the game output. As described above, player input is expected to be in simple command form (imperative sentences). A typical command may be:> PULL Lever\n\nThe responses from the game are usually written from a second-person point of view, in present tense. This is because, unlike in most works of fiction, the main character is closely associated with the player, and the events are seen to be happening as the player plays. While older text adventures often identified the protagonist with the player directly, newer games tend to have specific, well-defined protagonists with separate identities from the player. The classic essay \"Crimes Against Mimesis\" discusses, among other IF issues, the nature of \"You\" in interactive fiction. A typical response might look something like this, the response to \"look in tea chest\" at the start of \"Curses\":\n\n\"That was the first place you tried, hours and hours ago now, and there's nothing there but that boring old book. You pick it up anyway, bored as you are.\" \n\nMany text adventures, particularly those designed for humour (such as \"Zork\", \"The Hitchhiker's Guide to the Galaxy\", and \"Leather Goddesses of Phobos\"), address the player with an informal tone, sometimes including sarcastic remarks (see the transcript from \"Curses\", above, for an example). The late Douglas Adams, in designing the IF version of his 'Hitchhiker's Guide to the Galaxy', created a unique solution to the final puzzle of the game: the game requires the one solitary item that the player \"didn't\" choose at the outset of play.\n\nSome IF works dispense with second-person narrative entirely, opting for a first-person perspective ('I') or even placing the player in the position of an observer, rather than a direct participant. In some 'experimental' IF, the concept of self-identification is eliminated entirely, and the player instead takes the role of an inanimate object, a force of nature, or an abstract concept; experimental IF usually pushes the limits of the concept and challenges many assumptions about the medium.\n\nThough neither program was developed as a narrative work, the software programs ELIZA (1964–1966) and SHRDLU (1968–1970) can formally be considered early examples of interactive fiction, as both programs used natural language processing to take input from their user and respond in a virtual and conversational manner. ELIZA simulated a psychotherapist that appeared to provide human-like responses to the user's input, while SHRDLU employed an artificial intelligence that could move virtual objects around an environment and respond to questions asked about the environment's shape. The development of effective natural language processing would become an essential part of interactive fiction development.\n\nAround 1975, Will Crowther, a programmer and an amateur caver, wrote the first text adventure game, \"Adventure\" (originally called \"ADVENT\" because a filename could only be six characters long in the operating system he was using, and later named \"Colossal Cave Adventure\"). Having just gone through a divorce, he was looking for a way to connect with his two young children. Over the course of a few weekends, he wrote a text based cave exploration game that featured a sort of guide/narrator who talked in full sentences and who understood simple two word commands that came close to natural English. Adventure was programmed in Fortran for the PDP-10. Crowther's original version was an accurate simulation of part of the real Colossal Cave, but also included fantasy elements (such as axe-wielding dwarves and a magic bridge).\n\nStanford University graduate student Don Woods discovered \"Adventure\" while working at the Stanford Artificial Intelligence Laboratory, and in 1977 obtained and expanded Crowther's source code (with Crowther's permission). Woods's changes were reminiscent of the writings of J.R.R. Tolkien, and included a troll, elves, and a volcano some claim is based on Mount Doom, but Woods says was not.\n\nIn early 1977, Adventure spread across ARPAnet, and has survived on the Internet to this day. The game has since been ported to many other operating systems, and was included with the floppy-disk distribution of Microsoft's MS-DOS 1.0 OS. \"Adventure\" is a cornerstone of the online IF community; there currently exist dozens of different independently-programmed versions, with additional elements, such as new rooms or puzzles, and various scoring systems.\n\nThe popularity of \"Adventure\" led to the wide success of interactive fiction during the late 1970s, when home computers had little, if any, graphics capability. Many elements of the original game have survived into the present, such as the command 'xyzzy', which is now included as an Easter Egg in modern games, such as \"Microsoft Minesweeper\".\n\n\"Adventure\" was also directly responsible for the founding of Sierra Online (later Sierra Entertainment); Ken and Roberta Williams played the game and decided to design one of their own, but with graphics.\n\nAdventure International was founded by Scott Adams (not to be confused with the creator of Dilbert). In 1978, Adams wrote \"Adventureland\", which was loosely patterned after (the original) \"Colossal Cave Adventure\". He took out a small ad in a computer magazine in order to promote and sell \"Adventureland\", thus creating the first commercial adventure game. In 1979 he founded Adventure International, the first commercial publisher of interactive fiction. That same year, \"Dog Star Adventure\" was published in source code form in \"SoftSide\", spawning legions of similar games in BASIC.\n\nThe largest company producing works of interactive fiction was Infocom, which created the \"Zork\" series and many other titles, among them \"Trinity\", \"The Hitchhiker's Guide to the Galaxy\" and \"A Mind Forever Voyaging\".\n\nIn June 1977, Marc Blank, Bruce K. Daniels, Tim Anderson, and Dave Lebling began writing the mainframe version of \"Zork\" (also known as \"Dungeon\"), at the MIT Laboratory for Computer Science. The game was programmed in a computer language called MDL, a variant of LISP.\n\nThe term Implementer was the self-given name of the creators of the text adventure series Zork. It is for this reason that game designers and programmers can be referred to as an implementer, often shortened to Imp, rather than a writer.\n\nIn early 1979, the game was completed. Ten members of the \"MIT Dynamics Modelling Group\" went on to join Infocom when it was incorporated later that year.\n\nIn order to make its games as portable as possible, Infocom developed the Z-machine, a custom virtual machine that could be implemented on a large number of platforms, and took standardized \"story files\" as input.\n\nIn a non-technical sense, Infocom was responsible for developing the interactive style that would be emulated by many later interpreters. The Infocom parser was widely regarded as the best of its era. It accepted complex, complete sentence commands like \"put the blue book on the writing desk\" at a time when most of its competitors parsers were restricted to simple two word verb-noun combinations such as \"put book\". The parser was actively upgraded with new features like undo and error correction, and later games would 'understand' multiple sentence input: 'pick up the gem and put it in my bag. take the newspaper clipping out of my bag then burn it with the book of matches'.\n\nSeveral companies offered optional commercial feelies (physical props associated with a game). The tradition of 'feelies' (and the term itself) is believed to have originated with \"Deadline\" (1982), the third Infocom title after \"Zork I\" and \"II\". When writing this game, it was not possible to include all of the information in the limited (80KB) disk space, so Infocom created the first feelies for this game; extra items that gave more information than could be included within the digital game itself. These included police interviews, the coroner's findings, letters, crime scene evidence and photos of the murder scene.\n\nThese materials were very difficult for others to copy or otherwise reproduce, and many included information that was essential to completing the game. Seeing the potential benefits of both aiding game-play immersion and providing a measure of creative copy-protection, in addition to acting as a deterrent to software piracy, Infocom and later other companies began creating feelies for numerous titles. In 1987, Infocom released a special version of the first three \"Zork\" titles together with plot-specific coins and other trinkets. This concept would be expanded as time went on, such that later game feelies would contain passwords, coded instructions, page numbers, or other information that would be required to successfully complete the game.\n\nInteractive fiction became a standard product for many software companies. By 1982 \"Softline\" wrote that \"the demands of the market are weighted heavily toward hi-res graphics\" in games like Sierra's \"The Wizard and the Princess\" and its imitators. Such graphic adventures became the dominant form of the genre on computers with graphics, like the Apple II. By 1982 Adventure International began releasing versions of its games with graphics. The company went bankrupt in 1985. Synapse Software and Acornsoft were also closed in 1985. Leaving Infocom as the leading company producing text-only adventure games on the Apple II with sophisticated parsers and writing, and still advertising its lack of graphics as a virtue. The company was bought by Activision in 1986 after the failure of \"Cornerstone\", Infocom's database software program, and stopped producing text adventures a few years later. Soon after Telaium/Trillium also closed.\n\nProbably the first commercial work of interactive fiction produced outside the U.S. was the dungeon crawl game of \"Acheton\", produced in Cambridge, England, and first commercially released by Acornsoft (later expanded and reissued by Topologika). Other leading companies in the UK were Magnetic Scrolls and Level 9 Computing. Also worthy of mention are Delta 4, Melbourne House, and the homebrew company Zenobi.\n\nIn the early 1980s Edu-Ware also produced interactive fiction for the Apple II as designated by the \"if\" graphic that was displayed on startup. Their titles included the \"Prisoner\" and \"Empire\" series (\"Empire I: World Builders\", \"Empire II: Interstellar Sharks\", \"Empire III: Armageddon\").\n\nIn 1981, CE Software published \"SwordThrust\" as a commercial successor to the \"Eamon\" gaming system for the Apple II. SwordThrust and Eamon were simple two-word parser games with many role-playing elements not available in other interactive fiction. While SwordThrust published seven different titles, it was vastly overshadowed by the non-commercial Eamon system which allowed private authors to publish their own titles in the series. By March 1984, there were 48 titles published for the Eamon system (and over 270 titles in total as of March 2013).\n\nIn Italy, interactive fiction games were mainly published and distributed through various magazines in included tapes. The largest number of games were published in the two magazines Viking and Explorer, with versions for the main 8-bit home computers (Sinclair ZX Spectrum, Commodore 64 and MSX). The software house producing those games was Brainstorm Enterprise, and the most prolific IF author was Bonaventura Di Bello, who produced 70 games in the Italian language. The wave of interactive fiction in Italy lasted for a couple of years thanks to the various magazines promoting the genre, then faded and remains still today a topic of interest for a small group of fans and less known developers, celebrated on Web sites and in related newsgroups.\n\nIn Spain, interactive fiction was considered a minority genre, and was not very successful. The first Spanish interactive fiction commercially released was \"Yenght\" in 1983, by Dinamic Software, for the ZX Spectrum. Later on, in 1987, the same company produced an interactive fiction about \"Don Quijote\". After several other attempts, the company Aventuras AD, emerged from Dinamic, became the main interactive fiction publisher in Spain, including titles like a Spanish adaptation of \"Colossal Cave Adventure\", an adaptation of the Spanish comic \"El Jabato\", and mainly the \"Ci-U-Than\" trilogy, composed by \"La diosa de Cozumel\" (1990), \"Los templos sagrados\" (1991) and \"Chichen Itzá\" (1992). During this period, the Club de Aventuras AD (CAAD), the main Spanish speaking community around interactive fiction in the world, was founded, and after the end of Aventuras AD in 1992, the CAAD continued on its own, first with their own magazine, and then with the advent of Internet, with the launch of an active internet community that still produces interactive non commercial fiction nowadays.\n\nLegend Entertainment was founded by Bob Bates and Mike Verdu in 1989. It started out from the ashes of Infocom. The text adventures produced by Legend Entertainment used (high-resolution) graphics as well as sound. Some of their titles include \"Eric the Unready\", the \"Spellcasting\" series and \"Gateway\" (based on Frederik Pohl's novels).\n\nThe last text adventure created by Legend Entertainment was \"Gateway II\" (1992), while the last game ever created by Legend was \"\" (2003) – the well-known first-person shooter action game using the Unreal Engine for both impressive graphics and realistic physics. In 2004, Legend Entertainment was acquired by Atari, who published \"Unreal II\" and released for both Microsoft Windows and Microsoft's Xbox.\n\nMany other companies such as Level 9 Computing, Magnetic Scrolls, Delta 4 and Zenobi had closed by 1992.\n\nIn 1991 and 1992, Activision released \"The Lost Treasures of Infocom\" in two volumes, a collection containing most of Infocom's games, followed in 1996 by \"Classic Text Adventure Masterpieces of Infocom\".\n\nAfter the decline of the commercial interactive fiction market in the 1990s, an online community eventually formed around the medium. In 1987, the Usenet newsgroup rec.arts.int-fiction was created, and was soon followed by rec.games.int-fiction. By custom, the topic of rec.arts.int-fiction is interactive fiction authorship and programming, while rec.games.int-fiction encompasses topics related to playing interactive fiction games, such as hint requests and game reviews. As of late 2011, discussions between writers have mostly moved from rec.arts.int-fiction to the Interactive Fiction Community Forum.\n\nOne of the most important early developments was the reverse-engineering of Infocom's Z-Code format and Z-Machine virtual machine in 1987 by a group of enthusiasts called the InfoTaskForce and the subsequent development of an interpreter for Z-Code story files. As a result, it became possible to play Infocom's work on modern computers.\n\nFor years, amateurs with the IF community produced interactive fiction works of relatively limited scope using the Adventure Game Toolkit and similar tools.\n\nThe breakthrough that allowed the interactive fiction community to truly prosper, however, was the creation and distribution of two sophisticated development systems. In 1987, Michael J. Roberts released TADS, a programming language designed to produce works of interactive fiction. In 1993, Graham Nelson released Inform, a programming language and set of libraries which compiled to a Z-Code story file. Each of these systems allowed anyone with sufficient time and dedication to create a game, and caused a growth boom in the online interactive fiction community.\n\nDespite the lack of commercial support, the availability of high quality tools allowed enthusiasts of the genre to develop new high quality games. Competitions such as the annual Interactive Fiction Competition for short works, the Spring Thing for longer works, and the XYZZY Awards, further helped to improve the quality and complexity of the games. Modern games go much further than the original \"Adventure\" style, improving upon Infocom games, which relied extensively on puzzle solving, and to a lesser extent on communication with non player characters, to include experimentation with writing and story-telling techniques.\n\nWhile the majority of modern interactive fiction that is developed is distributed for free, there are some commercial endeavors. In 1998, Michael Berlyn, a former Implementor at Infocom, started a new game company, Cascade Mountain Publishing, whose goals were to publish interactive fiction. Despite the Interactive Fiction community providing social and financial backing Cascade Mountain Publishing went out of business in 2000.\n\nOther commercial endeavours include Peter Nepstad's \"\", several games by Howard Sherman published as Malinche Entertainment, The General Coffee Company's \"Future Boy!,\" \"Cypher\", a graphically enhanced cyberpunk game and various titles by \"Textfyre\". Emily Short was commissioned to develop the game \"City of Secrets\" but the project fell through and she ended up releasing it herself.\n\nTo learn more about the history of interactive fiction, see the \"Get Lamp\" documentary.\n\n\nThe original Interactive fiction Colossal Cave Adventure was programmed in Fortran, originally developed by IBM. Adventure's parsers could only handle two-word sentences in the form of verb-noun pairs.\n\nInfocom's games of 1979-88, such as Zork, were written using a LISP-like programming language called ZIL (Zork Implementation Language or Zork Interactive Language, it was referred to as both) that compiled into a byte code able to run on a standardized virtual machine called the Z-machine. As the games were text based and used variants of the same Z-machine interpreter, the interpreter only had to be ported to a computer once, rather than once each game. Each game file included a sophisticated parser which allowed the user to type complex instructions to the game. Unlike earlier works of interactive fiction which only understood commands of the form 'verb noun', Infocom's parser could understand a wider variety of sentences. For instance one might type \"open the large door, then go west\", or \"go to the hall\". With the Z-machine, Infocom was able to release most of their games for most popular home computers of the time simultaneously, including Apple II family, Atari 800, IBM PC compatibles, Amstrad CPC/PCW (one disc worked on both machines), Commodore 64, Commodore Plus/4, Commodore 128, Kaypro CP/M, Texas Instruments TI-99/4A, the Mac, Atari ST, the Commodore Amiga and the Radio Shack TRS-80. Infocom was also known for shipping creative props, or \"feelies\" (and even \"smellies\"), with its games.\n\nDuring the 1990s Interactive fiction was mainly written with C-like languages, such as TADS 2 and Inform 6. A number of systems for writing interactive fiction now exist. The most popular remain Inform, TADS, or ADRIFT, but they diverged in their approach to IF-writing during the 2000s, giving today's IF writers an objective choice. By 2006 IFComp, most games were written for Inform, with a strong minority of games for TADS and ADRIFT, followed by a small number of games for other systems.\n\nWhile familiarity with a programming language leads many new authors to attempt to produce their own complete IF application, most established IF authors recommend use of a specialised IF language, arguing that such systems allow authors to avoid the technicalities of producing a full featured parser, while allowing broad community support. The choice of authoring system usually depends on the author's desired balance of ease of use versus power, and the portability of the final product.\n\nOther development systems include:\n\nInterpreters are the software used to play the works of interactive fiction created with a development system. Since they need to interact with the player, the \"story files\" created by development systems are programs in their own right. Rather than running directly on any one computer, they are programs run by Interpreters, or virtual machines, which are designed specially for IF. They may be part of the development system, or can be compiled together with the work of fiction as a standalone executable file.\n\nThe Z-machine was designed by the founders of Infocom, in 1979. They were influenced by the then-new idea of a virtual Pascal computer, but replaced P with Z for Zork, the celebrated adventure game of 1977-79. The Z-machine evolved during the 1980s but over 30 years later, it remains in use essentially unchanged. Glulx was designed by Andrew Plotkin in the late 1990s as a new-generation IF virtual machine. It overcomes the technical constraint on the Z-machine by being a 32-bit rather than 16-bit processor. Frotz is a modern Z-machine interpreter originally written in C (programming language) by Stefan Jokisch in 1995 for DOS. Over time it was ported to other platforms, such as Unix, RISC OS, Mac OS and most recently iOS. Modern Glulx interpreters are based on \"Glulxe\", by Andrew Plotkin, and \"Git\", by Iain Merrick. Other interpreters include Zoom for Mac OS X, or for Unix or Linux, maintained by Andrew Hunter, and Spatterlight for Mac OS X, maintained by Tor Andersson.\n\nIn addition to commercial distribution venues and individual websites, many works of free interactive fiction are distributed through community websites. These include the Interactive Fiction Database (IFDb), The Interactive Fiction Reviews Organization (IFRO), a game catalog and recommendation engine, and the Interactive Fiction Archive.\n\nWorks may be distributed for playing with in a separate interpreter. In which case they are often made available in the Blorb package format that many interpreters support. A filename ending .zblorb is a story file intended for a Z-machine in a Blorb wrapper, while a filename ending .gblorb is a story file intended for a Glulx in a Blorb wrapper. It is not common but IF files are sometimes also seen without a Blorb wrapping, though this usually means cover art, help files, and so forth are missing, like a book with the covers torn off. Z-machine story files usually have names ending .z5 or .z8, the number being a version number, and Glulx story files usually end .ulx.\n\nAlternatively, works may be distributed for playing in a web browser. For example, the 'Parchment' project is for web browser-based IF Interpreter, for both Z-machine and Glulx files.\n\nSome software such as Twine publishes directly to HTML, the standard language used to create web pages, reducing the requirement for an Interpreter or virtual machine.\n\n\n\n"}
{"id": "14790", "url": "https://en.wikipedia.org/wiki?curid=14790", "title": "Ice hockey", "text": "Ice hockey\n\nIce hockey is a contact team sport played on ice, usually in a rink, in which two teams of skaters use their sticks to shoot a vulcanized rubber puck into their opponent's net to score points. The sport is known to be fast-paced and physical, with teams usually consisting of six players each: one goaltender, and five players who skate up and down the ice trying to take the puck and score a goal against the opposing team.\n\nIce hockey is most popular in Canada, central and eastern Europe, the Nordic countries, Russia and the United States. Ice hockey is the official national winter sport of Canada. In addition, ice hockey is the most popular winter sport in Belarus, Croatia, the Czech Republic, Finland, Latvia, Russia, Slovakia, Sweden, and Switzerland. North America's National Hockey League (NHL) is the highest level for men's ice hockey and the strongest professional ice hockey league in the world. The Kontinental Hockey League (KHL) is the highest league in Russia and much of Eastern Europe. The International Ice Hockey Federation (IIHF) is the formal governing body for international ice hockey, with the IIHF managing international tournaments and maintaining the IIHF World Ranking. Worldwide, there are ice hockey federations in 76 countries.\n\nIn Canada, the United States, Nordic countries, and some other European countries the sport is known simply as hockey; the name \"ice hockey\" is used in places where \"hockey\" more often refers to the more popular field hockey, such as countries in South America, Asia, Africa, Australasia, and some European countries including the United Kingdom, Ireland and the Netherlands.\n\nIce hockey is believed to have evolved from simple stick and ball games played in the 18th and 19th century United Kingdom and elsewhere. These games were brought to North America and several similar winter games using informal rules as they were developed, such as \"shinny\" and \"ice polo\". The contemporary sport of ice hockey was developed in Canada, most notably in Montreal, where the first indoor hockey game was played on March 3, 1875. Some characteristics of that game, such as the length of the ice rink and the use of a puck, have been retained to this day. Amateur ice hockey leagues began in the 1880s, and professional ice hockey originated around 1900. The Stanley Cup, emblematic of ice hockey club supremacy, was first awarded in 1893 to recognize the Canadian amateur champion and later became the championship trophy of the NHL. In the early 1900s, the Canadian rules were adopted by the Ligue Internationale de Hockey sur Glace, the precursor of the IIHF and the sport was played for the first time in the Olympics in the 1920 Summer Olympics.\n\nIn international competitions, the national teams of six countries (the \"Big Six\") predominate: Canada, Czech Republic, Finland, Russia, Sweden and the United States. Of the 69 medals awarded all-time in men's competition at the Olympics, only seven medals were not awarded to one of those countries (or two of their precursors, the Soviet Union for Russia, and Czechoslovakia for the Czech Republic). In the annual Ice Hockey World Championships, 177 of 201 medals have been awarded to the six nations. Teams outside the \"Big Six\" have won only five medals in either competition since 1953. The World Cup of Hockey is organized by the National Hockey League and the National Hockey League Players' Association (NHLPA), unlike the annual World Ice Hockey Championships and quadrennial Olympic tournament, both run by the International Ice Hockey Federation (IIHF). World Cup games are played under NHL rules and not those of the IIHF, and the tournament occurs prior to the NHL pre-season, allowing for all the NHL's players to be available, unlike the World Championships, which overlaps with the NHL's Stanley Cup playoffs. All 12 Women's Olympic and 36 IIHF World Women's Championships medals have been awarded to one of these six countries, and every gold medal in both competitions has been won by either the Canadian national team or the United States national team.\nIn England, field hockey has been historically referred to as simply \"hockey\" and it is in historical references to field hockey that the name \"hockey\" first appears. The first known mention spelled as \"hockey\" is in the 1773 book \"Juvenile Sports and Pastimes, to Which Are Prefixed, Memoirs of the Author: Including a New Mode of Infant Education\", by Richard Johnson (Pseud. Master Michel Angelo), whose chapter XI was titled \"New Improvements on the Game of Hockey\". The 1573 Statute of Galway banned a sport called hokie'—the hurling of a little ball with sticks or staves\". A form of this word was thus being used in the 16th century, though much removed from its current usage.\n\nThe belief that hockey was mentioned in a 1363 proclamation by King Edward III of England is based on modern translations of the proclamation, which was originally in Latin and explicitly forbade the games \"Pilam Manualem, Pedivam, & Bacularem: & ad Canibucam & Gallorum Pugnam\". The English historian and biographer John Strype did not use the word \"hockey\" when he translated the proclamation in 1720, instead translating \"Canibucam\" as \"Cambuck\"; this may have referred to either an early form of hockey or a game more similar to golf or croquet.\n\nAccording to the Austin Hockey Association, the word \"puck\" derives from the Scottish Gaelic \"puc\" or the Irish \"poc\" (to poke, punch or deliver a blow). \"...The blow given by a hurler to the ball with his camán or hurley is always called a puck.\"\n\nStick-and-ball games date back to pre-Christian times. In Europe, these games included the Irish game of hurling, the closely related Scottish game of shinty and versions of field hockey (including \"bandy ball\", played in England). IJscolf, a game resembling colf on an ice-covered surface, was popular in the Low Countries between the Middle Ages and the Dutch Golden Age. It was played with a wooden curved bat (called a \"colf\" or \"kolf\"), a wooden or leather ball and two poles (or nearby landmarks), with the objective to hit the chosen point using the least number of strokes. A similar game (\"knattleikr\") had been played for a thousand years or more by the Scandinavian peoples, as documented in the Icelandic sagas. Polo has been referred to as \"hockey on horseback\". In England, field hockey developed in the late 17th century, and there is evidence that some games of field hockey took place on the ice. These games of \"hockey on ice\" were sometimes played with a \"bung\" (a plug of cork or oak used as a stopper on a barrel). William Pierre Le Cocq stated, in a 1799 letter written in Chesham, England:\n\nI must now describe to you the game of Hockey; we have each a stick turning up at the end. We get a bung. There are two sides one of them knocks one way and the other side the other way. If any one of the sides makes the bung reach that end of the churchyard it is victorious.\n\nA 1797 engraving unearthed by Swedish sport historians Carl Gidén and Patrick Houda shows a person on skates with a stick and bung on the River Thames, probably in December 1796.\n\nBritish soldiers and immigrants to Canada and the United States brought their stick-and-ball games with them and played them on the ice and snow of winter. In 1825, John Franklin wrote \"The game of hockey played on the ice was the morning sport\" on Great Bear Lake during one of his Arctic expeditions. A mid-1830s watercolour portrays New Brunswick lieutenant-governor Archibald Campbell and his family with British soldiers on skates playing a stick-on-ice sport. Captain R.G.A. Levinge, a British Army officer in New Brunswick during Campbell's time, wrote about \"hockey on ice\" on Chippewa Creek (a tributary of the Niagara River) in 1839. In 1843 another British Army officer in Kingston, Ontario wrote, \"Began to skate this year, improved quickly and had great fun at hockey on the ice.\" An 1859 \"Boston Evening Gazette\" article referred to an early game of hockey on ice in Halifax that year. An 1835 painting by John O'Toole depicts skaters with sticks and bung on a frozen stream in the American state of West Virginia, at that time still part of Virginia.\n\nIn the same era, the Mi'kmaq, a First Nations people of the Canadian Maritimes, also had a stick-and-ball game. Canadian oral histories describe a traditional stick-and-ball game played by the Mi'kmaq, and Silas Tertius Rand (in his 1894 \"Legends of the Micmacs\") describes a Mi'kmaq ball game known as \"tooadijik\". Rand also describes a game played (probably after European contact) with hurleys, known as \"wolchamaadijik\". Sticks made by the Mi'kmaq were used by the British for their games.\n\nEarly 19th-century paintings depict shinney (or \"shinny\"), an early form of hockey with no standard rules which was played in Nova Scotia. Many of these early games absorbed the physical aggression of what the Onondaga called \"dehuntshigwa'es\" (lacrosse). Shinney was played on the St. Lawrence River at Montreal and Quebec City, and in Kingston, Ontario and Ottawa, Ontario. The number of players was often large. To this day, shinney (derived from \"shinty\") is a popular Canadian term for an informal type of hockey, either ice or street hockey.\n\nThomas Chandler Haliburton, in \"The Attache: Second Series\" (published in 1844) imagined a dialogue, between two of the novel's characters, which mentions playing \"hurly on the long pond on the ice\". This has been interpreted by some historians from Windsor, Nova Scotia as reminiscence of the days when the author was a student at King's College School in that town in 1810 and earlier. Based on Haliburton's quote, claims were made that modern hockey was invented in Windsor, Nova Scotia, by King's College students and perhaps named after an individual (\"Colonel Hockey's game\"). Others claim that the origins of hockey come from games played in the area of Dartmouth and Halifax in Nova Scotia. However, several references have been found to hurling and shinty being played on the ice long before the earliest references from both Windsor and Dartmouth/Halifax, and the word \"hockey\" was used to designate a stick-and-ball game at least as far back as 1773, as it was mentioned in the book \"Juvenile Sports and Pastimes, to Which Are Prefixed, Memoirs of the Author: Including a New Mode of Infant Education\" by Richard Johnson (Pseud. Master Michel Angelo), whose chapter XI was titled \"New Improvements on the Game of Hockey\".\n\nWhile the game's origins lie elsewhere, Montreal is at the centre of the development of the sport of contemporary ice hockey, and is recognized as the birthplace of organized ice hockey. On March 3, 1875, the first organized indoor game was played at Montreal's Victoria Skating Rink between two nine-player teams, including James Creighton and several McGill University students. Instead of a ball or bung, the game featured a \"flat circular piece of wood\" (to keep it in the rink and to protect spectators). The goal posts were apart (today's goals are six feet wide).\n\nIn 1876, games played in Montreal were \"conducted under the 'Hockey Association' rules\"; the Hockey Association was England's field hockey organization. In 1877, \"The Gazette\" (Montreal) published a list of seven rules, six of which were largely based on six of the Hockey Association's twelve rules, with only minor differences (even the word \"ball\" was kept); the one added rule explained how disputes should be settled. The McGill University Hockey Club, the first ice hockey club, was founded in 1877 (followed by the Quebec Hockey Club in 1878 and the Montreal Victorias in 1881). In 1880, the number of players per side was reduced from nine to seven.\n\nThe number of teams grew, enough to hold the first \"world championship\" of ice hockey at Montreal's annual Winter Carnival in 1883. The McGill team won the tournament and was awarded the \"Carnival Cup\". The game was divided into thirty-minute halves. The positions were now named: left and right wing, centre, rover, point and cover-point, and goaltender. In 1886, the teams competing at the Winter Carnival organized the Amateur Hockey Association of Canada (AHAC), and played a season comprising \"challenges\" to the existing champion.\nIn Europe, it is believed that in 1885 the Oxford University Ice Hockey Club was formed to play the first Ice Hockey Varsity Match against traditional rival Cambridge in St. Moritz, Switzerland; however, this is undocumented. The match was won by the Oxford Dark Blues, 6–0; the first photographs and team lists date from 1895. This rivalry continues, claiming to be the oldest hockey rivalry in history; a similar claim is made about the rivalry between Queen's University and Royal Military College of Kingston, Ontario. Since 1986, considered the 100th anniversary of the rivalry, teams of the two colleges play for the Carr-Harris Cup.\n\nIn 1888, the Governor General of Canada, Lord Stanley of Preston (whose sons and daughter were hockey enthusiasts), first attended the Montreal Winter Carnival tournament and was impressed with the game. In 1892, realizing that there was no recognition for the best team in Canada (although a number of leagues had championship trophies), he purchased a silver bowl for use as a trophy. The Dominion Hockey Challenge Cup (which later became known as the Stanley Cup) was first awarded in 1893 to the Montreal Hockey Club, champions of the AHAC; it continues to be awarded annually to the National Hockey League's championship team. Stanley's son Arthur helped organize the Ontario Hockey Association, and Stanley's daughter Isobel was one of the first women to play ice hockey.\n\nBy 1893, there were almost a hundred teams in Montreal alone; in addition, there were leagues throughout Canada. Winnipeg hockey players used cricket pads to better protect the goaltender's legs; they also introduced the \"scoop\" shot, or what is now known as the wrist shot. William Fairbrother, from Ontario, Canada is credited with inventing the ice hockey net in the 1890s. Goal nets became a standard feature of the Canadian Amateur Hockey League (CAHL) in 1900. Left and right defence began to replace the point and cover-point positions in the OHA in 1906.\n\nIn the United States, \"ice polo\", played with a ball rather than a puck, was popular during this period; however, by 1893 Yale University and Johns Hopkins University held their first ice hockey matches. American financier Malcolm Greene Chace is credited with being the father of hockey in the United States. In 1892, as an amateur tennis player, Chace visited Niagara Falls, New York for a tennis match, where he met some Canadian hockey players. Soon afterwards, Chace put together a team of men from Yale, Brown, and Harvard, and toured across Canada as captain of this team. The first collegiate hockey match in the United States was played between Yale University and Johns Hopkins in Baltimore. Yale, led by captain Chace, beat Hopkins, 2–1. In 1896, the first ice hockey league in the US was formed. The US Amateur Hockey League was founded in New York City, shortly after the opening of the artificial-ice St. Nicholas Rink.\nLord Stanley's five sons were instrumental in bringing ice hockey to Europe, defeating a court team (which included the future Edward VII and George V) at Buckingham Palace in 1895. By 1903, a five-team league had been founded. The \"Ligue Internationale de Hockey sur Glace\" was founded in 1908 to govern international competition, and the first European championship was won by Great Britain in 1910. The sport grew further in Europe in the 1920s, after ice hockey became an Olympic sport. Many bandy players switched to hockey so as to be able to compete in the Olympics. Bandy remained popular in the Soviet Union, which only started its ice hockey program in the 1950s. In the mid-20th century, the \"Ligue\" became the International Ice Hockey Federation.\nAs the popularity of ice hockey as a spectator sport grew, earlier rinks were replaced by larger rinks. Most of the early indoor ice rinks have been demolished; Montreal's Victoria Rink, built in 1862, was demolished in 1925. Many older rinks succumbed to fire, such as Denman Arena, Dey's Arena, Quebec Skating Rink and Montreal Arena, a hazard of the buildings' wood construction. The Stannus Street Rink in Windsor, Nova Scotia (built in 1897) may be the oldest still in existence; however, it is no longer used for hockey. The Aberdeen Pavilion (built in 1898) in Ottawa was used for hockey in 1904 and is the oldest existing facility that has hosted Stanley Cup games.\n\nThe oldest indoor ice hockey arena still in use today for hockey is Boston's Matthews Arena, which was built in 1910. It has been modified extensively several times in its history and is used today by Northeastern University for hockey and other sports. It was the original home rink of the Boston Bruins professional team, itself the oldest United States-based team in the NHL, starting play in the league in today's Matthews Arena on December 1, 1924. Madison Square Garden in New York City, built in 1968, is the oldest continuously-operating arena in the NHL.\n\nProfessional hockey has existed since the early 20th century. By 1902, the Western Pennsylvania Hockey League was the first to employ professionals. The league joined with teams in Michigan and Ontario to form the first fully professional league—the International Professional Hockey League (IPHL)—in 1904. The WPHL and IPHL hired players from Canada; in response, Canadian leagues began to pay players (who played with amateurs). The IPHL, cut off from its largest source of players, disbanded in 1907. By then, several professional hockey leagues were operating in Canada (with leagues in Manitoba, Ontario and Quebec).\n\nIn 1910, the National Hockey Association (NHA) was formed in Montreal. The NHA would further refine the rules: dropping the rover position, dividing the game into three 20-minute periods and introducing minor and major penalties. After re-organizing as the National Hockey League in 1917, the league expanded into the United States, starting with the Boston Bruins in 1924.\n\nProfessional hockey leagues developed later in Europe, but amateur leagues leading to national championships were in place. One of the first was the Swiss National League A, founded in 1916. Today, professional leagues have been introduced in most countries of Europe. Top European leagues include the Kontinental Hockey League, the Czech Extraliga, the Finnish Liiga and the Swedish Hockey League.\n\nWhile the general characteristics of the game stay the same wherever it is played, the exact rules depend on the particular code of play being used. The two most important codes are those of the IIHF and the NHL. Both of the codes, and others, originated from Canadian rules of ice hockey of the early 20th Century.\n\nIce hockey is played on a \"hockey rink\". During normal play, there are six players per side on the ice at any time, one of them being the goaltender, each of whom is on ice skates. The objective of the game is to score \"goals\" by shooting a hard vulcanized rubber disc, the \"puck\", into the opponent's goal net, which is placed at the opposite end of the rink. The players use their sticks to pass or shoot the puck.\n\nWithin certain restrictions, players may redirect the puck with any part of their body. Players may not hold the puck in their hand and are prohibited from using their hands to pass the puck to their teammates, unless they are in the defensive zone. Players are also prohibited from kicking the puck into the opponent's goal, though unintentional redirections off the skate are permitted. Players may not intentionally bat the puck into the net with their hands.\n\nHockey is an \"off-side\" game, meaning that forward passes are allowed, unlike in rugby. Before the 1930s hockey was an on-side game, meaning that only backward passes were allowed. Those rules favoured individual stick-handling as a key means of driving the puck forward. With the arrival of offside rules, the forward pass transformed hockey into a truly team sport, where individual performance diminished in importance relative to team play, which could now be coordinated over the entire surface of the ice as opposed to merely rearward players.\n\nThe six players on each team are typically divided into three forwards, two defencemen, and a goaltender. The term \"skaters\" is typically used to describe all players who are not goaltenders. The \"forward\" positions consist of a \"centre\" and two \"wingers\": a \"left wing\" and a \"right wing\". Forwards often play together as units or \"lines\", with the same three forwards always playing together. The \"defencemen\" usually stay together as a pair generally divided between left and right. Left and right side wingers or defencemen are generally positioned as such, based on the side on which they carry their stick. A substitution of an entire unit at once is called a \"line change\". Teams typically employ alternate sets of forward lines and defensive pairings when \"short-handed\" or on a \"power play\". The goaltender stands in a, usually blue, semi-circle called the \"crease\" in the defensive zone keeping pucks from going in. Substitutions are permitted at any time during the game, although during a stoppage of play the home team is permitted the final change. When players are substituted during play, it is called changing \"on the fly\". A new NHL rule added in the 2005–06 season prevents a team from changing their line after they \"ice\" the puck.\n\nThe boards surrounding the ice help keep the puck in play and they can also be used as tools to play the puck. Players are permitted to \"bodycheck\" opponents into the boards as a means of stopping progress. The referees, linesmen and the outsides of the goal are \"in play\" and do not cause a stoppage of the game when the puck or players are influenced (by either bouncing or colliding) into them. Play can be stopped if the goal is knocked out of position. Play often proceeds for minutes without interruption. When play is stopped, it is restarted with a \"faceoff\". Two players \"face\" each other and an official drops the puck to the ice, where the two players attempt to gain control of the puck. Markings (circles) on the ice indicate the locations for the faceoff and guide the positioning of players.\n\nThe three major rules of play in ice hockey that limit the movement of the puck: \"offside\", \"icing\", and the puck going out of play. A player is \"offside\" if he enters his opponent's zone before the puck itself. Under many situations, a player may not \"ice the puck\", shoot the puck all the way across both the centre line and the opponent's goal line. The puck goes \"out of play\" whenever it goes past the perimeter of the ice rink (onto the player benches, over the \"glass,\" or onto the protective netting above the glass) and a stoppage of play is called by the officials using whistles. It also does not matter if the puck comes back onto the ice surface from those areas as the puck is considered dead once it leaves the perimeter of the rink.\n\nUnder IIHF rules, each team may carry a maximum of 20 players and two goaltenders on their roster. NHL rules restrict the total number of players per game to 18, plus two goaltenders. In the NHL, the players are usually divided into four lines of three forwards, and into three pairs of defencemen. On occasion, teams may elect to substitute an extra defenceman for a forward. The seventh defenceman may play as a substitute defenceman, spend the game on the bench, or if a team chooses to play four lines then this seventh defenceman may see ice-time on the fourth line as a forward.\n\nA professional game consists of three \"periods\" of twenty minutes, the clock running only when the puck is in play. The teams change ends after each period of play, including overtime. Recreational leagues and children's leagues often play shorter games, generally with three shorter periods of play.\n\nVarious procedures are used if a tie occurs. In tournament play, as well as in the NHL playoffs, North Americans favour \"sudden death overtime\", in which the teams continue to play twenty-minute periods until a goal is scored. Up until the 1999–2000 season regular season NHL games were settled with a single five-minute sudden death period with five players (plus a goalie) per side, with both teams awarded one point in the standings in the event of a tie. With a goal, the winning team would be awarded two points and the losing team none (just as if they had lost in regulation).\n\nFrom 1999–2000 until 2003–04, the National Hockey League decided ties by playing a single five-minute sudden death overtime period with each team having four skaters per side (plus the goalie) to \"open up\" the game. In the event of a tie, each team would still receive one point in the standings but in the event of a victory the winning team would be awarded two points in the standings and the losing team one point. The idea was to discourage teams from playing for a tie, since previously some teams might have preferred a tie and 1 point to risking a loss and zero points. The only exception to this rule is if a team opts to pull their goalie in exchange for an extra skater during overtime and is subsequently scored upon (an \"empty net\" goal), in which case the losing team receives no points for the overtime loss. Since the 2015–16 season, the single five-minute sudden death overtime session involves three skaters on each side. Since three skaters must always be on the ice in an NHL game, the consequences of penalties are slightly different from those during regulation play. If a team is on a powerplay when overtime begins, that team will play with more than three skaters (usually four, very rarely five) until the expiration of the penalty. Any penalty during overtime that would result in a team losing a skater during regulation instead causes the non-penalized team to add a skater. Once the penalized team's penalty ends, the number of skaters on each side is adjusted accordingly, with the penalized team adding a skater in regulation and the non-penalized team subtracting a skater in overtime. This goes until the next stoppage of play.\n\nInternational play and several North American professional leagues, including the NHL (in the regular season), now use an overtime period identical to that from 99–00 – 03–04 followed by a penalty shootout. If the score remains tied after an extra overtime period, the subsequent shootout consists of three players from each team taking penalty shots. After these six total shots, the team with the most goals is awarded the victory. If the score is still tied, the shootout then proceeds to a \"sudden death\" format. Regardless of the number of goals scored during the shootout by either team, the final score recorded will award the winning team one more goal than the score at the end of regulation time. In the NHL if a game is decided in overtime or by a shootout the winning team is awarded two points in the standings and the losing team is awarded one point. Ties no longer occur in the NHL.\n\nThe overtime mode for the NHL playoffs differ from the regular season. In the playoffs there are no shootouts nor ties. If a game is tied after regulation an additional 20 minutes of 5 on 5 sudden death overtime will be added. In case of a tied game after the overtime, multiple 20-minute overtimes will be played until a team scores, which wins the match.\n\nIn ice hockey, infractions of the rules lead to play stoppages whereby the play is restarted at a face off. Some infractions result in the imposition of a \"penalty\" to a player or team. In the simplest case, the offending player is sent to the \"penalty box\" and their team has to play with one less player on the ice for a designated amount of time. \"Minor\" penalties last for two minutes, \"major\" penalties last for five minutes, and a \"double minor\" penalty is two \"consecutive\" penalties of two minutes duration. A single minor penalty may be extended by a further two minutes for causing visible injury to the victimized player. This is usually when blood is drawn during high sticking. Players may be also assessed personal extended penalties or game expulsions for misconduct in addition to the penalty or penalties their team must serve. The team that has been given a penalty is said to be playing \"short-handed\" while the opposing team is on a \"power play\".\n\nA two-minute minor penalty is often charged for lesser infractions such as \"tripping\", \"elbowing\", \"roughing\", \"high-sticking\", \"delay of the game\", \"too many players on the ice\", \"boarding\", illegal equipment, \"charging\" (leaping into an opponent or body-checking him after taking more than two strides), \"holding\", holding the stick (grabbing an opponent's stick), \"interference\", \"hooking\", \"slashing\", \"kneeing\", \"unsportsmanlike conduct\" (arguing a penalty call with referee, extremely vulgar or inappropriate verbal comments), \"butt-ending\" (striking an opponent with the knob of the stick—a very rare penalty), \"spearing\", or \"cross-checking\". As of the 2005–2006 season, a minor penalty is also assessed for \"diving\", where a player embellishes or simulates an offence. More egregious fouls may be penalized by a four-minute double-minor penalty, particularly those that injure the victimized player. These penalties end either when the time runs out or when the other team scores during the power play. In the case of a goal scored during the first two minutes of a double-minor, the penalty clock is set down to two minutes upon a score, effectively expiring the first minor penalty. Five-minute major penalties are called for especially violent instances of most minor infractions that result in intentional injury to an opponent, or when a \"minor\" penalty results in visible injury (such as bleeding), as well as for fighting. Major penalties are always served in full; they do not terminate on a goal scored by the other team. Major penalties assessed for fighting are typically offsetting, meaning neither team is short-handed and the players exit the penalty box upon a stoppage of play following the expiration of their respective penalties. The foul of \"boarding\" (defined as \"check[ing] an opponent in such a manner that causes the opponent to be thrown violently in the boards\") is penalized either by a minor or major penalty at the discretion of the referee, based on the violent state of the hit. A minor or major penalty for boarding is often assessed when a player checks an opponent from behind and into the boards.\n\nSome varieties of penalties do not always require the offending team to play a man short. Concurrent five-minute major penalties in the NHL usually result from fighting. In the case of two players being assessed five-minute fighting majors, both the players serve five minutes without their team incurring a loss of player (both teams still have a full complement of players on the ice). This differs with two players from opposing sides getting minor penalties, at the same time or at any intersecting moment, resulting from more common infractions. In this case, both teams will have only four skating players (not counting the goaltender) until one or both penalties expire (if one penalty expires before the other, the opposing team gets a power play for the remainder of the time); this applies regardless of current pending penalties. However, in the NHL, a team always has at least three skaters on the ice. Thus, ten-minute \"misconduct\" penalties are served in full by the penalized player, but his team may immediately substitute another player on the ice \"unless\" a minor or major penalty is assessed in conjunction with the misconduct (a \"two-and-ten\" or \"five-and-ten\"). In this case, the team designates another player to serve the minor or major; both players go to the penalty box, but only the designee may not be replaced, and he is released upon the expiration of the two or five minutes, at which point the ten-minute misconduct begins. In addition, \"game misconducts\" are assessed for deliberate intent to inflict severe injury on an opponent (at the officials' discretion), or for a major penalty for a stick infraction or repeated major penalties. The offending player is ejected from the game and must immediately leave the playing surface (he does not sit in the penalty box); meanwhile, if an additional minor or major penalty is assessed, a designated player must serve out of that segment of the penalty in the box (similar to the above-mentioned \"two-and-ten\"). In some rare cases, a player may receive up to nineteen minutes in penalties for one string of plays. This could involve receiving a four-minute double minor penalty, getting in a fight with an opposing player who retaliates, and then receiving a game misconduct after the fight. In this case, the player is ejected and two teammates must serve the double-minor and major penalties.\n\nA \"penalty shot\" is awarded to a player when the illegal actions of another player stop a clear scoring opportunity, most commonly when the player is on a \"breakaway\". A penalty shot allows the obstructed player to pick up the puck on the centre red-line and attempt to score on the goalie with no other players on the ice, to compensate for the earlier missed scoring opportunity. A penalty shot is also awarded for a defender other than the goaltender covering the puck in the goal crease, a goaltender intentionally displacing his own goal posts during a breakaway to avoid a goal, a defender intentionally displacing his own goal posts when there is less than two minutes to play in regulation time or at any point during overtime, or a player or coach intentionally throwing a stick or other object at the puck or the puck carrier and the throwing action disrupts a shot or pass play.\nOfficials also stop play for puck movement violations, such as using one's hands to pass the puck in the offensive end, but no players are penalized for these offences. The sole exceptions are deliberately falling on or gathering the puck to the body, carrying the puck in the hand, and shooting the puck out of play in one's defensive zone (all penalized two minutes for delay of game).\n\nIn the NHL, a unique penalty applies to the goalies. The goalies now are forbidden to play the puck in the \"corners\" of the rink near their own net. This will result in a two-minute penalty against the goalie's team. Only in the area in-front of the goal line and immediately behind the net (marked by two red lines on either side of the net) the goalie can play the puck.\n\nAn additional rule that has never been a penalty, but was an infraction in the NHL before recent rules changes, is the \"two-line offside pass\". Prior to the 2005–06 NHL season, play was stopped when a pass from inside a team's defending zone crossed the centre line, with a face-off held in the defending zone of the offending team. Now, the centre line is no longer used in the NHL to determine a two-line pass infraction, a change that the IIHF had adopted in 1998. Players are now able to pass to teammates who are more than the blue and centre ice red line away.\n\nThe NHL has taken steps to speed up the game of hockey and create a game of finesse, by retreating from the past when illegal hits, fights, and \"clutching and grabbing\" among players were commonplace. Rules are now more strictly enforced, resulting in more penalties, which in turn provides more protection to the players and facilitates more goals being scored. The governing body for United States' amateur hockey has implemented many new rules to reduce the number of stick-on-body occurrences, as well as other detrimental and illegal facets of the game (\"zero tolerance\").\n\nIn men's hockey, but not in women's, a player may use his hip or shoulder to hit another player if the player has the puck or is the last to have touched it. This use of the hip and shoulder is called \"body checking\". Not all physical contact is legal—in particular, hits from behind, hits to the head and most types of forceful stick-on-body contact are illegal.\n\nA \"delayed penalty call\" occurs when a penalty offence is committed by the team that does not have possession of the puck. In this circumstance the team with possession of the puck is allowed to complete the play; that is, play continues until a goal is scored, a player on the opposing team gains control of the puck, or the team in possession commits an infraction or penalty of their own. Because the team on which the penalty was called cannot control the puck without stopping play, it is impossible for them to score a goal. In these cases, the team in possession of the puck can pull the goalie for an extra attacker without fear of being scored on. However, it is possible for the controlling team to mishandle the puck into their own net. If a delayed penalty is signalled and the team in possession scores, the penalty is still assessed to the offending player, but not served. In 2012, this rule was changed by the United States' National Collegiate Athletic Association (NCAA) for college level hockey. In college games, the penalty is still enforced even if the team in possession scores.\n\nA typical game of hockey is governed by two to four \"officials\" on the ice, charged with enforcing the rules of the game. There are typically two \"linesmen\" who are mainly responsible for calling \"offside\" and \"icing\" violations, breaking up fights, and conducting faceoffs, and one or two \"referees\", who call goals and all other penalties. Linesmen can, however, report to the referee(s) that a penalty should be assessed against an offending player in some situations. The restrictions on this practice vary depending on the governing rules. On-ice officials are assisted by off-ice officials who act as goal judges, time keepers, and official scorers.\n\nThe most widespread system in use today is the \"three-man system,\" that uses one referee and two linesmen. Another less commonly used system is the two referee and one linesman system. This system is very close to the regular three-man system except for a few procedure changes. With the first being the National Hockey League, a number of leagues have started to implement the \"four-official system,\" where an additional referee is added to aid in the calling of penalties normally difficult to assess by one single referee. The system is now used in every NHL game, at IIHF World Championships, the Olympics and in many professional and high-level amateur leagues in North America and Europe.\n\nOfficials are selected by the league they work for. Amateur hockey leagues use guidelines established by national organizing bodies as a basis for choosing their officiating staffs. In North America, the national organizing bodies Hockey Canada and USA Hockey approve officials according to their experience level as well as their ability to pass rules knowledge and skating ability tests. Hockey Canada has officiating levels I through VI. USA Hockey has officiating levels 1 through 4.\n\nSince men's ice hockey is a full contact sport, body checks are allowed so injuries are a common occurrence. Protective equipment is mandatory and is enforced in all competitive situations. This includes a helmet (cage worn if certain age or clear plastic visor can be worn), shoulder pads, elbow pads, mouth guard, protective gloves, heavily padded shorts (also known as hockey pants) or a girdle, athletic cup (also known as a jock, for males; and jill, for females), shin pads, skates, and (optionally) a neck protector.\nGoaltenders use different equipment. With hockey pucks approaching them at speeds of up to 100 mph (160 km/h) they must wear equipment with more protection. Goaltenders wear specialized goalie skates (these skates are built more for movement side to side rather than forwards and backwards), a jock or jill, large leg pads (there are size restrictions in certain leagues), blocking glove, catching glove, a chest protector, a goalie mask, and a large jersey. Goaltenders' equipment has continually become larger and larger, leading to fewer goals in each game and many official rule changes.\nHockey skates are optimized for physical acceleration, speed and manoeuvrability. This includes rapid starts, stops, turns, and changes in skating direction. In addition, they must be rigid and tough to protect the skater's feet from contact with other skaters, sticks, pucks, the boards, and the ice itself. Rigidity also improves the overall manoeuvrability of the skate. Blade length, thickness (width), and curvature (rocker/radius (front to back) and radius of hollow (across the blade width) are quite different from speed or figure skates. Hockey players usually adjust these parameters based on their skill level, position, and body type. The blade width of most skates are about thick.\nThe hockey stick consists of a long, relatively wide, and slightly curved flat blade, attached to a shaft. The curve itself has a big impact on its performance. A deep curve allows for lifting the puck easier while a shallow curve allows for easier backhand shots. The flex of the stick also impacts the performance. Typically, a less flexible stick is meant for a stronger player since the player is looking for the right balanced flex that allows the stick to flex easily while still having a strong \"whip-back\" which sends the puck flying at high speeds. It is quite distinct from sticks in other sports games and most suited to hitting and controlling the flat puck. Its unique shape contributed to the early development of the game.\nIce hockey is a full contact sport and carries a high risk of injury. Players are moving at speeds around approximately and quite a bit of the game revolves around the physical contact between the players. Skate blades, hockey sticks, shoulder contact, hip contact, and hockey pucks can all potentially cause injuries. The types of injuries associated with hockey include: lacerations, concussions, contusions, ligament tears, broken bones, hyperextensions, and muscle strains. Women's ice hockey players are allowed to contact other players but are not allowed to body check.\n\nCompared to athletes who play other sports, ice hockey players are at higher risk of overuse injuries and injuries caused by early sports specialization by teenagers.\n\nAccording to the Hughston Health Alert, \"Lacerations to the head, scalp, and face are the most frequent types of injury [in hockey].\" Even a shallow cut to the head results in a loss of a large amount of blood. Direct trauma to the head is estimated to account for 80% of all hockey injuries as a result of player contact with other players or hockey equipment.\n\nOne of the leading causes of head injury is body checking from behind. Due to the danger of delivering a check from behind, many leagues, including the NHL have made this a major and game misconduct penalty (called \"boarding\"). Another type of check that accounts for many of the player-to-player contact concussions is a check to the head resulting in a misconduct penalty (called \"head contact\"). A check to the head can be defined as delivering a hit while the receiving player's head is down and their waist is bent and the aggressor is targeting the opponent player's head.\n\nThe most dangerous result of a head injury in hockey can be classified as a concussion. Most concussions occur during player-to-player contact rather than when a player is checked into the boards. Checks to the head have accounted for nearly 50% of concussions that players in the National Hockey League have suffered. Concussions that players suffer may go unreported because there is no obvious physical signs if a player is not knocked unconscious. This can prove to be dangerous if a player decides to return to play without receiving proper medical attention. Studies show that ice hockey causes 44.3% of all traumatic brain injuries among Canadian children. In severe cases, the traumatic brain injuries are capable of resulting in death. Occurrences of death from these injuries are rare.\n\nAn important defensive tactic is checking—attempting to take the puck from an opponent or to remove the opponent from play. \"Stick checking\", \"sweep checking\", and \"poke checking\" are legal uses of the stick to obtain possession of the puck. The \"neutral zone trap\" is designed to isolate the puck carrier in the neutral zone preventing him from entering the offensive zone. \"Body checking\" is using one's shoulder or hip to strike an opponent who has the puck or who is the last to have touched it (the last person to have touched the puck is still legally \"in possession\" of it, although a penalty is generally called if he is checked more than two seconds after his last touch). Often the term checking is used to refer to body checking, with its true definition generally only propagated among fans of the game.\n\nOffensive tactics include improving a team's position on the ice by advancing the puck out of one's zone towards the opponent's zone, progressively by gaining lines, first your own blue line, then the red line and finally the opponent's blue line. NHL rules instated for the 2006 season redefined the offside rule to make the two-line pass legal; a player may pass the puck from behind his own blue line, past both that blue line and the centre red line, to a player on the near side of the opponents' blue line. Offensive tactics are designed ultimately to score a goal by taking a shot. When a player purposely directs the puck towards the opponent's goal, he or she is said to \"shoot\" the puck.\n\nA \"deflection\" is a shot that redirects a shot or a pass towards the goal from another player, by allowing the puck to strike the stick and carom towards the goal. A \"one-timer\" is a shot struck directly off a pass, without receiving the pass and shooting in two separate actions. \"Headmanning the puck\", also known as \"breaking out\", is the tactic of rapidly passing to the player farthest down the ice. \"Loafing\", also known as \"cherry-picking\", is when a player, usually a forward, skates behind an attacking team, instead of playing defence, in an attempt to create an easy scoring chance.\n\nA team that is losing by one or two goals in the last few minutes of play will often elect to \"pull the goalie\"; that is, remove the goaltender and replace him or her with an \"extra attacker\" on the ice in the hope of gaining enough advantage to score a goal. However, it is an act of desperation, as it sometimes leads to the opposing team extending their lead by scoring a goal in the empty net.\n\nOne of the most important strategies for a team is their \"forecheck\". Forechecking is the act of attacking the opposition in their defensive zone. Forechecking is an important part of the \"dump and chase\" strategy (i.e. shooting the puck into the offensive zone and then chasing after it). Each team will use their own unique system but the main ones are: 2–1–2, 1–2–2, and 1–4. The 2–1–2 is the most basic forecheck system where two forwards will go in deep and pressure the opposition's defencemen, the third forward stays high and the two defencemen stay at the blueline. The 1–2–2 is a bit more conservative system where one forward pressures the puck carrier and the other two forwards cover the oppositions' wingers, with the two defencemen staying at the blueline. The 1–4 is the most defensive forecheck system, referred to as the neutral zone trap, where one forward will apply pressure to the puck carrier around the oppositions' blueline and the other 4 players stand basically in a line by their blueline in hopes the opposition will skate into one of them. Another strategy is the left wing lock, which has two forwards pressure the puck and the left wing and the two defencemen stay at the blueline.\n\nThere are many other little tactics used in the game of hockey. \"Cycling\" moves the puck along the boards in the offensive zone to create a scoring chance by making defenders tired or moving them out of position. \"Pinching\" is when a defenceman pressures the opposition's winger in the offensive zone when they are breaking out, attempting to stop their attack and keep the puck in the offensive zone. A \"saucer pass\" is a pass used when an opposition's stick or body is in the passing lane. It is the act of raising the puck over the obstruction and having it land on a teammate's stick.\n\nA deke, short for \"decoy,\" is a feint with the body or stick to fool a defender or the goalie. Many modern players, such as Pavel Datsyuk, Sidney Crosby and Patrick Kane, have picked up the skill of \"dangling,\" which is fancier deking and requires more stick handling skills.\n\nAlthough fighting is officially prohibited in the rules, it is not an uncommon occurrence at the professional level, and its prevalence has been both a target of criticism and a considerable draw for the sport. At the professional level in North America fights are unofficially condoned. Enforcers and other players fight to demoralize the opposing players while exciting their own, as well as settling personal scores. A fight will also break out if one of the team's skilled players gets hit hard or someone gets hit by what the team perceives as a dirty hit. The amateur game penalizes fisticuffs more harshly, as a player who receives a fighting major is also assessed at least a 10-minute misconduct penalty (NCAA and some Junior leagues) or a game misconduct penalty and suspension (high school and younger, as well as some casual adult leagues). Crowds seem to like fighting in ice hockey and cheer when fighting erupts.\n\nIce hockey is one of the fastest growing women's sports in the world, with the number of participants increasing by 400 percent from 1995 to 2005. In 2011, Canada had 85,827 women players, United States had 65,609, Finland 4,760, Sweden 3,075 and Switzerland 1,172. While there are not as many organized leagues for women as there are for men, there exist leagues of all levels, including the Canadian Women's Hockey League (CWHL), Western Women's Hockey League, National Women's Hockey League (NWHL), Mid-Atlantic Women's Hockey League, and various European leagues; as well as university teams, national and Olympic teams, and recreational teams. The IIHF holds IIHF World Women's Championships tournaments in several divisions; championships are held annually, except that the top flight does not play in Olympic years.\nThe chief difference between women's and men's ice hockey is that body checking is prohibited in women's hockey. After the 1990 Women's World Championship, body checking was eliminated in women's hockey. In current IIHF women's competition, body checking is either a minor or major penalty, decided at the referee's discretion. In addition, players in women's competition are required to wear protective full-face masks.\n\nIn Canada, to some extent ringette has served as the female counterpart to ice hockey, in the sense that traditionally, boys have played hockey while girls have played ringette.\n\nWomen are known to have played the game in the 19th century. Several games were recorded in the 1890s in Ottawa, Ontario, Canada. The women of Lord Stanley's family were known to participate in the game of ice hockey on the outdoor ice rink at Rideau Hall, the residence of Canada's Governor-General.\n\nThe game developed at first without an organizing body. A tournament in 1902 between Montreal and Trois-Rivieres was billed as the first championship tournament. Several tournaments, such as at the Banff Winter Carnival, were held in the early 20th century and numerous women's teams such as the Seattle Vamps and Vancouver Amazons existed. Organizations started to develop in the 1920s, such as the Ladies Ontario Hockey Association, and later, the Dominion Women's Amateur Hockey Association. Starting in the 1960s, the game spread to universities. Today, the sport is played from youth through adult leagues, and in the universities of North America and internationally. There are two major professional women's hockey leagues, the National Women's Hockey League with teams in the United States and the Canadian Women's Hockey League with teams in Canada, the United States, and China.\n\nThe first women's world championship tournament, albeit unofficial, was held in 1987 in Toronto, Ontario, Canada. This was followed by the first IIHF World Championship in 1990 in Ottawa. Women's ice hockey was added as a medal sport at the 1998 Winter Olympics in Nagano, Japan. The United States won the gold, Canada won the silver and Finland won the bronze medal. The United States won the gold medal again in 2018 at the 2018 Winter Olympics in Pyeongchang, South Korea.\n\nThe United States Hockey League (USHL) welcomed the first female professional ice hockey player in 1969–70, when the Marquette Iron Rangers signed Karen Koch. One woman, Manon Rhéaume, has played in an NHL pre-season game as a goaltender for the Tampa Bay Lightning against the St. Louis Blues. In 2003, Hayley Wickenheiser played with the Kirkkonummi Salamat in the Finnish men's Suomi-sarja league. Several women have competed in North American minor leagues, including Rhéaume, goaltenders Kelly Dyer and Erin Whitten and defenceman Angela Ruggiero.\n\nWith interest in women's ice hockey growing, between 2007 and 2010 the number of registered female players worldwide grew from 153,665 to 170,872. Women's hockey is on the rise in almost every part of the world and there are teams in North America, Europe, Asia, Oceania, Africa and Latin America.\n\nThere are currently two North American based professional women's hockey leagues, the Canadian Women's Hockey League (CWHL) and the National Women's Hockey League (NWHL). The CWHL is based in Canada while the NWHL is based in the United States.\n\nThe CWHL was founded in 2007 and originally consisted of seven teams, but has had several membership changes. The league began paying its players a salary in the 2017–18 season. As of 2018, there are six teams consisting of the Calgary Inferno, Les Canadiennes de Montreal, Markham Thunder, Shenzhen KRS Vanke Rays, Toronto Furies, and the Worcester Blades. While the CWHL is based in Canada, it does have two teams that play outside Canada. The Worcester Blades are based in the United States and Shenzhen KRS Vanke Rays are based in China.\n\nThe NWHL was founded in 2015 and was the first North American women's league to pay its players. The league consists of five teams, though it had four teams for the league's first three seasons. The five teams in the league are the Boston Pride, Buffalo Beauts, Connecticut Whale, Metropolitan Riveters, and Minnesota Whitecaps.\n\nThe NHL is by far the best attended and most popular ice hockey league in the world. The league's history began after Canada's National Hockey Association decided to disband in 1917; the result was the creation of the National Hockey League. The league expanded to the United States beginning in 1924. In 1967, the NHL doubled in size to 12 teams, undertaking one of the greatest expansions in professional sports history. A few years later, in 1972, a new 12 team league, the World Hockey Association (WHA) was formed and due to its ensuing rivalry with the NHL, it caused an escalation in players salaries. As of 1979, the NHL had grown to 17 teams and merged with the WHA. This created a 21 team league. By 2017, the NHL had expanded to 31 teams, and after a realignment in 2013, these teams were divided into two conferences and four divisions.\n\nThe American Hockey League (AHL), sometimes referred to as \"The A,\" is the primary developmental professional league for players aspiring to enter the NHL. It comprises 31 teams from the United States and Canada. It is run as a \"farm league\" to the NHL, with the vast majority of AHL players under contract to an NHL team. The ECHL (called the East Coast Hockey League before the 2003–04 season) is a mid-level minor league in the United States with a few players under contract to NHL or AHL teams.\n\nAs of 2018, there are three minor professional leagues with no NHL affiliations: the Federal Hockey League (FHL), Ligue Nord-Américaine de Hockey (LNAH), and the Southern Professional Hockey League (SPHL).\n\nIn the United States especially, college hockey is popular and the best university teams compete in the annual NCAA Men's Ice Hockey Championship. The American Collegiate Hockey Association is composed of college teams at the club level.\n\nIn Canada, the Canadian Hockey League is an umbrella organization comprising three major junior leagues: the Ontario Hockey League, the Western Hockey League, and the Quebec Major Junior Hockey League. It attracts players from Canada, the United States and Europe. The major junior players are considered amateurs as they are under 21-years-old and not paid a salary, however, they do get a stipend and play a schedule similar to a professional league. Typically, the NHL drafts many players directly from the major junior leagues.\n\nIn the United States, the United States Hockey League (USHL) is the highest junior league. Players in this league are also amateur with players required to be under 21-years old, but do not get a stipend, which allows players to retain their eligibility for participation in NCAA ice hockey.\n\nThe Kontinental Hockey League (KHL) is the largest and most popular ice hockey league in Eurasia. The league is the direct successor to the Russian Super League, which in turn was the successor to the Soviet League, the history of which dates back to the Soviet adoption of ice hockey in the 1940s. The KHL was launched in 2008 with clubs predominantly from Russia, but featuring teams from other post-Soviet states. The league expanded beyond the former Soviet countries beginning in the 2011–12 season, with clubs in Croatia and Slovakia. The number of teams has since increased to 28 from eight different countries.\n\nThe second division of hockey in Eurasia is the Supreme Hockey League (VHL). This league features 24 teams from Russia and 2 from Kazakhstan. This league is currently being converted to a farm league for the KHL, similarly to the AHL's function in relation to the NHL. The third division is the Russian Hockey League, which features only teams from Russia. The Asia League, an international ice hockey league featuring clubs from China, Japan, South Korea, and the Russian Far East, is the successor to the Japan Ice Hockey League.\n\nThe highest junior league in Eurasia is the Junior Hockey League (MHL). It features 32 teams from post-Soviet states, predominantly Russia. The second tier to this league is the Junior Hockey League Championships (MHL-B).\n\nSeveral countries in Europe have their own top professional senior leagues. Many future KHL and NHL players start or end their professional careers in these leagues. The National League A in Switzerland, Swedish Hockey League in Sweden, Liiga in Finland, and Czech Extraliga in the Czech Republic are all very popular in their respective countries.\n\nBeginning in the 2014–15 season, the Champions Hockey League was launched, a league consisting of first-tier teams from several European countries, running parallel to the teams' domestic leagues. The competition is meant to serve as a Europe-wide ice hockey club championship. The competition is a direct successor to the European Trophy and is related to the 2008–09 tournament of the same name.\n\nThere are also several annual tournaments for clubs, held outside of league play. Pre-season tournaments include the European Trophy, Tampere Cup and the Pajulahti Cup. One of the oldest international ice hockey competition for clubs is the Spengler Cup, held every year in Davos, Switzerland, between Christmas and New Year's Day. It was first awarded in 1923 to the Oxford University Ice Hockey Club. The Memorial Cup, a competition for junior-level (age 20 and under) clubs is held annually from a pool of junior championship teams in Canada and the United States.\n\nInternational club competitions organized by the IIHF include the Continental Cup, the Victoria Cup and the European Women's Champions Cup. The World Junior Club Cup is an annual tournament of junior ice hockey clubs representing each of the top junior leagues.\n\nIce hockey has been played at the Winter Olympics since 1924 (and was played at the summer games in 1920). Hockey is Canada's national winter sport, and Canadians are extremely passionate about the game. The nation has traditionally done very well at the Olympic games, winning 6 of the first 7 gold medals. However, by 1956 its amateur club teams and national teams could not compete with the teams of government-supported players from the Soviet Union. The USSR won all but two gold medals from 1956 to 1988. The United States won their first gold medal in 1960. On the way to winning the gold medal at the 1980 Lake Placid Olympics amateur US college players defeated the heavily favoured Soviet squad—an event known as the \"Miracle on Ice\" in the United States. Restrictions on professional players were fully dropped at the 1988 games in Calgary. NHL agreed to participate ten years later. 1998 Games saw the full participation of players from the NHL, which suspended operations during the Games and has done so in subsequent Games. The 2010 games in Vancouver were the first played in an NHL city since the inclusion of NHL players. The 2010 games were the first played on NHL-sized ice rinks, which are narrower than the IIHF standard.\nNational teams representing the member federations of the IIHF compete annually in the IIHF Ice Hockey World Championships. Teams are selected from the available players by the individual federations, without restriction on amateur or professional status. Since it is held in the spring, the tournament coincides with the annual NHL Stanley Cup playoffs and many of the top players are hence not available to participate in the tournament. Many of the NHL players who do play in the IIHF tournament come from teams eliminated before the playoffs or in the first round, and federations often hold open spots until the tournament to allow for players to join the tournament after their club team is eliminated. For many years, the tournament was an amateur-only tournament, but this restriction was removed, beginning in 1977.\n\nThe 1972 Summit Series and 1974 Summit Series, two series pitting the best Canadian and Soviet players without IIHF restrictions were major successes, and established a rivalry between Canada and the USSR. In the spirit of best-versus-best without restrictions on amateur or professional status, the series were followed by five Canada Cup tournaments, played in North America. Two NHL versus USSR series were also held: the 1979 Challenge Cup and Rendez-vous '87. The Canada Cup tournament later became the World Cup of Hockey, played in 1996, 2004 and 2016. The United States won in 1996 and Canada won in 2004 and 2016.\n\nSince the initial women's world championships in 1990, there have been fifteen tournaments. Women's hockey has been played at the Olympics since 1998. The 2006 Winter Olympic final between Canada and Sweden marked the only time the women's world championship or Olympic final did not involve both Canada and the United States.\n\nOther ice hockey tournaments featuring national teams include the World U20 Championship, the World U18 Championships, the World U-17 Hockey Challenge, the World Junior A Challenge, the Ivan Hlinka Memorial Tournament, the World Women's U18 Championships and the 4 Nations Cup. The annual Euro Hockey Tour, an unofficial European championship between the national men's teams of the Czech Republic, Finland, Russia and Sweden have been played since 1996–97.\n\nThe Australian Ice Hockey League and New Zealand Ice Hockey League are represented by nine and five teams respectively. As of 2012, the two top teams of the previous season from each league compete in the Trans-Tasman Champions League.\n\nIce hockey in Africa is a small but growing sport; while no African ice hockey playing nation has a domestic league, there are several regional leagues in South Africa.\n\nPond hockey is a form of ice hockey played generally as pick-up hockey on lakes, ponds and artificial outdoor rinks during the winter. Pond hockey is commonly referred to in hockey circles as shinny. Its rules differ from traditional hockey because there is no hitting and very little shooting, placing a greater emphasis on skating, puckhandling and passing abilities. Since 2002, the World Pond Hockey Championship has been played on Roulston Lake in Plaster Rock, New Brunswick, Canada. Since 2006, the US Pond Hockey Championships have been played in Minneapolis, Minnesota, and the Canadian National Pond Hockey Championships have been played in Huntsville, Ontario.\n\nIce hockey is the official winter sport of Canada. Ice hockey, partially because of its popularity as a major professional sport, has been a source of inspiration for numerous films, television episodes and songs in North American popular culture.\n\nThe record for a Stanley Cup playoff game is 28,183, set on April 23, 1996, at the Thunderdome during a Tampa Bay Lightning – Philadelphia Flyers game.\n\nA record was set on December 11, 2010, when the University of Michigan's men's ice hockey team faced cross-state rival Michigan State in an event billed as \"The Big Chill at the Big House\". The game was played at Michigan's (American) football venue, Michigan Stadium in Ann Arbor, with a capacity of 109,901 as of the 2010 football season. When UM stopped sales to the public on May 6, 2010, with plans to reserve remaining tickets for students, over 100,000 tickets had been sold for the event. Ultimately, a crowd announced by UM as 113,411, the largest in the stadium's history (including football), saw the homestanding Wolverines win 5–0. \"Guinness World Records\", using a count of ticketed fans who actually entered the stadium instead of UM's figure of tickets sold, announced a final figure of 104,173.\n\nThe record was approached but not broken at the 2014 NHL Winter Classic, which also held at Michigan Stadium, with the Detroit Red Wings as the home team and the Toronto Maple Leafs as the opposing team with an announced crowd of 105,491.\n\nNumber of registered hockey players, including male, female and junior, provided by the respective countries' federations. Note that this list only includes the 42 of 76 IIHF member countries with more than 1,000 registered players as of October 2018.\n\n\n\n"}
{"id": "14791", "url": "https://en.wikipedia.org/wiki?curid=14791", "title": "IEEE 802.3", "text": "IEEE 802.3\n\nIEEE 802.3 is a working group and a collection of Institute of Electrical and Electronics Engineers (IEEE) standards produced by the working group defining the physical layer and data link layer's media access control (MAC) of wired Ethernet. This is generally a local area network (LAN) technology with some wide area network (WAN) applications. Physical connections are made between nodes and/or infrastructure devices (hubs, switches, routers) by various types of copper or fiber cable.\n\n802.3 is a technology that supports the IEEE 802.1 network architecture.\n\n802.3 also defines LAN access method using CSMA/CD.\n\n\n"}
{"id": "14794", "url": "https://en.wikipedia.org/wiki?curid=14794", "title": "Integer (computer science)", "text": "Integer (computer science)\n\nIn computer science, an integer is a datum of integral data type, a data type that represents some range of mathematical integers. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits (bits). The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware, including virtual machines, nearly always provide a way to represent a processor register or memory address as an integer.\n\nThe \"value\" of an item with an integral type is the mathematical integer that it corresponds to. Integral types may be \"unsigned\" (capable of representing only non-negative integers) or \"signed\" (capable of representing negative integers as well).\n\nAn integer value is typically specified in the source code of a program as a sequence of digits optionally prefixed with + or −. Some programming languages allow other notations, such as hexadecimal (base 16) or octal (base 8). Some programming languages also permit digit group separators.\n\nThe \"internal representation\" of this datum is the way the value is stored in the computer's memory. Unlike mathematical integers, a typical datum in a computer has some minimal and maximum possible value.\n\nThe most common representation of a positive integer is a string of bits, using the binary numeral system. The order of the memory bytes storing the bits varies; see endianness. The \"width\" or \"precision\" of an integral type is the number of bits in its representation. An integral type with \"n\" bits can encode 2 numbers; for example an unsigned type typically represents the non-negative values 0 through 2−1. Other encodings of integer values to bit patterns are sometimes used, for example binary-coded decimal or Gray code, or as printed character codes such as ASCII.\n\nThere are four well-known ways to represent signed numbers in a binary computing system. The most common is two's complement, which allows a signed integral type with \"n\" bits to represent numbers from −2 through 2−1. Two's complement arithmetic is convenient because there is a perfect one-to-one correspondence between representations and values (in particular, no separate +0 and −0), and because addition, subtraction and multiplication do not need to distinguish between signed and unsigned types. Other possibilities include offset binary, sign-magnitude, and ones' complement.\n\nSome computer languages define integer sizes in a machine-independent way; others have varying definitions depending on the underlying processor word size. Not all language implementations define variables of all integer sizes, and defined sizes may not even be distinct in a particular implementation. An integer in one programming language may be a different size in a different language or on a different processor.\n\nDifferent CPUs support different integral data types. Typically, hardware will support both signed and unsigned types, but only a small, fixed set of widths.\n\nThe table above lists integral type widths that are supported in hardware by common processors. High level programming languages provide more possibilities. It is common to have a 'double width' integral type that has twice as many bits as the biggest hardware-supported type. Many languages also have \"bit-field\" types (a specified number of bits, usually constrained to be less than the maximum hardware-supported width) and \"range\" types (that can represent only the integers in a specified range).\n\nSome languages, such as Lisp, Smalltalk, REXX, Haskell, Python, and Perl 6 support \"arbitrary precision\" integers (also known as \"infinite precision integers\" or \"bignums\"). Other languages that do not support this concept as a top-level construct may have libraries available to represent very large numbers using arrays of smaller variables, such as Java's BigInteger class or Perl 5's \"bigint\" package. These use as much of the computer's memory as is necessary to store the numbers; however, a computer has only a finite amount of storage, so they too can only represent a finite subset of the mathematical integers. These schemes support very large numbers, for example one kilobyte of memory could be used to store numbers up to 2466 decimal digits long.\n\nA Boolean or Flag type is a type that can represent only two values: 0 and 1, usually identified with \"false\" and \"true\" respectively. This type can be stored in memory using a single bit, but is often given a full byte for convenience of addressing and speed of access.\n\nA four-bit quantity is known as a \"nibble\" (when eating, being smaller than a \"bite\") or \"nybble\" (being a pun on the form of the word \"byte\"). One nibble corresponds to one digit in hexadecimal and holds one digit or a sign code in binary-coded decimal.\n\nThe term \"byte\" initially meant 'the smallest addressable unit of memory'. In the past, 5-, 6-, 7-, 8-, and 9-bit bytes have all been used. There have also been computers that could address individual bits ('bit-addressed machine'), or that could only address 16- or 32-bit quantities ('word-addressed machine'). The term \"byte\" was usually not used at all in connection with bit- and word-addressed machines.\n\nThe term \"octet\" always refers to an 8-bit quantity. It is mostly used in the field of computer networking, where computers with different byte widths might have to communicate.\n\nIn modern usage \"byte\" almost invariably means eight bits, since all other sizes have fallen into disuse; thus \"byte\" has come to be synonymous with \"octet\".\n\nThe term 'word' is used for a small group of bits that are handled simultaneously by processors of a particular architecture. The size of a word is thus CPU-specific. Many different word sizes have been used, including 6-, 8-, 12-, 16-, 18-, 24-, 32-, 36-, 39-, 40-, 48-, 60-, and 64-bit. Since it is architectural, the size of a \"word\" is usually set by the first CPU in a family, rather than the characteristics of a later compatible CPU. The meanings of terms derived from \"word\", such as \"longword\", \"doubleword\", \"quadword\", and \"halfword\", also vary with the CPU and OS.\n\nPractically all new desktop processors are capable of using 64-bit words, though embedded processors with 8- and 16-bit word size are still common. The 36-bit word length was common in the early days of computers.\n\nOne important cause of non-portability of software is the incorrect assumption that all computers have the same word size as the computer used by the programmer. For example, if a programmer using the C language incorrectly declares as int a variable that will be used to store values greater than 2−1, the program will fail on computers with 16-bit integers. That variable should have been declared as long, which has at least 32 bits on any computer. Programmers may also incorrectly assume that a pointer can be converted to an integer without loss of information, which may work on (some) 32-bit computers, but fail on 64-bit computers with 64-bit pointers and 32-bit integers.\n\nA \"short integer\" can represent a whole number that may take less storage, while having a smaller range, compared with a standard integer on the same machine.\n\nIn C, it is denoted by short. It is required to be at least 16 bits, and is often smaller than a standard integer, but this is not required. A conforming program can assume that it can safely store values between −(2−1) and 2−1, but it may not assume that the range isn't larger. In Java, a short is \"always\" a 16-bit integer. In the Windows API, the datatype SHORT is defined as a 16-bit signed integer on all machines.\n\nA \"long integer\" can represent a whole integer whose range is greater than or equal to that of a standard integer on the same machine.\n\nIn C, it is denoted by long. It is required to be at least 32 bits, and may or may not be larger than a standard integer. A conforming program can assume that it can safely store values between −(2−1) and 2−1, but it may not assume that the range isn't larger.\n\n the terms long and int are equivalent\n\nIn the C99 version of the C programming language and the C++11 version of C++, a codice_1 type is supported that has double the minimum capacity of the standard codice_2. This type is not supported by compilers that require C code to be compliant with the previous C++ standard, C++03, because the long long type did not exist in C++03. For an ANSI/ISO compliant compiler, the minimum requirements for the specified ranges, that is, −(2−1) to 2−1 for signed and 0 to 2−1 for unsigned, must be fulfilled; however, extending this range is permitted. This can be an issue when exchanging code and data between platforms, or doing direct hardware access. Thus, there are several sets of headers providing platform independent exact width types. The C standard library provides \"stdint.h\"; this was introduced in C99 and C++11.\n"}
{"id": "14800", "url": "https://en.wikipedia.org/wiki?curid=14800", "title": "Icon", "text": "Icon\n\nAn icon (from the Greek \"eikōn\" \"image\", \"resemblance\") is a religious work of art, most commonly a painting, in the cultures of the Eastern Orthodox Church, Oriental Orthodoxy, the Roman Catholic, and certain Eastern Catholic churches. The most common subjects include Christ, Mary, saints and angels. Though especially associated with \"portrait\" style images concentrating on one or two main figures, the term also covers most religious images in a variety of artistic media produced by Eastern Christianity, including narrative scenes.\n\nIcons may also be cast in metal, carved in stone, embroidered on cloth, painted on wood, done in mosaic or fresco work, printed on paper or metal, etc. Comparable images from Western Christianity are generally not classified as \"icons\", although \"iconic\" may be used to describe a static style of devotional image.\n\nEastern Orthodox tradition holds that the production of Christian images dates back to the very early days of Christianity, and that it has been a continuous tradition since then. Modern academic art history considers that, while images may have existed earlier, the tradition can be traced back only as far as the 3rd century, and that the images which survive from Early Christian art often differ greatly from later ones. The icons of later centuries can be linked, often closely, to images from the 5th century onwards, though very few of these survive. Widespread destruction of images occurred during the Byzantine Iconoclasm of 726-842, although this did settle permanently the question of the appropriateness of images. Since then icons have had a great continuity of style and subject; far greater than in the images of the Western church. At the same time there has been change and development.\n\nChristian tradition dating from the 8th century identifies Luke the Evangelist as the first icon painter.\n\nAside from the legend that Pilate had made an image of Christ, the 4th-century Eusebius of Caesarea, in his \"Church History\", provides a more substantial reference to a \"first\" icon of Jesus. He relates that King Abgar of Edessa (died ca 50 CE) sent a letter to Jesus at Jerusalem, asking Jesus to come and heal him of an illness. In this version there is no image. A later account found in the Syriac \"Doctrine of Addai\" (ca. 400 ?) mentions a painted image of Jesus in the story; and even later, in the 6th-century account given by Evagrius Scholasticus, the painted image transforms into an image that miraculously appeared on a towel when Christ pressed the cloth to his wet face. Further legends relate that the cloth remained in Edessa until the 10th century, when it was taken to Constantinople. It went missing in 1204 when Crusaders sacked Constantinople, but by then numerous copies had firmly established its iconic type.\n\nThe 4th-century Christian Aelius Lampridius produced the earliest known written records of Christian images treated like icons (in a pagan or Gnostic context) in his \"Life of Alexander Severus\" (xxix) that formed part of the \"Augustan History\". According to Lampridius, the emperor Alexander Severus (reigned 222–235), himself not a Christian, had kept a domestic chapel for the veneration of images of deified emperors, of portraits of his ancestors, and of Christ, Apollonius, Orpheus and Abraham. Saint Irenaeus, (c. 130–202) in his \"Against Heresies\" (1:25;6) says scornfully of the Gnostic Carpocratians:\n\"They also possess images, some of them painted, and others formed from different kinds of material; while they maintain that a likeness of Christ was made by Pilate at that time when Jesus lived among them. They crown these images, and set them up along with the images of the philosophers of the world that is to say, with the images of Pythagoras, and Plato, and Aristotle, and the rest. They have also other modes of honouring these images, after the same manner of the Gentiles [pagans]\".\nOn the other hand, Irenaeus does not speak critically of icons or portraits in a general sense – only of certain gnostic sectarians' use of icons.\n\nAnother criticism of image veneration appears in the non-canonical 2nd-century \"Acts of John\" (generally considered a gnostic work), in which the Apostle John discovers that one of his followers has had a portrait made of him, and is venerating it: (27)\n\"...he [John] went into the bedchamber, and saw the portrait of an old man crowned with garlands, and lamps and altars set before it. And he called him and said: Lycomedes, what do you mean by this matter of the portrait? Can it be one of thy gods that is painted here? For I see that you are still living in heathen fashion.\"\nLater in the passage John says, \"But this that you have now done is childish and imperfect: you have drawn a dead likeness of the dead.\"\n\nAt least some of the hierarchy of the Christian churches still strictly opposed icons in the early 4th century. At the Spanish non-ecumenical Synod of Elvira (c. 305) bishops concluded, \"Pictures are not to be placed in churches, so that they do not become objects of worship and adoration\". Bishop Epiphanius of Salamis, wrote his letter 51 to John, Bishop of Jerusalem (c. 394) in which he recounted how he tore down an image in a church and admonished the other bishop that such images are \"opposed . . . to our religion\".\n\nElsewhere in his \"Church History\", Eusebius reports seeing what he took to be portraits of Jesus, Peter and Paul, and also mentions a bronze statue at Banias / Paneas under Mount Hermon, of which he wrote, \"They say that this statue is an image of Jesus\" (\"H.E.\" 7:18); further, he relates that locals regarded the image as a memorial of the healing of the woman with an issue of blood by Jesus (Luke 8:43-48), because it depicted a standing man wearing a double cloak and with arm outstretched, and a woman kneeling before him with arms reaching out as if in supplication. John Francis Wilson suggests the possibility that this refers to a pagan bronze statue whose true identity had been forgotten; some have thought it to represent Aesculapius, the Greek god of healing, but the description of the standing figure and the woman kneeling in supplication precisely matches images found on coins depicting the bearded emperor Hadrian reaching out to a female figure – symbolizing a province – kneeling before him.\n\nWhen asked by Constantia (Emperor Constantine's sister) for an image of Jesus, Eusebius denied the request, replying: \"To depict purely the human form of Christ before its transformation, on the other hand, is to break the commandment of God and to fall into pagan error.\"\n\nAfter the emperor Constantine I extended official toleration of Christianity within the Roman Empire in 313, huge numbers of pagans became converts. This period of Christianization probably saw the use of Christian images became very widespread among the faithful, though with great differences from pagan habits. Robin Lane Fox states \"By the early fifth century, we know of the ownership of private icons of saints; by c. 480-500, we can be sure that the inside of a saint's shrine would be adorned with images and votive portraits, a practice which had probably begun earlier.\"\n\nWhen Constantine himself (reigned 306-337) apparently converted to Christianity, the majority of his subjects remained pagans. The Roman Imperial cult of the divinity of the emperor, expressed through the traditional burning of candles and the offering of incense to the emperor's image, was tolerated for a period because it would have been politically dangerous to attempt to suppress it. Indeed, in the 5th century the courts of justice and municipal buildings of the empire still honoured the portrait of the reigning emperor in this way. In 425 Philostorgius, an allegedly Arian Christian, charged the Orthodox Christians in Constantinople with idolatry because they still honored the image of the emperor Constantine the Great, the founder of the city, in this way. Dix notes that this occurred more than a century before we find the first reference to a similar honouring of the image of Christ or of His apostles or saints, but that it would seem a natural progression for the image of Christ, the King of Heaven and Earth, to be paid similar veneration as that given to the earthly Roman emperor. However, the Orthodox, Eastern Catholics, and other groups insist on explicitly distinguishing the veneration of icons from the worship of idols by pagans.\nSee further below on this topic.\n\nAfter adoption of Christianity as the only permissible Roman state religion under Theodosius I, Christian art began to change not only in quality and sophistication, but also in nature. This was in no small part due to Christians being free for the first time to express their faith openly without persecution from the state, in addition to the faith spreading to the non-poor segments of society. Paintings of martyrs and their feats began to appear, and early writers commented on their lifelike effect, one of the elements a few Christian writers criticized in pagan art — the ability to imitate life. The writers mostly criticized pagan works of art for pointing to false gods, thus encouraging idolatry. Statues in the round were avoided as being too close to the principal artistic focus of pagan cult practices, as they have continued to be (with some small-scale exceptions) throughout the history of Eastern Christianity.\n\nNilus of Sinai (d. c.430), in his \"Letter to Heliodorus Silentiarius\", records a miracle in which St. Plato of Ankyra appeared to a Christian in a dream. The Saint was recognized because the young man had often seen his portrait. This recognition of a religious apparition from likeness to an image was also a characteristic of pagan pious accounts of appearances of gods to humans, and was a regular \"topos\" in hagiography. One critical recipient of a vision from Saint Demetrius of Thessaloniki apparently specified that the saint resembled the \"more ancient\" images of him – presumably the 7th-century mosaics still in Hagios Demetrios. Another, an African bishop, had been rescued from Arab slavery by a young soldier called Demetrios, who told him to go to his house in Thessaloniki. Having discovered that most young soldiers in the city seemed to be called Demetrios, he gave up and went to the largest church in the city, to find his rescuer on the wall.\nDuring this period the church began to discourage all non-religious human images – the Emperor and donor figures counting as religious. This became largely effective, so that most of the population would only ever see religious images and those of the ruling class. The word icon referred to any and all images, not just religious ones, but there was barely a need for a separate word for these.\n\nIt is in a context attributed to the 5th century that the first mention of an image of Mary painted from life appears, though earlier paintings on catacomb walls bear resemblance to modern icons of Mary. Theodorus Lector, in his 6th-century \"History of the Church\" 1:1 stated that Eudokia (wife of emperor Theodosius II, died 460) sent an image of the \"Mother of God\" named Icon of the Hodegetria from Jerusalem to Pulcheria, daughter of Arcadius, the former emperor and father of Theodosius II. The image was specified to have been \"painted by the Apostle Luke.\"\n\nMargherita Guarducci relates a tradition that the original icon of Mary attributed to Luke, sent by Eudokia to Pulcheria from Palestine, was a large circular icon only of her head. When the icon arrived in Constantinople it was fitted in as the head into a very large rectangular icon of her holding the Christ child and it is this composite icon that became the one historically known as the Hodegetria. She further states another tradition that when the last Latin Emperor of Constantinople, Baldwin II, fled Constantinople in 1261 he took this original circular portion of the icon with him. This remained in the possession of the Angevin dynasty who had it likewise inserted into a much larger image of Mary and the Christ child, which is presently enshrined above the high altar of the Benedictine Abbey church of Montevergine. Unfortunately this icon has been over the subsequent centuries subjected to repeated repainting, so that it is difficult to determine what the original image of Mary's face would have looked like. However, Guarducci also states that in 1950 an ancient image of Mary at the Church of Santa Francesca Romana was determined to be a very exact, but reverse mirror image of the original circular icon that was made in the 5th century and brought to Rome, where it has remained until the present.\n\nIn later tradition the number of icons of Mary attributed to Luke would greatly multiply; the Salus Populi Romani, the Theotokos of Vladimir, the Theotokos Iverskaya of Mount Athos, the Theotokos of Tikhvin, the Theotokos of Smolensk and the Black Madonna of Częstochowa are examples, and another is in the cathedral on St Thomas Mount, which is believed to be one of the seven painted by St. Luke the Evangelist and brought to India by St. Thomas. Ethiopia has at least seven more.\n\nIn the period before and during the Iconoclastic Controversy, stories attributing the creation of icons to the New Testament period greatly increased, with several apostles and even the Virgin herself believed to have acted as the artist or commissioner of images (also embroidered in the case of the Virgin).\n\nThere was a continuing opposition to images and their misuse within Christianity from very early times. \"Whenever images threatened to gain undue influence within the church, theologians have sought to strip them of their power\". Further, \"there is no century between the fourth and the eighth in which there is not some evidence of opposition to images even within the Church\". Nonetheless, popular favor for icons guaranteed their continued existence, while no systematic apologia for or against icons, or doctrinal authorization or condemnation of icons yet existed.\n\nThe use of icons was seriously challenged by Byzantine Imperial authority in the 8th century. Though by this time opposition to images was strongly entrenched in Judaism and Islam, attribution of the impetus toward an iconoclastic movement in Eastern Orthodoxy to Muslims or Jews \"\"seems to have been highly exaggerated, both by contemporaries and by modern scholars\"\".\n\nThough significant in the history of religious doctrine, the Byzantine controversy over images is not seen as of primary importance in Byzantine history. \"Few historians still hold it to have been the greatest issue of the period...\"\n\nThe Iconoclastic Period began when images were banned by Emperor Leo III the Isaurian sometime between 726 and 730. Under his son Constantine V, a council forbidding image veneration was held at Hieria near Constantinople in 754. Image veneration was later reinstated by the Empress Regent Irene, under whom another council was held reversing the decisions of the previous iconoclast council and taking its title as Seventh Ecumenical Council. The council anathemized all who hold to iconoclasm, i.e. those who held that veneration of images constitutes idolatry. Then the ban was enforced again by Leo V in 815. And finally icon veneration was decisively restored by Empress Regent Theodora in 843.\n\nFrom then on all Byzantine coins had a religious image or symbol on the reverse, usually an image of Christ for larger denominations, with the head of the Emperor on the obverse, reinforcing the bond of the state and the divine order.\n\nThe tradition of \"acheiropoieta\" (, literally \"not-made-by-hand\") accrued to icons that are alleged to have come into existence miraculously, not by a human painter. Such images functioned as powerful relics as well as icons, and their images were naturally seen as especially authoritative as to the true appearance of the subject: naturally and especially because of the reluctance to accept mere human productions as embodying anything of the divine, a commonplace of Christian deprecation of man-made \"idols\". Like icons believed to be painted directly from the live subject, they therefore acted as important references for other images in the tradition. Beside the developed legend of the \"mandylion\" or Image of Edessa, was the tale of the Veil of Veronica, whose very name signifies \"true icon\" or \"true image\", the fear of a \"false image\" remaining strong.\n\nAlthough there are earlier records of their use, no panel icons earlier than the few from the 6th century preserved at the Greek Orthodox Saint Catherine's Monastery in Egypt survive, as the other examples in Rome have all been drastically over-painted. The surviving evidence for the earliest depictions of Christ, Mary and saints therefore comes from wall-paintings, mosaics and some carvings. They are realistic in appearance, in contrast to the later stylization. They are broadly similar in style, though often much superior in quality, to the mummy portraits done in wax (encaustic) and found at Fayyum in Egypt. As we may judge from such items, the first depictions of Jesus were generic rather than portrait images, generally representing him as a beardless young man. It was some time before the earliest examples of the long-haired, bearded face that was later to become standardized as the image of Jesus appeared. When they did begin to appear there was still variation. Augustine of Hippo (354-430) said that no one knew the appearance of Jesus or that of Mary. However, Augustine was not a resident of the Holy Land and therefore was not familiar with the local populations and their oral traditions. Gradually, paintings of Jesus took on characteristics of portrait images.\n\nAt this time the manner of depicting Jesus was not yet uniform, and there was some controversy over which of the two most common icons was to be favored. The first or \"Semitic\" form showed Jesus with short and \"frizzy\" hair; the second showed a bearded Jesus with hair parted in the middle, the manner in which the god Zeus was depicted. Theodorus Lector remarked that of the two, the one with short and frizzy hair was \"more authentic\". To support his assertion, he relates a story (excerpted by John of Damascus) that a pagan commissioned to paint an image of Jesus used the \"Zeus\" form instead of the \"Semitic\" form, and that as punishment his hands withered.\n\nThough their development was gradual, we can date the full-blown appearance and general ecclesiastical (as opposed to simply popular or local) acceptance of Christian images as venerated and miracle-working objects to the 6th century, when, as Hans Belting writes, \"we first hear of the church's use of religious images.\" \"As we reach the second half of the sixth century, we find that images are attracting direct veneration and some of them are credited with the performance of miracles\" Cyril Mango writes, \"In the post-Justinianic period the icon assumes an ever increasing role in popular devotion, and there is a proliferation of miracle stories connected with icons, some of them rather shocking to our eyes\". However, the earlier references by Eusebius and Irenaeus indicate veneration of images and reported miracles associated with them as early as the 2nd century. What might be shocking to our contemporary eyes may not have been viewed as such by the early Christians. Acts 5:15 reports that \"people brought the sick into the streets and laid them on beds and mats so that at least Peter's shadow might fall on some of them as he passed by.\"\n\nIn the icons of Eastern Orthodoxy, and of the Early Medieval West, very little room is made for artistic license. Almost everything within the image has a symbolic aspect. Christ, the saints, and the angels all have halos. Angels (and often John the Baptist) have wings because they are messengers. Figures have consistent facial appearances, hold attributes personal to them, and use a few conventional poses.\n\nColour plays an important role as well. Gold represents the radiance of Heaven; red, divine life. Blue is the color of human life, white is the Uncreated Light of God, only used for resurrection and transfiguration of Christ. If you look at icons of Jesus and Mary: Jesus wears red undergarment with a blue outer garment (God become Human) and Mary wears a blue undergarment with a red overgarment (human was granted gifts by God), thus the doctrine of deification is conveyed by icons. Letters are symbols too. Most icons incorporate some calligraphic text naming the person or event depicted. Even this is often presented in a stylized manner.\n\nIn the Eastern Orthodox Christian tradition there are reports of particular, Wonderworking icons that exude myrrh (fragrant, healing oil), or perform miracles upon petition by believers. When such reports are verified by the Orthodox hierarchy, they are understood as miracles performed by God through the prayers of the saint, rather than being magical properties of the painted wood itself. Theologically, all icons are considered to be sacred, and are miraculous by nature, being a means of spiritual communion between the heavenly and earthly realms. However, it is not uncommon for specific icons to be characterised as \"miracle-working\", meaning that God has chosen to glorify them by working miracles through them. Such icons are often given particular names (especially those of the Virgin Mary), and even taken from city to city where believers gather to venerate them and pray before them. Islands like that of Tinos are renowned for possessing such \"miraculous\" icons, and are visited every year by thousands of pilgrims.\n\nThe Eastern Orthodox view of the origin of icons is generally quite different from that of most secular scholars and from some in contemporary Roman Catholic circles: \"The Orthodox Church maintains and teaches that the sacred image has existed from the beginning of Christianity\", Léonid Ouspensky has written. Accounts that some non-Orthodox writers consider legendary are accepted as history within Eastern Orthodoxy, because they are a part of church tradition. Thus accounts such as that of the miraculous \"Image Not Made by Hands\", and the weeping and moving \"Mother of God of the Sign\" of Novgorod are accepted as fact: \"Church Tradition tells us, for example, of the existence of an Icon of the Savior during His lifetime (the \"Icon-Made-Without-Hands\") and of Icons of the Most-Holy Theotokos [Mary] immediately after Him.\" Eastern Orthodoxy further teaches that \"a clear understanding of the importance of Icons\" was part of the church from its very beginning, and has never changed, although explanations of their importance may have developed over time. This is because icon painting is rooted in the theology of the Incarnation (Christ being the \"eikon\" of God) which didn't change, though its subsequent clarification within the Church occurred over the period of the first seven Ecumenical Councils. Also, icons served as tools of edification for the illiterate faithful during most of the history of Christendom. Thus, icons are words in painting; they refer to the history of salvation and to its manifestation in concrete persons. In the Orthodox Church \"icons have always been understood as a visible gospel, as a testimony to the great things given man by God the incarnate Logos\" In the Council of 860 it was stated that \"all that is uttered in words written in syllables is also proclaimed in the language of colors\".\n\nEastern Orthodox find the first instance of an image or icon in the Bible when God made man in His own image (Septuagint Greek \"eikona\"), in Genesis 1:26-27. In Exodus, God commanded that the Israelites not make any graven image; but soon afterwards, he commanded that they make graven images of cherubim and other like things, both as statues and woven on tapestries. Later, Solomon included still more such imagery when he built the first temple. Eastern Orthodox believe these qualify as icons, in that they were visible images depicting heavenly beings and, in the case of the cherubim, used to indirectly indicate God's presence above the Ark.\n\nIn the Book of Numbers it is written that God told Moses to make a bronze serpent, \"Nehushtan\", and hold it up, so that anyone looking at the snake would be healed of their snakebites. In John 3, Jesus refers to the same serpent, saying that he must be lifted up in the same way that the serpent was. John of Damascus also regarded the brazen serpent as an icon. Further, Jesus Christ himself is called the \"image of the invisible God\" in Colossians 1:15, and is therefore in one sense an icon. As people are also made in God's images, people are also considered to be living icons, and are therefore \"censed\" along with painted icons during Orthodox prayer services.\n\nAccording to John of Damascus, anyone who tries to destroy icons \"is the enemy of Christ, the Holy Mother of God and the saints, and is the defender of the Devil and his demons.\" This is because the theology behind icons is closely tied to the Incarnational theology of the humanity and divinity of Jesus, so that attacks on icons typically have the effect of undermining or attacking the Incarnation of Jesus himself as elucidated in the Ecumenical Councils.\n\nBasil of Caesarea, in his writing \"On the Holy Spirit\", says: \"The honor paid to the image passes to the prototype\". He also illustrates the concept by saying, \"If I point to a statue of Caesar and ask you 'Who is that?', your answer would properly be, 'It is Caesar.' When you say such you do not mean that the stone itself is Caesar, but rather, the name and honor you ascribe to the statue passes over to the original, the archetype, Caesar himself.\" So it is with an Icon.\n\nThus to kiss an icon of Christ, in the Eastern Orthodox view, is to show love towards Christ Jesus himself, not mere wood and paint making up the physical substance of the icon. Worship of the icon as somehow entirely separate from its prototype is expressly forbidden by the Seventh Ecumenical Council.\n\nIcons are often illuminated with a candle or jar of oil with a wick. (Beeswax for candles and olive oil for oil lamps are preferred because they burn very cleanly, although other materials are sometimes used.) The illumination of religious images with lamps or candles is an ancient practice pre-dating Christianity.\n\nOf the icon painting tradition that developed in Byzantium, with Constantinople as the chief city, we have only a few icons from the 11th century and none preceding them, in part because of the Iconoclastic reforms during which many were destroyed or lost, and also because of plundering by the Republic of Venice in 1204 during the Fourth Crusade, and finally the Fall of Constantinople in 1453.\n\nIt was only in the Comnenian period (1081–1185) that the cult of the icon became widespread in the Byzantine world, partly on account of the dearth of richer materials (such as mosaics, ivory, and vitreous enamels), but also because an \"iconostasis\" a special screen for icons was introduced then in ecclesiastical practice. The style of the time was severe, hieratic and distant.\n\nIn the late Comnenian period this severity softened, and emotion, formerly avoided, entered icon painting. Major monuments for this change include the murals at Daphni Monastery (ca. 1100) and the Church of St. Panteleimon near Skopje (1164). The Theotokos of Vladimir (ca. 1115, \"illustration, right\") is probably the most representative example of the new trend towards spirituality and emotion.\n\nThe tendency toward emotionalism in icons continued in the Paleologan period, which began in 1261. Palaiologan art reached its pinnacle in mosaics such as those of Chora Church. In the last half of the 14th century, Palaiologan saints were painted in an exaggerated manner, very slim and in contorted positions, that is, in a style known as the Palaiologan Mannerism, of which is a superb example.\n\nAfter 1453, the Byzantine tradition was carried on in regions previously influenced by its religion and culture — in the Balkans, Russia, and other Slavic countries, Georgia and Armenia in the Caucasus, and among Eastern Orthodox minorities in the Islamic world. In the Greek-speaking world Crete, ruled by Venice until the mid-17th century, was an important centre of painted icons, as home of the Cretan School, exporting many to Europe.\n\nCrete was under Venetian control from 1204 and became a thriving center of art with eventually a \"Scuola di San Luca\", or organized painter's guild, the Guild of Saint Luke, on Western lines. Cretan painting was heavily patronized both by Catholics of Venetian territories and by Eastern Orthodox. For ease of transport, Cretan painters specialized in panel paintings, and developed the ability to work in many styles to fit the taste of various patrons. El Greco, who moved to Venice after establishing his reputation in Crete, is the most famous artist of the school, who continued to use many Byzantine conventions in his works. In 1669 the city of Heraklion, on Crete, which at one time boasted at least 120 painters, finally fell to the Turks, and from that time Greek icon painting went into a decline, with a revival attempted in the 20th century by art reformers such as Photis Kontoglou, who emphasized a return to earlier styles.\n\nRussian icons are typically paintings on wood, often small, though some in churches and monasteries may be as large as a table top. Many religious homes in Russia have icons hanging on the wall in the \"krasny ugol\" – the \"red\" corner (see Icon corner). There is a rich history and elaborate religious symbolism associated with icons. In Russian churches, the nave is typically separated from the sanctuary by an \"iconostasis\", a wall of icons.\n\nThe use and making of icons entered Kievan Rus' following its conversion to Orthodox Christianity from the Eastern Roman (Byzantine) Empire in 988 AD. As a general rule, these icons strictly followed models and formulas hallowed by usage, some of which had originated in Constantinople. As time passed, the Russians—notably Andrei Rublev and Dionisius—widened the vocabulary of iconic types and styles far beyond anything found elsewhere. The personal, improvisatory and creative traditions of Western European religious art are largely lacking in Russia before the 17th century, when Simon Ushakov's painting became strongly influenced by religious paintings and engravings from Protestant as well as Catholic Europe.\n\nIn the mid-17th century, changes in liturgy and practice instituted by Patriarch Nikon of Moscow resulted in a split in the Russian Orthodox Church. The traditionalists, the persecuted \"Old Ritualists\" or \"Old Believers\", continued the traditional stylization of icons, while the State Church modified its practice. From that time icons began to be painted not only in the traditional stylized and nonrealistic mode, but also in a mixture of Russian stylization and Western European realism, and in a Western European manner very much like that of Catholic religious art of the time. The Stroganov School and the icons from Nevyansk rank among the last important schools of Russian icon-painting.\n\nIn Romania, icons painted as reversed images behind glass and set in frames were common in the 19th century and are still made. The process is known as reverse glass painting. \"In the Transylvanian countryside, the expensive icons on panels imported from Moldavia, Wallachia, and Mt. Athos were gradually replaced by small, locally produced icons on glass, which were much less expensive and thus accessible to the Transylvanian peasants[.]\"\n\nThe Coptic Orthodox Church of Alexandria and Oriental Orthodoxy also have distinctive, living icon painting traditions. Coptic icons have their origin in the Hellenistic art of Egyptian Late Antiquity, as exemplified by the Fayum mummy portraits. Beginning in the 4th century, churches painted their walls and made icons to reflect an authentic expression of their faith.\n\nAlthough the word \"icon\" is not used in Western Christianity, there are religious works of art which were largely patterned on Byzantine works, and equally conventional in composition and depiction. Until the 13th century, \"icon\"-like portraits followed East pattern – although very few survive from this early period. From the 13th century, the western tradition came slowly to allow the artist far more flexibility, and a more realist approach to the figures. If only because there was a much smaller number of skilled artists, the quantity of works of art, in the sense of panel paintings, was much smaller in the West, and in most Western settings a single diptych as an altarpiece, or in a domestic room, probably stood in place of the larger collections typical of Orthodox \"icon corners\".\n\nOnly in the 15th century did production of painted works of art begin to approach Eastern levels, supplemented by mass-produced imports from the Cretan School. In this century, the use of \"icon\"-like portraits in the West was enormously increased by the introduction of old master prints on paper, mostly woodcuts which were produced in vast numbers (although hardly any survive). They were mostly sold, hand-coloured, by churches, and the smallest sizes (often only an inch high) were affordable even by peasants, who glued or pinned them straight onto a wall.\n\nWith the Reformation, after an initial uncertainty among early Lutherans, who painted a few \"icon\"-like depictions of leading Reformers, and continued to paint scenes from Scripture, Protestants came down firmly against icon-like portraits, especially larger ones, even of Christ. Many Protestants found these \"idolatrous\".\n\nThe Roman Catholic Church accepted the decrees of the iconodule Seventh Ecumenical Council regarding images. There is some minor difference, however, in the Catholic attitude to images from that of the Orthodox. Following Gregory the Great, Catholics emphasize the role of images as the \"Biblia Pauperum\", the \"Bible of the Poor,\" from which those who could not read could nonetheless learn.\n\nCatholics also, however, share the same viewpoint with the Orthodox when it comes to image veneration, believing that whenever approached, sacred images are to be reverenced. Though using both flat wooden panel and stretched canvas paintings, Catholics traditionally have also favored images in the form of three-dimensional statuary, whereas in the East, statuary is much less widely employed.\n\nA recent joint Lutheran–Orthodox statement made in the 7th Plenary of the Lutheran–Orthodox Joint Commission, on July 1993 in Helsinki, reaffirmed the ecumenical council decisions on the nature of Christ and the veneration of images:\n\n\n\n\n"}
{"id": "14801", "url": "https://en.wikipedia.org/wiki?curid=14801", "title": "Icon (programming language)", "text": "Icon (programming language)\n\nIcon is a very high-level programming language featuring goal-directed execution and many facilities for managing strings and textual patterns. It is related to SNOBOL and SL5, string processing languages. Icon is not object-oriented, but an object-oriented extension called Idol was developed in 1996 which eventually became Unicon.\n\nThe Icon language is derived from the ALGOL-class of structured programming languages, and thus has syntax similar to C or Pascal. Icon is most similar to Pascal, using codice_1 syntax for assignments, the codice_2 keyword and similar syntax. On the other hand, Icon uses C-style brackets for structuring execution groups, and programs start by running a procedure called \"main\".\n\nIn many ways Icon also shares features with most scripting languages (as well as SNOBOL and SL5, from which they were taken): variables do not have to be declared, types are cast automatically, and numbers can be converted to strings and back automatically. Another feature common to many scripting languages, but not all, is the lack of a line-ending character; in Icon, lines not ended by a semicolon get ended by an implied semicolon if it makes sense.\n\nProcedures are the basic building blocks of Icon programs. Although they use Pascal naming, they work more like C functions and can return values; there is no codice_3 keyword in Icon.\n\nOne of Icon's key concepts is that control structures are based on the \"success\" or \"failure\" of expressions, rather than on boolean logic, as in most other programming languages. Under this model, simple comparisons like codice_4 do not mean \"if the operations to the right evaluate to true\" as they would under most languages; instead it means something more like \"if the operations to the right \"succeed\"\". In this case the < operator succeeds if the comparison is true, so the end result is the same. In addition, the < operator returns its second argument if it succeeds, allowing things like codice_5, a common type of comparison that in most languages must be written as a conjunction of two inequalities like codice_6.\n\nThe utility of this concept becomes much clearer when you consider real-world examples. Since Icon uses success or failure for all flow control, this simple code:\n\nwill copy one line of standard input to standard output. This code will work even if the read() causes an error, for instance, if the file does not exist. In that case the statement codice_7 will fail, and write will simply not be called.\n\nSuccess and failure are passed \"up\" through functions, meaning that a failure inside a nested function will cause the functions calling it to fail as well. For instance, we can write a program to copy an entire input file to output in a single line:\n\nWhen the read() command fails, at the end of file for instance, the failure will be passed up the chain, and write() will fail as well. The while, being a control structure, stops on failure, meaning it stops when the file is empty. For comparison, consider a similar example written in pseudocode (using syntax close to C++ and derived languages such as Java):\n\nThis case needs two comparisons: one for end of file (EOF) and another for all other errors. Since Java does not allow errors to be compared as logic elements, as under Icon, the lengthy try/catch syntax must be used instead. Try blocks also impose a performance penalty for simply using them, even if no error occurs, a distributed cost that Icon avoids.\n\nIcon refers to this concept as \"goal-directed execution\", referring to the way that execution continues until some goal is reached. In the example above the goal is to read the entire file; the read command continues to succeed while there is more information to be read, and fails when there isn't. The goal is thus coded directly in the language, instead of using statements checking return codes or similar constructs.\n\nExpressions in Icon often return a single value, for instance, x < 5 will evaluate and succeed if the value of x is less than 5, or else fail. However several of the examples below rely on the fact that many expressions do not \"immediately\" return success or failure, returning values in the meantime. This drives the examples with every and to; every causes to to continue to return values until it fails.\n\nThis is a key concept in Icon, known as \"generators\". Generators drive much of the loop functionality in the language, but do so more directly; the programmer does not write a loop and then pull out and compare values, Icon will do all of this for you.\n\nWithin the parlance of Icon, the evaluation of an expression or function results in a result sequence. A result sequence contains all the possible values that can be generated by the expression or function. When the result sequence is exhausted (e.g. there are no more values within the result sequence), the expression or function fails. Iteration over the result sequence is achieved either implicitly via Icon's goal directed evaluation or explicitly via the every clause.\n\nIcon includes several generator-builders. The \"alternator\" syntax allows a series of items to be generated in sequence until one fails:\n\ncan generate \"1\", \"hello\", and \"5\" if x is less than 5. Alternators can be read as \"or\" in many cases, for instance:\n\nwill write out the value of y if it is smaller than x \"or\" 5. Internally Icon checks every value from left to right until one succeeds or the list empties and it returns a failure. Remember that functions will not be called unless the calls within do not fail, so this example can be shortened to:\n\nAnother simple generator is the codice_8, which generates lists of integers; codice_9 will do exactly what it seems to. The \"bang syntax\" generates every item of a list; codice_10 will output each character of aString on a new line.\n\nTo demonstrate the power of this concept, consider string operations. Most languages include a function known as codice_11 or codice_12 that returns the location of a string within another. Consider:\n\nThis code will return 4, the position of the first occurrence of the word \"the\". To get the next instance of \"the\" an alternate form must be used,\n\nthe 5 at the end saying it should look from position 5 on. In order to extract all the occurrences of \"the\", a loop must be used...\n\nUnder Icon the find function is a generator, and will return the next instance of the string each time it is resumed before finally failing after it passes the end of the string. The same code under Icon can be written:\n\nfind will return the index of the next instance of \"the\" each time it is resumed by every, eventually passing the end of the string and failing. As in the prior example, this will cause write to fail, and the (one-line) every loop to exit.\n\nOf course there are times where you deliberately want to find a string after some point in input, for instance, you might be scanning a text file containing data in multiple columns. Goal-directed execution works here as well, and can be used this way:\n\nThe position will only be returned if \"the\" appears after position 5, the comparison will fail otherwise, passing that failure to write() as before. There is one small \"trick\" to this code that needs to be considered: comparisons return the right-hand result, so it is important to put the find on the right-hand side of the comparison. If the 5 were placed on the right, 5 would be written.\n\nIcon adds several control structures for looping through\ngenerators. The every operator is similar to while, looping through every item returned by a generator and exiting on failure:\n\nWhy use every instead of a while loop in this case?\nBecause while re-evaluates the first result,\nbut every produces all results.\nThe every syntax actually injects values into the function in a fashion similar to blocks under Smalltalk. For instance, the above loop can be re-written this way:\n\nUsers can build new generators easily using the suspend keyword:\n\nThis example loops over \"theString\" using find to look for \"pattern\". When one is found, and the position is odd, the location is returned from the function with suspend. Unlike return, suspend writes down where it is in the internal generators as well, allowing it to pick up where it left off on the next iteration.\n\nIn keeping with its script-like functionality, Icon adds a number of features to make working with strings easier. Most notable among these is the \"scanning\" system, which repeatedly calls functions on a string:\n\nis a short form of the examples shown earlier. In this case the \"subject\" of the codice_11 function is placed outside the parameters in front of the question-mark. Icon functions are deliberately (as opposed to automatically) written to identify the subject in parameter lists and allow them to be pulled out in this fashion.\n\nSubstrings can be extracted from a string by using a range specification within brackets. A range specification can return a point to a single character, or a slice of the string. Strings can be indexed from either the right or the left. Positions within a string are defined to be between the characters ABC and can be specified from the right ABC\n\nFor example,\n\nWhere the last example shows using a length instead of an ending position\n\nThe subscripting specification can be used as a lvalue within an expression. This can be used to insert strings into another string or delete parts of a string. For example,\nAs noted above, Icon's subscript indices are between the elements. Given the string s := \"ABCDEFG\", the indexes are: ABCDEFG. The slice s[3:5] is the string between the indices 3 and 5, which is the string \"CD\".\n\nIcon also allows the user to easily construct their own lists (or \"arrays\"):\n\nThe items within a list can be of any sort, including other structures. To quickly build larger lists, Icon includes the codice_14 generator; codice_15 generates a list containing 10 copies of \"word\".\n\nLike arrays in other languages, Icon allows items to be looked up by position, e.g., codice_16. As with strings, the indices are between the elements, and a slice of a list can be obtained by specifying the range, e.g., codice_17 produces the list codice_18. Unlike strings, a slice using a range cannot be a lvalue.\n\nThe \"bang-syntax\", e.g., codice_19, will print out four lines, each with one element.\n\nIcon includes stack-like functions, codice_20 and codice_21 to allow them to form the basis of stacks and queues.\n\nIcon also includes functionality for sets and tables (known as \"hashes\", \"associative arrays\", \"dictionaries\", etc.):\n\nThis code creates a table that will use zero as the default value of any unknown key. It then adds two items into it, with the keys \"there\" and \"here\", and values 1 and 2.\n\nOne of the powerful features of Icon is string scanning. The scan string operator, codice_22 saves the current string scanning environment and creates a new string scanning environment. The string scanning environment consists of two keyword variables, codice_23 and codice_24. Where &subject is the string being scanned, and &pos is the \"cursor\" or current position within the subject string.\n\nFor example,\n\nwould produce\nBuilt-in and user-defined functions can be used to move around within the string being scanned. Many of the built-in functions will default to &subject and &pos (for example the \"find\" function). The following, for example, will write all blank delimited \"words\" in a string.\n\nA more complex example demonstrates the integration of generators and string scanning within the language.\n\nThe idiom of codice_25 returns the value of the last expression\n\n\nThe definitive work is \"The Icon Programming Language\" (third edition) by Griswold and Griswold, .\nIt is out of print but can be downloaded in PDF form.\n\nIcon also has co-expressions, providing non-local exits for program execution. Please see \"The Icon Programming language\" and also Shamim Mohamed's article \"Co-expressions in Icon\". (This topic should probably be expanded.)\n\n"}
{"id": "14802", "url": "https://en.wikipedia.org/wiki?curid=14802", "title": "Iconology", "text": "Iconology\n\nIconology is a method of interpretation in cultural history and the history of art used by Aby Warburg, Erwin Panofsky and their followers that uncovers the cultural, social, and historical background of themes and subjects in the visual arts. \n\nIt is derived from synthesis rather than scattered analysis and examines symbolic meaning on more than its face value by reconciling it with its historical context and with the artist's body of work – in contrast to the widely descriptive iconography, which, as described by Panofsky, is an approach to studying the content and meaning of works of art that is primarily focused on classifying, establishing dates, provenance and other necessary fundamental knowledge concerning the subject matter of an artwork that is needed for further interpretation.\n\nThough Panofsky strongly differentiated between iconology and iconography, the distinction is not very widely followed, \"and they have never been given definitions accepted by all iconographers and iconologists\". Few 21st-century authors continue to use the term consistently.\n\nIt should also be noted that Panofsky's \"use of iconology as the principle tool of art analysis brought him critics.\" For instance, in 1946, Jan Gerrit Van Gelder \"criticized Panofsky's iconology as putting too much emphasis on the symbolic content of the work of art, neglecting its formal aspects and the work as a unity of form and content.\" Furthermore, iconology is mostly avoided by social historians who do not accept the theoretical dogmaticism in the work of Panofsky.\n\nErwin Panofsky defines iconography as \"a known principle in the known world\", while iconology is \"an iconography turned interpretive\". According to his view, iconology tries to reveal the underlying principles that form the basic attitude of a nation, a period, a class, a religious or philosophical perspective, which is modulated by one personality and condensed into one work. According to Roelof van Straten, iconology \"can explain why an artist or patron chose a particular subject at a specific location and time and represented it in a certain way. An iconological investigation should concentrate on the social-historical, not art-historical, influences and values that the artist might not have consciously brought into play but are nevertheless present. The artwork is primarily seen as a document of its time.\"\n\nWarburg used the term \"iconography\" in his early research, replacing it in 1908 with \"iconology\" in his particular method of visual interpretation called \"critical iconology\", which focused on the tracing of motifs through different cultures and visual forms. In 1932, Panofsky published a seminal article, introducing a three-step method of visual interpretation dealing with (1) primary or natural subject matter; (2) secondary or conventional subject matter, i.e. iconography; (3) tertiary or intrinsic meaning or content, i.e. iconology. Whereas iconography analyses the world of images, stories and allegories and requires knowledge of literary sources, an understanding of the history of types and how themes and concepts were expressed by objects and events under different historical conditions, iconology interprets intrinsic meaning or content and the world of symbolical values by using \"synthetic intuition\". The interpreter is aware of the essential tendencies of the human mind as conditioned by psychology and world view; he analyses the history of cultural symptoms or symbols, or how tendencies of the human mind were expressed by specific themes due to different historical conditions. Moreover, when understanding the work of art as a document of a specific civilization, or of a certain religious attitude therein, the work of art becomes a symptom of something else, which expresses itself in a variety of other symptoms. Interpreting these symbolical values, which can be unknown to, or different from, the artist's intention, is the object of iconology. Panofsky emphasized that \"iconology can be done when there are no originals to look at and nothing but artificial light to work in.\"\n\nAccording to Ernst Gombrich, \"the emerging discipline of iconology ... must ultimately do for the image what linguistics has done for the word.\" However, Michael Camille is of the opinion that \"though Panofsky's concept of iconology has been very influential in the humanities and is quite effective when applied to Renaissance art, it is still problematic when applied to art from periods before and after.\"\n\nIn 1952, Creighton Gilbert added another opinion about the meaning of the word \"iconology\". According to his view, iconology was not the actual investigation of the work of art but rather the result of this investigation. The Austrian art historian Hans Sedlmayr differentiated between \"sachliche\" and \"methodische\" iconology. \"Sachliche\" iconology refers to the \"general meaning of an individual painting or of an artistic complex (church, palace, monument) as seen and explained with reference to the ideas which take shape in them.\" In contrast, \"methodische\" iconology is the \"integral iconography which accounts for the changes and development in the representations\". In \"Iconology: Images, Text, Ideology\" (1986), W.J.T. Mitchell writes that iconology is a study of \"what to say about images\", concerned with the description and interpretation of visual art, and also a study of \"what images say\" – the ways in which they seem to speak for themselves by persuading, telling stories, or describing. He pleads for a postlinguistic, postsemiotic \"iconic turn\", emphasizing the role of \"non-linguistic symbol systems\". Instead of just pointing out the difference between the material (pictorial or artistic) images, \"he pays attention to the dialectic relationship between material images and mental images\". According to Dennise Bartelo and Robert Morton, the term \"iconology\" can also be used for characterizing \"a movement toward seeing connections across all the language processes\" and the idea about \"multiple levels and forms used to communicate meaning\" in order to get \"the total picture” of learning. \"Being both literate in the traditional sense and visually literate are the true mark of a well-educated human.\"\n\nFor several years, new approaches to iconology have developed in the theory of images. This is the case of what Jean-Michel Durafour, French philosopher and theorist of cinema, proposed to call \"econology\", a biological approach to images as forms of life, crossing iconology, ecology and sciences of nature. In an econological regime, the image (\"eikon\") self-speciates, that is to say, it self-iconicizes with others and eco-iconicizes with them its iconic habitat (\"oikos\"). The iconology, mainly Warburghian iconology, is thus merged with a conception of the relations between the beings of the nature inherited, among others (Arne Næss, etc.) from the writings of Kinji Imanishi. For Imanishi, living beings are subjects. Or, more precisely, the environment and the living being are juste one. One of the main consequences is that the \"specity\", the living individual, \"self-eco-speciates its place of life\" (\"Freedom in Evolution\"). As far as the images are concerned: \"If the living species self-specify, the images self-iconicize. This is not a tautology. The images update some of their iconic virtualities. They live in the midst of other images, past or present, but also future (those are only human classifications), which they have relations with. They self-iconicize in an iconic environment which they interact with, and which in particular makes them the images they are. Or more precisely, insofar as images have an active part: \"the images self-eco-iconicize their iconic environment\".\"\n\n\"Studies in Iconology\" is the title of a book by Erwin Panofsky on humanistic themes in the art of the Renaissance, which was first published in 1939. It is also the name of a peer-reviewed series of books started in 2014 under the editorship of Barbara Baert and published by Peeters international academic publishers, Leuven, Belgium, addressing the deeper meaning of the visual medium throughout human history in the fields of philosophy, art history, theology and cultural anthropology.\n\n\n"}
{"id": "14804", "url": "https://en.wikipedia.org/wiki?curid=14804", "title": "List of Indian massacres", "text": "List of Indian massacres\n\nIn the history of the European colonization of the Americas, an atrocity termed \"Indian massacre\" is a specific incident wherein a group of people (military, mob or other) deliberately kill a significant number of unarmed, defenseless people — usually civilian noncombatants — or to the summary execution of prisoners-of-war. The term usually refers to the killing of unarmed Native American women, children, and elders by colonists and the colonizing military forces. In historical usage, it has also been used by colonists to describe the actions of Native Americans killing colonists.\n\n\"Indian massacre\" is a phrase whose use and definition has evolved and expanded over time. The phrase was initially used by European colonists to describe attacks by indigenous Americans which resulted in mass colonial casualties. While similar attacks by colonists on Indian villages were called \"raids\" or \"battles\", successful Indian attacks on white settlements or military posts were routinely termed \"massacres\". Knowing very little about the native inhabitants of the American frontier, the colonists were deeply fearful, and as time passed, \"far more white Americans eagerly consumed Indian atrocity stories around the family table and in popular literature and newspapers than ever interacted with Indians or witnessed an Indian raid.\" Emphasis was placed on the depredations of \"murderous savages\" in their information about Indians, and as the migrants headed further west, fear was the prevailing emotion behind their thoughts and actions concerning Indians. In some instances motivated by politics, in Colorado for example, \"stories in the \"News\" continued to stir those fears: wild rumors of Indian conspiracies were heralded as fact; any violence at all between whites and Indians was reported as an Indian 'massacre'\".\n\nThe phrase eventually became commonly used also to describe mass killings of American Indians. Killings described as \"massacres\" often had an element of indiscriminate targeting, barbarism, or genocidal intent. According to one historian, \"Any discussion of genocide must, of course, eventually consider the so-called Indian Wars\", the term commonly used for U.S. Army campaigns to subjugate Indian nations of the American West beginning in the 1860s. In an older historiography, key events in this history were narrated as battles.\n\nSince the late 20th century, it has become more common for scholars to refer to certain of these events as massacres, especially if there were large numbers of women and children as victims. This includes the Colorado territorial militia's slaughter of Cheyenne at Sand Creek (1864), and the US army's slaughter of Shoshone at Bear River (1863), Blackfeet on the Marias River (1870), and Lakota at Wounded Knee (1890). Some scholars have begun referring to these events as \"genocidal massacres,\" defined as the annihilation of a portion of a larger group, sometimes to provide a lesson to the larger group.\n\nIt is difficult to determine the total number of people who died as a result of \"Indian massacres\". In \"The Wild Frontier: Atrocities during the American-Indian War from Jamestown Colony to Wounded Knee\", lawyer William M. Osborn compiled a list of alleged and actual atrocities in what would eventually become the continental United States, from first contact in 1511 until 1890. His parameters for inclusion included the intentional and indiscriminate murder, torture, or mutilation of civilians, the wounded, and prisoners. His list included 7,193 people who died from atrocities perpetrated by those of European descent, and 9,156 people who died from atrocities perpetrated by Native Americans. Many of the incidents included on this list are not mentioned in Osborn's book.\n\nIn \"An American Genocide, The United States and the California Catastrophe, 1846-1873\", historian Benjamin Madley recorded the numbers of killings of California Indians between 1846 and 1873. He found evidence that during this period at least 9,400 to 16,000 California Indians were killed by non-Indians. Most of these killings occurred in what he said were more than 370 massacres (defined by him as the \"intentional killing of five or more disarmed combatants or largely unarmed noncombatants, including women, children, and prisoners, whether in the context of a battle or otherwise\").\n\nThis is a listing of some of the events reported then or referred to now as \"Indian massacre\". This list contains only incidents that occurred in Canada or the United States, or territory presently part of the United States.\n\n\n"}
{"id": "14810", "url": "https://en.wikipedia.org/wiki?curid=14810", "title": "Islamic calendar", "text": "Islamic calendar\n\nThe Islamic, Muslim, or Hijri calendar ( \"at-taqwīm al-hijrī\") is a lunar calendar consisting of 12 lunar months in a year of 354 or 355 days. It is used to determine the proper days of Islamic holidays and rituals, such as the annual period of fasting and the proper time for the pilgrimage to Mecca. The civil calendar of almost all countries where the religion is predominantly Muslim is the Gregorian calendar. Notable exceptions to this rule are Iran and Afghanistan, which use the Solar Hijri calendar. Rents, wages etc. are generally paid by the civil calendar.\n\nThe Islamic calendar employs the Hijri era whose epoch was established as the Islamic New Year of 622 AD/CE. During that year, Muhammad and his followers migrated from Mecca to Yathrib (now Medina) and established the first Muslim community (\"ummah\"), an event commemorated as the Hijra. In the West, dates in this era are usually denoted AH (, \"in the year of the Hijra\") in parallel with the Christian (AD), Common (CE) and Jewish eras (AM). In Muslim countries, it is also sometimes denoted as H from its Arabic form (, abbreviated ). In English, years prior to the Hijra are reckoned as BH (\"Before the Hijra\").\n\nThe current Islamic year is 1440 AH. In the Gregorian calendar, 1440 AH runs from approximately 11 September 2018 to 30 August 2019.\n\nFor central Arabia, especially Mecca, there is a lack of epigraphical evidence but details are found in the writings of Muslim authors of the Abbasid era. Inscriptions of the ancient South Arabian calendars reveal the use of a number of local calendars. At least some of these South Arabian calendars followed the lunisolar system. Both al-Biruni and al-Mas'udi suggest that the ancient Arabs used the same month names as the Muslims, though they also record other month names used by the pre-Islamic Arabs.\n\nThe Islamic tradition is unanimous in stating that Arabs of Tihamah, Hejaz, and Najd distinguished between two types of months, permitted (\"ḥalāl\") and forbidden (\"ḥarām\") months. The forbidden months were four months during which fighting is forbidden, listed as Rajab and the three months around the pilgrimage season, Dhu al-Qa‘dah, Dhu al-Hijjah, and Muharram. Information about the forbidden months is also found in the writings of Procopius, where he describes an armistice with the Eastern Arabs of the Lakhmid al-Mundhir which happened in the summer of 541 AD/CE. However, Muslim historians do not link these months to a particular season. The Qur'an links the four forbidden months with \"Nasī’\", a word that literally means \"postponement\". According to Muslim tradition, the decision of postponement was administered by the tribe of Kinanah, by a man known as the \"al-Qalammas\" of Kinanah and his descendants (pl. \"qalāmisa\").\n\nDifferent interpretations of the concept of \"Nasī’\" have been proposed. Some scholars, both Muslim and Western, maintain that the pre-Islamic calendar used in central Arabia was a purely lunar calendar similar to the modern Islamic calendar. According to this view, \"Nasī’\" is related to the pre-Islamic practices of the Meccan Arabs, where they would alter the distribution of the forbidden months within a given year without implying a calendar manipulation. This interpretation is supported by Arab historians and lexicographers, like Ibn Hisham, Ibn Manzur, and the corpus of Qur'anic exegesis.\n\nThis is corroborated by an early Sabaic inscription, where a religious ritual was \"postponed\" (\"ns'’w\") due to war. According to the context of this inscription, the verb \"ns'’\" has nothing to do with intercalation, but only with moving religious events within the calendar itself. The similarity between the religious concept of this ancient inscription and the Qur'an suggests that non-calendaring postponement is also the Qur'anic meaning of \"Nasī’\". The \"Encyclopaedia of Islam\" concludes \"\"The Arabic system of [Nasī’] can only have been intended to move the Hajj and the fairs associated with it in the vicinity of Mecca to a suitable season of the year. It was not intended to establish a fixed calendar to be generally observed.\"\" The term \"fixed calendar\" is generally understood to refer to the non-intercalated calendar. \n\nOthers concur that it was originally a lunar calendar, but suggest that about 200 years before the Hijra it was transformed into a lunisolar calendar containing an intercalary month added from time to time to keep the pilgrimage within the season of the year when merchandise was most abundant. This interpretation was first proposed by the medieval Muslim astrologer and astronomer Abu Ma'shar al-Balkhi, and later by al-Biruni, al-Mas'udi, and some western scholars. This interpretation considers \"Nasī’\" to be a synonym to the Arabic word for \"intercalation\" (\"kabīsa\"). The Arabs, according to one explanation mentioned by Abu Ma'shar, learned of this type of intercalation from the Jews. The Jewish \"Nasi\" was the official who decided when to intercalate the Jewish calendar. Some sources say that the Arabs followed the Jewish practice and intercalated seven months over nineteen years, or else that they intercalated nine months over 24 years; there is, however, no consensus among scholars on this issue.\n\nPostponement (\"Nasī’\") of one ritual in a particular circumstance does not imply alteration of the sequence of months, and scholars agree that this did not happen. Al-Biruni also says this did not happen, and the festivals were kept within their season by intercalation every second or third year of a month between Dhu al-Hijjah and Muharram. He also says that, in terms of the fixed calendar that was not introduced until 10 AH (632 AD/CE), the first intercalation was, for example, of a month between Dhu al-Hijjah and Muharram, the second of a month between Muharram and Safar, the third of a month between Safar and Rabi'I, and so on. The intercalations were arranged so that there were seven of them every nineteen years. The notice of intercalation was issued at the pilgrimage, the next month would be \"Nasī’\" and Muharram would follow. If, on the other hand, the names relate to the intercalated rather than the fixed calendar, the second intercalation might be, for example, of a month between Muharram and Safar allowing for the first intercalation, and the third intercalation of a month between Safar and Rabi'I allowing for the two preceding intercalations, and so on. The time for the intercalation to move from the beginning of the year to the end (twelve intercalations) is the time it takes the fixed calendar to revolve once through the seasons (about 32 1/2 tropical years). There are two big drawbacks of such a system, which would explain why it is not known ever to have been used anywhere in the world. First, it cannot be regulated by means of a cycle (the only cycles known in antiquity were the octaeteris (3 intercalations in 8 years) and the enneadecaeteris (7 intercalations in 19 years). Secondly, without a cycle it is difficult to establish from the number of the year (a) if it is intercalary and (b) if it is intercalary, where exactly in the year the intercalation is located. \n\nAlthough some scholars (see list above) claim that the holy months were shuffled about for convenience without the use of intercalation, there is no documentary record of the festivals of any of the holy months being observed in any month other than those they are now observed in. The Qu'ran (sura 9.37) only refers to the \"postponement\" of a sacred month. If they were shuffled as suggested, one would expect there to be a prohibition against \"anticipation\" as well. If the festivities of the sacred months were kept in season by moving them into later months, they would move through the whole twelve months in only 33 years. Had this happened, at least one writer would have mentioned it. Sura 9.36 states \"Verily, the number of months with Allah is twelve months\" and sura 37 refers to \"adjusting the number of months\". Such adjustment can only be effected by intercalation. \n\nThere are a number of indications that the intercalated calendar was similar to the Jewish calendar, whose year began in the spring. There are clues in the names of the months themselves:\n\nIn the intercalated calendar's last year (AD/CE 632), Dhu al-Hijjah corresponded to March. The Battle of the Trench in Shawwal and Dhu'l Qi'dah of AH 5 coincided with \"harsh winter weather\". Military campaigns clustered round Ramadan, when the summer heat had dissipated, and all fighting was forbidden during Rajab, at the height of summer. The invasion of Tabak in Rajab AH 9 was hampered by \"too much hot weather\" and \"drought\". In AH 1 Muhammad noted the Jews of Yathrib observing a festival when he arrived on Monday, 8 Rabi'I. Rabi'I is the third month and if it coincided with the third month of the Jewish calendar the festival would have been the Feast of Weeks, which is observed on the 6th and 7th days of that month.\n\nIn the tenth year of the Hijra, as documented in the Qur'an (Sura At-Tawba (9):36–37), Muslims believe God revealed the \"prohibition of the Nasī’\".\n\nThe prohibition of Nasī’ would presumably have been announced when the intercalated month had returned to its position just before the month of Nasi' began. If Nasī' meant intercalation, then the number and the position of the intercalary months between AH 1 and AH 10 are uncertain; western calendar dates commonly cited for key events in early Islam such as the Hijra, the Battle of Badr, the Battle of Uhud and the Battle of the Trench should be viewed with caution as they might be in error by one, two, three or even four lunar months. This prohibition was mentioned by Muhammad during the farewell sermon which was delivered on 9 Dhu al-Hijjah AH 10 (Julian date Friday 6 March, 632 AD/CE) on Mount Arafat during the farewell pilgrimage to Mecca.\n\nThe three successive sacred (forbidden) months mentioned by Prophet Muhammad (months in which battles are forbidden) are Dhu al-Qa‘dah, Dhu al-Hijjah, and Muharram, months 11, 12, and 1 respectively. The single forbidden month is Rajab, month 7. These months were considered forbidden both within the new Islamic calendar and within the old pagan Meccan calendar.\n\nFour of the twelve Hijri months are considered sacred: Rajab (7), and the three consecutive months of Dhū al-Qa‘dah (11), Dhu al-Ḥijjah (12) and Muḥarram (1). As the lunar calendar lags behind the solar calendar by about ten days every Gregorian year, months of the Islamic calendar fall in different parts of the Gregorian calendar each year. The cycle repeats every 33 lunar years.\n\nEach month of the Islamic calendar commences on the birth of the new lunar cycle. Traditionally this is based on actual observation of the crescent (\"hilal\") marking the end of the previous lunar cycle and hence the previous month, thereby beginning the new month. Consequently, each month can have 29 or 30 days depending on the visibility of the moon, astronomical positioning of the earth and weather conditions. However, certain sects and groups, most notably Bohras Muslims namely Alavis, Dawoodis and Sulaymanis and Shia Ismaili Muslims, use a tabular Islamic calendar (see section below) in which odd-numbered months have thirty days (and also the twelfth month in a leap year) and even months have 29.\n\nIn Arabic, the \"first day\" of the week corresponds with Sunday of the planetary week. The Islamic weekdays, like those in the Hebrew and Bahá'í calendars, begin at sunset. The Christian liturgical day, kept in monasteries, begins with vespers (see vesper), which is evening, in line with the other Abrahamic traditions. Christian and planetary weekdays begin at the following midnight. Muslims gather for worship at a mosque at noon on \"gathering day\" (, meaning \"day\") which corresponds with Friday.\n\nThus \"gathering day\" is often regarded as the weekly day of rest. This is frequently made official, with many Muslim countries adopting Friday and Saturday (e.g., Egypt, Saudi Arabia) or Thursday and Friday as official weekends, during which offices are closed; other countries (e.g., Iran) choose to make Friday alone a day of rest. A few others (e.g., Turkey, Pakistan, Morocco, Nigeria) have adopted the Saturday-Sunday weekend while making Friday a working day with a long midday break to allow time off for worship.\n\nIn pre-Islamic Arabia, it was customary to identify a year after a major event which took place in it. Thus, according to Islamic tradition, Abraha, governor of Yemen, then a province of the Christian Kingdom of Aksum (Ethiopia), attempted to destroy the Kaaba with an army which included several elephants. The raid was unsuccessful, but that year became known as the \"Year of the Elephant\", during which Muhammad was born (sura al-Fil). Most equate this to the year 570 AD/CE, but a minority use 571 CE.\n\nThe first ten years of the Hijra were not numbered, but were named after events in the life of Muhammad according to Abū Rayḥān al-Bīrūnī:\n\nIn AH 17 (638 AD/CE), Abu Musa Ashaari, one of the officials of the Caliph Umar in Basrah, complained about the absence of any years on the correspondence he received from Umar, making it difficult for him to determine which instructions were most recent. This report convinced Umar of the need to introduce an era for Muslims. After debating the issue with his counsellors, he decided that the first year should be the year of Muhammad's arrival at Medina (known as Yathrib, before Muhammad's arrival). Uthman ibn Affan then suggested that the months begin with Muharram, in line with the established custom of the Arabs at that time. The years of the Islamic calendar thus began with the month of Muharram in the year of Muhammad's arrival at the city of Medina, even though the actual emigration took place in Safar and Rabi' I of the intercalated calendar, two months before the commencement of Muharram in the new fixed calendar. Because of the Hijra, the calendar was named the Hijri calendar.\n\nF A Shamsi (1984) postulated that the Arabic calendar was never intercalated. According to him, the first day of the first month of the new fixed Islamic calendar (1 Muharram AH 1) was no different from what was observed at the time. The day the Prophet moved from Quba' to Medina was originally 26 Rabi' I on the pre-Islamic calendar. 1 Muharram of the new fixed calendar corresponded to Friday, 16 July 622 AD/CE, the equivalent civil tabular date (same daylight period) in the Julian calendar. The Islamic day began at the preceding sunset on the evening of 15 July. This Julian date (16 July) was determined by medieval Muslim astronomers by projecting back in time their own tabular Islamic calendar, which had alternating 30- and 29-day months in each lunar year plus eleven leap days every 30 years. For example, al-Biruni mentioned this Julian date in the year 1000 AD/CE. Although not used by either medieval Muslim astronomers or modern scholars to determine the Islamic epoch, the thin crescent moon would have also first become visible (assuming clouds did not obscure it) shortly after the preceding sunset on the evening of 15 July, 1.5 days after the associated dark moon (astronomical new moon) on the morning of 14 July.\n\nThough Cook and Crone in \"\" cite a coin from AH 17, the first surviving attested use of a Hijri calendar date alongside a date in another calendar (Coptic) is on a papyrus from Egypt in AH 22, PERF 558.\n\nDue to the fact that the Islamic calendar relies on certain variable methods of observation which are used to determine its month-start-dates, the start-dates of its months sometimes vary slightly from the month-start-dates of the astronomical lunar calendar, which are based directly on astronomical calculations. Still, the Islamic calendar seldom varies by more than three days from the astronomical-lunar-calendar system, and roughly approximates it. Both the Islamic calendar and the astronomical-lunar-calendar take no account of the solar year in their calculations, and thus both of these strictly lunar based calendar systems have no ability to reckon the timing of the four seasons of the year.\n\nIn the astronomical-lunar-calendar system, a year of 12 lunar months is 354.37 days long. In this calendar system, lunar months begin precisely at the time of the monthly \"conjunction\", when the Moon is located most directly between the Earth and the Sun. The month is defined as the average duration of a revolution of the Moon around the Earth (29.53 days). By convention, months of 30 days and 29 days succeed each other, adding up over two successive months to 59 full days. This leaves only a small monthly variation of 44 minutes to account for, which adds up to a total of 24 hours (i.e., the equivalent of one full day) in 2.73 years. To settle accounts, it is sufficient to add one day every three years to the lunar calendar, in the same way that one adds one day to the Gregorian calendar every four years. The technical details of the adjustment are described in Tabular Islamic calendar.\n\nThe Islamic calendar, however, is based on a different set of conventions being used for the determination of the month-start-dates. Each month still has either 29 or 30 days, but due to the variable method of observations employed, there is usually no discernible order in the sequencing of either 29 or 30 day month lengths. Traditionally, the first day of each month is the day (beginning at sunset) of the first sighting of the hilal (crescent moon) shortly after sunset. If the hilal is not observed immediately after the 29th day of a month (either because clouds block its view or because the western sky is still too bright when the moon sets), then the day that begins at that sunset is the 30th. Such a sighting has to be made by one or more trustworthy men testifying before a committee of Muslim leaders. Determining the most likely day that the hilal could be observed was a motivation for Muslim interest in astronomy, which put Islam in the forefront of that science for many centuries. Still, due to the fact that both lunar reckoning systems are ultimately based on the lunar cycle itself, both systems still do roughly correspond to one another, never being more than three days out of synchronisation with one another.\nThis traditional practice for the determination of the start-date of the month is still followed in the overwhelming majority of Muslim countries. Each Islamic state proceeds with its own monthly observation of the new moon (or, failing that, awaits the completion of 30 days) before declaring the beginning of a new month on its territory. But, the lunar crescent becomes visible only some 17 hours after the conjunction, and only subject to the existence of a number of favourable conditions relative to weather, time, geographic location, as well as various astronomical parameters. Given the fact that the moon sets progressively later than the sun as one goes west, with a corresponding increase in its \"age\" since conjunction, Western Muslim countries may, under favorable conditions, observe the new moon one day earlier than eastern Muslim countries. Due to the interplay of all these factors, the beginning of each month differs from one Muslim country to another, during the 48 hour period following the conjunction. The information provided by the calendar in any country does not extend beyond the current month.\n\nA number of Muslim countries try to overcome some of these difficulties by applying different astronomy-related rules to determine the beginning of months. Thus, Malaysia, Indonesia, and a few others begin each month at sunset on the first day that the moon sets after the sun (moonset after sunset). In Egypt, the month begins at sunset on the first day that the moon sets at least five minutes after the sun. A detailed analysis of the available data shows, however, that there are major discrepancies between what countries say they do on this subject, and what they actually do. In some instances, what a country says it does is impossible.\n\nDue to the somewhat variable nature of the Islamic calendar, in most Muslim countries, the Islamic calendar is used primarily for religious purposes, while the Solar-based Gregorian calendar is still used primarily for matters of commerce and agriculture.\n\nIf the Islamic calendar were prepared using astronomical calculations, Muslims throughout the Muslim world could use it to meet all their needs, the way they use the Gregorian calendar today. But, there are divergent views on whether it is licit to do so.\n\nA majority of theologians oppose the use of calculations (beyond the constraint that each month must be not less than 29 nor more than 30 days) on the grounds that the latter would not conform with Muhammad's recommendation to observe the new moon of Ramadan and Shawal in order to determine the beginning of these months.\n\nHowever, some jurists see no contradiction between Muhammad's teachings and the use of calculations to determine the beginnings of lunar months. They consider that Muhammad's recommendation was adapted to the culture of the times, and should not be confused with the acts of worship.\n\nThus the jurists Ahmad Muhammad Shakir and Yusuf al-Qaradawi both endorsed the use of calculations to determine the beginning of all months of the Islamic calendar, in 1939 and 2004 respectively. So did the Fiqh Council of North America (FCNA) in 2006 and the European Council for Fatwa and Research (ECFR) in 2007.\n\nThe major Muslim associations of France also announced in 2012 that they would henceforth use a calendar based on astronomical calculations, taking into account the criteria of the possibility of crescent sighting in any place on Earth. But, shortly after the official adoption of this rule by the French Council of the Muslim Faith (CFCM) in 2013, the new leadership of the association decided, on the eve of Ramadan 2013, to follow the Saudi announcement rather than to apply the rule just adopted. This resulted in a division of the Muslim community of France, with some members following the new rule, and others following the Saudi announcement.\n\nIsma'ili-Taiyebi Bohras having the institution of \"da'i al-mutlaq\" follow the tabular Islamic calendar (see section below) prepared on the basis of astronomical calculations from the days of Fatimid imams.\n\nTurkish Muslims use an Islamic calendar which is calculated several years in advance (currently up to 1444 AH/2022 CE) by the Turkish Presidency of Religious Affairs (Diyanet İşleri Başkanlığı). From 1 Muharrem 1400 AH (21 November 1979) until 29 Zilhicce 1435 (24 October 2014) the computed Turkish lunar calendar was based on the following rule: \"The lunar month is assumed to begin on the evening when, within some region of the terrestrial globe, the computed centre of the lunar crescent at local sunset is more than 5° above the local horizon and (geocentrically) more than 8° from the Sun.\" In the current rule the (computed) lunar crescent has to be above the local horizon of Ankara at sunset.\n\nSaudi Arabia uses the sighting method to determine the beginning of each month of the Hijri calendar. Since AH 1419 (1998/99), several official hilal sighting committees have been set up by the government to determine the first visual sighting of the lunar crescent at the beginning of each lunar month. Nevertheless, the religious authorities also allow the testimony of less experienced observers and thus often announce the sighting of the lunar crescent on a date when none of the official committees could see it.\n\nThe country also uses the Umm al-Qura calendar, based on astronomical calculations, but this is restricted to administrative purposes. The parameters used in the establishment of this calendar underwent significant changes over the past decade.\n\nBefore AH 1420 (before 18 April 1999), if the moon's age at sunset in Riyadh was at least 12 hours, then the day \"ending\" at that sunset was the first day of the month. This often caused the Saudis to celebrate holy days one or even two days before other predominantly Muslim countries, including the dates for the Hajj, which can only be dated using Saudi dates because it is performed in Mecca.\n\nFor AH 1420–22, if moonset occurred after sunset at Mecca, then the day beginning at that sunset was the first day of a Saudi month, essentially the same rule used by Malaysia, Indonesia, and others (except for the location from which the hilal was observed).\n\nSince the beginning of AH 1423 (16 March 2002), the rule has been clarified a little by requiring the geocentric conjunction of the sun and moon to occur before sunset, in addition to requiring moonset to occur after sunset at Mecca. This ensures that the moon has moved past the sun by sunset, even though the sky may still be too bright immediately before moonset to actually see the crescent.\n\nIn 2007, the Islamic Society of North America, the \"Fiqh\" Council of North America and the European Council for \"Fatwa\" and Research announced that they will henceforth use a calendar based on calculations using the same parameters as the \"Umm al-Qura\" calendar to determine (well in advance) the beginning of all lunar months (and therefore the days associated with all religious observances). This was intended as a first step on the way to unify, at some future time, Muslims' calendars throughout the world.\n\nSince 1 October 2016, as a cost-cutting measure, Saudi Arabia no longer uses the Islamic calendar for paying the monthly salaries of government employees but the Gregorian calendar.\n\nThe Solar Hijri calendar is a solar calendar used in Iran and Afghanistan which counts its years from the Hijra or migration of Muhammad from Mecca to Medina in 622 AD/CE.\n\nThe Tabular Islamic calendar is a rule-based variation of the Islamic calendar, in which months are worked out by arithmetic rules rather than by observation or astronomical calculation. It has a 30-year cycle with 11 leap years of 355 days and 19 years of 354 days. In the long term, it is accurate to one day in about 2,500 solar years or 2,570 lunar years. It also deviates up to about one or two days in the short term.\n\nMicrosoft uses the \"Kuwaiti algorithm\", a variant of the tabular Islamic calendar, to convert Gregorian dates to the Islamic ones. Microsoft claimed that the variant is based on a statistical analysis of historical data from Kuwait, however it matches a known tabular calendar.\n\nImportant dates in the Islamic (Hijri) year are:\n\nDays considered important predominantly for Shia Muslims:\n\nDays considered important for Sunni Muslims (especially in India & parts of Asia):\n\nConversions may be made by using the Tabular Islamic calendar, or, for greatest accuracy (one day in 15,186 years), via the Jewish calendar. Theoretically, the days of the months correspond in both calendars if the displacements which are a feature of the Jewish system are ignored. The table below gives, for nineteen years, the Muslim month which corresponds to the first Jewish month.\n\nThis table may be extended since every nineteen years the Muslim month number increases by seven. When it goes above twelve, subtract twelve and add one to the year AH. From 412 AD/CE to 632 AD/CE inclusive the month number is 1 and the calculation gives the month correct to a month or so. 622 AD/CE corresponds to BH 1 and AH 1. For earlier years, year BH = (623 or 622) – year AD/CE).\n\nAn example calculation: What is the civil date and year AH of the first day of the first month in the year 20875 AD/CE?\n\nWe first find the Muslim month number corresponding to the first month of the Jewish year which begins in 20874 AD/CE. Dividing 20874 by 19 gives quotient 1098 and remainder 12. Dividing 2026 by 19 gives quotient 106 and remainder 12. 2026 is chosen because it gives the same remainder on division by 19 as 20874. The two years are therefore (1098–106)=992×19 years apart. The Muslim month number corresponding to the first Jewish month is therefore 992×7=6944 higher than in 2026. To convert into years and months divide by twelve – 6944/12=578 years and 8 months. Adding, we get 1447y 10m + 20874y – 2026y + 578y 8m = 20874y 6m. Therefore, the first month of the Jewish year beginning in 20874 AD/CE corresponds to the sixth month of the Muslim year AH 20874. The worked example in Conversion between Jewish and civil dates, shows that the civil date of the first day of this month (ignoring the displacements) is Friday, 14 June. The year AH 20875 will therefore begin seven months later, on the first day of the eighth Jewish month, which the worked example shows to be 7 January, 20875 AD/CE (again ignoring the displacements). The date given by this method, being calculated, may differ by a day from the actual date, which is determined by observation.\n\nA reading of the section which follows will show that the year AH 20875 is wholly contained within the year 20875 AD/CE, also that in the Gregorian calendar this correspondence will occur one year earlier. The reason for the discrepancy is that the Gregorian year (like the Julian, though less so) is slightly too long, so the Gregorian date for a given AH date will be earlier and the Muslim calendar catches up sooner.\nAn Islamic year will be entirely within a Gregorian year of the same number in the year 20874, after which year the number of the Islamic year will always be greater than the number of the concurrent civil year. The Islamic calendar year of 1429 occurred entirely within the civil calendar year of 2008. Such years occur once every 33 or 34 Islamic years (32 or 33 civil years). More are listed here:\n\nBecause a Hijri or Islamic lunar year is between 10 and 12 days shorter than a civil year, it begins 10–12 days earlier in the civil year following the civil year in which the previous Hijri year began. Once every 33 or 34 Hijri years, or once every 32 or 33 civil years, the beginning of a Hijri year (1 Muharram) coincides with one of the first ten days of January. Subsequent Hijri New Years move backward through the civil year back to the beginning of January again, passing through each civil month from December to January.\n\nThe Islamic calendar is now used primarily for religious purposes, and for official dating of public events and documents in Muslim countries. Because of its nature as a purely lunar calendar, it cannot be used for agricultural purposes and historically Islamic communities have used other calendars for this purpose: the Egyptian calendar was formerly widespread in Islamic countries, and the Iranian calendar and the 1789 Ottoman calendar (a modified Julian calendar) were also used for agriculture in their countries. In the Levant and Iraq the Aramaic names of the Babylonian calendar are still used for all secular matters. In Morocco, the Berber calendar (another Julian calendar) is still used by farmers in the countryside. These local solar calendars have receded in importance with the near-universal adoption of the Gregorian calendar for civil purposes. The Saudi Arabia uses the lunar Islamic calendar. In Indonesia, the Javanese calendar, created by Sultan Agung in 1633, combines elements of the Islamic and pre-Islamic Saka calendars.\n\nBritish author Nicholas Hagger writes that after seizing control of Libya, Muammar Gaddafi \"declared\" on 1 December 1978 \"that the Muslim calendar should start with the death of the prophet Mohammed in 632 rather than the hijra (Mohammed's 'emigration' from Mecca to Medina) in 622\". This put the country ten solar years behind the standard Muslim calendar. However, according to the 2006 \"Encyclopedia of the Developing World\", \"More confusing still is Qaddafi's unique Libyan calendar, which counts the years from the Prophet's birth, or sometimes from his death. The months July and August, named after Julius and Augustus Caesar, are now Nasser and Hannibal respectively.\" Reflecting on a 2001 visit to the country, American reporter Neil MacFarquhar observed, \"Life in Libya was so unpredictable that people weren't even sure what year it was. The year of my visit was officially 1369. But just two years earlier Libyans had been living through 1429. No one could quite name for me the day the count changed, especially since both remained in play. ... Event organizers threw up their hands and put the Western year in parentheses somewhere in their announcements.\"\n\n\n\n"}
{"id": "14812", "url": "https://en.wikipedia.org/wiki?curid=14812", "title": "Interquartile range", "text": "Interquartile range\n\nIn descriptive statistics, the interquartile range (IQR), also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = \"Q\" −  \"Q\". In other words, the IQR is the first quartile subtracted from the third quartile; these quartiles can be clearly seen on a box plot on the data. It is a trimmed estimator, defined as the 25% trimmed range, and is a commonly used robust measure of scale.\n\nThe IQR is a measure of variability, based on dividing a data set into quartiles. Quartiles divide a rank-ordered data set into four equal parts. The values that separate parts are called the first, second, and third quartiles; and they are denoted by Q1, Q2, and Q3, respectively.\n\nUnlike total range, the interquartile range has a breakdown point of 25%, and is thus often preferred to the total range.\n\nThe IQR is used to build box plots, simple graphical representations of a probability distribution.\n\nFor a symmetric distribution (where the median equals the midhinge, the average of the first and third quartiles), half the IQR equals the median absolute deviation (MAD).\n\nThe median is the corresponding measure of central tendency.\n\nThe IQR can be used to identify outliers (see below).\n\nQuartiles are calculated recursively, by using median.\n\nIf the number of entries is an even number \"2n\", then the \"first quartile Q\" is defined as\nand the \"third quartile Q\" = median of the \"n\" largest entries\n\nIf the number of entries is an odd number \"2n+1\", then the \"first quartile Q\" is defined as\nand the \"third quartile Q\" = median of the \"n\" largest entries\n\nThe \"second quartile Q\" is the same as the ordinary median.\n\nThe following table has 13 rows, and follows the rules for the odd number of entries.\nFor the data in this table the interquartile range is IQR = Q − Q = 119 - 31 = 88.\n\nFor the data set in this box plot:\n\nThe interquartile range of a continuous distribution can be calculated by integrating the probability density function (which yields the cumulative distribution function—any other means of calculating the CDF will also work). The lower quartile, \"Q\", is a number such that integral of the PDF from -∞ to \"Q\" equals 0.25, while the upper quartile, \"Q\", is such a number that the integral from -∞ to \"Q\" equals 0.75; in terms of the CDF, the quartiles can be defined as follows:\n\nwhere CDF is the quantile function.\n\nThe interquartile range and median of some common distributions are shown below\n\nThe IQR, mean, and standard deviation of a population \"P\" can be used in a simple test of whether or not \"P\" is normally distributed, or Gaussian. If \"P\" is normally distributed, then the standard score of the first quartile, \"z\", is −0.67, and the standard score of the third quartile, \"z\", is +0.67. Given \"mean\" = \"X\" and \"standard deviation\" = σ for \"P\", if \"P\" is normally distributed, the first quartile\n\nand the third quartile\n\nIf the actual values of the first or third quartiles differ substantially from the calculated values, \"P\" is not normally distributed. However, a normal distribution can be trivially perturbed to maintain its Q1 and Q2 std. scores at 0.67 and −0.67 and not be normally distributed (so the above test would produce a false positive). A better test of normality, such as Q-Q plot would be indicated here.\n\nThe interquartile range is often used to find outliers in data. Outliers here are defined as observations that fall below Q1 − 1.5 IQR or above Q3 + 1.5 IQR. In a boxplot, the highest and lowest occurring value within this limit are indicated by \"whiskers\" of the box (frequently with an additional bar at the end of the whisker) and any outliers as individual points.\n\n"}
{"id": "14814", "url": "https://en.wikipedia.org/wiki?curid=14814", "title": "Indiana Jones", "text": "Indiana Jones\n\nDr. Henry Walton \"Indiana\" Jones, Jr. is the title character and protagonist of the \"Indiana Jones\" franchise. George Lucas created the character in homage to the action heroes of 1930s film serials. The character first appeared in the 1981 film \"Raiders of the Lost Ark\", to be followed by \"Indiana Jones and the Temple of Doom\" in 1984, \"Indiana Jones and the Last Crusade\" in 1989, \"The Young Indiana Jones Chronicles\" from 1992 to 1996, and \"Indiana Jones and the Kingdom of the Crystal Skull\" in 2008. The character is also featured in novels, comics, video games, and other media. Jones is also featured in several Disney theme parks, including the Indiana Jones Adventure, Indiana Jones et le Temple du Péril, and \"Epic Stunt Spectacular!\" attractions.\n\nJones is most famously portrayed by Harrison Ford and has also been portrayed by River Phoenix (as the young Jones in \"The Last Crusade\") and in the television series \"The Young Indiana Jones Chronicles\" by Corey Carrier, Sean Patrick Flanery, and George Hall. Doug Lee has supplied the voice of Jones for two LucasArts video games, \"Indiana Jones and the Fate of Atlantis\" and \"Indiana Jones and the Infernal Machine\", David Esch supplied his voice for \"Indiana Jones and the Emperor's Tomb\", and John Armstrong for \"Indiana Jones and the Staff of Kings\".\n\nJones is characterized by his iconic accoutrements (bullwhip, fedora, satchel, and leather jacket), wry sense of humor, deep knowledge of ancient civilizations and languages, and fear of snakes.\n\nSince his first appearance in \"Raiders of the Lost Ark\", Indiana Jones has become one of cinema's most famous characters. In 2003, the American Film Institute ranked him the second greatest film hero of all time. He was also named the 1st Greatest Movie Character by \"Empire\" magazine. \"Entertainment Weekly\" ranked Indy 2nd on their list of The All-Time Coolest Heroes in Pop Culture. \"Premiere\" magazine also placed Indy at number 7 on their list of The 100 Greatest Movie Characters of All Time.\n\n\nA native of Princeton, New Jersey, Indiana Jones was introduced as a tenured professor of archeology in the 1981 film \"Raiders of the Lost Ark\", set in 1936. The character is an adventurer reminiscent of the 1930s film serial treasure hunters and pulp action heroes. His research is funded by Marshall College (named after producer Frank Marshall), a fictional college in Connecticut, where he is a professor of archaeology. He also attended the University of Chicago.\n\nIn this first adventure, he is pitted against Nazis commissioned by Hitler to recover artifacts of great power from the Old Testament (see Nazi archaeology). In consequence, Dr Jones travels the world to prevent them from recovering the Ark of the Covenant (see also Biblical archaeology). He is aided by Marion Ravenwood and Sallah. The Nazis are led by Jones's archrival, a Nazi-sympathizing French archaeologist named René Belloq, and Arnold Toht, a sinister Gestapo agent.\n\nIn the 1984 prequel, \"Indiana Jones and the Temple of Doom\", set in 1935, Jones travels to India and attempts to free enslaved children and the three Sankara stones from the bloodthirsty Thuggee cult. He is aided by Short Round, a young boy, and is accompanied by singer Willie Scott (Kate Capshaw). The prequel is not as centered on archaeology as \"Raiders of the Lost Ark\" and is considerably darker.\n\nThe third film, 1989's \"Indiana Jones and the Last Crusade\", set in 1938, returned to the formula of the original, reintroducing characters such as Sallah and Marcus Brody, a scene from Professor Jones's classroom (he now teaches at Barnett College), the globe trotting element of multiple locations, and the return of the infamous Nazi mystics, this time trying to find the Holy Grail. The film's introduction, set in 1912, provided some back story to the character, specifically the origin of his fear of snakes, his use of a bullwhip, the scar on his chin, and his hat; the film's epilogue also reveals that \"Indiana\" is not Jones's first name, but a nickname he took from the family dog. The film was a buddy movie of sorts, teaming Jones with his father, Henry Jones, Sr., often to comical effect. Although Lucas intended to make five Indiana Jones films, \"Indiana Jones and the Last Crusade\" was the last for over eighteen years, as he could not think of a good plot element to drive the next installment.\n\nThe 2008 film, \"Indiana Jones and the Kingdom of the Crystal Skull\", is the latest film in the series. Set in 1957, 19 years after the third film, it pits an older, wiser Indiana Jones against Soviet agents bent on harnessing the power of an extraterrestrial device discovered in South America. Jones is aided in his adventure by his former lover, Marion Ravenwood (Karen Allen), and her son—a young greaser named Henry \"Mutt\" Williams (Shia LaBeouf), later revealed to be Jones' unknown child. There were rumors that Harrison Ford would not return for any future installments and LaBeouf would take over the Indy franchise. This film also reveals that Jones was recruited by the Office of Strategic Services during World War II, attaining the rank of Colonel in the United States Army. He is tasked with conducting covert operations with MI6 agent George McHale against the Soviet Union.\n\nIn March 2016, Disney announced a fifth \"Indiana Jones\" film in development, with Ford and Spielberg set to return to the franchise. Initially set for release on July 10, 2020, the film's release date was pushed back to July 9, 2021 due to production issues.\n\nIndiana Jones is featured at several Walt Disney theme park attractions. The Indiana Jones Adventure attractions at Disneyland and Tokyo DisneySea (\"Temple of the Forbidden Eye\" and \"Temple of the Crystal Skull,\" respectively) place Indy at the forefront of two similar archaeological discoveries. These two temples each contain a wrathful deity who threatens the guests who ride through in World War II troop transports. The attractions, some of the most expensive of their kind at the time, opened in 1995 and 2001, respectively, with sole design credit attributed to Walt Disney Imagineering. Disney did not originally license Harrison Ford's likeness for the American version; nonetheless, a differentiated Indiana Jones audio-animatronic character appears at three points in both attractions. However, the Indiana Jones featured in the DisneySea version does use Harrison Ford's likeness but uses Japanese audio for all of his speaking parts. In 2010, some of the Indy audio-animatronics at the Disneyland version were replaced with ones resembling Ford.\n\nDisneyland Paris also features an Indiana Jones-titled ride where people speed off through ancient ruins in a runaway mine wagon similar to that found in \"Indiana Jones and the Temple of Doom\". \"Indiana Jones and the Temple of Peril\" is a looping roller coaster engineered by Intamin, designed by Walt Disney Imagineering, and opened in 1993.\n\nThe \"Indiana Jones Epic Stunt Spectacular!\" is a live show that has been presented in the Disney's Hollywood Studios theme park of the Walt Disney World Resort with few changes since the park's 1989 opening, as Disney-MGM Studios. The 25-minute show presents various stunts framed in the context of a feature film production, and recruits members of the audience to participate in the show. Stunt artists in the show re-create and ultimately reveal some of the secrets of the stunts of the \"Raiders of the Lost Ark\" films, including the well-known \"running-from-the-boulder\" scene. Stunt performer Anislav Varbanov was fatally injured in August 2009, while rehearsing the popular show. Also at Disney's Hollywood Studios, an audio-animatronic Indiana Jones appears in another attraction; during The Great Movie Ride's \"Raiders of the Lost Ark\" segment.\n\nIndy also appears in the 2004 Dark Horse Comics story \"Into the Great Unknown\", collected in \"Star Wars Tales Volume 5\". In this non-canon story bringing together two of Harrison Ford's best-known roles, Indy and Short Round discover a crash-landed \"Millennium Falcon\" in the Pacific Northwest, along with Han Solo's skeleton and the realization that a rumored nearby Sasquatch is in fact Chewbacca. Indy also appears in a series of Marvel Comics.\n\nThe four Indiana Jones film scripts were novelized and published in the time-frame of the films' initial releases. \"Raiders of the Lost Ark\" was novelized by Campbell Black based on the script by Lawrence Kasdan that was based on the story by George Lucas and Philip Kaufman and published in April 1981 by Ballantine Books; \"Indiana Jones and the Temple of Doom\" was novelized by James Kahn and based on the script by Willard Huyck & Gloria Katz that was based on the story by George Lucas and published May 1984 by Ballantine Books; \"Indiana Jones and the Last Crusade\" was novelized by Rob MacGregor based on the script by Jeffrey Boam that was based on a story by George Lucas and Menno Meyjes and published June 1989 by Ballantine Books. Nearly 20 years later \"Indiana Jones and the Kingdom of the Crystal Skull\" was novelized by James Rollins based on the script by David Koepp based on the story by George Lucas and Jeff Nathanson and published May 2008 by Ballantine Books. In addition, in 2008 to accompany the release of \"Kingdom of Skulls\", Scholastic Books published juvenile novelizations of the four scripts written, successively in the order above, by Ryder Windham, Suzanne Weyn, Ryder Windham, and James Luceno. All these books have been reprinted, with \"Raiders of the Lost Ark\" being retitled \"Indiana Jones and the Raiders of the Lost Ark\". While these are the principal titles and authors, there are numerous other volumes derived from the four film properties.\n\nFrom February 1991 through February 1999, twelve original Indiana Jones-themed adult novels were licensed by Lucasfilm, Ltd. and written by three genre authors of the period. Ten years afterward, a thirteenth original novel was added, also written by a popular genre author. The first twelve were published by Bantam Books; the last by Ballantine Books in 2009. (See Indiana Jones (franchise) for broad descriptions of these original adult novels.) The novels are:\n\n\nFrom 1992 to 1996, George Lucas executive-produced a television series named \"The Young Indiana Jones Chronicles\", aimed mainly at teenagers and children, which showed many of the important events and historical figures of the early 20th century through the prism of Indiana Jones' life.\nThe show initially featured the formula of an elderly (93 to 94 years of age) Indiana Jones played by George Hall introducing a story from his youth by way of an anecdote: the main part of the episode then featured an adventure with either a young adult Indy (16 to 21 years of age) played by Sean Patrick Flanery or a child Indy (8 to 11 years) played by Corey Carrier. One episode, \"Young Indiana Jones and the Mystery of the Blues\", is bookended by Harrison Ford as Indiana Jones, rather than Hall. Later episodes and telemovies did not have this bookend format.\n\nThe bulk of the series centers around the young adult Indiana Jones and his activities during World War I as a 16- to 17-year-old soldier in the Belgian Army and then as an intelligence officer and spy seconded to French intelligence. The child Indy episodes follow the boy's travels around the globe as he accompanies his parents on his father's worldwide lecture tour from 1908 to 1910.\n\nThe show provided some backstory for the films, as well as new information regarding the character. Indiana Jones was born July 1, 1899, and his middle name is Walton (Lucas's middle name). It is also mentioned that he had a sister called Suzie who died as an infant of fever, and that he eventually has a daughter and grandchildren who appear in some episode introductions and epilogues. His relationship with his father, first introduced in \"Indiana Jones and the Last Crusade\", was further fleshed out with stories about his travels with his father as a young boy. Indy damages or loses his right eye sometime between the events in 1957 and the early 1990s, when the \"Old Indy\" segments take place, as the elderly Indiana Jones wears an eyepatch.\n\nIn 1999, Lucas removed the episode introductions and epilogues by George Hall for the VHS and DVD releases, and re-edited the episodes into chronologically ordered feature-length stories. The series title was also changed to \"The Adventures of Young Indiana Jones\".\n\nThe character has appeared in several officially licensed games, beginning with adaptations of \"Raiders of the Lost Ark\", \"Indiana Jones and the Temple of Doom\", two adaptations of \"Indiana Jones and the Last Crusade\" (one with purely action mechanics, one with an adventure and puzzle based structure) and \"Indiana Jones' Greatest Adventures\", which included the storylines from all three of the original films.\n\nFollowing this, the games branched off into original storylines with Indiana Jones in the Lost Kingdom, \"Indiana Jones and the Fate of Atlantis\", \"Indiana Jones and the Infernal Machine\", \"Indiana Jones and the Emperor's Tomb\" and \"Indiana Jones and the Staff of Kings\". \"Emperor's Tomb\" sets up Jones's companion Wu Han and the search for Nurhaci's ashes seen at the beginning of \"Temple of Doom\". The first two games were developed by Hal Barwood and starred Doug Lee as the voice of Indiana Jones; \"Emperor's Tomb\" had David Esch fill the role and \"Staff of Kings\" starred John Armstrong.\n\n\"Indiana Jones and the Infernal Machine\" was the first Indy-based game presented in three dimensions, as opposed to 8-bit graphics and side-scrolling games before.\n\nThere is also a small game from Lucas Arts \"Indiana Jones and His Desktop Adventures\". A video game was made for young Indy called \"Young Indiana Jones and the Instruments of Chaos\", as well as a video game version of \"The Young Indiana Jones Chronicles\".\n\nTwo Lego Indiana Jones games have also been released. \"\" was released in 2008 and follows the plots of the first three films. It was followed by \"\" in late 2009. The sequel includes an abbreviated reprise of the first three films, but focuses on the plot of \"Indiana Jones and the Kingdom of the Crystal Skull\".\n\nSocial gaming company Zynga introduced Indiana Jones to their \"Adventure World\" game in late 2011.\n\n\"Indiana\" Jones's full name is Dr. Henry Walton Jones Jr., and his nickname is often shortened to \"Indy\".\n\nIn his role as a college professor of archaeology, Jones is scholarly and learned in a tweed suit, lecturing on ancient civilizations. At the opportunity to recover important artifacts, Dr. Jones transforms into \"Indiana,\" a \"non-superhero superhero\" image he has concocted for himself. Producer Frank Marshall said, \"Indy [is] a fallible character. He makes mistakes and gets hurt. ... That's the other thing people like: He's a real character, not a character with superpowers.\" Spielberg said there \"was the willingness to allow our leading man to get hurt and to express his pain and to get his mad out and to take pratfalls and sometimes be the butt of his own jokes. I mean, Indiana Jones is not a perfect hero, and his imperfections, I think, make the audience feel that, with a little more exercise and a little more courage, they could be just like him.\" According to Spielberg biographer Douglas Brode, Indiana created his heroic figure so as to escape the dullness of teaching at a school. Both of Indiana's personas reject one another in philosophy, creating a duality. Harrison Ford said the fun of playing the character was that Indiana is both a romantic and a cynic, while scholars have analyzed Indiana as having traits of a lone wolf; a man on a quest; a noble treasure hunter; a hardboiled detective; a human superhero; and an American patriot.\n\nLike many characters in his films, Jones has some autobiographical elements of Spielberg. Indiana lacks a proper father figure because of his strained relationship with his father, Henry Senior. His own contained anger is misdirected towards Professor Abner Ravenwood, his mentor at the University of Chicago, leading to a strained relationship with Marion Ravenwood. The teenage Indiana bases his own look on a figure from the prologue of \"Indiana Jones and the Last Crusade\", after being given his hat. Marcus Brody acts as Indiana's positive role model at the college. Indiana's own insecurities are made worse by the absence of his mother. In \"Indiana Jones and the Temple of Doom\", he becomes the father figure to Willie Scott and Short Round, to survive; he is rescued from Kali's evil by Short Round's dedication. Indiana also saves many enslaved children.\n\nIndiana uses his knowledge of Shiva to defeat Mola Ram. In \"Raiders of the Lost Ark\", he is wise enough to close his eyes in the presence of God in the Ark of the Covenant. By contrast, his rival Rene Belloq is killed for having the audacity to try to communicate directly with God.\n\nIn the prologue of \"Indiana Jones and the Last Crusade\", Jones is seen as a teenager, establishing his look when given a fedora hat. Indiana's intentions are revealed as prosocial, as he believes artifacts \"belong in a museum.\" In the film's climax, Indiana undergoes \"literal\" tests of faith to retrieve the Grail and save his father's life. He also remembers Jesus as a historical figure – a humble carpenter – rather than an exalted figure when he recognizes the simple nature and tarnished appearance of the real Grail amongst a large assortment of much more ornately decorated ones. Henry Senior rescues his son from falling to his death when reaching for the fallen Grail, telling him to \"let it go,\" overcoming his mercenary nature. \"The Young Indiana Jones Chronicles\" explains how Indiana becomes solitary and less idealistic following his service in World War I. In \"Indiana Jones and the Kingdom of the Crystal Skull\", Jones is older and wiser, whereas his sidekicks Mutt and Mac are youthfully arrogant and greedy, respectively.\n\nIndiana Jones is modeled after the strong-jawed heroes of the matinée serials and pulp magazines that George Lucas and Steven Spielberg enjoyed in their childhoods (such as the Republic Pictures serials, and the Doc Savage series). Sir H. Rider Haggard's safari guide/big game hunter Allan Quatermain of \"King Solomon's Mines\" is a notable template for Jones. The two friends first discussed the project in Hawaii around the time of the release of the first \"Star Wars\" film. Spielberg told Lucas how he wanted his next project to be something fun, like a \"James Bond\" film (this would later be referenced when they cast Sean Connery as Henry Jones Sr.). According to sources, Lucas responded to the effect that he had something \"even better\", or that he'd \"got that beat.\"\n\nOne of the possible bases for Indiana Jones is Professor Challenger, created by Sir Arthur Conan Doyle in 1912 for his novel, \"The Lost World\". Challenger was based on Doyle's physiology professor, William Rutherford, an adventuring academic, albeit a zoologist/anthropologist.\n\nAnother important influence on the development of the character Indiana Jones is the Disney character Scrooge McDuck. Carl Barks created Scrooge in 1948 as a one-off relation for Donald Duck in the patter's self-titled comic book. Barks realized that the character had more potential, so a separate \"Uncle Scrooge\" comic book series full of exciting and strange adventures in the company of his duck nephews was developed. This \"Uncle Scrooge\" comic series strongly influenced George Lucas. This appreciation of Scrooge as an adventurer influenced the development of Jones, with the prologue of \"Raiders of the Lost Ark\" containing homage to Barks' Scrooge adventure ″The Seven Cities of Cibola,″ published in \"Uncle Scrooge\" #7 from September 1954. This homage in the film takes the form of playfully mimicking the removal-of-the-statuette-from-its-pedestal and the falling-stone sequences of the comic book.\n\nThe character was originally named Indiana Smith, after an Alaskan Malamute called Indiana that Lucas owned in the 1970s and on which he based the Star Wars character Chewbacca. Spielberg disliked the name Smith, and Lucas casually suggested Jones as an alternative. The \"Last Crusade\" script references the name's origin, with Jones's father revealing his son's birth name to be Henry and explaining that \"we named the \"dog\" Indiana\", to his son's chagrin. Some have also posited that C.L. Moore’s science fiction character Northwest Smith may have also influenced Lucas and Spielberg in their naming choice.\n\nLucas has said on various occasions that Sean Connery's portrayal of British secret agent James Bond was one of the primary inspirations for Jones, a reason Connery was chosen for the role of Indiana's father in \"Indiana Jones and the Last Crusade\". Spielberg earned the rank of Eagle Scout and Ford the Life Scout badge in their youth, which gave them the inspiration to portray Indiana Jones as a Life Scout at age 13 in \"The Last Crusade\".\n\nCostume designer Deborah Nadoolman Landis noted that the inspiration for the series as well as Indiana Jones' outfit was Charlton Heston's Harry Steele in \"Secret of the Incas\" (1954) and called \"Raiders of the Lost Ark\" \"almost a shot for shot\" remake of the Heston film, stating that Indiana Jones was \"a kinder, gentler Harry Steele.\" Landis also stated that \"We did watch this film together as a crew several times, and I always thought it strange that the filmmakers did not credit it later as the inspiration for the series.\"\n\nMany people are said to be the real-life inspiration of the Indiana Jones character—although none of the following have been confirmed as inspirations by Lucas or Spielberg. There are some suggestions listed here in alphabetical order by last name:\n\nUpon requests by Spielberg and Lucas, the costume designer gave the character a distinctive silhouette through the styling of the hat; after examining many hats, the designers chose a tall-crowned, wide-brimmed fedora. As a documentary of \"Raiders\" pointed out, the hat served a practical purpose. Following the lead of the old \"B\"-movies that inspired the \"Indiana Jones\" series, the fedora hid the actor's face sufficiently to allow doubles to perform the more dangerous stunts seamlessly. Examples in \"Raiders\" include the wider-angle shot of Indy and Marion crashing a statue through a wall, and Indy sliding under a fast-moving vehicle from front to back. Thus it was necessary for the hat to stay in place much of the time.\n\nThe hat became so iconic that the filmmakers could only come up with very good reasons or jokes to remove it. If it ever fell off during a take, filming would have to stop to put it back on. In jest, Ford put a stapler against his head to stop his hat from falling off when a documentary crew visited during shooting of \"Indiana Jones and the Last Crusade\". This created the urban legend that Ford stapled the hat to his head. Anytime Indy's hat accidentally came off as part of the storyline (blown off by the wind, knocked off, etc.) and seemed almost irretrievable, filmmakers would make sure Indy and his hat were always reunited, regardless of the implausibility of its return. Although other hats were also used throughout the films, the general style and profile remained the same. Elements of the outfit include:\n\nThe fedora and leather jacket from \"Indiana Jones and the Last Crusade\" are on display at the Smithsonian Institution's American History Museum in Washington, D.C. The collecting of props and clothing from the films has become a thriving hobby for some aficionados of the franchise. Jones' whip was the third most popular film weapon, as shown by a 2008 poll held by 20th Century Fox, which surveyed approximately two thousand film fans.\n\nOriginally, Spielberg suggested Harrison Ford; Lucas resisted the idea, since he had already cast the actor in \"American Graffiti\", \"Star Wars\" and \"The Empire Strikes Back\", and did not want Ford to become known as his \"Bobby De Niro\" (in reference to the fact that fellow director Martin Scorsese regularly casts Robert De Niro in his films). During an intensive casting process, Lucas and Spielberg auditioned many actors, and finally cast actor Tom Selleck as Indiana Jones. Shortly afterward pre-production began in earnest on \"Raiders of the Lost Ark\". However, CBS refused to release Selleck from his contractual commitment to \"Magnum, P.I.\" (which was gradually gaining momentum in the ratings), forcing him to turn down the role. One of CBS's concerns was that shooting for \"Magnum P.I.\" conflicted with shooting for \"Raiders\", both of which were to begin about the same time. However, Selleck was to say later in an interview that shooting for \"Magnum P.I.\" was delayed and did not actually begin until shooting for \"Raiders\" had concluded.\n\nSubsequently, both Peter Coyote and Tim Matheson auditioned for the role. However, after Spielberg suggested Ford again, Lucas relented, and Ford was cast in the role less than three weeks before filming began.\n\nThe industry magazine \"Archaeology\" named eight past and present archaeologists who they felt \"embodied [Jones'] spirit\" as recipients of the Indy Spirit Awards in 2008. That same year Ford himself was elected to the Board of Directors for the Archaeological Institute of America. Commenting that \"understanding the past can only help us in dealing with the present and the future,\" Ford was praised by the association's president for his character's \"significant role in stimulating the public's interest in archaeological exploration.\"\n\nHe is perhaps the most influential character in films that explore archaeology. Since the release of \"Raiders of the Lost Ark\" in 1981, the very idea of archaeology and archaeologists has fundamentally shifted. Prior to the film's release, the stereotypical image of an archaeologist was that of an older, lackluster professor type. In the early years of films involving archaeologists, they were portrayed as victims who would need to be rescued by a more masculine or heroic figure. Following 1981, the stereotypical archaeologist was thought of as an adventurer consistently engaged in fieldwork.\n\nArcheologist Anne Pyburn described the influence of Indiana Jones as elitist and sexist, and argued that the film series had caused new discoveries in the field of archaeology to become oversimplified and overhyped in an attempt to gain public interest, which negatively influences archaeology as a whole. Eric Powell, an editor with the magazine \"Archaeology\", said \"O.K., fine, the movie romanticizes what we do\", and that \"Indy may be a horrible archeologist, but he's a great diplomat for archeology. I think we'll see a spike in kids who want to become archeologists\". Kevin McGeoughs, associate professor of archaeology, describes the original archaeological criticism of the film as missing the point of the film: \"dramatic interest is what is at issue, and it is unlikely that film will change in order to promote and foster better archaeological techniques\".\n\nWhile himself an homage to various prior adventurers, aspects of Indiana Jones also directly influenced some subsequent characterizations:\n\n"}
{"id": "14822", "url": "https://en.wikipedia.org/wiki?curid=14822", "title": "Irreducible fraction", "text": "Irreducible fraction\n\nAn irreducible fraction (or fraction in lowest terms or reduced fraction) is a fraction in which the numerator and denominator are integers that have no other common divisors than 1 (and -1, when negative numbers are considered). In other words, a fraction ⁄ is irreducible if and only if \"a\" and \"b\" are coprime, that is, if \"a\" and \"b\" have a greatest common divisor of 1. In higher mathematics, \"irreducible fraction\" may also refer to rational fractions such that the numerator and the denominator are coprime polynomials. Every positive rational number can be represented as an irreducible fraction in exactly one way.\n\nAn equivalent definition is sometimes useful: if \"a\", \"b\" are integers, then the fraction ⁄ is irreducible if and only if there is no other equal fraction ⁄ such that |\"c\"| < |\"a\"| or |\"d\"| < |\"b\"|, where |\"a\"| means the absolute value of \"a\". (Two fractions ⁄ and ⁄ are \"equal\" or \"equivalent\" if and only if \"ad\" = \"bc\".)\n\nFor example, ⁄, ⁄, and ⁄ are all irreducible fractions. On the other hand, ⁄ is reducible since it is equal in value to ⁄, and the numerator of ⁄ is less than the numerator of ⁄.\n\nA fraction that is reducible can be reduced by dividing both the numerator and denominator by a common factor. It can be fully reduced to lowest terms if both are divided by their greatest common divisor. In order to find the greatest common divisor, the Euclidean algorithm or prime factorization may be used. The Euclidean algorithm is commonly preferred because it allows one to reduce fractions with numerators and denominators too large to be easily factored.\n\nIn the first step both numbers were divided by 10, which is a factor common to both 120 and 90. In the second step, they were divided by 3. The final result, /, is an irreducible fraction because 4 and 3 have no common factors other than 1.\n\nThe original fraction could have also been reduced in a single step by using the greatest common divisor of 90 and 120, which is 30 (i.e., gcd(90,120)=30).\n\nWhich method is faster \"by hand\" depends on the fraction and the ease with which common factors are spotted. In case a denominator and numerator remain that are too large to ensure they are coprime by inspection, a greatest common divisor computation is needed anyway to ensure the fraction is actually irreducible.\n\nEvery rational number has a \"unique\" representation as an irreducible fraction with a positive denominator (however formula_3 although both are irreducible). Uniqueness is a consequence of the unique prime factorization of integers, since formula_4 implies \"ad\" = \"bc\" and so both sides of the latter must share the same prime factorization, yet formula_5 and formula_6 share no prime factors so the set of prime factors of formula_5 (with multiplicity) is a subset of those of formula_8 and vice versa meaning formula_9 and formula_10.\n\nThe fact that any rational number has a unique representation as an irreducible fraction is utilized in various proofs of the irrationality of the square root of 2 and of other irrational numbers. For example, one proof notes that if the square root of 2 could be represented as a ratio of integers, then it would have in particular the fully reduced representation formula_11 where \"a\" and \"b\" are the smallest possible; but given that formula_11 equals the square root of 2, so does formula_13 (since cross-multiplying this with formula_11 shows that they are equal). Since the latter is a ratio of smaller integers, this is a contradiction, so the premise that the square root of two has a representation as the ratio of two integers is false.\n\nThe notion of irreducible fraction generalizes to the field of fractions of any unique factorization domain: any element of such a field can be written as a fraction in which denominator and numerator are coprime, by dividing both by their greatest common divisor. This applies notably to rational expressions over a field. The irreducible fraction for a given element is unique up to multiplication of denominator and numerator by the same invertible element. In the case of the rational numbers this means that any number has two irreducible fractions, related by a change of sign of both numerator and denominator; this ambiguity can be removed by requiring the denominator to be positive. In the case of rational functions the denominator could similarly be required to be a monic polynomial.\n\n"}
{"id": "14826", "url": "https://en.wikipedia.org/wiki?curid=14826", "title": "Isomorphism class", "text": "Isomorphism class\n\nAn isomorphism class is a collection of mathematical objects isomorphic to each other.\n\nIsomorphism classes are often defined if the exact identity of the elements of the set is considered irrelevant, and the properties of the structure of the mathematical object are studied. Examples of this are ordinals and graphs. However, there are circumstances in which the isomorphism class of an object conceals vital internal information about it; consider these examples:\n"}
{"id": "14828", "url": "https://en.wikipedia.org/wiki?curid=14828", "title": "Isomorphism", "text": "Isomorphism\n\nIn mathematics, an isomorphism (from the Ancient Greek: ἴσος \"isos\" \"equal\", and μορφή \"morphe\" \"form\" or \"shape\") is a homomorphism or morphism (i.e. a mathematical mapping) that can be reversed by an inverse morphism. Two mathematical objects are isomorphic if an isomorphism exists between them. An \"automorphism\" is an isomorphism whose source and target coincide. The interest of isomorphisms lies in the fact that two isomorphic objects cannot be distinguished by using only the properties used to define morphisms; thus isomorphic objects may be considered the same as long as one considers only these properties and their consequences.\n\nFor most algebraic structures, including groups and rings, a homomorphism is an isomorphism if and only if it is bijective.\n\nIn topology, where the morphisms are continuous functions, isomorphisms are also called \"homeomorphisms\" or \"bicontinuous functions\". In mathematical analysis, where the morphisms are differentiable functions, isomorphisms are also called \"diffeomorphisms\".\n\nA canonical isomorphism is a canonical map that is an isomorphism. Two objects are said to be canonically isomorphic if there is a canonical isomorphism between them. For example, the canonical map from a finite-dimensional vector space \"V\" to its second dual space is a canonical isomorphism; on the other hand, \"V\" is isomorphic to its dual space but not canonically in general.\n\nIsomorphisms are formalized using category theory. A morphism in a category is an isomorphism if it admits a two-sided inverse, meaning that there is another morphism in that category such that and , where 1 and 1 are the identity morphisms of \"X\" and \"Y\", respectively.\n\nLet formula_1 be the multiplicative group of positive real numbers, and let formula_2 be the additive group of real numbers.\n\nThe logarithm function formula_3 satisfies formula_4 for all formula_5, so it is a group homomorphism. The exponential function formula_6 satisfies formula_7 for all formula_8, so it too is a homomorphism.\n\nThe identities formula_9 and formula_10 show that formula_11 and formula_12 are inverses of each other. Since formula_11 is a homomorphism that has an inverse that is also a homomorphism, formula_11 is an isomorphism of groups.\n\nBecause formula_11 is an isomorphism, it translates multiplication of positive real numbers into addition of real numbers. This facility makes it possible to multiply real numbers using a ruler and a table of logarithms, or using a slide rule with a logarithmic scale.\n\nConsider the group formula_16, the integers from 0 to 5 with addition modulo 6. Also consider the group formula_17, the ordered pairs where the \"x\" coordinates can be 0 or 1, and the y coordinates can be 0, 1, or 2, where addition in the \"x\"-coordinate is modulo 2 and addition in the \"y\"-coordinate is modulo 3.\n\nThese structures are isomorphic under addition, under the following scheme:\n\nor in general mod 6.\n\nFor example, , which translates in the other system as .\n\nEven though these two groups \"look\" different in that the sets contain different elements, they are indeed isomorphic: their structures are exactly the same. More generally, the direct product of two cyclic groups formula_18 and formula_19 is isomorphic to formula_20 if and only if \"m\" and \"n\" are coprime, per the Chinese remainder theorem.\n\nIf one object consists of a set \"X\" with a binary relation R and the other object consists of a set \"Y\" with a binary relation S then an isomorphism from \"X\" to \"Y\" is a bijective function such that:\n\nS is reflexive, irreflexive, symmetric, antisymmetric, asymmetric, transitive, total, trichotomous, a partial order, total order, well-order, strict weak order, total preorder (weak order), an equivalence relation, or a relation with any other special properties, if and only if R is.\n\nFor example, R is an ordering ≤ and S an ordering formula_22, then an isomorphism from \"X\" to \"Y\" is a bijective function such that\nSuch an isomorphism is called an \"order isomorphism\" or (less commonly) an \"isotone isomorphism\".\n\nIf , then this is a relation-preserving automorphism.\n\nIn a concrete category (that is, roughly speaking, a category whose objects are sets and morphisms are mappings between sets), such as the category of topological spaces or categories of algebraic objects like groups, rings, and modules, an isomorphism must be bijective on the underlying sets. In algebraic categories (specifically, categories of varieties in the sense of universal algebra), an isomorphism is the same as a homomorphism which is bijective on underlying sets. However, there are concrete categories in which bijective morphisms are not necessarily isomorphisms (such as the category of topological spaces), and there are categories in which each object admits an underlying set but in which isomorphisms need not be bijective (such as the homotopy category of CW-complexes).\n\nIn abstract algebra, two basic isomorphisms are defined:\n\nJust as the automorphisms of an algebraic structure form a group, the isomorphisms between two algebras sharing a common structure form a heap. Letting a particular isomorphism identify the two structures turns this heap into a group.\n\nIn mathematical analysis, the Laplace transform is an isomorphism mapping hard differential equations into easier algebraic equations.\n\nIn category theory, let the category \"C\" consist of two classes, one of \"objects\" and the other of morphisms. Then a general definition of isomorphism that covers the previous and many other cases is: an isomorphism is a morphism that has an inverse, i.e. there exists a morphism with and . For example, a bijective linear map is an isomorphism between vector spaces, and a bijective continuous function whose inverse is also continuous is an isomorphism between topological spaces, called a homeomorphism.\n\nIn graph theory, an isomorphism between two graphs \"G\" and \"H\" is a bijective map \"f\" from the vertices of \"G\" to the vertices of \"H\" that preserves the \"edge structure\" in the sense that there is an edge from vertex \"u\" to vertex \"v\" in \"G\" if and only if there is an edge from ƒ(\"u\") to ƒ(\"v\") in \"H\". See graph isomorphism.\n\nIn mathematical analysis, an isomorphism between two Hilbert spaces is a bijection preserving addition, scalar multiplication, and inner product.\n\nIn early theories of logical atomism, the formal relationship between facts and true propositions was theorized by Bertrand Russell and Ludwig Wittgenstein to be isomorphic. An example of this line of thinking can be found in Russell's \"Introduction to Mathematical Philosophy\".\n\nIn cybernetics, the good regulator or Conant–Ashby theorem is stated \"Every good regulator of a system must be a model of that system\". Whether regulated or self-regulating, an isomorphism is required between the regulator and processing parts of the system.\n\nIn certain areas of mathematics, notably category theory, it is valuable to distinguish between \"equality\" on the one hand and \"isomorphism\" on the other. Equality is when two objects are exactly the same, and everything that's true about one object is true about the other, while an isomorphism implies everything that's true about a designated part of one object's structure is true about the other's. For example, the sets\nare \"equal\"; they are merely different representations—the first an intensional one (in set builder notation), and the second extensional (by explicit enumeration)—of the same subset of the integers. By contrast, the sets {\"A\",\"B\",\"C\"} and {1,2,3} are not \"equal\"—the first has elements that are letters, while the second has elements that are numbers. These are isomorphic as sets, since finite sets are determined up to isomorphism by their cardinality (number of elements) and these both have three elements, but there are many choices of isomorphism—one isomorphism is\nand no one isomorphism is intrinsically better than any other. On this view and in this sense, these two sets are not equal because one cannot consider them \"identical\": one can choose an isomorphism between them, but that is a weaker claim than identity—and valid only in the context of the chosen isomorphism.\n\nSometimes the isomorphisms can seem obvious and compelling, but are still not equalities. As a simple example, the genealogical relationships among Joe, John, and Bobby Kennedy are, in a real sense, the same as those among the American football quarterbacks in the Manning family: Archie, Peyton, and Eli. The father-son pairings and the elder-brother-younger-brother pairings correspond perfectly. That similarity between the two family structures illustrates the origin of the word \"isomorphism\" (Greek \"iso\"-, \"same,\" and -\"morph\", \"form\" or \"shape\"). But because the Kennedys are not the same people as the Mannings, the two genealogical structures are merely isomorphic and not equal.\n\nAnother example is more formal and more directly illustrates the motivation for distinguishing equality from isomorphism: the distinction between a finite-dimensional vector space \"V\" and its dual space } of linear maps from \"V\" to its field of scalars K.\nThese spaces have the same dimension, and thus are isomorphic as abstract vector spaces (since algebraically, vector spaces are classified by dimension, just as sets are classified by cardinality), but there is no \"natural\" choice of isomorphism formula_28.\nIf one chooses a basis for \"V\", then this yields an isomorphism: For all ,\n\nThis corresponds to transforming a column vector (element of \"V\") to a row vector (element of \"V\"*) by transpose, but a different choice of basis gives a different isomorphism: the isomorphism \"depends on the choice of basis\".\nMore subtly, there \"is\" a map from a vector space \"V\" to its double dual } that does not depend on the choice of basis: For all \n\nThis leads to a third notion, that of a natural isomorphism: while \"V\" and \"V\"** are different sets, there is a \"natural\" choice of isomorphism between them.\nThis intuitive notion of \"an isomorphism that does not depend on an arbitrary choice\" is formalized in the notion of a natural transformation; briefly, that one may \"consistently\" identify, or more generally map from, a finite-dimensional vector space to its double dual, formula_31, for \"any\" vector space in a consistent way.\nFormalizing this intuition is a motivation for the development of category theory.\n\nHowever, there is a case where the distinction between natural isomorphism and equality is usually not made. That is for the objects that may be characterized by a universal property. In fact, there is a unique isomorphism, necessarily natural, between two objects sharing the same universal property. A typical example is the set of real numbers, which may be defined through infinite decimal expansion, infinite binary expansion, Cauchy sequences, Dedekind cuts and many other ways. Formally these constructions define different objects, which all are solutions of the same universal property. As these objects have exactly the same properties, one may forget the method of construction and considering them as equal. This is what everybody does when talking of \"\"the\" set of the real numbers\". The same occurs with quotient spaces: they are commonly constructed as sets of equivalence classes. However, talking of set of sets may be counterintuitive, and quotient spaces are commonly considered as a pair of a set of undetermined objects, often called \"points\", and a surjective map onto this set.\n\nIf one wishes to draw a distinction between an arbitrary isomorphism (one that depends on a choice) and a natural isomorphism (one that can be done consistently), one may write for an unnatural isomorphism and for a natural isomorphism, as in and \nThis convention is not universally followed, and authors who wish to distinguish between unnatural isomorphisms and natural isomorphisms will generally explicitly state the distinction.\n\nGenerally, saying that two objects are \"equal\" is reserved for when there is a notion of a larger (ambient) space that these objects live in. Most often, one speaks of equality of two subsets of a given set (as in the integer set example above), but not of two objects abstractly presented. For example, the 2-dimensional unit sphere in 3-dimensional space\n\nwhich can be presented as the one-point compactification of the complex plane } \"or\" as the complex projective line (a quotient space)\n\nare three different descriptions for a mathematical object, all of which are isomorphic, but not \"equal\" because they are not all subsets of a single space: the first is a subset of R, the second is plus an additional point, and the third is a subquotient of C\n\nIn the context of category theory, objects are usually at most isomorphic—indeed, a motivation for the development of category theory was showing that different constructions in homology theory yielded equivalent (isomorphic) groups. Given maps between two objects \"X\" and \"Y\", however, one asks if they are equal or not (they are both elements of the set Hom(\"X\", \"Y\"), hence equality is the proper relationship), particularly in commutative diagrams.\n\n\n"}
{"id": "14829", "url": "https://en.wikipedia.org/wiki?curid=14829", "title": "Infinite descending chain", "text": "Infinite descending chain\n\nGiven a set \"S\" with a partial order ≤, an infinite descending chain is an infinite, strictly decreasing sequence of elements \"x > x > ... > x > ...\"\n\nAs an example, in the set of integers, the chain −1, −2, −3, ... is an infinite descending chain, but there exists no infinite descending chain on the natural numbers, as every chain of natural numbers has a minimal element.\n\nIf a partially ordered set does not possess any infinite descending chains, it is said then, that it satisfies the descending chain condition. Assuming the axiom of choice, the descending chain condition on a partially ordered set is equivalent to requiring that the corresponding strict order is well-founded. A stronger condition, that there be no infinite descending chains and no infinite antichains, defines the well-quasi-orderings. A totally ordered set without infinite descending chains is called well-ordered.\n\n\n"}
{"id": "14832", "url": "https://en.wikipedia.org/wiki?curid=14832", "title": "Intergovernmental organization", "text": "Intergovernmental organization\n\nHypergovernmental organization or international governmental organisation (IGO) is an organization composed primarily of sovereign states (referred to as \"member states\"), or of other intergovernmental organizations. Intergovernmental organizations are called international organizations, although that term may also include international non-governmental organization such as international nonprofit organizations or multinational corporations.\nIntergovernmental organizations are an important aspect of public international law. IGOs are established by a treaty that acts as a charter creating the group. Treaties are formed when lawful representatives (governments) of several states go through a ratification process, providing the IGO with an international legal personality.\n\nIntergovernmental organizations in a legal sense should be distinguished from simple groupings or coalitions of states, such as the G8 or the Quartet. Such groups or associations have not been founded by a constituent document and exist only as task groups.\n\nIntergovernmental organizations must also be distinguished from treaties. Many treaties (such as the North American Free Trade Agreement, or the General Agreement on Tariffs and Trade before the establishment of the World Trade Organization) do not establish an organization and instead rely purely on the parties for their administration becoming legally recognized as an \"ad hoc\" commission. Other treaties have established an administrative apparatus which was not deemed to have been granted international legal personality.\n\nIntergovernmental organizations differ in function, membership, and membership criteria. They have various goals and scopes, often outlined in the treaty or charter. Some IGOs developed to fulfill a need for a neutral forum for debate or negotiation to resolve disputes. Others developed to carry out mutual interests with unified aims to preserve peace through conflict resolution and better international relations, promote international cooperation on matters such as environmental protection, to promote human rights, to promote social development (education, health care), to render humanitarian aid, and to economic development. Some are more general in scope (the United Nations) while others may have subject-specific missions (such as Interpol or the International Organization for Standardization and other standards organizations). Common types include:\n\n\nMission:\n\n\nMembership:\n\n193 Member States. Membership is \"...open to all other peace-loving states which accept the obligations contained in the present Charter and, in the judgment of the Organization, are able and willing to carry out these obligations.\"\n\nMission\n\n\"The Parties to this Treaty reaffirm their faith in the purposes and principles of the Charter of the United Nations and their desire to live in peace with all people and all governments. They are determined to safeguard the freedom, common heritage and civilization of their peoples, founded on the principles of democracy, individual liberty and the rule of law. They seek to promote stability and well-being in the North Atlantic area.\nThey are resolved to unite their efforts for collective defense and for the preservation of peace and security. They therefore agree to this North Atlantic Treaty.\"\n\nMembership\n\n\"NATO is an Alliance that consists of 29 independent member countries.\"\n\nMission\n\n\nMission\n\nThe Islamic Development Bank is an international financial institution established in pursuance of the Declaration of Intent issued by the Conference of Finance Ministers of Muslim Countries held in Jeddah in Dhul Q'adah 1393H, corresponding to December 1973. The Inaugural Meeting of the Board of Governors took place in Rajab 1395H, corresponding to July 1975, and the Bank was formally opened on 15 Shawwal 1395H corresponding to 20 October 1975. \n\nMembership\n\n188 member countries made up of government-owned organizations.\n\nINBAR evolved from an informal network of bamboo and rattan researchers set up in 1984 by the International Development Research Centre (IDRC) of Canada. In 1993 the network was formalized under its present name, but remained a project of IDRC. Work to launch INBAR as an independent organization started in 1995, and was completed in 1997 when INBAR became an independent organization with its headquarters in Beijing, China – the first intergovernmental organization to be headquartered in the People's Republic.\nMembership and structure\n\nMembership\n\n42 member countries make up this organisation.\n\nWhile treaties, alliances, and multilateral conferences had existed for centuries, IGOs only began to be established in the 19th century. Among the first were the Central Commission for Navigation on the Rhine, initiated in the aftermath of the Napoleonic Wars, and the International Telegraph Union (the future International Telecommunication Union), which was founded by the signing of the International Telegraph Convention by 20 countries in May 1865. Of notable significance was the emergence of the League of Nations following World War One, designed as an institution to foster collective security in order to sustain peace.\n\nHeld and McGrew (2002) counted thousands of IGOs worldwide, and this number continues to rise. This increase may be attributed to globalization, which increases and encourages the cooperation among and within states. Globalization has also provided easier means for IGO growth, as a result of increased international relations. This is seen economically, politically, militarily, as well as on the domestic level. Economically, IGOs gain material and non-material resources for economic prosperity. IGOs also provide more political stability within the state and among differing states. Military alliances are also formed by establishing common standards in order to ensure security of the members to ward off outside threats. Lastly, the formation has encouraged autocratic states to develop into democracies in order to form an effective and internal government.\n\nThere are several different reasons a state may choose membership in an intergovernmental organization. But there are also reasons membership may be rejected. These reasons are explored in the sections below.\n\nReasons for participation:\nReasons for rejecting membership:\n\nIntergovernmental organizations are provided with privileges and immunities that are intended to ensure their independent and effective functioning. They are specified in the treaties that give rise to the organization (such as the Convention on the Privileges and Immunities of the United Nations and the Agreement on the Privileges and Immunities of the International Criminal Court), which are normally supplemented by further multinational agreements and national regulations (for example the International Organizations Immunities Act in the United States). The organizations are thereby immune from the jurisdiction of national courts.\n\nRather than by national jurisdiction, legal accountability is intended to be ensured by legal mechanisms that are internal to the intergovernmental organization itself and access to administrative tribunals. In the course of many court cases where private parties tried to pursue claims against international organizations, there has been a gradual realization that alternate means of dispute settlement are required, as states have fundamental human rights obligations to provide plaintiffs with access to court in view of their right to a fair trial. Otherwise, the organizations' immunities may be put in question in national and international courts. Some organizations hold proceedings before tribunals relating to their organization to be confidential, and in some instances have threatened disciplinary action should an employee disclose any of the relevant information. Such confidentiality has been criticized as a lack of transparency.\n\nThe immunities also extend to employment law. In this regard, immunity from national jurisdiction necessitates that reasonable alternative means are available to effectively protect employees' rights; in this context, a first instance Dutch court considered an estimated duration of proceedings before the Administrative Tribunal of the International Labour Organization of 15 years to be too long.\n\nThese are some of the strengths and weaknesses of IGOs:\n\nStrengths:\n\nWeaknesses:\n\nThey can be deemed unfair as countries with a higher percentage voting power have the right to veto any decision that is not in their favor, leaving the smaller countries powerless.\n\n\n"}
{"id": "14836", "url": "https://en.wikipedia.org/wiki?curid=14836", "title": "International Telecommunication Union", "text": "International Telecommunication Union\n\nThe International Telecommunication Union (ITU; (UIT)), originally the International Telegraph Union (), is a specialized agency of the United Nations (UN) that is responsible for issues that concern information and communication technologies. It is the oldest among all the 15 specialised agencies of UN.\n\nThe ITU coordinates the shared global use of the radio spectrum, promotes international cooperation in assigning satellite orbits, works to improve telecommunication infrastructure in the developing world, and assists in the development and coordination of worldwide technical standards. The ITU is active in areas including broadband Internet, latest-generation wireless technologies, aeronautical and maritime navigation, radio astronomy, satellite-based meteorology, convergence in fixed-mobile phone, Internet access, data, voice, TV broadcasting, and next-generation networks. The agency also organizes worldwide and regional exhibitions and forums, such as ITU Telecom World, bringing together representatives of government and the telecommunications and ICT industry to exchange ideas, knowledge and technology.\n\nITU, based in Geneva, Switzerland, is a member of the United Nations Development Group, and has 12 regional and area offices in the world. ITU has been an intergovernmental public–private partnership organization since its inception. Its membership includes 193 Member States and around 800 public and private sector companies, and academic institutions as well as international and regional telecommunication entities, known as Sector Members and Associates, which undertake most of the work of each Sector.\n\nITU was formed in 1865, in Paris, at the International Telegraph Convention; this makes it one of the oldest intergovernmental organizations in the world. The International Radiotelegraph Union was unofficially established at first International Radiotelegraph Convention in 1906. Both were merged into the International Telecommunication Union in 1932. ITU became a United Nations specialized agency in 1947.\n\nThe ITU comprises three sectors, each managing a different aspect of the matters handled by the Union, as well as ITU Telecom. The sectors were created during the restructuring of ITU at its 1992 Plenipotentiary Conference.\n\nA permanent General Secretariat, headed by the Secretary General, manages the day-to-day work of the Union and its sectors.\n\nThe basic texts of the ITU are adopted by the ITU Plenipotentiary Conference. The founding document of the ITU was the 1865 International Telegraph Convention, which has since been amended several times and is now entitled the \"Constitution and Convention of the International Telecommunication Union\". In addition to the Constitution and Convention, the consolidated basic texts include the Optional Protocol on the settlement of disputes, the Decisions, Resolutions and Recommendations in force, as well as the General Rules of Conferences, Assemblies and Meetings of the Union.\n\nThe ITU is headed by a Secretary-General, a Deputy Secretary General and the three directors of the Bureaux, who are elected to a four-year terms by the member states at the ITU Plenipotentiary Conference. \n\nOn 23 October 2014 Houlin Zhao was elected 19th Secretary-General of the ITU at the Plenipotentiary Conference in Busan, Republic of Korea. His four-year mandate started on 1 January 2015, and he was formally inaugurated on 15 January 2015. Houlin Zhao was reelected at the 2018 Plenipotentiary Conference in Dubai.\n\nMembership of ITU is open to only Member States of the United Nations, which may join the Union as Member States, as well as to private organizations like carriers, equipment manufacturers, funding bodies, research and development organizations and international and regional telecommunication organizations, which may join ITU as non-voting Sector Members.\n\nThere are 193 Member States of the ITU, including all UN member states except the Republic of Palau, plus the Vatican City. The most recent member state to join the ITU is South Sudan, which became a member on 14 July 2011.\n\nThe Republic of China (Taiwan) was blocked from membership by the People's Republic of China, but nevertheless received a country code, being listed as \"Taiwan, China\". Palestine was admitted as an observer in 2010.\n\nSix Regional Offices and seven Area Offices guarantee a regional presence of ITU:\nRegional Office for CSI (in Moscow)\nAfrica Regional Office in Addis Ababa, with Area Offices in Dakar, Harare and Yaoundé\nArab States Regional Office in Cairo\nAsia-Pacific Regional Office in Bangkok, with Area Office in Jakarta\nAmerica Regional Office in Brasilia, with Area Offices in Bridgetown, Santiago and Tegucigalpa.\nThe sixth is a Coordination office for Europe Region Europe at ITU Headquarters.\n\nOther Regional organizations, connected to ITU, are: \n\nThe ITU was one of the UN agencies responsible for convening the World Summit on the Information Society (WSIS), along with UNESCO, UNCTAD and UNDP. The Summit was held as two conferences in 2003 and 2005 in Geneva and Tunis, respectively, with the aim of bridging the digital divide.\n\nIn December 2012, the ITU facilitated The World Conference on International Telecommunications 2012 (WCIT-12) in Dubai. WCIT-12 was a treaty-level conference to address International Telecommunications Regulations, the international rules for telecommunications, including international tariffs. The previous conference to update the Regulations (ITRs) was held in Melbourne in 1988.\n\nIn August 2012, ITU called for a public consultation on a draft document ahead of the conference. It is claimed the proposal would allow government restriction or blocking of information disseminated via the internet and create a global regime of monitoring internet communications, including the demand that those who send and receive information identify themselves. It would also allow governments to shut down the internet if there is the belief that it may interfere in the internal affairs of other states or that information of a sensitive nature might be shared.\n\nTelecommunications ministers from 193 countries attended the conference in Dubai.\n\nThe current regulatory structure was based on voice telecommunications, when the Internet was still in its infancy. In 1988, telecommunications operated under regulated monopolies in most countries. As the Internet has grown, organizations such as ICANN have come into existence to manage key resources such as Internet addresses and Domain Names. Some outside the United States believe that the United States exerts too much influence over the governance of the Internet.\n\nCurrent proposals look to take into account the prevalence of data communications. Proposals under consideration would establish regulatory oversight by the UN over security, fraud, traffic accounting as well as traffic flow, management of Internet Domain Names and IP addresses, and other aspects of the Internet that are currently governed either by community-based approaches such as Regional Internet Registries, ICANN, or largely national regulatory frameworks. The move by the ITU and some countries has alarmed many within the United States and within the Internet community. Indeed, some European telecommunication services have proposed a so-called \"sender pays\" model that would require sources of Internet traffic to pay destinations, similar to the way funds are transferred between countries using the telephone.\n\nThe WCIT-12 activity has been attacked by Google, which has characterized it as a threat to the \"...free and open internet.\"\n\nOn 22 November 2012, the European Parliament passed a resolution urging member states to prevent ITU WCIT-12 activity that would \"negatively impact the internet, its architecture, operations, content and security, business relations, internet governance and the free flow of information online\". The resolution asserted that \"the ITU [...] is not the appropriate body to assert regulatory authority over the internet\".\n\nOn 5 December 2012, the lower chamber of the United States Congress passed a resolution opposing U.N. governance of the Internet by a rare unanimous 397–0 vote. The resolution warned that \"... proposals have been put forward for consideration at the [WCIT-12] that would fundamentally alter the governance and operation of the Internet ... [and] would attempt to justify increased government control over the Internet ...\", and stated that the policy of the United States is \"... to promote a global Internet free from government control and preserve and advance the successful Multistakeholder Model that governs the Internet today.\" The same resolution had previously been passed unanimously by the upper chamber of the Congress in September.\n\nOn 14 December 2012, an amended version of the Regulations was signed by 89 of the 152 countries. Countries that did not sign included the United States, Japan, Canada, Germany, New Zealand, India and the United Kingdom. The Head of the U.S. Delegation, Terry Kramer, said \"We cannot support a treaty that is not supportive of the multistakeholder model of Internet governance\".\n\nThe conference itself was managed by the International Telecommunication Union (ITU). While certain parts of civil society and industry were able to advise and observe, active participation was restricted to member states. The Electronic Frontier Foundation expressed concern at this, calling for a more transparent multi-stakeholder process. Some leaked contributions can be found on the wcitleaks.org web site. Google-affiliated researchers have suggested that the ITU should completely reform its processes to align itself with the openness and participation of other multistakeholder organizations concerned with the Internet.\n\n"}
{"id": "14837", "url": "https://en.wikipedia.org/wiki?curid=14837", "title": "Internet Message Access Protocol", "text": "Internet Message Access Protocol\n\nIn computing, the Internet Message Access Protocol (IMAP) is an Internet standard protocol used by email clients to retrieve email messages from a mail server over a TCP/IP connection. IMAP is defined by RFC 3501.\n\nIMAP was designed with the goal of permitting complete management of an email box by multiple email clients, therefore clients generally leave messages on the server until the user explicitly deletes them. An IMAP server typically listens on port number 143. IMAP over SSL (IMAPS) is assigned the port number 993.\n\nVirtually all modern e-mail clients and servers support IMAP, which along with the earlier POP3 (Post Office Protocol) are the two most prevalent standard protocols for email retrieval. Many webmail service providers such as Gmail, Outlook.com and Yahoo! Mail also provide support for either IMAP or POP3.\n\nThe Internet Message Access Protocol is an Application Layer Internet protocol that allows an e-mail client to access e-mail on a remote mail server. The current version is defined by RFC 3501. An IMAP server typically listens on well-known port 143, while IMAP over SSL (IMAPS) uses 993.\n\nIncoming e-mail messages are sent to an e-mail server that stores messages in the recipient's e-mail box. The user retrieves the messages with an e-mail client that uses one of a number of e-mail retrieval protocols. While some clients and servers preferentially use vendor-specific, proprietary protocols, almost all support POP and IMAP for retrieving e-mail - allowing many free choice between many e-mail clients such as Pegasus Mail or Mozilla Thunderbird to access these servers, and allows the clients to be used with other servers.\n\nE-mail clients using IMAP generally leave messages on the server until the user explicitly deletes them. This and other characteristics of IMAP operation allow multiple clients to manage the same mailbox. Most e-mail \"clients\" support IMAP in addition to Post Office Protocol (POP) to retrieve messages. IMAP offers access to the mail storage. Clients may store local copies of the messages, but these are considered to be a temporary cache.\n\nIMAP was designed by Mark Crispin in 1986 as a remote access mailbox protocol, in contrast to the widely used POP, a protocol for simply retrieving the contents of a mailbox.\n\nIt went through a number of iterations before the current VERSION 4rev1 (MAPI4), as detailed below:\n\nThe original \"Interim Mail Access Protocol\" was implemented as a Xerox Lisp machine client and a TOPS-20 server.\n\nNo copies of the original interim protocol specification or its software exist. Although some of its commands and responses were similar to IMAP2, the interim protocol lacked command/response tagging and thus its syntax was incompatible with all other versions of IMAP.\n\nThe interim protocol was quickly replaced by the \"Interactive Mail Access Protocol\" (IMAP2), defined in RFC 1064 (in 1988) and later updated by RFC 1176 (in 1990). IMAP2 introduced the command/response tagging and was the first publicly distributed version.\n\nIMAP3 is an extremely rare variant of IMAP. It was published as RFC 1203 in 1991. It was written specifically as a counter proposal to RFC 1176, which itself proposed modifications to IMAP2. IMAP3 was never accepted by the marketplace. The IESG reclassified RFC1203 \"Interactive Mail Access Protocol - Version 3\" as a Historic protocol in 1993. The IMAP Working Group used RFC1176 (IMAP2) rather than RFC1203 (IMAP3) as its starting point.\n\nWith the advent of MIME, IMAP2 was extended to support MIME body structures and add mailbox management functionality (create, delete, rename, message upload) that was absent from IMAP2. This experimental revision was called IMAP2bis; its specification was never published in non-draft form. An internet draft of IMAP2bis was published by the IETF IMAP Working Group in October 1993. This draft was based upon the following earlier specifications: unpublished \"IMAP2bis.TXT\" document, RFC1176, and RFC1064 (IMAP2). The \"IMAP2bis.TXT\" draft documented the state of extensions to IMAP2 as of December 1992. Early versions of Pine were widely distributed with IMAP2bis support (Pine 4.00 and later supports IMAP4rev1).\n\nAn IMAP Working Group formed in the IETF in the early 1990s took over responsibility for the IMAP2bis design. The IMAP WG decided to rename IMAP2bis to IMAP4 to avoid confusion.\n\nWhen using POP, clients typically connect to the e-mail server briefly, only as long as it takes to download new messages. When using IMAP4, clients often stay connected as long as the user interface is active and download message content on demand. For users with many or large messages, this IMAP4 usage pattern can result in faster response times.\n\nThe POP protocol requires the currently connected client to be the only client connected to the mailbox. In contrast, the IMAP protocol specifically allows simultaneous access by multiple clients and provides mechanisms for clients to detect changes made to the mailbox by other, concurrently connected, clients. See for example RFC3501 section 5.2 which specifically cites \"simultaneous access to the same mailbox by multiple agents\" as an example.\n\nUsually all Internet e-mail is transmitted in MIME format, allowing messages to have a tree structure where the leaf nodes are any of a variety of single part content types and the non-leaf nodes are any of a variety of multipart types. The IMAP4 protocol allows clients to retrieve any of the individual MIME parts separately and also to retrieve portions of either individual parts or the entire message. These mechanisms allow clients to retrieve the text portion of a message without retrieving attached files or to stream content as it is being fetched.\n\nThrough the use of flags defined in the IMAP4 protocol, clients can keep track of message state: for example, whether or not the message has been read, replied to, or deleted. These flags are stored on the server, so different clients accessing the same mailbox at different times can detect state changes made by other clients. POP provides no mechanism for clients to store such state information on the server so if a single user accesses a mailbox with two different POP clients (at different times), state information—such as whether a message has been accessed—cannot be synchronized between the clients. The IMAP4 protocol supports both predefined system flags and client-defined keywords. System flags indicate state information such as whether a message has been read. Keywords, which are not supported by all IMAP servers, allow messages to be given one or more tags whose meaning is up to the client. IMAP keywords should not be confused with proprietary labels of web-based e-mail services which are sometimes translated into IMAP folders by the corresponding proprietary servers.\n\nIMAP4 clients can create, rename, and/or delete mailboxes (usually presented to the user as folders) on the server, and copy messages between mailboxes. Multiple mailbox support also allows servers to provide access to shared and public folders. The \"IMAP4 Access Control List (ACL) Extension\" (RFC 4314) may be used to regulate access rights.\n\nIMAP4 provides a mechanism for a client to ask the server to search for messages meeting a variety of criteria. This mechanism avoids requiring clients to download every message in the mailbox in order to perform these searches.\n\nReflecting the experience of earlier Internet protocols, IMAP4 defines an explicit mechanism by which it may be extended. Many IMAP4 extensions to the base protocol have been proposed and are in common use. IMAP2bis did not have an extension mechanism, and POP now has one defined by RFC 2449.\n\nWhile IMAP remedies many of the shortcomings of POP, this inherently introduces additional complexity. Much of this complexity (e.g., multiple clients accessing the same mailbox at the same time) is compensated for by server-side workarounds such as Maildir or database backends.\n\nThe IMAP specification has been criticised for being insufficiently strict and allowing behaviours that effectively negate its usefulness. For instance, the specification states that each message stored on the server has a \"unique id\" to allow the clients to identify messages they have already seen between sessions. However, the specification also allows these UIDs to be invalidated with no restrictions, practically defeating their purpose.\n\nUnless the mail storage and searching algorithms on the server are carefully implemented, a client can potentially consume large amounts of server resources when searching massive mailboxes.\n\nIMAP4 clients need to maintain a TCP/IP connection to the IMAP server in order to be notified of the arrival of new mail. Notification of mail arrival is done through in-band signaling, which contributes to the complexity of client-side IMAP protocol handling somewhat. A private proposal, push IMAP, would extend IMAP to implement push e-mail by sending the entire message instead of just a notification. However, push IMAP has not been generally accepted and current IETF work has addressed the problem in other ways (see the Lemonade Profile for more information).\n\nUnlike some proprietary protocols which combine sending and retrieval operations, sending a message and saving a copy in a server-side folder with a base-level IMAP client requires transmitting the message content twice, once to SMTP for delivery and a second time to IMAP to store in a sent mail folder. This is addressed by a set of extensions defined by the IETF Lemonade Profile for mobile devices: URLAUTH (RFC 4467) and CATENATE (RFC 4469) in IMAP and BURL (RFC 4468) in SMTP-SUBMISSION. In addition to this, Courier Mail Server offers a non-standard method of sending using IMAP by copying an outgoing message to a dedicated outbox folder.\n\nSTARTTLS can be used to provide secure communications between the MUA communicating with the MSA or MTA implementing the SMTP Protocol.\n\nThis is an example IMAP connection as taken from RFC 3501 section 8:\n\n\n\n"}
{"id": "14838", "url": "https://en.wikipedia.org/wiki?curid=14838", "title": "Inertial frame of reference", "text": "Inertial frame of reference\n\nAn inertial frame of reference in classical physics and special relativity is a frame of reference in which a body with zero net force acting upon it is not accelerating; that is, such a body is at rest or it is moving at a constant speed in a straight line. In analytical terms, it is a frame of reference that describes time and space homogeneously, isotropically, and in a time-independent manner. Conceptually, the physics of a system in an inertial frame have no causes external to the system. An inertial frame of reference may also be called an inertial reference frame, inertial frame, Galilean reference frame, or inertial space.\n\nAll inertial frames are in a state of constant, rectilinear motion with respect to one another; an accelerometer moving with any of them would detect zero acceleration. Measurements in one inertial frame can be converted to measurements in another by a simple transformation (the Galilean transformation in Newtonian physics and the Lorentz transformation in special relativity). In general relativity, in any region small enough for the curvature of spacetime and tidal forces to be negligible, one can find a set of inertial frames that approximately describe that region.\n\nIn a non-inertial reference frame in classical physics and special relativity, the physics of a system vary depending on the acceleration of that frame with respect to an inertial frame, and the usual physical forces must be supplemented by fictitious forces. In contrast, systems in non-inertial frames in general relativity don't have external causes, because of the principle of geodesic motion. In classical physics, for example, a ball dropped towards the ground does not go exactly straight down because the Earth is rotating, which means the frame of reference of an observer on Earth is not inertial. The physics must account for the Coriolis effect—in this case thought of as a force—to predict the horizontal motion. Another example of such a fictitious force associated with rotating reference frames is the centrifugal effect, or centrifugal force.\n\nThe motion of a body can only be described relative to something else—other bodies, observers, or a set of space-time coordinates. These are called frames of reference. If the coordinates are chosen badly, the laws of motion may be more complex than necessary. For example, suppose a free body that has no external forces acting on it is at rest at some instant. In many coordinate systems, it would begin to move at the next instant, even though there are no forces on it. However, a frame of reference can always be chosen in which it remains stationary. Similarly, if space is not described uniformly or time independently, a coordinate system could describe the simple flight of a free body in space as a complicated zig-zag in its coordinate system. Indeed, an intuitive summary of inertial frames can be given: in an inertial reference frame, the laws of mechanics take their simplest form.\n\nIn an inertial frame, Newton's first law, the \"law of inertia\", is satisfied: Any free motion has a constant magnitude and direction. Newton's second law for a particle takes the form:\n\nwith F the net force (a vector), \"m\" the mass of a particle and a the acceleration of the particle (also a vector) which would be measured by an observer at rest in the frame. The force F is the vector sum of all \"real\" forces on the particle, such as electromagnetic, gravitational, nuclear and so forth. In contrast, Newton's second law in a rotating frame of reference, rotating at angular rate \"Ω\" about an axis, takes the form:\n\nwhich looks the same as in an inertial frame, but now the force F′ is the resultant of not only F, but also additional terms (the paragraph following this equation presents the main points without detailed mathematics):\n\nwhere the angular rotation of the frame is expressed by the vector Ω pointing in the direction of the axis of rotation, and with magnitude equal to the angular rate of rotation \"Ω\", symbol × denotes the vector cross product, vector x locates the body and vector v is the velocity of the body according to a rotating observer (different from the velocity seen by the inertial observer).\n\nThe extra terms in the force F′ are the \"fictitious\" forces for this frame, whose causes are external to the system in the frame. The first extra term is the Coriolis force, the second the centrifugal force, and the third the Euler force. These terms all have these properties: they vanish when \"Ω\" = 0; that is, they are zero for an inertial frame (which, of course, does not rotate); they take on a different magnitude and direction in every rotating frame, depending upon its particular value of Ω; they are ubiquitous in the rotating frame (affect every particle, regardless of circumstance); and they have no apparent source in identifiable physical sources, in particular, matter. Also, fictitious forces do not drop off with distance (unlike, for example, nuclear forces or electrical forces). For example, the centrifugal force that appears to emanate from the axis of rotation in a rotating frame increases with distance from the axis.\n\nAll observers agree on the real forces, F; only non-inertial observers need fictitious forces. The laws of physics in the inertial frame are simpler because unnecessary forces are not present.\n\nIn Newton's time the fixed stars were invoked as a reference frame, supposedly at rest relative to absolute space. In reference frames that were either at rest with respect to the fixed stars or in uniform translation relative to these stars, Newton's laws of motion were supposed to hold. In contrast, in frames accelerating with respect to the fixed stars, an important case being frames rotating relative to the fixed stars, the laws of motion did not hold in their simplest form, but had to be supplemented by the addition of fictitious forces, for example, the Coriolis force and the centrifugal force. Two experiments were devised by Newton to demonstrate how these forces could be discovered, thereby revealing to an observer that they were not in an inertial frame: the example of the tension in the cord linking two spheres rotating about their center of gravity, and the example of the curvature of the surface of water in a rotating bucket. In both cases, application of Newton's second law would not work for the rotating observer without invoking centrifugal and Coriolis forces to account for their observations (tension in the case of the spheres; parabolic water surface in the case of the rotating bucket).\n\nAs we now know, the fixed stars are not fixed. Those that reside in the Milky Way turn with the galaxy, exhibiting proper motions. Those that are outside our galaxy (such as nebulae once mistaken to be stars) participate in their own motion as well, partly due to expansion of the universe, and partly due to peculiar velocities. The Andromeda galaxy is on collision course with the Milky Way at a speed of 117 km/s. The concept of inertial frames of reference is no longer tied to either the fixed stars or to absolute space. Rather, the identification of an inertial frame is based upon the simplicity of the laws of physics in the frame. In particular, the absence of fictitious forces is their identifying property.\n\nIn practice, although not a requirement, using a frame of reference based upon the fixed stars as though it were an inertial frame of reference introduces very little discrepancy. For example, the centrifugal acceleration of the Earth because of its rotation about the Sun is about thirty million times greater than that of the Sun about the galactic center.\n\nTo illustrate further, consider the question: \"Does our Universe rotate?\" To answer, we might attempt to explain the shape of the Milky Way galaxy using the laws of physics, although other observations might be more definitive, that is, provide larger discrepancies or less measurement uncertainty, like the anisotropy of the microwave background radiation or Big Bang nucleosynthesis. The flatness of the Milky Way depends on its rate of rotation in an inertial frame of reference. If we attribute its apparent rate of rotation entirely to rotation in an inertial frame, a different \"flatness\" is predicted than if we suppose part of this rotation actually is due to rotation of the universe and should not be included in the rotation of the galaxy itself. Based upon the laws of physics, a model is set up in which one parameter is the rate of rotation of the Universe. If the laws of physics agree more accurately with observations in a model with rotation than without it, we are inclined to select the best-fit value for rotation, subject to all other pertinent experimental observations. If no value of the rotation parameter is successful and theory is not within observational error, a modification of physical law is considered, for example, dark matter is invoked to explain the galactic rotation curve. So far, observations show any rotation of the universe is very slow, no faster than once every 60·10 years (10 rad/yr), and debate persists over whether there is \"any\" rotation. However, if rotation were found, interpretation of observations in a frame tied to the universe would have to be corrected for the fictitious forces inherent in such rotation in classical physics and special relativity, or interpreted as the curvature of spacetime and the motion of matter along the geodesics in general relativity.\n\nWhen quantum effects are important, there are additional conceptual complications that arise in quantum reference frames.\n\nAccording to the first postulate of special relativity, all physical laws take their simplest form in an inertial frame, and there exist multiple inertial frames interrelated by uniform translation: \nThis simplicity manifests in that inertial frames have self-contained physics without the need for external causes, while physics in non-inertial frames have external causes. The principle of simplicity can be used within Newtonian physics as well as in special relativity; see Nagel and also Blagojević.\nIn practical terms, the equivalence of inertial reference frames means that scientists within a box moving uniformly cannot determine their absolute velocity by any experiment. Otherwise, the differences would set up an absolute standard reference frame. According to this definition, supplemented with the constancy of the speed of light, inertial frames of reference transform among themselves according to the Poincaré group of symmetry transformations, of which the Lorentz transformations are a subgroup. In Newtonian mechanics, which can be viewed as a limiting case of special relativity in which the speed of light is infinite, inertial frames of reference are related by the Galilean group of symmetries.\n\nNewton posited an absolute space considered well approximated by a frame of reference stationary relative to the fixed stars. An inertial frame was then one in uniform translation relative to absolute space. However, some scientists (called \"relativists\" by Mach), even at the time of Newton, felt that absolute space was a defect of the formulation, and should be replaced.\n\nIndeed, the expression \"inertial frame of reference\" () was coined by Ludwig Lange in 1885, to replace Newton's definitions of \"absolute space and time\" by a more operational definition. As translated by Iro, Lange proposed the following definition:\n\nA discussion of Lange's proposal can be found in Mach.\n\nThe inadequacy of the notion of \"absolute space\" in Newtonian mechanics is spelled out by Blagojević: \nThe utility of operational definitions was carried much further in the special theory of relativity. Some historical background including Lange's definition is provided by DiSalle, who says in summary:\n\nWithin the realm of Newtonian mechanics, an inertial frame of reference, or inertial reference frame, is one in which Newton's first law of motion is valid. However, the principle of special relativity generalizes the notion of inertial frame to include all physical laws, not simply Newton's first law.\n\nNewton viewed the first law as valid in any reference frame that is in uniform motion relative to the fixed stars; that is, neither rotating nor accelerating relative to the stars. Today the notion of \"absolute space\" is abandoned, and an inertial frame in the field of classical mechanics is defined as:\n\nHence, with respect to an inertial frame, an object or body accelerates only when a physical force is applied, and (following Newton's first law of motion), in the absence of a net force, a body at rest will remain at rest and a body in motion will continue to move uniformly—that is, in a straight line and at constant speed. Newtonian inertial frames transform among each other according to the Galilean group of symmetries.\n\nIf this rule is interpreted as saying that straight-line motion is an indication of zero net force, the rule does not identify inertial reference frames because straight-line motion can be observed in a variety of frames. If the rule is interpreted as defining an inertial frame, then we have to be able to determine when zero net force is applied. The problem was summarized by Einstein:\nThere are several approaches to this issue. One approach is to argue that all real forces drop off with distance from their sources in a known manner, so we have only to be sure that a body is far enough away from all sources to ensure that no force is present. A possible issue with this approach is the historically long-lived view that the distant universe might affect matters (Mach's principle). Another approach is to identify all real sources for real forces and account for them. A possible issue with this approach is that we might miss something, or account inappropriately for their influence, perhaps, again, due to Mach's principle and an incomplete understanding of the universe. A third approach is to look at the way the forces transform when we shift reference frames. Fictitious forces, those that arise due to the acceleration of a frame, disappear in inertial frames, and have complicated rules of transformation in general cases. On the basis of universality of physical law and the request for frames where the laws are most simply expressed, inertial frames are distinguished by the absence of such fictitious forces.\n\nNewton enunciated a principle of relativity himself in one of his corollaries to the laws of motion: \n\nThis principle differs from the special principle in two ways: first, it is restricted to mechanics, and second, it makes no mention of simplicity. It shares with the special principle the invariance of the form of the description among mutually translating reference frames. The role of fictitious forces in classifying reference frames is pursued further below.\n\nInertial and non-inertial reference frames can be distinguished by the absence or presence of fictitious forces, as explained shortly. \nThe presence of fictitious forces indicates the physical laws are not the simplest laws available so, in terms of the special principle of relativity, a frame where fictitious forces are present is not an inertial frame:\n\nBodies in non-inertial reference frames are subject to so-called \"fictitious\" forces (pseudo-forces); that is, forces that result from the acceleration of the reference frame itself and not from any physical force acting on the body. Examples of fictitious forces are the centrifugal force and the Coriolis force in rotating reference frames.\n\nHow then, are \"fictitious\" forces to be separated from \"real\" forces? It is hard to apply the Newtonian definition of an inertial frame without this separation. For example, consider a stationary object in an inertial frame. Being at rest, no net force is applied. But in a frame rotating about a fixed axis, the object appears to move in a circle, and is subject to centripetal force (which is made up of the Coriolis force and the centrifugal force). How can we decide that the rotating frame is a non-inertial frame? There are two approaches to this resolution: one approach is to look for the origin of the fictitious forces (the Coriolis force and the centrifugal force). We will find there are no sources for these forces, no associated force carriers, no originating bodies. A second approach is to look at a variety of frames of reference. For any inertial frame, the Coriolis force and the centrifugal force disappear, so application of the principle of special relativity would identify these frames where the forces disappear as sharing the same and the simplest physical laws, and hence rule that the rotating frame is not an inertial frame.\n\nNewton examined this problem himself using rotating spheres, as shown in Figure 2 and Figure 3. He pointed out that if the spheres are not rotating, the tension in the tying string is measured as zero in every frame of reference. If the spheres only appear to rotate (that is, we are watching stationary spheres from a rotating frame), the zero tension in the string is accounted for by observing that the centripetal force is supplied by the centrifugal and Coriolis forces in combination, so no tension is needed. If the spheres really are rotating, the tension observed is exactly the centripetal force required by the circular motion. Thus, measurement of the tension in the string identifies the inertial frame: it is the one where the tension in the string provides exactly the centripetal force demanded by the motion as it is observed in that frame, and not a different value. That is, the inertial frame is the one where the fictitious forces vanish.\n\nSo much for fictitious forces due to rotation. However, for linear acceleration, Newton expressed the idea of undetectability of straight-line accelerations held in common:\nThis principle generalizes the notion of an inertial frame. For example, an observer confined in a free-falling lift will assert that he himself is a valid inertial frame, even if he is accelerating under gravity, so long as he has no knowledge about anything outside the lift. So, strictly speaking, inertial frame is a relative concept. With this in mind, we can define inertial frames collectively as a set of frames which are stationary or moving at constant velocity with respect to each other, so that a single inertial frame is defined as an element of this set.\n\nFor these ideas to apply, everything observed in the frame has to be subject to a base-line, common acceleration shared by the frame itself. That situation would apply, for example, to the elevator example, where all objects are subject to the same gravitational acceleration, and the elevator itself accelerates at the same rate.\n\nInertial navigation systems used a cluster of gyroscopes and accelerometers to determine accelerations relative to inertial space. After a gyroscope is spun up in a particular orientation in inertial space, the law of conservation of angular momentum requires that it retain that orientation as long as no external forces are applied to it. Three orthogonal gyroscopes establish an inertial reference frame, and the accelerators measure acceleration relative to that frame. The accelerations, along with a clock, can then be used to calculate the change in position. Thus, inertial navigation is a form of dead reckoning that requires no external input, and therefore cannot be jammed by any external or internal signal source.\n\nA gyrocompass, employed for navigation of seagoing vessels, finds the geometric north. It does so, not by sensing the Earth's magnetic field, but by using inertial space as its reference. The outer casing of the gyrocompass device is held in such a way that it remains aligned with the local plumb line. When the gyroscope wheel inside the gyrocompass device is spun up, the way the gyroscope wheel is suspended causes the gyroscope wheel to gradually align its spinning axis with the Earth's axis. Alignment with the Earth's axis is the only direction for which the gyroscope's spinning axis can be stationary with respect to the Earth and not be required to change direction with respect to inertial space. After being spun up, a gyrocompass can reach the direction of alignment with the Earth's axis in as little as a quarter of an hour.\n\nClassical theories that use the Galilean transformation postulate the equivalence of all inertial reference frames. Some theories may even postulate the existence of a privileged frame which provides absolute space and absolute time. The Galilean transformation transforms coordinates from one inertial reference frame, formula_4, to another, formula_5, by simple addition or subtraction of corrdinates:\n\nwhere r and \"t\" represent shifts in the origin of space and time, and v is the relative velocity of the two inertial reference frames. Under Galilean transformations, the time \"t\" − \"t\" between two events is the same for all reference frames and the distance between two simultaneous events (or, equivalently, the length of any object, |r − r|) is also the same.\n\nEinstein's theory of special relativity, like Newtonian mechanics, postulates the equivalence of all inertial reference frames. However, because special relativity postulates that the speed of light in free space is invariant, the transformation between inertial frames is the Lorentz transformation, not the Galilean transformation which is used in Newtonian mechanics. The invariance of the speed of light leads to counter-intuitive phenomena, such as time dilation and length contraction, and the relativity of simultaneity, which have been extensively verified experimentally. The Lorentz transformation reduces to the Galilean transformation as the speed of light approaches infinity or as the relative velocity between frames approaches zero.\n\nGeneral relativity is based upon the principle of equivalence:\nThis idea was introduced in Einstein's 1907 article \"Principle of Relativity and Gravitation\" and later developed in 1911. Support for this principle is found in the Eötvös experiment, which determines whether the ratio of inertial to gravitational mass is the same for all bodies, regardless of size or composition. To date no difference has been found to a few parts in 10. For some discussion of the subtleties of the Eötvös experiment, such as the local mass distribution around the experimental site (including a quip about the mass of Eötvös himself), see Franklin.\n\nEinstein’s general theory modifies the distinction between nominally \"inertial\" and \"noninertial\" effects by replacing special relativity's \"flat\" Minkowski Space with a metric that produces non-zero curvature. In general relativity, the principle of inertia is replaced with the principle of geodesic motion, whereby objects move in a way dictated by the curvature of spacetime. As a consequence of this curvature, it is not a given in general relativity that inertial objects moving at a particular rate with respect to each other will continue to do so. This phenomenon of geodesic deviation means that inertial frames of reference do not exist globally as they do in Newtonian mechanics and special relativity.\n\nHowever, the general theory reduces to the special theory over sufficiently small regions of spacetime, where curvature effects become less important and the earlier inertial frame arguments can come back into play. Consequently, modern special relativity is now sometimes described as only a \"local theory\". \"Local\" can encompass, for example, the entire Milky Way galaxy: The astronomer Karl Schwarzschild observed the motion of pairs of stars orbiting each other. He found that the two orbits of the stars of such a system lie in a plane, and the perihelion of the orbits of the two stars remains pointing in the same direction with respect to the solar system. Schwarzschild pointed out that that was invariably seen: the direction of the angular momentum of all observed double star systems remains fixed with respect to the direction of the angular momentum of the Solar System. These observations allowed him to conclude that inertial frames inside the galaxy do not rotate with respect to one another, and that the space of the Milky Way is approximately Galilean or Minkowskian.\n\n\n\n\n"}
{"id": "14840", "url": "https://en.wikipedia.org/wiki?curid=14840", "title": "Illuminati: New World Order", "text": "Illuminati: New World Order\n\nIlluminati: New World Order (\"INWO\") is an out-of-print collectible card game (CCG) that was released in 1994 by Steve Jackson Games, based on their original boxed game Illuminati, which in turn was inspired by the 1975 book \"The Illuminatus! Trilogy\" by Robert Anton Wilson and Robert Shea. \"INWO\" won the Origins Award for \"Best Card Game\" in 1997. An OMNI sealed-deck league patterned after the Atlas Games model was also developed.\n\nPlayers attempt to achieve World Domination by utilizing the powers of their chosen Illuminati (the Adepts of Hermes, the Bavarian Illuminati, the Bermuda Triangle, the Discordian Society, the Gnomes of Zürich, The Network, the Servants of Cthulhu, Shangri-La, and the UFOs). The first player to control a predetermined number of Organizations (usually twelve in a standard game) has achieved the Basic Goal and can claim victory. \n\nControllable Organizations include: groups such as the Men in Black, the CIA, and the Boy Sprouts; Personalities such as Princess Di, Saddam Hussein, Ross Perot or Björne (the purple dinosaur); and Places like Japan, California, Canada, and the Moonbase. Many Organization names are spoofs of real organizations, presumably altered to avoid lawsuits. \n\nOther ways to achieve victory include: destroying your rival Illuminati by capturing or destroying the last Organization in their Power Structure; and/or fulfilling a Special Goal before your opponent(s) can.\n\nCards come in three main types: Illuminati cards, Plot cards, and Group cards. Illuminati and Plot cards both feature an illustration of a puppeteer's hand in a blue color scheme on the rear side, whereas Group cards feature a puppet on a string in a red color scheme. \n\nEach Illuminati card represents a different Illuminated organization at the center of each player's Power Structure. They have Power, a Special Goal, and an appropriate Special Ability. Their power flows outwards into the Groups they control via Control Arrows. \n\nPlot cards provide the bulk of the game's narrative structure, allowing players to go beyond - or even break - the rules of the game as described in the World Domination Handbook. Plot cards are identified by their overall blue color scheme (border, and/or title color). Included among the general Plots are several special types, including \"Assassinations\" and \"Disasters\" (for delivering insults to the various Personalities and Places in play), \"GOAL\" (special goals that can lead to surprise victories), and \"New World Order\" cards (a set of conditions that affect all players, typically overridden when replacement \"New World Order\" cards are brought into play).\n\nGroup cards represent the power elite in charge of the named organization. There are two main types of Group: Organizations and Resources. \n\nOrganizations are identified by their overall red color scheme (border and/or title). There are three main types of Organization: regular Organizations, People, and Places. They all feature Power, Resistance, Special Abilities, Alignments, Attributes, and Control Arrows (an inward arrow, and 0-3 outward arrows). Just like their Illuminati masters, Organizations can launch and defend against a variety of attacks. Provided that the attacking Organization has a free, outward-pointing Control Arrow, players can increase the size of their Power Structure via successful Attacks to Control, a mathematically determined method employed whenever a player wants to capture an Organization from their own hand, or from a rival player's Power Structure. Unless the attack is Privileged (only the target and attacker can be involved), all players can aid or undermine the attack. Attacks to Destroy follow a similar game mechanic, but result in the Organization's removal from the Power Structure, after which they are immediately discarded. The outcome of all Attacks are determined by a dice roll. Other ways to introduce Organizations to the Power Structure involve Plots, or spending Action Tokens to bring Groups into play, or by using free moves, each at appropriate times during the play cycle. \n\nResources represent the custodians of a variety of objects, ranging from gadgets to artefacts (such as The Shroud of Turin, Flying Saucers, and ELIZA). They are identified by their overall purple color scheme (border and/or title). Resources are introduced into play by spending Action Tokens, or by using free moves during appropriate moments in the play cycle. They go alongside the Power Structure of the player's Illuminati, and bestow a useful Special Ability or similar.\n\n\"The INWO Book\" (1995) Steve Jackson Games Incorporated.\n\n\"Illuminati: New World Order\", Official Website.\n\n"}
{"id": "14841", "url": "https://en.wikipedia.org/wiki?curid=14841", "title": "Integration", "text": "Integration\n\nIntegration may refer to:\n\n\n\n\n\n\n\n"}
{"id": "14843", "url": "https://en.wikipedia.org/wiki?curid=14843", "title": "Interstellar travel", "text": "Interstellar travel\n\nInterstellar travel is the term used for crewed or uncrewed travel between stars or planetary systems. Interstellar travel will be much more difficult than interplanetary spaceflight; the distances between the planets in the Solar System are less than 30 astronomical units (AU)—whereas the distances between stars are typically hundreds of thousands of AU, and usually expressed in light-years. Because of the vastness of those distances, interstellar travel would require a high percentage of the speed of light; huge travel time, lasting from decades to millennia or longer; or a combination of both.\n\nThe speeds required for interstellar travel in a human lifetime far exceed what current methods of spacecraft propulsion can provide. Even with a hypothetically perfectly efficient propulsion system, the kinetic energy corresponding to those speeds is enormous by today's standards of energy development. Moreover, collisions by the spacecraft with cosmic dust and gas can produce very dangerous effects both to passengers and the spacecraft itself.\n\nA number of strategies have been proposed to deal with these problems, ranging from giant arks that would carry entire societies and ecosystems, to microscopic space probes. Many different spacecraft propulsion systems have been proposed to give spacecraft the required speeds, including nuclear propulsion, beam-powered propulsion, and methods based on speculative physics.\n\nFor both crewed and uncrewed interstellar travel, considerable technological and economic challenges need to be met. Even the most optimistic views about interstellar travel see it as only being feasible decades from now. However, in spite of the challenges, if or when interstellar travel is realised, a wide range of scientific benefits is expected.\n\nMost interstellar travel concepts require a developed space logistics system capable of moving millions of tons to a construction / operating location, and most would require gigawatt-scale power for construction or power (such as Star Wisp or Light Sail type concepts). Such a system could grow organically if space-based solar power became a significant component of Earth's energy mix. Consumer demand for a multi-terawatt system would automatically create the necessary multi-million ton/year logistical system.\n\nDistances between the planets in the Solar System are often measured in astronomical units (AU), defined as the average distance between the Sun and Earth, some . Venus, the closest other planet to Earth is (at closest approach) 0.28 AU away. Neptune, the farthest planet from the Sun, is 29.8 AU away. As of January 2018, Voyager 1, the farthest man-made object from Earth, is 141.5 AU away.\n\nThe closest known star, Proxima Centauri, is approximately away, or over 9,000 times farther away than Neptune.\n\nBecause of this, distances between stars are usually expressed in light-years, defined as the distance that a light photon travels in a year. Light in a vacuum travels around per second, so this is some or in a year. Proxima Centauri is 4.243 light-years away.\n\nAnother way of understanding the vastness of interstellar distances is by scaling: One of the closest stars to the Sun, Alpha Centauri A (a Sun-like star), can be pictured by scaling down the Earth–Sun distance to . On this scale, the distance to Alpha Centauri A would be .\n\nThe fastest outward-bound spacecraft yet sent, Voyager 1, has covered 1/600 of a light-year in 30 years and is currently moving at 1/18,000 the speed of light. At this rate, a journey to Proxima Centauri would take 80,000 years.\n\nA significant factor contributing to the difficulty is the energy that must be supplied to obtain a reasonable travel time. A lower bound for the required energy is the kinetic energy formula_1 where formula_2 is the final mass. If deceleration on arrival is desired and cannot be achieved by any means other than the engines of the ship, then the lower bound for the required energy is doubled to formula_3.\n\nThe velocity for a manned round trip of a few decades to even the nearest star is several thousand times greater than those of present space vehicles. This means that due to the formula_4 term in the kinetic energy formula, millions of times as much energy is required. Accelerating one ton to one-tenth of the speed of light requires at least (world energy consumption 2008 was 143,851 terawatt-hours), without factoring in efficiency of the propulsion mechanism. This energy has to be generated onboard from stored fuel, harvested from the interstellar medium, or projected over immense distances.\n\nA knowledge of the properties of the interstellar gas and dust through which the vehicle must pass is essential for the design of any interstellar space mission. A major issue with traveling at extremely high speeds is that interstellar dust may cause considerable damage to the craft, due to the high relative speeds and large kinetic energies involved. Various shielding methods to mitigate this problem have been proposed. Larger objects (such as macroscopic dust grains) are far less common, but would be much more destructive. The risks of impacting such objects, and methods of mitigating these risks, have been discussed in the literature, but many unknowns remain and, owing to the inhomogeneous distribution of interstellar matter around the Sun, will depend on direction travelled. Although a high density interstellar medium may cause difficulties for many interstellar travel concepts, interstellar ramjets, and some proposed concepts for decelerating interstellar spacecraft, would actually benefit from a denser interstellar medium.\n\nThe crew of an interstellar ship would face several significant hazards, including the psychological effects of long-term isolation, the effects of exposure to ionizing radiation, and the physiological effects of weightlessness to the muscles, joints, bones, immune system, and eyes. There also exists the risk of impact by micrometeoroids and other space debris. These risks represent challenges that have yet to be overcome.\n\nIt has been argued that an interstellar mission that cannot be completed within 50 years should not be started at all. Instead, assuming that a civilization is still on an increasing curve of propulsion system velocity and not yet having reached the limit, the resources should be invested in designing a better propulsion system. This is because a slow spacecraft would probably be passed by another mission sent later with more advanced propulsion (the incessant obsolescence postulate). On the other hand, Andrew Kennedy has shown that if one calculates the journey time to a given destination as the rate of travel speed derived from growth (even exponential growth) increases, there is a clear minimum in the total time to that destination from now. Voyages undertaken before the minimum will be overtaken by those that leave at the minimum, whereas voyages that leave after the minimum will never overtake those that left at the minimum.\n\nThere are 59 known stellar systems within 40 light years of the Sun, containing 81 visible stars. The following could be considered prime targets for interstellar missions:\n\nExisting and near-term astronomical technology is capable of finding planetary systems around these objects, increasing their potential for exploration\n\nSlow interstellar missions based on current and near-future propulsion technologies are associated with trip times starting from about one hundred years to thousands of years. These missions consist of sending a robotic probe to a nearby star for exploration, similar to interplanetary probes such as used in the Voyager program. By taking along no crew, the cost and complexity of the mission is significantly reduced although technology lifetime is still a significant issue next to obtaining a reasonable speed of travel. Proposed concepts include Project Daedalus, Project Icarus, Project Dragonfly, Project Longshot, and more recently Breakthrough Starshot.\n\nNear-lightspeed nano spacecraft might be possible within the near future built on existing microchip technology with a newly developed nanoscale thruster. Researchers at the University of Michigan are developing thrusters that use nanoparticles as propellant. Their technology is called \"nanoparticle field extraction thruster\", or nanoFET. These devices act like small particle accelerators shooting conductive nanoparticles out into space.\n\nMichio Kaku, a theoretical physicist, has suggested that clouds of \"smart dust\" be sent to the stars, which may become possible with advances in nanotechnology. Kaku also notes that a large number of nanoprobes would need to be sent due to the vulnerability of very small probes to be easily deflected by magnetic fields, micrometeorites and other dangers to ensure the chances that at least one nanoprobe will survive the journey and reach the destination.\n\nGiven the light weight of these probes, it would take much less energy to accelerate them. With onboard solar cells, they could continually accelerate using solar power. One can envision a day when a fleet of millions or even billions of these particles swarm to distant stars at nearly the speed of light and relay signals back to Earth through a vast interstellar communication network.\n\nAs a near-term solution, small, laser-propelled interstellar probes, based on current CubeSat technology were proposed in the context of Project Dragonfly.\n\nIn crewed missions, the duration of a slow interstellar journey presents a major obstacle and existing concepts deal with this problem in different ways. They can be distinguished by the \"state\" in which humans are transported on-board of the spacecraft.\n\nA generation ship (or world ship) is a type of interstellar ark in which the crew that arrives at the destination is descended from those who started the journey. Generation ships are not currently feasible because of the difficulty of constructing a ship of the enormous required scale and the great biological and sociological problems that life aboard such a ship raises.\n\nScientists and writers have postulated various techniques for suspended animation. These include human hibernation and cryonic preservation. Although neither is currently practical, they offer the possibility of sleeper ships in which the passengers lie inert for the long duration of the voyage.\n\nA robotic interstellar mission carrying some number of frozen early stage human embryos is another theoretical possibility. This method of space colonization requires, among other things, the development of an artificial uterus, the prior detection of a habitable terrestrial planet, and advances in the field of fully autonomous mobile robots and educational robots that would replace human parents.\n\nInterstellar space is not completely empty; it contains trillions of icy bodies ranging from small asteroids (Oort cloud) to possible rogue planets. There may be ways to take advantage of these resources for a good part of an interstellar trip, slowly hopping from body to body or setting up waystations along the way.\n\nIf a spaceship could average 10 percent of light speed (and decelerate at the destination, for manned missions), this would be enough to reach Proxima Centauri in forty years. Several propulsion concepts have been proposed that might be eventually developed to accomplish this (see § Propulsion below), but none of them are ready for near-term (few decades) developments at acceptable cost.\n\nAssuming faster-than-light travel is impossible, one might conclude that a human can never make a round-trip farther from Earth than 20 light years if the traveler is active between the ages of 20 and 60. A traveler would never be able to reach more than the very few star systems that exist within the limit of 20 light years from Earth. This, however, fails to take into account relativistic time dilation. Clocks aboard an interstellar ship would run slower than Earth clocks, so if a ship's engines were capable of continuously generating around 1 g of acceleration (which is comfortable for humans), the ship could reach almost anywhere in the galaxy and return to Earth within 40 years ship-time (see diagram). Upon return, there would be a difference between the time elapsed on the astronaut's ship and the time elapsed on Earth.\n\nFor example, a spaceship could travel to a star 32 light-years away, initially accelerating at a constant 1.03g (i.e. 10.1 m/s) for 1.32 years (ship time), then stopping its engines and coasting for the next 17.3 years (ship time) at a constant speed, then decelerating again for 1.32 ship-years, and coming to a stop at the destination. After a short visit, the astronaut could return to Earth the same way. After the full round-trip, the clocks on board the ship show that 40 years have passed, but according to those on Earth, the ship comes back 76 years after launch.\n\nFrom the viewpoint of the astronaut, onboard clocks seem to be running normally. The star ahead seems to be approaching at a speed of 0.87 light years per ship-year. The universe would appear contracted along the direction of travel to half the size it had when the ship was at rest; the distance between that star and the Sun would seem to be 16 light years as measured by the astronaut.\n\nAt higher speeds, the time on board will run even slower, so the astronaut could travel to the center of the Milky Way (30,000 light years from Earth) and back in 40 years ship-time. But the speed according to Earth clocks will always be less than 1 light year per Earth year, so, when back home, the astronaut will find that more than 60 thousand years will have passed on Earth.\n\nRegardless of how it is achieved, a propulsion system that could produce acceleration continuously from departure to arrival would be the fastest method of travel. A constant acceleration journey is one where the propulsion system accelerates the ship at a constant rate for the first half of the journey, and then decelerates for the second half, so that it arrives at the destination stationary relative to where it began. If this were performed with an acceleration similar to that experienced at the Earth's surface, it would have the added advantage of producing artificial \"gravity\" for the crew. Supplying the energy required, however, would be prohibitively expensive with current technology.\n\nFrom the perspective of a planetary observer, the ship will appear to accelerate steadily at first, but then more gradually as it approaches the speed of light (which it cannot exceed). It will undergo hyperbolic motion. The ship will be close to the speed of light after about a year of accelerating and remain at that speed until it brakes for the end of the journey.\n\nFrom the perspective of an onboard observer, the crew will feel a gravitational field opposite the engine's acceleration, and the universe ahead will appear to fall in that field, undergoing hyperbolic motion. As part of this, distances between objects in the direction of the ship's motion will gradually contract until the ship begins to decelerate, at which time an onboard observer's experience of the gravitational field will be reversed.\n\nWhen the ship reaches its destination, if it were to exchange a message with its origin planet, it would find that less time had elapsed on board than had elapsed for the planetary observer, due to time dilation and length contraction.\n\nThe result is an impressively fast journey for the crew.\n\nAll rocket concepts are limited by the rocket equation, which sets the characteristic velocity available as a function of exhaust velocity and mass ratio, the ratio of initial (\"M\", including fuel) to final (\"M\", fuel depleted) mass.\n\nVery high specific power, the ratio of thrust to total vehicle mass, is required to reach interstellar targets within sub-century time-frames. Some heat transfer is inevitable and a tremendous heating load must be adequately handled.\n\nThus, for interstellar rocket concepts of all technologies, a key engineering problem (seldom explicitly discussed) is limiting the heat transfer from the exhaust stream back into the vehicle.\n\nA type of electric propulsion, spacecraft such as Dawn use an ion engine. In an ion engine, electric power is used to create charged particles of the propellant, usually the gas xenon, and accelerate them to extremely high velocities. The exhaust velocity of conventional rockets is limited by the chemical energy stored in the fuel's molecular bonds, which limits the thrust to about 5 km/s. They produce a high thrust (about 10⁶ N), but they have a low specific impulse, and that limits their top speed. By contrast, ion engines have low force, but the top speed in principle is limited only by the electrical power available on the spacecraft and on the gas ions being accelerated. The exhaust speed of the charged particles range from 15 km/s to 35 km/s.<ref name=\"http://www.iflscience.com\"></ref>\n\nNuclear-electric or plasma engines, operating for long periods at low thrust and powered by fission reactors, have the potential to reach speeds much greater than chemically powered vehicles or nuclear-thermal rockets. Such vehicles probably have the potential to power solar system exploration with reasonable trip times within the current century. Because of their low-thrust propulsion, they would be limited to off-planet, deep-space operation. Electrically powered spacecraft propulsion powered by a portable power-source, say a nuclear reactor, producing only small accelerations, would take centuries to reach for example 15% of the velocity of light, thus unsuitable for interstellar flight during a single human lifetime.\n\nFission-fragment rockets use nuclear fission to create high-speed jets of fission fragments, which are ejected at speeds of up to . With fission, the energy output is approximately 0.1% of the total mass-energy of the reactor fuel and limits the effective exhaust velocity to about 5% of the velocity of light. For maximum velocity, the reaction mass should optimally consist of fission products, the \"ash\" of the primary energy source, so no extra reaction mass need be bookkept in the mass ratio.\n\nBased on work in the late 1950s to the early 1960s, it has been technically possible to build spaceships with nuclear pulse propulsion engines, i.e. driven by a series of nuclear explosions. This propulsion system contains the prospect of very high specific impulse (space travel's equivalent of fuel economy) and high specific power.\n\nProject Orion team member Freeman Dyson proposed in 1968 an interstellar spacecraft using nuclear pulse propulsion that used pure deuterium fusion detonations with a very high fuel-burnup fraction. He computed an exhaust velocity of 15,000 km/s and a 100,000-tonne space vehicle able to achieve a 20,000 km/s delta-v allowing a flight-time to Alpha Centauri of 130 years. Later studies indicate that the top cruise velocity that can theoretically be achieved by a Teller-Ulam thermonuclear unit powered Orion starship, assuming no fuel is saved for slowing back down, is about 8% to 10% of the speed of light (0.08-0.1c). An atomic (fission) Orion can achieve perhaps 3%-5% of the speed of light. A nuclear pulse drive starship powered by fusion-antimatter catalyzed nuclear pulse propulsion units would be similarly in the 10% range and pure matter-antimatter annihilation rockets would be theoretically capable of obtaining a velocity between 50% to 80% of the speed of light. In each case saving fuel for slowing down halves the maximum speed. The concept of using a magnetic sail to decelerate the spacecraft as it approaches its destination has been discussed as an alternative to using propellant, this would allow the ship to travel near the maximum theoretical velocity. Alternative designs utilizing similar principles include Project Longshot, Project Daedalus, and Mini-Mag Orion. The principle of external nuclear pulse propulsion to maximize survivable power has remained common among serious concepts for interstellar flight without external power beaming and for very high-performance interplanetary flight.\n\nIn the 1970s the Nuclear Pulse Propulsion concept further was refined by Project Daedalus by use of externally triggered inertial confinement fusion, in this case producing fusion explosions via compressing fusion fuel pellets with high-powered electron beams. Since then, lasers, ion beams, neutral particle beams and hyper-kinetic projectiles have been suggested to produce nuclear pulses for propulsion purposes.\n\nA current impediment to the development of \"any\" nuclear-explosion-powered spacecraft is the 1963 Partial Test Ban Treaty, which includes a prohibition on the detonation of any nuclear devices (even non-weapon based) in outer space. This treaty would, therefore, need to be renegotiated, although a project on the scale of an interstellar mission using currently foreseeable technology would probably require international cooperation on at least the scale of the International Space Station.\n\nAnother issue to be considered, would be the g-forces imparted to a rapidly accelerated spacecraft, cargo, and passengers inside (see Inertia negation).\n\nFusion rocket starships, powered by nuclear fusion reactions, should conceivably be able to reach speeds of the order of 10% of that of light, based on energy considerations alone. In theory, a large number of stages could push a vehicle arbitrarily close to the speed of light. These would \"burn\" such light element fuels as deuterium, tritium, He, B, and Li. Because fusion yields about 0.3–0.9% of the mass of the nuclear fuel as released energy, it is energetically more favorable than fission, which releases <0.1% of the fuel's mass-energy. The maximum exhaust velocities potentially energetically available are correspondingly higher than for fission, typically 4–10% of c. However, the most easily achievable fusion reactions release a large fraction of their energy as high-energy neutrons, which are a significant source of energy loss. Thus, although these concepts seem to offer the best (nearest-term) prospects for travel to the nearest stars within a (long) human lifetime, they still involve massive technological and engineering difficulties, which may turn out to be intractable for decades or centuries.\n\nEarly studies include Project Daedalus, performed by the British Interplanetary Society in 1973–1978, and Project Longshot, a student project sponsored by NASA and the US Naval Academy, completed in 1988. Another fairly detailed vehicle system, \"Discovery II\", designed and optimized for crewed Solar System exploration, based on the DHe reaction but using hydrogen as reaction mass, has been described by a team from NASA's Glenn Research Center. It achieves characteristic velocities of >300 km/s with an acceleration of ~1.7•10 \"g\", with a ship initial mass of ~1700 metric tons, and payload fraction above 10%. Although these are still far short of the requirements for interstellar travel on human timescales, the study seems to represent a reasonable benchmark towards what may be approachable within several decades, which is not impossibly beyond the current state-of-the-art. Based on the concept's 2.2% burnup fraction it could achieve a pure fusion product exhaust velocity of ~3,000 km/s.\n\nAn antimatter rocket would have a far higher energy density and specific impulse than any other proposed class of rocket. If energy resources and efficient production methods are found to make antimatter in the quantities required and store it safely, it would be theoretically possible to reach speeds of several tens of percent that of light. Whether antimatter propulsion could lead to the higher speeds (>90% that of light) at which relativistic time dilation would become more noticeable, thus making time pass at a slower rate for the travelers as perceived by an outside observer, is doubtful owing to the large quantity of antimatter that would be required.\n\nSpeculating that production and storage of antimatter should become feasible, two further issues need to be considered. First, in the annihilation of antimatter, much of the energy is lost as high-energy gamma radiation, and especially also as neutrinos, so that only about 40% of \"mc\" would actually be available if the antimatter were simply allowed to annihilate into radiations thermally. Even so, the energy available for propulsion would be substantially higher than the ~1% of \"mc\" yield of nuclear fusion, the next-best rival candidate.\n\nSecond, heat transfer from the exhaust to the vehicle seems likely to transfer enormous wasted energy into the ship (e.g. for 0.1\"g\" ship acceleration, approaching 0.3 trillion watts per ton of ship mass), considering the large fraction of the energy that goes into penetrating gamma rays. Even assuming shielding was provided to protect the payload (and passengers on a crewed vehicle), some of the energy would inevitably heat the vehicle, and may thereby prove a limiting factor if useful accelerations are to be achieved.\n\nMore recently, Friedwardt Winterberg proposed that a matter-antimatter GeV gamma ray laser photon rocket is possible by a relativistic proton-antiproton pinch discharge, where the recoil from the laser beam is transmitted by the Mössbauer effect to the spacecraft.\n\nRockets deriving their power from external sources, such as a laser, could replace their internal energy source with an energy collector, potentially reducing the mass of the ship greatly and allowing much higher travel speeds. Geoffrey A. Landis has proposed for an interstellar probe, with energy supplied by an external laser from a base station powering an Ion thruster.\n\nA problem with all traditional rocket propulsion methods is that the spacecraft would need to carry its fuel with it, thus making it very massive, in accordance with the rocket equation. Several concepts attempt to escape from this problem:\n\nIn 1960, Robert W. Bussard proposed the Bussard ramjet, a fusion rocket in which a huge scoop would collect the diffuse hydrogen in interstellar space, \"burn\" it on the fly using a proton–proton chain reaction, and expel it out of the back. Later calculations with more accurate estimates suggest that the thrust generated would be less than the drag caused by any conceivable scoop design. Yet the idea is attractive because the fuel would be collected \"en route\" (commensurate with the concept of \"energy harvesting\"), so the craft could theoretically accelerate to near the speed of light. The limitation is due to the fact that the reaction can only accelerate the propellant to 0.12c. Thus the drag of catching interstellar dust and the thrust of accelerating that same dust to 0.12c would be the same when the speed is 0.12c, preventing further acceleration.\n\nA light sail or magnetic sail powered by a massive laser or particle accelerator in the home star system could potentially reach even greater speeds than rocket- or pulse propulsion methods, because it would not need to carry its own reaction mass and therefore would only need to accelerate the craft's payload. Robert L. Forward proposed a means for decelerating an interstellar light sail in the destination star system without requiring a laser array to be present in that system. In this scheme, a smaller secondary sail is deployed to the rear of the spacecraft, whereas the large primary sail is detached from the craft to keep moving forward on its own. Light is reflected from the large primary sail to the secondary sail, which is used to decelerate the secondary sail and the spacecraft payload. In 2002, Geoffrey A. Landis of NASA's Glen Research center also proposed a laser-powered, propulsion, sail ship that would host a diamond sail (of a few nanometers thick) powered with the use of solar energy. With this proposal, this interstellar ship would, theoretically, be able to reach 10 percent the speed of light.\n\nA magnetic sail could also decelerate at its destination without depending on carried fuel or a driving beam in the destination system, by interacting with the plasma found in the solar wind of the destination star and the interstellar medium.\n\nThe following table lists some example concepts using beamed laser propulsion as proposed by the physicist Robert L. Forward:\n\nThe following table is based on work by Heller, Hippke and Kervella.\n\nAchieving start-stop interstellar trip times of less than a human lifetime require mass-ratios of between 1,000 and 1,000,000, even for the nearer stars. This could be achieved by multi-staged vehicles on a vast scale. Alternatively large linear accelerators could propel fuel to fission propelled space-vehicles, avoiding the limitations of the Rocket equation.\n\nScientists and authors have postulated a number of ways by which it might be possible to surpass the speed of light, but even the most serious-minded of these are highly speculative.\n\nIt is also debatable whether faster-than-light travel is physically possible, in part because of causality concerns: travel faster than light may, under certain conditions, permit travel backwards in time within the context of special relativity. Proposed mechanisms for faster-than-light travel within the theory of general relativity require the existence of exotic matter and it is not known if this could be produced in sufficient quantity.\n\nIn physics, the Alcubierre drive is based on an argument, within the framework of general relativity and without the introduction of wormholes, that it is possible to modify a spacetime in a way that allows a spaceship to travel with an arbitrarily large speed by a local expansion of spacetime behind the spaceship and an opposite contraction in front of it. Nevertheless, this concept would require the spaceship to incorporate a region of exotic matter, or hypothetical concept of negative mass.\n\nA theoretical idea for enabling interstellar travel is by propelling a starship by creating an artificial black hole and using a parabolic reflector to reflect its Hawking radiation. Although beyond current technological capabilities, a black hole starship offers some advantages compared to other possible methods. Getting the black hole to act as a power source and engine also requires a way to convert the Hawking radiation into energy and thrust. One potential method involves placing the hole at the focal point of a parabolic reflector attached to the ship, creating forward thrust. A slightly easier, but less efficient method would involve simply absorbing all the gamma radiation heading towards the fore of the ship to push it onwards, and let the rest shoot out the back.\n\nWormholes are conjectural distortions in spacetime that theorists postulate could connect two arbitrary points in the universe, across an Einstein–Rosen Bridge. It is not known whether wormholes are possible in practice. Although there are solutions to the Einstein equation of general relativity that allow for wormholes, all of the currently known solutions involve some assumption, for example the existence of negative mass, which may be unphysical. However, Cramer \"et al.\" argue that such wormholes might have been created in the early universe, stabilized by cosmic string. The general theory of wormholes is discussed by Visser in the book \"Lorentzian Wormholes\".\n\nThe Enzmann starship, as detailed by G. Harry Stine in the October 1973 issue of \"Analog\", was a design for a future starship, based on the ideas of Robert Duncan-Enzmann. The spacecraft itself as proposed used a 12,000,000 ton ball of frozen deuterium to power 12–24 thermonuclear pulse propulsion units. Twice as long as the Empire State Building and assembled in-orbit, the spacecraft was part of a larger project preceded by interstellar probes and telescopic observation of target star systems.\n\nProject Hyperion, one of the projects of Icarus Interstellar.\n\nNASA has been researching interstellar travel since its formation, translating important foreign language papers and conducting early studies on applying fusion propulsion, in the 1960s, and laser propulsion, in the 1970s, to interstellar travel.\n\nThe NASA Breakthrough Propulsion Physics Program (terminated in FY 2003 after a 6-year, $1.2-million study, because \"No breakthroughs appear imminent.\") identified some breakthroughs that are needed for interstellar travel to be possible.\n\nGeoffrey A. Landis of NASA's Glenn Research Center states that a laser-powered interstellar sail ship could possibly be launched within 50 years, using new methods of space travel. \"I think that ultimately we're going to do it, it's just a question of when and who,\" Landis said in an interview. Rockets are too slow to send humans on interstellar missions. Instead, he envisions interstellar craft with extensive sails, propelled by laser light to about one-tenth the speed of light. It would take such a ship about 43 years to reach Alpha Centauri if it passed through the system without stopping. Slowing down to stop at Alpha Centauri could increase the trip to 100 years, whereas a journey without slowing down raises the issue of making sufficiently accurate and useful observations and measurements during a fly-by.\n\nThe 100 Year Starship (100YSS) is the name of the overall effort that will, over the next century, work toward achieving interstellar travel. The effort will also go by the moniker 100YSS. The 100 Year Starship study is the name of a one-year project to assess the attributes of and lay the groundwork for an organization that can carry forward the 100 Year Starship vision.\n\nHarold (\"Sonny\") White from NASA's Johnson Space Center is a member of Icarus Interstellar, the nonprofit foundation whose mission is to realize interstellar flight before the year 2100. At the 2012 meeting of 100YSS, he reported using a laser to try to warp spacetime by 1 part in 10 million with the aim of helping to make interstellar travel possible.\n\n\nA few organisations dedicated to interstellar propulsion research and advocacy for the case exist worldwide. These are still in their infancy, but are already backed up by a membership of a wide variety of scientists, students and professionals.\n\nThe energy requirements make interstellar travel very difficult. It has been reported that at the 2008 Joint Propulsion Conference, multiple experts opined that it was improbable that humans would ever explore beyond the Solar System. Brice N. Cassenti, an associate professor with the Department of Engineering and Science at Rensselaer Polytechnic Institute, stated that at least 100 times the total energy output of the entire world [in a given year] would be required to send a probe to the nearest star.\n\nAstrophysicist Sten Odenwald stated that the basic problem is that through intensive studies of thousands of detected exoplanets, most of the closest destinations within 50 light years do not yield Earth-like planets in the star's habitable zones. Given the multitrillion-dollar expense of some of the proposed technologies, travelers will have to spend up to 200 years traveling at 20% the speed of light to reach the best known destinations. Moreover, once the travelers arrive at their destination (by any means), they will not be able to travel down to the surface of the target world and set up a colony unless the atmosphere is non-lethal. The prospect of making such a journey, only to spend the rest of the colony's life inside a sealed habitat and venturing outside in a spacesuit, may eliminate many prospective targets from the list.\n\nMoving at a speed close to the speed of light and encountering even a tiny stationary object like a grain of sand will have fatal consequences. For example, a gram of matter moving at 90% of the speed of light contains a kinetic energy corresponding to a small nuclear bomb (around 30kt TNT).\n\nExplorative high-speed missions to Alpha Centauri, as planned for by the Breakthrough Starshot initiative, are projected to be realizable within the 21st century. It is alternatively possible to plan for unmanned slow-cruising missions taking millennia to arrive. These probes would not be for human benefit in the sense that one can not foresee whether there would be anybody around on earth interested in then back-transmitted science data. An example would be the Genesis mission, which aims to bring unicellular life, in the spirit of directed panspermia, to habitable but otherwise barren planets. Comparatively slow cruising Genesis probes, with a typical speed of formula_5, corresponding to about formula_6, can be decelerated using a magnetic sail. Unmanned missions not for human benefit would hence be feasible.\n\nIn February 2017, NASA announced that its Spitzer Space Telescope had revealed seven Earth-size planets in the TRAPPIST-1 system orbiting an ultra-cool dwarf star 40 light-years away from our solar system. Three of these planets are firmly located in the habitable zone, the area around the parent star where a rocky planet is most likely to have liquid water. The discovery sets a new record for greatest number of habitable-zone planets found around a single star outside our solar system. All of these seven planets could have liquid water – the key to life as we know it – under the right atmospheric conditions, but the chances are highest with the three in the habitable zone.\n\n\n\n"}
{"id": "14844", "url": "https://en.wikipedia.org/wiki?curid=14844", "title": "Interior Gateway Routing Protocol", "text": "Interior Gateway Routing Protocol\n\nInterior Gateway Routing Protocol (IGRP) is a distance vector interior gateway protocol (IGP) developed by Cisco. It is used by routers to exchange routing data within an autonomous system.\n\nIGRP is a proprietary protocol. IGRP was created in part to overcome the limitations of RIP (maximum hop count of only 15, and a single routing metric) when used within large networks. IGRP supports multiple metrics for each route, including bandwidth, delay, load, and reliability; to compare two routes these metrics are combined together into a single metric, using a formula which can be adjusted through the use of pre-set constants. By default, the IGRP composite metric is a sum of the segment delays and the lowest segment bandwidth. The maximum configurable hop count of IGRP-routed packets is 255 (default 100), and routing updates are broadcast every 90 seconds (by default). IGRP uses protocol number 9 for communication.\n\nIGRP is considered a classful routing protocol. Because the protocol has no field for a subnet mask, the router assumes that all subnetwork addresses within the same Class A, Class B, or Class C network have the same subnet mask as the subnet mask configured for the interfaces in question. This contrasts with classless routing protocols that can use variable length subnet masks. Classful protocols have become less popular as they are wasteful of IP address space.\n\nIn order to address the issues of address space and other factors, Cisco created EIGRP (Enhanced Interior Gateway Routing Protocol). EIGRP adds support for VLSM (variable length subnet mask) and adds the Diffusing Update Algorithm (DUAL) in order to improve routing and provide a loopless environment. EIGRP has completely replaced IGRP, making IGRP an obsolete routing protocol. In Cisco IOS versions 12.3 and greater, IGRP is completely unsupported. In the new Cisco CCNA curriculum (version 4), IGRP is mentioned only briefly, as an \"obsolete protocol\".\n\n"}
{"id": "14845", "url": "https://en.wikipedia.org/wiki?curid=14845", "title": "IRS (disambiguation)", "text": "IRS (disambiguation)\n\nIRS is the United States Internal Revenue Service. \n\nIRS may also refer to:\n\n\n\n\n\n\n"}
{"id": "14848", "url": "https://en.wikipedia.org/wiki?curid=14848", "title": "Indo-European languages", "text": "Indo-European languages\n\nThere are about 445 living Indo-European languages, according to the estimate by \"Ethnologue\", with over two thirds (313) of them belonging to the Indo-Iranian branch. The most widely spoken Indo-European languages by native speakers are Hindustani (Hindi-Urdu), Spanish, English, Portuguese, Bengali, Punjabi, and Russian, each with over 100 million speakers, with German, French, Marathi, Italian, and Persian also having more than 50 million. Today, nearly 42% of the human population (3.2 billion) speaks an Indo-European language as a first language, by far the highest of any language family.\n\nThe Indo-European family includes most of the modern languages of Europe; notable exceptions include Hungarian, Turkish, Finnish, Estonian, Basque, Maltese, and Sami. The Indo-European family is also represented in Asia with the exception of East and Southeast Asia. It was predominant in ancient Anatolia (present-day Turkey), the ancient Tarim Basin (present-day Northwest China) and most of Central Asia until the medieval Turkic and Mongol invasions. Outside Eurasia, Indo-European languages are dominant in the Americas and much of Oceania and Africa, having reached there during the Age of Discovery. Indo-European languages are also most commonly present as minority languages or second languages in countries where other families are dominant.\n\nWith written evidence appearing since the Bronze Age in the form of the Anatolian languages and Mycenaean Greek, the Indo-European family is significant to the field of historical linguistics as possessing the second-longest recorded history, after the Afroasiatic family, although certain language isolates, such as Sumerian, Elamite, Hurrian, Hattian, and Kassite are recorded earlier.\n\nAll Indo-European languages are descendants of a single prehistoric language, reconstructed as Proto-Indo-European, spoken sometime in the Neolithic era. Although no written records remain, aspects of the culture and religion of the Proto-Indo-Europeans can also be reconstructed from the related cultures of ancient and modern Indo-European speakers who continue to live in areas to where the Proto-Indo-Europeans migrated from their original homeland. Several disputed proposals link Indo-European to other major language families. Although they are written in Semitic Old Assyrian, the Hittite loanwords and names found in the Kültepe texts are the oldest record of any Indo-European language.\n\nDuring the nineteenth century, the linguistic concept of Indo-European languages was frequently used interchangeably with the racial concepts of Aryan and Japhetite.\n\nIn the 16th century, European visitors to the Indian subcontinent began to notice similarities among Indo-Aryan, Iranian, and European languages. In 1583, English Jesuit missionary and Konkani scholar Thomas Stephens wrote a letter from Goa to his brother (not published until the 20th century) in which he noted similarities between Indian languages and Greek and Latin.\n\nAnother account was made by Filippo Sassetti, a merchant born in Florence in 1540, who travelled to the Indian subcontinent. Writing in 1585, he noted some word similarities between Sanskrit and Italian (these included \"devaḥ\"/\"dio\" \"God\", \"sarpaḥ\"/\"serpe\" \"serpent\", \"sapta\"/\"sette\" \"seven\", \"aṣṭa\"/\"otto\" \"eight\", and \"nava\"/\"nove\" \"nine\"). However, neither Stephens' nor Sassetti's observations led to further scholarly inquiry.\n\nIn 1647, Dutch linguist and scholar Marcus Zuerius van Boxhorn noted the similarity among certain Asian and European languages and theorized that they were derived from a primitive common language which he called \"Scythian\". He included in his hypothesis Dutch, Albanian, Greek, Latin, Persian, and German, later adding Slavic, Celtic, and Baltic languages. However, Van Boxhorn's suggestions did not become widely known and did not stimulate further research.\n\nOttoman Turkish traveler Evliya Çelebi visited Vienna in 1665–1666 as part of a diplomatic mission and noted a few similarities between words in German and in Persian.\nGaston Coeurdoux and others made observations of the same type. Coeurdoux made a thorough comparison of Sanskrit, Latin and Greek conjugations in the late 1760s to suggest a relationship among them. Meanwhile, Mikhail Lomonosov compared different language groups, including Slavic, Baltic (\"Kurlandic\"), Iranian (\"Medic\"), Finnish, Chinese, \"Hottentot\" (Khoekhoe), and others, noting that related languages (including Latin, Greek, German and Russian) must have separated in antiquity from common ancestors.\n\nThe hypothesis reappeared in 1786 when Sir William Jones first lectured on the striking similarities among three of the oldest languages known in his time: Latin, Greek, and Sanskrit, to which he tentatively added Gothic, Celtic, and Persian, though his classification contained some inaccuracies and omissions. In one of the most famous quotations in linguistics, Jones made the following prescient statement in a lecture to the Asiatic Society of Bengal in 1786, conjecturing the existence of an earlier ancestor language, which he called \"a common source\" but did not name:\nThomas Young first used the term \"Indo-European\" in 1813, deriving from the geographical extremes of the language family: from Western Europe to North India. A synonym is \"Indo-Germanic\" (\"Idg.\" or \"IdG.\"), specifying the family's southeasternmost and northwesternmost branches. This first appeared in French (\"indo-germanique\") in 1810 in the work of Conrad Malte-Brun; in most languages this term is now dated or less common than \"Indo-European\", although in German \"indogermanisch\" remains the standard scientific term. A number of other synonymous terms have also been used.\n\nFranz Bopp wrote in 1816 \"On the conjugational system of the Sanskrit language compared with that of Greek, Latin, Persian and Germanic\" and between 1833 and 1852 he wrote \"Comparative Grammar\". This marks the beginning of Indo-European studies as an academic discipline. The classical phase of Indo-European comparative linguistics leads from this work to August Schleicher's 1861 \"Compendium\" and up to Karl Brugmann's \"Grundriss\", published in the 1880s. Brugmann's neogrammarian reevaluation of the field and Ferdinand de Saussure's development of the laryngeal theory may be considered the beginning of \"modern\" Indo-European studies. The generation of Indo-Europeanists active in the last third of the 20th century (such as Calvert Watkins, Jochem Schindler, and Helmut Rix) developed a better understanding of morphology and of ablaut in the wake of Kuryłowicz's 1956 \"Apophony in Indo-European,\" who in 1927 pointed out the existence of the Hittite consonant ḫ. Kuryłowicz's discovery supported Ferdinand de Saussure's 1879 proposal of the existence of \"coefficients sonantiques\", elements de Saussure reconstructed to account for vowel length alternations in Indo-European languages. This led to the so-called laryngeal theory, a major step forward in Indo-European linguistics and a confirmation of de Saussure's theory.\n\nThe various subgroups of the Indo-European language family include ten major branches, listed below in alphabetical order\n\nIn addition to the classical ten branches listed above, several extinct and little-known languages and language-groups have existed:\n\nMembership of languages in the Indo-European language family is determined by genealogical relationships, meaning that all members are presumed descendants of a common ancestor, Proto-Indo-European. Membership in the various branches, groups and subgroups of Indo-European is also genealogical, but here the defining factors are \"shared innovations\" among various languages, suggesting a common ancestor that split off from other Indo-European groups. For example, what makes the Germanic languages a branch of Indo-European is that much of their structure and phonology can be stated in rules that apply to all of them. Many of their common features are presumed innovations that took place in Proto-Germanic, the source of all the Germanic languages.\n\nThe \"tree model\" is considered an appropriate representation of the genealogical history of a language family if communities do not remain in contact after their languages have started to diverge. In this case, subgroups defined by shared innovations form a nested pattern. The tree model is not appropriate in cases where languages remain in contact as they diversify; in such cases subgroups may overlap, and the \"wave model\" is a more accurate representation. Most approaches to Indo-European subgrouping to date have assumed that the tree model is by-and-large valid for Indo-European; however, there is also a long tradition of wave-model approaches.\n\nIn addition to genealogical changes, many of the early changes in Indo-European languages can be attributed to language contact. It has been asserted, for example, that many of the more striking features shared by Italic languages (Latin, Oscan, Umbrian, etc.) might well be areal features. More certainly, very similar-looking alterations in the systems of long vowels in the West Germanic languages greatly postdate any possible notion of a proto-language innovation (and cannot readily be regarded as \"areal\", either, because English and continental West Germanic were not a linguistic area). In a similar vein, there are many similar innovations in Germanic and Balto-Slavic that are far more likely areal features than traceable to a common proto-language, such as the uniform development of a high vowel (*\"u\" in the case of Germanic, *\"i/u\" in the case of Baltic and Slavic) before the PIE syllabic resonants *\"ṛ,* ḷ, *ṃ, *ṇ\", unique to these two groups among IE languages, which is in agreement with the wave model. The Balkan sprachbund even features areal convergence among members of very different branches.\n\nAn extension to the \"Ringe-Warnow model of language evolution\", suggests that early IE had featured limited contact between distinct lineages, with only the Germanic subfamily exhibiting a less treelike behaviour as it acquired some characteristics from neighbours early in its evolution. The internal diversification of especially West Germanic is cited to have been radically non-treelike.\n\nSpecialists have postulated the existence of higher-order subgroups such as Italo-Celtic, Graeco-Armenian, Graeco-Aryan or Graeco-Armeno-Aryan, and Balto-Slavo-Germanic. However, unlike the ten traditional branches, these are all controversial to a greater or lesser degree.\n\nThe Italo-Celtic subgroup was at one point uncontroversial, considered by Antoine Meillet to be even better established than Balto-Slavic. The main lines of evidence included the genitive suffix \"-ī\"; the superlative suffix \"-m̥mo\"; the change of /p/ to /kʷ/ before another /kʷ/ in the same word (as in \"penkʷe\" > \"*kʷenkʷe\" > Latin \"quīnque\", Old Irish \"cóic\"); and the subjunctive morpheme \"-ā-\". This evidence was prominently challenged by Calvert Watkins; while Michael Weiss has argued for the subgroup.\n\nEvidence for a relationship between Greek and Armenian includes the regular change of the second laryngeal to \"a\" at the beginnings of words, as well as terms for \"woman\" and \"sheep\". Greek and Indo-Iranian share innovations mainly in verbal morphology and patterns of nominal derivation. Relations have also been proposed between Phrygian and Greek, and between Thracian and Armenian. Some fundamental shared features, like the aorist (a verb form denoting action without reference to duration or completion) having the perfect active particle -s fixed to the stem, link this group closer to Anatolian languages and Tocharian. Shared features with Balto-Slavic languages, on the other hand (especially present and preterit formations), might be due to later contacts.\n\nThe Indo-Hittite hypothesis proposes that the Indo-European language family consists of two main branches: one represented by the Anatolian languages and another branch encompassing all other Indo-European languages. Features that separate Anatolian from all other branches of Indo-European (such as the gender or the verb system) have been interpreted alternately as archaic debris or as innovations due to prolonged isolation. Points proffered in favour of the Indo-Hittite hypothesis are the (non-universal) Indo-European agricultural terminology in Anatolia and the preservation of laryngeals. However, in general this hypothesis is considered to attribute too much weight to the Anatolian evidence. According to another view, the Anatolian subgroup left the Indo-European parent language comparatively late, approximately at the same time as Indo-Iranian and later than the Greek or Armenian divisions. A third view, especially prevalent in the so-called French school of Indo-European studies, holds that extant similarities in non-satem languages in general—including Anatolian—might be due to their peripheral location in the Indo-European language-area and to early separation, rather than indicating a special ancestral relationship. Hans J. Holm, based on lexical calculations, arrives at a picture roughly replicating the general scholarly opinion and refuting the Indo-Hittite hypothesis.\n\nThe division of the Indo-European languages into satem and centum groups was put forward by Peter von Bradke in 1890, although Karl Brugmann had proposed a similar type of division in 1886. In the satem languages, which include the Balto-Slavic and Indo-Iranian branches, as well as (in most respects) Albanian and Armenian, the reconstructed Proto-Indo-European palatovelars remained distinct and were fricativized, while the labiovelars merged with the \"plain velars\". In the centum languages, the palatovelars merged with the plain velars, while the labiovelars remained distinct. The results of these alternative developments are exemplified by the words for \"hundred\" in Avestan (\"satem\") and Latin (\"centum\")—the initial palatovelar developed into a fricative [s] in the former, but became an ordinary velar [k] in the latter.\n\nRather than being a genealogical separation, the centum–satem division is commonly seen as resulting from innovative changes that spread across PIE dialect-branches over a particular geographical area; the centum–satem isogloss intersects a number of other isoglosses that mark distinctions between features in the early IE branches. It may be that the centum branches in fact reflect the original state of affairs in PIE, and only the satem branches shared a set of innovations, which affected all but the peripheral areas of the PIE dialect continuum. Kortlandt proposes that the ancestors of Balts and Slavs took part in satemization before being drawn later into the western Indo-European sphere.\n\nSome linguists propose that Indo-European languages form part of one of several hypothetical macrofamilies. However, these theories remain highly controversial, not being accepted by most linguists in the field. Some of the smaller proposed macrofamilies include:\n\nOther, greater proposed families including Indo-European languages, include:\n\nObjections to such groupings are not based on any theoretical claim about the likely historical existence or non-existence of such macrofamilies; it is entirely reasonable to suppose that they might have existed. The serious difficulty lies in identifying the details of actual relationships between language families, because it is very hard to find concrete evidence that transcends chance resemblance, or is not equally likely explained as being due to borrowing (including Wanderwörter, which can travel very long distances). Because the signal-to-noise ratio in historical linguistics declines steadily over time, at great enough time-depths it becomes open to reasonable doubt that one can even distinguish between signal and noise.\n\nThe proposed Proto-Indo-European language (PIE) is the reconstructed common ancestor of the Indo-European languages, spoken by the Proto-Indo-Europeans. From the 1960s, knowledge of Anatolian became certain enough to establish its relationship to PIE. Using the method of internal reconstruction an earlier stage, called Pre-Proto-Indo-European, has been proposed.\n\nPIE was an inflected language, in which the grammatical relationships between words were signaled through inflectional morphemes (usually endings). The roots of PIE are basic morphemes carrying a lexical meaning. By addition of suffixes, they form stems, and by addition of endings, these form grammatically inflected words (nouns or verbs). The reconstructed Indo-European verb system is complex and, like the noun, exhibits a system of ablaut.\n\nThe diversification of the parent language into the attested branches of daughter languages is historically unattested. The timeline of the evolution of the various daughter languages, on the other hand, is mostly undisputed, quite regardless of the question of Indo-European origins.\n\nUsing a mathematical analysis borrowed from evolutionary biology, Don Ringe and Tandy Warnow propose the following evolutionary tree of Indo-European branches:\n\nDavid Anthony proposes the following sequence:\n\nFrom 1500 BC the following sequence may be given:\n\nIn reconstructing the history of the Indo-European languages and the form of the Proto-Indo-European language, some languages have been of particular importance. These generally include the ancient Indo-European languages that are both well-attested and documented at an early date, although some languages from later periods are important if they are particularly linguistically conservative (most notably, Lithuanian). Early poetry is of special significance because of the rigid poetic meter normally employed, which makes it possible to reconstruct a number of features (e.g. vowel length) that were either unwritten or corrupted in the process of transmission down to the earliest extant written manuscripts.\n\nMost noticeable of all:\n\nOther primary sources:\n\nOther secondary sources, of lesser value due to poor attestation:\n\nOther secondary sources, of lesser value due to extensive phonological changes and relatively limited attestation:\n\nAs the Proto-Indo-European (PIE) language broke up, its sound system diverged as well, changing according to various sound laws evidenced in the daughter languages.\n\nPIE is normally reconstructed with a complex system of 15 stop consonants, including an unusual three-way phonation (voicing) distinction between voiceless, voiced and \"voiced aspirated\" (i.e. breathy voiced) stops, and a three-way distinction among velar consonants (\"k\"-type sounds) between \"palatal\" \"ḱ ǵ ǵh\", \"plain velar\" \"k g gh\" and labiovelar \"kʷ gʷ gʷh\". (The correctness of the terms \"palatal\" and \"plain velar\" is disputed; see Proto-Indo-European phonology.) All daughter languages have reduced the number of distinctions among these sounds, often in divergent ways.\n\nAs an example, in English, one of the Germanic languages, the following are some of the major changes that happened:\nNone of the daughter-language families (except possibly Anatolian, particularly Luvian) reflect the plain velar stops differently from the other two series, and there is even a certain amount of dispute whether this series existed at all in PIE. The major distinction between \"centum\" and \"satem\" languages corresponds to the outcome of the PIE plain velars:\n\nThe three-way PIE distinction between voiceless, voiced and voiced aspirated stops is considered extremely unusual from the perspective of linguistic typology—particularly in the existence of voiced aspirated stops without a corresponding series of voiceless aspirated stops. None of the various daughter-language families continue it unchanged, with numerous \"solutions\" to the apparently unstable PIE situation:\n\nAmong the other notable changes affecting consonants are:\n\nThe following table shows the basic outcomes of PIE consonants in some of the most important daughter languages for the purposes of reconstruction. For a fuller table, see Indo-European sound laws.\n\n\nThe following table presents a comparison of conjugations of the thematic present indicative of the verbal root * of the English verb \"to bear\" and its reflexes in various early attested IE languages and their modern descendants or relatives, showing that all languages had in the early stage an inflectional verb system.\n\nWhile similarities are still visible between the modern descendants and relatives of these ancient languages, the differences have increased over time. Some IE languages have moved from synthetic verb systems to largely periphrastic systems. In addition, the pronouns of periphrastic forms are in brackets when they appear. Some of these verbs have undergone a change in meaning as well.\n\nToday, Indo-European languages are spoken by almost 3 billion native speakers across all inhabited continents, the largest number by far for any recognised language family. Of the 20 languages with the largest numbers of native speakers according to \"Ethnologue\", 10 are Indo-European: Spanish, English, Hindustani, Portuguese, Bengali, Russian, Punjabi, German, French and Marathi, accounting for over 1.7 billion native speakers. Additionally, hundreds of millions of persons worldwide study Indo-European languages as secondary or tertiary languages, including in cultures which have completely different language families and historical backgrounds—there between 600,000,000 and one billion L2 learners of English alone.\n\nThe success of the language family, including the large number of speakers and the vast portions of the Earth that they inhabit, is due to several factors. The ancient Indo-European migrations and widespread dissemination of Indo-European culture throughout Eurasia, including that of the Proto-Indo-Europeans themselves, and that of their daughter cultures including the Indo-Aryans, Iranian peoples, Celts, Greeks, Romans, Germanic peoples, and Slavs, led to these peoples' branches of the language family already taking a dominant foothold in virtually all of Eurasia except for North and East Asia by the end of the prehistoric era, replacing the previously-spoken pre-Indo-European languages of this extensive area.\n\nDespite being unaware of their common linguistic origin, diverse groups of Indo-European speakers continued to culturally dominate and replace the indigenous languages of the western two-thirds of Eurasia. By the beginning of the Common Era, Indo-European peoples controlled almost the entirety of this area: the Celts western and central Europe, the Romans southern Europe, the Germanic peoples northern Europe, the Slavs eastern Europe, the Iranian peoples the entirety of western and central Asia and parts of eastern Europe, and the Indo-Aryan peoples in the Indian subcontinent, with the Tocharians inhabiting the Indo-European frontier in western China. By the medieval period, only the Vasconic, Semitic, Dravidian, Caucasian and Uralic languages remained of the (relatively) indigenous languages of Europe and the western half of Asia.\n\nDespite medieval invasions by Eurasian nomads, a group to which the Proto-Indo-Europeans had once belonged, Indo-European expansion reached another peak in the early modern period with the dramatic increase in the population of the Indian subcontinent and European expansionism throughout the globe during the Age of Discovery, as well as the continued replacement and assimilation of surrounding non-Indo-European languages and peoples due to increased state centralization and nationalism. These trends compounded throughout the modern period due to the general global population growth and the results of European colonization of the Western Hemisphere and Oceania, leading to an explosion in the number of Indo-European speakers as well as the territories inhabited by them.\n\nDue to colonization and the modern dominance of Indo-European languages in the fields of global science, technology, education, finance, and sports, even many modern countries whose populations largely speak non-Indo-European languages have Indo-European languages as official languages, and the majority of the global population speaks at least one Indo-European language. The overwhelming majority of languages used on the Internet are Indo-European, with English continuing to lead the group; English in general has in many respects become the \"lingua franca\" of global communication.\n\n\n\n"}
{"id": "14849", "url": "https://en.wikipedia.org/wiki?curid=14849", "title": "Illinois", "text": "Illinois\n\nIllinois ( ) is a state in the Midwestern region of the United States. It has the 5th largest Gross Domestic Product by state, is the\n6th-most populous U.S. state and 25th-largest state in terms of land area. Illinois is often noted as a microcosm of the entire United States. With Chicago in the northeast, small industrial cities and great agricultural productivity in northern and central Illinois, and natural resources such as coal, timber, and petroleum in the south, Illinois has a diverse economic base, and is a major transportation hub. The Port of Chicago connects the state to other global ports around the world from the Great Lakes, via the Saint Lawrence Seaway, to the Atlantic Ocean; as well as the Great Lakes to the Mississippi River, via the Illinois Waterway on the Illinois River. The Mississippi River, the Ohio River, and the Wabash River form parts of the boundaries of Illinois. For decades, Chicago's O'Hare International Airport has been ranked as one of the world's busiest airports. Illinois has long had a reputation as a bellwether both in social and cultural terms and, through the 1980s, in politics.\n\nThe capital of Illinois is Springfield in the central part of the state. Although today the state's largest population center is in and around Chicago in the northeastern part of the state, the state's European population grew first in the west, with French who settled along the Mississippi River and gave the area the name \"Illinois\" Country. After the American Revolutionary War established the United States, American settlers began arriving from Kentucky in the 1780s via the Ohio River, and the population grew from south to north. In 1818, Illinois achieved statehood. After construction of the Erie Canal increased traffic and trade through the Great Lakes, Chicago was founded in the 1830s on the banks of the Chicago River, at one of the few natural harbors on southern Lake Michigan. John Deere's invention of the self-scouring steel plow turned Illinois's rich prairie into some of the world's most productive and valuable farmland, attracting immigrant farmers from Germany and Sweden. The Illinois and Michigan Canal (1848) made transportation between the Great Lakes and the Mississippi River valley faster and cheaper. New railroads carried immigrants to new homes, as well as being used to ship commodity crops to Eastern markets. The state became a transportation hub for the nation.\n\nBy 1900, the growth of industrial jobs in the northern cities and coal mining in the central and southern areas attracted immigrants from Eastern and Southern Europe. Illinois was an important manufacturing center during both world wars. The Great Migration from the South established a large community of African Americans in the state, including Chicago, who created the city's famous jazz and blues cultures. Chicago, the center of the Chicago Metropolitan Area, became a global alpha-level city.\n\nThree U.S. presidents have been elected while living in Illinois: Abraham Lincoln, Ulysses S. Grant, and Barack Obama. Additionally, Ronald Reagan, whose political career was based in California, was born and raised in Illinois. Today, Illinois honors Lincoln with its official state slogan, \"Land of Lincoln\", which has been displayed on its license plates since 1954. The state is the site of the Abraham Lincoln Presidential Library and Museum, located in the state capital of Springfield, and the future home of the Barack Obama Presidential Center in Chicago.\n\n\"Illinois\" is the modern spelling for the early French Catholic missionaries and explorers' name for the Illinois Native Americans, a name that was spelled in many different ways in the early records.\n\nAmerican scholars previously thought the name \"Illinois\" meant \"man\" or \"men\" in the Miami-Illinois language, with the original \"iliniwek\" transformed via French into Illinois. This etymology is not supported by the Illinois language, as the word for \"man\" is \"ireniwa\", and plural of \"man\" is \"ireniwaki\". The name \"Illiniwek\" has also been said to mean \"tribe of superior men\", which is a false etymology. The name \"Illinois\" derives from the Miami-Illinois verb \"irenwe·wa\" - \"he speaks the regular way\". This was taken into the Ojibwe language, perhaps in the Ottawa dialect, and modified into \"ilinwe·\" (pluralized as \"ilinwe·k\"). The French borrowed these forms, changing the /we/ ending to spell it as \"-ois\", a transliteration for its pronunciation in French of that time. The current spelling form, \"Illinois\", began to appear in the early 1670s, when French colonists had settled in the western area. The Illinois's name for themselves, as attested in all three of the French missionary-period dictionaries of Illinois, was \"Inoka\", of unknown meaning and unrelated to the other terms.\n\nAmerican Indians of successive cultures lived along the waterways of the Illinois area for thousands of years before the arrival of Europeans. The Koster Site has been excavated and demonstrates 7,000 years of continuous habitation. Cahokia, the largest regional chiefdom and urban center of the Pre-Columbian Mississippian culture, was located near present-day Collinsville, Illinois. They built an urban complex of more than 100 platform and burial mounds, a plaza larger than 35 football fields, and a woodhenge of sacred cedar, all in a planned design expressing the culture's cosmology. Monks Mound, the center of the site, is the largest Pre-Columbian structure north of the Valley of Mexico. It is high, long, wide, and covers . It contains about of earth. It was topped by a structure thought to have measured about in length and in width, covered an area , and been as much as high, making its peak above the level of the plaza. The finely crafted ornaments and tools recovered by archaeologists at Cahokia include elaborate ceramics, finely sculptured stonework, carefully embossed and engraved copper and mica sheets, and one funeral blanket for an important chief fashioned from 20,000 shell beads. These artifacts indicate that Cahokia was truly an urban center, with clustered housing, markets, and specialists in toolmaking, hide dressing, potting, jewelry making, shell engraving, weaving and salt making. The civilization vanished in the 15th century for unknown reasons, but historians and archeologists have speculated that the people depleted the area of resources. Many indigenous tribes engaged in constant warfare. According to Suzanne Austin Alchon, \"At one site in the central Illinois River valley, one third of all adults died as a result of violent injuries.\"\nThe next major power in the region was the Illinois Confederation or Illini, a political alliance. As the Illini declined during the Beaver Wars era, members of the Algonquian-speaking Potawatomi, Miami, Sauk, and other tribes including the Fox (Mesquakie), Ioway, Kickapoo, Mascouten, Piankashaw, Shawnee, Wea, and Winnebago (Ho-Chunk) came into the area from the east and north around the Great Lakes.\n\nFrench explorers Jacques Marquette and Louis Jolliet explored the Illinois River in 1673. Marquette soon after founded a mission at the Grand Village of the Illinois in Illinois Country. In 1680, French explorers under René-Robert Cavelier, Sieur de La Salle and Henri de Tonti constructed a fort at the site of present-day Peoria, and in 1682, a fort atop Starved Rock in today's Starved Rock State Park. French Empire Canadiens came south to settle particularly along the Mississippi River, and Illinois was part of first New France, and then of La Louisiane until 1763, when it passed to the British with their defeat of France in the Seven Years' War. The small French settlements continued, although many French migrated west to Ste. Genevieve and St. Louis, Missouri, to evade British rule.\n\nA few British soldiers were posted in Illinois, but few British or American settlers moved there, as the Crown made it part of the territory reserved for Indians west of the Appalachians, and then part of the British Province of Quebec. In 1778, George Rogers Clark claimed Illinois County for Virginia. In a compromise, Virginia ceded the area to the new United States in 1783 and it became part of the Northwest Territory, to be administered by the federal government and later organized as states. Connecticut ceded northern Illinois in 1786 (see Connecticut Western Reserve).\n\nThe Illinois-Wabash Company was an early claimant to much of Illinois. The Illinois Territory was created on February 3, 1809, with its capital at Kaskaskia, an early French settlement.\n\nDuring the discussions leading up to Illinois's admission to the Union, the proposed northern boundary of the state was moved twice. The original provisions of the Northwest Ordinance had specified a boundary that would have been tangent to the southern tip of Lake Michigan. Such a boundary would have left Illinois with no shoreline on Lake Michigan at all. However, as Indiana had successfully been granted a northern extension of its boundary to provide it with a usable lakefront, the original bill for Illinois statehood, submitted to Congress on January 23, 1818, stipulated a northern border at the same latitude as Indiana's, which is defined as 10 miles north of the southernmost extremity of Lake Michigan. However, the Illinois delegate, Nathaniel Pope, wanted more, and lobbied to have the boundary moved further north. The final bill passed by Congress included an amendment to shift the border to 42° 30' north, which is approximately north of the Indiana northern border. This shift added to the state, including the lead mining region near Galena. More importantly, it added nearly 50 miles of Lake Michigan shoreline and the Chicago River. Pope and others envisioned a canal that would connect the Chicago and Illinois rivers and thus connect the Great Lakes to the Mississippi.\n\nIn 1818, Illinois became the 21st U.S. state. The capital remained at Kaskaskia, headquartered in a small building rented by the state. In 1819, Vandalia became the capital, and over the next 18 years, three separate buildings were built to serve successively as the capitol building. In 1837, the state legislators representing Sangamon County, under the leadership of state representative Abraham Lincoln, succeeded in having the capital moved to Springfield, where a fifth capitol building was constructed. A sixth capitol building was erected in 1867, which continues to serve as the Illinois capitol today.\n\nThough it was ostensibly a \"free state\", there was slavery in Illinois. The ethnic French had owned black slaves since the 1720s, and American settlers had already brought slaves into the area from Kentucky. Slavery was nominally banned by the Northwest Ordinance, but that was not enforced for those already holding slaves. When Illinois became a sovereign state in 1818, the Ordinance no longer applied, and about 900 slaves were held in the state. As the southern part of the state, later known as \"Egypt\" or \"Little Egypt\", was largely settled by migrants from the South, the section was hostile to free blacks. Settlers were allowed to bring slaves with them for labor, but, in 1822, state residents voted against making slavery legal. Still, most residents opposed allowing free blacks as permanent residents. Some settlers brought in slaves seasonally or as house servants. The Illinois Constitution of 1848 was written with a provision for exclusionary laws to be passed. In 1853, John A. Logan helped pass a law to prohibit all African Americans, including freedmen, from settling in the state.\n\nThe winter of 1830–1831 is called the \"Winter of the Deep Snow\"; a sudden, deep snowfall blanketed the state, making travel impossible for the rest of the winter, and many travelers perished. Several severe winters followed, including the \"Winter of the Sudden Freeze\". On December 20, 1836, a fast-moving cold front passed through, freezing puddles in minutes and killing many travelers who could not reach shelter. The adverse weather resulted in crop failures in the northern part of the state. The southern part of the state shipped food north, and this may have contributed to its name: \"Little Egypt\", after the Biblical story of Joseph in Egypt supplying grain to his brothers.\n\nIn 1832, the Black Hawk War was fought in Illinois and current-day Wisconsin between the United States and the Sauk, Fox (Meskwaki), and Kickapoo Indian tribes. It represents the end of Indian resistance to white settlement in the Chicago region. The Indians had been forced to leave their homes and move to Iowa in 1831; when they attempted to return, they were attacked and eventually defeated by U.S. militia. The survivors were forced back to Iowa.\n\nBy 1839, the Latter Day Saints had founded a utopian city called Nauvoo. Located in Hancock County along the Mississippi River, Nauvoo flourished, and soon rivaled Chicago for the position of the state's largest city. But in 1844, the Latter Day Saint movement founder Joseph Smith was killed in the Carthage Jail, about 30 miles away from Nauvoo. Following a succession crisis (Latter Day Saints), Brigham Young led most Latter Day Saints out of Illinois in a mass exodus to present-day Utah; after close to six years of rapid development, Nauvoo rapidly declined afterward.\n\nAfter it was established in 1833, Chicago gained prominence as a Great Lakes port, and then as an Illinois and Michigan Canal port after 1848, and as a rail hub soon afterward. By 1857, Chicago was Illinois's largest city. With the tremendous growth of mines and factories in the state in the 19th century, Illinois was the ground for the formation of labor unions in the United States.\n\nIn 1847, after lobbying by Dorothea L. Dix, Illinois became one of the first states to establish a system of state-supported treatment of mental illness and disabilities, replacing local almshouses. Dix came into this effort after having met J. O. King, a Jacksonville, Illinois businessman, who invited her to Illinois, where he had been working to build an asylum for the insane. With the lobbying expertise of Dix, plans for the Jacksonville State Hospital (now known as the Jacksonville Developmental Center) were signed into law on March 1, 1847.\n\nDuring the American Civil War, Illinois ranked fourth in men who served (more than 250,000) in the Union Army, a figure surpassed by only New York, Pennsylvania, and Ohio. Beginning with President Abraham Lincoln's first call for troops and continuing throughout the war, Illinois mustered 150 infantry regiments, which were numbered from the 7th to the 156th regiments. Seventeen cavalry regiments were also gathered, as well as two light artillery regiments. The town of Cairo, at the southern tip of the state at the confluence of the Mississippi and Ohio Rivers, served as a strategically important supply base and training center for the Union army. For several months, both General Grant and Admiral Foote had headquarters in Cairo.\n\nDuring the Civil War, and more so afterwards, Chicago's population skyrocketed, which increased its prominence. The Pullman Strike and Haymarket Riot, in particular, greatly influenced the development of the American labor movement. From Sunday, October 8, 1871, until Tuesday, October 10, 1871, the Great Chicago Fire burned in downtown Chicago, destroying .\n\nAt the turn of the 20th century, Illinois had a population of nearly 5 million. Many people from other parts of the country were attracted to the state by employment caused by the then-expanding industrial base. Whites were 98% of the state's population. Bolstered by continued immigration from southern and eastern Europe, and by the African-American Great Migration from the South, Illinois grew and emerged as one of the most important states in the union. By the end of the century, the population had reached 12.4 million.\n\nThe Century of Progress World's Fair was held at Chicago in 1933. Oil strikes in Marion County and Crawford County led to a boom in 1937, and by 1939, Illinois ranked fourth in U.S. oil production. Illinois manufactured 6.1 percent of total United States military armaments produced during World War II, ranking seventh among the 48 states. Chicago became an ocean port with the opening of the Saint Lawrence Seaway in 1959. The seaway and the Illinois Waterway connected Chicago to both the Mississippi River and the Atlantic Ocean. In 1960, Ray Kroc opened the first McDonald's franchise in Des Plaines (which still exists as a museum, with a working McDonald's across the street).\n\nIllinois had a prominent role in the emergence of the nuclear age. In 1942, as part of the Manhattan Project, the University of Chicago conducted the first sustained nuclear chain reaction. In 1957, Argonne National Laboratory, near Chicago, activated the first experimental nuclear power generating system in the United States. By 1960, the first privately financed nuclear plant in the United States, Dresden 1, was dedicated near Morris. In 1967, Fermilab, a national nuclear research facility near Batavia, opened a particle accelerator, which was the world's largest for over 40 years. With eleven plants currently operating, Illinois leads all states in the amount of electricity generated from nuclear power.\n\nIn 1961, Illinois became the first state in the nation to adopt the recommendation of the American Law Institute and pass a comprehensive criminal code revision that repealed the law against sodomy. The code also abrogated common law crimes and established an age of consent of 18. The state's fourth constitution was adopted in 1970, replacing the 1870 document.\n\nThe first Farm Aid concert was held in Champaign to benefit American farmers, in 1985. The worst upper Mississippi River flood of the century, the Great Flood of 1993, inundated many towns and thousands of acres of farmland.\n\nIllinois is located in the Midwest Region of the United States and is one of the eight states and Canadian province in the bi-national Great Lakes region of North America.\n\nIllinois's eastern border with Indiana consists of a north-south line at 87° 31′ 30″ west longitude in Lake Michigan at the north, to the Wabash River in the south above Post Vincennes. The Wabash River continues as the eastern/southeastern border with Indiana until the Wabash enters the Ohio River. This marks the beginning of Illinois's southern border with Kentucky, which runs along the northern shoreline of the Ohio River. Most of the western border with Missouri and Iowa is the Mississippi River; Kaskaskia is an exclave of Illinois, lying west of the Mississippi and reachable only from Missouri. The state's northern border with Wisconsin is fixed at 42°  30' north latitude. The northeastern border of Illinois lies in Lake Michigan, within which Illinois shares a water boundary with the state of Michigan, as well as Wisconsin and Indiana.\n\nThough Illinois lies entirely in the Interior Plains, it does have some minor variation in its elevation. In extreme northwestern Illinois, the Driftless Area, a region of unglaciated and therefore higher and more rugged topography, occupies a small part of the state.\n\nCharles Mound, located in this region, has the state's highest elevation above sea level at . Other highlands include the Shawnee Hills in the south, and there is varying topography along its rivers; the Illinois River bisects the state northeast to southwest. The floodplain on the Mississippi River from Alton to the Kaskaskia River is known as the American Bottom.\n\nIllinois has three major geographical divisions. Northern Illinois is dominated by Chicago metropolitan area, or Chicagoland, which is the city of Chicago and its suburbs, and the adjoining exurban area into which the metropolis is expanding. As defined by the federal government, the Chicago metro area includes several counties in Illinois, Indiana, and Wisconsin, and has a population of over 9.8 million people. Chicago itself is a cosmopolitan city, densely populated, industrialized, the transportation hub of the nation, and settled by a wide variety of ethnic groups. The city of Rockford, Illinois's third-largest city and center of the state's fourth largest metropolitan area, sits along Interstates 39 and 90 some northwest of Chicago. The Quad Cities region, located along the Mississippi River in northern Illinois, had a population of 381,342 in 2011.\n\nThe midsection of Illinois is the second major division, called Central Illinois. It is an area of mainly prairie and known as the Heart of Illinois. It is characterized by small towns and medium-small cities. The western section (west of the Illinois River) was originally part of the Military Tract of 1812 and forms the conspicuous western bulge of the state. Agriculture, particularly corn and soybeans, as well as educational institutions and manufacturing centers, figure prominently in Central Illinois. Cities include Peoria; Springfield, the state capital; Quincy; Decatur; Bloomington-Normal; and Champaign-Urbana.\n\nThe third division is Southern Illinois, comprising the area south of U.S. Route 50, including Little Egypt, near the juncture of the Mississippi River and Ohio River. Southern Illinois is the site of the ancient city of Cahokia, as well as the site of the first state capital at Kaskaskia, which today is separated from the rest of the state by the Mississippi River. This region has a somewhat warmer winter climate, different variety of crops (including some cotton farming in the past), more rugged topography (due to the area remaining unglaciated during the Illinoian Stage, unlike most of the rest of the state), as well as small-scale oil deposits and coal mining. The Illinois suburbs of St. Louis, such as East St. Louis, are located in this region, and collectively, they are known as the Metro-East. The other somewhat significant concentration of population in Southern Illinois is the Carbondale-Marion-Herrin, Illinois Combined Statistical Area centered on Carbondale and Marion, a two-county area that is home to 123,272 residents. A portion of southeastern Illinois is part of the extended Evansville, Indiana, Metro Area, locally referred to as the Tri-State with Indiana and Kentucky. Seven Illinois counties are in the area.\n\nIn addition to these three, largely latitudinally defined divisions, all of the region outside the Chicago Metropolitan area is often called \"downstate\" Illinois. This term is flexible, but is generally meant to mean everything outside the influence of the Chicago area. Thus, some cities in \"Northern\" Illinois, such as DeKalb, which is west of Chicago, and Rockford—which is actually north of Chicago—are sometimes incorrectly considered to be 'downstate'.\n\nIllinois has a climate that varies widely throughout the year. Because of its nearly 400-mile distance between its northernmost and southernmost extremes, as well as its mid-continental situation, most of Illinois has a humid continental climate (Köppen climate classification \"Dfa\"), with hot, humid summers and cold winters. The southern part of the state, from about Carbondale southward, has a humid subtropical climate (Koppen \"Cfa\"), with more moderate winters. Average yearly precipitation for Illinois varies from just over at the southern tip to around in the northern portion of the state. Normal annual snowfall exceeds in the Chicago area, while the southern portion of the state normally receives less than . The all-time high temperature was , recorded on July 14, 1954, at East St. Louis, while the all-time low temperature was , recorded on January 5, 1999, at Congerville. A temperature of −37 °F (−39 °C), was recorded on January 15, 2009, at Rochelle. A weather station near Mount Carroll recorded a temperature of -38°F on January 31, 2019, which is still being verified by the National Weather Service.\n\nIllinois averages approximately 51 days of thunderstorm activity a year, which ranks somewhat above average in the number of thunderstorm days for the United States. Illinois is vulnerable to tornadoes, with an average of 35 occurring annually, which puts much of the state at around five tornadoes per annually. While tornadoes are no more powerful in Illinois than other states, some of Tornado Alley's deadliest tornadoes on record have occurred in the state. The Tri-State Tornado of 1925 killed 695 people in three states; 613 of the victims died in Illinois. Other significant high-casualty tornadoes include the 1896 St. Louis – East St. Louis tornado, which killed 111 people in East St. Louis and a May 1917 tornado that killed 101 people in Charleston and Mattoon. Modern developments in storm forecasting and tracking have caused death tolls from tornadoes to decline dramatically, with the 1967 Belvidere – Oak Lawn – Chicago South Side tornado outbreak (58 fatalities) and 1990 Plainfield tornado (29 fatalities) standing out as exceptions. On November 17, 2013, an EF4 tornado touched down and ripped through Washington, Illinois. There were three fatalities.\n\nThe United States Census Bureau estimates that the population of Illinois was 12,741,080 in 2018, moving from the fifth-largest state to the sixth-largest state (losing out to Pennsylvania). Illinois's population declined by 60,943 people from July 2017 to July 2018, making it the worst decline of any state in the U.S. in raw terms. Illinois is the most populous state in the Midwest region. Chicago, the third-most populous city in the United States, is the center of the Chicago metropolitan area or Chicagoland, as this area is nicknamed, comprises only 9% of the land area of the state, but contains 65% of the state's residents.\n\nAccording to the 2010 Census, the racial composition of the state was:\n\nIn the same year 15.8% of the total population was of Hispanic or Latino origin (they may be of any race).\n\nThe state's most populous ethnic group, non-Hispanic white, has declined from 83.5% in 1970 to 63.3% in 2011. , 49.4% of Illinois's population younger than age 1 were minorities (Note: Children born to white Hispanics are counted as minority group).\nAt the 2007 estimates from the U.S. Census Bureau, there were 1,768,518 foreign-born inhabitants of the state or 13.8% of the population, with 48.4% from Latin America, 24.6% from Asia, 22.8% from Europe, 2.9% from Africa, 1.2% from Canada, and 0.2% from Oceania. Of the foreign-born population, 43.7% were naturalized U.S. citizens, and 56.3% were not U.S. citizens. In 2007, 6.9% of Illinois's population was reported as being under age 5, 24.9% under age 18 and 12.1% were age 65 and over. Females made up approximately 50.7% of the population.\n\nAccording to the 2007 estimates, 21.1% of the population had German ancestry, 13.3% had Irish ancestry, 8% had British ancestry, 7.9% had Polish ancestry, 6.4% had Italian ancestry, 4.6% listed themselves as American, 2.4% had Swedish ancestry, 2.2% had French ancestry, other than Basque, 1.6% had Dutch ancestry, and 1.4% had Norwegian ancestry. Illinois also has large numbers of African Americans and Latinos (mostly Mexicans and Puerto Ricans).\n\nChicago, along the shores of Lake Michigan, is the nation's third largest city. In 2000, 23.3% of Illinois's population lived in the city of Chicago, 43.3% in Cook County, and 65.6% in the counties of the Chicago metropolitan area: Will, DuPage, Kane, Lake, and McHenry counties, as well as Cook County. The remaining population lives in the smaller cities and rural areas that dot the state's plains. As of 2000, the state's center of population was at , located in Grundy County, northeast of the village of Mazon.\n\n\"Note: Births in table don't add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number.\"\n\n\nChicago is the largest city in the state and the third-most populous city in the United States, with its 2010 population of 2,695,598. The U.S. Census Bureau currently lists seven other cities with populations of over 100,000 within Illinois. Based upon the Census Bureau's official 2010 population: Aurora, a Chicago satellite town that eclipsed Rockford for the title of second-most populous city in Illinois; its 2010 population was 197,899. Rockford, at 152,871, is the third-largest city in the state, and is the largest city in the state not located within the Chicago suburbs. Joliet, located in metropolitan Chicago, is the fourth-largest city in the state, with a population of 147,433. Naperville, a suburb of Chicago, is fifth with 141,853. Naperville and Aurora share a boundary along Illinois Route 59. Springfield, the state's capital, comes in as sixth-most populous with 117,352 residents. Peoria, which decades ago was the second-most populous city in the state, is seventh with 115,007. The eighth-largest and final city in the 100,000 club is Elgin, a northwest suburb of Chicago, with a 2010 population of 108,188.\n\nThe most populated city in the state south of Springfield is Belleville, with 44,478 people at the 2010 census. It is located in the Illinois portion of Greater St. Louis (often called the Metro-East area), which has a rapidly growing population of over 700,000 people.\n\nOther major urban areas include the Champaign-Urbana Metropolitan Area, which has a combined population of almost 230,000 people, the Illinois portion of the Quad Cities area with about 215,000 people, and the Bloomington-Normal area with a combined population of over 165,000.\n\nThe official language of Illinois is English, although between 1923 and 1969, state law gave official status to \"the American language\". Nearly 80% of people in Illinois speak English natively, and most of the rest speak it fluently as a second language. A number of dialects of American English are spoken, ranging from Inland Northern American English and African-American English around Chicago, to Midland American English in Central Illinois, to Southern American English in the far south.\n\nOver 20% of Illinoians speak a language other than English at home, of which Spanish is by far the most widespread, at more than 12% of the total population. A sizeable number of Polish speakers is present in the Chicago Metropolitan Area.\n\nRoman Catholics constitute the single largest religious denomination in Illinois; they are heavily concentrated in and around Chicago, and account for nearly 30% of the state's population. However, taken together \"as a group\", the various Protestant denominations comprise a greater percentage of the state's population than do Catholics. In 2010 Catholics in Illinois numbered 3,648,907. The largest Protestant denominations were the United Methodist Church with 314,461, and the Southern Baptist Convention, with 283,519 members. Illinois has one of the largest concentrations of Missouri Synod Lutherans in the United States.\n\nIllinois played an important role in the early Latter Day Saint movement, with Nauvoo, Illinois, becoming a gathering place for Mormons in the early 1840s. Nauvoo was the location of the succession crisis, which led to the separation of the Mormon movement into several Latter Day Saint sects. The Church of Jesus Christ of Latter-day Saints, the largest of the sects to emerge from the Mormon schism, has over 55,000 adherents in Illinois today.\n\nA significant number of adherents of other Abrahamic faiths can be found in Illinois. Largely concentrated in the Chicago metropolitan area, followers of the Muslim, Bahá'í, and Jewish religions all call the state home. Muslims constituted the largest non-Christian group, with 359,264 adherents. Illinois has the largest concentration of Muslims by state in the country, with 2,800 Muslims per 100,000 citizens. The largest and oldest surviving Bahá'í House of Worship in the world is located in Wilmette, Illinois, and the oldest standing mosque in the U.S. is the Al-Sadiq Mosque of the Ahmadiyya Muslim Community, located in the Bronzeville neighborhood of Chicago. The Chicago area has a very large Jewish community, particularly in the suburbs of Skokie and Morton Grove. Current Chicago Mayor Rahm Emanuel is the Windy City's first Jewish mayor.\n\nChicago is also home to a very large population of Hindus, Sikhs, Jains, and Buddhists.\n\nThe dollar gross state product for Illinois was estimated to be billion in 2016. The state's 2010 per capita gross state product was estimated to be , and its per capita personal income was estimated to be in 2009.\n\n, the state's unemployment rate was 4.6%.\n\nIllinois's state income tax is calculated by multiplying net income by a flat rate. In 1990, that rate was set at 3%, but in 2010, the General Assembly voted in a temporary increase in the rate to 5%; the new rate went into effect on January 1, 2011; the personal income rate partially sunset on January 1, 2015 to 3.75%, while the corporate income tax fell to 5.25%. There are two rates for state sales tax: 6.25% for general merchandise and 1% for qualifying food, drugs, and medical appliances. The property tax is a major source of tax revenue for local government taxing districts. The property tax is a local—not state—tax, imposed by local government taxing districts, which include counties, townships, municipalities, school districts, and special taxation districts. The property tax in Illinois is imposed only on real property.\n\nIllinois's major agricultural outputs are corn, soybeans, hogs, cattle, dairy products, and wheat. In most years, Illinois is either the first or second state for the highest production of soybeans, with a harvest of 427.7 million bushels (11.64 million metric tons) in 2008, after Iowa's production of 444.82 million bushels (12.11 million metric tons). Illinois ranks second in U.S. corn production with more than 1.5 billion bushels produced annually. With a production capacity of 1.5 billion gallons per year, Illinois is a top producer of ethanol, ranking third in the United States in 2011. Illinois is a leader in food manufacturing and meat processing. Although Chicago may no longer be \"Hog Butcher for the World\", the Chicago area remains a global center for food manufacture and meat processing, with many plants, processing houses, and distribution facilities concentrated in the area of the former Union Stock Yards. Illinois also produces wine, and the state is home to two American viticultural areas. In the area of The Meeting of the Great Rivers Scenic Byway, peaches and apples are grown. The German immigrants from agricultural backgrounds who settled in Illinois in the mid- to late 19th century are in part responsible for the profusion of fruit orchards in that area of Illinois. Illinois's universities are actively researching alternative agricultural products as alternative crops.\n\nIllinois is one of the nation's manufacturing leaders, boasting annual value added productivity by manufacturing of over $107 billion in 2006. , Illinois is ranked as the 4th-most productive manufacturing state in the country, behind California, Texas, and Ohio. About three quarters of the state's manufacturers are located in the Northeastern Opportunity Return Region, with 38 percent of Illinois's approximately 18,900 manufacturing plants located in Cook County. As of 2006, the leading manufacturing industries in Illinois, based upon value-added, were chemical manufacturing ($18.3 billion), machinery manufacturing ($13.4 billion), food manufacturing ($12.9 billion), fabricated metal products ($11.5 billion), transportation equipment ($7.4 billion), plastics and rubber products ($7.0 billion), and computer and electronic products ($6.1 billion).\n\nBy the early 2000s, Illinois's economy had moved toward a dependence on high-value-added services, such as financial trading, higher education, law, logistics, and medicine. In some cases, these services clustered around institutions that hearkened back to Illinois's earlier economies. For example, the Chicago Mercantile Exchange, a trading exchange for global derivatives, had begun its life as an agricultural futures market. Other important non-manufacturing industries include publishing, tourism, and energy production and distribution.\n\nVenture capitalists funded a total of approximately $62 billion in the US economy in 2016. Of this amount, Illinois-based companies received approximately $1.1 billion. Similarly, in FY 2016, the US federal government spent $461 billion on contracts in the US. Of this amount, Illinois based companies received approximately $8.7 billion.\n\nIllinois is a net importer of fuels for energy, despite large coal resources and some minor oil production. Illinois exports electricity, ranking fifth among states in electricity production and seventh in electricity consumption.\n\nThe coal industry of Illinois has its origins in the middle 19th century, when entrepreneurs such as Jacob Loose discovered coal in locations such as Sangamon County. Jacob Bunn contributed to the development of the Illinois coal industry, and was a founder and owner of the Western Coal & Mining Company of Illinois. About 68% of Illinois has coal-bearing strata of the Pennsylvanian geologic period. According to the Illinois State Geological Survey, 211 billion tons of bituminous coal are estimated to lie under the surface, having a total heating value greater than the estimated oil deposits in the Arabian Peninsula. However, this coal has a high sulfur content, which causes acid rain, unless special equipment is used to reduce sulfur dioxide emissions. Many Illinois power plants are not equipped to burn high-sulfur coal. In 1999, Illinois produced 40.4 million tons of coal, but only 17 million tons (42%) of Illinois coal was consumed in Illinois. Most of the coal produced in Illinois is exported to other states and countries. In 2008, Illinois exported 3 million tons of coal, and was projected to export 9 million tons in 2011, as demand for energy grows in places such as China, India, and elsewhere in Asia and Europe. , Illinois was ranked third in recoverable coal reserves at producing mines in the nation. Most of the coal produced in Illinois is exported to other states, while much of the coal burned for power in Illinois (21 million tons in 1998) is mined in the Powder River Basin of Wyoming.\n\nMattoon was recently chosen as the site for the Department of Energy's FutureGen project, a 275-megawatt experimental zero emission coal-burning power plant that the DOE just gave a second round of funding. In 2010, after a number of setbacks, the city of Mattoon backed out of the project.\n\nIllinois is a leading refiner of petroleum in the American Midwest, with a combined crude oil distillation capacity of nearly . However, Illinois has very limited crude oil proved reserves that account for less than 1% of U.S. crude oil proved reserves. Residential heating is 81% natural gas compared to less than 1% heating oil. Illinois is ranked 14th in oil production among states, with a daily output of approximately in 2005.\n\nNuclear power arguably began in Illinois with the Chicago Pile-1, the world's first artificial self-sustaining nuclear chain reaction in the world's first nuclear reactor, built on the University of Chicago campus. There are six operating nuclear power plants in Illinois: Braidwood, Byron, Clinton, Dresden, LaSalle, and Quad Cities. With the exception of the single-unit Clinton plant, each of these facilities has two reactors. Three reactors have been permanently shut down and are in various stages of decommissioning: Dresden-1 and Zion-1 and 2. Illinois ranked first in the nation in 2010 in both nuclear capacity and nuclear generation. Generation from its nuclear power plants accounted for 12 percent of the nation's total. In 2007, 48% of Illinois's electricity was generated using nuclear power. The Morris Operation is the only de facto high-level radioactive waste storage site in the United States.\n\nIllinois has seen growing interest in the use of wind power for electrical generation. Most of Illinois was rated in 2009 as \"marginal or fair\" for wind energy production by the U.S. Department of Energy, with some western sections rated \"good\" and parts of the south rated \"poor\". These ratings are for wind turbines with hub heights; newer wind turbines are taller, enabling them to reach stronger winds farther from the ground. As a result, more areas of Illinois have become prospective wind farm sites. As of September 2009, Illinois had 1116.06 MW of installed wind power nameplate capacity with another 741.9 MW under construction. Illinois ranked ninth among U.S. states in installed wind power capacity, and sixteenth by potential capacity. Large wind farms in Illinois include Twin Groves, Rail Splitter, EcoGrove, and Mendota Hills.\n\nAs of 2007, wind energy represented only 1.7% of Illinois's energy production, and it was estimated that wind power could provide 5–10% of the state's energy needs. Also, the Illinois General Assembly mandated in 2007 that by 2025, 25% of all electricity generated in Illinois is to come from renewable resources.\n\nIllinois is ranked second in corn production among U.S. states, and Illinois corn is used to produce 40% of the ethanol consumed in the United States. The Archer Daniels Midland corporation in Decatur, Illinois, is the world's leading producer of ethanol from corn.\n\nThe National Corn-to-Ethanol Research Center (NCERC), the world's only facility dedicated to researching the ways and means of converting corn (maize) to ethanol is located on the campus of Southern Illinois University Edwardsville.\n\nUniversity of Illinois at Urbana–Champaign is one of the partners in the Energy Biosciences Institute (EBI), a $500 million biofuels research project funded by petroleum giant BP.\n\nIllinois has numerous museums; the greatest concentration of these are in Chicago. Several museums in Chicago are ranked as some of the best in the world. These include the John G. Shedd Aquarium, the Field Museum of Natural History, the Art Institute of Chicago, the Adler Planetarium, and the Museum of Science and Industry.\n\nThe modern Abraham Lincoln Presidential Library and Museum in Springfield is the largest and most attended presidential library in the country. The Illinois State Museum boasts a collection of 13.5 million objects that tell the story of Illinois life, land, people, and art. The ISM is among only 5% of the nation's museums that are accredited by the American Alliance of Museums. Other historical museums in the state include the Polish Museum of America in Chicago; Magnolia Manor in Cairo; Easley Pioneer Museum in Ipava; the Elihu Benjamin Washburne; Ulysses S. Grant Homes, both in Galena; and the Chanute Air Museum, located on the former Chanute Air Force Base in Rantoul.\n\nThe Chicago metropolitan area also hosts two zoos: The very large Brookfield Zoo, located approximately 10 miles west of the city center in suburban Brookfield, contains over 2,300 animals and covers . The Lincoln Park Zoo is located in huge Lincoln Park on Chicago's North Side, approximately north of the Loop. The zoo covers over within the park.\n\nIllinois is a leader in music education, having hosted the Midwest Clinic International Band and Orchestra Conference since 1946, as well being home to the Illinois Music Educators Association (IMEA), one of the largest professional music educator's organizations in the country. Each summer since 2004, Southern Illinois University Carbondale has played host to the Southern Illinois Music Festival, which presents dozens of performances throughout the region. Past featured artists include the Eroica Trio and violinist David Kim.\n\nChicago, in the northeast corner of the state, is a major center for music in the midwestern United States where distinctive forms of blues (greatly responsible for the future creation of rock and roll), and house music, a genre of electronic dance music, were developed.\n\nThe Great Migration of poor black workers from the South into the industrial cities brought traditional jazz and blues music to the city, resulting in Chicago blues and \"Chicago-style\" Dixieland jazz. Notable blues artists included Muddy Waters, Junior Wells, Howlin' Wolf and both Sonny Boy Williamsons; jazz greats included Nat King Cole, Gene Ammons, Benny Goodman, and Bud Freeman. Chicago is also well known for its soul music.\n\nIn the early 1930s, Gospel music began to gain popularity in Chicago due to Thomas A. Dorsey's contributions at Pilgrim Baptist Church.\n\nIn the 1980s and 1990s, heavy rock, punk, and hip hop also became popular in Chicago. Orchestras in Chicago include the Chicago Symphony Orchestra, the Lyric Opera of Chicago, and the Chicago Sinfonietta.\n\nJohn Hughes, who moved from Grosse Pointe to Northbrook, based many films of his in Chicago, and its suburbs. Ferris Bueller's Day Off, Home Alone, The Breakfast Club, and all of his films take place in the fictional Shermer, Illinois (the original name of Northbrook was Shermerville, and Hughes's High School, Glenbrook North High School, is on Shermer Road). Most locations in his films include Glenbrook North, the former Maine North High School, the Ben Rose House in Highland Park, and the famous Home Alone house in Winnetka, Illinois.\n\nAs one of the United States' major metropolises, all major sports leagues have teams headquartered in Chicago.\n\n\nMany minor league teams also call Illinois their home. They include:\n\nThe state features 13 athletic programs that compete in NCAA Division I, the highest level of U.S. college sports.\n\nThe two most prominent are the Illinois Fighting Illini and Northwestern Wildcats, both members of the Big Ten Conference and the only ones competing in one of the so-called \"Power Five conferences\". The Fighting Illini football team has won five national championships and three Rose Bowl Games, whereas the men's basketball team has won 17 conference seasons and played five Final Fours. Meanwhile, the Wildcats have won eight football conference championships and one Rose Bowl Game.\n\nThe Northern Illinois Huskies from DeKalb, Illinois compete in the Mid-American Conference winning 4 conference championships and earning a bid in the Orange Bowl along with producing Heisman candidate Jordan Lynch at quarterback. The Huskies are the state's only other team competing in the Football Bowl Subdivision, the top level of NCAA football.\n\nFour schools have football programs that compete in the second level of Division I football, the Football Championship Subdivision. The Illinois State Redbirds (Normal, adjacent to Bloomington) and Southern Illinois Salukis (the latter representing Southern Illinois University's main campus in Carbondale) are members of the Missouri Valley Conference (MVC) for non-football sports and the Missouri Valley Football Conference (MVFC). The Western Illinois Leathernecks (Macomb) are full members of the Summit League, which does not sponsor football, and also compete in the MVFC. The Eastern Illinois Panthers (Charleston) are members of the Ohio Valley Conference (OVC).\n\nThe city of Chicago is home to four Division I programs that do not sponsor football. The DePaul Blue Demons, with main campuses in Lincoln Park and the Loop, are members of the Big East Conference. The Loyola Ramblers, with their main campus straddling the Edgewater and Rogers Park community areas on the city's far north side, compete in the MVC. The UIC Flames, from the Near West Side next to the Loop, are in the Horizon League. The Chicago State Cougars, from the city's south side, compete in the Western Athletic Conference.\n\nFinally, two non-football Division I programs are located downstate. The Bradley Braves (Peoria) are MVC members, and the SIU Edwardsville Cougars (in the Metro East region across the Mississippi River from St. Louis) compete in the OVC.\n\nThe city was formerly home to several other teams that either failed to survive, or that belonged to leagues that folded.\n\nThe NFL's Arizona Cardinals, who currently play in the Phoenix suburb of Glendale, Arizona, played in Chicago as the Chicago Cardinals, until moving to St. Louis, Missouri after the 1959 season. An NBA expansion team known as the Chicago Packers in 1961–1962, and as the Chicago Zephyrs the following year, moved to Baltimore after the 1962–1963 season. The franchise is now known as the Washington Wizards.\n\nThe Peoria Chiefs and Kane County Cougars are minor league baseball teams affiliated with MLB. The Schaumburg Boomers and Lake County Fielders are members of the North American League, and the Southern Illinois Miners, Gateway Grizzlies, Joliet Slammers, Windy City ThunderBolts, and Normal CornBelters belong to the Frontier League.\n\nIn addition to the Chicago Wolves, the AHL also has the Rockford IceHogs serving as the AHL affiliate of the Chicago Blackhawks. The second incarnation of the Peoria Rivermen plays in the SPHL.\n\nMotor racing oval tracks at the Chicagoland Speedway in Joliet, the Chicago Motor Speedway in Cicero and the Gateway International Raceway in Madison, near St. Louis, have hosted NASCAR, CART, and IRL races, whereas the Sports Car Club of America, among other national and regional road racing clubs, have visited the Autobahn Country Club in Joliet, the Blackhawk Farms Raceway in South Beloit and the former Meadowdale International Raceway in Carpentersville. Illinois also has several short tracks and dragstrips. The dragstrip at Gateway International Raceway and the Route 66 Raceway, which sits on the same property as the Chicagoland Speedway, both host NHRA drag races.\n\nIllinois features several golf courses, such as Olympia Fields, Medinah, Midlothian, Cog Hill, and Conway Farms, which have often hosted the BMW Championship, Western Open, and Women's Western Open.\n\nAlso, the state has hosted 13 editions of the U.S. Open (latest at Olympia Fields in 2003), six editions of the PGA Championship (latest at Medinah in 2006), three editions of the U.S. Women's Open (latest at The Merit Club), the 2009 Solheim Cup (at Rich Harvest Farms), and the 2012 Ryder Cup (at Medinah).\n\nThe John Deere Classic is a regular PGA Tour event played in the Quad Cities since 1971, whereas the Encompass Championship is a Champions Tour event since 2013. Previously, the LPGA State Farm Classic was an LPGA Tour event from 1976 to 2011.\n\nThe Illinois state parks system began in 1908 with what is now Fort Massac State Park, becoming the first park in a system encompassing over 60 parks and about the same number of recreational and wildlife areas.\n\nAreas under the protection and control of the National Park Service include: the Illinois and Michigan Canal National Heritage Corridor near Lockport, the Lewis and Clark National Historic Trail, the Lincoln Home National Historic Site in Springfield, the Mormon Pioneer National Historic Trail, the Trail of Tears National Historic Trail, the American Discovery Trail, and the Pullman National Monument. The federal government also manages the Shawnee National Forest and the Midewin National Tallgrass Prairie.\n\nThe government of Illinois, under the Constitution of Illinois, has three branches of government: executive, legislative and judicial. The executive branch is split into several statewide elected offices, with the Governor as chief executive. Legislative functions are granted to the Illinois General Assembly. The judiciary is composed of the Supreme Court and lower courts.\n\nThe Illinois General Assembly is the state legislature, composed of the 118-member Illinois House of Representatives and the 59-member Illinois Senate. The members of the General Assembly are elected at the beginning of each even-numbered year. The \"Illinois Compiled Statutes\" (ILCS) are the codified statutes of a general and permanent nature.\n\nThe executive branch is composed of six elected officers and their offices as well as numerous other departments. The six elected officers are: Governor, Lieutenant Governor, Attorney General, Secretary of State, Comptroller, and Treasurer. The government of Illinois has numerous departments, agencies, boards and commissions, but the so-called code departments provide most of the state's services.\n\nThe Judiciary of Illinois is the unified court system of Illinois. It consists of the Supreme Court, Appellate Court, and Circuit Courts. The Supreme Court oversees the administration of the court system.\n\nThe administrative divisions of Illinois are counties, townships, precincts, cities, towns, villages, and special-purpose districts. The basic subdivision of Illinois are the 102 counties. Eighty-five of the 102 counties are in turn divided into townships and precincts. Municipal governments are the cities, villages, and incorporated towns. Some localities possess \"home rule\", which allows them to govern themselves to a certain extent.\n\nIllinois is a Democratic stronghold, and it is considered one of the most Democratic states in the US. Historically, Illinois was a political swing state, with near-parity existing between the Republican and the Democratic parties. However, in recent elections, the Democratic Party has gained ground, and Illinois has come to be seen as a solid \"blue\" state in presidential campaigns. Votes from Chicago and most of Cook County have long been strongly Democratic. However, the \"collar counties\" (the suburbs surrounding Chicago's Cook County, Illinois), can be seen as moderate voting districts. College towns like Carbondale, Champaign, and Normal also lean Democratic.\n\nRepublicans continue to prevail in the outlying Chicago exurban areas, as well as rural northern and central Illinois; Republican support is also strong in southern Illinois, outside of East St. Louis. From 1920 until 1972, Illinois was carried by the victor of each of these 14 presidential elections. In fact, the state was long seen as a national bellwether, supporting the winner in every election in the 20th century, except for 1916 and 1976. By contrast, Illinois has trended more toward the Democratic party, and has voted for their presidential candidates in the last six elections; in 2000, George W. Bush became the first Republican to win the presidency without carrying either Illinois or Vermont. Local politician and Chicago resident Barack Obama easily won the state's 21 electoral votes in 2008, with 61.9% of the vote. In 2010, incumbent Governor Pat Quinn was re-elected with 47% of the vote, while Republican Mark Kirk was elected to the Senate with 48% of the vote. In 2012, President Obama easily carried Illinois again, with 58% to Republican candidate Mitt Romney's 41%. In 2014, Republican Bruce Rauner defeated Governor Quinn 50% to 46% to become Illinois's first Republican governor in 12 years after being sworn in on January 12, 2015, while Democratic Senator Dick Durbin was re-elected with 53% of the vote. In 2016, Hillary Clinton carried Illinois with 55% of the vote, and Tammy Duckworth defeated incumbent Mark Kirk 54% to 40%. George W. Bush and Donald Trump are the only Republicans presidential candidates to win the US Presidency without carrying either Illinois or Vermont.\n\nPolitics in the state have been infamous for highly visible corruption cases, as well as for crusading reformers, such as governors Adlai Stevenson and James R. Thompson. In 2006, former Governor George Ryan was convicted of racketeering and bribery, leading to a six-and-a-half-year prison sentence. In 2008, then-Governor Rod Blagojevich was served with a criminal complaint on corruption charges, stemming from allegations that he conspired to sell the vacated Senate seat left by President Barack Obama to the highest bidder. Subsequently, on December 7, 2011, Rod Blagojevich was sentenced to 14 years in prison for those charges, as well as perjury while testifying during the case, totaling 18 convictions. Blagojevich was impeached and convicted by the legislature, resulting in his removal from office. In the late 20th century, Congressman Dan Rostenkowski was imprisoned for mail fraud; former governor and federal judge Otto Kerner, Jr. was imprisoned for bribery; Secretary of State Paul Powell was investigated and found to have gained great wealth through bribes, and State Auditor of Public Accounts (Comptroller) Orville Hodge was imprisoned for embezzlement. In 1912, William Lorimer, the GOP boss of Chicago, was expelled from the U.S. Senate for bribery and in 1921, Governor Len Small was found to have defrauded the state of a million dollars.\nIllinois has shown a strong presence in presidential elections. Three presidents have claimed Illinois as their political base when running for president: Abraham Lincoln, Ulysses S. Grant, and most recently Barack Obama. Lincoln was born in Kentucky, but he moved to Illinois at age 21. He served in the General Assembly and represented the 7th congressional district in the U.S. House of Representatives before his election to the presidency in 1860. Ulysses S. Grant was born in Ohio and had a military career that precluded settling down, but on the eve of the Civil War and approaching middle age, he moved to Illinois and thus utilized the state as his home and political base when running for President. Barack Obama was born in Hawaii and made Illinois his home after graduating from law school, and later represented Illinois in the U.S. Senate. He then became president in 2008, running as a candidate from his Illinois base.\n\nRonald Reagan was born in Illinois, in the city of Tampico, raised in Dixon, Illinois, and educated at Eureka College, outside Peoria. Reagan later moved to California during his young adulthood. He then became an actor, and later became California's Governor before being elected president.\n\nHillary Clinton was born and raised in the suburbs of Chicago and became the first (and only woman thus far) to represent a major political party in the general election of the U.S. presidency. Clinton ran from a platform based in New York State.\n\nNine African-Americans have served as members of the United States Senate. Three of them have represented Illinois, the most of any single state: Carol Moseley-Braun, Barack Obama, and Roland Burris, who was appointed to replace Obama after his election to the presidency. Moseley-Braun was the first African-American woman to become a U.S. Senator.\nThree families from Illinois have played particularly prominent roles in the Democratic Party, gaining both statewide and national fame.\n\nThe Stevenson family, initially rooted in central Illinois and later based in the Chicago metropolitan area, has provided four generations of Illinois officeholders.\n\nThe Daley family's powerbase was in Chicago.\n\nThe Pritzker family is based in Chicago and have played important roles both in the private and public sectors.\n\nThe Illinois State Board of Education (ISBE) is autonomous of the governor and the state legislature, and administers public education in the state. Local municipalities and their respective school districts operate individual public schools, but the ISBE audits performance of public schools with the Illinois School Report Card. The ISBE also makes recommendations to state leaders concerning education spending and policies.\n\nEducation is compulsory from ages 7 to 17 in Illinois. Schools are commonly, but not exclusively, divided into three tiers of primary and secondary education: elementary school, middle school or junior high school, and high school. District territories are often complex in structure. Many areas in the state are actually located in \"two\" school districts—one for high school, the other for elementary and middle schools. And such districts do not necessarily share boundaries. A given high school may have several elementary districts that feed into it, yet some of those feeder districts may themselves feed into multiple high school districts.\n\nUsing the criterion established by the Carnegie Foundation for the Advancement of Teaching, there are eleven \"National Universities\" in the state. , six of these rank in the \"first tier\" (that is, the top quartile) among the top 500 National Universities in the United States, as determined by the \"U.S. News & World Report\" rankings: the University of Chicago (4), Northwestern University (12), the University of Illinois at Urbana–Champaign (41), Loyola University Chicago (89), the Illinois Institute of Technology (108), DePaul University (123), University of Illinois at Chicago (129), Illinois State University (149), Southern Illinois University Carbondale (153), and Northern Illinois University (194).\n\nThe University of Chicago is continuously ranked as one of the world's top ten universities on various independent university rankings, and its Booth School of Business, along with Northwestern's Kellogg School of Management consistently rank within the top 5 graduate business schools in the country and top 10 globally. The University of Illinois at Urbana–Champaign is often ranked among the best engineering schools in the world and in United States.\n\nIllinois also has more than 20 additional accredited four-year universities, both public and private, and dozens of small liberal arts colleges across the state. Additionally, Illinois supports 49 public community colleges in the Illinois Community College System.\n\nBecause of its central location and its proximity to the Rust Belt and Grain Belt, Illinois is a national crossroads for air, auto, rail, and truck traffic.\n\nFrom 1962 until 1998, Chicago's O'Hare International Airport (ORD) was the busiest airport in the world, measured both in terms of total flights and passengers. While it was surpassed by Atlanta's Hartsfield in 1998 (as Chicago splits its air traffic between O'Hare and Midway airports, while Atlanta only uses one airport), with 59.3 million domestic passengers annually, along with 11.4 million international passengers in 2008, O'Hare consistently remains one of the two or three busiest airports globally, and in some years still ranks number one in total flights. It is a major hub for both United Airlines and American Airlines, and a major airport expansion project is currently underway. Midway Airport (MDW), which had been the busiest airport in the world at one point until it was supplanted by O'Hare as the busiest airport in 1962, is now the secondary airport in the Chicago metropolitan area and still ranks as one of the nation's busiest airports. Midway is a major hub for Southwest Airlines and services many other carriers as well. Midway served 17.3 million domestic and international passengers in 2008.\n\nIllinois has an extensive passenger and freight rail transportation network. Chicago is a national Amtrak hub and in-state passengers are served by Amtrak's Illinois Service, featuring the Chicago to Carbondale \"Illini\" and \"Saluki\", the Chicago to Quincy \"Carl Sandburg\" and \"Illinois Zephyr\", and the Chicago to St. Louis \"Lincoln Service\". Currently there is trackwork on the Chicago–St. Louis line to bring the maximum speed up to , which would reduce the trip time by an hour and a half. Nearly every North American railway meets at Chicago, making it the largest and most active rail hub in the country. Extensive commuter rail is provided in the city proper and some immediate suburbs by the Chicago Transit Authority's 'L' system. One of the largest suburban commuter rail system in the United States, operated by Metra, uses existing rail lines to provide direct commuter rail access for hundreds of suburbs to the city and beyond.\n\nIn addition to the state's rail lines, the Mississippi River and Illinois River provide major transportation routes for the state's agricultural interests. Lake Michigan gives Illinois access to the Atlantic Ocean by way of the Saint Lawrence Seaway.\n\nIllinois has a well developed interstate highway system. Illinois has the distinction of having the most primary (two-digit) interstates pass through it among all the 50 states with 13 (with the new addition of Interstate 41 near Wisconsin). Illinois also ranks third among the fifty states with the most interstate mileage, coming in after California and Texas, which are much bigger states in area.\n\nMajor U.S. Interstate highways crossing the state include: Interstate 24 (I-24), I-39, I-41, I-55, I-57, I-64, I-70, I-72, I-74, I-80, I-88, I-90, and I-94.\n\nAmong the U.S. highways that pass through the state, the primary ones are: US 6, US 12, US 14, US 20, US 24, US 30, US 34, US 36, US 40, US 41, US 45, US 50, US 51, US 52, US 54, US 60, US 62, and US 67.\n\nA 2018 survey conducted by the Center for State Policy and Leadership at the University of Illinois Springfield and NPR Illinois found that over half of respondents had at least one time considered leaving the state. The three main reasons people cite are dysfunctional government, \"disappointing job opportunities,\" and high taxes. Taxes were the number one reason.\n\n\n\n"}
{"id": "14851", "url": "https://en.wikipedia.org/wiki?curid=14851", "title": "Ian Murdock", "text": "Ian Murdock\n\nIan Ashley Murdock (28April 1973 28December 2015) was an American software engineer, known for being the founder of the Debian project and Progeny Linux Systems, a commercial Linux company.\n\nAlthough Murdock's parents were both from Southern Indiana, he was born in Konstanz, West Germany, on 28 April 1973, where his father was pursuing postdoctoral\nresearch. The family returned to the United States in 1975, and Murdock grew up in Lafayette, Indiana, beginning in 1977 when his father became a professor of entomology at Purdue University. Murdock graduated from Harrison High School in 1991, and then earned his bachelor's degree in computer science from Purdue in 1996.\n\nWhile a college student, Murdock founded the Debian project in August 1993, and wrote the Debian Manifesto in January 1994. Murdock conceived Debian as a Linux distribution that embraced open design, contributions, and support from the free software community. He named Debian after his then-girlfriend (later wife) Debra Lynn, and himself (Deb and Ian). They later married, had three children, and divorced in January 2008.\n\nIn January 2006, Murdock was appointed Chief Technology Officer of the Free Standards Group and elected chair of the Linux Standard Base workgroup. He continued as CTO of the Linux Foundation when the group was formed from the merger of the Free Standards Group and Open Source Development Labs.\n\nMurdock left the Linux Foundation to join Sun Microsystems in March 2007 to lead Project Indiana, which he described as \"taking the lesson that Linux has brought to the operating system and providing that for Solaris\", making a full OpenSolaris distribution with GNOME and userland tools from GNU plus a network-based package management system. From March 2007 to February 2010, he was Vice President of Emerging Platforms at Sun, until the company merged with Oracle and he resigned his position with the company.\n\nFrom 2011 until 2015 Murdock was Vice President of Platform and Developer Community at Salesforce Marketing Cloud, based in Indianapolis.\n\nFrom November 2015 until his death Murdock was working for Docker, Inc.\n\nMurdock died on 28 December 2015 in San Francisco. Though initially no cause of death was released, in July 2016 it was announced his death had been ruled a suicide. The police confirmed that the cause of death was due to asphyxiation caused by hanging himself with a vacuum cleaner electrical cord.\n\nThe last tweets from Murdock's Twitter account first announced that he would commit suicide, then said he would not. He reported having been accused of assault on a police officer after having been himself assaulted by the police, then declared an intent to devote his life to opposing police abuse. His Twitter account was taken down shortly afterwards.\n\nThe San Francisco police confirmed he was detained, saying he matched the description in a reported attempted break-in and that he appeared to be drunk. The police stated that he became violent and was ultimately taken to jail on suspicion of four misdemeanor counts. They added that he did not appear to be suicidal and was medically examined prior to release. Later, police returned on reports of a possible suicide. The city medical examiner's office confirmed Murdock was found dead.\n\n\n"}
{"id": "14856", "url": "https://en.wikipedia.org/wiki?curid=14856", "title": "Inner product space", "text": "Inner product space\n\nIn linear algebra, an inner product space is a vector space with an additional structure called an inner product. This additional structure associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors. Inner products allow the rigorous introduction of intuitive geometrical notions such as the length of a vector or the angle between two vectors. They also provide the means of defining orthogonality between vectors (zero inner product). Inner product spaces generalize Euclidean spaces (in which the inner product is the dot product, also known as the scalar product) to vector spaces of any (possibly infinite) dimension, and are studied in functional analysis. The first usage of the concept of a vector space with an inner product is due to Peano, in 1898.\n\nAn inner product naturally induces an associated norm, thus an inner product space is also a normed vector space. A complete space with an inner product is called a Hilbert space. An (incomplete) space with an inner product is called a pre-Hilbert space, since its completion with respect to the norm induced by the inner product is a Hilbert space. Inner product spaces over the field of complex numbers are sometimes referred to as unitary spaces.\n\nIn this article, the field of scalars denoted is either the field of real numbers or the field of complex numbers .\n\nFormally, an inner product space is a vector space over the field together with an \"inner product\", i.e., with a map\n\nthat satisfies the following three axioms for all vectors and all scalars :\n\n\n\n\nWhen , conjugate symmetry reduces to symmetry. That is, for ; while for , is equal to the complex conjugate.\n\nNotice that conjugate symmetry implies that is real for all , since we have:\n\nMoreover, sesquilinearity (see below) implies that\n\nConjugate symmetry and linearity in the first variable gives\n\nso an inner product is a sesquilinear form, in the sense that the second argument is conjugate linear. Conjugate symmetry is also called Hermitian symmetry, and a conjugate symmetric sesquilinear form is called a \"Hermitian form\". While the above axioms are more mathematically economical, a compact verbal definition of an inner product is a \"positive-definite Hermitian form\".\n\nIn the case of , conjugate-symmetry reduces to symmetry, and sesquilinear reduces to bilinear. So, an inner product on a real vector space is a \"positive-definite symmetric bilinear form\".\n\nCombining the linearity of the inner product in its first argument and the conjugate symmetry gives the following important generalization of the familiar square expansion:\nAssuming the underlying field to be , the inner product becomes symmetric, and we obtain\nThe property of an inner product space that\nis also known as \"additivity\".\n\nSome authors, especially in physics and matrix algebra, prefer to define the inner product and the sesquilinear form with linearity in the second argument rather than the first. Then the first argument becomes conjugate linear, rather than the second. In those disciplines we would write the product as (the bra–ket notation of quantum mechanics), respectively (dot product as a case of the convention of forming the matrix product as the dot products of rows of with columns of ). Here the kets and columns are identified with the vectors of and the bras and rows with the linear functionals (covectors) of the dual space , with conjugacy associated with duality. This reverse order is now occasionally followed in the more abstract literature, taking to be conjugate linear in rather than . A few instead find a middle ground by recognizing both and as distinct notations differing only in which argument is conjugate linear.\n\nThere are various technical reasons why it is necessary to restrict the basefield to and in the definition. Briefly, the basefield has to contain an ordered subfield in order for non-negativity to make sense, and therefore has to have characteristic equal to 0 (since any ordered field has to have such characteristic). This immediately excludes finite fields. The basefield has to have additional structure, such as a distinguished automorphism. More generally any quadratically closed subfield of or will suffice for this purpose, e.g., the algebraic numbers or the constructible numbers. However in these cases when it is a proper subfield (i.e., neither nor ) even finite-dimensional inner product spaces will fail to be metrically complete. In contrast all finite-dimensional inner product spaces over or , such as those used in quantum computation, are automatically metrically complete and hence Hilbert spaces.\n\nIn some cases we need to consider non-negative \"semi-definite\" sesquilinear forms. This means that is only required to be non-negative. We show how to treat these below.\n\nA simple example is the real numbers with the standard multiplication as the inner product\n\nMore generally, the real -space with the dot product is an inner product space, an example of a Euclidean -space.\nwhere is the transpose of .\n\nThe general form of an inner product on is known as the Hermitian form and is given by\nwhere is any Hermitian positive-definite matrix and is the conjugate transpose of . For the real case this corresponds to the dot product of the results of directionally different scaling of the two vectors, with positive scale factors and orthogonal directions of scaling. Up to an orthogonal transformation it is a weighted-sum version of the dot product, with positive weights.\n\nThe article on Hilbert space has several examples of inner product spaces wherein the metric induced by the inner product yields a complete metric space. An example of an inner product which induces an incomplete metric occurs with the space of continuous complex valued functions on the interval . The inner product is\nThis space is not complete; consider for example, for the interval the sequence of continuous \"step\" functions, , defined by:\nThis sequence is a Cauchy sequence for the norm induced by the preceding inner product, which does not converge to a \"continuous\" function.\n\nFor real random variables and , the expected value of their product\nis an inner product. In this case, if and only if (i.e., almost surely). This definition of expectation as inner product can be extended to random vectors as well.\n\nFor real square matrices of the same size, with transpose as conjugation\nis an inner product.\n\nOn an inner product space, or more generally a vector space with a nondegenerate form (so an isomorphism ) vectors can be sent to covectors (in coordinates, via transpose), so one can take the inner product and outer product of two vectors, not simply of a vector and a covector.\n\nA linear space with a norm such as:\n\nis a normed space but not an inner product space, because this norm does not satisfy the parallelogram equality required of a norm to have an inner product associated with it.\n\nHowever, inner product spaces have a naturally defined norm based upon the inner product of the space itself that does satisfy the parallelogram equality:\n\nThis is well defined by the nonnegativity axiom of the definition of inner product space. The norm is thought of as the length of the vector . Directly from the axioms, we can prove the following:\n\n\n\n\n\n\n\n\n\nLet be a finite dimensional inner product space of dimension . Recall that every basis of consists of exactly linearly independent vectors. Using the Gram–Schmidt process we may start with an arbitrary basis and transform it into an orthonormal basis. That is, into a basis in which all the elements are orthogonal and have unit norm. In symbols, a basis is orthonormal if for every and for each .\n\nThis definition of orthonormal basis generalizes to the case of infinite-dimensional inner product spaces in the following way. Let be any inner product space. Then a collection\n\nis a \"basis\" for if the subspace of generated by finite linear combinations of elements of is dense in (in the norm induced by the inner product). We say that is an \"orthonormal basis\" for if it is a basis and\n\nif and for all .\n\nUsing an infinite-dimensional analog of the Gram-Schmidt process one may show:\n\nTheorem. Any separable inner product space has an orthonormal basis.\n\nUsing the Hausdorff maximal principle and the fact that in a complete inner product space orthogonal projection onto linear subspaces is well-defined, one may also show that\n\nTheorem. Any complete inner product space has an orthonormal basis.\n\nThe two previous theorems raise the question of whether all inner product spaces have an orthonormal basis. The answer, it turns out is negative. This is a non-trivial result, and is proved below. The following proof is taken from Halmos's \"A Hilbert Space Problem Book\" (see the references).\n\nParseval's identity leads immediately to the following theorem:\n\nTheorem. Let be a separable inner product space and an orthonormal basis of . Then the map\nis an isometric linear map with a dense image.\n\nThis theorem can be regarded as an abstract form of Fourier series, in which an arbitrary orthonormal basis plays the role of the sequence of trigonometric polynomials. Note that the underlying index set can be taken to be any countable set (and in fact any set whatsoever, provided is defined appropriately, as is explained in the article Hilbert space). In particular, we obtain the following result in the theory of Fourier series:\n\nTheorem. Let be the inner product space . Then the sequence (indexed on set of all integers) of continuous functions\n\nis an orthonormal basis of the space with the inner product. The mapping\n\nis an isometric linear map with dense image.\n\nOrthogonality of the sequence follows immediately from the fact that if , then\n\nNormality of the sequence is by design, that is, the coefficients are so chosen so that the norm comes out to 1. Finally the fact that the sequence has a dense algebraic span, in the \"inner product norm\", follows from the fact that the sequence has a dense algebraic span, this time in the space of continuous periodic functions on with the uniform norm. This is the content of the Weierstrass theorem on the uniform density of trigonometric polynomials.\n\nSeveral types of linear maps from an inner product space to an inner product space are of relevance:\n\nFrom the point of view of inner product space theory, there is no need to distinguish between two spaces which are isometrically isomorphic. The spectral theorem provides a canonical form for symmetric, unitary and more generally normal operators on finite dimensional inner product spaces. A generalization of the spectral theorem holds for continuous normal operators in Hilbert spaces.\n\nAny of the axioms of an inner product may be weakened, yielding generalized notions. The generalizations that are closest to inner products occur where bilinearity and conjugate symmetry are retained, but positive-definiteness is weakened.\n\nIf is a vector space and a semi-definite sesquilinear form, then the function:\n\nmakes sense and satisfies all the properties of norm except that does not imply (such a functional is then called a semi-norm). We can produce an inner product space by considering the quotient }. The sesquilinear form factors through .\n\nThis construction is used in numerous contexts. The Gelfand–Naimark–Segal construction is a particularly important example of the use of this technique. Another example is the representation of semi-definite kernels on arbitrary sets.\n\nAlternatively, one may require that the pairing be a nondegenerate form, meaning that for all non-zero there exists some such that , though need not equal ; in other words, the induced map to the dual space is injective. This generalization is important in differential geometry: a manifold whose tangent spaces have an inner product is a Riemannian manifold, while if this is related to nondegenerate conjugate symmetric form the manifold is a pseudo-Riemannian manifold. By Sylvester's law of inertia, just as every inner product is similar to the dot product with positive weights on a set of vectors, every nondegenerate conjugate symmetric form is similar to the dot product with \"nonzero\" weights on a set of vectors, and the number of positive and negative weights are called respectively the positive index and negative index. Product of vectors in Minkowski space is an example of indefinite inner product, although, technically speaking, it is not an inner product according to the standard definition above. Minkowski space has four dimensions and indices 3 and 1 (assignment of \"+\" and \"−\" to them differs depending on conventions).\n\nPurely algebraic statements (ones that do not use positivity) usually only rely on the nondegeneracy (the injective homomorphism ) and thus hold more generally.\n\nThe term \"inner product\" is opposed to outer product, which is a slightly more general opposite. Simply, in coordinates, the inner product is the product of a \"covector\" with an vector, yielding a 1 × 1 matrix (a scalar), while the outer product is the product of an vector with a covector, yielding an matrix. Note that the outer product is defined for different dimensions, while the inner product requires the same dimension. If the dimensions are the same, then the inner product is the \"trace\" of the outer product (trace only being properly defined for square matrices). In a quip: \"inner is horizontal times vertical and shrinks down, outer is vertical times horizontal and expands out\".\n\nMore abstractly, the outer product is the bilinear map sending a vector and a covector to a rank 1 linear transformation (simple tensor of type (1,1)), while the inner product is the bilinear evaluation map given by evaluating a covector on a vector; the order of the domain vector spaces here reflects the covector/vector distinction.\n\nThe inner product and outer product should not be confused with the interior product and exterior product, which are instead operations on vector fields and differential forms, or more generally on the exterior algebra.\n\nAs a further complication, in geometric algebra the inner product and the \"exterior\" (Grassmann) product are combined in the geometric product (the Clifford product in a Clifford algebra) – the inner product sends two vectors (1-vectors) to a scalar (a 0-vector), while the exterior product sends two vectors to a bivector (2-vector) – and in this context the exterior product is usually called the \"\"outer\" (alternatively, wedge) product\". The inner product is more correctly called a \"scalar\" product in this context, as the nondegenerate quadratic form in question need not be positive definite (need not be an inner product).\n\n\n"}
{"id": "14858", "url": "https://en.wikipedia.org/wiki?curid=14858", "title": "Iain Banks", "text": "Iain Banks\n\nIain Banks (16 February 1954 – 9 June 2013) was a Scottish author. He wrote mainstream fiction under the name Iain Banks and science fiction as Iain M. Banks, including the initial of his adopted middle name Menzies ().\n\nAfter the publication and success of \"The Wasp Factory\" (1984), Banks began to write on a full-time basis. His first science fiction book, \"Consider Phlebas\", was released in 1987, marking the start of the Culture series. His books have been adapted for theatre, radio and television. In 2008, \"The Times\" named Banks in their list of \"The 50 greatest British writers since 1945\". In April 2013, Banks announced that he had inoperable cancer and was unlikely to live beyond a year. He died on 9 June 2013.\n\nBanks was born in Dunfermline, Fife, to a mother who was a professional ice skater and a father who was an officer in the Admiralty. An only child, Banks lived in North Queensferry until the age of nine, near the naval dockyards in Rosyth where his father was based. Banks's family then moved to Gourock due to the requirements of his father's work. When someone introduced him to science fiction by giving him \"Kemlo and the Zones of Silence\", he continued reading the Kemlo series which made him want to write science fiction himself. After attending Gourock and Greenock High Schools, Banks studied English, philosophy and psychology at the University of Stirling (1972–1975).\n\nAfter graduation Banks chose a succession of jobs that left him free to write in the evenings. These posts supported his writing throughout his twenties and allowed him to take long breaks between contracts, during which time he travelled through Europe and North America. He was an expediter analyser for IBM, a technician for the British Steel Corporation and a costing clerk for a Chancery Lane, London, law firm during this period of his life.\n\nBanks decided to become a writer at the age of 11. He completed his first novel \"The Hungarian Lift-Jet\" at 16 and his second novel \"TTR\" (aka \"The Tashkent Rambler\") during his first year at Stirling University in 1972. Though he considered himself primarily a science fiction author, his lack of success at being published as such led him to pursue mainstream fiction, resulting in his first published novel \"The Wasp Factory\", which was published in 1984 when he was thirty. After the publication and success of \"The Wasp Factory\", Banks began to write full-time. His editor at Macmillan, James Hale, advised him to write one book a year and Banks agreed to this schedule.\n\nHis second novel \"Walking on Glass\" was published in 1985. \"The Bridge\" followed in 1986, and \"Espedair Street\", published in 1987, was later broadcast as a series on BBC Radio 4. His first published science fiction book \"Consider Phlebas\" was released in 1987 and was the first of several novels of the acclaimed Culture series. Banks cited Robert A. Heinlein, Isaac Asimov, Arthur C. Clarke, Brian Aldiss, M. John Harrison and Dan Simmons as literary influences. \"The Crow Road\", published in 1992, was adapted as a BBC television series. Banks continued to write both science fiction and mainstream novels, with his final novel \"The Quarry\" published in June 2013, the month of his death.\n\nBanks published work under two names. His parents had intended to name him \"Iain Menzies Banks\", but his father made a mistake when registering the birth and \"Iain Banks\" became the officially registered name. Despite this error, Banks used the middle name and submitted \"The Wasp Factory\" for publication as \"Iain M. Banks\". Banks's editor inquired about the possibility of omitting the 'M' as it appeared \"too fussy\" and the potential existed for confusion with Rosie M. Banks, a romantic novelist in the Jeeves novels by P.G. Wodehouse; Banks agreed to the omission. After three mainstream novels, Banks's publishers agreed to publish his first science fiction (SF) novel \"Consider Phlebas\". To create a distinction between the mainstream and SF novels, Banks suggested the return of the 'M' to his name, and it was used in all of his science fiction works.\nBy his death in June 2013 Banks had published 26 novels. His twenty-seventh novel \"The Quarry\" was published posthumously. His final work, a collection of poetry, was released in February 2015. In an interview January 2013, he also mentioned he had the plot idea for another novel in the Culture series, which would most likely be his next book and planned for publication in 2014.\n\nHe wrote in different categories, but enjoyed writing science fiction the most.\n\nIn September 2012 Banks was revealed as one of the Guests of Honour at the 2014 World Science Fiction Convention, Loncon 3.\n\nBanks was the subject of \"The Strange Worlds of Iain Banks\" \"South Bank Show\" (1997), a television documentary that examined his mainstream writing, and was also an in-studio guest for the final episode of Marc Riley's \"Rocket Science\" radio show, broadcast on BBC Radio 6 Music.\n\nAn audio version of \"The Business\", set to contemporary music, arranged by Paul Oakenfold, was broadcast in October 1999 on Galaxy Fm as the tenth Urban Soundtracks.\n\nA radio adaptation of Banks's \"The State of the Art\" was broadcast on BBC Radio 4 in 2009; the adaptation was written by Paul Cornell and the production was directed/produced by Nadia Molinari. In 1998 \"Espedair Street\" was dramatised as a serial for Radio 4, presented by Paul Gambaccini in the style of a Radio 1 documentary.\n\nIn 2011 Banks was featured on the BBC Radio 4 programme \"Saturday Live\". Banks reaffirmed his atheism during his \"Saturday Live\" appearance, whereby he explained that death is an important \"part of the totality of life\" and should be treated realistically, instead of feared.\n\nBanks appeared on the BBC television programme \"Question Time\", a show that features political discussion. In 2006 Banks captained a team of writers to victory in a special series of BBC Two's \"\". Banks also won a 2006 edition of BBC One's \"Celebrity Mastermind\"; the author selected \"Malt whisky and the distilleries of Scotland\" as his specialist subject.\n\nHis final interview was with Kirsty Wark and was broadcast as \"Iain Banks: Raw Spirit\" on BBC2 Scotland on Wednesday 12 June 2013.\n\nBBC One Scotland and BBC2 broadcast an adaptation of his novel Stonemouth in June 2015.\n\nBanks was involved in the theatre production \"The Curse of Iain Banks\" that was written by Maxton Walker and was performed at the Edinburgh Fringe festival in 1999. Banks collaborated with the play's soundtrack composer Gary Lloyd frequently, including on a collection of songs they co-composed in tribute to the fictional band 'Frozen Gold' from Banks's novel 'Espedair Street'. Lloyd also composed the score for a spoken word and musical production of the Banks novel \"The Bridge\" which Banks himself voiced and featured a cast of forty musicians (released on cd by Codex Records in 1996). Lloyd recorded Banks for inclusion in the play as a disembodied voice appearing as himself in one of the cast member's dreams. Lloyd explained his collaboration with Banks on their first versions of 'Espedair Street' (subsequent versions are dated from between 2005 and 2013) in a \"Guardian\" article prior to the opening of \"The Curse of Iain Banks\":\nWhen he [Banks] first played them to me, I think he was worried that they might not be up to scratch (some of them dated back to 1973 and had never been heard). He needn't have worried. They're fantastic. We're slaving away to get the songs to the stage where we can go into the studio and make a demo. Iain bashes out melodies on his state-of-the-art Apple Mac in Edinburgh and sends them down to me in Chester where I put them onto my Atari.\nBanks's political position has been described as \"left of centre\", and he was an Honorary Associate of the National Secular Society and a Distinguished Supporter of the Humanist Society Scotland. As a signatory to the Declaration of Calton Hill, he was an open supporter of Scottish independence. In November 2012, Banks supported the campaign group that emerged from the Radical Independence Conference that was held during that month. Banks explained that the Scottish independence movement was motivated by co-operation and \"just seem to be more communitarian than the consensus expressed by the UK population as a whole\".\n\nIn late 2004, Banks was a member of a group of British politicians and media figures who campaigned to have Prime Minister Tony Blair impeached following the 2003 invasion of Iraq. In protest he cut up his passport and posted it to 10 Downing Street—in a \"Socialist Review\" interview, Banks explained that his passport protest occurred after he \"abandoned the idea of crashing my Land Rover through the gates of Fife dockyard, after spotting the guys armed with machine guns.\" Banks relayed his concerns about the invasion of Iraq in his book \"Raw Spirit\", and the principal protagonist (Alban McGill) in the novel \"The Steep Approach to Garbadale\" confronts another character with arguments of a similar nature.\n\nIn 2010 Banks called for a cultural and educational boycott of Israel after the Gaza flotilla raid incident. In a letter to \"The Guardian\" newspaper, Banks stated that he had instructed his agent to turn down any further book translation deals with Israeli publishers:\nAppeals to reason, international law, U.N. resolutions and simple human decency meanit is now obviousnothing to Israel ... I would urge all writers, artists and others in the creative arts, as well as those academics engaging in joint educational projects with Israeli institutions, to consider doing everything they can to convince Israel of its moral degradation and ethical isolation, preferably by simply having nothing more to do with this outlaw state.\nAn extract from Banks's contribution to the written collection \"Generation Palestine: Voices from the Boycott, Divestment and Sanctions Movement\", entitled \"Our People\", was published in \"The Guardian\" in the wake of the author's cancer revelation. The extract relays the author's support for the Boycott, Divestment and Sanctions (BDS) campaign that was issued by a Palestinian civil society against Israel until the country complies with what they hold are international law and Palestinian rights, that commenced in 2005 and applies the lessons from Banks's experience with South Africa's apartheid era. The continuation of Banks's boycott of Israeli publishers for the sale of the rights to his novels was also confirmed in the extract and Banks further explained, \"I don't buy Israeli-sourced products or food, and my partner and I try to support Palestinian-sourced products wherever possible.\"\n\nIn 2002, Banks endorsed the Scottish Socialist Party.\n\nBanks met his first wife, Annie, in London before the 1984 release of his first book. The couple lived in Faversham in the south of England, then split up in 1988. Banks returned to Edinburgh and dated another woman for two years until she left him. Iain and Annie reconciled a year later and moved to Fife. They got married in Hawaii in 1992; in 2007, after 15 years of marriage, they announced their separation.\n\nIn 1998 Banks was in a near-fatal accident when his car rolled off the road. In February 2007, Banks sold his extensive car collection, including a 3.2-litre Porsche Boxster, a Porsche 911 Turbo, a 3.8-litre Jaguar Mark II, a 5-litre BMW M5 and a daily use diesel Land Rover Defender whose power he had boosted by about 50%. Banks exchanged all of the vehicles for a Lexus RX 400h hybrid – later replaced by a diesel Toyota Yaris – and said in the future he would fly only in emergencies.\n\nIn April 2012 Banks became the \"Acting Honorary Non-Executive Figurehead President Elect pro tem (trainee)\" of the Science Fiction Book Club based in London. The title was his own creation and on 3 October 2012 Banks accepted a T-shirt decorated with this title.\n\nBanks lived in North Queensferry, on the north side of the Firth of Forth, with the author and founder of the Dead by Dawn film festival Adele Hartley. Banks and Hartley commenced their relationship in 2006, and married on 29 March 2013 after he asked her to \"do me the honour of becoming my widow\".\n\nOn 3 April 2013, Banks announced on his website, and one set up by him and some friends, that he had been diagnosed with terminal cancer of the gallbladder and was unlikely to live beyond a year. In his announcement, Banks stated that he would be withdrawing from all public engagements and that \"The Quarry\" would be his last novel. The dates of publication of \"The Quarry\" were brought forward at Banks's request, to 20 June 2013 in the UK and 25 June 2013 in the US. Banks died on 9 June 2013.\n\nBanks's publisher stated that the author was \"an irreplaceable part of the literary world\", a sentiment that was reaffirmed by fellow Scottish author and friend since secondary school Ken MacLeod, who observed that Banks's death \"left a large gap in the Scottish literary scene as well as the wider English-speaking world.\" British author Charles Stross wrote that \"One of the giants of 20th and 21st century Scottish literature has left the building.\" Authors, including Neil Gaiman, Ian Rankin, Alastair Reynolds, and David Brin also paid tribute to Banks, in their blogs and elsewhere.\n\nThe asteroid 5099 Iainbanks was named after him shortly after his death. On 23 January 2015, SpaceX's CEO and Chief Designer Elon Musk named two of the company's autonomous spaceport drone ships \"Just Read The Instructions\" and \"Of Course I Still Love You\", after ships from Banks's novel \"The Player of Games\". Another, \"A Shortfall of Gravitas\", began construction in 2018. The name is a reference to the ship \"Experiencing A Significant Gravitas Shortfall\", first mentioned in \"Look to Windward\".\n\nOn 20 July 2017, Jeph Jacques completed his Alice Grove series, and dedicated it to the memory of Iain Banks.\n\nIain Banks received the following literary awards and nominations:\n\n\nBanks' non-SF work comprises fourteen novels and one non-fiction book. Many of his novels contain elements of autobiography, and feature various locations in his native Scotland. \"Raw Spirit\" (subtitled \"In Search of the Perfect Dram\") is a travel book of Banks' visits to the distilleries of Scotland in search of the finest whisky, including his musings on other subjects such as cars and politics.\n\n\n\nBanks wrote thirteen SF novels, nine of which were part of the Culture series; and a short story collection called \"The State of the Art\" (1991) includes some stories set in the same universe. These works focus upon characters that are usually on the margins of the Culture, a post-scarcity anarchist utopia; in the same universe are other civilizations, with which the Culture sometimes enters into conflict, and sentient artificial intelligences.\n\n\n\n\nBanks wrote introductions for works by other writers including:\n\n\n"}
{"id": "14863", "url": "https://en.wikipedia.org/wiki?curid=14863", "title": "Incunable", "text": "Incunable\n\nAn incunable, or sometimes incunabulum (plural incunables or incunabula, respectively), is a book, pamphlet, or broadside printed in Europe before the year 1501. (Importantly, incunabula are not manuscripts.) there are about 30,000 distinct known incunable editions extant. The number of surviving copies in Germany alone is estimated at around 125,000.\n\n\"Incunable\" is the anglicised singular form of \"incunabula\", Latin for \"swaddling clothes\" or \"cradle\", which can refer to \"the earliest stages or first traces in the development of anything\". A former term for \"incunable\" is \"fifteener\", referring to the 15th century.\n\nThe term \"incunabula\" as a printing term was first used by the Dutch physician and humanist Hadrianus Iunius (Adriaan de Jonghe, 1511–1575) and appears in a passage from his posthumous work (written in 1569): Hadrianus Iunius, \"Batavia\", [...], [Lugduni Batavorum], ex officina Plantiniana, apud Franciscum Raphelengium, 1588, p. 256 l. 3: «inter prima artis [typographicae] incunabula», a term (\"the first infancy of printing\") to which he arbitrarily set an end of 1500 which still stands as a convention.\n\nOnly by a misunderstanding was Bernhard von Mallinckrodt (1591–1664) considered to be the inventor of this meaning of \"incunabula\"; the identical passage is found in his Latin pamphlet \"De ortu ac progressu artis typographicae\" (\"On the rise and progress of the typographic art\", Cologne, 1640): Bernardus a Mallinkrot, \"De ortu ac progressu artis typographicae dissertatio historica\", [...], Coloniae Agrippinae, apud Ioannem Kinchium, 1640 (in frontispiece: 1639), p. 29 l. 16: «inter prima artis [typographicae] incunabula», within a long passage of several pages, which he (correctly) quotes entirely in italic characters (that is between quotation marks), referring to the name of author and work cited: «Primus istorum [...] Hadrianus Iunius est, cuius integrum locum, ex \"Batavia\" eius, operae pretium est adscribere; [...]. Ita igitur Iunius» (ibid., p. 27 ll. 27-32, followed by the long passage, «Redeo → sordes», ibid., p. 27, l. 32 – p. 33 l. 32 [= \"Batavia\", p. 253 l. 28 – p. 258 l. 21]). So the source is only one, the other is a quotation.\n\nThe term \"incunabula\" came to denote the printed books themselves in the late 17th century. John Evelyn, in moving the Arundel Manuscripts to the Royal Society in August 1678, remarked of the printed books among the manuscripts: \"The printed books, being of the oldest impressions, are not the less valuable; I esteem them almost equal to MSS.\" The convenient but arbitrarily chosen end date for identifying a printed book as an incunable does not reflect any notable developments in the printing process, and many books printed for a number of years after 1500 continued to be visually indistinguishable from incunables. \n\n\"Post-incunable\" typically refers to books printed after 1500 up to another arbitrary end date such as 1520 or 1540. From around this period the dating of any edition becomes easier, as the practice of printers including information such as the place and year of printing became more widespread.\n\nThere are two types of \"incunabula\" in printing: the block book, printed from a single carved or sculpted wooden block for each page, employing the same process as the woodcut in art (these may be called \"xylographic\"); and the \"typographic book\", made with individual pieces of cast-metal movable type on a printing press. Many authors reserve the term \"incunabula\" for the latter kind only.\n\nThe spread of printing to cities both in the north and in Italy ensured that there was great variety in the texts chosen for printing and the styles in which they appeared. Many early typefaces were modelled on local forms of writing or derived from the various European forms of Gothic script, but there were also some derived from documentary scripts (such as most of Caxton's types), and, particularly in Italy, types modelled on handwritten scripts and calligraphy employed by humanists.\n\nPrinters congregated in urban centres where there were scholars, ecclesiastics, lawyers, and nobles and professionals who formed their major customer base. Standard works in Latin inherited from the medieval tradition formed the bulk of the earliest printed works, but as books became cheaper, vernacular works (or translations into vernaculars of standard works) began to appear.\n\nThe most famous \"incunabula\" include two from Mainz, the Gutenberg Bible of 1455 and the \"Peregrinatio in terram sanctam\" of 1486, printed and illustrated by Erhard Reuwich; the \"Nuremberg Chronicle\" written by Hartmann Schedel and printed by Anton Koberger in 1493; and the \"Hypnerotomachia Poliphili\" printed by Aldus Manutius with important illustrations by an unknown artist. \n\nOther printers of incunabula were Günther Zainer of Augsburg, Johannes Mentelin and Heinrich Eggestein of Strasbourg, Heinrich Gran of Haguenau and William Caxton of Bruges and London. The first incunable to have woodcut illustrations was Ulrich Boner's \"Der Edelstein\", printed by Albrecht Pfister in Bamberg in 1461.\n\nMany incunabula are undated, needing complex bibliographical analysis to place them correctly. The post-incunabula period marks a time of development during which the printed book evolved fully as a mature artefact with a standard format. After c. 1540 books tended to conform to a template that included the author, title-page, date, seller, and place of printing. This makes it much easier to identify any particular edition.\n\nAs noted above, the \"end date\" for identifying a printed book as an incunable is convenient but was chosen arbitrarily; it does not reflect any notable developments in the printing process around the year 1500. Books printed for a number of years after 1500 continued to look much like incunables, with the notable exception of the small format books printed in italic type introduced by Aldus Manutius in 1501. The term post-incunable is sometimes used to refer to books printed \"after 1500—how long after, the experts have not yet agreed.\" For books printed in the UK, the term generally covers 1501–1520, and for books printed in mainland Europe, 1501–1540.\n\nThe data in this section were derived from the Incunabula Short-Title Catalogue (ISTC).\n\nThe number of printing towns and cities stands at 282. These are situated in some 18 countries in terms of present-day boundaries. In descending order of the number of editions printed in each, these are: Italy, Germany, France, Netherlands, Switzerland, Spain, Belgium, England, Austria, the Czech Republic, Portugal, Poland, Sweden, Denmark, Turkey, Croatia, Montenegro, and Hungary (see diagram). \n\nThe following table shows the 20 main 15th century printing locations; as with all data in this section, exact figures are given, but should be treated as close estimates (the total editions recorded in ISTC at May 2013 is 28,395):\n\nThe 18 languages that incunabula are printed in, in descending order, are: Latin, German, Italian, French, Dutch, Spanish, English, Hebrew, Catalan, Czech, Greek, Church Slavonic, Portuguese, Swedish, Breton, Danish, Frisian and Sardinian (see diagram).\n\nOnly about one edition in ten (i.e. just over 3,000) has any illustrations, woodcuts or metalcuts.\n\nThe \"commonest\" incunable is Schedel's \"Nuremberg Chronicle\" (\"Liber Chronicarum\") of 1493, with c 1,250 surviving copies (which is also the most heavily illustrated). Many incunabula are unique, but on average about 18 copies survive of each. This makes the Gutenberg Bible, at 48 or 49 known copies, a relatively common (though extremely valuable) edition. Counting extant incunabula is complicated by the fact that most libraries consider a single volume of a multi-volume work as a separate item, as well as fragments or copies lacking more than half the total leaves. A complete incunable may consist of a slip, or up to ten volumes.\n\nIn terms of format, the 29,000-odd editions comprise: 2,000 broadsides, 9,000 folios, 15,000 quartos, 3,000 octavos, 18 12mos, 230 16mos, 20 32mos, and 3 64mos.\n\nISTC at present cites 528 extant copies of books printed by Caxton, which together with 128 fragments makes 656 in total, though many are broadsides or very imperfect (incomplete).\n\nApart from migration to mainly North American and Japanese universities, there has been little movement of incunabula in the last five centuries. None were printed in the Southern Hemisphere, and the latter appears to possess less than 2,000 copies, about 97.75% remain north of the equator. However many incunabula are sold at auction or through the rare book trade every year.\n\nThe British Library's Incunabula Short Title Catalogue now records over 29,000 titles, of which around 27,400 are incunabula editions (not all unique works). Studies of incunabula began in the 17th century. Michel Maittaire (1667–1747) and Georg Wolfgang Panzer (1729–1805) arranged printed material chronologically in annals format, and in the first half of the 19th century, Ludwig Hain published, \"Repertorium bibliographicum\"— a checklist of incunabula arranged alphabetically by author: \"Hain numbers\" are still a reference point. Hain was expanded in subsequent editions, by Walter A. Copinger and Dietrich Reichling, but it is being superseded by the authoritative modern listing, a German catalogue, the \"Gesamtkatalog der Wiegendrucke\", which has been under way since 1925 and is still being compiled at the Staatsbibliothek zu Berlin. North American holdings were listed by Frederick R. Goff and a worldwide union catalogue is provided by the Incunabula Short Title Catalogue.\n\nNotable collections, with the approximate numbers of incunabula held, include:\n\n\n"}
{"id": "14865", "url": "https://en.wikipedia.org/wiki?curid=14865", "title": "Isotropy", "text": "Isotropy\n\nIsotropy is uniformity in all orientations; it is derived from the Greek \"isos\" (ἴσος, \"equal\") and \"tropos\" (τρόπος, \"way\"). Precise definitions depend on the subject area. Exceptions, or inequalities, are frequently indicated by the prefix \"an\", hence \"anisotropy\". \"Anisotropy\" is also used to describe situations where properties vary systematically, dependent on direction. Isotropic radiation has the same intensity regardless of the direction of measurement, and an isotropic field exerts the same action regardless of how the test particle is oriented.\n\nWithin mathematics, \"isotropy\" has a few different meanings:\n\n\n\n\n\n\n\nIn the study of mechanical properties of materials, \"isotropic\" means having identical values of a property in all directions. This definition is also used in geology and mineralogy. Glass and metals are examples of isotropic materials. Common anisotropic materials include wood, because its material properties are different parallel and perpendicular to the grain, and layered rocks such as slate.\n\nIsotropic materials are useful since they are easier to shape, and their behavior is easier to predict. Anisotropic materials can be tailored to the forces an object is expected to experience. For example, the fibers in carbon fiber materials and rebars in reinforced concrete are oriented to withstand tension.\n\nIn industrial processes, such as etching steps, isotropic means that the process proceeds at the same rate, regardless of direction. Simple chemical reaction and removal of a substrate by an acid, a solvent or a reactive gas is often very close to isotropic. Conversely, anisotropic means that the attack rate of the substrate is higher in a certain direction. Anisotropic etch processes, where vertical etch-rate is high, but lateral etch-rate is very small are essential processes in microfabrication of integrated circuits and MEMS devices.\n\nAn isotropic antenna is an idealized \"radiating element\" used as a reference; an antenna that broadcasts power equally (calculated by the Poynting vector) in all directions. The gain of an arbitrary antenna is usually reported in decibels relative to an isotropic antenna, and is expressed as dBi or dB(i).\n\n\n\n\n\n"}
{"id": "14868", "url": "https://en.wikipedia.org/wiki?curid=14868", "title": "International Mathematical Union", "text": "International Mathematical Union\n\nThe International Mathematical Union (IMU) is an international non-governmental organization devoted to international cooperation in the field of mathematics across the world. It is a member of the International Council for Science (ICSU) and supports the International Congress of Mathematicians. Its members are national mathematics organizations from more than 80 countries.\n\nThe objectives of the International Mathematical Union (IMU) are: promoting international cooperation in mathematics, supporting and assisting the International Congress of Mathematicians (ICM) and other international scientific meetings/conferences, acknowledging outstanding research contributions to mathematics through the awarding of scientific prizes, and encouraging and supporting other international mathematical activities, considered likely to contribute to the development of mathematical science in any of its aspects, whether pure, applied, or educational.\n\nThe IMU was established in 1920, but dissolved in September 1932 and then re-established 1950 de facto at the Constitutive Convention in New York, de jure on September 10, 1951, when ten countries had become members. The last milestone was the General Assembly in March 1952, in Rome, Italy where the activities of the new IMU were inaugurated and the first Executive Committee, President and various commissions where elected. In 1952 the IMU was also readmitted to the ICSU. The past president of the Union is Ingrid Daubechies (2011–2014). The current president is Shigefumi Mori who is the first head of the group from Asia.\n\nAt the 16th meeting of the IMU General Assembly in Bangalore, India, in August 2010, Berlin was chosen as the location of the permanent office of the IMU, which was opened on January 1, 2011, and is hosted by the Weierstrass Institute for Applied Analysis and Stochastics (WIAS), an institute of the Gottfried Wilhelm Leibniz Scientific Community, with about 120 scientists engaging in mathematical research applied to complex problems in industry and commerce.\n\nIMU has a close relationship to mathematics education through its International Commission on Mathematical Instruction (ICMI). This commission is organized similarly to IMU with its own Executive Committee and General Assembly.\n\nDeveloping countries are a high priority for the IMU and a significant percentage of its budget, including grants received from individuals, mathematical societies, foundations, and funding agencies, is spent on activities for developing countries. Since 2011 this has been coordinated by the Commission for Developing Countries (CDC).\n\nThe Committee for Women in Mathematics (CWM) is concerned with issues related to women in mathematics worldwide. It organizes the World Meeting for Women in Mathematics formula_1 as a satellite event of ICM.\n\nThe International Commission on the History of Mathematics (ICHM) is operated jointly by the IMU and the Division of the History of Science (DHS) of the International Union of History and Philosophy of Science (IUHPS).\n\nThe Committee on Electronic Information and Communication (CEIC) advises IMU on matters concerning mathematical information, communication, and publishing.\n\nThe scientific prizes awarded by the IMU are deemed to be the highest distinctions in the mathematical world. The opening ceremony of the International Congress of Mathematicians (ICM) is where the awards are presented: Fields Medals (two to four medals are given since 1936), the Rolf Nevanlinna Prize (since 1986), the Carl Friedrich Gauss Prize (since 2006), and the Chern Medal Award (since 2010).\n\nThe IMU's members are Member Countries and each Member country is represented through an Adhering Organization, which may be its principal academy, a mathematical society, its research council or some other institution or association of institutions, or an appropriate agency of its government. A country starting to develop its mathematical culture and interested in building links to mathematicians all over the world is invited to join IMU as an Associate Member. For the purpose of facilitating jointly sponsored activities and jointly pursuing the objectives of the IMU, multinational mathematical societies and professional societies can join IMU as an Affiliate Member. Every four years the IMU membership gathers in a General Assembly (GA) which consists of delegates appointed by the Adhering Organizations, together with the members of the Executive Committee. All important decisions are made at the GA, including the election of the officers, establishment of commissions, the approval of the budget, and any changes to the statutes and by-laws.\n\nThe International Mathematical Union is administered by an Executive Committee (EC) which conducts the business of the Union. The EC consists of the President, two Vice-Presidents, the Secretary, six Members-at-Large, all elected for a term of four years, and the Past President. The EC is responsible for all policy matters and for tasks, such as choosing the members of the ICM Program Committee and various prize committees.\n\nEvery two months IMU publishes an electronic newsletter, \"IMU-Net\", that aims to improve communication between IMU and the worldwide mathematical community by reporting on decisions and recommendations of the Union, major international mathematical events and developments, and on other topics of general mathematical interest. IMU Bulletins are published annually with the aim to inform IMU’s members about the Union’s current activities. In 2009 IMU published the document \"Best Current Practices for Journals\".\n\nThe IMU took its first organized steps towards the promotion of mathematics in developing countries in the early 1970s and has, since then supported various activities. In 2010 IMU formed the Commission for Developing Countries (CDC) which brings together all of the past and current initiatives in support of mathematics and mathematicians in the developing world.\n\nSome IMU Supported Initiatives:\n\nIMU also supports the \"International Commission on Mathematical Instruction\" (ICMI) with its programmes, exhibits and workshops in emerging countries, especially in Asia and Africa.\n\nIMU released a report in 2008, \"Mathematics in Africa: Challenges and Opportunities\", on the current state of mathematics in Africa and on opportunities for new initiatives to support mathematical development. In 2014, the IMU's Commission for Developing Countries CDC released an update of the report.\n\nAdditionally, reports about \"Mathematics in Latin America and the Caribbean and South East Asia\". were published.\n\nIn July 2014 IMU released the report: The International Mathematical Union in the Developing World: Past, Present and Future (July 2014).\n\nIn 2014, the IMU held a day-long symposium prior to the opening of the International Congress of Mathematicians (ICM), entitled \"Mathematics in Emerging Nations: Achievements and Opportunities\" (MENAO). Approximately 260 participants from around the world, including representatives of embassies, scientific institutions, private business and foundations attended this session. Attendees heard inspiring stories of individual mathematicians and specific developing nations.\n\n\nList of presidents of the International Mathematical Union from 1952 to the present:\n\n1952–1954: Marshall Harvey Stone (vice: Émile Borel, Erich Kamke)\n\n1955–1958: Heinz Hopf (vice: Arnaud Denjoy, W. V. D. Hodge)\n\n1959–1962: Rolf Nevanlinna (vice: Pavel Alexandrov, Marston Morse)\n\n1963–1966: Georges de Rham (vice: Henri Cartan, Kazimierz Kuratowski)\n\n1967–1970: Henri Cartan (vice: Mikhail Lavrentyev, Deane Montgomery)\n\n1971–1974: K. S. Chandrasekharan (vice: Abraham Adrian Albert, Lev Pontryagin)\n\n1975–1978: Deane Montgomery (vice: J. W. S. Cassels, Miron Nicolescu, Gheorghe Vrânceanu)\n\n1979–1982: Lennart Carleson (vice: Masayoshi Nagata, Yuri Vasilyevich Prokhorov)\n\n1983–1986: Jürgen Moser (vice: Ludvig Faddeev, Jean-Pierre Serre)\n\n1987–1990: Ludvig Faddeev (vice: Walter Feit, Lars Hörmander)\n\n1991–1994: Jacques-Louis Lions (vice: John H. Coates, David Mumford)\n\n1995–1998: David Mumford (vice: Vladimir Arnold, Albrecht Dold)\n\n1999–2002: Jacob Palis (vice: Simon Donaldson, Shigefumi Mori)\n\n2003–2006: John M. Ball (vice: Jean-Michel Bismut, Masaki Kashiwara)\n\n2007–2010: László Lovász (vice: Zhi-Ming Ma, Claudio Procesi)\n\n2011–2014: Ingrid Daubechies (vice: Christiane Rousseau, Marcelo Viana)\n\n2015–2018: Shigefumi Mori (vice: Alicia Dickenstein, Vaughan Jones)\n\n2019–2022: Carlos Kenig (vice: Nalini Joshi, Loyiso Nongxa )\n\n\n"}
{"id": "14869", "url": "https://en.wikipedia.org/wiki?curid=14869", "title": "International Council for Science", "text": "International Council for Science\n\nThe International Council for Science (ICSU, after its former name, International Council of Scientific Unions) was an international organization devoted to international cooperation in the advancement of science. Its members are national scientific bodies and international scientific unions. \n\nIn July 2018 ICSU merged with the International Social Science Council (ISSC) to form the International Science Council.\n\nIn 2017 ICSU comprised 122 multi-disciplinary National Scientific Members, Associates and Observers representing 142 countries and 31 international, disciplinary Scientific Unions. ICSU also had 22 Scientific Associates.\n\nICSU’s mission was to strengthen international science for the benefit of society. To do this, ICSU mobilized the knowledge and resources of the international scientific community to:\n\n\nActivities focused on three areas: International Research Collaboration, Science for Policy, and Universality of Science.\n\nIn 2018 ICSU became the International Science Council. \n\nICSU itself was one of the oldest non-governmental organizations in the world, representing the evolution and expansion of two earlier bodies known as the International Association of Academies (IAA; 1899-1914) and the International Research Council (IRC; 1919-1931). In 1998, Members agreed that the Council’s current composition and activities would be better reflected by modifying the name from the International Council of Scientific Unions to the International Council for Science, while its rich history and strong identity would be well served by retaining the existing acronym, ICSU.\n\nThe ICSU Principle of Universality of Science states: \"\"the free and responsible practice of science is fundamental to scientific advancement and human and environmental well-being. Such practice, in all its aspects, requires freedom of movement, association, expression and communication for scientists, as well as equitable access to data, information, and other resources for research. It requires responsibility at all levels to carry out and communicate scientific work with integrity, respect, fairness, trustworthiness, and transparency, recognising its benefits and possible harms.<br>\n\"In advocating the free and responsible practice of science, ICSU promotes equitable opportunities for access to science and its benefits, and opposes discrimination based on such factors as ethnic origin, religion, citizenship, language, political or other opinion, sex, gender identity, sexual orientation, disability, or age.\"\" \nAdherence to this Principle is a condition of ICSU membership. The Committee on Freedom and Responsibility in the conduct of Science (CFRS) \"serves as the guardian of the Principle and undertakes a variety of actions to defend scientific freedoms and promote integrity and responsibility.\"\n\nThe ICSU Secretariat (20 staff in 2012) in Paris ensured the day-to-day planning and operations under the guidance of an elected Executive Board. Three Policy Committees − Committee on Scientific Planning and Review (CSPR), Committee on Freedom and Responsibility in the conduct of Science (CFRS) and Committee on Finance − assisted the Executive Board in its work and a General Assembly of all Members was convened every three years. ICSU has three Regional Offices − Africa, Asia and the Pacific as well as Latin America and the Caribbean.\n\nThe principal source of ICSU's finances was the contributions it receives from its members. Other sources of income are the framework contracts from UNESCO (United Nations Educational, Scientific and Cultural Organization) and grants and contracts from United Nations bodies, foundations and agencies, which are used to support the scientific activities of the ICSU Unions and interdisciplinary bodies.\n\n\n\n"}
{"id": "14870", "url": "https://en.wikipedia.org/wiki?curid=14870", "title": "International Union of Pure and Applied Chemistry", "text": "International Union of Pure and Applied Chemistry\n\nThe International Union of Pure and Applied Chemistry (IUPAC ) is an international federation of National Adhering Organizations that represents chemists in individual countries. It is a member of the International Council for Science (ICSU). IUPAC is registered in Zürich, Switzerland, and the administrative office, known as the \"IUPAC Secretariat\", is in Research Triangle Park, North Carolina, United States. This administrative office is headed by IUPAC's executive director, currently Lynn Soby.\n\nIUPAC was established in 1919 as the successor of the International Congress of Applied Chemistry for the advancement of chemistry. Its members, the National Adhering Organizations, can be national chemistry societies, national academies of sciences, or other bodies representing chemists. There are fifty-four National Adhering Organizations and three Associate National Adhering Organizations. IUPAC's Inter-divisional Committee on Nomenclature and Symbols (IUPAC nomenclature) is the recognized world authority in developing standards for the naming of the chemical elements and compounds. Since its creation, IUPAC has been run by many different committees with different responsibilities. These committees run different projects which include standardizing nomenclature, finding ways to bring chemistry to the world, and publishing works.\n\nIUPAC is best known for its works standardizing nomenclature in chemistry and other fields of science, but IUPAC has publications in many fields including chemistry, biology and physics. Some important work IUPAC has done in these fields includes standardizing nucleotide base sequence code names; publishing books for environmental scientists, chemists, and physicists; and improving education in science. IUPAC is also known for standardizing the atomic weights of the elements through one of its oldest standing committees, the Commission on Isotopic Abundances and Atomic Weights (CIAAW).\n\nThe need for an international standard for chemistry was first addressed in 1860 by a committee headed by German scientist Friedrich August Kekulé von Stradonitz. This committee was the first international conference to create an international naming system for organic compounds. The ideas that were formulated in that conference evolved into the official IUPAC nomenclature of organic chemistry. IUPAC stands as a legacy of this meeting, making it one of the most important historical international collaborations of chemistry societies. Since this time, IUPAC has been the official organization held with the responsibility of updating and maintaining official organic nomenclature. IUPAC as such was established in 1919. One notable country excluded from this early IUPAC is Germany. Germany's exclusion was a result of prejudice towards Germans by the Allied powers after World War I. Germany was finally admitted into IUPAC during 1929. However, Nazi Germany was removed from IUPAC during World War II.\n\nDuring World War II, IUPAC was affiliated with the Allied powers, but had little involvement during the war effort itself. After the war, East and West Germany were eventually readmitted to IUPAC. Since World War II, IUPAC has been focused on standardizing nomenclature and methods in science without interruption.\n\nIn 2016, IUPAC denounced the use of chlorine as a chemical weapon. The organization pointed out their concerns in a letter to Ahmet Üzümcü, the director of the Organisation for the Prohibition of Chemical Weapons (OPCW), in regards to the practice of utilizing chlorine for weapon usage in Syria among other locations. The letter stated, \"Our organizations deplore the use of chlorine in this manner. The indiscriminate attacks, possibly carried out by a member state of the Chemical Weapons Convention (CWC), is of concern to chemical scientists and engineers around the globe and we stand ready to support your mission of implementing the CWC.\" According to the CWC, \"the use, stockpiling, distribution, development or storage of any chemical weapons is forbidden by any of the 192 state party signatories.\"\n\nIUPAC is governed by several committees that all have different responsibilities. The committees are as follows: Bureau, CHEMRAWN (Chem Research Applied to World Needs) Committee, Committee on Chemistry Education, Committee on Chemistry and Industry, Committee on Printed and Electronic Publications, Evaluation Committee, Executive Committee, Finance Committee, Interdivisional Committee on Terminology, Nomenclature and Symbols, Project Committee, and Pure and Applied Chemistry Editorial Advisory Board. Each committee is made up of members of different National Adhering Organizations from different countries.\n\nThe steering committee hierarchy for IUPAC is as follows:\n\nIUPAC committee has a long history of officially naming organic and inorganic compounds. IUPAC nomenclature is developed so that any compound can be named under one set of standardized rules to avoid duplicate names. The first publication on IUPAC nomenclature of organic compounds was \"A Guide to IUPAC Nomenclature of Organic Compounds\" in 1900, which contained information from the International Congress of Applied Chemistry.\n\nIUPAC organic nomenclature has three basic parts: the substituents, carbon chain length and chemical ending. The substituents are any functional groups attached to the main carbon chain. The main carbon chain is the longest possible continuous chain. The chemical ending denotes what type of molecule it is. For example, the ending \"ane\" denotes a single bonded carbon chain, as in \"hexane\" ().\n\nAnother example of IUPAC organic nomenclature is cyclohexanol:\n\nBasic IUPAC inorganic nomenclature has two main parts: the cation and the anion. The cation is the name for the positively charged ion and the anion is the name for the negatively charged ion.\n\nAn example of IUPAC nomenclature of inorganic chemistry is potassium chlorate (KClO):\n\nIUPAC also has a system for giving codes to identify amino acids and nucleotide bases. IUPAC needed a coding system that represented long sequences of amino acids. This would allow for these sequences to be compared to try to find homologies. These codes can consist of either a one letter code or a three letter code.\n\nThese codes make it easier and shorter to write down the amino acid sequences that make up proteins. The nucleotide bases are made up of purines (adenine and guanine) and pyrimidines (cytosine and thymine or uracil). These nucleotide bases make up DNA and RNA. These nucleotide base codes make the genome of an organism much smaller and easier to read.\n\nThe codes for amino acids (24 amino acids and three special codes) are:\n\nThe \"Experimental Thermodynamics\" books series covers many topics in the fields of thermodynamics.\n\nIUPAC color code their books in order to make each publication distinguishable.\nIUPAC and UNESCO were the lead organizations coordinating events for the International Year of Chemistry, which took place in 2011. The International Year of Chemistry was originally proposed by IUPAC at the general assembly in Turin, Italy. This motion was adopted by UNESCO at a meeting in 2008. The main objectives of the International Year of Chemistry were to increase public appreciation of chemistry and gain more interest in the world of chemistry. This event is also being held to encourage young people to get involved and contribute to chemistry. A further reason for this event being held is to honour how chemistry has made improvements to everyone's way of life.\n\nIUPAC Presidents are elected by the IUPAC Council during the General Assembly. Below is the list of IUPAC Presidents since its inception in 1919.\n\n\n"}
{"id": "14871", "url": "https://en.wikipedia.org/wiki?curid=14871", "title": "International Hydrographic Organization", "text": "International Hydrographic Organization\n\nThe International Hydrographic Organization (IHO) is the inter-governmental organisation representing hydrography. \n\nA principal aim of the IHO is to ensure that the world’s seas, oceans and navigable waters are properly surveyed and charted. It does this through the setting of international standards, the co-ordination of the endeavours of the world's national hydrographic offices, and through its capacity building programme.\nThe IHO enjoys observer status at the United Nations where it is the recognised competent authority on hydrographic surveying and nautical charting. When referring to hydrography and nautical charting in Conventions and similar Instruments, it is the IHO standards and specifications that are normally used.\n\nThe IHO was established in 1921 as the International Hydrographic Bureau (IHB). The present name was adopted in 1970 as part of a new international Convention on the IHO adopted by the then member nations. The former name International Hydrographic Bureau was retained to describe the IHO secretariat until 8 November 2016, when a revision to the Convention on the IHO entered into force. Thereafter the IHB became known as the \"IHO Secretariat\", comprising an elected Secretary-General and two supporting Directors, together with a small staff of 17, at the Organization's headquarters in Monaco. \n\nDuring the 19th century, many maritime nations established hydrographic offices to provide means for improving the navigation of naval and merchant vessels by providing nautical publications, nautical charts, and other navigational services. There were substantial differences in hydrographic procedures charts, and publications. In 1889, an International Maritime Conference was held at Washington, D.C., and it was proposed to establish a \"permanent international commission.\" Similar proposals were made at the sessions of the International Congress of Navigation held at Saint Petersburg in 1908 and the International Maritime Conference held at Saint Petersburg in 1912.\n\nIn 1919 the hydrographers of Great Britain and France cooperated in taking the necessary steps to convene an international conference of hydrographers. London was selected as the most suitable place for this conference, and on 24 July 1919, the First International Conference opened, attended by the hydrographers of 24 nations. The object of the conference was \"To consider the advisability of all maritime nations adopting similar methods in preparation, construction, and production of their charts and all hydrographic publications; of rendering the results in the most convenient form to enable them to be readily used; of instituting a prompt system of mutual exchange of hydrographic information between all countries; and of providing an opportunity to consultations and discussions to be carried out on hydrographic subjects generally by the hydrographic experts of the world.\" This is still the major purpose of the IHO.\n\nAs a result of the Conference, a permanent organization was formed and statutes for its operations were prepared. The IHB, now the IHO, began its activities in 1921 with 18 nations as members. The Principality of Monaco was selected as the seat of the organization as a result of the offer of Albert I, Prince of Monaco to provide suitable accommodation for the Bureau in the principality. This organization firstly was composed by 89 members, but two of them were suspended because they couldn't pay their fees. Indeed, thirteen Member States had failed to pay their contributions to the organization for 2017 during the calendar year.\n\nThe IHO develops hydrographic and nautical charting standards. These standards are subsequently adopted and used by its 89 (as of June 2018) member countries and others in their surveys, nautical charts, and publications. The almost universal use of the IHO standards means that the products and services provided by the world's national hydrographic and oceanographic offices are consistent and recognisable by all seafarers and for other users. Much has been done in the field of standardisation since the Bureau (now the IHO) was founded.\n\nThe IHO has encouraged the formation of Regional Hydrographic Commissions (RHCs). Each RHC coordinates the national surveying and charting activities of countries within each region and acts as a forum to address other matters of common hydrographic interest. The 15 RHCs plus the IHO Hydrographic Commission on Antarctica (HCA) effectively cover the world.\n\nThe IHO, in partnership with the Intergovernmental Oceanographic Commission (IOC), directs the General Bathymetric Chart of the Oceans programme.\n\nMain achievements of this organization: \n\nEstablishment of the Chart Specifications Committee and International Charts. Great improvements have taken place in the following topics:\n\n1) The exploration of the seabed and movements of the sea.\n\n2) Standardization of maritime measurements, hydrographic terminology, marine cartographic products and geographical information systems for navigation. Great progress has been made concerning standardization of electronic charts\n\n3) High efficiency of the rapid dissemination of information on safety at sea\n\n4) Training of hydrographers and nautical cartographers.\n\nMost IHO publications, including the standards, guidelines and associated documents such as the \"International Hydrographic Review\", \"International Hydrographic Bulletin\", the \"Hydrographic Dictionary\" and the \"Year Book\" are available to the general public free of charge from the IHO website.\n\nThe IHO publishes the international standards related to charting and hydrography, including S-57, \"IHO Transfer Standard for Digital Hydrographic Data\", the encoding standard that is used primarily for electronic navigational charts. In 2010 the IHO introduced a new, contemporary hydrographic geospatial standard for modelling marine data and information, known as S-100. S-100 and any dependent product specifications are underpinned by an on-line registry accessible via the IHO website. S-100 is aligned with the ISO 19100 series of geographic standards, thereby making it fully compatible with contemporary geospatial data standards. Because S-100 is based on ISO 19100, it can be used by other data providers for their maritime-related (non-hydrographic) data and information. Various data and information providers from both the government and private sector are now using S-100 as part of the implementation of the e-Navigation concept that has been endorsed by the UN International Maritime Organization.\n\nThe IHO maintains a programme of the meetings of its Council, committees and working groups around the world. The meetings and the meetings of other related International Organisations are promulgated in the calendar on the IHO website.\n\nEstablishment of the Chart Specifications Committee and International Charts. Great improvements have taken place in the following topics:\n\n\nThe following countries are members of the IHO:\n\n"}
{"id": "14872", "url": "https://en.wikipedia.org/wiki?curid=14872", "title": "IBM mainframe", "text": "IBM mainframe\n\nIBM mainframes are large computer systems produced by IBM since 1952. During the 1960s and 1970s, IBM dominated the large computer market. Current mainframe computer in IBM's line of business computers are developments of the basic design of the IBM System/360.\n\nFrom 1952 into the late 1960s, IBM manufactured and marketed several large computer models, known as the IBM 700/7000 series. The first-generation 700s were based on vacuum tubes, while the later, second-generation 7000s used transistors. These machines established IBM's dominance in electronic data processing (\"EDP\"). IBM had two model categories: one (701, 704, 709, 7030, 7090, 7094, 7040, 7044) for engineering and scientific use, and one (702, 705, 705-II, 705-III, 7080, 7070, 7072, 7074, 7010) for commercial or data processing use. The two categories, scientific and commercial, generally used common peripherals but had completely different instruction sets, and there were incompatibilities even within each category.\n\nIBM initially sold its computers without any software, expecting customers to write their own; programs were manually initiated, one at a time. Later, IBM provided compilers for the newly developed higher-level programming languages Fortran, COMTRAN and later COBOL. The first operating systems for IBM computers were written by IBM customers who did not wish to have their very expensive machines ($2M USD in the mid-1950s) sitting idle while operators set up jobs manually. These first operating systems were essentially scheduled work queues. It is generally thought that the first operating system used for real work was GM-NAA I/O, produced by General Motors' Research division in 1956. IBM enhanced one of GM-NAA I/O's successors, the SHARE Operating System, and provided it to customers under the name IBSYS. As software became more complex and important, the cost of supporting it on so many different designs became burdensome, and this was one of the factors which led IBM to develop System/360 and its operating systems.\n\nThe second generation (transistor-based) products were a mainstay of IBM's business and IBM continued to make them for several years after the introduction of the System/360. (Some IBM 7094s remained in service into the 1980s.)\n\nPrior to System/360, IBM also sold computers smaller in scale that were not considered mainframes, though they were still bulky and expensive by modern standards. These included:\n\n\nIBM had difficulty getting customers to upgrade from the smaller machines to the mainframes because so much software had to be rewritten. The 7010 was introduced in 1962 as a mainframe-sized 1410. The later Systems 360 and 370 could emulate the 1400 machines. A desk-size machine with a different instruction set, the IBM 1130, was released concurrently with the System/360 to address the niche occupied by the 1620. It used the same EBCDIC character encoding as the 360 and was mostly programmed in Fortran, which was relatively easy to adapt to larger machines when necessary.\n\n\"Midrange computer\" is a designation used by IBM for a class of computer systems which fall in between mainframes and microcomputers.\n\nAll that changed with the announcement of the System/360 (S/360) in April, 1964. The System/360 was a single series of compatible models for both commercial and scientific use. The number \"360\" suggested a \"360 degree,\" or \"all-around\" computer system. System/360 incorporated features which had previously been present on only either the commercial line (such as decimal arithmetic and byte addressing) or the engineering and scientific line (such as floating point arithmetic). Some of the arithmetic units and addressing features were optional on some models of the System/360. However, models were upward compatible and most were also downward compatible. The System/360 was also the first computer in wide use to include dedicated hardware provisions for the use of operating systems. Among these were supervisor and application mode programs and instructions, as well as built-in memory protection facilities. Hardware memory protection was provided to protect the operating system from the user programs (tasks) and user tasks from each other. The new machine also had a larger address space than the older mainframes, 24 bits addressing 8-bit bytes vs. a typical 18 bits addressing 36-bit words. \n\nThe smaller models in the System/360 line (e.g. the 360/30) were intended to replace the 1400 series while providing an easier upgrade path to the larger 360s. To smooth the transition from the second generation to the new line, IBM used the 360's microprogramming capability to emulate the more popular older models. Thus 360/30s with this added cost feature could run 1401 programs and the larger 360/65s could run 7094 programs. To run old programs, the 360 had to be halted and restarted in emulation mode. Many customers kept using their old software and one of the features of the later System/370 was the ability to switch to emulation mode and back under operating system control.\n\nOperating systems for the System/360 family included OS/360 (with PCP, MFT, and MVT), BOS/360, TOS/360, and DOS/360.\n\nThe System/360 later evolved into the System/370, the System/390, and the 64-bit zSeries, System z, and zEnterprise machines. System/370 introduced virtual memory capabilities in all models other than the very first System/370 models; the OS/VS1 variant of OS/360 MFT, the OS/VS2 (SVS) variant of OS/360 MVT, and the DOS/VS variant of DOS/360 were introduced to use the virtual memory capabilities, followed by MVS, which, unlike the earlier virtual-memory operating systems, ran separate programs in separate address spaces, rather than running all programs in a single virtual address space. The virtual memory capabilities also allowed the system to support virtual machines; the VM/370 hypervisor would run one or more virtual machines running either standard System/360 or System/370 operating systems or the single-user Conversational Monitor System (CMS). A time-sharing VM system could run multiple virtual machines, one per user, with each virtual machine running an instance of CMS.\n\nThe zSeries family, introduced in 2000 with the z900, included IBM's newly designed 64-bit z/Architecture.\n\nThe different processors on current IBM mainframes are:\n\nNote that these are essentially identical, but distinguished for software cost control: all but CP are slightly restricted such they cannot be used to run arbitrary operating systems, and thus do not count in software licensing costs (which are typically based on the number of CPs).\nThere are other supporting processors typically installed inside mainframes such as cryptographic accelerators (CryptoExpress), the OSA-Express networking processor, and FICON Express disk I/O processors.\n\nSoftware to allow users to run \"traditional\" workloads on zIIPs and zAAPs was briefly marketed by Neon Enterprise Software as \"zPrime\" but was withdrawn from the market in 2011 after a lawsuit by IBM.\n\nThe primary operating systems in use on current IBM mainframes include z/OS (which followed MVS/ESA and OS/390 in the OS/360 lineage), z/VM (which followed VM/ESA and VM/XA in the CP-40 lineage), z/VSE (which is in the DOS/360 lineage), z/TPF (a successor of Airlines Control Program), and Linux on z Systems such as SUSE Linux Enterprise Server and others. A few systems run MUSIC/SP and UTS (Mainframe UNIX). In October 2008, Sine Nomine Associates introduced OpenSolaris on System z.\n\nCurrent IBM mainframes run all the major enterprise transaction processing environments and databases, including CICS, IMS, WebSphere Application Server, DB2, and Oracle. In many cases these software subsystems can run on more than one mainframe operating system.\n\nThere are software-based emulators for the System/370, System/390, and System z hardware, including FLEX-ES, which runs under UnixWare or Linux, and the freely available Hercules, which runs under Linux, FreeBSD, Solaris, macOS and Microsoft Windows.\nIBM offers an emulator called zPDT (System z Personal Development Tool) which runs on Linux on x86-64 machines.\n\n\n\n"}
{"id": "14875", "url": "https://en.wikipedia.org/wiki?curid=14875", "title": "Iowa State University", "text": "Iowa State University\n\nIowa State University of Science and Technology, generally referred to as Iowa State, is a public land-grant and space-grant research university located in Ames, Iowa, United States. It is the largest university in the state of Iowa and the third largest university in the Big 12 athletic conference. Iowa State is classified as a research university with \"highest research activity\" by the Carnegie Foundation for the Advancement of Teaching. Iowa State is also a member of the Association of American Universities (AAU), which consists of 60 leading research universities in North America.\n\nFounded in 1858 and coeducational from its start, Iowa State became the nation's first designated land-grant institution when the Iowa Legislature accepted the provisions of the 1862 Morrill Act on September 11, 1862, making Iowa the first state in the nation to do so.\n\nIowa State's academic offerings are administered today through eight colleges, including the graduate college, that offer over 100 bachelor's degree programs, 112 master's degree programs, and 83 at the Ph.D. level, plus a professional degree program in Veterinary Medicine.\n\nIowa State University's athletic teams, the Cyclones, compete in Division I of the NCAA and are a founding member of the Big 12 Conference. The Cyclones field 16 varsity teams and have won numerous NCAA national championships.\n\nIn 1856, the Iowa General Assembly enacted legislation to establish the Iowa Agricultural College and Model Farm. This institution (now Iowa State University) was officially established on March 22, 1858, by the General Assembly. Story County was chosen as the location on June 21, 1859, beating proposals from Johnson, Kossuth, Marshall and Polk counties. The original farm of was purchased for a cost of $5,379.\nIowa was the first state in the nation to accept the provisions of the Morrill Act of 1862. Iowa subsequently designated Iowa State as the land-grant college on March 29, 1864. From the start, Iowa Agricultural College focused on the ideals that higher education should be accessible to all and that the university should teach liberal and practical subjects. These ideals are integral to the land-grant university.\n\nThe institution was coeducational from the first preparatory class admitted in 1868. The formal admitting of students began the following year, and the first graduating class of 1872 consisted of 24 men and two women.\n\nThe Farm House, the first building on the Iowa State campus, was completed in 1861 before the campus was occupied by students or classrooms. It became the home of the superintendent of the Model Farm and in later years, the deans of Agriculture, including Seaman Knapp and \"Tama Jim\" Wilson. Iowa State's first president, Adonijah Welch, briefly stayed at the Farm House and penned his inaugural speech in a second floor bedroom.\n\nThe college's first farm tenants primed the land for agricultural experimentation. The Iowa Experiment Station was one of the university's prominent features. Practical courses of instruction were taught, including one designed to give a general training for the career of a farmer. Courses in mechanical, civil, electrical, and mining engineering were also part of the curriculum.\n\nIn 1870, President Welch and I. P. Robert, professor of agriculture, held three-day farmers' institutes at Cedar Falls, Council Bluffs, Washington, and Muscatine. These became the earliest institutes held off-campus by a land grant institution and were the forerunners of 20th century extension.\n\nIn 1872, the first courses were given in domestic economy (home economics, family and consumer sciences) and were taught by Mary B. Welch, the president's wife. Iowa State became the first land grant university in the nation to offer training in domestic economy for college credit.\n\nIn 1879, the \"School\" of Veterinary Science was organized, the first state veterinary college in the United States (although veterinary courses has been taught since the beginning of the College). This was originally a two-year course leading to a diploma. The veterinary course of study contained classes in zoology, botany, anatomy of domestic animals, veterinary obstetrics, and sanitary science.\nWilliam M. Beardshear was appointed President of Iowa State in 1891. During his tenure, Iowa Agricultural College truly came of age. Beardshear developed new agricultural programs and was instrumental in hiring premier faculty members such Anson Marston, Louis B. Spinney, J.B. Weems, Perry G. Holden, and Maria Roberts. He also expanded the university administration, and the following buildings were added to the campus: Morrill Hall (1891); the Campanile (1899); Old Botany (now Carrie Chapman Catt Hall) (1892); and Margaret Hall (1895) which continue to stand today. In his honor, Iowa State named its central administrative building (Central Building) after Beardshear in 1925. In 1898, reflecting the school's growth during his tenure, it was renamed Iowa State College of Agricultural and Mechanic Arts, or Iowa State for short.\n\nToday, Beardshear Hall holds the following offices: President, Vice-President, Treasurer, Secretary, Registrar, Provost, and student financial aid. Catt Hall is named after famed alumna Carrie Chapman Catt and is the home of the College of Liberal Arts and Sciences.\nIn 1912 Iowa State had its first Homecoming celebration. The idea was first proposed by Professor Samuel Beyer, the college's “patron saint of athletics,” who suggested that Iowa State inaugurate a celebration for alumni during the annual football game against rival University of Iowa. Iowa State's new president, Raymond A. Pearson, liked the idea and issued a special invitation to alumni two weeks prior to the event: “We need you, we must have you. Come and see what a school you have made in Iowa State College. Find a way.” In October 2012 Iowa State marked its 100th Homecoming with a \"CYtennial\" Celebration.\n\nIowa State celebrated its first VEISHEA on May 11–13, 1922. Wallace McKee (class of 1922) served as the first chairman of the Central Committee and Frank D. Paine (professor of electrical engineering) chose the name, based on the first letters of Iowa State's colleges: Veterinary Medicine, Engineering, Industrial Science, Home Economics, and Agriculture. VEISHEA grew to become the largest student-run festival in the nation.\n\nThe Statistical Laboratory was established in 1933, with George W. Snedecor, professor of mathematics, as the first director. It was and is the first research and consulting institute of its kind in the country.\n\nWhile attempting to develop a faster method of computation, mathematics and physics professor John Vincent Atanasoff conceptualized the basic tenets of what would become the world's first electronic digital computer, the Atanasoff-Berry Computer (ABC), during a drive to Illinois in 1937. These included the use of a binary system of arithmetic, the separation of computer and memory functions, and regenerative drum memory, among others. The 1939 prototype was constructed with graduate student Clifford Berry in the basement of the Physics Building.\n\nDuring World War II, Iowa State was one of 131 colleges and universities nationally that took part in the V-12 Navy College Training Program which offered students a path to a Navy commission.\n\nOn July 4, 1959, the college was officially renamed Iowa State University of Science and Technology. However, the short-form name \"Iowa State University\" is used even in official documents such as diplomas.\n\nOfficial names given to the university's divisions were the College of Agriculture, College of Engineering, College of Home Economics, College of Sciences and Humanities, and College of Veterinary Medicine.\n\nIowa State's eight colleges today offer more than 100 undergraduate majors and 200 fields of study leading to graduate and professional degrees. The academic program at ISU includes a liberal arts education and some of the world's leading research in the biological and physical sciences.\n\nBreakthroughs at Iowa State changing the world are in the areas of human, social, economic, and environmental sustainability; new materials and processes for biomedical as well as industrial applications; nutrition, health, and wellness for humans and animals; transportation and infrastructure; food safety and security; plant and animal sciences; information and decision sciences; and renewable energies. The focus on technology has led directly to many research patents and inventions including the first binary computer (the ABC), Maytag blue cheese, the round hay baler, and many more.\n\nLocated on a campus, the university has grown considerably from its roots as an agricultural college and model farm and is recognized internationally today for its comprehensive research programs. It continues to grow and set a new record for enrollment in the fall of 2015 with 36,001 students.\n\nIowa State University is organized into eight colleges and two schools that offer 100 Bachelor's degree programs, 112 Masters programs, and 83 Ph.D programs, including one professional degree program in Veterinary Medicine.\n\nISU is home to the following schools:\nClassified as one of Carnegie's \"R1: Doctoral Universities - Highest Research Activity,\" Iowa State receives nearly $300 million in research grants each year.\n\nThe university is one of 62 elected members of the Association of American Universities, an organization composed of the most highly ranked public and private research universities in the U.S. and Canada.\n\nIn 2016-17 Iowa State university became part of only fifty-four institutions in the U.S. to have earned the \"Innovation and Economic Prosperity University\" designation by the Association of Public and Land-grant Universities.\n\nOverall, ISU ranks 111th in the \"U.S. News & World Report\" ranking of national universities and 42nd in the \"Washington Monthly\" rankings. The agriculture and forestry programs are consistently ranked top 15 in the world by QS. In engineering specialties, at schools whose highest degree is a doctorate, Iowa State's biological/agricultural engineering program is ranked first, the mechanical and civil are ranked 9th and 16th nationally in the U.S. by \"U.S. News & World Report.\" Almost all of the engineering specialities at ISU are ranked in the top 30 nationally... ISU's chemistry and physics programs are considered to be some of the best in the world and are ranked in the Top 100 globally and in Top 50 nationally. ISU's Greenlee School of Journalism and Mass Communication is one of the top journalism schools in the country and is notable for being among the first group of accredited journalism and mass communication programs. Greenlee is also cited as one of the leading JMC research programs in the nation, ranked 23rd in a publication by the AEJMC.\n\nThe National Science Foundation ranks ISU 78th in the nation in total research and development expenditures and 94th in research and development expenditures for science and engineering. Currently, ISU ranks second nationally in license and options executed on its intellectual property and #2 nationally in license and options that yield income.\n\nIn 2016, ISU's landscape architecture program was ranked as the 10th best undergraduate program in the nation, and architecture as the 18th best.\n\nThe W. Robert and Ellen Sorge Parks Library contains over 2.6 million books and subscribes to more than 98,600 journal titles. Named for W. Robert Parks (1915–2003), the 11th president of Iowa State University, and his wife, Ellen Sorge Parks, the original library was built in 1925 with three subsequent additions made in 1961, 1969, and 1983. The library was dedicated and named after W. Robert and Ellen Sorge Parks in 1984.\n\nParks Library provides extensive research collections, services and information literacy instruction/information for all students. Facilities consist of the main Parks Library, the e-Library, the Veterinary Medical Library, two subject-oriented reading rooms (design and mathematics), and a remote library storage building.\n\nThe Library's extensive collections include electronic and print resources that support research and study for all undergraduate and graduate programs. Nationally recognized collections support the basic and applied fields of biological and physical sciences. The Parks Library includes four public service desks: the Learning Connections Center, the Circulation Desk, the Media Center (including Maps, Media,\nMicroforms, and Course Reserve collections), and Special Collections. The Library's instruction program includes a required undergraduate information literacy course as well as a wide variety of subject-based seminars on effective use of Library resources for undergraduate and graduate students.\n\nThe e-Library, accessed through the Internet, provides access to local and Web-based resources including electronic journals and books, local collections, online indexes, electronic course reserves and guides, and a broad range of subject research guides.\n\nSurrounding the first floor lobby staircase in Parks Library are eight mural panels\ndesigned by Iowa artist Grant Wood. As with \"Breaking the Prairie Sod\", Wood's other\nIowa State University mural painted two years later, Wood borrowed his theme for \"When Tillage Begins Other Arts Follow\" from a speech on agriculture delivered by Daniel\nWebster in 1840 at the State House in Boston. Webster said, “When tillage begins, other\narts follow. The farmers therefore are the founders of human civilization.” Wood had\nplanned to create seventeen mural panels for the library, but only the eleven devoted to\nagriculture and the practical arts were completed. The final six, which would have hung\nin the main reading room (now the Periodical Room) and were to have depicted the fine\narts, were never begun.\n\nThe Special Collections Department at the Parks Library houses a collection of underground comix from 1947 to 2007. The collection also consists of correspondences between the Special Collections Department, comic book artists, and dealers.\n\nThe university has an IEOP for foreign students. Students whose native language is not English can take IEOP courses to improve their English proficiency to help them succeed at University-level study. IEOP course content also helps students prepare for English proficiency exams, like the TOEFL and IELTS. Classes included in the IEOP include Grammar, Reading, Writing, Oral Communication and Business and various bridge classes.\n\nIowa State is the birthplace of the first electronic digital computer, starting the world's computer technology revolution. Invented by mathematics and physics professor John Atanasoff and engineering graduate student Clifford Berry during 1937-42, the Atanasoff-Berry Computer, or ABC, pioneered important elements of modern computing, including binary arithmetic, regenerative memory, parallel processing, electronic switching elements, and separation of memory and computer functions.\n\nOn October 19, 1973, U.S. Federal Judge Earl R. Larson signed his decision following a lengthy court trial which declared the ENIAC patent of Mauchly and Eckert invalid and named Atanasoff the inventor of the electronic digital computer—the Atanasoff-Berry Computer or the ABC.\n\nAn ABC Team consisting of Ames Laboratory and Iowa State engineers, technicians, researchers and students unveiled a working replica of the Atanasoff-Berry Computer in 1997 which can be seen on display on campus in the Durham Computation Center.\n\nThe Extension Service traces its roots to farmers' institutes developed at Iowa State in the late 19th century. Committed to community, Iowa State pioneered the outreach mission of being a land-grant college through creation of the first Extension Service in 1902. In 1906, the Iowa Legislature enacted the Agricultural Extension Act making funds available for demonstration projects. It is believed this was the first specific legislation establishing state extension work, for which Iowa State assumed responsibility. The national extension program was created in 1914 based heavily on the Iowa State model.\n\nISU is the only university nationwide that has a U.S. Department of Energy research laboratory physically located on its campus. Iowa State played a critical role in the development of the atomic bomb during World War II as part of the Manhattan Project, a research and development program begun in 1942 under the U.S. Army Corps of Engineers to develop the atomic bomb.\n\nThe process to produce large quantities of high-purity uranium metal became known as the Ames process. One-third of the uranium metal used in the world's first controlled nuclear chain reaction was produced at Iowa State under the direction of Frank Spedding and Harley Wilhelm. The Ames project received the Army-Navy 'E' Award for Excellence in Production on October 12, 1945, signifying two-and-one-half years of excellence in industrial production of metallic uranium as a vital war material. Iowa State is unique among educational institutions to have received this award for outstanding service, an honor normally given to industry.\n\nToday, the Ames Laboratory focuses on more peaceful applications of materials research, usually related to increasing energy efficiency. It has broadened the scope of its research into various areas of national concern, including energy resources, high-speed computer design, environmental cleanup and restoration, and the synthesis and study of new materials.\n\nIowa State is widely known for VEISHEA, an annual education and entertainment festival that was held on campus each spring. The name VEISHEA was derived from the initials of ISU's five original colleges, forming an acronym as the university existed when the festival was founded in 1922:\n\nVEISHEA was the largest student run festival in the nation, bringing in tens of thousands of visitors to the campus each year.\n\nThe celebration featured an annual parade and many open-house demonstrations of the university facilities and departments. Campus organizations exhibited products, technologies, and held fund raisers for various charity groups. In addition, VEISHEA brought speakers, lecturers, and entertainers to Iowa State, and throughout its over eight decade history, it has hosted such distinguished guests as Bob Hope, John Wayne, Presidents Harry Truman, Ronald Reagan, and Lyndon Johnson, and performers Diana Ross, Billy Joel, Sonny and Cher, The Who, The Goo Goo Dolls, Bobby V, and The Black Eyed Peas.\n\nThe 2007 VEISHEA festivities marked the start of Iowa State's year-long sesquicentennial celebration.\n\nOn August 8, 2014, President Steven Leath announced that VEISHEA would no longer be an annual event at Iowa State and the name VEISHEA would be retired.\n\nIowa State is the only university nationwide that has a U.S. Department of Energy research laboratory physically located on its campus. Operated by ISU, the Ames Laboratory is one of ten national DOE Office of Science research laboratories.\n\nISU research for the government provided Ames Laboratory its start in the 1940s with the development of a highly efficient process for producing high-purity uranium for atomic energy. Today, Ames Laboratory continues its leading status in current materials research and focuses diverse fundamental and applied research strengths upon issues of national concern, cultivates research talent, and develops and transfers technologies to improve industrial competitiveness and enhance U.S. economic security. Ames Laboratory employs more than 430 full- and part-time employees, including more than 250 scientists and engineers. Students make up more than 20 percent of the paid workforce.\n\nThe Ames Laboratory is the U.S. home to 2011 Nobel Prize in Chemistry winner Dan Shechtman and is intensely engaged with the international scientific community, including hosting a large number of international visitors each year.\n\nThe ISU Research Park is a 230-acre development with over 270,000 square feet of building space located just south of the Iowa State campus in Ames. Though closely connected with the university, the research park operates independently to help tenants reach their proprietary goals, linking technology creation, business formation, and development assistance with established technology firms and the marketplace.\n\nThe ISU Research Park Corporation was established in 1987 as a not-for-profit, independent, corporation operating under a board of directors appointed by Iowa State University and the ISU Foundation. The corporation manages both the Research Park and incubator programs.\n\nIowa State is involved in a number of other significant research and creative endeavors, multidisciplinary collaboration, technology transfer, and strategies addressing real-world problems.\n\nIn 2010, the Biorenewables Research Laboratory opened in a LEED-Gold certified building that complements and helps replace labs and offices across Iowa State and promotes interdisciplinary, systems-level research and collaboration. The Lab houses the Bioeconomy Institute, the Biobased Industry Center, and the National Science Foundation Engineering Research Center for Biorenewable Chemicals, a partnership of six universities as well as the Max Planck Society in Germany and the Technical University of Denmark.\n\nThe Engineering Teaching and Research Complex was built in 1999 and is home to Stanley and Helen Howe Hall and Gary and Donna Hoover Hall. The complex is occupied by the to the Virtual Reality Applications Center (VRAC), Center for Industrial Research and Service (CIRAS), Department of Aerospace Engineering and Engineering Mechanics, Department of Materials Science and Engineering, Engineering Computer Support Services, Engineering Distance Education, and Iowa Space Grant Consortium. And the complex contains one of the world's only six-sided immersive virtual reality labs (C6), as well as the 240 seat 3D-capable Alliant Energy Lee Liu Auditorium, the Multimodal Experience Testbed and Laboratory (METaL), and the User Experience Lab (UX Lab). All of which supports the research of more than 50 faculty and 200 graduate, undergraduate, and postdoctoral students.\n\nIowa State's campus contains over 160 buildings. Several buildings, as well as the Marston Water Tower, are listed on the National Register of Historic Places. The central campus includes of trees, plants, and classically designed buildings. The landscape's most dominant feature is the central lawn, which was listed as a \"medallion site\" by the American Society of Landscape Architects in 1999, one of only three central campuses designated as such. The other two were Harvard University and the University of Virginia.\n\nThomas Gaines, in \"The Campus As a Work of Art\", proclaimed the Iowa State campus to be one of the twenty-five most beautiful campuses in the country. Gaines noted Iowa State's park-like expanse of central campus, and the use of trees and shrubbery to draw together ISU's varied building architecture. Over decades, campus buildings, including the Campanile, Beardshear Hall, and Curtiss Hall, circled and preserved the central lawn, creating a space where students study, relax, and socialize.\n\nThe campanile was constructed during 1897-1898 as a memorial to Margaret MacDonald Stanton, Iowa State's first dean of women, who died on July 25, 1895. The tower is located on ISU's central campus, just north of the Memorial Union. The site was selected by Margaret's husband, Edgar W. Stanton, with the help of then-university president William M. Beardshear. The campanile stands tall on a 16 by 16 foot (5 by 5 m) base, and cost $6,510.20 to construct.\n\nThe campanile is widely seen as one of the major symbols of Iowa State University. It is featured prominently on the university's official ring and the university's mace, and is also the subject of the university's alma mater, \"The Bells of Iowa State\".\n\nNamed for Dr. LaVerne W. Noyes, who also donated the funds to see that Alumni Hall could be completed after sitting unfinished and unused from 1905 to 1907. Dr. Noyes is an 1872 alumnus. Lake LaVerne is located west of the Memorial Union and south of Alumni Hall, Carver Hall, and Music Hall. The lake was a gift from Dr. Noyes in 1916.\n\nLake LaVerne is the home of two mute swans named Sir Lancelot and Elaine, donated to Iowa State by VEISHEA 1935. In 1944, 1970, and 1971 cygnets (baby swans) made their home on Lake LaVerne. Previously Sir Lancelot and Elaine were trumpeter swans but were too aggressive and in 1999 were replaced with two mute swans.\n\nIn early spring 2003, Lake LaVerne welcomed its newest and most current mute swan duo. In support of Iowa Department of Natural Resources efforts to re-establish the trumpeter swans in Iowa, university officials avoided bringing breeding pairs of male and female mute swans to Iowa State which means the current Sir Lancelot and Elaine are both female.\n\nIowa State has maintained a horticulture garden since 1914. Reiman Gardens is the third location for these gardens. Today's gardens began in 1993 with a gift from Bobbi and Roy Reiman. Construction began in 1994 and the Gardens' initial were officially dedicated on September 16, 1995.\n\nReiman Gardens has since grown to become a site consisting of a dozen distinct garden areas, an indoor conservatory and an indoor butterfly \"wing\", butterfly emergence cases, a gift shop, and several supporting greenhouses. Located immediately south of Jack Trice Stadium on the ISU campus, Reiman Gardens is a year-round facility that has become one of the most visited attractions in central Iowa.\n\nThe Gardens has received a number of national, state, and local awards since its opening, and its rose gardens are particularly noteworthy. It was honored with the President's Award in 2000 by All American Rose Selections, Inc., which is presented to one public garden in the United States each year for superior rose maintenance and display: “For contributing to the public interest in rose growing through its efforts in maintaining an outstanding public rose garden.”\n\nThe University Museums consist of the Brunnier Art Museum, Farm House Museum, the Art on Campus Program, the Christian Petersen Art Museum, and the Elizabeth and Byron Anderson Sculpture Garden. The Museums include a multitude of unique exhibits, each promoting the understanding and delight of the visual arts as well as attempt to incorporate a vast interaction between the arts, sciences, and technology.\n\nThe Brunnier Art Museum, Iowa's only accredited museum emphasizing a decorative arts collection, is one of the nation's few museums located within a performing arts and conference complex, the Iowa State Center. Founded in 1975, the museum is named after its benefactors, Iowa State alumnus Henry J. Brunnier and his wife Ann. The decorative arts collection they donated, called the Brunnier Collection, is extensive, consisting of ceramics, glass, dolls, ivory, jade, and enameled metals.\n\nOther fine and decorative art objects from the University Art Collection include prints, paintings, sculptures, textiles, carpets, wood objects, lacquered pieces, silver, and furniture. About eight to 12 annual changing exhibitions and permanent collection exhibitions provide educational opportunities for all ages, from learning the history of a quilt hand-stitched over 100 years ago to discovering how scientists analyze the physical properties of artists' materials, such as glass or stone. Lectures, receptions, conferences, university classes, panel discussions, gallery walks, and gallery talks are presented to assist with further interpretation of objects.\n\nLocated near the center of the Iowa State campus, the Farm House Museum sits as a monument to early Iowa State history and culture as well as a National Historic Landmark. As the first building on campus, the Farm House was built in 1860 before campus was occupied by students or even classrooms. The college's first farm tenants primed the land for agricultural experimentation. This early practice lead to Iowa State Agricultural College and Model Farm opening its doors to Iowa students for free in 1869 under the Morrill Act (or Land-grant Act) of 1862.\n\nMany prominent figures have made the Farm House their home throughout its 150 years of use. The first president of the College, Adonijah Welch, briefly stayed at the Farm House and even wrote his inaugural speech in a bedroom on the second floor. James “Tama Jim” Wilson resided for much of the 1890s with his family at the Farm House until he joined President William McKinley's cabinet as U.S. Secretary of Agriculture. Agriculture Dean Charles Curtiss and his young family replaced Wilson and became the longest resident of Farm House.\n\nIn 1976, over 110 years after the initial construction, the Farm House became a museum after much time and effort was put into restoring the early beauty of the modest farm home. Today, faculty, students, and community members can enjoy the museum while honoring its significance in shaping a nationally recognized land-grant university. Its collection boasts a large collection of 19th and early 20th century decorative arts, furnishings and material culture reflecting Iowa State and Iowa heritage. Objects include furnishings from Carrie Chapman Catt and Charles Curtiss, a wide variety of quilts, a modest collection of textiles and apparel, and various china and glassware items.\n\nAs with many sites on the Iowa State University Campus, The Farm House Museum has a few old myths and legends associated with it. There are rumors of a ghost changing silverware and dinnerware, unexplained rattling furniture, and curtains that have opened seemingly by themselves.\n\nThe Farm House Museum is a unique on-campus educational resource providing a changing environment of exhibitions among the historical permanent collection objects that are on display. A walk through the Farm House Museum immerses visitors in the Victorian era (1860-1910) as well as exhibits colorful Iowa and local Ames history.\n\nIowa State is home to one of the largest campus public art programs in the United States. Over 2,000 works of public art, including 600 by significant national and international artists, are located across campus in buildings, courtyards, open spaces and offices.\n\nThe traditional public art program began during the Depression in the 1930s when Iowa State College's President Raymond Hughes envisioned that \"the arts would enrich and provide substantial intellectual exploration into our college curricula.\" Hughes invited Grant Wood to create the Library's agricultural murals that speak to the founding of Iowa and Iowa State College and Model Farm. He also offered Christian Petersen a one-semester sculptor residency to design and build the fountain and bas relief at the Dairy Industry Building. In 1955, 21 years later, Petersen retired having created 12 major sculptures for the campus and hundreds of small studio sculptures.\n\nThe Art on Campus Collection is a campus-wide resource of over 2000 public works of art. Programs, receptions, dedications, university classes, Wednesday Walks, and educational tours are presented on a regular basis to enhance visual literacy and aesthetic appreciation of this diverse collection.\n\nThe Christian Petersen Art Museum in Morrill Hall is named for the nation's first permanent campus artist-in-residence, Christian Petersen, who sculpted and taught at Iowa State from 1934 through 1955, and is considered the founding artist of the Art on Campus Collection.\n\nNamed for Justin Smith Morrill who created the Morrill Land-Grant Colleges Act, Morrill Hall was completed in 1891. Originally constructed to fill the capacity of a library, museum, and chapel, its original uses are engraved in the exterior stonework on the east side. The building was vacated in 1996 when it was determined unsafe and was also listed in the National Register of Historic Places the same year. In 2005, $9 million was raised to renovate the building and convert it into a museum. Completed and reopened in March 2007, Morrill Hall is home to the Christian Petersen Art Museum.\n\nAs part of University Museums, the Christian Petersen Art Museum at Morrill Hall is the home of the Christian Petersen Art Collection, the Art on Campus Program, the University Museums's Visual Literacy and Learning Program, and Contemporary Changing Art Exhibitions Program.\n\nLocated within the Christian Petersen Art Museum are the Lyle and Nancy Campbell Art Gallery, the Roy and Bobbi Reiman Public Art Studio Gallery, the Margaret Davidson Center for the Study of the Art on Campus Collection, the Edith D. and Torsten E. Lagerstrom Loaned Collections Center, and the Neva M. Petersen Visual Learning Gallery. University Museums shares the James R. and Barbara R. Palmer Small Objects Classroom in Morrill Hall.\n\nThe Elizabeth and Byron Anderson Sculpture Garden is located by the Christian Petersen Art Museum at historic Morrill Hall. The sculpture garden design incorporates sculptures, a gathering arena, and sidewalks and pathways. Planted with perennials, ground cover, shrubs, and flowering trees, the landscape design provides a distinctive setting for important works of 20th and 21st century sculpture, primarily American. Ranging from forty-four inches to nearly nine feet high and from bronze to other metals, these works of art represent the richly diverse character of modern and contemporary sculpture.\n\nThe sculpture garden is adjacent to Iowa State's central campus. Adonijah Welch, ISU's first president, envisioned a picturesque campus with a winding road encircling the college's majestic buildings, vast lawns of green grass, many varieties of trees sprinkled throughout to provide shade, and shrubbery and flowers for fragrance. Today, the central lawn continues to be an iconic place for all Iowa Staters, and enjoys national acclaim as one of the most beautiful campuses in the country. The new Elizabeth and Byron Anderson Sculpture Garden further enhances the beauty of Iowa State.\n\nIowa State's composting facility \"can handle more than 10,000 tons of organic wastes annually.\" The school's new $3 million revolving loan fund loans money for energy efficiency and conservation projects on campus. In the 2011 College Sustainability Report Card issued by the Sustainable Endowments Institute, the university received a B grade.\n\nIowa State operates 20 on-campus residence halls. The residence halls are divided into geographical areas.\n\nThe Union Drive Association\n(UDA) consists of four residence halls located on the west side of campus, including Friley Hall, which has been declared one of the largest residence halls in the country.\n\nThe Richardson Court Association (RCA) consists of 12 residence halls on the east side of campus.\n\nThe Towers Residence Association (TRA) are located south of the main campus. Two of the four towers, Knapp and Storms Halls, were imploded in 2005; however, Wallace and Wilson Halls still stand.\n\nBuchanan Hall and Geoffroy Hall are nominally considered part of the RCA, despite their distance from the other buildings.\n\nISU operates four apartment complexes for upperclassmen, Frederiksen Court, SUV Apartments, Legacy Tower, and Maricopa, the latter two being leased by the university.\n\nThe governing body for ISU students is ISU Student Government. The ISU Student Government is composed of a president, vice president, finance director, cabinet appointed by the president, a clerk appointed by the vice president, senators representing each college and residence area at the university, a nine-member judicial branch and an election commission.\n\nISU has over 800 student organizations on campus that represent a variety of interests. Organizations are supported by Iowa State's Student Activities Center. Many student organization offices are housed in the Memorial Union.\n\nThe Memorial Union at Iowa State University opened in September 1928 and is currently home to a number of University departments and student organizations, a bowling alley, the University Book Store, and the Hotel Memorial Union.\n\nThe original building was designed by architect, William T. Proudfoot. The building employs a classical style of architecture reflecting Greek and Roman influences. The building's design specifically complements the designs of the major buildings surrounding the University's Central Campus area, Beardshear Hall to the west, Curtiss Hall to the east, and MacKay Hall to the north. The style utilizes columns with Corinthian capitals, Paladian windows, triangular pediments, and formally balanced facades.\n\nDesigned to be a living memorial for ISU students lost in World War I, the building includes a solemn memorial hall, named the Gold Star Room, which honors the names of the dead World War I, World War II, Korean, Vietnam, and War on Terrorism veterans engraved in marble. Symbolically, the hall was built directly over a library (the Browsing Library) and a small chapel, the symbol being that no country would ever send its young men to die in a war for a noble cause without a solid foundation on both education (the library) and religion (the chapel).\n\nRenovations and additions have continued through the years to include: elevators, bowling lanes, a parking ramp, a book store, food court, and additional wings.\n\nThe Choral Division of the Department of Music and Theater at Iowa State University consists of over 400 choristers in four main ensembles – the \"Iowa State Singers\", \"Cantamus,\" the \"Iowa Statesmen\", and \"Lyrica\" – and multiple small ensembles including three a cappella groups, \"Count Me In\" (female), \"Shy of a Dozen\" (male), and \"Hymn and Her\" (co-ed).\n\nISU is home to an active Greek community. There are 50 chapters that involve 14.6 percent of undergraduate students. Collectively, fraternity and sorority members have raised over $82,000 for philanthropies and committed 31,416 hours to community service. In 2006, the ISU Greek community was named the best large Greek community in the Midwest.\n\nThe ISU Greek Community has received multiple Jellison and Sutherland Awards from Association for Fraternal Leadership and Values, formerly the Mid-American Greek Council Association. These awards recognize the top Greek Communities in the Midwest.\n\nThe first fraternity, Delta Tau Delta, was established at Iowa State in 1875, six years after the first graduating class entered Iowa State. The first sorority, I.C. Sorocis, was established only two years later, in 1877. I.C. Sorocis later became a chapter of the first national sorority at Iowa State, Pi Beta Phi. Anti-Greek rioting occurred in 1888. As reported in \"The Des Moines Register\", \"The anti-secret society men of the college met in a mob last night about 11 o'clock in front of the society rooms in chemical and physical hall, determined to break up a joint meeting of three secret societies.\" In 1891, President William Beardshear banned students from joining secret college fraternities, resulting in the eventual closing of all formerly established fraternities. President Storms lifted the ban in 1904.\n\nFollowing the lifting of the fraternity ban, the first thirteen national fraternities (IFC) installed on the Iowa State campus between 1904 and 1913 were, in order, Sigma Nu, Sigma Alpha Epsilon, Beta Theta Pi, Phi Gamma Delta, Alpha Tau Omega, Kappa Sigma, Theta Xi, Acacia, Phi Sigma Kappa, Delta Tau Delta, Pi Kappa Alpha, and Phi Delta Theta. Though some have suspended their chapters at various times, eleven of the original thirteen fraternities were active in 2008. Many of these chapters existed on campus as local fraternities before being reorganized as national fraternities, prior to 1904.\n\nIn the Spring of 2014, it was announced that Alpha Phi Sorority would be coming to Iowa state in the Fall of 2014, with Delta Gamma Sorority Following in the near future.\n\nThe \"Iowa State Daily\" is the university's student newspaper. The \"Daily\" has its roots from a news sheet titled the \"Clipper\", which was started in the spring of 1890 by a group of students at Iowa Agricultural College led by F.E. Davidson. The \"Clipper\" soon led to the creation of the \"Iowa Agricultural College Student\", and the beginnings of what would one day become the \"Iowa State Daily\". It was awarded the 2016 Best All-Around Daily Student Newspaper by the Society of Professional Journalists.\n\n88.5 KURE is the university's student-run radio station. Programming for KURE includes ISU sports coverage, talk shows, the annual quiz contest Kaleidoquiz, and various music genres.\n\nISUtv is the university's student-run television station. It is housed in the former WOI-TV station that was established in 1950. The student organization of ISUtv has many programs including Newswatch, a twice weekly news spot, Cyclone InCyders, the campus sports show, Fortnightly News, a satirical/comedy program, and Cy's Eyes on the Skies, a twice weekly weather show.\n\nThe \"Cyclones\" name dates back to 1895. That year, Iowa suffered an unusually high number of devastating cyclones (as tornadoes were called at the time). In September, Iowa Agricultural College's football team traveled to Northwestern University and defeated that team by a score of 36-0. The next day, the \"Chicago Tribune\"'s headline read \"Struck by a Cyclone: It Comes from Iowa and Devastates Evanston Town.\" The article began, \"Northwestern might as well have tried to play football with an Iowa cyclone as with the Iowa team it met yesterday.\" The nickname stuck.\n\nThe school colors are cardinal and gold. The mascot is Cy the Cardinal, introduced in 1954. Since a cyclone was determined to be difficult to depict in costume, the cardinal was chosen in reference to the school colors. A contest was held to select a name for the mascot, with the name Cy being chosen as the winner.\n\nThe Iowa State Cyclones are a member of the Big 12 Conference and compete in NCAA Division I Football Bowl Subdivision (FBS), fielding 16 varsity teams in 12 sports. The Cyclones also compete in and are a founding member of the Central States Collegiate Hockey League of the American Collegiate Hockey Association.\n\nIowa State's intrastate archrival is the University of Iowa with whom it competes annually for the Iowa Corn Cy-Hawk Series trophy, an annual athletic competition between the two schools. Sponsored by the Iowa Corn Growers Association, the competition includes all head-to-head regular season competitions between the two rival universities in all sports.\n\nFootball first made its way onto the Iowa State campus in 1878 as a recreational sport, but it was not until 1892 that Iowa State organized its first team to represent the school in football. In 1894, college president William M. Beardshear spearheaded the foundation of an athletic association to officially sanction Iowa State football teams. The 1894 team finished with a 6-1 mark. The Cyclones compete each year for traveling trophies. Since 1977, Iowa State and Iowa compete annually for the Cy-Hawk Trophy. Iowa State competes in an annual rivalry game against Kansas State known as Farmageddon and against former conference foe Missouri for the Telephone Trophy. The main rival is the Iowa Hawkeyes. Unfortunately for Iowa State, this competition has not gone well in recent years. The Hawkeyes have won the last four games. Nevertheless, this rivalry has provided excitement for fans from Ames and Iowa City alike.\nThe Cyclones play their home games at Jack Trice Stadium, named after Jack Trice, ISU's first African-American athlete and also the first and only Iowa State athlete to die from injuries sustained during athletic competition. Trice died three days after his first game playing for Iowa State against Minnesota in Minneapolis on October 6, 1923. Suffering from a broken collarbone early in the game, he continued to play until he was trampled by a group of Minnesota players. It is disputed whether he was trampled purposely or if it was by accident. The stadium was named in his honor in 1997 and is the only NCAA Division I-A stadium named after an African-American. Jack Trice Stadium, formerly known as Cyclone Stadium, opened on September 20, 1975, with a win against the Air Force Academy.\n\nHopes of \"Hilton Magic\" returning took a boost with the hiring of ISU alum, Ames native, and fan favorite Fred Hoiberg as coach of the men's basketball team in April 2010. Hoiberg (\"The Mayor\") played three seasons under legendary coach Johnny Orr and one season under future Chicago Bulls coach Tim Floyd during his standout collegiate career as a Cyclone (1991–95). Orr laid the foundation of success in men's basketball upon his arrival from Michigan in 1980 and is credited with building Hilton Magic. Besides Hoiberg, other Cyclone greats played for Orr and brought winning seasons, including Jeff Grayer, Barry Stevens, and walk-on Jeff Hornacek. The 1985-86 Cyclones were one of the most memorable. Orr coached the team to second place in the Big Eight and produced one of his greatest career wins, a victory over his former team and No. 2 seed Michigan in the second round of the NCAA tournament.\n\nUnder coaches Floyd (1995–98) and Larry Eustachy (1998–2003), Iowa State achieved even greater success. Floyd took the Cyclones to the Sweet Sixteen in 1997 and Eustachy led ISU to two consecutive Big 12 regular season conference titles in 1999-2000 and 2000–01, plus the conference tournament title in 2000. Seeded No. 2 in the 2000 NCAA tournament, Eustachy and the Cyclones defeated UCLA in the Sweet Sixteen before falling to Michigan State, the eventual NCAA Champion, in the regional finals by a score of 75-64 (the differential representing the Spartans' narrowest margin of victory in the tournament). Standout Marcus Fizer and Jamaal Tinsley were scoring leaders for the Cyclones who finished the season 32-5. Tinsley returned to lead the Cyclones the following year with another conference title and No. 2 seed, but ISU finished the season with a 25-6 overall record after a stunning loss to No. 15 seed Hampton in the first round.\n\nIn 2011-12, Hoiberg's Cyclones finished third in the Big 12 and returned to the NCAA Tournament, dethroning defending national champion Connecticut, 77-64, in the second round before losing in the Round of 32 to top-seeded Kentucky. All-Big 12 First Team selection Royce White led the Cyclones with 38 points and 22 rebounds in the two contests, ending the season at 23-11.\n\nThe 2013-14 campaign turned out to be another highly successful season. Iowa State went 28-8, won the Big 12 Tournament, and advanced to the Sweet Sixteen by beating North Carolina in the second round of the NCAA Tournament. The Cyclones finished 11-7 in Big 12 play, finishing in a tie for third in the league standings, and beat a school-record nine teams (9-3) that were ranked in the Associated Press top 25. The Cyclones opened the season 14-0, breaking the school record for consecutive wins. Melvin Ejim was named the Big 12 Player of the Year and an All-American by five organizations. Deandre Kane was named the Big 12 Tournament's most valuable player.\n\nOn June 8, 2015, Steve Prohm took over as head basketball coach replacing Hoiberg who left to take the head coaching position with the Chicago Bulls. In his first season with the Cyclones, Prohm secured a #4 seed in the Midwest region where the Cyclones advanced to the Sweet Sixteen before falling to top-seeded Virginia, 84-71. In 2017, Iowa State stunned 3rd ranked Kansas, 92-89, in overtime, snapping KU's 54-game home winning streak, before winning the 2017 Big 12 Men's Basketball Tournament, its third conference championship in four years, defeating West Virginia in the final.\n\nOf Iowa State's 16 NCAA Tournament appearances, the Cyclones have reached the Sweet Sixteen six times (1944, 1986, 1997, 2000, 2014, 2016), made two appearances in the Elite Eight (1944, 2000), and reached the Final Four once in 1944.\n\nIowa State is known for having one of the most successful women's basketball programs in the nation. Since the founding of the Big 12, Coach Bill Fennelly and the Cyclones have won three conference titles (one regular season, two tournament), and have advanced to the Sweet Sixteen five times (1999–2001, 2009, 2010) and the Elite Eight twice (1999, 2009) in the NCAA Tournament. The team has one of the largest fan bases in the nation with attendance figures ranked third in the nation in 2009, 2010, and 2012.\n\nCoach Christy Johnson-Lynch led the 2012 Cyclones team to a fifth straight 20-win season and fifth NCAA regional semifinal appearance in six seasons, and leading Iowa State to a 22-8 (13-3 Big 12) overall record and second-place finish in the conference. The Cyclones finished the season with seven wins over top-25 teams, including a victory over No. 1 Nebraska Cornhuskers in Iowa State's first-ever win over a top-ranked opponent in addition to providing the only Big 12 Conference loss to the 2012 conference and NCAA champion Texas Longhorns.\n\nIn 2011, Iowa State finished the season 25-6 (13-3 Big 12), placing second in the league, as well as a final national ranking of eighth. 2011 is only the second season in which an Iowa State volleyball team has ever recorded 25 wins. The Cyclones beat No. 9 Florida during the season in Gainesville, its sixth win over a top-10 team in Cyclone history. In 2009, Iowa State finished the season second in the Big 12 behind Texas with a 27-5 record and ranked No. 6, its highest ever national finish.\n\nJohnson-Lynch is the fastest Iowa State coach to clinch 100 victories. In 2011, she became the school's winningest volleyball coach when her team defeated the Texas Tech Red Raiders, her 136th coaching victory, in straight sets.\n\nThe ISU wrestling program has captured the NCAA wrestling tournament title eight times between 1928 and 1987, and won the Big 12 Conference Tournament three consecutive years, 2007-2009. On February 7, 2010, the Cyclones became the first collegiate wrestling program to record its 1,000th dual win in program history by defeating the Arizona State Sun Devils, 30-10, in Tempe, Arizona.\n\nIn 2002, under former NCAA champion & Olympian Coach Bobby Douglas, Iowa State became the first school to produce a four-time, undefeated NCAA Division I champion, Cael Sanderson (considered by the majority of the wrestling community to be the best college wrestler ever), who also took the gold medal at the 2004 Olympic Games in Athens, Greece. Dan Gable, another legendary ISU wrestler, is famous for having lost only one match in his entire Iowa State collegiate career - his last - and winning gold at the 1972 Olympics in Munich, Germany, while not giving up a single point.\n\nIn 2013, Iowa State hosted its eighth NCAA Wrestling Championships. The Cyclones hosted the first NCAA championships in 1928.\n\nIn February 2017, former Virginia Tech coach and 2016 NWCA Coach of the Year Kevin Dresser was introduced as the new Cyclone wrestling coach, replacing Kevin Jackson.\n\nSince its inception in 1858, Iowa State has fostered excellence in its alumni, under the instruction of world-class faculty. These people include Nobel laureates, astronauts, scientists, Pulitzer Prize winners, statesmen, academics, CEOs, entrepreneurs, athletes, film and television actors, and a host of other notable individuals in their respective fields.\n\n\n"}
{"id": "14877", "url": "https://en.wikipedia.org/wiki?curid=14877", "title": "Induction", "text": "Induction\n\nInduction may refer to:\n\n\n\n\n\n"}
{"id": "14878", "url": "https://en.wikipedia.org/wiki?curid=14878", "title": "International Astronomical Union", "text": "International Astronomical Union\n\nThe International Astronomical Union (IAU; , UAI) is an international association of professional astronomers, at the PhD level and beyond, active in professional research and education in astronomy. Among other activities, it acts as the internationally recognized authority for assigning designations and names to celestial bodies (stars, planets, asteroids, etc.) and any surface features on them.\n\nThe IAU is a member of the International Council for Science (ICSU). Its main objective is to promote and safeguard the science of astronomy in all its aspects through international cooperation. The IAU maintains friendly relations with organizations that include amateur astronomers in their membership. The IAU has its head office on the second floor of the \"Institut d'Astrophysique de Paris\" in the 14th arrondissement of Paris. Working groups include the Working Group for Planetary System Nomenclature (WGPSN), which maintains the astronomical naming conventions and planetary nomenclature for planetary bodies, and the Working Group on Star Names (WGSN), which catalogs and standardizes proper names for stars. The IAU is also responsible for the system of astronomical telegrams which are produced and distributed on its behalf by the Central Bureau for Astronomical Telegrams. The Minor Planet Center also operates under the IAU, and is a \"clearinghouse\" for all non-planetary or non-moon bodies in the Solar System. The Working Group for Meteor Shower Nomenclature and the Meteor Data Center coordinate the nomenclature of meteor showers.\n\nThe IAU was founded on 28 July 1919, at the Constitutive Assembly of the International Research Council (now International Council for Science) held in Brussels, Belgium. Two subsidiaries of the IAU were also created at this assembly: the \"International Time Commission\" seated at the International Time Bureau in Paris, France, and the \"International Central Bureau of Astronomical Telegrams\" initially seated in Copenhagen, Denmark. The 7 initial member states were Belgium, Canada, France, Great Britain, Greece, Japan, and the United States, soon to be followed by Italy and Mexico. The first executive committee consisted of Benjamin Baillaud (President, France), Alfred Fowler (General Secretary, UK), and four vice presidents: William Campbell (USA), Frank Dyson (UK), Georges Lecointe (Belgium), and Annibale Riccò (Italy). Thirty-two Commissions (referred to initially as Standing Committees) were appointed at the Brussels meeting and focused on topics ranging from relativity to minor planets. The reports of these 32 Commissions formed the main substance of the first General Assembly, which took place in Rome, Italy, 2–10 May 1922. By the end of the first General Assembly, ten additional nations (Australia, Brazil, Czecho-Slovakia, Denmark, the Netherlands, Norway, Poland, Romania, South Africa, and Spain) had joined the Union, bringing the total membership to 19 countries. Although the Union was officially formed eight months after the end of World War I, international collaboration in astronomy had been strong in the pre-war era (e.g., the Astronomische Gesellschaft Katalog projects since 1868, the Astrographic Catalogue since 1887, and the International Union for Solar research since 1904).\n\nThe first 50 years of the Union's history are well documented. Subsequent history is recorded in the form of reminiscences of past IAU Presidents and General Secretaries. Twelve of the fourteen past General Secretaries in the period 1964-2006 contributed their recollections of the Union's history in IAU Information Bulletin No. 100. Six past IAU Presidents in the period 1976–2003 also contributed their recollections in IAU Information Bulletin No. 104.\n\nThe IAU includes a total of 12,664 \"individual members\" who are professional astronomers from 96 countries worldwide. 83% of all individual members are male, while 17% are female, among them the union's former president, Mexican astronomer Silvia Torres-Peimbert.\n\nMembership also includes 79 \"national members\", professional astronomical communities representing their country's affiliation with the IAU. National members include the Australian Academy of Science, the Chinese Astronomical Society, the French Academy of Sciences, the Indian National Science Academy, the National Academies (United States), the National Research Foundation of South Africa, the National Scientific and Technical Research Council (Argentina), KACST (Saudi Arabia), the Council of German Observatories, the Royal Astronomical Society (United Kingdom), the Royal Astronomical Society of New Zealand, the Royal Swedish Academy of Sciences, the Russian Academy of Sciences, and the Science Council of Japan, among many others.\n\nThe sovereign body of the IAU is its \"General Assembly\", which comprises all members. The Assembly determines IAU policy, approves the Statutes and By-Laws of the Union (and amendments proposed thereto) and elects various committees.\n\nThe right to vote on matters brought before the Assembly varies according to the type of business under discussion. The Statutes consider such business to be divided into two categories:\n\n\nOn budget matters (which fall into the second category), votes are weighted according to the relative subscription levels of the national members. A second category vote requires a turnout of at least two-thirds of national members in order to be valid. An absolute majority is sufficient for approval in any vote, except for Statute revision which requires a two-thirds majority. An equality of votes is resolved by the vote of the President of the Union.\n\nSince 1922, the IAU General Assembly meets every three years, with the exception of the period between 1938 and 1948, due to World War II.\nAfter a Polish request in 1967, and by a controversial decision of the then President of the IAU, an \"Extraordinary IAU General Assembly\" was held in September 1973 in Warsaw, Poland, to commemorate the 500th anniversary of the birth of Nicolaus Copernicus, soon after the regular 1973 GA had been held in Sydney, Australia.\n\nSources.\nCommission 46 is a Committee of the Executive Committee of the IAU, playing a special role in the discussion of astronomy development with governments and scientific academies. The IAU is affiliated with the International Council of Scientific Unions (ICSU), a non-governmental organization representing a global membership that includes both national scientific bodies and international scientific unions. They often encourage countries to become members of the IAU. The Commission further seeks to development, information or improvement of astronomical education. Part of Commission 46, is Teaching Astronomy for Development (TAD) program in countries where there is currently very little astronomical education. Another program is named the Galileo Teacher Training Program (GTTP), being a project of the International Year of Astronomy 2009, among which Hands-On Universe that will concentrate more resources on education activities for children and schools designed to advance sustainable global development. GTTP is also concerned with the effective use and transfer of astronomy education tools and resources into classroom science curricula. A strategic plan for the period 2010-2020 has been published.\n\nIn 2004 the IAU contracted with the Cambridge University Press to publish the \"Proceedings of the International Astronomical Union\".\n\nIn 2007, the Communicating Astronomy with the Public Journal Working Group prepared a study assessing the feasibility of the \"Communicating Astronomy with the Public Journal\" (\"CAP Journal\").\n\n\n"}
{"id": "14879", "url": "https://en.wikipedia.org/wiki?curid=14879", "title": "Interval", "text": "Interval\n\nInterval may refer to:\n\n\n\n\n\n"}
{"id": "14880", "url": "https://en.wikipedia.org/wiki?curid=14880", "title": "International Criminal Court", "text": "International Criminal Court\n\nThe International Criminal Court (ICC or ICCt) is an intergovernmental organization and international tribunal that sits in The Hague in the Netherlands. The ICC has the jurisdiction to prosecute individuals for the international crimes of genocide, crimes against humanity, and war crimes. The ICC is intended to complement existing national judicial systems and it may therefore exercise its jurisdiction only when certain conditions are met, such as when national courts are unwilling or unable to prosecute criminals or when the United Nations Security Council or individual states refer situations to the Court. The ICC began functioning on 1 July 2002, the date that the Rome Statute entered into force. The Rome Statute is a multilateral treaty which serves as the ICC's foundational and governing document. States which become party to the Rome Statute, for example by ratifying it, become member states of the ICC. Currently, there are 123 ICC member states.\n\nThe ICC has four principal organs: the Presidency, the Judicial Divisions, the Office of the Prosecutor, and the Registry. The President is the most senior judge chosen by his or her peers in the Judicial Division, which hears cases before the Court. The Office of the Prosecutor is headed by the Prosecutor who investigates crimes and initiates proceedings before the Judicial Division. The Registry is headed by the Registrar and is charged with managing all the administrative functions of the ICC, including the headquarters, detention unit, and public defense office.\n\nThe Office of the Prosecutor has opened ten official investigations and is also conducting an additional eleven preliminary examinations. Thus far, 39 individuals have been indicted in the ICC, including Ugandan rebel leader Joseph Kony, Sudanese president Omar al-Bashir, Kenyan president Uhuru Kenyatta, Libyan leader Muammar Gaddafi, Ivorian president Laurent Gbagbo, and DR Congo vice-president Jean-Pierre Bemba.\n\nThe ICC has faced a number of criticisms from states and civil society, including objections about its jurisdiction, accusations of bias, questioning of the fairness of its case-selection and trial procedures, and doubts about its effectiveness.\n\nThe establishment of an international tribunal to judge political leaders accused of international crimes was first proposed during the Paris Peace Conference in 1919 following the First World War by the Commission of Responsibilities. The issue was addressed again at a conference held in Geneva under the auspices of the League of Nations in 1937, which resulted in the conclusion of the first convention stipulating the establishment of a permanent international court to try acts of international terrorism. The convention was signed by 13 states, but none ratified it and the convention never entered into force.\n\nFollowing the Second World War, the allied powers established two \"ad hoc\" tribunals to prosecute axis power leaders accused of war crimes. The International Military Tribunal, which sat in Nuremberg, prosecuted German leaders while the International Military Tribunal for the Far East in Tokyo prosecuted Japanese leaders. In 1948 the United Nations General Assembly first recognised the need for a permanent international court to deal with atrocities of the kind prosecuted after the Second World War. At the request of the General Assembly, the International Law Commission (ILC) drafted two statutes by the early 1950s but these were shelved during the Cold War, which made the establishment of an international criminal court politically unrealistic.\n\nBenjamin B. Ferencz, an investigator of Nazi war crimes after the Second World War, and the Chief Prosecutor for the United States Army at the Einsatzgruppen Trial, became a vocal advocate of the establishment of international rule of law and of an international criminal court. In his first book published in 1975, entitled \"Defining International Aggression: The Search for World Peace\", he advocated for the establishment of such a court. A second major advocate was Robert Kurt Woetzel, who co-edited \"Toward a Feasible International Criminal Court\" in 1970 and created the Foundation for the Establishment of an International Criminal Court in 1971.\n\nIn June 1989 Prime Minister of Trinidad and Tobago A. N. R. Robinson revived the idea of a permanent international criminal court by proposing the creation of such a court to deal with the illegal drug trade. Following Trinidad and Tobago's proposal, the General Assembly tasked the ILC with once again drafting a statute for a permanent court. While work began on the draft, the United Nations Security Council established two \"ad hoc\" tribunals in the early 1990s. The International Criminal Tribunal for the former Yugoslavia was created in 1993 in response to large-scale atrocities committed by armed forces during Yugoslav Wars, and the International Criminal Tribunal for Rwanda was created in 1994 following the Rwandan Genocide. The creation of these tribunals further highlighted the need for a permanent international criminal court.\n\nIn 1994, the ILC presented its final draft statute for the International Criminal Court to the General Assembly and recommended that a conference be convened to negotiate a treaty that would serve as the Court's statute. To consider major substantive issues in the draft statute, the General Assembly established the Ad Hoc Committee on the Establishment of an International Criminal Court, which met twice in 1995. After considering the Committee's report, the General Assembly created the Preparatory Committee on the Establishment of the ICC to prepare a consolidated draft text. From 1996 to 1998, six sessions of the Preparatory Committee were held at the United Nations headquarters in New York City, during which NGOs provided input and attended meetings under the umbrella organisation of the Coalition for an ICC (CICC). In January 1998, the Bureau and coordinators of the Preparatory Committee convened for an Inter-Sessional meeting in Zutphen in the Netherlands to technically consolidate and restructure the draft articles into a draft.\n\nFinally the General Assembly convened a conference in Rome in June 1998, with the aim of finalizing the treaty to serve as the Court's statute. On 17 July 1998, the Rome Statute of the International Criminal Court was adopted by a vote of 120 to 7, with 21 countries abstaining. The seven countries that voted against the treaty were China, Iraq, Israel, Libya, Qatar, the United States, and Yemen. Israel’s vote against was due to the inclusion in the list of a war crimes of “the action of transferring population into occupied territory”.\n\nFollowing 60 ratifications, the Rome Statute entered into force on 1 July 2002 and the International Criminal Court was formally established. The first bench of 18 judges was elected by the Assembly of States Parties in February 2003. They were sworn in at the inaugural session of the Court on 11 March 2003.\n\nThe Court issued its first arrest warrants on 8 July 2005, and the first pre-trial hearings were held in 2006. The Court issued its first judgment in 2012 when it found Congolese rebel leader Thomas Lubanga Dyilo guilty of war crimes related to using child soldiers.\n\nIn 2010 the states parties of the Rome Statute held the first Review Conference of the Rome Statute of the International Criminal Court in Kampala, Uganda. There they adopted two amendments to the Statute. The second amendment defined the crime of aggression and outlined the procedure by which the ICC could prosecute individuals. However, the conditions outlined in the amendment have not yet been met and the ICC can not yet exercise jurisdiction over crimes of aggression.\n\nDuring the Obama administration US opposition to the ICC evolved in \"what Harold Koh, then the State Department’s legal adviser, called \"positive engagement\"\".\n\nIn October 2016, after repeated claims that the court was biased against African states, Burundi, South Africa and the Gambia announced their withdrawals from the Rome Statute. However, following Gambia's presidential election later that year, which ended the long rule of Yahya Jammeh, Gambia rescinded its withdrawal notification. Subsequent to a ruling of the High Court of South Africa, in early 2017, that the country's withdrawal would be unconstitutional, the South African government informed the United Nations, on 7 March 2017, that it was revoking its decision to withdraw.\n\nExperts believe that Kenya, Namibia, and Uganda may soon follow in withdrawing from the court, while South Africa is still committed to withdrawing, leading to a mass African exodus.\n\nPresident Rodrigo Duterte announced on March 14, 2018 that the Philippines will start to submit plans for its withdrawal in the ICC.\n\nThe ICC is governed by an Assembly of States Parties, which is made up of the states which are party to the Rome Statute. The Assembly elects officials of the Court, approves its budget, and adopts amendments to the Rome Statute. The Court itself, however, is composed of four organs: the Presidency, the Judicial Divisions, the Office of the Prosecutor, and the Registry.\n\nThe Court's management oversight and legislative body, the Assembly of States Parties, consists of one representative from each state party. Each state party has one vote and \"every effort\" has to be made to reach decisions by consensus. If consensus cannot be reached, decisions are made by vote. The Assembly is presided over by a president and two vice-presidents, who are elected by the members to three-year terms.\n\nThe Assembly meets in full session once a year, alternating between New York and The Hague, and may also hold special sessions where circumstances require. Sessions are open to observer states and non-governmental organizations.\n\nThe Assembly elects the judges and prosecutors, decides the Court's budget, adopts important texts (such as the Rules of Procedure and Evidence), and provides management oversight to the other organs of the Court. Article 46 of the Rome Statute allows the Assembly to remove from office a judge or prosecutor who \"is found to have committed serious misconduct or a serious breach of his or her duties\" or \"is unable to exercise the functions required by this Statute\".\n\nThe states parties cannot interfere with the judicial functions of the Court. Disputes concerning individual cases are settled by the Judicial Divisions.\n\nIn 2010, Kampala, Uganda hosted the Assembly's Rome Statute Review Conference.\n\nThe Court has four organs: the Presidency, the Judicial Division, the Office of the Prosecutor, and the Registry.\n\nThe Presidency is responsible for the proper administration of the Court (apart from the Office of the Prosecutor). It comprises the President and the First and Second Vice-Presidents—three judges of the Court who are elected to the Presidency by their fellow judges for a maximum of two three-year terms. The current president is Chile Eboe-Osuji, who was elected 11 March 2018, succeeding Silvia Fernández de Gurmendi (first female president).\n\nThe Judicial Divisions consist of the 18 judges of the Court, organized into three chambers—the Pre-Trial Chamber, Trial Chamber and Appeals Chamber—which carry out the judicial functions of the Court. Judges are elected to the Court by the Assembly of States Parties. They serve nine-year terms and are not generally eligible for re-election. All judges must be nationals of states parties to the Rome Statute, and no two judges may be nationals of the same state. They must be \"persons of high moral character, impartiality and integrity who possess the qualifications required in their respective States for appointment to the highest judicial offices\".\n\nThe Prosecutor or any person being investigated or prosecuted may request the disqualification of a judge from \"any case in which his or her impartiality might reasonably be doubted on any ground\". Any request for the disqualification of a judge from a particular case is decided by an absolute majority of the other judges. A judge may be removed from office if he or she \"is found to have committed serious misconduct or a serious breach of his or her duties\" or is unable to exercise his or her functions. The removal of a judge requires both a two-thirds majority of the other judges and a two-thirds majority of the states parties.\n\nThe Office of the Prosecutor (OTP) is responsible for conducting investigations and prosecutions. It is headed by the Chief Prosecutor, who is assisted by one or more Deputy Prosecutors. The Rome Statute provides that the Office of the Prosecutor shall act independently; as such, no member of the Office may seek or act on instructions from any external source, such as states, international organisations, non-governmental organisations or individuals.\n\nThe Prosecutor may open an investigation under three circumstances:\n\nAny person being investigated or prosecuted may request the disqualification of a prosecutor from any case \"in which their impartiality might reasonably be doubted on any ground\". Requests for the disqualification of prosecutors are decided by the Appeals Chamber. A prosecutor may be removed from office by an absolute majority of the states parties if he or she \"is found to have committed serious misconduct or a serious breach of his or her duties\" or is unable to exercise his or her functions. However, critics of the Court argue that there are \"insufficient checks and balances on the authority of the ICC prosecutor and judges\" and \"insufficient protection against politicized prosecutions or other abuses\". Luis Moreno-Ocampo, chief ICC prosecutor, stressed in 2011 the importance of politics in prosecutions: \"You cannot say al-Bashir is in London, arrest him. You need a political agreement.\" Henry Kissinger says the checks and balances are so weak that the prosecutor \"has virtually unlimited discretion in practice\". \n\nAs of 16 June 2012, the Prosecutor has been Fatou Bensouda of Gambia, who had been elected as the new Prosecutor on 12 December 2011. She has been elected for nine years. Her predecessor, Luis Moreno Ocampo of Argentina, had been in office from 2003 to 2012.\n\nA Policy Paper is a document published by the Office of the Prosecutor occasionally where the particular considerations given to the topics in focus of the Office and often criteria for case selection are stated. While a policy paper does not give the Court jurisdiction over a new category of crimes, it promises what the Office of Prosecutor will consider when selecting cases in the upcoming term of service. OTP's policy papers are subject to revision.\n\nOn the Policy Paper published in September 2016 it was announced that the International Criminal Court will focus on environmental crimes when selecting the cases. According to this document, the Office will give particular consideration to prosecuting Rome Statute crimes that are committed by means of, or that result in, \"inter alia, the destruction of the environment, the illegal exploitation of natural resources or the illegal dispossession of land\".\n\nThis has been interpreted as a major shift towards the environmental crimes and a move with significant effects.\n\nThe Registry is responsible for the non-judicial aspects of the administration and servicing of the Court. This includes, among other things, \"the administration of legal aid matters, court management, victims and witnesses matters, defence counsel, detention unit, and the traditional services provided by administrations in international organisations, such as finance, translation, building management, procurement and personnel\". The Registry is headed by the Registrar, who is elected by the judges to a five-year term. The current Registrar is Herman von Hebel, who was elected on 8 March 2013.\n\nThe Rome Statute requires that several criteria exist in a particular case before an individual can be prosecuted by the Court. The Statute contains three jurisdictional requirements and three admissibility requirements. All criteria must be met for a case to proceed.\n\nThere are three jurisdictional requirements in the Rome Statute that must be met before a case may begin against an individual. The requirements are (1) subject-matter jurisdiction (what acts constitute crimes), (2) territorial or personal jurisdiction (where the crimes were committed or who committed them), and (3) temporal jurisdiction (when the crimes were committed).\n\nThe Court's subject-matter jurisdiction means the crimes for which individuals can be prosecuted. Individuals can only be prosecuted for crimes that are listed in the Statute. The primary crimes are listed in article 5 of the Statute and defined in later articles: genocide (defined in article 6), crimes against humanity (defined in article 7), war crimes (defined in article 8), and crimes of aggression (defined in article 8 \"bis\") (which is not yet within the jurisdiction of the Court; see below). In addition, article 70 defines \"offences against the administration of justice\", which is a fifth category of crime for which individuals can be prosecuted.\n\nArticle 6 defines the crime of genocide as \"acts committed with intent to destroy, in whole or in part, a national, ethnical, racial or religious group\". There are five such acts which constitute crimes of genocide under article 6:\nThe definition of these crimes is identical to those contained within the Convention on the Prevention and Punishment of the Crime of Genocide of 1948.\n\nArticle 7 defines crimes against humanity as acts \"committed as part of a widespread or systematic attack directed against any civilian population, with knowledge of the attack\". The article lists 16 such as individual crimes:\n\n\nArticle 8 defines war crimes depending on whether an armed conflict is either international (which generally means it is fought between states) or non-international (which generally means that it is fought between non-state actors, such as rebel groups, or between a state and such non-state actors). In total there are 74 war crimes listed in article 8. The most serious crimes, however, are those that constitute either grave breaches of the Geneva Conventions of 1949, which only apply to international conflicts, and serious violations of article 3 common to the Geneva Conventions of 1949, which apply to non-international conflicts.\n\nThere are 11 crimes which constitute grave breaches of the Geneva Conventions and which are applicable only to international armed conflicts:\n\nThere are seven crimes which constitute serious violations of article 3 common to the Geneva Conventions and which are applicable only to non-international armed conflicts:\n\nAdditionally, there are 56 other crimes defined by article 8: 35 that apply to international armed conflicts and 21 that apply to non-international armed conflicts. Such crimes include attacking civilians or civilian objects, attacking peacekeepers, causing excessive incidental death or damage, transferring populations into occupied territories, treacherously killing or wounding, denying quarter, pillaging, employing poison, using expanding bullets, rape and other forms of sexual violence, and conscripting or using child soldiers.\n\nArticle 8 \"bis\" defines crimes of aggression; however, the Court is not yet able to prosecute individuals for these crimes. The Statute originally provided that the Court could not exercise its jurisdiction over the crime of aggression until such time as the states parties agreed on a definition of the crime and set out the conditions under which it could be prosecuted. Such an amendment was adopted at the first review conference of the ICC in Kampala, Uganda, in June 2010. However, this amendment specified that the ICC would not be allowed to exercise jurisdiction of the crime of aggression until two further conditions had been satisfied: (1) the amendment has entered into force for 30 states parties and (2) on or after 1 January 2017, the Assembly of States Parties has voted in favor of allowing the Court to exercise jurisdiction.\n\nThe Statute, as amended, defines the crime of aggression as \"the planning, preparation, initiation or execution, by a person in a position effectively to exercise control over or to direct the political or military action of a State, of an act of aggression which, by its character, gravity and scale, constitutes a manifest violation of the Charter of the United Nations.\" The Statute defines an \"act of aggression\" as \"the use of armed force by a State against the sovereignty, territorial integrity or political independence of another State, or in any other manner inconsistent with the Charter of the United Nations.\" The article also contains a list of seven acts of aggression, which are identical to those in United Nations General Assembly Resolution 3314 of 1974 and include the following acts when committed by one state against another state:\n\n\nArticle 70 criminalizes certain intentional acts which interfere with investigations and proceedings before the Court, including giving false testimony, presenting false evidence, corruptly influencing a witness or official of the Court, retaliating against an official of the Court, and soliciting or accepting bribes as an official of the Court.\n\nFor an individual to be prosecuted by the Court either territorial jurisdiction or personal jurisdiction must exist. Therefore, an individual can only be prosecuted if he or she has either (1) committed a crime within the territorial jurisdiction of the Court or (2) committed a crime while a national of a state that is within the territorial jurisdiction of the Court.\n\nThe territorial jurisdiction of the Court includes the territory, registered vessels, and registered aircraft of states which have either (1) become party to the Rome Statute or (2) accepted the Court's jurisdiction by filing a declaration with the Court.\n\nIn situations that are referred to the Court by the United Nations Security Council, the territorial jurisdiction is defined by the Security Council, which may be more expansive than the Court's normal territorial jurisdiction. For example, if the Security Council refers a situation that took place in the territory of a state that has both not become party to the Rome Statute and not lodged a declaration with the Court, the Court will still be able to prosecute crimes that occurred within that state.\n\nThe personal jurisdiction of the Court extends to all natural persons who commit crimes, regardless of where they are located or where the crimes were committed, as long as those individuals are nationals of either (1) states that are party to the Rome Statute or (2) states that have accepted the Court's jurisdiction by filing a declaration with the Court. As with territorial jurisdiction, the personal jurisdiction can be expanded by the Security Council if it refers a situation to the Court.\n\nTemporal jurisdiction is the time period over which the Court can exercise its powers. No statute of limitations applies to any of the crimes defined in the Statute. However, the Court's jurisdiction is not completely retroactive. Individuals can only be prosecuted for crimes that took place on or after 1 July 2002, which is the date that the Rome Statute entered into force. If a state became party to the Statute, and therefore a member of the Court, after 1 July 2002, then the Court cannot exercise jurisdiction prior to the membership date for certain cases. For example, if the Statute entered into force for a state on 1 January 2003, the Court could only exercise temporal jurisdiction over crimes that took place in that state or were committed by a national of that state on or after 1 January 2003.\n\nTo initiate an investigation, the Prosecutor must (1) have a \"reasonable basis to believe that a crime within the jurisdiction of the Court has been or is being committed\", (2) the investigation would be consistent with the principle of complementarity, and (3) the investigation serves the interests of justice.\n\nThe principle of complementarity means that the Court will only prosecute an individual if states are unwilling or unable to prosecute. Therefore, if legitimate national investigations or proceedings into crimes have taken place or are ongoing, the Court will not initiate proceedings. This principle applies regardless of the outcome of national proceedings. Even if an investigation is closed without any criminal charges being filed or if an accused person is acquitted by a national court, the Court will not prosecute an individual for the crime in question so long as it is satisfied that the national proceedings were legitimate. However, the actual application of the complementarity principle has recently come under theoretical scrutiny.\n\nThe Court will only initiate proceedings if a crime is of \"sufficient gravity to justify further action by the Court\".\n\nThe Prosecutor will initiate an investigation unless there are \"substantial reasons to believe that an investigation would not serve the interests of justice\" when \"[t]aking into account the gravity of the crime and the interests of victims\". Furthermore, even if an investigation has been initiated and there are substantial facts to warrant a prosecution and no other admissibility issues, the Prosecutor must determine whether a prosecution would serve the interests of justice \"taking into account all the circumstances, including the gravity of the crime, the interests of victims and the age or infirmity of the alleged perpetrator, and his or her role in the alleged crime\".\n\nTrials are conducted under a hybrid common law and civil law judicial system, but it has been argued the procedural orientation and character of the court is still evolving. A majority of the three judges present, as triers of fact, may reach a decision, which must include a full and reasoned statement. Trials are supposed to be public, but proceedings are often closed, and such exceptions to a public trial have not been enumerated in detail. \"In camera\" proceedings are allowed for protection of witnesses or defendants as well as for confidential or sensitive evidence. Hearsay and other indirect evidence is not generally prohibited, but it has been argued the court is guided by hearsay exceptions which are prominent in common law systems. There is no subpoena or other means to compel witnesses to come before the court, although the court has some power to compel testimony of those who chose to come before it, such as fines.\n\nThe Rome Statute provides that all persons are presumed innocent until proven guilty beyond reasonable doubt, and establishes certain rights of the accused and persons during investigations. These include the right to be fully informed of the charges against him or her; the right to have a lawyer appointed, free of charge; the right to a speedy trial; and the right to examine the witnesses against him or her.\n\nTo ensure \"equality of arms\" between defence and prosecution teams, the ICC has established an independent Office of Public Counsel for the Defence (OPCD) to provide logistical support, advice and information to defendants and their counsel. The OPCD also helps to safeguard the rights of the accused during the initial stages of an investigation. However, Thomas Lubanga's defence team say they were given a smaller budget than the Prosecutor and that evidence and witness statements were slow to arrive.\n\nOne of the great innovations of the Statute of the International Criminal Court and its Rules of Procedure and Evidence is the series of rights granted to victims. For the first time in the history of international criminal justice, victims have the possibility under the Statute to present their views and observations before the Court.\n\nParticipation before the Court may occur at various stages of proceedings and may take different forms, although it will be up to the judges to give directions as to the timing and manner of participation.\n\nParticipation in the Court's proceedings will in most cases take place through a legal representative and will be conducted \"in a manner which is not prejudicial or inconsistent with the rights of the accused and a fair and impartial trial\".\n\nThe victim-based provisions within the Rome Statute provide victims with the opportunity to have their voices heard and to obtain, where appropriate, some form of reparation for their suffering. It is the aim of this attempted balance between retributive and restorative justice that, it is hoped, will enable the ICC to not only bring criminals to justice but also help the victims themselves obtain some form of justice. Justice for victims before the ICC comprises both procedural and substantive justice, by allowing them to participate and present their views and interests, so that they can help to shape truth, justice and reparations outcomes of the Court.\n\nArticle 43(6) establishes a Victims and Witnesses Unit to provide \"protective measures and security arrangements, counseling and other appropriate assistance for witnesses, victims who appear before the Court, and others who are at risk on account of testimony given by such witnesses.\" Article 68 sets out procedures for the \"Protection of the victims and witnesses and their participation in the proceedings.\" The Court has also established an Office of Public Counsel for Victims, to provide support and assistance to victims and their legal representatives.\n\nThe ICC does not have its own witness protection program, but rather must rely on national programs to keep witnesses safe.\n\nVictims before the International Criminal Court can also claim reparations under Article 75 of the Rome Statute. Reparations can only be claimed when a defendant is convicted and at the discretion of the Court's judges. So far the Court has ordered reparations against Thomas Lubanga. Reparations can include compensation, restitution and rehabilitation, but other forms of reparations may be appropriate for individual, collective or community victims. Article 79 of the Rome Statute establishes a Trust Fund to provide assistance before a reparation order to victims in a situation or to support reparations to victims and their families if the convicted person has no money.\n\nOne of the principles of international law is that a treaty does not create either obligations or rights for third states without their consent, and this is also enshrined in the 1969 Vienna Convention on the Law of Treaties. The co-operation of the non-party states with the ICC is envisioned by the Rome Statute of the International Criminal Court to be of voluntary nature. However, even states that have not acceded to the Rome Statute might still be subjects to an obligation to co-operate with ICC in certain cases. When a case is referred to the ICC by the UN Security Council all UN member states are obliged to co-operate, since its decisions are binding for all of them. Also, there is an obligation to respect and ensure respect for international humanitarian law, which stems from the Geneva Conventions and Additional Protocol I, which reflects the absolute nature of international humanitarian law. Although the wording of the Conventions might not be precise as to what steps have to be taken, it has been argued that it at least requires non-party states to make an effort not to block actions of ICC in response to serious violations of those Conventions.\n\nIn relation to co-operation in investigation and evidence gathering, it is implied from the Rome Statute that the consent of a non-party state is a prerequisite for ICC Prosecutor to conduct an investigation within its territory, and it seems that it is even more necessary for him to observe any reasonable conditions raised by that state, since such restrictions exist for states party to the Statute. Taking into account the experience of the International Criminal Tribunal for the former Yugoslavia (which worked with the principle of the primacy, instead of complementarity) in relation to co-operation, some scholars have expressed their pessimism as to the possibility of ICC to obtain co-operation of non-party states. As for the actions that ICC can take towards non-party states that do not co-operate, the Rome Statute stipulates that the Court may inform the Assembly of States Parties or Security Council, when the matter was referred by it, when non-party state refuses to co-operate after it has entered into an \"ad hoc\" arrangement or an agreement with the Court.\n\nIt is unclear to what extent the ICC is compatible with reconciliation processes that grant amnesty to human rights abusers as part of agreements to end conflict. Article 16 of the Rome Statute allows the Security Council to prevent the Court from investigating or prosecuting a case, and Article 53 allows the Prosecutor the discretion not to initiate an investigation if he or she believes that \"an investigation would not serve the interests of justice\". Former ICC president Philippe Kirsch has said that \"some limited amnesties may be compatible\" with a country's obligations genuinely to investigate or prosecute under the Statute.\n\nIt is sometimes argued that amnesties are necessary to allow the peaceful transfer of power from abusive regimes. By denying states the right to offer amnesty to human rights abusers, the International Criminal Court may make it more difficult to negotiate an end to conflict and a transition to democracy. For example, the outstanding arrest warrants for four leaders of the Lord's Resistance Army are regarded by some as an obstacle to ending the insurgency in Uganda. Czech politician Marek Benda argues that \"the ICC as a deterrent will in our view only mean the worst dictators will try to retain power at all costs\". However, the United Nations and the International Committee of the Red Cross maintain that granting amnesty to those accused of war crimes and other serious crimes is a violation of international law.\n\nThe official seat of the Court is in The Hague, Netherlands, but its proceedings may take place anywhere.\n\nThe Court moved into its first permanent premises in The Hague, located at Oude Waalsdorperweg 10, on 14 December 2015. Part of The Hague's International Zone, which also contains the Peace Palace, Europol, Eurojust, ICTY, OPCW and The Hague World Forum, the court facilities are situated on the site of the \"Alexanderkazerne\", a former military barracks, adjacent to the dune landscape on the northern edge of the city. The ICC's detention centre is a short distance away.\n\nThe land and financing for the new construction were provided by the Netherlands. In addition, the host state organised and financed the architectural design competition which started at the end of 2008.\n\nThree architects were chosen by an international jury from a total of 171 applicants to enter into further negotiations. The Danish firm schmidt hammer lassen were ultimately selected to design the new premises since its design met all the ICC criteria, such as design quality, sustainability, functionality and costs.\n\nDemolition of the barracks started in November 2011 and was completed in August 2012. In October 2012 the tendering procedure for the General Contractor was completed and the combination Visser & Smit Bouw and Boele & van Eesteren (“Courtys”) was selected.\n\nThe building has a compact footprint and consists of six connected building volumes with a garden motif. The tallest volume with a green facade, placed in the middle of the design, is the Court Tower that accommodates 3 courtrooms. The rest of the building's volumes accommodate the offices of the different organs of the ICC.\n\nUntil late 2015, the ICC was housed in interim premises in The Hague provided by the Netherlands. Formerly belonging to KPN, the provisional headquarters were located at Maanweg 174 in the east-central portion of the city.\n\nThe ICC's detention centre accommodates both those convicted by the court and serving sentences as well as those suspects detained pending the outcome of their trial. It comprises twelve cells on the premises of the Scheveningen branch of the Haaglanden Penal Institution, The Hague, close to the ICC's new headquarters in the Alexanderkazerne. Suspects held by the International Criminal Tribunal for the former Yugoslavia are held in the same prison and share some facilities, like the fitness room, but have no contact with suspects held by the ICC.\n\nThe ICC maintains a liaison office in New York and field offices in places where it conducts its activities. As of 18 October 2007, the Court had field offices in Kampala, Kinshasa, Bunia, Abéché and Bangui.\n\nThe ICC is financed by contributions from the states parties. The amount payable by each state party is determined using the same method as the United Nations: each state's contribution is based on the country's capacity to pay, which reflects factors such as a national income and population. The maximum amount a single country can pay in any year is limited to 22% of the Court's budget; Japan paid this amount in 2008.\n\nThe Court spent €80.5 million in 2007. The Assembly of States Parties approved a budget of €90.4 million for 2008, €101.2 million for 2009, and €141.6 million for 2017. , the ICC’s staff consisted of 800 persons from approximately 100 states.\n\nTo date, the Prosecutor has \n\nThe Court's Pre-Trial Chambers have \n\nThe \"Lubanga\" and \"Katanga-Chui\" trials in the situation of the DR Congo are concluded. Mr Lubanga and Mr Katanga were convicted and sentenced to 14 and 12 years imprisonment, respectively, whereas Mr Chui was acquitted.\n\nThe \"Bemba\" trial in the Central African Republic situation is concluded. Mr Bemba was convicted on two counts of crimes against humanity and three counts of war crimes. This marked the first time the ICC convicted someone of sexual violence as they added rape to his conviction.\n\nTrials in the \"Ntaganda\" case (DR Congo), the \"Bemba et al.\" case and the \"Laurent Gbagbo-Blé Goudé\" trial in the Côte d'Ivoire situation are ongoing. The \"Banda\" trial in the situation of Darfur, Sudan, was scheduled to begin in 2014 but the start date was vacated. Charges against Dominic Ongwen in the Uganda situation and Ahmed al-Faqi in the Mali situation have been confirmed; both are awaiting their trials.\n\nCurrently, the Office of the Prosecutor has \n\nNotes\n\nUnlike the International Court of Justice, the ICC is legally independent from the United Nations. However, the Rome Statute grants certain powers to the United Nations Security Council, which limits its functional independence. Article 13 allows the Security Council to refer to the Court situations that would not otherwise fall under the Court's jurisdiction (as it did in relation to the situations in Darfur and Libya, which the Court could not otherwise have prosecuted as neither Sudan nor Libya are state parties). Article 16 allows the Security Council to require the Court to defer from investigating a case for a period of 12 months. Such a deferral may be renewed indefinitely by the Security Council. This sort of an arrangement gives the ICC some of the advantages inhering in the organs of the United Nations such as using the enforcement powers of the Security Council, but it also creates a risk of being tainted with the political controversies of the Security Council.\n\nThe Court cooperates with the UN in many different areas, including the exchange of information and logistical support. The Court reports to the UN each year on its activities, and some meetings of the Assembly of States Parties are held at UN facilities. The relationship between the Court and the UN is governed by a \"Relationship Agreement between the International Criminal Court and the United Nations\".\n\nDuring the 1970s and 1980s, international human rights and humanitarian Nongovernmental Organizations (or NGOs) began to proliferate at exponential rates. Concurrently, the quest to find a way to punish international crimes shifted from being the exclusive responsibility of legal experts to being shared with international human rights activism.\n\nNGOs helped birth the ICC through advocacy and championing for the prosecution of perpetrators of crimes against humanity. NGOs closely monitor the organization's declarations and actions, ensuring that the work that is being executed on behalf of the ICC is fulfilling its objectives and responsibilities to civil society. According to Benjamin Schiff, \"From the Statute Conference onward, the relationship between the ICC and the NGOs has probably been closer, more consistent, and more vital to the Court than have analogous relations between NGOs and any other international organization.\"\n\nThere are a number of NGOs working on a variety of issues related to the ICC. The NGO Coalition for the International Criminal Court has served as a sort of umbrella for NGOs to coordinate with each other on similar objectives related to the ICC. The CICC has 2,500 member organizations in 150 different countries. The original steering committee included representatives from the World Federalist Movement, the International Commission of Jurists, Amnesty International, the Lawyers Committee for Human Rights, Human Rights Watch, Parliamentarians for Global Action, and No Peace Without Justice. Today, many of the NGOs with which the ICC cooperates are members of the CICC. These organizations come from a range of backgrounds, spanning from major international NGOs such as Human Rights Watch and Amnesty International, to smaller, more local organizations focused on peace and justice missions. Many work closely with states, such as the International Criminal Law Network, founded and predominantly funded by the Hague municipality and the Dutch Ministries of Defense and Foreign Affairs. The CICC also claims organizations that are themselves federations, such as the International Federation of Human Rights Leagues (FIDH).\n\nCICC members ascribe to three principles that permit them to work under the umbrella of the CICC, so long as their objectives match them:\n\nThe NGOs that work under the CICC do not normally pursue agendas exclusive to the work of the Court, rather they may work for broader causes, such as general human rights issues, victims' rights, gender rights, rule of law, conflict mediation, and peace. The CICC coordinates their efforts to improve the efficiency of NGOs' contributions to the Court and to pool their influence on major common issues. From the ICC side, it has been useful to have the CICC channel NGO contacts with the Court so that its officials do not have to interact individually with thousands of separate organizations.\n\nNGOs have been crucial to the evolution of the ICC, as they assisted in the creation of the normative climate that urged states to seriously consider the Court's formation. Their legal experts helped shape the Statute, while their lobbying efforts built support for it. They advocate Statute ratification globally and work at expert and political levels within member states for passage of necessary domestic legislation. NGOs are greatly represented at meetings for the Assembly of States Parties, and they use the ASP meetings to press for decisions promoting their priorities. Many of these NGOs have reasonable access to important officials at the ICC because of their involvement during the Statute process. They are engaged in monitoring, commenting upon, and assisting in the ICC's activities.\n\nThe ICC often depends on NGOs to interact with local populations. The Registry Public Information Office personnel and Victims Participation and Reparations Section officials hold seminars for local leaders, professionals and the media to spread the word about the Court. These are the kinds of events that are often hosted or organized by local NGOs. Because there can be challenges with determining which of these NGOs are legitimate, CICC regional representatives often have the ability to help screen and identify trustworthy organizations.\n\nHowever, NGOs are also \"sources of criticism, exhortation and pressure upon\" the ICC. The ICC heavily depends on NGOs for its operations. Although NGOs and states cannot directly impact the judicial nucleus of the organization, they can impart information on crimes, can help locate victims and witnesses, and can promote and organize victim participation. NGOs outwardly comment on the Court's operations, \"push for expansion of its activities especially in the new justice areas of outreach in conflict areas, in victims' participation and reparations, and in upholding due-process standards and defense 'equality of arms' and so implicitly set an agenda for the future evolution of the ICC.\" The relatively uninterrupted progression of NGO involvement with the ICC may mean that NGOs have become repositories of more institutional historical knowledge about the ICC than its national representatives, and have greater expertise than some of the organization's employees themselves. While NGOs look to mold the ICC to satisfy the interests and priorities that they have worked for since the early 1990s, they unavoidably press against the limits imposed upon the ICC by the states that are members of the organization. NGOs can pursue their own mandates, irrespective of whether they are compatible with those of other NGOs, while the ICC must respond to the complexities of its own mandate as well as those of the states and NGOs.\n\nAnother issue has been that NGOs possess \"exaggerated senses of their ownership over the organization and, having been vital to and successful in promoting the Court, were not managing to redefine their roles to permit the Court its necessary independence.\" Additionally, because there does exist such a gap between the large human rights organizations and the smaller peace-oriented organizations, it is difficult for ICC officials to manage and gratify all of their NGOs. \"ICC officials recognize that the NGOs pursue their own agendas, and that they will seek to pressure the ICC in the direction of their own priorities rather than necessarily understanding or being fully sympathetic to the myriad constraints and pressures under which the Court operates.\" Both the ICC and the NGO community avoid criticizing each other publicly or vehemently, although NGOs have released advisory and cautionary messages regarding the ICC. They avoid taking stances that could potentially give the Court's adversaries, particularly the US, more motive to berate the organization.\n\nThe ICC has been accused of bias and as being a tool of Western imperialism, only punishing leaders from small, weak states while ignoring crimes committed by richer and more powerful states. This sentiment has been expressed particularly by African leaders due to an alleged disproportionate focus of the Court on Africa, while it claims to have a global mandate; until January 2016, all nine situations which the ICC had been investigating were in African countries.\n\nThe prosecution of Kenyan Deputy President William Ruto and President Uhuru Kenyatta (both charged before coming into office) led to the Kenyan parliament passing a motion calling for Kenya's withdrawal from the ICC, and the country called on the other 33 African states party to the ICC to withdraw their support, an issue which was discussed at a special African Union (AU) summit in October 2013.\n\nThough the ICC has denied the charge of disproportionately targeting African leaders, and claims to stand up for victims wherever they may be, Kenya was not alone in criticising the ICC. Sudanese President Omar al-Bashir visited Kenya, South Africa, China, Nigeria, Saudi Arabia, United Arab Emirates, Egypt, Ethiopia, Qatar and several other countries despite an outstanding ICC warrant for his arrest but was not arrested; he said that the charges against him are \"exaggerated\" and that the ICC was a part of a \"Western plot\" against him. Ivory Coast’s government opted not to transfer former first lady Simone Gbagbo to the court but to instead try her at home. Rwanda’s ambassador to the African Union, Joseph Nsengimana, argued that \"It is not only the case of Kenya. We have seen international justice become more and more a political matter.\" Ugandan President Yoweri Museveni accused the ICC of \"mishandling complex African issues.\" Ethiopian Prime Minister Hailemariam Desalegn, at the time AU chairman, told the UN General Assembly at the General debate of the sixty-eighth session of the United Nations General Assembly: \"The manner in which the ICC has been operating has left a very bad impression in Africa. It is totally unacceptable.\"\n\nSouth African President Jacob Zuma said the perceptions of the ICC as \"unreasonable\" led to the calling of the special AU summit on 13 October 2015. Botswana is a notable supporter of the ICC in Africa. At the summit, the AU did not endorse the proposal for a mass withdrawal from the ICC due to lack of support for the idea. However, the summit did conclude that serving heads of state should not be put on trial and that the Kenyan cases should be deferred. Ethiopian Foreign Minister Tedros Adhanom said: \"We have rejected the double standard that the ICC is applying in dispensing international justice.\" Despite these calls, the ICC went ahead with requiring William Ruto to attend his trial. The UNSC was then asked to consider deferring the trials of Kenyatta and Ruto for a year, but this was rejected. In November, the ICC's Assembly of State Parties responded to Kenya's calls for an exemption for sitting heads of state by agreeing to consider amendments to the Rome Statute to address the concerns.\n\nOn 7 October 2016, Burundi announced that it would leave the ICC, after the court began investigating political violence in that nation. In the subsequent two weeks, South Africa and Gambia also announced their intention to leave the court, with Kenya and Namibia reportedly also considering departure. All three nations cited the fact that all 39 people indicted by the court over its history have been African and that the court has made no effort to investigate war crimes tied to the 2003 invasion of Iraq. However, following Gambia's presidential election later that year, which ended the long rule of Yahya Jammeh, Gambia rescinded its withdrawal notification. The High Court of South Africa ruled on 2 February 2017 that the South African government's notice to withdraw was unconstitutional and invalid. On 7 March 2017 the South African government formally revoked its intention to withdraw; however, the ruling ANC revealed on 5 July 2017 that its intention to withdraw stands.\n\nThe United States Department of State argues that there are \"insufficient checks and balances on the authority of the ICC prosecutor and judges\" and \"insufficient protection against politicized prosecutions or other abuses\". The current law in the United States on the ICC is the American Service-Members' Protection Act (ASPA), 116 Stat. 820, The ASPA authorizes the President of the United States to use \"all means necessary and appropriate to bring about the release of any U.S. or allied personnel being detained or imprisoned by, on behalf of, or at the request of the International Criminal Court.\" This authorization has led the act to be nicknamed the \"Hague Invasion Act\", because the freeing of U.S. citizens by force might be possible only through military action.\n\nOn September 10, 2018, John R. Bolton, in his first major address as U.S. National Security Advisor, reiterated that the ICC lacks checks and balances, exercises \"jurisdiction over crimes that have disputed and ambiguous definitions,\" and has failed to \"deter and punish atrocity crimes.\" The ICC, said Bolton, is \"superfluous\" given that \"domestic judicial systems already hold American citizens to the highest legal and ethical standards.\" He added that the U.S. would do everything \"to protect our citizens\" should the ICC attempt to prosecute U.S. servicemen over alleged detainee abuse in Afghanistan. In that event, ICC judges and prosecutors would be barred from entering the U.S., their funds in the U.S. would be sanctioned and the U.S. \"will prosecute them in the US criminal system. We will do the same for any company or state that assists an ICC investigation of Americans\", Bolton said. He also criticized Palestinian efforts to bring Israel before the ICC over allegations of human rights abuses in the occupied West Bank and Gaza.\n\nICC responded that it will continue to investigate war crimes undeterred.\n\nConcerning the independent Office of Public Counsel for the Defence (OPCD), Thomas Lubanga's defence team say they were given a smaller budget than the Prosecutor and that evidence and witness statements were slow to arrive.\n\nLimitations exist for the ICC. Human Rights Watch (HRW) reported that the ICC's prosecutor team takes no account of the roles played by the government in the conflict of Uganda, Rwanda or Congo. This led to a flawed investigation, because the ICC did not reach the conclusion of its verdict after considering the governments' position and actions in the conflict.\n\nResearch suggests that prosecutions of leaders in the ICC makes dictators less likely to peacefully step down. It is also argued that justice is a means to peace: \"As a result, the ICC has been used as a means\nof intervention in ongoing conflicts with the expectation that the indictments, arrests, and\ntrials of elite perpetrators have deterrence and preventive effects for atrocity crimes.\nDespite these legitimate intentions and great expectations, there is little evidence of the\nefficacy of justice as a means to peace\".\n\nThat the ICC cannot mount successful cases without state cooperation is problematic for several reasons. It means that the ICC acts inconsistently in its selection of cases, is prevented from taking on hard cases and loses legitimacy. It also gives the ICC less deterrent value, as potential perpetrators of war crimes know that they can avoid ICC judgment by taking over government and refusing to cooperate.\n\nThe fundamental principle of complementarity of the ICC Rome Statute is often taken for granted in the legal analysis of international criminal law and its jurisprudence. Initially the thorny issue of the actual application of the complementarity principle arose in 2008, when William Schabas published his monumental paper. However, despite Schabas' theoretical impact, no substantive research was made by other scholars on this issue for quite some time. In June 2017, Victor Tsilonis advanced the same criticism which is reinforced by events, practices of the Office of the Prosecutor and ICC cases in the Essays in Honour of Nestor Courakis. His paper essentially argues that the Αl‐Senussi case arguably is the first instance of the complementarity principle's actual implementation eleven whole years after the ratification of the Rome Statute of the International Criminal Court.\n\nOn the other hand, the Chief Prosecutor, Fatou Bensouda, has invoked recently the principle of complementarity in the situation between Russia and Georgia in\nOssetia region. Moreover, following the threats of certain African states (initially Burundi, Gambia and South Africa) to withdraw their ratifications, Bensouda again referred to the principle of complementarity as a core principle of ICC’s jurisdiction and has more extensively focused on the principle’s application on the latest Office of The Prosecutor’s Report on Preliminary Examination Activities 2016.\n\n\n"}
{"id": "14881", "url": "https://en.wikipedia.org/wiki?curid=14881", "title": "ICC", "text": "ICC\n\nICC may refer to:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "14882", "url": "https://en.wikipedia.org/wiki?curid=14882", "title": "Incubus (disambiguation)", "text": "Incubus (disambiguation)\n\nAn incubus is a male demon that has sexual intercourse with sleeping women.\n\nIncubus may also refer to:\n\n\n\n\n"}
{"id": "14883", "url": "https://en.wikipedia.org/wiki?curid=14883", "title": "Iberian Peninsula", "text": "Iberian Peninsula\n\nThe Iberian Peninsula , also known as Iberia, is located in the southwest corner of Europe. The peninsula is principally divided between Spain and Portugal, comprising most of their territory. It also includes Andorra, small areas of France, and the British overseas territory of Gibraltar. With an area of approximately ), it is the second largest European peninsula, after the Scandinavian.\n\nThe word \"Iberia\" is a noun adapted from the Latin word \"Hiberia\" originated by the Ancient Greek word Ἰβηρία (\"\") by Greek geographers under the rule of the Roman Empire to refer to what is known today in English as the Iberian Peninsula. At that time, the name did not describe a single political entity or a distinct population of people. Strabo's 'Iberia' was delineated from Keltikē (Gaul) by the Pyrenees and included the entire land mass southwest (he says \"west\") of there. With the fall of the Roman Empire and the establishment of the new Castillian language in Spain, the word \"Iberia\" appeared for the first time in use as a direct 'descendant' of the Greek word \"Ἰβηρία\" and the Roman word \"Hiberia\". \n\nThe ancient Greeks reached the Iberian Peninsula, of which they had heard from the Phoenicians, by voyaging westward on the Mediterranean. Hecataeus of Miletus was the first known to use the term \"Iberia\", which he wrote about circa 500 BC. Herodotus of Halicarnassus says of the Phocaeans that \"it was they who made the Greeks acquainted with... Iberia.\" According to Strabo, prior historians used \"Iberia\" to mean the country \"this side of the Ἶβηρος (\"\")\" as far north as the river Rhône in France, but currently they set the Pyrenees as the limit. Polybius respects that limit, but identifies Iberia as the Mediterranean side as far south as Gibraltar, with the Atlantic side having no name. Elsewhere he says that Saguntum is \"on the seaward foot of the range of hills connecting Iberia and Celtiberia.\"\n\nStrabo refers to the Carretanians as people \"of the Iberian stock\" living in the Pyrenees, who are distinct from either Celts or Celtiberians.\n\nAccording to Charles Ebel, the ancient sources in both Latin and Greek use Hispania and Hiberia (Greek: Iberia) as synonyms. The confusion of the words was because of an overlapping in political and geographic perspectives. The Latin word \"Hiberia\", similar to the Greek \"Iberia\", literally translates to \"land of the Hiberians\". This word was derived from the river Ebro, which the Romans called \"Hiberus\". \"Hiber\" (Iberian) was thus used as a term for peoples living near the river Ebro. The first mention in Roman literature was by the annalist poet Ennius in 200 BC. Virgil refers to the \"Ipacatos Hiberos\" (\"restless Iberi\") in his Georgics. The Roman geographers and other prose writers from the time of the late Roman Republic called the entire peninsula \"Hispania\".\n\nAs they became politically interested in the former Carthaginian territories, the Romans began to use the names \"Hispania Citerior\" and \"Hispania Ulterior\" for 'near' and 'far' Hispania. At the time Hispania was made up of three Roman provinces: Hispania Baetica, Hispania Tarraconensis, and Hispania Lusitania. Strabo says that the Romans use \"Hispania\" and \"Iberia\" synonymously, distinguishing between the \"near\" northern and the \"far\" southern provinces. (The name \"Iberia\" was ambiguous, being also the name of the Kingdom of Iberia in the Caucasus.)\n\nWhatever language may generally have been spoken on the peninsula soon gave way to Latin, except for that of the Vascones, which was preserved as a language isolate by the barrier of the Pyrenees.\n\nThe Iberian Peninsula has always been associated with the Ebro, Ibēros in ancient Greek and Ibērus or Hibērus in Latin. The association was so well known it was hardly necessary to state; for example, Ibēria was the country \"this side of the Ibērus\" in Strabo. Pliny goes so far as to assert that the Greeks had called \"the whole of Spain\" Hiberia because of the Hiberus River. The river appears in the Ebro Treaty of 226 BC between Rome and Carthage, setting the limit of Carthaginian interest at the Ebro. The fullest description of the treaty, stated in Appian, uses Ibērus. With reference to this border, Polybius states that the \"native name\" is \"Ibēr\", apparently the original word, stripped of its Greek or Latin \"-os\" or \"-us\" termination.\n\nThe early range of these natives, which geographers and historians place from today's southern Spain to today's southern France along the Mediterranean coast, is marked by instances of a readable script expressing a yet unknown language, dubbed \"Iberian.\" Whether this was the native name or was given to them by the Greeks for their residence on the Ebro remains unknown. Credence in Polybius imposes certain limitations on etymologizing: if the language remains unknown, the meanings of the words, including Iber, must also remain unknown. In modern Basque, the word \"ibar\" means \"valley\" or \"watered meadow\", while \"ibai\" means \"river\", but there is no proof relating the etymology of the Ebro River with these Basque names.\n\nThe Iberian Peninsula has been inhabited for at least 1.2 million years as remains found in the sites in the Atapuerca Mountains demonstrate. Among these sites is the cave of Gran Dolina, where six hominin skeletons, dated between 780,000 and one million years ago, were found in 1994. Experts have debated whether these skeletons belong to the species \"Homo erectus\", \"Homo heidelbergensis\", or a new species called \"Homo antecessor\".\n\nAround 200,000 BP, during the Lower Paleolithic period, Neanderthals first entered the Iberian Peninsula. Around 70,000 BP, during the Middle Paleolithic period, the last glacial event began and the Neanderthal Mousterian culture was established. Around 37,000 BP, during the Upper Paleolithic, the Neanderthal Châtelperronian cultural period began. Emanating from Southern France, this culture extended into the north of the peninsula. It continued to exist until around 30,000 BP, when Neanderthal man faced extinction.\n\nAbout 40,000 years ago, anatomically modern humans entered the Iberian Peninsula from Southern France. Here, this genetically homogeneous population (characterized by the M173 mutation in the Y chromosome), developed the M343 mutation, giving rise to Haplogroup R1b, still the most common in modern Portuguese and Spanish males. On the Iberian Peninsula, modern humans developed a series of different cultures, such as the Aurignacian, Gravettian, Solutrean and Magdalenian cultures, some of them characterized by the complex forms of the art of the Upper Paleolithic.\n\nDuring the Neolithic expansion, various megalithic cultures developed in the Iberian Peninsula. An open seas navigation culture from the east Mediterranean, called the Cardium culture, also extended its influence to the eastern coasts of the peninsula, possibly as early as the 5th millennium BC. These people may have had some relation to the subsequent development of the Iberian civilization.\n\nIn the Chalcolithic (c. 3000 BC), a series of complex cultures developed that would give rise to the peninsula's first civilizations and to extensive exchange networks reaching to the Baltic, Middle East and North Africa. Around 2800 – 2700 BC, the Beaker culture, which produced the \"Maritime Bell Beaker\", probably originated in the vibrant copper-using communities of the Tagus estuary in Portugal and spread from there to many parts of western Europe.\n\nBronze Age cultures developed beginning c.1800 BC, when the civilization of Los Millares was followed by that of El Argar. From this centre, bronze technology spread to other cultures like the Bronze of Levante, South-Western Iberian Bronze and Las Cogotas.\n\nIn the Late Bronze Age, the urban civilisation of Tartessos developed in the area of modern western Andalusia, characterized by Phoenician influence and using the Southwest Paleohispanic script for its Tartessian language, not related to the Iberian language.\n\nEarly in the first millennium BC, several waves of Pre-Celts and Celts migrated from Central Europe, thus partially changing the peninsula's ethnic landscape to Indo-European-speaking in its northern and western regions. In Northwestern Iberia (modern Northern Portugal, Asturias and Galicia), a Celtic culture developed, the Castro culture, with a large number of hill forts and some fortified cities.\n\nBy the Iron Age, starting in the 7th century BC, the Iberian Peninsula consisted of complex agrarian and urban civilizations, either Pre-Celtic or Celtic (such as the Lusitanians, Celtiberians, Gallaeci, Astures, Celtici and others), the cultures of the Iberians in the eastern and southern zones and the cultures of the Aquitanian in the western portion of the Pyrenees.\n\nThe seafaring Phoenicians, Greeks and Carthaginians successively settled along the Mediterranean coast and founded trading colonies there over a period of several centuries. Around 1100 BC, Phoenician merchants founded the trading colony of Gadir or Gades (modern day Cádiz) near Tartessos. In the 8th century BC, the first Greek colonies, such as Emporion (modern Empúries), were founded along the Mediterranean coast on the east, leaving the south coast to the Phoenicians. The Greeks coined the name Iberia, after the river Iber (Ebro). In the sixth century BC, the Carthaginians arrived in the peninsula while struggling with the Greeks for control of the Western Mediterranean. Their most important colony was Carthago Nova (modern-day Cartagena, Spain).\n\nIn 218 BC, during the Second Punic War against the Carthaginians, the first Roman troops invaded the Iberian Peninsula; however, it was not until the reign of Augustus that it was annexed after 200 years of war with the Celts and Iberians. The result was the creation of the province of Hispania. It was divided into Hispania Ulterior and Hispania Citerior during the late Roman Republic, and during the Roman Empire, it was divided into Hispania Tarraconensis in the northeast, Hispania Baetica in the south and Lusitania in the southwest.\n\nHispania supplied the Roman Empire with silver, food, olive oil, wine, and metal. The emperors Trajan, Hadrian, Marcus Aurelius, and Theodosius I, the philosopher Seneca the Younger, and the poets Martial and Lucan were born from families living on the Iberian Peninsula.\n\nDuring their 600-year rule in the Iberian Peninsula, the Romans introduced the Latin language that influenced many of the languages that exist today in the Iberian peninsula.\n\nIn the early fifth century, Germanic peoples invaded the peninsula, namely the Suebi, the Vandals (Silingi and Hasdingi) and their allies, the Alans. Only the kingdom of the Suebi (Quadi and Marcomanni) would endure after the arrival of another wave of Germanic invaders, the Visigoths, who conquered all of the Iberian Peninsula and expelled or partially integrated the Vandals and the Alans. The Visigoths eventually conquered the Suebi kingdom and its capital city, Bracara (modern day Braga), in 584–585. They would also conquer the province of the Byzantine Empire (552–624) of Spania in the south of the peninsula and the Balearic Islands.\n\nIn 711, a Muslim army invaded the Visigothic Kingdom in Hispania. Under Tariq ibn Ziyad, the Islamic army landed at Gibraltar and, in an eight-year campaign, occupied all except the northern kingdoms of the Iberian Peninsula in the Umayyad conquest of Hispania. Al-Andalus (, tr. \"al-ʾAndalūs\", possibly \"Land of the Vandals\"), is the Arabic name given to what is today southern Spain by its Muslim Berber and Arab occupiers.\n\nFrom the 8th–15th centuries, only the southern part of the Iberian Peninsula was part of the Islamic world. It became a center of culture and learning, especially during the Caliphate of Córdoba, which reached its height of its power under the rule of Abd-ar-Rahman III and his successor al-Hakam II. The Muslims, who were initially Arabs and Berbers, included some local converts, the so-called Muladi. The Muslims were referred to by the generic name, \"Moors\" The Reconquista gained momentum on c. 718, when the Christian Asturians opposed the Moors.\n\nMany of the ousted Gothic nobles took refuge in the unconquered north Kingdom of Asturias. From there, they aimed to reconquer their lands from the Moors; this war of reconquest is known as the Reconquista. Christian and Muslim kingdoms fought and allied among themselves. The fighting was characterised by raids into Islamic territory with the intent of destroying crops, orchards, and villages, and of killing and enslaving any Muslims they came across. Christian forces were usually better armoured than their Muslim counterparts, with noble and non-noble \"milites\" and \"cavallers\" wearing mail hauberks, separate mail coifs and metal helmets, and armed with maces, cavalry axes, sword and lances.\n\nDuring the Middle Ages, the peninsula housed many small states including the Kingdom of Castile, Kingdom of Aragon, Kingdom of Navarre, Kingdom of León and the Kingdom of Portugal. The Muslims were driven out of Portugal by 1249. By the end of the 13th century, the Spanish Reconquista was largely completed.\n\nThe 14th century was a period of great internal changes in the Spanish kingdoms. After the death of Peter the Cruel of Castile (reigned 1350–69), the House of Trastámara succeeded to the throne in the person of Peter's half brother, Henry II (reigned 1369–79). In the kingdom of Aragón, following the death without heirs of John I (reigned 1387–96) and Martin I (reigned 1396–1410), a prince of the House of Trastámara, Ferdinand I (reigned 1412–16), succeeded to the Aragonese throne.\n\nDuring this period the Jews in Spain became very numerous and acquired great power; they were not only the physicians, but also the treasurers of the kings. Don Jusaph de Ecija administered the revenues of Alfonso XI, and Samuel ha-Levi was chief favourite of Peter the Cruel. The Jews of Toledo then set on foot their migration in protest against the laws of Alfonso X (\"Las Siete Partidas\"), which prohibited the building of new synagogues.\n\nAfter the accession of Henry of Trastámara to the throne, the populace, exasperated by the preponderance of Jewish influence, perpetrated a massacre of Jews at Toledo. In 1391, mobs went from town to town throughout Castile and Aragon, killing an estimated 50,000–100,000 Jews. Women and children were sold as slaves to Muslims, and many synagogues were converted into churches. According to Hasdai Crescas, about 70 Jewish communities were destroyed. \n\nThe last Muslim stronghold, Granada, was conquered by a combined Castilian and Aragonese force in 1492. As many as 100,000 Moors died or were enslaved in the military campaign, while 200,000 fled to North Africa. Muslims and Jews throughout the period were variously tolerated or shown intolerance in different Christian kingdoms. After the fall of Granada, all Muslims and Jews were ordered to convert to Christianity or face expulsion—as many as 200,000 Jews were expelled from Spain. Historian Henry Kamen estimates that some 25,000 Jews died en route from Spain. The Jews were also expelled from Sicily and Sardinia, which were under Aragonese rule, and an estimated 37,000 to 100,000 Jews left.\n\nIn 1497, King Manuel I of Portugal forced all Jews in his kingdom to convert or leave. That same year he expelled all Muslims that were not slaves, and in 1502 the Catholic Monarchs followed suit, imposing the choice of conversion to Christianity or exile and loss of property. Many Jews and Muslims fled to North Africa and the Ottoman Empire, while others publicly converted to Christianity and became known respectively as Marranos (Spanish for pig) and Moriscos (after the old term \"Moors\"). However, many of these continued to practice their religion in secret. The Moriscos revolted several times and were ultimately forcibly expelled from Spain in the early 17th century. From 1609–14, over 300,000 Moriscos were sent on ships to North Africa and other locations, and, of this figure, around 50,000 died resisting the expulsion, and 60,000 died on the journey.\n\nThe small states gradually amalgamated over time. Portugal was the exception, except for a brief period (1580–1640) during which the whole peninsula was united politically under the Iberian Union. After that point, the modern position was reached and the peninsula now consists of the countries of Spain and Portugal (excluding their islands—the Portuguese Azores and Madeira and the Spanish Canary Islands and Balearic Islands; and the Spanish exclaves of Ceuta and Melilla), Andorra, French Cerdagne and Gibraltar.\n\nThe Iberian Peninsula is the westernmost of the three major southern European peninsulas—the Iberian, Italian, and Balkan. It is bordered on the southeast and east by the Mediterranean Sea, and on the north, west, and southwest by the Atlantic Ocean. The Pyrenees mountains are situated along the northeast edge of the peninsula, where it adjoins the rest of Europe. Its southern tip is very close to the northwest coast of Africa, separated from it by the Strait of Gibraltar and the Mediterranean Sea.\n\nThe Iberian Peninsula extends from the southernmost extremity at Punta de Tarifa () to the northernmost extremity at Punta de Estaca de Bares () over a distance between lines of latitude of about based on a degree length of per degree, and from the westernmost extremity at Cabo da Roca () to the easternmost extremity at Cap de Creus () over a distance between lines of longitude at 40° N latitude of about based on an estimated degree length of about for that latitude. The irregular, roughly octagonal shape of the peninsula contained within this spherical quadrangle was compared to an ox-hide by the geographer Strabo.\n\nAbout three quarters of that rough octagon is the Meseta Central, a vast plateau ranging from 610 to 760 m in altitude. It is located approximately in the centre, staggered slightly to the east and tilted slightly toward the west (the conventional centre of the Iberian Peninsula has long been considered Getafe just south of Madrid). It is ringed by mountains and contains the sources of most of the rivers, which find their way through gaps in the mountain barriers on all sides.\n\nThe coastline of the Iberian Peninsula is , on the Mediterranean side and on the Atlantic side. The coast has been inundated over time, with sea levels having risen from a minimum of lower than today at the Last Glacial Maximum (LGM) to its current level at 4,000 years BP. The coastal shelf created by sedimentation during that time remains below the surface; however, it was never very extensive on the Atlantic side, as the continental shelf drops rather steeply into the depths. An estimated length of Atlantic shelf is only wide. At the isobath, on the edge, the shelf drops off to .\n\nThe submarine topography of the coastal waters of the Iberian Peninsula has been studied extensively in the process of drilling for oil. Ultimately, the shelf drops into the Bay of Biscay on the north (an abyss), the Iberian abyssal plain at on the west, and Tagus abyssal plain to the south. In the north, between the continental shelf and the abyss, is an extension called the Galicia Bank, a plateau that also contains the Porto, Vigo, and Vasco da Gama seamounts, which form the Galicia interior basin. The southern border of these features is marked by Nazaré Canyon, which splits the continental shelf and leads directly into the abyss.\n\nThe major rivers flow through the wide valleys between the mountain systems. These are the Ebro, Douro, Tagus, Guadiana and Guadalquivir. All rivers in the Iberian Peninsula are subject to seasonal variations in flow.\n\nThe Tagus is the longest river on the peninsula and, like the Douro, flows westwards with its lower course in Portugal. The Guadiana river bends southwards and forms the border between Spain and Portugal in the last stretch of its course.\n\nThe terrain of the Iberian Peninsula is largely mountainous. The major mountain systems are:\n\nThe Iberian Peninsula contains rocks of every geological period from the Ediacaran to the Recent, and almost every kind of rock is represented. World-class mineral deposits can also be found there. The core of the Iberian Peninsula consists of a Hercynian cratonic block known as the Iberian Massif. On the northeast, this is bounded by the Pyrenean fold belt, and on the southeast it is bounded by the Baetic System. These twofold chains are part of the Alpine belt. To the west, the peninsula is delimited by the continental boundary formed by the magma-poor opening of the Atlantic Ocean. The Hercynian Foldbelt is mostly buried by Mesozoic and Tertiary cover rocks to the east, but nevertheless outcrops through the Sistema Ibérico and the Catalan Mediterranean System.\n\nThe Iberian peninsula has two dominant climate types. One of these is the oceanic climate seen in the Atlantic coastal region resulting in evenly temperatures with relatively cool summers. However, most of Portugal and Spain have a mediterranean climate with various precipitation and temperatures depending on latitude and position versus the sea. There are also more localized semi-arid climates in central Spain, with temperatures resembling a more continental mediterranean climate. In other extreme cases highland alpine climates such as in Sierra Nevada and areas with extremely low precitipation and desert climates or semi-arid climates such as the Almería area, Murcia area and southern Alicante area. In the Spanish interior the hottest temperatures in Europe are found, with Córdoba averaging around in July. The Spanish mediterranean coast usually averages around in summer. In sharp contrast A Coruña at the northern tip of Galicia has a summer daytime high average at just below . This cool and wet summer climate is replicated throughout most of the northern coastline. Winter temperatures are more consistent throughout the peninsula, although frosts are common in the Spanish interior, even though daytime highs are usually above the freezing point. In Portugal, the warmest winters of the country are found in the area of Algarve, very similar to the ones from Huelva in Spain, while most of the Portuguese Atlantic coast has fresh and humid winters, similar to Galicia.\n\nPolitical divisions of the Iberian Peninsula sorted by area:\n\nThe main metropolitan areas of the Iberian Peninsula are Madrid, Barcelona, Lisbon, Valencia, Porto, Seville, Bilbao, Guimarães, Málaga, Braga, Central Asturias (Gijón-Oviedo-Avilés), Alicante-Elche, Murcia and Coimbra.\n\nVarious other notable cities (populations given are for the cities proper not the metro areas or municipalities) are also present on the peninsula, such as: Elche (228,647) (part of the Alicante-Elche-Elda metro area), Oviedo (225,973), Badalona (220,977) and Terrassa (215 678) in Spain; and Braga (192,494), Amadora (175,558), Almada (174,030), Odivelas (144,549) and Coimbra (143,397) in Portugal.\n\nThe woodlands of the Iberian Peninsula are distinct ecosystems. Although the various regions are each characterized by distinct vegetation, there are some similarities across the peninsula.\n\nWhile the borders between these regions are not clearly defined, there is a mutual influence that makes it very hard to establish boundaries and some species find their optimal habitat in the intermediate areas.\n\nThe Iberian Peninsula in an important stopover on the East Atlantic flyway for birds migrating from northern Europe to Africa. For example, curlew sandpipers rest in the region of the Bay of Cádiz.\n\nIn addition to the birds migrating through, some seven million wading birds from the north spend the winter in the estuaries and wetlands of the Iberian Peninsula, mainly at locations on the Atlantic coast. In Galicia are Ría de Arousa (a home of grey plover), Ria de Ortigueira, Ria de Corme and Ria de Laxe. In Portugal, the Aveiro Lagoon hosts \"Recurvirostra avosetta\", the common ringed plover, grey plover and little stint. Ribatejo Province on the Tagus supports \"Recurvirostra arosetta\", grey plover, dunlin, bar-tailed godwit and common redshank. In the Sado Estuary are dunlin, Eurasian curlew, grey plover and common redshank. The Algarve hosts red knot, common greenshank and turnstone. The Guadalquivir Marshes region of Andalusia and the Salinas de Cádiz are especially rich in wintering wading birds: Kentish plover, common ringed plover, sanderling, and black-tailed godwit in addition to the others. And finally, the Ebro delta is home to all the species mentioned above.\n\nWith the sole exception of Basque, which is of unknown origin, all modern Iberian languages descend from Vulgar Latin and belong to the Western Romance languages. Throughout history (and pre-history), many different languages have been spoken in the Iberian Peninsula, contributing to the formation and differentiation of the contemporaneous languages of Iberia; however, most of them have become extinct or fallen into disuse. Basque is the only non-Indo-European surviving language in Iberia and Western Europe.\n\nIn modern times, Spanish (cf. 30 to 40 million speakers), Portuguese (cf. around 10 million speakers), Catalan (cf. around 9 million speakers), Galician (cf. around 3 million speakers) and Basque (cf. around 1 million speakers) are the most widely spoken languages in the Iberian Peninsula. Spanish and Portuguese have expanded beyond Iberia to the rest of world, becoming global languages.\n\nMajor industries include mining, tourism, small farms, and fishing. Because the coast is so long, fishing is popular, especially sardines, tuna and anchovies. Most of the mining occurs in the Pyrenees mountains. Commodities mined include: iron, gold, coal, lead, silver, zinc, and salt.\n\n"}
{"id": "14884", "url": "https://en.wikipedia.org/wiki?curid=14884", "title": "Intermediate value theorem", "text": "Intermediate value theorem\n\nIn mathematical analysis, the intermediate value theorem states that if a continuous function, \"f\", with an interval, [\"a\", \"b\"], as its domain, takes values \"f\"(\"a\") and \"f\"(\"b\") at each end of the interval, then it also takes any value between \"f\"(\"a\") and \"f\"(\"b\") at some point within the interval.\n\nThis has two important corollaries: \n\n\nThis captures an intuitive property of continuous functions: given \"f\" continuous on [1, 2] with the known values \"f\"(1) = 3 and \"f\"(2) = 5. Then the graph of \"y\" = \"f\"(\"x\") must pass through the horizontal line \"y\" = 4 while \"x\" moves from 1 to 2. It represents the idea that the graph of a continuous function on a closed interval can be drawn without lifting your pencil from the paper.\n\nThe intermediate value theorem states the following.\n\nConsider an interval formula_1 in the real numbers formula_2 and a continuous function formula_3. Then,\n\n\n\nRemark: \"Version II\" states that the set of function values has no gap. For any two function values formula_11, even if they are outside the interval between formula_5 and formula_6, all points in the interval formula_14 are also function values,\nA subset of the real numbers with no internal gap is an interval. \"Version I\" is naturally contained in \"Version II\".\n\nThe theorem depends on, and is equivalent to, the completeness of the real numbers. The intermediate value theorem does not apply to the rational numbers ℚ because gaps exist between rational numbers; irrational numbers fill those gaps. For example, the function formula_16 for formula_17 satisfies formula_18 and formula_19. However, there is no rational number formula_20 such that formula_21, because formula_22 is an irrational number.\n\nThe theorem may be proven as a consequence of the completeness property of the real numbers as follows:\n\nWe shall prove the first case, formula_23 be the set of all formula_24 such that formula_25. Then formula_26 is non-empty since formula_27 is an element of formula_26, and formula_26 is bounded above by formula_30. Hence, by completeness, the supremum formula_31 exists. That is, formula_32 is the lowest number that is greater than or equal to every member of formula_26. We claim that formula_8.\n\nFix some formula_35. Since formula_36 is continuous, there is a formula_37 such that formula_38 whenever formula_39. This means that\nfor all formula_41. By the properties of the supremum, there exist formula_42 that is contained in formula_26, so that for that formula_44\nChoose formula_46 that will obviously not be contained in formula_26, so we have\n\nBoth inequalities\nare valid for all formula_35, from which we deduce formula_8 as the only possible value, as stated.\n\nThe intermediate value theorem is an easy consequence of the basic properties of connected sets: the preservation of connectedness under continuous functions and the characterization of connected subsets of ℝ as intervals (\"see below for details\" \"and alternate proof\")\".\" The latter characterization is ultimately a consequence of the least-upper-bound property of the real numbers.\n\nThe intermediate value theorem can also be proved using the methods of non-standard analysis, which places \"intuitive\" arguments involving infinitesimals on a rigorous footing. (\"See the article:\" non-standard calculus.)\n\nFor \"u\" = 0 above, the statement is also known as \"Bolzano's theorem.\" This theorem was first proved by Bernard Bolzano in 1817. Augustin-Louis Cauchy provided a proof in 1821. Both were inspired by the goal of formalizing the analysis of functions and the work of Joseph-Louis Lagrange. The idea that continuous functions possess the intermediate value property has an earlier origin. Simon Stevin proved the intermediate value theorem for polynomials (using a cubic as an example) by providing an algorithm for constructing the decimal expansion of the solution. The algorithm iteratively subdivides the interval into 10 parts, producing an additional decimal digit at each step of the iteration. Before the formal definition of continuity was given, the intermediate value property was given as part of the definition of a continuous function. Proponents include Louis Arbogast, who assumed the functions to have no jumps, satisfy the intermediate value property and have increments whose sizes corresponded to the sizes of the increments of the variable.\nEarlier authors held the result to be intuitively obvious and requiring no proof. The insight of Bolzano and Cauchy was to define a general notion of continuity (in terms of infinitesimals in Cauchy's case and using real inequalities in Bolzano's case), and to provide a proof based on such definitions.\n\nThe intermediate value theorem is closely linked to the topological notion of connectedness and follows from the basic properties of connected sets in metric spaces and connected subsets of ℝ in particular:\n\nIn fact, connectedness is a topological property and (*) generalizes to topological spaces: \"If formula_51 and formula_52 are topological spaces, formula_53 is a continuous map, and formula_51 is a connected space, then formula_62 is connected.\" The preservation of connectedness under continuous maps can be thought of as a generalization of the intermediate value theorem, a property of real valued functions of a real variable, to continuous functions in general spaces.\n\nRecall the first version of the intermediate value theorem, stated previously:\n\nIntermediate value theorem. \"(Version I). Consider a closed interval formula_1 in the real numbers formula_2 and a continuous function formula_3. Then, if formula_66 is a real number such that formula_67, there exists formula_68 such that formula_8.\"\n\nThe intermediate value theorem is an immediate consequence of these two properties of connectedness:\n\nProof: By (**), formula_1 is a connected set. It follows from (*) that the image, formula_9, is also connected. For convenience, assume that formula_72. Then once more invoking (**), formula_73, or formula_8 for some formula_75. Since formula_76, formula_68 must actually hold, and the desired conclusion follows. The same argument applies if formula_78, so we are done.formula_79\n\nThe intermediate value theorem generalizes in a natural way: Suppose that \"X\" is a connected topological space and (\"Y\", <) is a totally ordered set equipped with the order topology, and let \"f\" : \"X\" → \"Y\" be a continuous map. If \"a\" and \"b\" are two points in \"X\" and \"u\" is a point in \"Y\" lying between \"f\"(\"a\") and \"f\"(\"b\") with respect to <, then there exists \"c\" in \"X\" such that \"f\"(\"c\") = \"u\". The original theorem is recovered by noting that ℝ is connected and that its natural topology is the order topology.\n\nThe Brouwer fixed-point theorem is a related theorem that, in one dimension gives a special case of the intermediate value theorem.\n\nA \"Darboux function\" is a real-valued function \"f\" that has the \"intermediate value property\", i.e., that satisfies the conclusion of the intermediate value theorem: for any two values \"a\" and \"b\" in the domain of \"f\", and any \"y\" between \"f\"(\"a\") and \"f\"(\"b\"), there is some \"c\" between \"a\" and \"b\" with \"f\"(\"c\") = \"y\". The intermediate value theorem says that every continuous function is a Darboux function. However, not every Darboux function is continuous; i.e., the converse of the intermediate value theorem is false.\n\nAs an example, take the function \"f\" : [0, ∞) → [−1, 1] defined by \"f\"(\"x\") = sin(1/\"x\") for \"x\" > 0 and f(0) = 0. This function is not continuous at \"x\" = 0 because the limit of \"f\"(\"x\") as \"x\" tends to 0 does not exist; yet the function has the intermediate value property. Another, more complicated example is given by the Conway base 13 function.\n\nHistorically, this intermediate value property has been suggested as a \"definition\" for continuity of real-valued functions; this definition was not adopted.\n\nDarboux's theorem states that all functions that result from the differentiation of some other function on some interval have the intermediate value property (even though they need not be continuous).\n\nThe theorem implies that on any great circle around the world, for the temperature, pressure, elevation, carbon dioxide concentration, if the simplification is taken that this varies continuously, there will always exist two antipodal points that share the same value for that variable.\n\n\"Proof:\" Take \"f\" to be any continuous function on a circle. Draw a line through the center of the circle, intersecting it at two opposite points \"A\" and \"B\". Let \"d\" be defined by the difference \"f\"(\"A\") − \"f\"(\"B\"). If the line is rotated 180 degrees, the value −\"d\" will be obtained instead. Due to the intermediate value theorem there must be some intermediate rotation angle for which \"d\" = 0, and as a consequence \"f\"(\"A\") = \"f\"(\"B\") at this angle.\n\nThis is a special case of a more general result called the Borsuk–Ulam theorem.\n\nAnother generalization for which this holds is for any closed convex n (n > 1) dimensional shape. Specifically, for any continuous function whose domain is the given shape, and any point inside the shape (not necessarily its center), there exist two antipodal points with respect to the given point whose functional value is the same. The proof is identical to the one given above.\n\nThe theorem also underpins the explanation of why rotating a wobbly table will bring it to stability (subject to certain easily met constraints).\n\n\n"}
