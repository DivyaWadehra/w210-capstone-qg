{"id": "8303", "url": "https://en.wikipedia.org/wiki?curid=8303", "title": "Down syndrome", "text": "Down syndrome\n\nDown syndrome (DS or DNS), also known as trisomy 21, is a genetic disorder caused by the presence of all or part of a third copy of chromosome 21. It is typically associated with physical growth delays, mild to moderate intellectual disability, and characteristic facial features. The average IQ of a young adult with Down syndrome is 50, equivalent to the mental ability of an 8- or 9-year-old child, but this can vary widely.\nThe parents of the affected individual are typically genetically normal. The probability increases from less than 0.1% in 20-year-old mothers to 3% in those age 45. The extra chromosome is believed to occur by chance, with no known behavioral activity or environmental factor that changes the probability. Down syndrome can be identified during pregnancy by prenatal screening followed by diagnostic testing or after birth by direct observation and genetic testing. Since the introduction of screening, pregnancies with the diagnosis are often terminated. Regular screening for health problems common in Down syndrome is recommended throughout the person's life.\nThere is no cure for Down syndrome. Education and proper care have been shown to improve quality of life. Some children with Down syndrome are educated in typical school classes, while others require more specialized education. Some individuals with Down syndrome graduate from high school, and a few attend post-secondary education. In adulthood, about 20% in the United States do paid work in some capacity, with many requiring a sheltered work environment. Support in financial and legal matters is often needed. Life expectancy is around 50 to 60 years in the developed world with proper health care.\nDown syndrome is one of the most common chromosome abnormalities in humans. It occurs in about one per 1,000 babies born each year. In 2015, Down syndrome was present in 5.4 million individuals globally and resulted in 27,000 deaths, down from 43,000 deaths in 1990. It is named after John Langdon Down, a British doctor who fully described the syndrome in 1866. Some aspects of the condition were described earlier by Jean-Étienne Dominique Esquirol in 1838 and Édouard Séguin in 1844. In 1959, the genetic cause of Down syndrome, an extra copy of chromosome 21, was discovered.\nThose with Down syndrome nearly always have physical and intellectual disabilities. As adults, their mental abilities are typically similar to those of an 8- or 9-year-old. They also typically have poor immune function and generally reach developmental milestones at a later age. They have an increased risk of a number of other health problems, including congenital heart defect, epilepsy, leukemia, thyroid diseases, and mental disorders.\n\nPeople with Down syndrome may have some or all of these physical characteristics: a small chin, slanted eyes, poor muscle tone, a flat nasal bridge, a single crease of the palm, and a protruding tongue due to a small mouth and relatively large tongue. These airway changes lead to obstructive sleep apnea in around half of those with Down syndrome. Other common features include: a flat and wide face, a short neck, excessive joint flexibility, extra space between big toe and second toe, abnormal patterns on the fingertips and short fingers. Instability of the atlantoaxial joint occurs in about 20% and may lead to spinal cord injury in 1–2%. Hip dislocations may occur without trauma in up to a third of people with Down syndrome.\n\nGrowth in height is slower, resulting in adults who tend to have short stature—the average height for men is 154 cm (5 ft 1 in) and for women is 142 cm (4 ft 8 in). Individuals with Down syndrome are at increased risk for obesity as they age. Growth charts have been developed specifically for children with Down syndrome.\n\nThis syndrome causes about a third of cases of intellectual disability. Many developmental milestones are delayed with the ability to crawl typically occurring around 8 months rather than 5 months and the ability to walk independently typically occurring around 21 months rather than 14 months.\n\nMost individuals with Down syndrome have mild (IQ: 50–69) or moderate (IQ: 35–50) intellectual disability with some cases having severe (IQ: 20–35) difficulties. Those with mosaic Down syndrome typically have IQ scores 10–30 points higher. As they age, people with Down syndrome typically perform worse than their same-age peers.\n\nCommonly, individuals with Down syndrome have better language understanding than ability to speak. Between 10 and 45% have either a stutter or rapid and irregular speech, making it difficult to understand them. Some after 30 years of age may lose their ability to speak.\n\nThey typically do fairly well with social skills. Behavior problems are not generally as great an issue as in other syndromes associated with intellectual disability. In children with Down syndrome, mental illness occurs in nearly 30% with autism occurring in 5–10%. People with Down syndrome experience a wide range of emotions. While people with Down syndrome are generally happy, symptoms of depression and anxiety may develop in early adulthood.\n\nChildren and adults with Down syndrome are at increased risk of epileptic seizures, which occur in 5–10% of children and up to 50% of adults. This includes an increased risk of a specific type of seizure called infantile spasms. Many (15%) who live 40 years or longer develop Alzheimer disease. In those who reach 60 years of age, 50–70% have the disease.\n\nHearing and vision disorders occur in more than half of people with Down syndrome. \n\nVision problems occur in 38 to 80%. Between 20 and 50% have strabismus, in which the two eyes do not move together. Cataracts (cloudiness of the lens of the eye) occur in 15%, and may be present at birth. Keratoconus (a thin, cone-shaped cornea) and glaucoma (increased eye pressure) are also more common, as are refractive errors requiring glasses or contacts. Brushfield spots (small white or grayish/brown spots on the outer part of the iris) are present in 38 to 85% of individuals.\nHearing problems are found in 50–90% of children with Down syndrome. This is often the result of otitis media with effusion which occurs in 50–70% and chronic ear infections which occur in 40 to 60%. Ear infections often begin in the first year of life and are partly due to poor eustachian tube function. Excessive ear wax can also cause hearing loss due to obstruction of the outer ear canal. Even a mild degree of hearing loss can have negative consequences for speech, language understanding, and academics. Additionally, it is important to rule out hearing loss as a factor in social and cognitive deterioration. Age-related hearing loss of the sensorineural type occurs at a much earlier age and affects 10–70% of people with Down syndrome.\n\nThe rate of congenital heart disease in newborns with Down syndrome is around 40%. Of those with heart disease, about 80% have an atrioventricular septal defect or ventricular septal defect with the former being more common. Mitral valve problems become common as people age, even in those without heart problems at birth. Other problems that may occur include tetralogy of Fallot and patent ductus arteriosus. People with Down syndrome have a lower risk of hardening of the arteries.\n\nAlthough the overall risk of cancer in DS is not changed, the risk of testicular cancer and certain blood cancers, including acute lymphoblastic leukemia (ALL) and acute megakaryoblastic leukemia (AMKL) is increased while the risk of other non blood cancers are decreased. People with DS are believed to have an increased risk of developing cancers derived from germ cells whether these cancers are blood or non-blood related.\n\nLeukemia is 10 to 15 times more common in children with Down syndrome. In particular, acute lymphoblastic leukemia is 20 times more common and the megakaryoblastic form of acute myeloid leukemia (acute megakaryoblastic leukemia), is 500 times more common. Acute megakaryoblastic leukemia (AMKL) is a leukemia of megakaryoblasts, the precursors cells to megakaryocytes which form blood platelets. Acute lymphoblastic leukemia in Down syndrome accounts for 1–3% of all childhood cases of ALL. It occurs most often in those older than nine years or having a white blood cell count greater than 50,000 per microliter and is rare in those younger than one year old. ALL in DS tends to have poorer outcomes than other cases of ALL in people without DS.\n\nIn Down syndrome, AMKL is typically preceded by transient myeloproliferative disease (TMD), a disorder of blood cell production in which non-cancerous megakaryoblasts with a mutation in the \"GATA1\" gene rapidly divide during the later period of pregnancy. The condition affects 3–10% of babies with Down. While it often spontaneously resolves within three months of birth, it can cause serious blood, liver, or other complications. In about 10% of cases, TMD progresses to AMKL during the three months to five years following its resolution.\n\nPeople with DS have a lower risk of all major solid cancers including those of lung, breast, cervix, with the lowest relative rates occurring in those aged 50 years or older. This low risk is thought due to an increase in the expression of tumor suppressor genes present on chromosome 21. One exception is testicular germ cell cancer which occurs at a higher rate in DS.\n\nProblems of the thyroid gland occur in 20–50% of individuals with Down syndrome. Low thyroid is the most common form, occurring in almost half of all individuals. Thyroid problems can be due to a poorly or nonfunctioning thyroid at birth (known as congenital hypothyroidism) which occurs in 1% or can develop later due to an attack on the thyroid by the immune system resulting in Graves' disease or autoimmune hypothyroidism. Type 1 diabetes mellitus is also more common.\n\nConstipation occurs in nearly half of people with Down syndrome and may result in changes in behavior. One potential cause is Hirschsprung's disease, occurring in 2–15%, which is due to a lack of nerve cells controlling the colon. Other frequent congenital problems include duodenal atresia, pyloric stenosis, Meckel diverticulum, and imperforate anus. Celiac disease affects about 7–20% and gastroesophageal reflux disease is also more common.\n\nIndividuals with Down syndrome tend to be more susceptible to gingivitis as well as early, severe periodontal disease, necrotising ulcerative gingivitis, and early tooth loss, especially in the lower front teeth. While plaque and poor oral hygiene are contributing factors, the severity of these periodontal diseases cannot be explained solely by external factors. Research suggests that the severity is likely a result of a weakened immune system. The weakened immune system also contributes to increased incidence of yeast infections in the mouth (from Candida albicans).\n\nIndividuals with Down syndrome also tend to have a more alkaline saliva resulting in a greater resistance to tooth decay, despite decreased quantities of saliva, less effective oral hygiene habits, and higher plaque indexes.\n\nHigher rates of tooth wear and bruxism are also common. Other common oral manifestations of Down syndrome include enlarged hypotonic tongue, crusted and hypotonic lips, mouth breathing, narrow palate with crowded teeth, class III malocclusion with an underdeveloped maxilla and posterior crossbite, delayed exfoliation of baby teeth and delayed eruption of adult teeth, shorter roots on teeth, and often missing and malformed (usually smaller) teeth. Less common manifestations include cleft lip and palate and enamel hypocalcification (20% prevalence).\n\nMales with Down syndrome usually do not father children, while females have lower rates of fertility relative to those who are unaffected. Fertility is estimated to be present in 30–50% of females. Menopause typically occurs at an earlier age. The poor fertility in males is thought to be due to problems with sperm development; however, it may also be related to not being sexually active. As of 2006, three instances of males with Down syndrome fathering children and 26 cases of females having children have been reported. Without assisted reproductive technologies, around half of the children of someone with Down syndrome will also have the syndrome.\n\nDown syndrome is caused by having three copies of the genes on chromosome 21, rather than the usual two. The parents of the affected individual are typically genetically normal. Those who have one child with Down syndrome have about a 1% risk of having a second child with the syndrome, if both parents are found to have normal karyotypes.\n\nThe extra chromosome content can arise through several different ways. The most common cause (about 92–95% of cases) is a complete extra copy of chromosome 21, resulting in trisomy 21. In 1.0 to 2.5% of cases, some of the cells in the body are normal and others have trisomy 21, known as mosaic Down syndrome. The other common mechanisms that can give rise to Down syndrome include: a Robertsonian translocation, isochromosome, or ring chromosome. These contain additional material from chromosome 21 and occur in about 2.5% of cases. An isochromosome results when the two long arms of a chromosome separate together rather than the long and short arm separating together during egg or sperm development.\n\nTrisomy 21 (also known by the karyotype 47,XX,+21 for females and 47,XY,+21 for males) is caused by a failure of the 21st chromosome to separate during egg or sperm development (nondisjunction). As a result, a sperm or egg cell is produced with an extra copy of chromosome 21; this cell thus has 24 chromosomes. When combined with a normal cell from the other parent, the baby has 47 chromosomes, with three copies of chromosome 21. About 88% of cases of trisomy 21 result from nonseparation of the chromosomes in the mother, 8% from nonseparation in the father, and 3% after the egg and sperm have merged.\n\nThe extra chromosome 21 material may also occur due to a Robertsonian translocation in 2–4% of cases. In this situation, the long arm of chromosome 21 is attached to another chromosome, often chromosome 14. In a male affected with Down syndrome, it results in a karyotype of 46XY,t(14q21q). This may be a new mutation or previously present in one of the parents. The parent with such a translocation is usually normal physically and mentally; however, during production of egg or sperm cells, a higher chance of creating reproductive cells with extra chromosome 21 material exists. This results in a 15% chance of having a child with Down syndrome when the mother is affected and a less than 5% probability if the father is affected. The probability of this type of Down syndrome is not related to the mother's age. Some children without Down syndrome may inherit the translocation and have a higher probability of having children of their own with Down syndrome. In this case it is sometimes known as familial Down syndrome.\n\nThe extra genetic material present in DS results in overexpression of a portion of the 310 genes located on chromosome 21. This overexpression has been estimated at around 50%. Some research has suggested the Down syndrome critical region is located at bands 21q22.1–q22.3, with this area including genes for amyloid, superoxide dismutase, and likely the ETS2 proto oncogene. Other research, however, has not confirmed these findings. microRNAs are also proposed to be involved.\n\nThe dementia which occurs in Down syndrome is due to an excess of amyloid beta peptide produced in the brain and is similar to Alzheimer's disease. This peptide is processed from amyloid precursor protein, the gene for which is located on chromosome 21. Senile plaques and neurofibrillary tangles are present in nearly all by 35 years of age, though dementia may not be present. Those with DS also lack a normal number of lymphocytes and produce less antibodies which contributes to their increased risk of infection.\n\nDown syndrome is associated with an increased risk of many chronic diseases that are typically associated with older age such as Alzheimer's disease. The accelerated aging suggest that trisomy 21 increases the biological age of tissues, but molecular evidence for this hypothesis is sparse. According to a biomarker of tissue age known as epigenetic clock, trisomy 21 increases the age of blood and brain tissue (on average by 6.6 years).\n\nWhen screening tests predict a high risk of Down syndrome, a more invasive diagnostic test (amniocentesis or chorionic villus sampling) is needed to confirm the diagnosis. If Down syndrome occurs in one in 500 pregnancies and the test used has a 5% false-positive rate, this means, of 26 women who test positive on screening, only one will have Down syndrome confirmed. If the screening test has a 2% false-positive rate, this means one of eleven who test positive on screening have a fetus with DS. Amniocentesis and chorionic villus sampling are more reliable tests, but they increase the risk of miscarriage between 0.5 and 1%. The risk of limb problems may be increased in the offspring if chorionic villus sampling is performed before 10 weeks. The risk from the procedure is greater the earlier it is performed, thus amniocentesis is not recommended before 15 weeks gestational age and chorionic villus sampling before 10 weeks gestational age.\n\nAbout 92% of pregnancies in Europe with a diagnosis of Down syndrome are terminated. As a result there are almost no people with Downs in Iceland and Denmark, where screening is commonplace. In the United States, the termination rate after diagnosis is around 75%, but varies from 61% to 93% depending on the population surveyed. Rates are lower among women who are younger and have decreased over time. When nonpregnant people are asked if they would have a termination if their fetus tested positive, 23–33% said yes, when high-risk pregnant women were asked, 46–86% said yes, and when women who screened positive are asked, 89–97% say yes.\n\nThe diagnosis can often be suspected based on the child's physical appearance at birth. An analysis of the child's chromosomes is needed to confirm the diagnosis, and to determine if a translocation is present, as this may help determine the risk of the child's parents having further children with Down syndrome. Parents generally wish to know the possible diagnosis once it is suspected and do not wish pity.\n\nGuidelines recommend screening for Down syndrome to be offered to all pregnant women, regardless of age. A number of tests are used, with varying levels of accuracy. They are typically used in combination to increase the detection rate. None can be definitive, thus if screening is positive, either amniocentesis or chorionic villus sampling is required to confirm the diagnosis. Screening in both the first and second trimesters is better than just screening in the first trimester. The different screening techniques in use are able to pick up 90–95% of cases with a false-positive rate of 2–5%.\n\nUltrasound imaging can be used to screen for Down syndrome. Findings that indicate increased risk when seen at 14 to 24 weeks of gestation include a small or no nasal bone, large ventricles, nuchal fold thickness, and an abnormal right subclavian artery, among others. The presence or absence of many markers is more accurate. Increased fetal nuchal translucency (NT) indicates an increased risk of Down syndrome picking up 75–80% of cases and being falsely positive in 6%.\n\nSeveral blood markers can be measured to predict the risk of Down syndrome during the first or second trimester. Testing in both trimesters is sometimes recommended and test results are often combined with ultrasound results. In the second trimester, often two or three tests are used in combination with two or three of: α-fetoprotein, unconjugated estriol, total hCG, and free βhCG detecting about 60–70% of cases.\n\nTesting of the mother's blood for fetal DNA is being studied and appears promising in the first trimester. The International Society for Prenatal Diagnosis considers it a reasonable screening option for those women whose pregnancies are at a high risk for trisomy 21. Accuracy has been reported at 98.6% in the first trimester of pregnancy. Confirmatory testing by invasive techniques (amniocentesis, CVS) is still required to confirm the screening result.\n\nEfforts such as early childhood intervention, screening for common problems, medical treatment where indicated, a good family environment, and work-related training can improve the development of children with Down syndrome. Education and proper care can improve quality of life. Raising a child with Down syndrome is more work for parents than raising an unaffected child. Typical childhood vaccinations are recommended.\n\nA number of health organizations have issued recommendations for screening those with Down syndrome for particular diseases. This is recommended to be done systematically.\n\nAt birth, all children should get an electrocardiogram and ultrasound of the heart. Surgical repair of heart problems may be required as early as three months of age. Heart valve problems may occur in young adults, and further ultrasound evaluation may be needed in adolescents and in early adulthood. Due to the elevated risk of testicular cancer, some recommend checking the person's testicles yearly.\n\nHearing aids or other amplification devices can be useful for language learning in those with hearing loss. Speech therapy may be useful and is recommended to be started around nine months of age. As those with Down syndrome typically have good hand-eye coordination, learning sign language may be possible. Augmentative and alternative communication methods, such as pointing, body language, objects, or pictures, are often used to help with communication. Behavioral issues and mental illness are typically managed with counseling or medications.\nEducation programs before reaching school age may be useful. School-age children with Down syndrome may benefit from inclusive education (whereby students of differing abilities are placed in classes with their peers of the same age), provided some adjustments are made to the curriculum. Evidence to support this, however, is not very strong. In the United States, the Individuals with Disabilities Education Act of 1975 requires public schools generally to allow attendance by students with Down syndrome.\nIndividuals with Down syndrome may learn better visually. Drawing may help with language, speech, and reading skills. Children with Down syndrome still often have difficulty with sentence structure and grammar, as well as developing the ability to speak clearly. Several types of early intervention can help with cognitive development. Efforts to develop motor skills include physical therapy, speech and language therapy, and occupational therapy. Physical therapy focuses specifically on motor development and teaching children to interact with their environment. Speech and language therapy can help prepare for later language. Lastly, occupational therapy can help with skills needed for later independence.\n\nTympanostomy tubes are often needed and often more than one set during the person's childhood. Tonsillectomy is also often done to help with sleep apnea and throat infections. Surgery, however, does not always address the sleep apnea and a continuous positive airway pressure (CPAP) machine may be useful. Physical therapy and participation in physical education may improve motor skills. Evidence to support this in adults, however, is not very good.\n\nEfforts to prevent respiratory syncytial virus (RSV) infection with human monoclonal antibodies should be considered, especially in those with heart problems. In those who develop dementia there is no evidence for memantine, donepezil, rivastigmine, or galantamine.\n\nPlastic surgery has been suggested as a method of improving the appearance and thus the acceptance of people with Down syndrome. It has also been proposed as a way to improve speech. Evidence, however, does not support a meaningful difference in either of these outcomes. Plastic surgery on children with Down syndrome is uncommon, and continues to be controversial. The U.S. National Down Syndrome Society views the goal as one of mutual respect and acceptance, not appearance.\n\nMany alternative medical techniques are used in Down syndrome; however, they are poorly supported by evidence. These include: dietary changes, massage, animal therapy, chiropractic and naturopathy, among others. Some proposed treatments may also be harmful.\n\nBetween 5 and 15% of children with Down syndrome in Sweden attend regular school. Some graduate from high school; however, most do not. Of those with intellectual disability in the United States who attended high school about 40% graduated. Many learn to read and write and some are able to do paid work. In adulthood about 20% in the United States do paid work in some capacity. In Sweden, however, less than 1% have regular jobs. Many are able to live semi-independently, but they often require help with financial, medical, and legal matters. Those with mosaic Down syndrome usually have better outcomes.\n\nIndividuals with Down syndrome have a higher risk of early death than the general population. This is most often from heart problems or infections. Following improved medical care, particularly for heart and gastrointestinal problems, the life expectancy has increased. This increase has been from 12 years in 1912, to 25 years in the 1980s, to 50 to 60 years in the developed world in the 2000s. Currently between 4 and 12% die in the first year of life. The probability of long-term survival is partly determined by the presence of heart problems. In those with congenital heart problems 60% survive to 10 years and 50% survive to 30 years of age. In those without heart problems 85% survive to 10 years and 80% survive to 30 years of age. About 10% live to 70 years of age. The National Down Syndrome Society provide information regarding raising a child with Down syndrome.\n\nGlobally, , Down syndrome occurs in about 1 per 1000 births and results in about 17,000 deaths. More children are born with Down syndrome in countries where abortion is not allowed and in countries where pregnancy more commonly occurs at a later age. About 1.4 per 1000 live births in the United States and 1.1 per 1000 live births in Norway are affected. In the 1950s, in the United States, it occurred in 2 per 1000 live births with the decrease since then due to prenatal screening and abortions. The number of pregnancies with Down syndrome is more than two times greater with many spontaneously aborting. It is the cause of 8% of all congenital disorders.\n\nMaternal age affects the chances of having a pregnancy with Down syndrome. At age 20, the chance is one in 1441; at age 30, it is one in 959; at age 40, it is one in 84; and at age 50 it is one in 44. Although the probability increases with maternal age, 70% of children with Down syndrome are born to women 35 years of age and younger, because younger people have more children. The father's older age is also a risk factor in women older than 35, but not in women younger than 35, and may partly explain the increase in risk as women age.\n\nEnglish physician John Langdon Down first described Down syndrome in 1862, recognizing it as a distinct type of mental disability, and again in a more widely published report in 1866. Édouard Séguin described it as separate from cretinism in 1844. By the 20th century, Down syndrome had become the most recognizable form of mental disability.\n\nIn antiquity, many infants with disabilities were either killed or abandoned. A number of historical pieces of art are believed to portray Down syndrome, including pottery from the pre-Columbian Tumaco-La Tolita culture in present-day Colombia and Ecuador, and the 16th-century painting \"The Adoration of the Christ Child\".\n\nIn the 20th century, many individuals with Down syndrome were institutionalized, few of the associated medical problems were treated, and most died in infancy or early adult life. With the rise of the eugenics movement, 33 of the then 48 U.S. states and several countries began programs of forced sterilization of individuals with Down syndrome and comparable degrees of disability. Action T4 in Nazi Germany made public policy of a program of systematic involuntary euthanization.\n\nWith the discovery of karyotype techniques in the 1950s, it became possible to identify abnormalities of chromosomal number or shape. In 1959, Jérôme Lejeune reported the discovery that Down syndrome resulted from an extra chromosome. However, Lejeune's claim to the discovery has been disputed, and in 2014, the Scientific Council of the French Federation of Human Genetics unanimously awarded its Grand Prize to his colleague Marthe Gautier for her role in this discovery. The discovery was in the laboratory of Raymond Turpin at the Hôpital Trousseau in Paris, France. Jérôme Lejeune and Marthe Gautier were both his students.\n\nAs a result of this discovery, the condition became known as trisomy 21. Even before the discovery of its cause, the presence of the syndrome in all races, its association with older maternal age, and its rarity of recurrence had been noticed. Medical texts had assumed it was caused by a combination of inheritable factors that had not been identified. Other theories had focused on injuries sustained during birth.\nDue to his perception that children with Down syndrome shared facial similarities with those of Blumenbach's Mongolian race, John Langdon Down used the term \"mongoloid\". He felt that the existence of Down syndrome confirmed that all peoples were genetically related. In the 1950s with discovery of the underlying cause as being related to chromosomes, concerns about the race-based nature of the name increased.\n\nIn 1961, 19 scientists suggested that \"mongolism\" had \"misleading connotations\" and had become \"an embarrassing term\". The World Health Organization (WHO) dropped the term in 1965 after a request by the delegation from the Mongolian People's Republic. While the term mongoloid (also mongolism, Mongolian imbecility or idiocy) continued to be used until the early 1980s, it is now considered unacceptable and is no longer in common use.\n\nIn 1975, the United States National Institutes of Health (NIH) convened a conference to standardize the naming and recommended replacing the possessive form, \"Down's syndrome\" with \"Down syndrome\". However, both the possessive and nonpossessive forms remain in use by the general population. The term \"trisomy 21\" is also commonly used.\n\nSome obstetricians argue that not offering screening for Down syndrome is unethical. As it is a medically reasonable procedure, per informed consent, people should at least be given information about it. It will then be the woman's choice, based on her personal beliefs, how much or how little screening she wishes. When results from testing become available, it is also considered unethical not to give the results to the person in question.\n\nSome bioethicists deem it reasonable for parents to select a child who would have the highest well-being. One criticism of this reasoning is that it often values those with disabilities less. Some parents argue that Down syndrome shouldn't be prevented or cured and that eliminating Down syndrome amounts to genocide. The disability rights movement does not have a position on screening, although some members consider testing and abortion discriminatory. Some in the United States who are pro-life support abortion if the fetus is disabled, while others do not. Of a group of 40 mothers in the United States who have had one child with Down syndrome, half agreed to screening in the next pregnancy.\n\nWithin the US, some Protestant denominations see abortion as acceptable when a fetus has Down syndrome, while Orthodox Christians and Roman Catholics often do not. Some of those against screening refer to it as a form of \"eugenics\". Disagreement exists within Islam regarding the acceptability of abortion in those carrying a fetus with Down syndrome. Some Islamic countries allow abortion, while others do not. Women may face stigmatization whichever decision they make.\n\nAdvocacy groups for individuals with Down syndrome began to be formed after the Second World War. These were organizations advocating for the inclusion of people with Down syndrome into the general school system and for a greater understanding of the condition among the general population, as well as groups providing support for families with children living with Down syndrome. Before this individuals with Down syndrome were often placed in mental hospitals or asylums. Organizations included the Royal Society for Handicapped Children and Adults founded in the UK in 1946 by Judy Fryd, Kobato Kai founded in Japan in 1964, the National Down Syndrome Congress founded in the United States in 1973 by Kathryn McGee and others, and the National Down Syndrome Society founded in 1979 in the United States.\n\nThe first World Down Syndrome Day was held on 21 March 2006. The day and month were chosen to correspond with 21 and trisomy, respectively. It was recognized by the United Nations General Assembly in 2011.\n\nEfforts are underway to determine how the extra chromosome 21 material causes Down syndrome, as currently this is unknown, and to develop treatments to improve intelligence in those with the syndrome. Two efforts being studied are the use stem cells and gene therapy. Other methods being studied include the use of antioxidants, gamma secretase inhibition, adrenergic agonists, and memantine. Research is often carried out on an animal model, the Ts65Dn mouse.\n\n"}
{"id": "8305", "url": "https://en.wikipedia.org/wiki?curid=8305", "title": "Dyslexia", "text": "Dyslexia\n\nDyslexia, also known as reading disorder, is characterized by trouble with reading despite normal intelligence. Different people are affected to varying degrees. Problems may include difficulties in spelling words, reading quickly, writing words, \"sounding out\" words in the head, pronouncing words when reading aloud and understanding what one reads. Often these difficulties are first noticed at school. When someone who previously could read loses their ability, it is known as alexia. The difficulties are involuntary and people with this disorder have a normal desire to learn.\nDyslexia is believed to be caused by both genetic and environmental factors. Some cases run in families. It often occurs in people with attention deficit hyperactivity disorder (ADHD) and is associated with similar difficulties with numbers. It may begin in adulthood as the result of a traumatic brain injury, stroke, or dementia. The underlying mechanisms of dyslexia are problems within the brain's language processing. Dyslexia is diagnosed through a series of tests of memory, spelling, vision, and reading skills. Dyslexia is separate from reading difficulties caused by hearing or vision problems or by insufficient teaching.\nTreatment involves adjusting teaching methods to meet the person's needs. While not curing the underlying problem, it may decrease the degree of symptoms. Treatments targeting vision are not effective. Dyslexia is the most common learning disability and occurs in all areas of the world. It affects 3–7% of the population, however, up to 20% may have some degree of symptoms. While dyslexia is more often diagnosed in men, it has been suggested that it affects men and women equally. Some believe that dyslexia should be best considered as a different way of learning, with both benefits and downsides.\nDyslexia is thought to have two types of cause, one related to language processing and another to visual processing. It is considered a cognitive disorder, not a problem with intelligence. However, emotional problems often arise because of it. Some published definitions are purely descriptive, whereas others propose causes. The latter usually cover a variety of reading skills and deficits, and difficulties with distinct causes rather than a single condition. The National Institute of Neurological Disorders and Stroke definition describes dyslexia as \"difficulty with phonological processing (the manipulation of sounds), spelling, and/or rapid visual-verbal responding\". The British Dyslexia Association definition describes dyslexia as \"a learning difficulty that primarily affects the skills involved in accurate and fluent word reading and spelling\" and is characterized by \"difficulties in phonological awareness, verbal memory and verbal processing speed\".\n\nAcquired dyslexia or alexia may be caused by brain damage due to stroke or atrophy. Forms of alexia include pure alexia, surface dyslexia, semantic dyslexia, phonological dyslexia, and deep dyslexia.\n\nThere is some variability in the definition of dyslexia. Some sources, such as the U.S. National Institutes of Health, define it specifically as a learning disorder. Other sources, however, define it simply as an inability to read in the context of normal intelligence, and distinguish between \"developmental dyslexia\" (a learning disorder) and \"acquired dyslexia\" (loss of the ability to read caused by brain damage). ICD 10, the manual of medical diagnosis used in much of the world, includes separate diagnoses for \"developmental dyslexia\" (81.0) and for \"dyslexia and alexia\" (48.0). DSM 5, the manual of psychiatric diagnosis used in the United States, does not specifically define dyslexia, justifying this decision by stating that \"the many definitions of dyslexia and dyscalculia meant those terms would not be useful as disorder names or in the diagnostic \ncriteria\". Instead it includes dyslexia in a category called specific learning disorders.\n\nIn early childhood, symptoms that correlate with a later diagnosis of dyslexia include delayed onset of speech and a lack of phonological awareness, as well as being easily distracted by background noise. A common myth closely associates dyslexia with mirror writing and reading letters or words backwards. These behaviors are seen in many children as they learn to read and write, and are not considered to be defining characteristics of dyslexia.\n\nSchool-age children with dyslexia may exhibit signs of difficulty in identifying or generating rhyming words, or counting the number of syllables in words – both of which depend on phonological awareness. They may also show difficulty in segmenting words into individual sounds or may blend sounds when producing words, indicating reduced phonemic awareness. Difficulties with word retrieval or naming things is also associated with dyslexia. People with dyslexia are commonly poor spellers, a feature sometimes called dysorthographia or dysgraphia, which depends on orthographic coding.\n\nProblems persist into adolescence and adulthood and may accompany difficulties with summarizing stories, memorization, reading aloud, or learning foreign languages. Adults with dyslexia can often read with good comprehension, though they tend to read more slowly than others without a learning difficulty and perform worse in spelling tests or when reading nonsense words – a measure of phonological awareness.\n\nThe orthographic complexity of a language directly impacts how difficult learning to read the language is. English and French have comparatively \"deep\" phonemic orthographies within the Latin alphabet writing system, with complex structures employing spelling patterns on several levels: letter-sound correspondence, syllables, and morphemes. Languages such as Spanish, Italian and Finnish have mostly alphabetic orthographies, which primarily employ letter-sound correspondence – so-called shallow orthographies – which for dyslexics makes them easier to learn. Logographic writing systems, such as Chinese characters, have extensive symbol use, and pose problems for dyslexic learners.\n\nDyslexia is often accompanied by several learning disabilities, but it is unclear whether they share underlying neurological causes. These associated disabilities include:\n\nResearchers have been trying to find the neurobiological basis of dyslexia since the condition was first identified in 1881. For example, some have tried to associate the common problem among dyslexics of not being able to see letters clearly to abnormal development of their visual nerve cells.\n\nModern neuroimaging techniques such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET) have shown a correlation between both functional and structural differences in the brains of children with reading difficulties. Some dyslexics show less electrical activation in parts of the left hemisphere of the brain involved with reading, such as the inferior frontal gyrus, inferior parietal lobule, and the middle and ventral temporal cortex. Over the past decade, brain activation studies using PET to study language have produced a breakthrough in the understanding of the neural basis of language. Neural bases for the visual lexicon and for auditory verbal short-term memory components have been proposed, with some implication that the observed neural manifestation of developmental dyslexia is task-specific (i.e. functional rather than structural). fMRIs in dyslexics have provided important data which point to the interactive role of the cerebellum and cerebral cortex as well as other brain structures.\n\nThe cerebellar theory of dyslexia proposes that impairment of cerebellum-controlled muscle movement affects the formation of words by the tongue and facial muscles, resulting in the fluency problems that are characteristic of some dyslexics. The cerebellum is also involved in the automatization of some tasks, such as reading. The fact that some dyslexic children have motor task and balance impairments has been used as evidence for a cerebellar role in their reading difficulties. However, the cerebellar theory is not supported by controlled research studies.\n\nResearch into potential genetic causes of dyslexia has its roots in post-autopsy examination of the brains of people with dyslexia. Observed anatomical differences in the language centers of such brains include microscopic cortical malformations known as ectopias, more rarely, vascular micro-malformations, and microgyrus. The previously cited studies and others suggest that abnormal cortical development presumed to occur before or during the sixth month of fetal brain development was the cause of the abnormalities. Abnormal cell formations in dyslexics have also been reported in non-language cerebral and subcortical brain structures. Several genes have been associated with dyslexia, including DCDC2 and KIAA0319 on chromosome 6, and DYX1C1 on chromosome 15.\n\nThe contribution of gene–environment interaction to reading disability has been intensely studied using twin studies, which estimate the proportion of variance associated with a person's environment and the proportion associated with their genes. Studies examining the influence of environmental factors such as parental education and teacher quality have determined that genetics have greater influence in supportive, rather than less optimal, environments. However, more optimal conditions may just allow those genetic risk factors to account for more of the variance in outcome because the environmental risk factors have been minimized. As environment plays a large role in learning and memory, it is likely that epigenetic modifications play an important role in reading ability. Animal experiments and measures of gene expression and methylation in the human periphery are used to study epigenetic processes; however, both types of study have many limitations in the extrapolation of results for application to the human brain.\n\nThe dual-route theory of reading aloud was first described in the early 1970s. This theory suggests that two separate mental mechanisms, or cognitive routes, are involved in reading aloud. One mechanism is the lexical route, which is the process whereby skilled readers can recognize known words by sight alone, through a \"dictionary\" lookup procedure. The other mechanism is the nonlexical or sublexical route, which is the process whereby the reader can \"sound out\" a written word. This is done by identifying the word's constituent parts (letters, phonemes, graphemes) and applying knowledge of how these parts are associated with each other, for example, how a string of neighboring letters sound together. The dual-route system could explain the different rates of dyslexia occurrence between different languages (e.g. the Spanish language dependence on phonological rules accounts for the fact that Spanish-speaking children show a higher level of performance in non-word reading, when compared to English-speakers).\n\nDyslexia disorder is not caused by mutation in one gene; in fact, it appears to involve the combined effects of several genes. Studying the cognitive problems associated with other disorders helps to better understand the genotype-phenotype link of dyslexia. Neurophysiological and imaging procedures are being used to ascertain phenotypic characteristics in dyslexics, thus identifying the effects of certain genes.\n\nThere are tests that can indicate with high probability whether a person is a dyslexic. If diagnostic testing indicates that a person may be dyslexic, such tests are often followed up with a full diagnostic assessment to determine the extent and nature of the disorder. Tests can be administered by a teacher or computer. Some test results indicate how to carry out teaching strategies.\n\nCentral dyslexias include surface dyslexia, semantic dyslexia, phonological dyslexia, and deep dyslexia. ICD-10 reclassified the previous distinction between dyslexia (315.02 in ICD-9) and alexia (315.01 in ICD-9) into a single classification as R48.0. The terms are applied to developmental dyslexia and inherited dyslexia along with developmental aphasia and inherited alexia, which are considered synonymous.\n\nIn surface dyslexia, words with regular pronunciations (highly consistent with their spelling, e.g. \"mint\") are read more accurately than words with irregular pronunciation, such as \"colonel\". Difficulty distinguishing homophones is a diagnostic used for some forms of surface dyslexia. This disorder is usually accompanied by surface agraphia and fluent aphasia. Acquired surface dyslexia arises when a previously literate person experiences brain damage, which results in pronunciation errors that indicate impairment of the lexical route.\n\nIn phonological dyslexia, sufferers can read familiar words but have difficulty with unfamiliar words, such as invented pseudo-words. Phonological dyslexia is associated with lesions in the parts of the brain supplied with blood by the middle cerebral artery. The superior temporal lobe is often also involved. Furthermore, dyslexics compensate by overusing a front-brain region called Broca's area, which is associated with aspects of language and speech. The Lindamood Phoneme Sequencing Program (LiPS) is used to treat phonological dyslexia. This system is based on a three-way sensory feedback process, using auditory, visual, and oral skills to learn to recognize words and word patterns. Case studies with a total of three patients found a significant improvement in spelling and reading ability after using LiPS.\n\nIndividuals with deep dyslexia experience both semantic paralexia (para-dyslexia) and phonological dyslexia, causing the person to read a word and then say a related meaning instead of the denoted meaning. Deep dyslexia is associated with clear phonological processing impairments. Deep dyslexia is caused by widespread damage to the brain that often includes the left hemisphere. The \"continuum\" hypothesis claims that deep dyslexia develops from phonological dyslexia.\n\nPeripheral dyslexias have been described as affecting the visual analysis of letters as a result of brain injury. Hemianopsia, a visual field loss on the left/right side of the vertical midline, is associated with this condition.\n\nPure, or phonologically-based, dyslexia, also known as agnosic dyslexia, dyslexia without agraphia, and pure word blindness, is dyslexia due to difficulty in recognizing written sequences of letters (such as words), or sometimes even letters. It is considered '\"pure\" because it is not accompanied by other significant language-related impairments. Pure dyslexia does not affect speech, handwriting style, language or comprehension impairments. Pure dyslexia is caused by lesions on the visual word form area (VWFA). The VWFA is composed of the left lateral occipital sulcus and is activated during reading. A lesion in the VWFA stops transmission between the visual cortex and the left angular gyrus. It can also be caused by a lesion involving the left occipital lobe or the splenium. It is usually accompanied by a homonymous hemianopsia in the right side of the visual field. Multiple oral re-reading (MOR) is a treatment for pure dyslexia. It is considered a top-down processing technique in which affected individuals read and reread texts a predetermined number of times or until reading speed or accuracy improves a predetermined amount.\n\nHemianopic dyslexia is commonly considered to derive from visual field loss due to damage to the primary visual cortex. Sufferers may complain of abnormally slow reading but are able to read individual words normally. This is the most common form of peripheral alexia, and the form with the best evidence of effective treatments.\n\nIn neglect dyslexia, some letters, most commonly those at the beginning or left side of a word, are skipped or misread during reading. This alexia is associated with right parietal lesions. The use of prism glasses has been shown to mitigate this condition substantially.\n\nPeople with attentional dyslexia complain of letter-crowding or migration, sometimes blending elements of two words into one. Sufferers read better when words are presented in isolation rather than flanked by other words and letters. Using a large magnifying glass may help mitigate this condition by reducing the effects of flanking from nearby words; however, no trials of this or indeed any other therapy for left parietal syndromes have been published as of 2014.\n\nThrough the use of compensation strategies, therapy and educational support, dyslexic individuals can learn to read and write. There are techniques and technical aids which help to manage or conceal symptoms of the disorder. Removing stress and anxiety alone can sometimes improve written comprehension. For dyslexia intervention with alphabet-writing systems, the fundamental aim is to increase a child's awareness of correspondences between graphemes (letters) and phonemes (sounds), and to relate these to reading and spelling by teaching how sounds blend into words. It has been found that reinforced collateral training focused on reading and spelling yields longer-lasting gains than oral phonological training alone. Early intervention that is done for children at a young age can be successful in reducing reading failure.\n\nThere is some evidence that the use of specially-tailored fonts may help with dyslexia. These fonts, which include Dyslexie, OpenDyslexic, and Lexie Readable, were created based on the idea that many of the letters of the Latin alphabet are visually similar and may, therefore, confuse people with dyslexia. Dyslexie and OpenDyslexic both put emphasis on making each letter more distinctive in order to be more easily identified. The benefits, however, might simply be due to the added spacing between words.\n\nThere have been many studies conducted regarding intervention in dyslexia. Among these studies one meta-analysis found that there was functional activation as a result.\n\nThere is no evidence demonstrating that the use of music education is effective in improving dyslexic adolescents' reading skills.\n\nDyslexic children require special instruction for word analysis and spelling from an early age. While there are fonts that may help people with dyslexia better understand writing, this might simply be due to the added spacing between words. The prognosis, generally speaking, is positive for individuals who are identified in childhood and receive support from friends and family.\n\nThe percentage of people with dyslexia is unknown, but it has been estimated to be as low as 5% and as high as 17% of the population. While it is diagnosed more often in males, some believe that it affects males and females equally.\n\nThere are different definitions of dyslexia used throughout the world, but despite significant differences in writing systems, dyslexia occurs in different populations. Dyslexia is not limited to difficulty in converting letters to sounds, and Chinese dyslexics may have difficulty converting Chinese characters into their meanings. The Chinese vocabulary uses logographic, monographic, non-alphabet writing where one character can represent an individual phoneme.\n\nThe phonological-processing hypothesis attempts to explain why dyslexia occurs in a wide variety of languages. Furthermore, the relationship between phonological capacity and reading appears to be influenced by orthography.\n\nDyslexia was identified by Oswald Berkhan in 1881, but the term \"dyslexia\" was coined in 1887 by Rudolf Berlin, an ophthalmologist in Stuttgart. He used the term to refer to the case of a young boy who had a severe impairment in learning to read and write, despite showing typical intelligence and physical abilities in all other respects. In 1896, W. Pringle Morgan, a British physician from Seaford, East Sussex, published a description of a reading-specific learning disorder in a report to the \"British Medical Journal\" titled \"Congenital Word Blindness\". The distinction between phonological and surface types of dyslexia is only descriptive, and without any etiological assumption as to the underlying brain mechanisms. However, studies have alluded to potential differences due to variation in performance.\n\nThe majority of currently available dyslexia research relates to alphabetic writing systems, and especially to European languages. However, substantial research is also available regarding dyslexics who speak Arabic, Chinese, Hebrew, or other languages.\n\nAs is the case with any disorder, society often makes an assessment based on incomplete information. Before the 1980s, dyslexia was thought to be a consequence of education, rather than a basic disability. As a result, society often misjudges those with the disorder. There is also sometimes a workplace stigma and negative attitude towards those with dyslexia. If a dyslexic's instructors lack the necessary training to support a child with the condition, there is often a negative effect on the student's learning participation.\n\n\n"}
{"id": "8308", "url": "https://en.wikipedia.org/wiki?curid=8308", "title": "Delft", "text": "Delft\n\nDelft () is a city and municipality in the province of South Holland, Netherlands. It is located between Rotterdam, to the southeast, and The Hague, to the northwest. Together with them, it is part of both Rotterdam–The Hague metropolitan area and the Randstad.\n\nDelft is a popular tourist attraction in the country. It is home to Delft University of Technology (TU Delft), regarded as center of technological research and development in the Netherlands, Delft Blue pottery and the currently reigning House of Orange-Nassau. Historically, Delft played a highly influential role in the Dutch Golden Age. Delft has a special place in the history of microbiology. In terms of science and technology, thanks to the pioneering contributions of Antonie van Leeuwenhoek and Martinus Beijerinck, Delft can be considered to be the true birthplace of microbiology, with its several sub-disciplines such as bacteriology, protozoology, and virology.\n\nThe city of Delft came into being beside a canal, the 'Delf', which comes from the word \"delven\", meaning delving or digging, and led to the name Delft. It presumably started around the 11th century as a landlord court.\n\nFrom a rural village in the early Middle Ages, Delft developed into a city, that in the 13th century (1246) received its charter. (For some more information about the early development, see Gracht).\"\n\nThe town's association with the House of Orange started when William of Orange (Willem van Oranje), nicknamed William the Silent (Willem de Zwijger), took up residence in 1572. At the time he was the leader of growing national Dutch resistance against Spanish occupation, known as the Eighty Years' War. By then Delft was one of the leading cities of Holland and it was equipped with the necessary city walls to serve as a headquarters. An attack by Spanish forces in October of that year was repelled.\n\nAfter the Act of Abjuration was proclaimed in 1581, Delft became the \"de facto\" capital of the newly independent Netherlands, as the seat of the Prince of Orange.\n\nWhen William was shot dead in 1584 by Balthazar Gerards in the hall of the Prinsenhof, the family's traditional burial place in Breda was still in the hands of the Spanish. Therefore, he was buried in the Delft Nieuwe Kerk (New Church), starting a tradition for the House of Orange that has continued to the present day.\n\nThe Delft Explosion, also known in history as the , occurred on 12 October 1654 when a gunpowder store exploded, destroying much of the city. Over a hundred people were killed and thousands were wounded.\n\nAbout of gunpowder were stored in barrels in a magazine in a former Clarissen convent in the Doelenkwartier district. Cornelis Soetens, the keeper of the magazine, opened the store to check a sample of the powder and a huge explosion followed. Luckily, many citizens were away, visiting a market in Schiedam or a fair in The Hague.\n\nToday, the explosion is remembered primarily for killing Rembrandt's most promising pupil, Carel Fabritius, and destroying almost all his works.\n\nDelft artist Egbert van der Poel painted several pictures of Delft showing the devastation.\n\nThe city centre retains a large number of monumental buildings, while in many streets there are canals of which the banks are connected by typical bridges, altogether making this city a notable tourist destination.\n\nHistorical buildings and other sights of interest include:\n\nDelft is well known for the Delft pottery ceramic products which were styled on the imported Chinese porcelain of the 17th century. The city had an early start in this area since it was a home port of the Dutch East India Company. It can still be seen at the pottery factories De Koninklijke Porceleyne Fles (or Royal Delft) and De Delftse Pauw.\n\nThe painter Johannes Vermeer (1632–1675) was born in Delft. Vermeer used Delft streets and home interiors as the subject or background in his paintings.\nSeveral other famous painters lived and worked in Delft at that time, such as Pieter de Hoogh, Carel Fabritius, Nicolaes Maes, Gerard Houckgeest and Hendrick Cornelisz. van Vliet. They were all members of the Delft School. The Delft School is known for its images of domestic life, views of households, church interiors, courtyards, squares and the streets of Delft. The painters also produced pictures showing historic events, flowers, portraits for patrons and the court as well as decorative pieces of art.\nDelft supports creative arts companies. From 2001 the , a building that had been disused since 1951, began to house small companies in the creative arts sector. However, demolition of the building started in December 2009, making way for the construction of the new railway tunnel in Delft. The occupants of the building, as well as the name 'Bacinol', moved to another building in the city. The name Bacinol relates to Dutch penicillin research during WWII.\n\nDelft University of Technology (TU Delft) is one of four universities of technology in the Netherlands. It was founded as an academy for civil engineering in 1842 by King William II. Today well over 21,000 students are enrolled.\n\nThe UNESCO-IHE Institute for Water Education, providing postgraduate education for people from developing countries, draws on the strong tradition in water management and hydraulic engineering of the Delft university.\n\nIn the local economic field essential elements are:\n\nEast of Delft lies a relatively large nature and recreation area called the \"Delftse Hout\" (\"Delft Wood\"). Through the forest lie bike, horse-riding and footpaths. It also includes a vast lake (suitable for swimming and windsurfing), narrow beaches, a restaurant, community gardens, plus camping ground and other recreational and sports facilities. (There is also a facility for renting bikes from the station.)\n\nInside the city, apart from a central park, there are also several smaller town parks, like \"Nieuwe Plantage\", \"Agnetapark\", \"Kalverbos\" and others.\nFurthermore, there is the Botanical Garden of the TU and an arboretum in Delftse Hout.\n\nDelft was the birthplace of:\n\nBefore 1900\n\nAfter 1900\n\nOtherwise related\n\n\nDelft is twinned with:\n\nDelft's longstanding connection with Rishon LeZion ended in 2016 after the supporting organizations shut down in both countries.\n\nTrains stopping at these stations connect Delft with, among others, the nearby cities of Rotterdam and The Hague, up to every five minutes, for most of the day.\n\nThere are several bus routes from Delft to similar destinations. Trams frequently travel between Delft and The Hague via special double tracks crossing the city. One of those two lines (19) is still under construction inside Delft and is meant to connect The Hague with a science park, which is being developed on the southern (Rotterdam) side of Delft and is a joint project by the Delft and Rotterdam municipalities.\n\n\n\n"}
{"id": "8309", "url": "https://en.wikipedia.org/wiki?curid=8309", "title": "Duesberg hypothesis", "text": "Duesberg hypothesis\n\nThe Duesberg hypothesis is the claim, associated with University of California, Berkeley professor Peter Duesberg, that various noninfectious factors such as but not limited to, recreational and pharmaceutical drug use are the cause of AIDS, and that HIV (human immunodeficiency virus) is merely a harmless passenger virus. The scientific consensus is that the Duesberg hypothesis is incorrect and that HIV is the cause of AIDS. The most prominent supporters of this hypothesis are Duesberg himself, biochemist vitamin proponent David Rasnick, and journalist Celia Farber. The scientific community contends that Duesberg's arguments are the result of cherry-picking predominantly outdated scientific data and selectively ignoring evidence in favor of HIV's role in AIDS.\n\nDuesberg argues that there is a statistical correlation between trends in recreational drug use and trends in AIDS cases. He argues that the epidemic of AIDS cases in the 1980s corresponds to a supposed epidemic of recreational drug use in the United States and Europe during the same time frame.\n\nThese claims are not supported by epidemiologic data. The average yearly increase in opioid-related deaths from 1990 to 2002 was nearly three times the yearly increase from 1979–90, with the greatest increase in 2000–02, yet AIDS cases and deaths fell dramatically during the mid-to-late-1990s. Duesberg's claim that recreational drug use, rather than HIV, was the cause of AIDS has been specifically examined and found to be false. Cohort studies have found that only HIV-positive drug users develop opportunistic infections; HIV-negative drug users do not develop such infections, indicating that HIV rather than drug use is the cause of AIDS.\n\nDuesberg has also argued that nitrite inhalants were the cause of the epidemic of Kaposi sarcoma (KS) in gay men. However, this argument has been described as an example of the fallacy of a statistical confounding effect; it is now known that a herpesvirus, potentiated by HIV, is responsible for AIDS-associated KS.\n\nMoreover, in addition to recreational drugs, Duesberg argues that anti-HIV drugs such as zidovudine (AZT) can cause AIDS. Duesberg's claim that antiviral medication causes AIDS is regarded as disproven by the scientific community. Placebo-controlled studies have found that AZT as a single agent produces modest and short-lived improvements in survival and delays the development of opportunistic infections; it certainly did not cause AIDS, which develops in both treated and untreated study patients. With the subsequent development of protease inhibitors and highly active antiretroviral therapy, numerous studies have documented the fact that anti-HIV drugs prevent the development of AIDS and substantially prolong survival, further disproving the claim that these drugs \"cause\" AIDS.\n\nSeveral studies have specifically addressed Duesberg's claim that recreational drug abuse or sexual promiscuity were responsible for the manifestations of AIDS. An early study of his claims, published in \"Nature\" in 1993, found Duesberg's drug abuse-AIDS hypothesis to have \"no basis in fact.\"\n\nA large prospective study followed a group of 715 homosexual men in the Vancouver, Canada, area; approximately half were HIV-seropositive or became so during the follow-up period, and the remainder were HIV-seronegative. After more than 8 years of follow-up, despite similar rates of drug use, sexual contact, and other supposed risk factors in both groups, only the HIV-positive group suffered from opportunistic infections. Similarly, CD4 counts dropped in the patients who were HIV-infected, but remained stable in the HIV-negative patients, despite similar rates of risk behavior. The authors concluded that \"the risk-AIDS hypothesis ... is clearly rejected by our data,\" and that \"the evidence supports the hypothesis that HIV-1 has an integral role in the CD4 depletion and progressive immune dysfunction that characterise AIDS.\"\n\nSimilarly, the Multicenter AIDS Cohort Study (MACS) and the Women's Interagency HIV Study (WIHS)—which between them observed more than 8,000 Americans—demonstrated that \"the presence of HIV infection is the only factor that is strongly and consistently associated with the conditions that define AIDS.\" A 2008 study found that recreational drug use (including cannabis, cocaine, poppers, and amphetamines) had no effect on CD4 or CD8 T-cell counts, providing further evidence against a role of recreational drugs as a cause of AIDS.\n\nDuesberg argued in 1989 that a significant number of AIDS victims had died without proof of HIV infection. However, with the use of modern culture techniques and polymerase chain reaction testing, HIV can be demonstrated in virtually all patients with AIDS. Since AIDS is now defined partially by the presence of HIV, Duesberg claims it is impossible by definition to offer evidence that AIDS doesn't require HIV. However, the first definitions of AIDS mentioned no cause and the first AIDS diagnoses were made before HIV was discovered. The addition of HIV positivity to surveillance criteria as an absolutely necessary condition for case reporting occurred only in 1993, after a scientific consensus was established that HIV caused AIDS.\n\nAccording to the Duesberg hypothesis, AIDS is not found in Africa. What Duesberg calls \"the myth of an African AIDS epidemic,\" among people\" exists for several reasons, including:\n\nDuesberg states that African AIDS cases are \"a collection of long-established, indigenous diseases, such as chronic fevers, weight loss, alias \"slim disease,\" diarrhea, and tuberculosis\" that result from malnutrition and poor sanitation. African AIDS cases, though, have increased in the last three decades as HIV's prevalence has increased but as malnutrition percentages and poor sanitation have declined in many African regions. In addition, while HIV and AIDS are more prevalent in urban than in rural settings in Africa, malnutrition and poor sanitation are found more commonly in rural than in urban settings.\n\nAccording to Duesberg, common diseases are easily misdiagnosed as AIDS in Africa because \"the diagnosis of African AIDS is arbitrary\" and does not include HIV testing. A definition of AIDS agreed upon in 1985 by the World Health Organization in Bangui did not require a positive HIV test, but since 1985, many African countries have added positive HIV tests to the Bangui criteria for AIDS or changed their definitions to match those of the U.S. Centers for Disease Control. One of the reasons for using more HIV tests despite their expense is that, rather than overestimating AIDS as Duesberg suggests, the Bangui definition alone excluded nearly half of African AIDS patients.\"\n\nDuesberg notes that diseases associated with AIDS differ between African and Western populations, concluding that the causes of immunodeficiency must be different. Tuberculosis is much more commonly diagnosed among AIDS patients in Africa than in Western countries, while PCP conforms to the opposite pattern. Tuberculosis, though, had higher prevalence in Africa than in the West before the spread of HIV. In Africa and the United States, HIV has spurred a similar percentage increase in tuberculosis cases. PCP may be underestimated in Africa: since machinery \"required for accurate testing is relatively rare in many resource-poor areas, including large parts of Africa, PCP is likely to be underdiagnosed in Africa. Consistent with this hypothesis, studies that report the highest rates of PCP in Africa are those that use the most advanced diagnostic methods\" Duesberg also claims that Kaposi's Sarcoma is \"exclusively diagnosed in male homosexual risk groups using nitrite inhalants and other psychoactive drugs as aphrodisiacs\", but the cancer is fairly common among heterosexuals in some parts of Africa, and is found in heterosexuals in the United States as well.\n\nBecause reported AIDS cases in Africa and other parts of the developing world include a larger proportion of people who do not belong to Duesberg's preferred risk groups of drug addicts and male homosexuals, Duesberg writes on his website that \"There are no risk groups in Africa, like drug addicts and homosexuals.\" However, many studies have addressed the issue of risk groups in Africa and concluded that the risk of AIDS is not equally distributed. In addition, AIDS in Africa largely kills sexually active working-age adults.\n\nSouth African president Thabo Mbeki accepted Duesberg's hypothesis and, through the mid-2000s, rejected offers of medical assistance to fight HIV infection, a policy of inaction that cost over 300,000 lives.\n\nDuesberg argues that retroviruses like HIV must be harmless to survive: they do not kill cells and they do not cause cancer, he maintains. Duesberg writes, \"retroviruses do not kill cells because they depend on viable cells for the replication of their RNA from viral DNA integrated into cellular DNA.\" Duesberg elsewhere states that \"the typical virus reproduces by entering a living cell and commandeering the cell's resources in order to make new virus particles, a process that ends with the disintegration of the dead cell.\"\n\nDuesberg also rejects the involvement of retroviruses and other viruses in cancer. To him, virus-associated cancers are \"freak accidents of nature\" that do not warrant research programs such as the War on Cancer. Duesberg rejects a role in cancer for numerous viruses, including leukemia viruses, Epstein-Barr Virus, Human Papilloma Virus, Hepatitis B, Feline Leukemia Virus, and Human T-lymphotropic virus.\n\nDuesberg claims that the supposedly innocuous nature of all retroviruses is supported by what he considers to be their normal mode of proliferation: infection from mother to child \"in utero\". Duesberg does not suggest that HIV is an endogenous retrovirus, a virus integrated into the germ line and genetically heritable:\n\nThe consensus in the scientific community is that the Duesberg hypothesis has been refuted by a large and growing mass of evidence showing that HIV causes AIDS, that the amount of virus in the blood correlates with disease progression, that a plausible mechanism for HIV's action has been proposed, and that anti-HIV medication decreases mortality and opportunistic infection in people with AIDS.\n\nIn the 9 December 1994 issue of \"Science\" (Vol. 266, No. 5191), Duesberg's methods and claims were evaluated in a group of articles. The authors concluded that\n\nThe vast majority of people with AIDS have never received antiretroviral drugs, including those in developed countries prior to the licensure of AZT (zidovudine) in 1987, and people in developing countries today where very few individuals have access to these medications.\n\nThe NIAID reports that \"in the mid-1980s, clinical trials enrolling patients with AIDS found that AZT given as single-drug therapy conferred a modest survival advantage compared [with] placebo. Among HIV-infected patients who had not yet developed AIDS, placebo-controlled trials found that AZT given as single-drug therapy delayed, for a year or two, the onset of AIDS-related illnesses. Significantly, long-term follow-up of these trials did not show a prolonged benefit of AZT, but also did not indicate that the drug increased disease progression or mortality. The lack of excess AIDS cases and death in the AZT arms of these placebo-controlled trials in effect counters the argument that AZT causes AIDS. Subsequent clinical trials found that patients receiving two-drug combinations had up to 50 percent improvements in time to progression to AIDS and in survival when compared with people receiving single-drug therapy. In more recent years, three-drug combination therapies have produced another 50 to 80 percent improvement in progression to AIDS and in survival when compared with two-drug regimens in clinical trials.\" \"Use of potent anti-HIV combination therapies has contributed to dramatic reductions in the incidence of AIDS and AIDS-related deaths in populations where these drugs are widely available, an effect which clearly would not be seen if antiretroviral drugs caused AIDS.\"\n\nDuesberg claims as support for his idea that many drug-free HIV-positive people have not yet developed AIDS; HIV/AIDS scientists note that many drug-free HIV-positive people have developed AIDS, and that, in the absence of medical treatment or rare genetic factors postulated to delay disease progression, it is very likely that nearly all HIV-positive people will eventually develop AIDS. Scientists also note that HIV-negative drug users do not suffer from immune system collapse.\n\n\n"}
{"id": "8310", "url": "https://en.wikipedia.org/wiki?curid=8310", "title": "DSL (disambiguation)", "text": "DSL (disambiguation)\n\nDSL or digital subscriber line is a family of technologies that provide digital data transmission over the wires of a local telephone network.\n\nDSL may also refer to:\n"}
{"id": "8311", "url": "https://en.wikipedia.org/wiki?curid=8311", "title": "Dinosaur", "text": "Dinosaur\n\nDinosaurs are a diverse group of reptiles of the clade Dinosauria. They first appeared during the Triassic period, between 243 and 233.23 million years ago, although the exact origin and timing of the evolution of dinosaurs is the subject of active research. They became the dominant terrestrial vertebrates after the Triassic–Jurassic extinction event 201 million years ago; their dominance continued through the Jurassic and Cretaceous periods. Reverse genetic engineering and the fossil record both demonstrate that birds are modern feathered dinosaurs, having evolved from earlier theropods during the late Jurassic Period. As such, birds were the only dinosaur lineage to survive the Cretaceous–Paleogene extinction event 66 million years ago. Dinosaurs can therefore be divided into \"avian dinosaurs\", or birds; and \"non-avian dinosaurs\", which are all dinosaurs other than birds. This article deals primarily with non-avian dinosaurs.\n\nDinosaurs are a varied group of animals from taxonomic, morphological and ecological standpoints. Birds, at over 10,000 living species, are the most diverse group of vertebrates besides perciform fish. Using fossil evidence, paleontologists have identified over 500 distinct genera and more than 1,000 different species of non-avian dinosaurs. Dinosaurs are represented on every continent by both extant species (birds) and fossil remains. Through the first half of the 20th century, before birds were recognized to be dinosaurs, most of the scientific community believed dinosaurs to have been sluggish and cold-blooded. Most research conducted since the 1970s, however, has indicated that all dinosaurs were active animals with elevated metabolisms and numerous adaptations for social interaction. Some were herbivorous, others carnivorous. Evidence suggests that egg-laying and nest-building are additional traits shared by all dinosaurs, avian and non-avian alike.\n\nWhile dinosaurs were ancestrally bipedal, many extinct groups included quadrupedal species, and some were able to shift between these stances. Elaborate display structures such as horns or crests are common to all dinosaur groups, and some extinct groups developed skeletal modifications such as bony armor and spines. While the dinosaurs' modern-day surviving avian lineage (birds) are generally small due to the constraints of flight, many prehistoric dinosaurs (non-avian and avian) were large-bodied—the largest sauropod dinosaurs are estimated to have reached lengths of and heights of and were the largest land animals of all time. Still, the idea that non-avian dinosaurs were uniformly gigantic is a misconception based in part on preservation bias, as large, sturdy bones are more likely to last until they are fossilized. Many dinosaurs were quite small: \"Xixianykus\", for example, was only about long.\n\nSince the first dinosaur fossils were recognized in the early 19th century, mounted fossil dinosaur skeletons have been major attractions at museums around the world, and dinosaurs have become an enduring part of world culture. The large sizes of some dinosaur groups, as well as their seemingly monstrous and fantastic nature, have ensured dinosaurs' regular appearance in best-selling books and films, such as \"Jurassic Park\". Persistent public enthusiasm for the animals has resulted in significant funding for dinosaur science, and new discoveries are regularly covered by the media.\n\nThe taxon 'Dinosauria' was formally named in 1841 by paleontologist Sir Richard Owen, who used it to refer to the \"distinct tribe or sub-order of Saurian Reptiles\" that were then being recognized in England and around the world. The term is derived . Though the taxonomic name has often been interpreted as a reference to dinosaurs' teeth, claws, and other fearsome characteristics, Owen intended it merely to evoke their size and majesty.\n\nOther prehistoric animals, including pterosaurs, mosasaurs, ichthyosaurs, plesiosaurs, and \"Dimetrodon\", while often popularly conceived of as dinosaurs, are not taxonomically classified as dinosaurs. Pterosaurs are distantly related to dinosaurs, being members of the clade Ornithodira. The other groups mentioned are, like dinosaurs and pterosaurs, members of Sauropsida (the reptile and bird clade), except \"Dimetrodon\" (which is a synapsid).\n\nUnder phylogenetic nomenclature, dinosaurs are usually defined as the group consisting of the most recent common ancestor (MRCA) of \"Triceratops\" and Neornithes, and all its descendants. It has also been suggested that Dinosauria be defined with respect to the MRCA of \"Megalosaurus\" and \"Iguanodon\", because these were two of the three genera cited by Richard Owen when he recognized the Dinosauria. Both definitions result in the same set of animals being defined as dinosaurs: \"Dinosauria = Ornithischia + Saurischia\", encompassing ankylosaurians (armored herbivorous quadrupeds), stegosaurians (plated herbivorous quadrupeds), ceratopsians (herbivorous quadrupeds with horns and frills), ornithopods (bipedal or quadrupedal herbivores including \"duck-bills\"), theropods (mostly bipedal carnivores and birds), and sauropodomorphs (mostly large herbivorous quadrupeds with long necks and tails).\n\nBirds are now recognized as being the sole surviving lineage of theropod dinosaurs. In traditional taxonomy, birds were considered a separate class that had evolved from dinosaurs, a distinct superorder. However, a majority of contemporary paleontologists concerned with dinosaurs reject the traditional style of classification in favor of phylogenetic taxonomy; this approach requires that, for a group to be natural, all descendants of members of the group must be included in the group as well. Birds are thus considered to be dinosaurs and dinosaurs are, therefore, not extinct. Birds are classified as belonging to the subgroup Maniraptora, which are coelurosaurs, which are theropods, which are saurischians, which are dinosaurs.\n\nResearch by Matthew Baron, David B. Norman, and Paul M. Barrett in 2017 suggested a radical revision of dinosaurian systematics. Phylogenetic analysis by Baron \"et al.\" recovered the Ornithischia as being closer to the Theropoda than the Sauropodomorpha, as opposed to the traditional union of theropods with sauropodomorphs. They resurrected the clade Ornithoscelida to refer to the group containing Ornithischia and Theropoda. Dinosauria itself was re-defined as the last common ancestor of \"Triceratops horridus\", \"Passer domesticus\", \"Diplodocus carnegii\", and all of its descendants, to ensure that sauropods and kin remain included as dinosaurs.\n\nUsing one of the above definitions, dinosaurs can be generally described as archosaurs with hind limbs held erect beneath the body. Many prehistoric animal groups are popularly conceived of as dinosaurs, such as ichthyosaurs, mosasaurs, plesiosaurs, pterosaurs, and pelycosaurs (especially \"Dimetrodon\"), but are not classified scientifically as dinosaurs, and none had the erect hind limb posture characteristic of true dinosaurs. Dinosaurs were the dominant terrestrial vertebrates of the Mesozoic, especially the Jurassic and Cretaceous periods. Other groups of animals were restricted in size and niches; mammals, for example, rarely exceeded the size of a domestic cat, and were generally rodent-sized carnivores of small prey.\n\nDinosaurs have always been an extremely varied group of animals; according to a 2006 study, over 500 non-avian dinosaur genera have been identified with certainty so far, and the total number of genera preserved in the fossil record has been estimated at around 1850, nearly 75% of which remain to be discovered. An earlier study predicted that about 3,400 dinosaur genera existed, including many that would not have been preserved in the fossil record. By September 17, 2008, 1,047 different species of dinosaurs had been named.\n\nIn 2016, the estimated number of dinosaur species that existed in the Mesozoic era was estimated to be 1,543–2,468. Some are herbivorous, others carnivorous, including seed-eaters, fish-eaters, insectivores, and omnivores. While dinosaurs were ancestrally bipedal (as are all modern birds), some prehistoric species were quadrupeds, and others, such as \"Anchisaurus\" and \"Iguanodon\", could walk just as easily on two or four legs. Cranial modifications like horns and crests are common dinosaurian traits, and some extinct species had bony armor. Although known for large size, many Mesozoic dinosaurs were human-sized or smaller, and modern birds are generally small in size. Dinosaurs today inhabit every continent, and fossils show that they had achieved global distribution by at least the early Jurassic period. Modern birds inhabit most available habitats, from terrestrial to marine, and there is evidence that some non-avian dinosaurs (such as \"Microraptor\") could fly or at least glide, and others, such as spinosaurids, had semiaquatic habits.\n\nWhile recent discoveries have made it more difficult to present a universally agreed-upon list of dinosaurs' distinguishing features, nearly all dinosaurs discovered so far share certain modifications to the ancestral archosaurian skeleton, or are clear descendants of older dinosaurs showing these modifications. Although some later groups of dinosaurs featured further modified versions of these traits, they are considered typical for Dinosauria; the earliest dinosaurs had them and passed them on to their descendants. Such modifications, originating in the most recent common ancestor of a certain taxonomic group, are called the synapomorphies of such a group.\n\nA detailed assessment of archosaur interrelations by Sterling Nesbitt confirmed or found the following twelve unambiguous synapomorphies, some previously known:\n\nNesbitt found a number of further potential synapomorphies, and discounted a number of synapomorphies previously suggested. Some of these are also present in silesaurids, which Nesbitt recovered as a sister group to Dinosauria, including a large anterior trochanter, metatarsals II and IV of subequal length, reduced contact between ischium and pubis, the presence of a cnemial crest on the tibia and of an ascending process on the astragalus, and many others.\n\nA variety of other skeletal features are shared by dinosaurs. However, because they are either common to other groups of archosaurs or were not present in all early dinosaurs, these features are not considered to be synapomorphies. For example, as diapsids, dinosaurs ancestrally had two pairs of temporal fenestrae (openings in the skull behind the eyes), and as members of the diapsid group Archosauria, had additional openings in the snout and lower jaw. Additionally, several characteristics once thought to be synapomorphies are now known to have appeared before dinosaurs, or were absent in the earliest dinosaurs and independently evolved by different dinosaur groups. These include an elongated scapula, or shoulder blade; a sacrum composed of three or more fused vertebrae (three are found in some other archosaurs, but only two are found in \"Herrerasaurus\"); and a perforate acetabulum, or hip socket, with a hole at the center of its inside surface (closed in \"Saturnalia\", for example). Another difficulty of determining distinctly dinosaurian features is that early dinosaurs and other archosaurs from the late Triassic are often poorly known and were similar in many ways; these animals have sometimes been misidentified in the literature.\n\nDinosaurs stand with their hind limbs erect in a manner similar to most modern mammals, but distinct from most other reptiles, whose limbs sprawl out to either side. This posture is due to the development of a laterally facing recess in the pelvis (usually an open socket) and a corresponding inwardly facing distinct head on the femur. Their erect posture enabled early dinosaurs to breathe easily while moving, which likely permitted stamina and activity levels that surpassed those of \"sprawling\" reptiles. Erect limbs probably also helped support the evolution of large size by reducing bending stresses on limbs. Some non-dinosaurian archosaurs, including rauisuchians, also had erect limbs but achieved this by a \"pillar erect\" configuration of the hip joint, where instead of having a projection from the femur insert on a socket on the hip, the upper pelvic bone was rotated to form an overhanging shelf.\n\nDinosaurs diverged from their archosaur ancestors during the middle to late Triassic period, roughly 20 million years after the Permian–Triassic extinction event wiped out an estimated 95% of all life on Earth. Radiometric dating of the rock formation that contained fossils from the early dinosaur genus \"Eoraptor\" at 231.4 million years old establishes its presence in the fossil record at this time. Paleontologists think that \"Eoraptor\" resembles the common ancestor of all dinosaurs; if this is true, its traits suggest that the first dinosaurs were small, bipedal predators. The discovery of primitive, dinosaur-like ornithodirans such as \"Marasuchus\" and \"Lagerpeton\" in Argentinian Middle Triassic strata supports this view; analysis of recovered fossils suggests that these animals were indeed small, bipedal predators. Dinosaurs may have appeared as early as 243 million years ago, as evidenced by remains of the genus \"Nyasasaurus\" from that period, though known fossils of these animals are too fragmentary to tell if they are dinosaurs or very close dinosaurian relatives. Recently, it has been determined that \"Staurikosaurus\" from the Santa Maria Formation dates to 233.23 Ma, making it older in geologic age than \"Eoraptor\".\n\nWhen dinosaurs appeared, they were not the dominant terrestrial animals. The terrestrial habitats were occupied by various types of archosauromorphs and therapsids, like cynodonts and rhynchosaurs. Their main competitors were the pseudosuchia, such as aetosaurs, ornithosuchids and rauisuchians, which were more successful than the dinosaurs. Most of these other animals became extinct in the Triassic, in one of two events. First, at about 215 million years ago, a variety of basal archosauromorphs, including the protorosaurs, became extinct. This was followed by the Triassic–Jurassic extinction event (about 200 million years ago), that saw the end of most of the other groups of early archosaurs, like aetosaurs, ornithosuchids, phytosaurs, and rauisuchians. Rhynchosaurs and dicynodonts survived (at least in some areas) at least as late as early-mid Norian and late Norian or earliest Rhaetian, respectively, and the exact date of their extinction is uncertain. These losses left behind a land fauna of crocodylomorphs, dinosaurs, mammals, pterosaurians, and turtles. The first few lines of early dinosaurs diversified through the Carnian and Norian stages of the Triassic, possibly by occupying the niches of the groups that became extinct. Also notably, there was a heightened rate of extinction during the Carnian Pluvial Event.\n\nDinosaur evolution after the Triassic follows changes in vegetation and the location of continents. In the late Triassic and early Jurassic, the continents were connected as the single landmass Pangaea, and there was a worldwide dinosaur fauna mostly composed of coelophysoid carnivores and early sauropodomorph herbivores. Gymnosperm plants (particularly conifers), a potential food source, radiated in the late Triassic. Early sauropodomorphs did not have sophisticated mechanisms for processing food in the mouth, and so must have employed other means of breaking down food farther along the digestive tract. The general homogeneity of dinosaurian faunas continued into the middle and late Jurassic, where most localities had predators consisting of ceratosaurians, spinosauroids, and carnosaurians, and herbivores consisting of stegosaurian ornithischians and large sauropods. Examples of this include the Morrison Formation of North America and Tendaguru Beds of Tanzania. Dinosaurs in China show some differences, with specialized sinraptorid theropods and unusual, long-necked sauropods like \"Mamenchisaurus\". Ankylosaurians and ornithopods were also becoming more common, but prosauropods had become extinct. Conifers and pteridophytes were the most common plants. Sauropods, like the earlier prosauropods, were not oral processors, but ornithischians were evolving various means of dealing with food in the mouth, including potential cheek-like organs to keep food in the mouth, and jaw motions to grind food. Another notable evolutionary event of the Jurassic was the appearance of true birds, descended from maniraptoran coelurosaurians.\n\nBy the early Cretaceous and the ongoing breakup of Pangaea, dinosaurs were becoming strongly differentiated by landmass. The earliest part of this time saw the spread of ankylosaurians, iguanodontians, and brachiosaurids through Europe, North America, and northern Africa. These were later supplemented or replaced in Africa by large spinosaurid and carcharodontosaurid theropods, and rebbachisaurid and titanosaurian sauropods, also found in South America. In Asia, maniraptoran coelurosaurians like dromaeosaurids, troodontids, and oviraptorosaurians became the common theropods, and ankylosaurids and early ceratopsians like \"Psittacosaurus\" became important herbivores. Meanwhile, Australia was home to a fauna of basal ankylosaurians, hypsilophodonts, and iguanodontians. The stegosaurians appear to have gone extinct at some point in the late early Cretaceous or early late Cretaceous. A major change in the early Cretaceous, which would be amplified in the late Cretaceous, was the evolution of flowering plants. At the same time, several groups of dinosaurian herbivores evolved more sophisticated ways to orally process food. Ceratopsians developed a method of slicing with teeth stacked on each other in batteries, and iguanodontians refined a method of grinding with tooth batteries, taken to its extreme in hadrosaurids. Some sauropods also evolved tooth batteries, best exemplified by the rebbachisaurid \"Nigersaurus\".\n\nThere were three general dinosaur faunas in the late Cretaceous. In the northern continents of North America and Asia, the major theropods were tyrannosaurids and various types of smaller maniraptoran theropods, with a predominantly ornithischian herbivore assemblage of hadrosaurids, ceratopsians, ankylosaurids, and pachycephalosaurians. In the southern continents that had made up the now-splitting Gondwana, abelisaurids were the common theropods, and titanosaurian sauropods the common herbivores. Finally, in Europe, dromaeosaurids, rhabdodontid iguanodontians, nodosaurid ankylosaurians, and titanosaurian sauropods were prevalent. Flowering plants were greatly radiating, with the first grasses appearing by the end of the Cretaceous. Grinding hadrosaurids and shearing ceratopsians became extremely diverse across North America and Asia. Theropods were also radiating as herbivores or omnivores, with therizinosaurians and ornithomimosaurians becoming common.\n\nThe Cretaceous–Paleogene extinction event, which occurred approximately 66 million years ago at the end of the Cretaceous period, caused the extinction of all dinosaur groups except for the neornithine birds. Some other diapsid groups, such as crocodilians, sebecosuchians, turtles, lizards, snakes, sphenodontians, and choristoderans, also survived the event.\n\nThe surviving lineages of neornithine birds, including the ancestors of modern ratites, ducks and chickens, and a variety of waterbirds, diversified rapidly at the beginning of the Paleogene period, entering ecological niches left vacant by the extinction of Mesozoic dinosaur groups such as the arboreal enantiornithines, aquatic hesperornithines, and even the larger terrestrial theropods (in the form of \"Gastornis\", eogruiids, bathornithids, ratites, geranoidids, mihirungs, and \"terror birds\"). It is often cited that mammals out-competed the neornithines for dominance of most terrestrial niches but many of these groups co-existed with rich mammalian faunas for most of the Cenozoic. Terror birds and bathornithids occupied carnivorous guilds alongside predatory mammals, and ratites are still fairly successful as mid-sized herbivores; eogruiids similarly lasted from the Eocene to Pliocene, only becoming extinct very recently after over 20 million years of co-existence with many mammal groups.\n\nDinosaurs belong to a group known as archosaurs, which also includes modern crocodilians. Within the archosaur group, dinosaurs are differentiated most noticeably by their gait. Dinosaur legs extend directly beneath the body, whereas the legs of lizards and crocodilians sprawl out to either side.\n\nCollectively, dinosaurs as a clade are divided into two primary branches, Saurischia and Ornithischia. Saurischia includes those taxa sharing a more recent common ancestor with birds than with Ornithischia, while Ornithischia includes all taxa sharing a more recent common ancestor with \"Triceratops\" than with Saurischia. Anatomically, these two groups can be distinguished most noticeably by their pelvic structure. Early saurischians—\"lizard-hipped\", from the Greek \"sauros\" (σαῦρος) meaning \"lizard\" and \"ischion\" (ἰσχίον) meaning \"hip joint\"—retained the hip structure of their ancestors, with a pubis bone directed cranially, or forward. This basic form was modified by rotating the pubis backward to varying degrees in several groups (\"Herrerasaurus\", therizinosauroids, dromaeosaurids, and birds). Saurischia includes the theropods (exclusively bipedal and with a wide variety of diets) and sauropodomorphs (long-necked herbivores which include advanced, quadrupedal groups).\n\nBy contrast, ornithischians—\"bird-hipped\", from the Greek \"ornitheios\" (ὀρνίθειος) meaning \"of a bird\" and \"ischion\" (ἰσχίον) meaning \"hip joint\"—had a pelvis that superficially resembled a bird's pelvis: the pubic bone was oriented caudally (rear-pointing). Unlike birds, the ornithischian pubis also usually had an additional forward-pointing process. Ornithischia includes a variety of species which were primarily herbivores. (NB: the terms \"lizard hip\" and \"bird hip\" are misnomers – birds evolved from dinosaurs with \"lizard hips\".)\n\nThe following is a simplified classification of dinosaur groups based on their evolutionary relationships, and organized based on the list of Mesozoic dinosaur species provided by Holtz (2007). A more detailed version can be found at Dinosaur classification.\nThe dagger (†) is used to signify groups with no living members.\n\nKnowledge about dinosaurs is derived from a variety of fossil and non-fossil records, including fossilized bones, feces, trackways, gastroliths, feathers, impressions of skin, internal organs and soft tissues. Many fields of study contribute to our understanding of dinosaurs, including physics (especially biomechanics), chemistry, biology, and the earth sciences (of which paleontology is a sub-discipline). Two topics of particular interest and study have been dinosaur size and behavior.\n\nCurrent evidence suggests that dinosaur average size varied through the Triassic, early Jurassic, late Jurassic and Cretaceous periods. Predatory theropod dinosaurs, which occupied most terrestrial carnivore niches during the Mesozoic, most often fall into the category when sorted by estimated weight into categories based on order of magnitude, whereas recent predatory carnivoran mammals peak in the category. The mode of Mesozoic dinosaur body masses is between one and ten metric tonnes. This contrasts sharply with the average size of Cenozoic mammals, estimated by the National Museum of Natural History as about .\n\nThe sauropods were the largest and heaviest dinosaurs. For much of the dinosaur era, the smallest sauropods were larger than anything else in their habitat, and the largest were an order of magnitude more massive than anything else that has since walked the Earth. Giant prehistoric mammals such as \"Paraceratherium\" (the largest land mammal ever) were dwarfed by the giant sauropods, and only modern whales approach or surpass them in size. There are several proposed advantages for the large size of sauropods, including protection from predation, reduction of energy use, and longevity, but it may be that the most important advantage was dietary. Large animals are more efficient at digestion than small animals, because food spends more time in their digestive systems. This also permits them to subsist on food with lower nutritive value than smaller animals. Sauropod remains are mostly found in rock formations interpreted as dry or seasonally dry, and the ability to eat large quantities of low-nutrient browse would have been advantageous in such environments.\n\nScientists will probably never be certain of the largest and smallest dinosaurs to have ever existed. This is because only a tiny percentage of animals ever fossilize, and most of these remain buried in the earth. Few of the specimens that are recovered are complete skeletons, and impressions of skin and other soft tissues are rare. Rebuilding a complete skeleton by comparing the size and morphology of bones to those of similar, better-known species is an inexact art, and reconstructing the muscles and other organs of the living animal is, at best, a process of educated guesswork.\nThe tallest and heaviest dinosaur known from good skeletons is \"Giraffatitan brancai\" (previously classified as a species of \"Brachiosaurus\"). Its remains were discovered in Tanzania between 1907 and 1912. Bones from several similar-sized individuals were incorporated into the skeleton now mounted and on display at the Museum für Naturkunde Berlin; this mount is tall and long, and would have belonged to an animal that weighed between and  kilograms ( and  lb). The longest complete dinosaur is the long \"Diplodocus\", which was discovered in Wyoming in the United States and displayed in Pittsburgh's Carnegie Natural History Museum in 1907. The longest dinosaur known from good fossil material is the \"Patagotitan\": the skeleton mount in the American Museum of Natural History is long. The Carmen Funes Museum has an \"Argentinosaurus\" reconstructed skeleton mount long.\n\nThere were larger dinosaurs, but knowledge of them is based entirely on a small number of fragmentary fossils. Most of the largest herbivorous specimens on record were discovered in the 1970s or later, and include the massive \"Argentinosaurus\", which may have weighed to  kilograms (90 to 110 short tons) and reached length of ; some of the longest were the long \"Diplodocus hallorum\" (formerly \"Seismosaurus\"), the long \"Supersaurus\" and long \"Patagotitan\"; and the tallest, the tall \"Sauroposeidon\", which could have reached a sixth-floor window. The heaviest and longest dinosaur may have been \"Amphicoelias fragillimus\", known only from a now lost partial vertebral neural arch described in 1878. Extrapolating from the illustration of this bone, the animal may have been long and weighed kg ( lb). However, as no further evidence of sauropods of this size has been found, and the discoverer, Edward Cope, had made typographic errors before, it is likely to have been an extreme overestimation.\n\nThe largest carnivorous dinosaur was \"Spinosaurus\", reaching a length of , and weighing 7–20.9 tonnes (7.7–23 short tons). Other large carnivorous theropods included \"Giganotosaurus\", \"Carcharodontosaurus\" and \"Tyrannosaurus\". \"Therizinosaurus\" and \"Deinocheirus\" were among the tallest of the theropods. The largest Ornithischian dinosaur was probably the hadrosaurid \"Shantungosaurus\" which measured and weighed about .\n\nThe smallest dinosaur known is the bee hummingbird, with a length of only and mass of around . The smallest known non-avialan dinosaurs were about the size of pigeons and were those theropods most closely related to birds. For example, \"Anchiornis huxleyi\" is currently the smallest non-avialan dinosaur described from an adult specimen, with an estimated weight of 110 grams and a total skeletal length of . The smallest herbivorous non-avialan dinosaurs included \"Microceratus\" and \"Wannanosaurus\", at about long each.\n\nMany modern birds are highly social, often found living in flocks. There is general agreement that some behaviors that are common in birds, as well as in crocodiles (birds' closest living relatives), were also common among extinct dinosaur groups. Interpretations of behavior in fossil species are generally based on the pose of skeletons and their habitat, computer simulations of their biomechanics, and comparisons with modern animals in similar ecological niches.\n\nThe first potential evidence for herding or flocking as a widespread behavior common to many dinosaur groups in addition to birds was the 1878 discovery of 31 \"Iguanodon bernissartensis\", ornithischians that were then thought to have perished together in Bernissart, Belgium, after they fell into a deep, flooded sinkhole and drowned. Other mass-death sites have been discovered subsequently. Those, along with multiple trackways, suggest that gregarious behavior was common in many early dinosaur species. Trackways of hundreds or even thousands of herbivores indicate that duck-bills (hadrosaurids) may have moved in great herds, like the American bison or the African Springbok. Sauropod tracks document that these animals traveled in groups composed of several different species, at least in Oxfordshire, England, although there is no evidence for specific herd structures. Congregating into herds may have evolved for defense, for migratory purposes, or to provide protection for young. There is evidence that many types of slow-growing dinosaurs, including various theropods, sauropods, ankylosaurians, ornithopods, and ceratopsians, formed aggregations of immature individuals. One example is a site in Inner Mongolia that has yielded the remains of over 20 \"Sinornithomimus\", from one to seven years old. This assemblage is interpreted as a social group that was trapped in mud. The interpretation of dinosaurs as gregarious has also extended to depicting carnivorous theropods as pack hunters working together to bring down large prey. However, this lifestyle is uncommon among modern birds, crocodiles, and other reptiles, and the taphonomic evidence suggesting mammal-like pack hunting in such theropods as \"Deinonychus\" and \"Allosaurus\" can also be interpreted as the results of fatal disputes between feeding animals, as is seen in many modern diapsid predators.\nThe crests and frills of some dinosaurs, like the marginocephalians, theropods and lambeosaurines, may have been too fragile to be used for active defense, and so they were likely used for sexual or aggressive displays, though little is known about dinosaur mating and territorialism. Head wounds from bites suggest that theropods, at least, engaged in active aggressive confrontations.\n\nFrom a behavioral standpoint, one of the most valuable dinosaur fossils was discovered in the Gobi Desert in 1971. It included a \"Velociraptor\" attacking a \"Protoceratops\", providing evidence that dinosaurs did indeed attack each other. Additional evidence for attacking live prey is the partially healed tail of an \"Edmontosaurus\", a hadrosaurid dinosaur; the tail is damaged in such a way that shows the animal was bitten by a tyrannosaur but survived. Cannibalism amongst some species of dinosaurs was confirmed by tooth marks found in Madagascar in 2003, involving the theropod \"Majungasaurus\".\n\nComparisons between the scleral rings of dinosaurs and modern birds and reptiles have been used to infer daily activity patterns of dinosaurs. Although it has been suggested that most dinosaurs were active during the day, these comparisons have shown that small predatory dinosaurs such as dromaeosaurids, \"Juravenator\", and \"Megapnosaurus\" were likely nocturnal. Large and medium-sized herbivorous and omnivorous dinosaurs such as ceratopsians, sauropodomorphs, hadrosaurids, ornithomimosaurs may have been cathemeral, active during short intervals throughout the day, although the small ornithischian \"Agilisaurus\" was inferred to be diurnal.\n\nBased on current fossil evidence from dinosaurs such as \"Oryctodromeus\", some ornithischian species seem to have led a partially fossorial (burrowing) lifestyle. Many modern birds are arboreal (tree climbing), and this was also true of many Mesozoic birds, especially the enantiornithines. While some early bird-like species may have already been arboreal as well (including dromaeosaurids such as \"Microraptor\") most non-avialan dinosaurs seem to have relied on land-based locomotion. A good understanding of how dinosaurs moved on the ground is key to models of dinosaur behavior; the science of biomechanics, pioneered by Robert McNeill Alexander, has provided significant insight in this area. For example, studies of the forces exerted by muscles and gravity on dinosaurs' skeletal structure have investigated how fast dinosaurs could run, whether diplodocids could create sonic booms via whip-like tail snapping, and whether sauropods could float.\n\nModern birds are known to communicate using visual and auditory signals, and the wide diversity of visual display structures among fossil dinosaur groups, such as horns, frills, crests, sails and feathers, suggests that visual communication has always been important in dinosaur biology. Reconstruction of the plumage color of \"Anchiornis huxleyi\", suggest the importance of color in visual communication in non-avian dinosaurs. The evolution of dinosaur vocalization is less certain. Paleontologist Phil Senter suggests that non-avian dinosaurs relied mostly on visual displays and possibly non-vocal acoustic sounds like hissing, jaw grinding or clapping, splashing and wing beating (possible in winged maniraptoran dinosaurs). He states they were unlikely to have been capable of vocalizing since their closest relatives, crocodilians and birds, use different means to vocalize, the former via the larynx and the latter through the unique syrinx, suggesting they evolved independently and their common ancestor was mute.\n\nThe earliest remains of a syrinx, which has enough mineral content for fossilization, was found in a specimen of the duck-like \"Vegavis iaai\" dated 69-66 million year ago, and this organ is unlikely to have existed in non-avian dinosaurs. However, in contrast to Senter, the researchers have suggested that dinosaurs could vocalize and that the syrinx-based vocal system of birds evolved from a larynx-based one, rather than the two systems evolving independently. A 2016 study suggests that dinosaurs produced closed mouth vocalizations like cooing, which occur in both crocodilians and birds as well as other reptiles. Such vocalizations evolved independently in extant archosaurs numerous times, following increases in body size. The crests of the Lambeosaurini and nasal chambers of ankylosaurids have been suggested to function in vocal resonance, though Senter states that the presence of resonance chambers in some dinosaurs is not necessarily evidence of vocalization as modern snakes have such chambers which intensify their hisses.\n\nAll dinosaurs lay amniotic eggs with hard shells made mostly of calcium carbonate. Eggs are usually laid in a nest. Most species create somewhat elaborate nests, which can be cups, domes, plates, beds scrapes, mounds, or burrows. Some species of modern bird have no nests; the cliff-nesting common guillemot lays its eggs on bare rock, and male emperor penguins keep eggs between their body and feet. Primitive birds and many non-avialan dinosaurs often lay eggs in communal nests, with males primarily incubating the eggs. While modern birds have only one functional oviduct and lay one egg at a time, more primitive birds and dinosaurs had two oviducts, like crocodiles. Some non-avialan dinosaurs, such as \"Troodon\", exhibited iterative laying, where the adult might lay a pair of eggs every one or two days, and then ensured simultaneous hatching by delaying brooding until all eggs were laid.\n\nWhen laying eggs, females grow a special type of bone between the hard outer bone and the marrow of their limbs. This medullary bone, which is rich in calcium, is used to make eggshells. A discovery of features in a \"Tyrannosaurus rex\" skeleton provided evidence of medullary bone in extinct dinosaurs and, for the first time, allowed paleontologists to establish the sex of a fossil dinosaur specimen. Further research has found medullary bone in the carnosaur \"Allosaurus\" and the ornithopod \"Tenontosaurus\". Because the line of dinosaurs that includes \"Allosaurus\" and \"Tyrannosaurus\" diverged from the line that led to \"Tenontosaurus\" very early in the evolution of dinosaurs, this suggests that the production of medullary tissue is a general characteristic of all dinosaurs.\nAnother widespread trait among modern birds (but see below in regards to fossil groups and extant megapodes) is parental care for young after hatching. Jack Horner's 1978 discovery of a \"Maiasaura\" (\"good mother lizard\") nesting ground in Montana demonstrated that parental care continued long after birth among ornithopods. A specimen of the Mongolian oviraptorid \"Citipati osmolskae\" was discovered in a chicken-like brooding position in 1993, which may indicate that they had begun using an insulating layer of feathers to keep the eggs warm. A dinosaur embryo (pertaining to the prosauropod \"Massospondylus\") was found without teeth, indicating that some parental care was required to feed the young dinosaurs. Trackways have also confirmed parental behavior among ornithopods from the Isle of Skye in northwestern Scotland.\n\nHowever, there is ample evidence of supreprecociality among many dinosaur species, particularly theropods. For instance, non-ornithuromorph birds have been abundantly demonstrated to have had slow growth rates, megapode-like egg burying behaviour and the ability to fly soon after birth. Both \"Tyrannosaurus rex\" and \"Troodon formosus\" display juveniles with clear supreprecociality and likely occupying different ecological niches than the adults. Superprecociality has been inferred for sauropods.\n\nBecause both modern crocodilians and birds have four-chambered hearts (albeit modified in crocodilians), it is likely that this is a trait shared by all archosaurs, including all dinosaurs. While all modern birds have high metabolisms and are \"warm blooded\" (endothermic), a vigorous debate has been ongoing since the 1960s regarding how far back in the dinosaur lineage this trait extends. Scientists disagree as to whether non-avian dinosaurs were endothermic, ectothermic, or some combination of both.\n\nAfter non-avian dinosaurs were discovered, paleontologists first posited that they were ectothermic. This supposed \"cold-bloodedness\" was used to imply that the ancient dinosaurs were relatively slow, sluggish organisms, even though many modern reptiles are fast and light-footed despite relying on external sources of heat to regulate their body temperature. The idea of dinosaurs as ectothermic and sluggish remained a prevalent view until Robert T. \"Bob\" Bakker, an early proponent of dinosaur endothermy, published an influential paper on the topic in 1968.\n\nModern evidence indicates that even non-avian dinosaurs and birds thrived in cooler temperate climates, and that at least some early species must have regulated their body temperature by internal biological means (aided by the animals' bulk in large species and feathers or other body coverings in smaller species). Evidence of endothermy in Mesozoic dinosaurs includes the discovery of polar dinosaurs in Australia and Antarctica as well as analysis of blood-vessel structures within fossil bones that are typical of endotherms. Scientific debate continues regarding the specific ways in which dinosaur temperature regulation evolved.\n\nIn saurischian dinosaurs, higher metabolisms were supported by the evolution of the avian respiratory system, characterized by an extensive system of air sacs that extended the lungs and invaded many of the bones in the skeleton, making them hollow. Early avian-style respiratory systems with air sacs may have been capable of sustaining higher activity levels than those of mammals of similar size and build. In addition to providing a very efficient supply of oxygen, the rapid airflow would have been an effective cooling mechanism, which is essential for animals that are active but too large to get rid of all the excess heat through their skin.\n\nLike other reptiles, dinosaurs are primarily uricotelic, that is, their kidneys extract nitrogenous wastes from their bloodstream and excrete it as uric acid instead of urea or ammonia via the ureters into the intestine. In most living species, uric acid is excreted along with feces as a semisolid waste. However, at least some modern birds (such as hummingbirds) can be facultatively ammonotelic, excreting most of the nitrogenous wastes as ammonia. They also excrete creatine, rather than creatinine like mammals. This material, as well as the output of the intestines, emerges from the cloaca. In addition, many species regurgitate pellets, and fossil pellets that may have come from dinosaurs are known from as long ago as the Cretaceous period.\n\nThe possibility that dinosaurs were the ancestors of birds was first suggested in 1868 by Thomas Henry Huxley. After the work of Gerhard Heilmann in the early 20th century, the theory of birds as dinosaur descendants was abandoned in favor of the idea of their being descendants of generalized thecodonts, with the key piece of evidence being the supposed lack of clavicles in dinosaurs. However, as later discoveries showed, clavicles (or a single fused wishbone, which derived from separate clavicles) were not actually absent; they had been found as early as 1924 in \"Oviraptor\", but misidentified as an interclavicle. In the 1970s, John Ostrom revived the dinosaur–bird theory, which gained momentum in the coming decades with the advent of cladistic analysis, and a great increase in the discovery of small theropods and early birds. Of particular note have been the fossils of the Yixian Formation, where a variety of theropods and early birds have been found, often with feathers of some type. Birds share over a hundred distinct anatomical features with theropod dinosaurs, which are now generally accepted to have been their closest ancient relatives.\nThey are most closely allied with maniraptoran coelurosaurs. A minority of scientists, most notably Alan Feduccia and Larry Martin, have proposed other evolutionary paths, including revised versions of Heilmann's basal archosaur proposal, or that maniraptoran theropods are the ancestors of birds but themselves are not dinosaurs, only convergent with dinosaurs.\n\nFeathers are one of the most recognizable characteristics of modern birds, and a trait that was shared by all other dinosaur groups. Based on the current distribution of fossil evidence, it appears that feathers were an ancestral dinosaurian trait, though one that may have been selectively lost in some species. Direct fossil evidence of feathers or feather-like structures has been discovered in a diverse array of species in many non-avian dinosaur groups, both among saurischians and ornithischians. Simple, branched, feather-like structures are known from heterodontosaurids, primitive neornithischians and theropods, and primitive ceratopsians. Evidence for true, vaned feathers similar to the flight feathers of modern birds has been found only in the theropod subgroup Maniraptora, which includes oviraptorosaurs, troodontids, dromaeosaurids, and birds. Feather-like structures known as pycnofibres have also been found in pterosaurs, suggesting the possibility that feather-like filaments may have been common in the bird lineage and evolved before the appearance of dinosaurs themselves. Research into the genetics of American alligators has also revealed that crocodylian scutes do possess feather-keratins during embryonic development, but these keratins are not expressed by the animals before hatching.\n\n\"Archaeopteryx\" was the first fossil found that revealed a potential connection between dinosaurs and birds. It is considered a transitional fossil, in that it displays features of both groups. Brought to light just two years after Darwin's seminal \"The Origin of Species\", its discovery spurred the nascent debate between proponents of evolutionary biology and creationism. This early bird is so dinosaur-like that, without a clear impression of feathers in the surrounding rock, at least one specimen was mistaken for \"Compsognathus\". Since the 1990s, a number of additional feathered dinosaurs have been found, providing even stronger evidence of the close relationship between dinosaurs and modern birds. Most of these specimens were unearthed in the lagerstätte of the Yixian Formation, Liaoning, northeastern China, which was part of an island continent during the Cretaceous. Though feathers have been found in only a few locations, it is possible that non-avian dinosaurs elsewhere in the world were also feathered. The lack of widespread fossil evidence for feathered non-avian dinosaurs may be because delicate features like skin and feathers are not often preserved by fossilization and thus are absent from the fossil record.\n\nThe description of feathered dinosaurs has not been without controversy; perhaps the most vocal critics have been Alan Feduccia and Theagarten Lingham-Soliar, who have proposed that some purported feather-like fossils are the result of the decomposition of collagenous fiber that underlaid the dinosaurs' skin, and that maniraptoran dinosaurs with vaned feathers were not actually dinosaurs, but convergent with dinosaurs. However, their views have for the most part not been accepted by other researchers, to the point that the scientific nature of Feduccia's proposals has been questioned.\n\nIn 2016, it was reported that a dinosaur tail with feathers had been found enclosed in amber. The fossil is about 99 million years old.\n\nBecause feathers are often associated with birds, feathered dinosaurs are often touted as the missing link between birds and dinosaurs. However, the multiple skeletal features also shared by the two groups represent another important line of evidence for paleontologists. Areas of the skeleton with important similarities include the neck, pubis, wrist (semi-lunate carpal), arm and pectoral girdle, furcula (wishbone), and breast bone. Comparison of bird and dinosaur skeletons through cladistic analysis strengthens the case for the link.\n\nLarge meat-eating dinosaurs had a complex system of air sacs similar to those found in modern birds, according to a 2005 investigation led by Patrick M. O'Connor. The lungs of theropod dinosaurs (carnivores that walked on two legs and had bird-like feet) likely pumped air into hollow sacs in their skeletons, as is the case in birds. \"What was once formally considered unique to birds was present in some form in the ancestors of birds\", O'Connor said. In 2008, scientists described \"Aerosteon riocoloradensis\", the skeleton of which supplies the strongest evidence to date of a dinosaur with a bird-like breathing system. CT-scanning of \"Aerosteon\"'s fossil bones revealed evidence for the existence of air sacs within the animal's body cavity.\n\nFossils of the troodonts \"Mei\" and \"Sinornithoides\" demonstrate that some dinosaurs slept with their heads tucked under their arms. This behavior, which may have helped to keep the head warm, is also characteristic of modern birds. Several deinonychosaur and oviraptorosaur specimens have also been found preserved on top of their nests, likely brooding in a bird-like manner. The ratio between egg volume and body mass of adults among these dinosaurs suggest that the eggs were primarily brooded by the male, and that the young were highly precocial, similar to many modern ground-dwelling birds.\n\nSome dinosaurs are known to have used gizzard stones like modern birds. These stones are swallowed by animals to aid digestion and break down food and hard fibers once they enter the stomach. When found in association with fossils, gizzard stones are called gastroliths.\n\nThe discovery that birds are a type of dinosaur showed that dinosaurs in general are not, in fact, extinct as is commonly stated. However, all non-avian dinosaurs, estimated to have been 628-1078 species, as well as many groups of birds did suddenly become extinct approximately 66 million years ago. It has been suggested that because small mammals, squamata and birds occupied the ecological niches suited for small body size, non-avian dinosaurs never evolved a diverse fauna of small-bodied species, which led to their downfall when large-bodied terrestrial tetrapods were hit by the mass extinction event. Many other groups of animals also became extinct at this time, including ammonites (nautilus-like mollusks), mosasaurs, plesiosaurs, pterosaurs, and many groups of mammals. Significantly, the insects suffered no discernible population loss, which left them available as food for other survivors. This mass extinction is known as the Cretaceous–Paleogene extinction event. The nature of the event that caused this mass extinction has been extensively studied since the 1970s; at present, several related theories are supported by paleontologists. Though the consensus is that an impact event was the primary cause of dinosaur extinction, some scientists cite other possible causes, or support the idea that a confluence of several factors was responsible for the sudden disappearance of dinosaurs from the fossil record.\n\nThe asteroid collision theory, which was brought to wide attention in 1980 by Walter Alvarez and colleagues, links the extinction event at the end of the Cretaceous period to a bolide impact approximately 66 million years ago. Alvarez \"et al.\" proposed that a sudden increase in iridium levels, recorded around the world in the period's rock stratum, was direct evidence of the impact. The bulk of the evidence now suggests that a bolide wide hit in the vicinity of the Yucatán Peninsula (in southeastern Mexico), creating the approximately Chicxulub Crater and triggering the mass extinction. Scientists are not certain whether dinosaurs were thriving or declining before the impact event. Some scientists propose that the meteorite impact caused a long and unnatural drop in Earth's atmospheric temperature, while others claim that it would have instead created an unusual heat wave. The consensus among scientists who support this theory is that the impact caused extinctions both directly (by heat from the meteorite impact) and also indirectly (via a worldwide cooling brought about when matter ejected from the impact crater reflected thermal radiation from the sun). Although the speed of extinction cannot be deduced from the fossil record alone, various models suggest that the extinction was extremely rapid, being down to hours rather than years.\n\nBefore 2000, arguments that the Deccan Traps flood basalts caused the extinction were usually linked to the view that the extinction was gradual, as the flood basalt events were thought to have started around 68 million years ago and lasted for over 2 million years. However, there is evidence that two thirds of the Deccan Traps were created in only 1 million years about 66 million years ago, and so these eruptions would have caused a fairly rapid extinction, possibly over a period of thousands of years, but still longer than would be expected from a single impact event.\n\nThe Deccan Traps in India could have caused extinction through several mechanisms, including the release into the air of dust and sulfuric aerosols, which might have blocked sunlight and thereby reduced photosynthesis in plants. In addition, Deccan Trap volcanism might have resulted in carbon dioxide emissions, which would have increased the greenhouse effect when the dust and aerosols cleared from the atmosphere. Before the mass extinction of the dinosaurs, the release of volcanic gases during the formation of the Deccan Traps \"contributed to an apparently massive global warming. Some data point to an average rise in temperature of in the last half million years before the impact [at Chicxulub].\"\n\nIn the years when the Deccan Traps hypothesis was linked to a slower extinction, Luis Alvarez (who died in 1988) replied that paleontologists were being misled by sparse data. While his assertion was not initially well-received, later intensive field studies of fossil beds lent weight to his claim. Eventually, most paleontologists began to accept the idea that the mass extinctions at the end of the Cretaceous were largely or at least partly due to a massive Earth impact. However, even Walter Alvarez has acknowledged that there were other major changes on Earth even before the impact, such as a drop in sea level and massive volcanic eruptions that produced the Indian Deccan Traps, and these may have contributed to the extinctions.\n\nNon-avian dinosaur remains are occasionally found above the Cretaceous–Paleogene boundary. In 2001, paleontologists Zielinski and Budahn reported the discovery of a single hadrosaur leg-bone fossil in the San Juan Basin, New Mexico, and described it as evidence of Paleocene dinosaurs. The formation in which the bone was discovered has been dated to the early Paleocene epoch, approximately 64.5 million years ago. If the bone was not re-deposited into that stratum by weathering action, it would provide evidence that some dinosaur populations may have survived at least a half million years into the Cenozoic Era. Other evidence includes the finding of dinosaur remains in the Hell Creek Formation up to above the Cretaceous–Paleogene boundary, representing  years of elapsed time. Similar reports have come from other parts of the world, including China. Many scientists, however, dismissed the supposed Paleocene dinosaurs as re-worked, that is, washed out of their original locations and then re-buried in much later sediments. Direct dating of the bones themselves has supported the later date, with U–Pb dating methods resulting in a precise age of 64.8 ± 0.9 million years ago. If correct, the presence of a handful of dinosaurs in the early Paleocene would not change the underlying facts of the extinction.\n\nDinosaur fossils have been known for millennia, although their true nature was not recognized. The Chinese considered them to be dragon bones and documented them as such. For example, \"Hua Yang Guo Zhi\", a book written by Chang Qu during the Western Jin Dynasty (265–316), reported the discovery of dragon bones at Wucheng in Sichuan Province. Villagers in central China have long unearthed fossilized \"dragon bones\" for use in traditional medicines, a practice that continues today. In Europe, dinosaur fossils were generally believed to be the remains of giants and other biblical creatures.\n\nScholarly descriptions of what would now be recognized as dinosaur bones first appeared in the late 17th century in England. Part of a bone, now known to have been the femur of a \"Megalosaurus\", was recovered from a limestone quarry at Cornwell near Chipping Norton, Oxfordshire, in 1676. The fragment was sent to Robert Plot, Professor of Chemistry at the University of Oxford and first curator of the Ashmolean Museum, who published a description in his \"Natural History of Oxfordshire\" in 1677. He correctly identified the bone as the lower extremity of the femur of a large animal, and recognized that it was too large to belong to any known species. He therefore concluded it to be the thigh bone of a giant human similar to those mentioned in the Bible. In 1699, Edward Lhuyd, a friend of Sir Isaac Newton, was responsible for the first published scientific treatment of what would now be recognized as a dinosaur when he described and named a sauropod tooth, \"Rutellum implicatum\", that had been found in Caswell, near Witney, Oxfordshire.\nBetween 1815 and 1824, the Rev William Buckland, a professor of geology at Oxford, collected more fossilized bones of \"Megalosaurus\" and became the first person to describe a dinosaur in a scientific journal. The second dinosaur genus to be identified, \"Iguanodon\", was discovered in 1822 by Mary Ann Mantell – the wife of English geologist Gideon Mantell. Gideon Mantell recognized similarities between his fossils and the bones of modern iguanas. He published his findings in 1825.\n\nThe study of these \"great fossil lizards\" soon became of great interest to European and American scientists, and in 1842 the English paleontologist Richard Owen coined the term \"dinosaur\". He recognized that the remains that had been found so far, \"Iguanodon\", \"Megalosaurus\" and \"Hylaeosaurus\", shared a number of distinctive features, and so decided to present them as a distinct taxonomic group. With the backing of Prince Albert, the husband of Queen Victoria, Owen established the Natural History Museum, London, to display the national collection of dinosaur fossils and other biological and geological exhibits.\n\nIn 1858, William Parker Foulke discovered the first known American dinosaur, in marl pits in the small town of Haddonfield, New Jersey. (Although fossils had been found before, their nature had not been correctly discerned.) The creature was named \"Hadrosaurus foulkii\". It was an extremely important find: \"Hadrosaurus\" was one of the first nearly complete dinosaur skeletons found (the first was in 1834, in Maidstone, England), and it was clearly a bipedal creature. This was a revolutionary discovery as, until that point, most scientists had believed dinosaurs walked on four feet, like other lizards. Foulke's discoveries sparked a wave of dinosaur mania in the United States.\n\nDinosaur mania was exemplified by the fierce rivalry between Edward Drinker Cope and Othniel Charles Marsh, both of whom raced to be the first to find new dinosaurs in what came to be known as the Bone Wars. The feud probably originated when Marsh publicly pointed out that Cope's reconstruction of an \"Elasmosaurus\" skeleton was flawed: Cope had inadvertently placed the plesiosaur's head at what should have been the animal's tail end. The fight between the two scientists lasted for over 30 years, ending in 1897 when Cope died after spending his entire fortune on the dinosaur hunt. Marsh 'won' the contest primarily because he was better funded through a relationship with the US Geological Survey. Unfortunately, many valuable dinosaur specimens were damaged or destroyed due to the pair's rough methods: for example, their diggers often used dynamite to unearth bones (a method modern paleontologists would find appalling). Despite their unrefined methods, the contributions of Cope and Marsh to paleontology were vast: Marsh unearthed 86 new species of dinosaur and Cope discovered 56, a total of 142 new species. Cope's collection is now at the American Museum of Natural History in New York, while Marsh's is on display at the Peabody Museum of Natural History at Yale University.\n\nAfter 1897, the search for dinosaur fossils extended to every continent, including Antarctica. The first Antarctic dinosaur to be discovered, the ankylosaurid \"Antarctopelta oliveroi\", was found on James Ross Island in 1986, although it was 1994 before an Antarctic species, the theropod \"Cryolophosaurus ellioti\", was formally named and described in a scientific journal.\n\nCurrent dinosaur \"hot spots\" include southern South America (especially Argentina) and China. China in particular has produced many exceptional feathered dinosaur specimens due to the unique geology of its dinosaur beds, as well as an ancient arid climate particularly conducive to fossilization.\n\nThe field of dinosaur research has enjoyed a surge in activity that began in the 1970s and is ongoing. This was triggered, in part, by John Ostrom's discovery of \"Deinonychus\", an active predator that may have been warm-blooded, in marked contrast to the then-prevailing image of dinosaurs as sluggish and cold-blooded. Vertebrate paleontology has become a global science. Major new dinosaur discoveries have been made by paleontologists working in previously unexploited regions, including India, South America, Madagascar, Antarctica, and most significantly China (the amazingly well-preserved feathered dinosaurs in China have further consolidated the link between dinosaurs and their living descendants, modern birds). The widespread application of cladistics, which rigorously analyzes the relationships between biological organisms, has also proved tremendously useful in classifying dinosaurs. Cladistic analysis, among other modern techniques, helps to compensate for an often incomplete and fragmentary fossil record.\n\nOne of the best examples of soft-tissue impressions in a fossil dinosaur was discovered in Pietraroia, Italy. The discovery was reported in 1998, and described the specimen of a small, very young coelurosaur, \"Scipionyx samniticus\". The fossil includes portions of the intestines, colon, liver, muscles, and windpipe of this immature dinosaur.\n\nIn the March 2005 issue of \"Science\", the paleontologist Mary Higby Schweitzer and her team announced the discovery of flexible material resembling actual soft tissue inside a 68-million-year-old \"Tyrannosaurus rex\" leg bone from the Hell Creek Formation in Montana. After recovery, the tissue was rehydrated by the science team. When the fossilized bone was treated over several weeks to remove mineral content from the fossilized bone-marrow cavity (a process called demineralization), Schweitzer found evidence of intact structures such as blood vessels, bone matrix, and connective tissue (bone fibers). Scrutiny under the microscope further revealed that the putative dinosaur soft tissue had retained fine structures (microstructures) even at the cellular level. The exact nature and composition of this material, and the implications of Schweitzer's discovery, are not yet clear.\n\nIn 2009, a team including Schweitzer announced that, using even more careful methodology, they had duplicated their results by finding similar soft tissue in a duck-billed dinosaur, \"Brachylophosaurus canadensis\", found in the Judith River Formation of Montana. This included even more detailed tissue, down to preserved bone cells that seem even to have visible remnants of nuclei and what seem to be red blood cells. Among other materials found in the bone was collagen, as in the \"Tyrannosaurus\" bone. The type of collagen an animal has in its bones varies according to its DNA and, in both cases, this collagen was of the same type found in modern chickens and ostriches.\n\nThe extraction of ancient DNA from dinosaur fossils has been reported on two separate occasions; upon further inspection and peer review, however, neither of these reports could be confirmed. However, a functional peptide involved in the vision of a theoretical dinosaur has been inferred using analytical phylogenetic reconstruction methods on gene sequences of related modern species such as reptiles and birds. In addition, several proteins, including hemoglobin, have putatively been detected in dinosaur fossils.\n\nIn 2015, researchers reported finding structures similar to blood cells and collagen fibers, preserved in the bone fossils of six Cretaceous dinosaur specimens, which are approximately 75 million years old.\n\nBy human standards, dinosaurs were creatures of fantastic appearance and often enormous size. As such, they have captured the popular imagination and become an enduring part of human culture. Entry of the word \"dinosaur\" into the common vernacular reflects the animals' cultural importance: in English, \"dinosaur\" is commonly used to describe anything that is impractically large, obsolete, or bound for extinction.\n\nPublic enthusiasm for dinosaurs first developed in Victorian England, where in 1854, three decades after the first scientific descriptions of dinosaur remains, a menagerie of lifelike dinosaur sculptures were unveiled in London's Crystal Palace Park. The Crystal Palace dinosaurs proved so popular that a strong market in smaller replicas soon developed. In subsequent decades, dinosaur exhibits opened at parks and museums around the world, ensuring that successive generations would be introduced to the animals in an immersive and exciting way. Dinosaurs' enduring popularity, in its turn, has resulted in significant public funding for dinosaur science, and has frequently spurred new discoveries. In the United States, for example, the competition between museums for public attention led directly to the Bone Wars of the 1880s and 1890s, during which a pair of feuding paleontologists made enormous scientific contributions.\n\nThe popular preoccupation with dinosaurs has ensured their appearance in literature, film, and other media. Beginning in 1852 with a passing mention in Charles Dickens \"Bleak House\", dinosaurs have been featured in large numbers of fictional works. Jules Verne's 1864 novel \"Journey to the Center of the Earth\", Sir Arthur Conan Doyle's 1912 book \"The Lost World\", the iconic 1933 film \"King Kong\", the 1954 \"Godzilla\" and its many sequels, the best-selling 1990 novel \"Jurassic Park\" by Michael Crichton and its 1993 film adaptation are just a few notable examples of dinosaur appearances in fiction. Authors of general-interest non-fiction works about dinosaurs, including some prominent paleontologists, have often sought to use the animals as a way to educate readers about science in general. Dinosaurs are ubiquitous in advertising; numerous companies have referenced dinosaurs in printed or televised advertisements, either in order to sell their own products or in order to characterize their rivals as slow-moving, dim-witted, or obsolete.\n\n\n\nGeneral\n\nImages\n\nVideo\n\nPopular\n\nTechnical\n"}
{"id": "8315", "url": "https://en.wikipedia.org/wiki?curid=8315", "title": "Diamagnetism", "text": "Diamagnetism\n\nDiamagnetic materials are repelled by a magnetic field; an applied magnetic field creates an induced magnetic field in them in the opposite direction, causing a repulsive force. In contrast, paramagnetic and ferromagnetic materials are attracted by a magnetic field. Diamagnetism is a quantum mechanical effect that occurs in all materials; when it is the only contribution to the magnetism, the material is called diamagnetic. In paramagnetic and ferromagnetic substances the weak diamagnetic force is overcome by the attractive force of magnetic dipoles in the material. The magnetic permeability of diamagnetic materials is less than μ, the permeability of vacuum. In most materials diamagnetism is a weak effect which can only be detected by sensitive laboratory instruments, but a superconductor acts as a strong diamagnet because it repels a magnetic field entirely from its interior.\n\nDiamagnetism was first discovered when Sebald Justinus Brugmans observed in 1778 that bismuth and antimony were repelled by magnetic fields. In 1845, Michael Faraday demonstrated that it was a property of matter and concluded that every material responded (in either a diamagnetic or paramagnetic way) to an applied magnetic field. On a suggestion by William Whewell, Faraday first referred to the phenomenon as \"diamagnetic\" (the prefix \"dia-\" meaning \"through\" or \"across\"), then later changed it to \"diamagnetism\".\n\nDiamagnetism is a property of all materials, and always makes a weak contribution to the material's response to a magnetic field. However, other forms of magnetism (such as ferromagnetism or paramagnetism) are so much stronger that when multiple different forms of magnetism are present in a material, the diamagnetic contribution is usually negligible. Substances where the diamagnetic behaviour is the strongest effect are termed diamagnetic materials, or diamagnets. Diamagnetic materials are those that laypeople generally think of as \"non-magnetic\", and include water, wood, most organic compounds such as petroleum and some plastics, and many metals including copper, particularly the heavy ones with many core electrons, such as mercury, gold and bismuth. The magnetic susceptibility values of various molecular fragments are called Pascal's constants.\n\nDiamagnetic materials, like water, or water-based materials, have a relative magnetic permeability that is less than or equal to 1, and therefore a magnetic susceptibility less than or equal to 0, since susceptibility is defined as . This means that diamagnetic materials are repelled by magnetic fields. However, since diamagnetism is such a weak property, its effects are not observable in everyday life. For example, the magnetic susceptibility of diamagnets such as water is . The most strongly diamagnetic material is bismuth, , although pyrolytic carbon may have a susceptibility of in one plane. Nevertheless, these values are orders of magnitude smaller than the magnetism exhibited by paramagnets and ferromagnets. Note that because χ is derived from the ratio of the internal magnetic field to the applied field, it is a dimensionless value.\n\nAll conductors exhibit an effective diamagnetism when they experience a changing magnetic field. The Lorentz force on electrons causes them to circulate around forming eddy currents. The eddy currents then produce an induced magnetic field opposite the applied field, resisting the conductor's motion.\n\nIn rare cases, the diamagnetic contribution can be stronger than paramagnetic contribution. As is the case for gold, which has a magnetic susceptibility less than 0, so is by definition a diamagnetic material, but when measured carefully with X-ray magnetic circular dichroism, shows an extremely weak paramagnetic contribution that is overcome by a stronger diamagnetic contribution.\n\nSuperconductors may be considered perfect diamagnets (), because they expel all magnetic fields (except in a thin surface layer) due to the Meissner effect.\n\nIf a powerful magnet (such as a supermagnet) is covered with a layer of water (that is thin compared to the diameter of the magnet) then the field of the magnet significantly repels the water. This causes a slight dimple in the water's surface that may be seen by its reflection.\n\nDiamagnets may be levitated in stable equilibrium in a magnetic field, with no power consumption. Earnshaw's theorem seems to preclude the possibility of static magnetic levitation. However, Earnshaw's theorem applies only to objects with positive susceptibilities, such as ferromagnets (which have a permanent positive moment) and paramagnets (which induce a positive moment). These are attracted to field maxima, which do not exist in free space. Diamagnets (which induce a negative moment) are attracted to field minima, and there can be a field minimum in free space.\n\nA thin slice of pyrolytic graphite, which is an unusually strong diamagnetic material, can be stably floated in a magnetic field, such as that from rare earth permanent magnets. This can be done with all components at room temperature, making a visually effective demonstration of diamagnetism.\n\nThe Radboud University Nijmegen, the Netherlands, has conducted experiments where water and other substances were successfully levitated. Most spectacularly, a live frog (see figure) was levitated.\n\nIn September 2009, NASA's Jet Propulsion Laboratory (JPL) in Pasadena, California announced it had successfully levitated mice using a superconducting magnet, an important step forward since mice are closer biologically to humans than frogs. JPL said it hopes to perform experiments regarding the effects of microgravity on bone and muscle mass.\n\nRecent experiments studying the growth of protein crystals have led to a technique using powerful magnets to allow growth in ways that counteract Earth's gravity.\n\nA simple homemade device for demonstration can be constructed out of bismuth plates and a few permanent magnets that levitate a permanent magnet.\n\nThe electrons in a material generally settle in orbitals, with effectively zero resistance and act like current loops. Thus it might be imagined that diamagnetism effects in general would be common, since any applied magnetic field would generate currents in these loops that would oppose the change, in a similar way to superconductors, which are essentially perfect diamagnets. However, since the electrons are rigidly held in orbitals by the charge of the protons and are further constrained by the Pauli exclusion principle, many materials exhibit diamagnetism, but typically respond very little to the applied field.\n\nThe Bohr–van Leeuwen theorem proves that there cannot be any diamagnetism or paramagnetism in a purely classical system. However, the classical theory of Langevin for diamagnetism gives the same prediction as the quantum theory. The classical theory is given below.\n\nPaul Langevin's theory of diamagnetism (1905) applies to materials containing atoms with closed shells (see dielectrics). A field with intensity , applied to an electron with charge and mass , gives rise to Larmor precession with frequency . The number of revolutions per unit time is , so the current for an atom with electrons is (in SI units)\n\nThe magnetic moment of a current loop is equal to the current times the area of the loop. Suppose the field is aligned with the axis. The average loop area can be given as formula_2, where formula_3 is the mean square distance of the electrons perpendicular to the axis. The magnetic moment is therefore\n\nIf the distribution of charge is spherically symmetric, we can suppose that the distribution of coordinates are independent and identically distributed. Then formula_5, where formula_6 is the mean square distance of the electrons from the nucleus. Therefore, formula_7. If formula_8 is the number of atoms per unit volume, the volume diamagnetic susceptibility in SI units is\n\nThe Langevin theory is not the full picture for metals because there are also non-localized electrons. The theory that describes diamagnetism in a free electron gas is called Landau diamagnetism, named after Lev Landau, and instead considers the weak counteracting field that forms when the electrons' trajectories are curved due to the Lorentz force. Landau diamagnetism, however, should be contrasted with Pauli paramagnetism, an effect associated with the polarization of delocalized electrons' spins. For the bulk case of a 3D system and low magnetic fields, the (volume) diamagnetic susceptibility can be calculated using Landau quantization, which in SI units is\n\nwhere formula_11 is the Fermi energy. This is equivalent to formula_12, exactly formula_13 times Pauli paramagnetic susceptibility, where formula_14 is the Bohr magneton and formula_15 is the density of states (number of states per energy per volume). This formula takes into account the spin degeneracy of the carriers (spin ½ electrons).\n\nIn doped semiconductors the ratio between Landau and Pauli susceptibilities may change due to the effective mass of the charge carriers differing from the electron mass in vacuum, increasing the diamagnetic contribution. The formula presented here only applies for the bulk; in confined systems like quantum dots, the description is altered due to quantum confinement. Additionally, for strong magnetic fields, the susceptibility of delocalized electrons oscillates as a function of the field strength, a phenomenon known as the de Haas–van Alphen effect, also first described theoretically by Landau.\n\n\n"}
{"id": "8317", "url": "https://en.wikipedia.org/wiki?curid=8317", "title": "Duke of Marlborough (title)", "text": "Duke of Marlborough (title)\n\nDuke of Marlborough ( ) is a title in the Peerage of England. It was created by Queen Anne in 1702 for John Churchill, 1st Earl of Marlborough (1650–1722), the noted military leader. In historical texts, it is often to him that an unqualified use of the title refers. The name of the dukedom refers to Marlborough in Wiltshire. It is one of the few titles in the peerage which allows for \"suo jure\" female inheritance, and the only current dukedom to do so.\n\nThe earldom of Marlborough was held by the family of Ley from its creation 1626 until its extinction with the death of the 4th earl in 1679. The title was recreated 10 years later for John Churchill (in 1689).\n\nChurchill had been made \"Lord Churchill of Eyemouth\" (1682) in the Scottish peerage, and \"Baron Churchill\" of Sandridge (1685) and \"Earl of Marlborough\" (1689) in the Peerage of England. Shortly after her accession to the throne in 1702, Queen Anne made Churchill the first \"Duke of Marlborough\" and granted him the subsidiary title \"Marquess of Blandford\".\n\nIn 1678, Churchill married Sarah Jennings (1660–1744), a courtier and influential favourite of the queen. They had seven children, of whom four daughters married into some of the most important families in Great Britain; one daughter and one son died in infancy. He was pre-deceased by his son, John Churchill, Marquess of Blandford, in 1703; so, to prevent the extinction of the titles, a special Act of Parliament was passed. When the 1st Duke of Marlborough died in 1722 his title as \"Lord Churchill of Eyemouth\" in the Scottish peerage became extinct and the Marlborough titles passed, according to the Act, to his eldest daughter Henrietta (1681–1733), the 2nd Duchess of Marlborough. She was married to the 2nd Earl of Godolphin and had a son who predeceased her.\n\nWhen Henrietta died in 1733, the Marlborough titles passed to her nephew Charles Spencer (1706–1758), the third son of her late sister Anne (1683–1716), who had married the 3rd Earl of Sunderland in 1699. After his older brother's death in 1729, Charles Spencer had already inherited the Spencer family estates and the titles of \"Earl of Sunderland\" (1643) and \"Baron Spencer\" of Wormleighton (1603), all in the Peerage of England. Upon his maternal aunt Henrietta's death in 1733, Charles Spencer succeeded to the Marlborough family estates and titles and became the 3rd Duke. When he died in 1758, his titles passed to his eldest son George (1739–1817), who was succeeded by his eldest son George, the 5th Duke (1766–1840). In 1815, Francis Spencer (the younger son of the 4th Duke) was created \"Baron Churchill\" in the Peerage of the United Kingdom. In 1902, his grandson, the 3rd Baron Churchill, was created Viscount Churchill.\n\nIn 1817, the 5th Duke obtained permission to assume and bear the surname of Churchill in addition to his surname of Spencer, to perpetuate the name of his illustrious great-great-grandfather. At the same time he received Royal Licence to quarter the coat of arms of Churchill with his paternal arms of Spencer. The modern Dukes thus originally bore the surname \"Spencer\": the double-barrelled surname of \"Spencer-Churchill\" as used since 1817 remains in the family, though some members have preferred to style themselves \"Churchill\".\n\nThe 7th Duke was the paternal grandfather of the British Prime Minister Sir Winston Churchill, born at Blenheim Palace on 30 November 1874.\n\nThe 11th Duke, John Spencer-Churchill died in 2014, having assumed the title in 1972. The 12th and present Duke is Charles James Spencer-Churchill.\n\nThe family seat is Blenheim Palace in Woodstock, Oxfordshire.\n\nAfter his leadership in the victory against the French in the Battle of Blenheim on 13 August 1704, the 1st Duke was honoured by Queen Anne granting him the royal manor of Woodstock, and building him a house at her expense to be called Blenheim. Construction started in 1705 and the house was completed in 1722, the year of the 1st Duke's death. Blenheim Palace has since remained in the Churchill and Spencer-Churchill family.\n\nWith the exception of the 10th Duke and his first wife, the Dukes and Duchesses of Marlborough are buried in Blenheim Palace's chapel. Most other members of the Spencer-Churchill family are interred in St. Martin's parish churchyard at Bladon, a short distance from the palace.\n\nThe dukedom is the only one in the United Kingdom that can still pass through a female line. However, unlike the remainder to heirs general found in most other peerages that allow male-preference primogeniture, the grant does not allow for abeyance and follows a more restrictive Semi-Salic formula designed to keep succession wherever possible in the male line. The succession is as follows:\nSuccession to the title under the first and second contingencies have lapsed; holders of the title from the 3rd Duke trace their status from the third contingency.\n\nIt is now very unlikely that the dukedom will be passed to a woman or through a woman, since all the male-line descendants of the 1st Duke's second daughter Anne Spencer, Countess of Sunderland—including the lines of the Viscounts Churchill and Barons Churchill of Wychwood and of the Earl Spencer and of the entire Spencer-Churchill and Spencer family—would have to become extinct.\n\nIf that were to happen, the Churchill titles would pass to the Earl of Jersey and his family, the heir-male of the 1st Duke's granddaughter Anne Villiers, Countess of Jersey, daughter of Elizabeth Egerton, Duchess of Bridgewater, the third daughter of the first Duke.\n\nThe next heir would be the Duke of Buccleuch and his family, the heir-male of the 1st Duke's great-granddaughter Elizabeth Montagu, Duchess of Buccleuch, the daughter of Mary Montagu, Duchess of Montagu (1766 creation), the daughter of the 1st Duke's youngest daughter Mary, Duchess of Montagu (1705 creation).\n\nThe fourth surviving line is represented by the Earl of Chichester and his family, the heir-male of the 1st Duke's most senior great-great-granddaughter Mary Henrietta Osborne, Countess of Chichester, daughter of Francis Osborne, 5th Duke of Leeds, only child of Mary Godolphin, Duchess of Leeds, daughter of the 1st Duke's eldest daughter Henrietta Godolphin, 2nd Duchess of Marlborough, by her husband Francis Godolphin, 2nd Earl of Godolphin.\n\n\nThe Duke holds subsidiary titles: \"Marquess of Blandford\" (created in 1702 for John Churchill), \"Earl of Sunderland\" (created in 1643 for the Spencer family), \"Earl of Marlborough\" (created in 1689 for John Churchill), \"Baron Spencer\" of Wormleighton (created in 1603 for the Spencer family), and \"Baron Churchill\" of Sandridge (created in 1685 for John Churchill), all in the Peerage of England.\n\nThe title \"Marquess of Blandford\" is used as the courtesy title for the Duke's eldest son and heir. The Duke's eldest son's eldest son can use the courtesy title \"Earl of Sunderland\", and the duke's eldest son's eldest son's eldest son (not necessarily the eldest great-grandson) the title \"Lord Spencer of Wormleighton\" (not to be confused with Earl Spencer).\n\nThe title of \"Earl of Marlborough\", created for John Churchill in 1689, had previously been created for James Ley, in 1626, becoming extinct in 1679.\n\nThe 1st Duke was honoured with land and titles in the Holy Roman Empire: Emperor Leopold I created him a Prince in 1704, and in 1705, his successor Emperor Joseph I gave him the principality of Mindelheim (once the lordship of the noted soldier Georg von Frundsberg). He was obliged to surrender Mindelheim in 1714 by the Treaty of Utrecht, which returned it to Bavaria. He tried to obtain Nellenburg in Austria in exchange, which at that time was only a county ('Landgrafschaft'), but this failed, partially because Austrian law did not allow for Nellenburg being converted into a sovereign principality. The 1st Duke's principality title of Mindelheim became extinct either on the return of the land to Bavaria or on his death, as the Empire operated Salic Law, which prevented female succession.\n\nThe original arms of Sir Winston Churchill (1620–1688), father of the 1st Duke of Marlborough, were simple and in use by his own father in 1619. The shield was Sable a lion rampant Argent, debruised by a bendlet Gules. The addition of a canton of Saint George (see below) rendered the distinguishing mark of the bendlet unnecessary.\n\nThe Churchill crest is blazoned as a lion couchant guardant Argent, supporting with its dexter forepaw a banner Gules, charged with a dexter hand appaumée of the first, staff Or.\n\nIn recognition of Sir Winston's services to King Charles I as Captain of the Horse, and his loyalty to King Charles II as a Member of Parliament, he was awarded an augmentation of honour to his arms around 1662. This rare mark of royal favour took the form of a canton of Saint George. At the same time, he was authorised to omit the bendlet, which had served the purpose of distinguishing this branch of the Churchill family from others which bore an undifferenced lion.\n\nSir Winston's shield and crest were inherited by his son John Churchill, 1st Duke of Marlborough. Minor modifications reflected the bearer's social rise: the helm was now shown in profile and had a closed grille to signify the bearer's rank as a peer, and there were now supporters placed on either side of the shield. They were the mythical Griffin (part lion, part eagle) and Wyvern (a dragon without hind legs). The supporters were derived from the arms of the family of the 1st Duke's mother, Drake of Ash (Argent, a wyvern gules; these arms can be seen on the monument in Musbury Church to Sir Bernard Drake, d.1586).\n\nThe motto was \"Fiel pero desdichado\" (Spanish for \"Faithful but unfortunate\"). The 1st Duke was also entitled to a coronet indicating his rank.\n\nWhen the 1st Duke was made a Prince of the Holy Roman Empire in 1705, two unusual features were added: the Imperial Eagle and a Princely Coronet. His estates in Germany, such as Mindelheim, were represented in his arms by additional quarterings.\n\nIn 1817, the 5th Duke received Royal Licence to place the quarter of Churchill ahead of his paternal arms of Spencer. The shield of the Spencer family arms is: quarterly Argent and Gules, in the second and third quarters a fret Or, over all on a bend Sable three escallops of the first. The Spencer crest is: out of a ducal coronet Or, a griffin's head between two wings expanded Argent, gorged with a collar gemel and armed Gules. Paul Courtenay observes that \"It would be normal in these circumstances for the paternal arms (Spencer) to take precedence over the maternal (Churchill), but because the Marlborough dukedom was senior to the Sunderland earldom, the procedure was reversed in this case.\"\n\nAlso in 1817, a further augmentation of honour was added to his armorial achievement. This incorporated the bearings from the standard of the Manor of Woodstock and was borne on an escutcheon, displayed over all in the centre chief point, as follows: Argent a cross of Saint George surmounted by an inescutcheon Azure, charged with three fleurs-de-lys Or, two over one. This inescutcheon represents the royal arms of France.\n\nThese quartered arms, incorporating the two augmentations of honour, have been the arms of all subsequent Dukes of Marlborough.\n\nThe motto \"Fiel pero desdichado\" is Spanish for \"Faithful though Joyless\". \"Desdichado\" means without happiness or without joy, alluding to the first Duke's father, Winston, who was a royalist and faithful supporter of the king during the English Civil War but was not compensated for his losses after the restoration. Charles II knighted Winston Churchill and other Civil War royalists but did not compensate them for their wartime losses, thereby inducing Winston to adopt the motto. It is unusual for the motto of an Englishman of the era to be in Spanish rather than Latin, and it is not known why this is the case.\n\nThe earldom of Marlborough was held by the family of Ley from 1626 to 1679. James Ley, the 1st Earl (c. 1550 – 1629), was lord chief justice of the King’s Bench in Ireland and then in England; he was an English member of parliament and was lord high treasurer from 1624 to 1628. In 1624 he was created Baron Ley and in 1626 Earl of Marlborough. The 3rd earl was his grandson James (1618–1665), a naval officer who was killed in action with the Dutch. James was succeeded by his uncle William, a younger son of the 1st earl, on whose death in 1679 the earldom became extinct.\n\n\n\nThe heir apparent to the dukedom is George John Godolphin Spencer-Churchill, Marquess of Blandford (b. 1992), eldest son of the 12th Duke.\n\n \n<section begin=FamilyTree />\n\n<section end=\"FamilyTree\" />\n\n"}
{"id": "8322", "url": "https://en.wikipedia.org/wiki?curid=8322", "title": "December 17", "text": "December 17\n\n\n\n"}
{"id": "8324", "url": "https://en.wikipedia.org/wiki?curid=8324", "title": "Difference engine", "text": "Difference engine\n\nA difference engine created by Charles Babbage is an automatic mechanical calculator designed to tabulate polynomial functions. Its name is derived from the method of divided differences, a way to interpolate or tabulate functions by using a small set of polynomial coefficients. Most mathematical functions commonly used by engineers, scientists and navigators, including logarithmic and trigonometric functions, can be approximated by polynomials, so a difference engine can compute many useful tables of numbers.\n\nThe historical difficulty in producing error-free tables by teams of mathematicians and human \"computers\" spurred Charles Babbage's desire to build a mechanism to automate the process.\n\nThe notion of a mechanical calculator for mathematical functions can be traced back to the Antikythera mechanism of the 2nd century BC, while early modern examples are attributed to Pascal and Leibniz in the 17th century. \nIn 1784 J. H. Müller, an engineer in the Hessian army, devised and built an adding machine and described the basic principles of a difference machine in a book published in 1786 (the first written reference to a difference machine is dated to 1784), but he was unable to obtain funding to progress with the idea.\n\nCharles Babbage began to construct a small difference engine in c. 1819 and had completed it by 1822 (Difference Engine 0). He announced his invention on June 14, 1822, in a paper to the Royal Astronomical Society, entitled \"Note on the application of machinery to the computation of astronomical and mathematical tables\". This machine used the decimal number system and was powered by cranking a handle. The British government was interested, since producing tables was time-consuming and expensive and they hoped the difference engine would make the task more economical.\n\nIn 1823, the British government gave Babbage £1700 to start work on the project. Although Babbage's design was feasible, the metalworking techniques of the era could not economically make parts in the precision and quantity required. Thus the implementation proved to be much more expensive and doubtful of success than the government's initial estimate. In 1832, Babbage and Joseph Clement produced a small working model (1/7 of the calculating section of Difference Engine No. 1, which was intended to operate on 20-digit numbers and sixth-order differences) which operated on 6-digit numbers and second-order differences. Lady Byron described seeing the working prototype in 1833: \"We both went to see the thinking machine (for so it seems) last Monday. It raised several Nos. to the 2nd and 3rd powers, and extracted the root of a Quadratic equation.\" Work on the larger engine was suspended in 1833.\n\nBy the time the government abandoned the project in 1842, Babbage had received and spent over £17,000 on development, which still fell short of achieving a working engine. The government valued only the machine's output (economically produced tables), not the development (at unknown and unpredictable cost to complete) of the machine itself. Babbage did not, or was unwilling to, recognize that predicament. Meanwhile, Babbage's attention had moved on to developing an analytical engine, further undermining the government's confidence in the eventual success of the difference engine. By improving the concept as an analytical engine, Babbage had made the difference engine concept obsolete, and the project to implement it an utter failure in the view of the government.\n\nThe incomplete Difference Engine No. 1 was put on display to the public at the 1862 International Exhibition in South Kensington, London.\n\nBabbage went on to design his much more general analytical engine, but later produced an improved \"Difference Engine No. 2\" design (31-digit numbers and seventh-order differences), between 1846 and 1849. Babbage was able to take advantage of ideas developed for the analytical engine to make the new difference engine calculate more quickly while using fewer parts.\n\nInspired by Babbage's difference engine in 1834, Per Georg Scheutz built several experimental models. In 1837 his son Edward proposed to construct a working model in metal, and in 1840 finished the calculating part, capable of calculating series with 5-digit numbers and first-order differences, which was later extended to third-order (1842). In 1843, after adding the printing part, the model was completed.\n\nIn 1851, funded by the government, construction of the larger and improved (15-digit numbers and fourth-order differences) machine began, and finished in 1853. The machine was demonstrated at the World's Fair in Paris, 1855 and then sold in 1856 to the Dudley Observatory in Albany, New York (delivered in 1857). In 1857 British government ordered next Scheutz's difference machine, which was built in 1859. It had the same basic construction as the previous one. Weighed about .\n\nMartin Wiberg improved Scheutz's construction (c. 1859, his machine has the same capacity as Scheutz's - 15-digit and fourth-order) but used his device only for producing and publishing printed tables (interest tables in 1860, and logarithmic tables in 1875).\n\nAlfred Deacon of London in c. 1862 produced a small difference engine (20-digit numbers and third-order differences).\n\nAmerican George B. Grant started working on his calculating machine in 1869, unaware of the works of Babbage and Scheutz (Schentz). One year later (1870) he learned about difference engines and proceed to design one himself, describing his construction in 1871. In 1874 the Boston Thursday Club raised a subscription for the construction of a large-scale model, which was built in 1876. It could be expanded to enhance precision, weighed about .\n\nChristel Hamann built one machine (16-digit numbers and second-order differences) in 1909 for the \"Tables of Bauschinger and Peters\" (\"Logarithmic-Trigonometrical Tables with eight decimal places\"), which was first published in Leipzig in 1910. Weighed about .\n\nBurroughs Corporation in about 1912 built a machine for Nautical Almanac Office which was used as a difference engine of second-order. It was later replaced in 1929 by a Burroughs Class 11 (13-digit numbers and second-order differences, or 11-digit numbers and <nowiki>[at least up to]</nowiki> fifth-order differences).\n\nAlexander John Thompson about 1927 built \"integrating and differencing machine\" (13-digit numbers and fifth-order differences) for his table of logarithms \"Logarithmetica britannica\". This machine was composed of four modified Triumphator calculators.\n\nLeslie Comrie in 1928 described how to use the Brunsviga-Dupla calculating machine as a difference engine of second-order (15-digit numbers). He also noted in 1931 that National Accounting Machine Class 3000 could be used as a difference engine of sixth-order.\n\nDuring the 1980s, Allan G. Bromley, an associate professor at the University of Sydney, Australia, studied Babbage's original drawings for the Difference and Analytical Engines at the Science Museum library in London. This work led the Science Museum to construct a working calculating section of difference engine No. 2 from 1985 to 1991, under Doron Swade, the then Curator of Computing. This was to celebrate the 200th anniversary of Babbage's birth in 1999. In 2002, the printer which Babbage originally designed for the difference engine was also completed. The conversion of the original design drawings into drawings suitable for engineering manufacturers' use revealed some minor errors in Babbage's design (possibly introduced as a protection in case the plans were stolen), which had to be corrected. Once completed, both the engine and its printer worked flawlessly, and still do. The difference engine and printer were constructed to tolerances achievable with 19th-century technology, resolving a long-standing debate as to whether Babbage's design would actually have worked. (One of the reasons formerly advanced for the non-completion of Babbage's engines had been that engineering methods were insufficiently developed in the Victorian era.)\n\nThe printer's primary purpose is to produce stereotype plates for use in printing presses, which it does by pressing type into soft plaster to create a flong. Babbage intended that the Engine's results be conveyed directly to mass printing, having recognized that many errors in previous tables were not the result of human calculating mistakes but from error in the manual typesetting process. The printer's paper output is mainly a means of checking the Engine's performance.\n\nIn addition to funding the construction of the output mechanism for the Science Museum's Difference Engine No. 2, Nathan Myhrvold commissioned the construction of a second complete Difference Engine No. 2, which was on exhibit at the Computer History Museum in Mountain View, California from 10 May 2008 until 31 January 2016.\nIt has since been transferred to Intellectual Ventures in Seattle where it is on display just outside the main lobby.\n\nThe difference engine consists of a number of columns, numbered from 1 to N. The machine is able to store one decimal number in each column. The machine can only add the value of a column \"n\" + 1 to column \"n\" to produce the new value of \"n\". Column \"N\" can only store a constant, column 1 displays (and possibly prints) the value of the calculation on the current iteration.\n\nThe engine is programmed by setting initial values to the columns. Column 1 is set to the value of the polynomial at the start of computation. Column 2 is set to a value derived from the first and higher derivatives of the polynomial at the same value of X. Each of the columns from 3 to \"N\" is set to a value derived from the formula_1 first and higher derivatives of the polynomial.\n\nIn the Babbage design, one iteration (i.e., one full set of addition and carry operations) happens for each rotation of the main shaft. Odd and even columns alternately perform an addition in one cycle. The sequence of operations for column formula_2 is thus:\n\n\nSteps 1,2,3,4 occur for every odd column, while steps 3,4,1,2 occur for every even column.\n\nWhile Babbage's original design placed the crank directly on the main shaft, it was later realized that the force required to crank the machine would have been too great for a human to handle comfortably. Therefore, the two models that were built incorporate a 4:1 reduction gear at the crank, and four revolutions of the crank are required to perform one full cycle.\n\nEach iteration creates a new result, and is accomplished in four steps corresponding to four complete turns of the handle shown at the far right in the picture below. The four steps are:\n\n\nThe engine represents negative numbers as ten's complements. Subtraction amounts to addition of a negative number. This works in the same manner that modern computers perform subtraction, known as two's complement.\n\nThe principle of a difference engine is Newton's method of divided differences. If the initial value of a polynomial (and of its finite differences) is calculated by some means for some value of X, the difference engine can calculate any number of nearby values, using the method generally known as the method of finite differences. For example, consider the quadratic polynomial\n\nwith the goal of tabulating the values \"p\"(0), \"p\"(1), \"p\"(2), \"p\"(3), \"p\"(4), and so forth. The table below is constructed as follows: the second column contains the values of the polynomial, the third column contains the differences of the two left neighbors in the second column, and the fourth column contains the differences of the two neighbors in the third column:\n\nThe numbers in the third values-column are constant. In fact, by starting with any polynomial of degree \"n\", the column number \"n\" + 1 will always be constant. This is the crucial fact behind the success of the method.\n\nThis table was built from left to right, but it is possible to continue building it from right to left down a diagonal in order to compute more values. To calculate \"p\"(5) use the values from the lowest diagonal. Start with the fourth column constant value of 4 and copy it down the column. Then continue the third column by adding 4 to 11 to get 15. Next continue the second column by taking its previous value, 22 and adding the 15 from the third column. Thus \"p\"(5) is 22 + 15 = 37. In order to compute \"p\"(6), we iterate the same algorithm on the \"p\"(5) values: take 4 from the fourth column, add that to the third column's value 15 to get 19, then add that to the second column's value 37 to get 56, which is \"p\"(6). This process may be continued ad infinitum. The values of the polynomial are produced without ever having to multiply. A difference engine only needs to be able to add. From one loop to the next, it needs to store 2 numbers—in this example (the last elements in the first and second columns). To tabulate polynomials of degree \"n\", one needs sufficient storage to hold \"n\" numbers.\n\nBabbage's difference engine No. 2, finally built in 1991, could hold 8 numbers of 31 decimal digits each and could thus tabulate 7th degree polynomials to that precision. The best machines from Scheutz could store 4 numbers with 15 digits each.\n\nThe initial values of columns can be calculated by first manually calculating N consecutive values of the function and by backtracking, i.e. calculating the required differences.\n\nCol formula_6 gets the value of the function at the start of computation formula_7. Col formula_8 is the difference between formula_9 and formula_7...\n\nIf the function to be calculated is a polynomial function, expressed as\nthe initial values can be calculated directly from the constant coefficients \"a\", \"a\",\"a\", ..., \"a\" without calculating any data points. The initial values are thus:\n\n\nMany commonly used functions are analytic functions, which can be expressed as power series, for example as a Taylor series. The initial values can be calculated to any degree of accuracy; if done correctly the engine will give exact results for first N steps. After that, the engine will only give an approximation of the function.\n\nThe Taylor series expresses the function as a sum obtained from its derivatives at one point. For many functions the higher derivatives are trivial to obtain; for instance, the sine function at 0 has values of 0 or formula_19 for all derivatives. Setting 0 as the start of computation we get the simplified Maclaurin series\n\nThe same method of calculating the initial values from the coefficients can be used as for polynomial functions. The polynomial constant coefficients will now have the value\n\nThe problem with the methods described above is that errors will accumulate and the series will tend to diverge from the true function. A solution which guarantees a constant maximum error is to use curve fitting. A minimum of \"N\" values are calculated evenly spaced along the range of the desired calculations. Using a curve fitting technique like Gaussian reduction an \"N\"−1th degree polynomial interpolation of the function is found. With the optimized polynomial, the initial values can be calculated as above.\n\nWilliam Gibson and Bruce Sterling's \"The Difference Engine\" is an alternate history novel that looks how society would have progressed had the difference engine worked the way Babbage envisioned it.\n\nThe story takes places in Victorian England where technological advancement is on the rise. This is due to the effect of the success of Babbage's analytical machine. The convention of steampunk where Victorian fashion is combined with the technological elements of the Industrial Revolution is seen throughout the story due to technology being so advanced in that era.\n\n"}
{"id": "8326", "url": "https://en.wikipedia.org/wiki?curid=8326", "title": "Draupnir", "text": "Draupnir\n\nIn Norse mythology, Draupnir (Old Norse \"the dripper\") is a gold ring possessed by the god Odin with the ability to multiply itself: Every ninth night, eight new rings 'drip' from Draupnir, each one of the same size and weight as the original.\n\nDraupnir was forged by the dwarven brothers Brokkr and Eitri (or Sindri). Brokkr and Eitri made this ring as one of a set of three gifts which included Mjöllnir and Gullinbursti. They made these gifts in accordance with a wager Loki made saying that Brokkr and Eitri could not make better gifts than the three made by the Sons of Ivaldi. In the end, Mjöllnir, Thor's hammer, won the contest for Brokkr and Eitri. Loki used a loophole to get out of the wager for his head (the wager was for Loki's head only, but he argued that, to remove his head, they would have to injure his neck, which was not in the bargain) and Brokkr punished him by sealing his lips shut with wire.\n\nThe ring was placed by Odin on the funeral pyre of his son Baldr:\n\nOdin laid upon the pyre the gold ring called Draupnir; this quality attended it: that every ninth night there fell from it eight gold rings of equal weight. (from the \"Gylfaginning\").\nThe ring was subsequently retrieved by Hermóðr. It was offered as a gift by Freyr's servant Skírnir in the wooing of Gerðr, which is described in the poem \"Skírnismál\".\n\nDraupnir is represented as a card in the Yu-Gi-Oh Trading Card Game. It has an effect that mimics the multiplication ability of the mythological version. If it is destroyed by another card's effect, you can add another \"Nordic Relic\" card to your hand. The art represents it as an arm brace, with another brace seemingly growing from it, once again mimicking the story.\n\n\"DRAUPNIR\" was revealed as the key to a website that Neal Caffrey and Mozzie used to view their stolen Nazi U-boat treasure in \"Taking Account\", the seventh episode of the third season of \"White Collar\".\n\nIt also appeared in episode 11 of \"\" as a tool to seal Loki's spirit.\n\nThe Draupnir is never called by name but is simply known as Odin's ring in the first three books of the Witches of East End novels. This rings allows the wearer to teleport to any place of the nine worlds, and a copy of equal power was once owned by Loki before it was destroyed by Freya.\n\n"}
{"id": "8328", "url": "https://en.wikipedia.org/wiki?curid=8328", "title": "Divergence", "text": "Divergence\n\nIn vector calculus, divergence is a vector operator that produces a scalar field, giving the quantity of a vector field's source at each point. More technically, the divergence represents the volume density of the outward flux of a vector field from an infinitesimal volume around a given point.\n\nAs an example, consider air as it is heated or cooled. The velocity of the air at each point defines a vector field. While air is heated in a region, it expands in all directions, and thus the velocity field points outward from that region. The divergence of the velocity field in that region would thus have a positive value. While the air is cooled and thus contracting, the divergence of the velocity has a negative value.\n\nIn physical terms, the divergence of a three-dimensional vector field is the extent to which the vector field flux behaves like a source at a given point. It is a local measure of its \"outgoingness\" – the extent to which there is more of some quantity exiting an infinitesimal region of space than entering it. If the divergence is nonzero at some point then there is compression or expansion at that point. (Note that we are imagining the vector field to be like the velocity vector field of a fluid (in motion) when we use the terms \"flux\" and so on.)\n\nMore rigorously, the divergence of a vector field at a point can be defined as the limit of the net flux of across the smooth boundary of a three-dimensional region divided by the volume of as shrinks to . Formally,\n\nwhere is the volume of , is the boundary of , and the integral is a surface integral with being the outward unit normal to that surface. The result, , is a function of . From this definition it also becomes obvious that can be seen as the \"source density\" of the flux of .\n\nIn light of the physical interpretation, a vector field with zero divergence everywhere is called \"incompressible\" or \"solenoidal\" – in which case any closed surface has no net flux across it.\n\nThe intuition that the sum of all sources minus the sum of all sinks should give the net flux outwards of a region is made precise by the divergence theorem.\n\nLet , , be a system of Cartesian coordinates in 3-dimensional Euclidean space, and let , , be the corresponding basis of unit vectors. The divergence of a continuously differentiable vector field is defined as the scalar-valued function:\n\nAlthough expressed in terms of coordinates, the result is invariant under rotations, as the physical interpretation suggests. This is because the trace of the Jacobian matrix of an -dimensional vector field in -dimensional space is invariant under any invertible linear transformation.\n\nThe common notation for the divergence is a convenient mnemonic, where the dot denotes an operation reminiscent of the dot product: take the components of the operator (see del), apply them to the corresponding components of , and sum the results. Because applying an operator is different from multiplying the components, this is considered an abuse of notation.\n\nThe divergence of a continuously differentiable second-order tensor field is a first-order tensor field:\n\nFor a vector expressed in local unit cylindrical coordinates as\nwhere is the unit vector in direction , the divergence is\n\nThe use of local coordinates is vital for the validity of the expression. If we consider the position vector and the functions formula_6, formula_7, and formula_8, which assign the corresponding global cylindrical coordinate to a vector, in general formula_9, formula_10, and formula_11. In particular, if we consider the identity function formula_12, we find that:\n\nIn spherical coordinates, with the angle with the axis and the rotation around the axis, and formula_14 again written in local unit coordinates, the divergence is\n\nUsing Einstein notation we can consider the divergence in general coordinates, which we write as , where is the number of dimensions of the domain. Here, the upper index refers to the number of the coordinate or component, so refers to the second component, and not the quantity squared. The index variable is used to refer to an arbitrary element, such as . The divergence can then be written via the Voss-Weyl formula, as:\n\nwhere formula_17 is the local coefficient of the volume element and are the components of with respect to the local unnormalized covariant basis (sometimes written as formula_18). The Einstein notation implies summation over , since it appears as both an upper and lower index.\n\nThe volume coefficient formula_17 is a function of position which depends on the coordinate system. In Cartesian, cylindrical and polar coordinates, formula_20 and formula_21 respectively, using the same conventions as above. It can also be expressed as formula_22, where formula_23 is the metric tensor. Since the determinant is a scalar quantity which doesn't depend on the indices, we can suppress them and simply write formula_24. Another expression comes from computing the determinant of the Jacobian for transforming from Cartesian coordinates, which for gives formula_25\n\nSome conventions expect all local basis elements to be normalized to unit length, as was done in the previous sections. If we write formula_26 for the normalized basis, and formula_27 for the components of with respect to it, we have that \nusing one of the properties of the metric tensor. By dotting both sides of the last equality with the contravariant element formula_29, we can conclude that formula_30. After substituting, the formula becomes:\n\nSee \"\" for further discussion.\n\nIt can be shown that any stationary flux that is at least twice continuously differentiable in and vanishes sufficiently fast for can be decomposed into an \"irrotational part\" and a \"source-free part\" . Moreover, these parts are explicitly determined by the respective \"source densities\" (see above) and \"circulation densities\" (see the article Curl):\n\nFor the irrotational part one has\n\nwith\n\nThe source-free part, , can be similarly written: one only has to replace the \"scalar potential\" by a \"vector potential\" and the terms by , and the source density \nby the circulation density .\n\nThis \"decomposition theorem\" is a by-product of the stationary case of electrodynamics. It is a special case of the more general Helmholtz decomposition which works in dimensions greater than three as well.\n\nThe following properties can all be derived from the ordinary differentiation rules of calculus. Most importantly, the divergence is a linear operator, i.e.,\n\nfor all vector fields and and all real numbers and .\n\nThere is a product rule of the following type: if is a scalar-valued function and is a vector field, then\n\nor in more suggestive notation\n\nAnother product rule for the cross product of two vector fields and in three dimensions involves the curl and reads as follows:\n\nor\n\nThe Laplacian of a scalar field is the divergence of the field's gradient:\n\nThe divergence of the curl of any vector field (in three dimensions) is equal to zero: \n\nIf a vector field with zero divergence is defined on a ball in , then there exists some vector field on the ball with . For regions in more topologically complicated than this, the latter statement might be false (see Poincaré lemma). The degree of \"failure\" of the truth of the statement, measured by the homology of the chain complex\n\nserves as a nice quantification of the complicatedness of the underlying region . These are the beginnings and main motivations of de Rham cohomology.\n\nOne can express the divergence as a particular case of the exterior derivative, which takes a 2-form to a 3-form in . Define the current two-form as\nIt measures the amount of \"stuff\" flowing through a surface per unit time in a \"stuff fluid\" of density moving with local velocity . Its exterior derivative is then given by\n\nThus, the divergence of the vector field can be expressed as:\nHere the superscript is one of the two musical isomorphisms, and is the Hodge star operator. Working with the current two-form and the exterior derivative is usually easier than working with the vector field and divergence, because unlike the divergence, the exterior derivative commutes with a change of (curvilinear) coordinate system.\n\nThe divergence of a vector field can be defined in any number of dimensions. If \n\nin a Euclidean coordinate system with coordinates , define\n\nThe appropriate expression is more complicated in curvilinear coordinates.\n\nIn the case of one dimension, reduces to a regular function, and the divergence reduces to the derivative.\n\nFor any , the divergence is a linear operator, and it satisfies the \"product rule\"\n\nfor any scalar-valued function .\n\nThe divergence of a vector field extends naturally to any differentiable manifold of dimension that has a volume form (or density) , e.g. a Riemannian or Lorentzian manifold. Generalising the construction of a two-form for a vector field on , on such a manifold a vector field defines an -form obtained by contracting with . The divergence is then the function defined by\n\nStandard formulas for the Lie derivative allow us to reformulate this as\n\nThis means that the divergence measures the rate of expansion of a volume element as we let it flow with the vector field.\n\nOn a pseudo-Riemannian manifold, the divergence with respect to the metric volume form can be computed in terms of the Levi-Civita connection :\n\nwhere the second expression is the contraction of the vector field valued 1-form with itself and the last expression is the traditional coordinate expression from Ricci calculus.\n\nAn equivalent expression without using connection is\n\nwhere is the metric and denotes the partial derivative with respect to coordinate .\n\nDivergence can also be generalised to tensors. In Einstein notation, the divergence of a contravariant vector is given by\n\nwhere denotes the covariant derivative.\n\nEquivalently, some authors define the divergence of a mixed tensor by using the musical isomorphism : if is a -tensor ( for the contravariant vector and for the covariant one), then we define the \"divergence of \" to be the -tensor\n\nthat is, we take the trace over the \"first two\" covariant indices of the covariant derivative\n\n\n\n"}
{"id": "8334", "url": "https://en.wikipedia.org/wiki?curid=8334", "title": "December 18", "text": "December 18\n\n\n\n"}
{"id": "8336", "url": "https://en.wikipedia.org/wiki?curid=8336", "title": "Decision problem", "text": "Decision problem\n\nIn computability theory and computational complexity theory, a decision problem is a problem that can be posed as a yes-no question of the input values. An example of a decision problem is deciding whether a given natural number is prime. Another is the problem \"given two numbers \"x\" and \"y\", does \"x\" evenly divide \"y\"?\". The answer is either 'yes' or 'no' depending upon the values of \"x\" and \"y\". A method for solving a decision problem, given in the form of an algorithm, is called a decision procedure for that problem. A decision procedure for the decision problem \"given two numbers \"x\" and \"y\", does \"x\" evenly divide \"y\"?\" would give the steps for determining whether \"x\" evenly divides \"y\". One such algorithm is long division. If the remainder is zero the answer is 'yes', otherwise it is 'no'. A decision problem which can be solved by an algorithm is called \"decidable\".\n\nDecision problems typically appear in mathematical questions of decidability, that is, the question of the existence of an effective method to determine the existence of some object or its membership in a set; some of the most important problems in mathematics are undecidable.\n\nThe field of computational complexity categorizes \"decidable\" decision problems by how difficult they are to solve. \"Difficult\", in this sense, is described in terms of the computational resources needed by the most efficient algorithm for a certain problem. The field of recursion theory, meanwhile, categorizes \"undecidable\" decision problems by Turing degree, which is a measure of the noncomputability inherent in any solution.\n\nA \"decision problem\" is a yes-or-no question on an infinite set of inputs. It is traditional to define the decision problem as the set of possible inputs together with the set of inputs for which the answer is \"yes\".\n\nThese inputs can be natural numbers, but can also be values of some other kind, like binary strings or strings over some other alphabet. The subset of strings for which the problem returns \"yes\" is a formal language, and often decision problems are defined as formal languages.\n\nUsing an encoding such as Gödel numberings, any string can be encoded as a natural number, via which a decision problem can be defined as a subset of the natural numbers.\n\nA classic example of a decidable decision problem is the set of prime numbers. It is possible to effectively decide whether a given natural number is prime by testing every possible nontrivial factor. Although much more efficient methods of primality testing are known, the existence of any effective method is enough to establish decidability.\n\nA decision problem \"A\" is \"decidable\" or \"effectively solvable\" if \"A\" is a recursive set. A problem is \"partially decidable\", \"semidecidable\", \"solvable\", or \"provable\" if \"A\" is a recursively enumerable set. Problems that are not decidable are \"undecidable\". For those it is not possible to create an algorithm, efficient or otherwise, that solves them.\n\nThe halting problem is an important undecidable decision problem; for more examples, see list of undecidable problems.\n\nDecision problems can be ordered according to many-one reducibility and related to feasible reductions such as polynomial-time reductions. A decision problem \"P\" is said to be \"complete\" for a set of decision problems \"S\" if \"P\" is a member of \"S\" and every problem in \"S\" can be reduced to \"P\". Complete decision problems are used in computational complexity theory to characterize complexity classes of decision problems. For example, the Boolean satisfiability problem is complete for the class NP of decision problems under polynomial-time reducibility.\n\nDecision problems are closely related to function problems, which can have answers that are more complex than a simple 'yes' or 'no'. A corresponding function problem is \"given two numbers \"x\" and \"y\", what is \"x\" divided by \"y\"?\".\n\nA function problem consists of a partial function \"f\"; the informal \"problem\" is to compute the values of \"f\" on the inputs for which it is defined.\n\nEvery function problem can be turned into a decision problem; the decision problem is just the graph of the associated function. (The graph of a function \"f\" is the set of pairs (\"x\",\"y\") such that \"f\"(\"x\") = \"y\".) If this decision problem were effectively solvable then the function problem would be as well. This reduction does not respect computational complexity, however. For example, it is possible for the graph of a function to be decidable in polynomial time (in which case running time is computed as a function of the pair (\"x\",\"y\") ) when the function is not computable in polynomial time (in which case running time is computed as a function of \"x\" alone). The function \"f\"(\"x\") = \"2\" has this property.\n\nEvery decision problem can be converted into the function problem of computing the characteristic function of the set associated to the decision problem. If this function is computable then the associated decision problem is decidable. However, this reduction is more liberal than the standard reduction used in computational complexity (sometimes called polynomial-time many-one reduction); for example, the complexity of the characteristic functions of an NP-complete problem and its co-NP-complete complement is exactly the same even though the underlying decision problems may not be considered equivalent in some typical models of computation.\n\nUnlike decision problems, for which there is only one correct answer for each input, optimization problems are concerned with finding the \"best\" answer to a particular input. Optimization problems arise naturally in many applications, such as the traveling salesman problem and many questions in linear programming.\n\nThere are standard techniques for transforming function and optimization problems into decision problems. For example, in the traveling salesman problem, the optimization problem is to produce a tour with minimal weight. The associated decision problem is: for each \"N\", to decide whether the graph has any tour with weight less than \"N\". By repeatedly answering the decision problem, it is possible to find the minimal weight of a tour.\n\nBecause the theory of decision problems is very well developed, research in complexity theory has typically focused on decision problems. Optimization problems themselves are still of interest in computability theory, as well as in fields such as operations research.\n\n\n"}
{"id": "8339", "url": "https://en.wikipedia.org/wiki?curid=8339", "title": "Domain Name System", "text": "Domain Name System\n\nThe Domain Name System (DNS) is a hierarchical decentralized naming system for computers, services, or other resources connected to the Internet or a private network. It associates various information with domain names assigned to each of the participating entities. Most prominently, it translates more readily memorized domain names to the numerical IP addresses needed for locating and identifying computer services and devices with the underlying network protocols. By providing a worldwide, distributed directory service, the Domain Name System has been an essential component of the functionality of the Internet since 1985.\n\nThe Domain Name System delegates the responsibility of assigning domain names and mapping those names to Internet resources by designating authoritative name servers for each domain. Network administrators may delegate authority over sub-domains of their allocated name space to other name servers. This mechanism provides distributed and fault-tolerant service and was designed to avoid a single large central database.\n\nThe Domain Name System also specifies the technical functionality of the database service that is at its core. It defines the DNS protocol, a detailed specification of the data structures and data communication exchanges used in the DNS, as part of the Internet Protocol Suite.\n\nThe Internet maintains two principal namespaces, the domain name hierarchy and the Internet Protocol (IP) address spaces. The Domain Name System maintains the domain name hierarchy and provides translation services between it and the address spaces. Internet name servers and a communication protocol implement the Domain Name System. A DNS name server is a server that stores the DNS records for a domain; a DNS name server responds with answers to queries against its database.\n\nThe most common types of records stored in the DNS database are for Start of Authority (SOA), IP addresses (A and AAAA), SMTP mail exchangers (MX), name servers (NS), pointers for reverse DNS lookups (PTR), and domain name aliases (CNAME). Although not intended to be a general purpose database, DNS has been expanded over time to store records for other types of data for either automatic lookups, such as DNSSEC records, or for human queries such as \"responsible person\" (RP) records. As a general purpose database, the DNS has also been used in combating unsolicited email (spam) by storing a real-time blackhole list (RBL). The DNS database is traditionally stored in a structured text file, the zone file, but other database systems are common.\n\nAn often-used analogy to explain the Domain Name System is that it serves as the phone book for the Internet by translating human-friendly computer hostnames into IP addresses. For example, the domain name www.example.com translates to the addresses 93.184.216.34 (IPv4) and 2606:2800:220:1:248:1893:25c8:1946 (IPv6). The DNS can be quickly and transparently updated, allowing a service's location on the network to change without affecting the end users, who continue to use the same hostname. Users take advantage of this when they use meaningful Uniform Resource Locators (URLs), and e-mail addresses without having to know how the computer actually locates the services.\n\nAn important and ubiquitous function of DNS is its central role in distributed Internet services such as cloud services and content delivery networks. When a user accesses a distributed Internet service using a URL, the domain name of the URL is translated to the IP address of a server that is proximal to the user. The key functionality of DNS exploited here is that different users can \"simultaneously\" receive different translations for the \"same\" domain name, a key point of divergence from a traditional phone-book view of the DNS. This process of using the DNS to assign proximal servers to users is key to providing faster and more reliable responses on the Internet and is widely used by most major Internet services.\n\nThe DNS reflects the structure of administrative responsibility in the Internet. Each subdomain is a zone of administrative autonomy delegated to a manager. For zones operated by a registry, administrative information is often complemented by the registry's RDAP and WHOIS services. That data can be used to gain insight on, and track responsibility for, a given host on the Internet.\n\nUsing a simpler, more memorable name in place of a host's numerical address dates back to the ARPANET era. The Stanford Research Institute (now SRI International) maintained a text file named HOSTS.TXT that mapped host names to the numerical addresses of computers on the ARPANET. Elizabeth Feinler developed and maintained the first ARPANET directory. Maintenance of numerical addresses, called the Assigned Numbers List, was handled by Jon Postel at the University of Southern California's Information Sciences Institute (ISI), whose team worked closely with SRI.\n\nAddresses were assigned manually. Computers, including their hostnames and addresses, were added to the master file by contacting the SRI's Network Information Center (NIC), directed by Elizabeth Feinler, by telephone during business hours. Later, Feinler set up a WHOIS directory on a server in the NIC for retrieval of information about resources, contacts, and entities. She and her team developed the concept of domains. Feinler suggested that domains should be based on the location of the physical address of the computer. Computers at educational institutions would have the domain \"edu\", for example. She and her team managed the Host Naming Registry from 1972 to 1989.\n\nBy the early 1980s, maintaining a single, centralized host table had become slow and unwieldy and the emerging network required an automated naming system to address technical and personnel issues. Postel directed the task of forging a compromise between five competing proposals of solutions to Paul Mockapetris. Mockapetris instead created the Domain Name System.\n\nThe Internet Engineering Task Force published the original specifications in RFC 882 and RFC 883 in November 1983.\n\nIn 1984, four UC Berkeley students, Douglas Terry, Mark Painter, David Riggle, and Songnian Zhou, wrote the first Unix name server implementation for the Berkeley Internet Name Domain, commonly referred to as BIND. In 1985, Kevin Dunlap of DEC substantially revised the DNS implementation. Mike Karels, Phil Almquist, and Paul Vixie have maintained BIND since then. In the early 1990s, BIND was ported to the Windows NT platform. It was widely distributed, especially on Unix systems, and is still the most widely used DNS software on the Internet.\n\nIn November 1987, RFC 1034 and RFC 1035 superseded the 1983 DNS specifications. Several additional Request for Comments have proposed extensions to the core DNS protocols.\n\nThe domain name space consists of a tree data structure. Each node or leaf in the tree has a \"label\" and zero or more \"resource records\" (RR), which hold information associated with the domain name. The domain name itself consists of the label, possibly concatenated with the name of its parent node on the right, separated by a dot.\n\nThe tree sub-divides into \"zones\" beginning at the root zone. A DNS zone may consist of only one domain, or may consist of many domains and sub-domains, depending on the administrative choices of the zone manager. DNS can also be partitioned according to \"class\" where the separate classes can be thought of as an array of parallel namespace trees.\n\nAdministrative responsibility for any zone may be divided by creating additional zones. Authority over the new zone is said to be \"delegated\" to a designated name server. The parent zone ceases to be authoritative for the new zone.\n\nThe definitive descriptions of the rules for forming domain names appear in RFC 1035, RFC 1123, RFC 2181, and RFC 5892.\nA domain name consists of one or more parts, technically called \"labels\", that are conventionally concatenated, and delimited by dots, such as example.com.\n\nThe right-most label conveys the top-level domain; for example, the domain name www.example.com belongs to the top-level domain \"com\".\n\nThe hierarchy of domains descends from right to left; each label to the left specifies a subdivision, or subdomain of the domain to the right. For example, the label \"example\" specifies a subdomain of the \"com\" domain, and \"www\" is a subdomain of example.com. This tree of subdivisions may have up to 127 levels.\n\nA label may contain zero to 63 characters. The null label, of length zero, is reserved for the root zone. The full domain name may not exceed the length of 253 characters in its textual representation. In the internal binary representation of the DNS the maximum length requires 255 octets of storage, as it also stores the length of the name.\n\nAlthough no technical limitation exists to use any character in domain name labels which are representable by an octet, hostnames use a preferred format and character set. The characters allowed in labels are a subset of the ASCII character set, consisting of characters \"a\" through \"z\", \"A\" through \"Z\", digits \"0\" through \"9\", and hyphen. This rule is known as the \"LDH rule\" (letters, digits, hyphen). Domain names are interpreted in case-independent manner. Labels may not start or end with a hyphen. An additional rule requires that top-level domain names should not be all-numeric.\n\nThe limited set of ASCII characters permitted in the DNS prevented the representation of names and words of many languages in their native alphabets or scripts. To make this possible, ICANN approved the Internationalizing Domain Names in Applications (IDNA) system, by which user applications, such as web browsers, map Unicode strings into the valid DNS character set using Punycode. In 2009 ICANN approved the installation of internationalized domain name country code top-level domains (\"ccTLD\"s). In addition, many registries of the existing top-level domain names (\"TLD\"s) have adopted the IDNA system, guided by RFC 5890, RFC 5891, RFC 5892, RFC 5893.\n\nThe Domain Name System is maintained by a distributed database system, which uses the client–server model. The nodes of this database are the name servers. Each domain has at least one authoritative DNS server that publishes information about that domain and the name servers of any domains subordinate to it. The top of the hierarchy is served by the root name servers, the servers to query when looking up (\"resolving\") a TLD.\n\nAn \"authoritative\" name server is a name server that only gives answers to DNS queries from data that has been configured by an original source, for example, the domain administrator or by dynamic DNS methods, in contrast to answers obtained via a query to another name server that only maintains a cache of data.\n\nAn authoritative name server can either be a \"master\" server or a \"slave\" server. A master server is a server that stores the original (\"master\") copies of all zone records. A slave server uses a special automatic updating mechanism in the DNS protocol in communication with its master to maintain an identical copy of the master records.\n\nEvery DNS zone must be assigned a set of authoritative name servers. This set of servers is stored in the parent domain zone with name server (NS) records.\n\nAn authoritative server indicates its status of supplying definitive answers, deemed \"authoritative\", by setting a protocol flag, called the \"\"Authoritative Answer\"\" (\"AA\") bit in its responses. This flag is usually reproduced prominently in the output of DNS administration query tools, such as dig, to indicate \"that the responding name server is an authority for the domain name in question.\"\n\nDomain name resolvers determine the domain name servers responsible for the domain name in question by a sequence of queries starting with the right-most (top-level) domain label.\n\nFor proper operation of its domain name resolver, a network host is configured with an initial cache (\"hints\") of the known addresses of the root name servers. The hints are updated periodically by an administrator by retrieving a dataset from a reliable source.\n\nAssuming the resolver has no cached records to accelerate the process, the resolution process starts with a query to one of the root servers. In typical operation, the root servers do not answer directly, but respond with a referral to more authoritative servers, e.g., a query for \"www.wikipedia.org\" is referred to the \"org\" servers. The resolver now queries the servers referred to, and iteratively repeats this process until it receives an authoritative answer. The diagram illustrates this process for the host that is named by the fully qualified domain name \"www.wikipedia.org\".\n\nThis mechanism would place a large traffic burden on the root servers, if every resolution on the Internet required starting at the root. In practice caching is used in DNS servers to off-load the root servers, and as a result, root name servers actually are involved in only a relatively small fraction of all requests.\n\nIn theory, authoritative name servers are sufficient for the operation of the Internet. However, with only authoritative name servers operating, every DNS query must start with recursive queries at the root zone of the Domain Name System and each user system would have to implement resolver software capable of recursive operation.\n\nTo improve efficiency, reduce DNS traffic across the Internet, and increase performance in end-user applications, the Domain Name System supports DNS cache servers which store DNS query results for a period of time determined in the configuration (\"time-to-live\") of the domain name record in question.\nTypically, such caching DNS servers also implement the recursive algorithm necessary to resolve a given name starting with the DNS root through to the authoritative name servers of the queried domain. With this function implemented in the name server, user applications gain efficiency in design and operation.\n\nThe combination of DNS caching and recursive functions in a name server is not mandatory; the functions can be implemented independently in servers for special purposes.\n\nInternet service providers typically provide recursive and caching name servers for their customers. In addition, many home networking routers implement DNS caches and recursors to improve efficiency in the local network.\n\nThe client side of the DNS is called a DNS resolver. A resolver is responsible for initiating and sequencing the queries that ultimately lead to a full resolution (translation) of the resource sought, e.g., translation of a domain name into an IP address. DNS resolvers are classified by a variety of query methods, such as \"recursive\", \"non-recursive\", and \"iterative\". A resolution process may use a combination of these methods.\n\nIn a \"non-recursive query\", a DNS resolver queries a DNS server that provides a record either for which the server is authoritative, or it provides a partial result without querying other servers. In case of a caching DNS resolver, the non-recursive query of its local DNS cache delivers a result and reduces the load on upstream DNS servers by caching DNS request records for a period of time after an initial response from upstream DNS servers.\n\nIn a \"recursive query\", a DNS resolver queries a single DNS server, which may in turn query other DNS servers on behalf of the requester. For example, a simple stub resolver running on a home router typically makes a recursive query to the DNS server run by the user's ISP. A recursive query is one for which the DNS server answers the query completely by querying other name servers as needed. In typical operation, a client issues a recursive query to a caching recursive DNS server, which subsequently issues non-recursive queries to determine the answer and send a single answer back to the client. The resolver, or another DNS server acting recursively on behalf of the resolver, negotiates use of recursive service using bits in the query headers. DNS servers are not required to support recursive queries.\n\nThe \"iterative query\" procedure is a process in which a DNS resolver queries a chain of one or more DNS servers. Each server refers the client to the next server in the chain, until the current server can fully resolve the request. For example, a possible resolution of www.example.com would query a global root server, then a \"com\" server, and finally an \"example.com\" server.\n\nName servers in delegations are identified by name, rather than by IP address. This means that a resolving name server must issue another DNS request to find out the IP address of the server to which it has been referred. If the name given in the delegation is a subdomain of the domain for which the delegation is being provided, there is a circular dependency.\n\nIn this case, the name server providing the delegation must also provide one or more IP addresses for the authoritative name server mentioned in the delegation. This information is called \"glue\". The delegating name server provides this glue in the form of records in the \"additional section\" of the DNS response, and provides the delegation in the \"authority section\" of the response. A glue record is a combination of the name server and IP address.\n\nFor example, if the authoritative name server for example.org is ns1.example.org, a computer trying to resolve www.example.org first resolves ns1.example.org. As ns1 is contained in example.org, this requires resolving example.org first, which presents a circular dependency. To break the dependency, the name server for the top level domain org includes glue along with the delegation for example.org. The glue records are address records that provide IP addresses for ns1.example.org. The resolver uses one or more of these IP addresses to query one of the domain's authoritative servers, which allows it to complete the DNS query.\n\nA standard practice in implementing name resolution in applications is to reduce the load on the Domain Name System servers by caching results locally, or in intermediate resolver hosts. Results obtained from a DNS request are always associated with the time to live (TTL), an expiration time after which the results must be discarded or refreshed. The TTL is set by the administrator of the authoritative DNS server. The period of validity may vary from a few seconds to days or even weeks.\n\nAs a result of this distributed caching architecture, changes to DNS records do not propagate throughout the network immediately, but require all caches to expire and to be refreshed after the TTL. RFC 1912 conveys basic rules for determining appropriate TTL values.\n\nSome resolvers may override TTL values, as the protocol supports caching for up to sixty-eight years or no caching at all. Negative caching, i.e. the caching of the fact of non-existence of a record, is determined by name servers authoritative for a zone which must include the Start of Authority (SOA) record when reporting no data of the requested type exists. The value of the \"minimum\" field of the SOA record and the TTL of the SOA itself is used to establish the TTL for the negative answer.\n\nA reverse DNS lookup is a query of the DNS for domain names when the IP address is known. Multiple domain names may be associated with an IP address. The DNS stores IP addresses in the form of domain names as specially formatted names in pointer (PTR) records within the infrastructure top-level domain arpa. For IPv4, the domain is in-addr.arpa. For IPv6, the reverse lookup domain is ip6.arpa. The IP address is represented as a name in reverse-ordered octet representation for IPv4, and reverse-ordered nibble representation for IPv6.\n\nWhen performing a reverse lookup, the DNS client converts the address into these formats before querying the name for a PTR record following the delegation chain as for any DNS query. For example, assuming the IPv4 address 208.80.152.2 is assigned to Wikimedia, it is represented as a DNS name in reverse order: 2.152.80.208.in-addr.arpa. When the DNS resolver gets a pointer (PTR) request, it begins by querying the root servers, which point to the servers of American Registry for Internet Numbers (ARIN) for the 208.in-addr.arpa zone. ARIN's servers delegate 152.80.208.in-addr.arpa to Wikimedia to which the resolver sends another query for 2.152.80.208.in-addr.arpa, which results in an authoritative response.\n\nUsers generally do not communicate directly with a DNS resolver. Instead DNS resolution takes place transparently in applications such as web browsers, e-mail clients, and other Internet applications. When an application makes a request that requires a domain name lookup, such programs send a resolution request to the DNS resolver in the local operating system, which in turn handles the communications required.\n\nThe DNS resolver will almost invariably have a cache (see above) containing recent lookups. If the cache can provide the answer to the request, the resolver will return the value in the cache to the program that made the request. If the cache does not contain the answer, the resolver will send the request to one or more designated DNS servers. In the case of most home users, the Internet service provider to which the machine connects will usually supply this DNS server: such a user will either have configured that server's address manually or allowed DHCP to set it; however, where systems administrators have configured systems to use their own DNS servers, their DNS resolvers point to separately maintained name servers of the organization. In any event, the name server thus queried will follow the process outlined above, until it either successfully finds a result or does not. It then returns its results to the DNS resolver; assuming it has found a result, the resolver duly caches that result for future use, and hands the result back to the software which initiated the request.\n\nSome large ISPs have configured their DNS servers to violate rules, such as by disobeying TTLs, or by indicating that a domain name does not exist just because one of its name servers does not respond.\n\nSome applications, such as web browsers, maintain an internal DNS cache to avoid repeated lookups via the network. This practice can add extra difficulty when debugging DNS issues, as it obscures the history of such data. These caches typically use very short caching times – in the order of one minute.\n\nInternet Explorer represents a notable exception: versions up to IE 3.x cache DNS records for 24 hours by default. Internet Explorer 4.x and later versions (up to IE 8) decrease the default time out value to half an hour, which may be changed by modifying default configuration.\n\nGoogle Chrome triggers a specific error message for DNS issues. When the DNS server is down or broken, Google Chrome returns an error message.\n\nThe Domain Name System includes several other functions and features.\n\nHostnames and IP addresses are not required to match in a one-to-one relationship. Multiple hostnames may correspond to a single IP address, which is useful in virtual hosting, in which many web sites are served from a single host. Alternatively, a single hostname may resolve to many IP addresses to facilitate fault tolerance and load distribution to multiple server instances across an enterprise or the global Internet.\n\nDNS serves other purposes in addition to translating names to IP addresses. For instance, mail transfer agents use DNS to find the best mail server to deliver e-mail: An MX record provides a mapping between a domain and a mail exchanger; this can provide an additional layer of fault tolerance and load distribution.\n\nThe DNS is used for efficient storage and distribution of IP addresses of blacklisted email hosts. A common method is to place the IP address of the subject host into the sub-domain of a higher level domain name, and to resolve that name to a record that indicates a positive or a negative indication.\n\nFor example:\nE-mail servers can query blacklist.example to find out if a specific host connecting to them is in the blacklist. Many of such blacklists, either subscription-based or free of cost, are available for use by email administrators and anti-spam software.\n\nThe Sender Policy Framework and DomainKeys were designed to take advantage of another DNS record type, the TXT record, but have since been assigned specific record types.\n\nTo provide resilience in the event of computer or network failure, multiple DNS servers are usually provided for coverage of each domain. At the top level of global DNS, thirteen groups of root name servers exist, with additional \"copies\" of them distributed worldwide via anycast addressing.\n\nDynamic DNS (DDNS) updates a DNS server with a client IP address on-the-fly, for example, when moving between ISPs or mobile hot spots, or when the IP address changes administratively.\n\nThe DNS protocol uses two types of DNS messages, queries and replies, and they both have the same format. Each message consists of a header and four sections: question, answer, authority, and an additional space. A header field (\"flags\") controls the content of these four sections.\n\nThe header section contains the following fields: \"Identification\", \"Flags\", \"Number of questions\", \"Number of answers\", \"Number of authority resource records\" (RRs), and \"Number of additional RRs\". The identification field can be used to match responses with queries. The flag field consists of several sub-fields. The first is a single bit which indicates if the message is a query (0) or a reply (1). The second sub-field consists of four bits indicating the type of query, or the type of query this message is a response to. 0 is a standard query, 1 an inverse query, 2 is a server status request. A single-bit sub-field indicates if the DNS server is authoritative for the queried hostname. Another single-bit sub-field indicates if the client wants to send a recursive query (\"RD\"). The next single-bit sub-field indicates if the replying DNS server supports recursion (\"RA\"), as not all DNS servers are configured to do this task. Another sub-field indicates if the message was truncated for some reason (\"TC\"), and a four-bit sub-field is used for error codes. The \"question\" section contains the domain name and type of record (A, AAAA, MX, TXT, etc.) being resolved. The domain name is broken into discrete labels which are concatenated; each label is prefixed by the length of that label. The \"answer\" section has the resource records of the queried name. A domain name may occur in multiple records if it has multiple IP addresses associated.\n\nDNS primarily uses the User Datagram Protocol (UDP) on port number 53 to serve requests. DNS queries consist of a single UDP request from the client followed by a single UDP reply from the server. When the length of the answer exceeds 512 bytes and both client and server support EDNS, larger UDP packets are used. Otherwise, the query is sent again using the Transmission Control Protocol (TCP). TCP is also used for tasks such as zone transfers. Some resolver implementations use TCP for all queries.\n\nThe Domain Name System specifies a database of information elements for network resources. The types of information elements are categorized and organized with a list of DNS record types, the resource records (RRs). Each record has a type (name and number), an expiration time (time to live), a class, and type-specific data. Resource records of the same type are described as a \"resource record set\" (RRset), having no special ordering. DNS resolvers return the entire set upon query, but servers may implement round-robin ordering to achieve load balancing. In contrast, the Domain Name System Security Extensions (DNSSEC) work on the complete set of resource record in canonical order.\n\nWhen sent over an Internet Protocol network, all records use the common format specified in RFC 1035:\n\n\"NAME\" is the fully qualified domain name of the node in the tree . On the wire, the name may be shortened using label compression where ends of domain names mentioned earlier in the packet can be substituted for the end of the current domain name. A free standing \"@\" is used to denote the current origin.\n\n\"TYPE\" is the record type. It indicates the format of the data and it gives a hint of its intended use. For example, the \"A\" record is used to translate from a domain name to an IPv4 address, the \"NS\" record lists which name servers can answer lookups on a DNS zone, and the \"MX\" record specifies the mail server used to handle mail for a domain specified in an e-mail address.\n\n\"RDATA\" is data of type-specific relevance, such as the IP address for address records, or the priority and hostname for MX records. Well known record types may use label compression in the RDATA field, but \"unknown\" record types must not (RFC 3597).\n\nThe \"CLASS\" of a record is set to IN (for \"Internet\") for common DNS records involving Internet hostnames, servers, or IP addresses. In addition, the classes Chaos (CH) and Hesiod (HS) exist. Each class is an independent name space with potentially different delegations of DNS zones.\n\nIn addition to resource records defined in a zone file, the domain name system also defines several request types that are used only in communication with other DNS nodes (\"on the wire\"), such as when performing zone transfers (AXFR/IXFR) or for EDNS (OPT).\n\nThe domain name system supports wildcard DNS records which specify names that start with the \"asterisk label\", '*', e.g., *.example. DNS records belonging to wildcard domain names specify rules for generating resource records within a single DNS zone by substituting whole labels with matching components of the query name, including any specified descendants. For example, in the following configuration, the DNS zone \"x.example\" specifies that all subdomains, including subdomains of subdomains, of \"x.example\" use the mail exchanger (MX) \"a.x.example\". The A record for \"a.x.example\" is needed to specify the mail exchanger IP address. As this has the result of excluding this domain name and its subdomains from the wildcard matches, an additional MX record for the subdomain \"a.x.example\", as well as a wildcarded MX record for all of its subdomains, must also be defined in the DNS zone.\n\nThe role of wildcard records was refined in RFC 4592, because the original definition in RFC 1034 was incomplete and resulted in misinterpretations by implementers.\n\nThe original DNS protocol had limited provisions for extension with new features. In 1999, Paul Vixie published in RFC 2671 (superseded by RFC 6891) an extension mechanism, called Extension mechanisms for DNS (EDNS) that introduced optional protocol elements without increasing overhead when not in use. This was accomplished through the OPT pseudo-resource record that only exists in wire transmissions of the protocol, but not in any zone files. Initial extensions were also suggested (EDNS0), such as increasing the DNS message size in UDP datagrams.\n\nDynamic DNS updates use the UPDATE DNS opcode to add or remove resource records dynamically from a zone database maintained on an authoritative DNS server. The feature is described in RFC 2136. This facility is useful to register network clients into the DNS when they boot or become otherwise available on the network. As a booting client may be assigned a different IP address each time from a DHCP server, it is not possible to provide static DNS assignments for such clients.\n\nOriginally, security concerns were not major design considerations for DNS software or any software for deployment on the early Internet, as the network was not open for participation by the general public. However, the expansion of the Internet into the commercial sector in the 1990s changed the requirements for security measures to protect data integrity and user authentication.\n\nSeveral vulnerability issues were discovered and exploited by malicious users. One such issue is DNS cache poisoning, in which data is distributed to caching resolvers under the pretense of being an authoritative origin server, thereby polluting the data store with potentially false information and long expiration times (time-to-live). Subsequently, legitimate application requests may be redirected to network hosts operated with malicious intent.\n\nDNS responses traditionally do not have a cryptographic signature, leading to many attack possibilities; the Domain Name System Security Extensions (DNSSEC) modify DNS to add support for cryptographically signed responses. DNSCurve has been proposed as an alternative to DNSSEC. Other extensions, such as TSIG, add support for cryptographic authentication between trusted peers and are commonly used to authorize zone transfer or dynamic update operations.\n\nSome domain names may be used to achieve spoofing effects. For example, and paypa1.com are different names, yet users may be unable to distinguish them in a graphical user interface depending on the user's chosen typeface. In many fonts the letter \"l\" and the numeral \"1\" look very similar or even identical. This problem is acute in systems that support internationalized domain names, as many character codes in ISO 10646 may appear identical on typical computer screens. This vulnerability is occasionally exploited in phishing.\n\nTechniques such as forward-confirmed reverse DNS can also be used to help validate DNS results.\n\nA device looking up a DNS record must communicate with a DNS server to do so. Considerable attention has been given to the adverse privacy implications. Even if DNS records cannot easily be read, modified or spoofed due to security extensions, a person with access to the DNS server or the traffic stream \"on the wire\" may have little difficulty in matching the IP address of the device (which often identifies the user), to the websites, email or other domains they visit, and track how often and when these records are queried, since DNS records typically expire and must be requeried regularly.\n\nDNS can also \"leak\" from otherwise secure or private connections, if attention is not paid to their configuration, and at times DNS has been used to bypass firewalls by malicious persons, and exfiltrate data, since it is often seen as innocuous.\n\nTwo main approaches are in use to counter privacy issues with DNS:\n\nThe right to use a domain name is delegated by domain name registrars which are accredited by the Internet Corporation for Assigned Names and Numbers (ICANN) or other organizations such as OpenNIC, that are charged with overseeing the name and number systems of the Internet. In addition to ICANN, each top-level domain (TLD) is maintained and serviced technically by an administrative organization, operating a registry. A \"registry\" is responsible for operating the database of names within its authoritative zone, although the term is most often used for TLDs. A \"registrant\" is a person or organization who asked for domain registration. The registry receives registration information from each domain name \"registrar\", which is authorized (accredited) to assign names in the corresponding zone and publishes the information using the WHOIS protocol. As of 2015, usage of RDAP is being considered.\n\nICANN publishes the complete list of TLDs, TLD registries, and domain name registrars. Registrant information associated with domain names is maintained in an online database accessible with the WHOIS service. For most of the more than 290 country code top-level domains (ccTLDs), the domain registries maintain the WHOIS (Registrant, name servers, expiration dates, etc.) information. For instance, DENIC, Germany NIC, holds the DE domain data. From about 2001, most Generic top-level domain (gTLD) registries have adopted this so-called \"thick\" registry approach, i.e. keeping the WHOIS data in central registries instead of registrar databases.\n\nFor top-level domains on COM and NET, a \"thin\" registry model is used. The domain registry (e.g., GoDaddy, BigRock and PDR, VeriSign, etc, etc) holds basic WHOIS data (i.e., registrar and name servers, etc.). Organizations, or registrants using ORG on the other hand, are on the Public Interest Registry exclusively.\n\nSome domain name registries, often called \"network information centers\" (NIC), also function as registrars to end-users, in addition to providing access to the WHOIS datasets. The top-level domain registries, such as for the domains COM, NET, and ORG use a registry-registrar model consisting of many domain name registrars. In this method of management, the registry only manages the domain name database and the relationship with the registrars. The \"registrants\" (users of a domain name) are customers of the registrar, in some cases through additional subcontracting of resellers.\n\nThe Domain Name System is defined by Request for Comments (RFC) documents published by the Internet Engineering Task Force (Internet standards). The following is a list of RFCs that define the DNS protocol.\n\n\n\n\n\nThese RFCs are advisory in nature, but may provide useful information despite defining neither a standard or BCP. (RFC 1796)\n\n\nThese RFCs have an official status of Unknown, but due to their age are not clearly labeled as such.\n\n\n"}
{"id": "8340", "url": "https://en.wikipedia.org/wiki?curid=8340", "title": "David Letterman", "text": "David Letterman\n\nDavid Michael Letterman (born April 12, 1947) is an American television host, comedian, writer, and producer. He hosted late night television talk shows for 33 years, beginning with the February 1, 1982, debut of \"Late Night with David Letterman\" on NBC, and ending with the May 20, 2015, broadcast of \"Late Show with David Letterman\" on CBS. In total, Letterman hosted 6,028 episodes of \"Late Night\" and \"Late Show\", surpassing friend and mentor Johnny Carson as the longest-serving late night talk show host in American television history. In 1996 Letterman was ranked 45th on \"TV Guide\"s 50 Greatest TV Stars of All Time. In 2002, \"The Late Show with David Letterman\" was ranked seventh on TV Guide's 50 Greatest TV Shows of All Time.\n\nLetterman currently hosts the Netflix series \"My Next Guest Needs No Introduction with David Letterman\". \n\nLetterman is also a television and film producer. His company, Worldwide Pants, produced his shows as well as \"The Late Late Show with Craig Ferguson\" and several prime-time comedies, the most successful of which was \"Everybody Loves Raymond\", now in syndication.\n\nSeveral late-night hosts have cited Letterman's influence, including Conan O'Brien (his successor on \"Late Night\"), Stephen Colbert (his successor on \"The Late Show\"), Jimmy Fallon, Jimmy Kimmel, John Oliver, and Seth Meyers.\n\nLetterman was born in Indianapolis, Indiana. His father, Harry Joseph Letterman (April 15, 1915 – February 13, 1973), was a florist. His mother, Dorothy Marie Letterman Mengering (née Hofert; July 18, 1921 – April 11, 2017), a church secretary for the Second Presbyterian Church of Indianapolis, was an occasional figure on Letterman's show, usually at holidays and birthdays.\n\nHe lived on the north side of Indianapolis (Broad Ripple area), about 12 miles from the Indianapolis Motor Speedway and he enjoyed collecting model cars, including racers. In 2000, he told an interviewer for \"Esquire\" that, while growing up, he admired his father's ability to tell jokes and be the life of the party. Harry Joseph Letterman survived a heart attack at age 36, when David was a young boy. The fear of losing his father was constantly with Letterman as he grew up. The elder Letterman died of a second heart attack at age 57.\nLetterman attended his hometown's Broad Ripple High School and worked as a stock boy at the local Atlas Supermarket. According to the \"Ball State Daily News\", he originally had wanted to attend Indiana University, but his grades were not good enough, so he instead attended Ball State University, in Muncie, Indiana. He is a member of the Sigma Chi fraternity, and he graduated in 1969 from what was then the Department of Radio and Television. A self-described average student, Letterman later endowed a scholarship for what he called \"C students\" at Ball State.\n\nThough he registered for the draft and passed his physical after graduating from college, he was not drafted for service in Vietnam because of receiving a draft lottery number of 346 (out of 366).\n\nLetterman began his broadcasting career as an announcer and newscaster at the college's student-run radio station—WBST—a 10-watt campus station which now is part of Indiana Public Radio. He was fired for treating classical music with irreverence. He then became involved with the founding of another campus station—WAGO-AM 570 (now WWHI, 91.3).\n\nHe credits Paul Dixon, host of the \"Paul Dixon Show\", a Cincinnati-based talk show also shown in Indianapolis while he was growing up, for inspiring his choice of career:\nI was just out of college [in 1969], and I really didn't know what I wanted to do. And then all of a sudden I saw him doing it [on TV]. And I thought: That's really what I want to do!\n\nSoon after graduating from Ball State in 1969, Letterman began his career as a radio talk show host on WNTS (AM) and on Indianapolis television station WLWI (which changed its call sign to WTHR in 1976) as an anchor and weatherman. He received some attention for his unpredictable on-air behavior, which included congratulating a tropical storm for being upgraded to a hurricane and predicting hail stones \"the size of canned hams.\" He would also occasionally report the weather and the day's very high and low temps for fictitious cities (\"Eight inches of snow in Bingree and surrounding areas\") while on another occasion saying that a state border had been erased when a satellite map accidentally omitted the state border between Indiana and Ohio, attributing it to dirty political dealings. (\"The higher-ups have removed the border between Indiana and Ohio making it one giant state. Personally, I'm against it. I don't know what to do about it.\") He also starred in a local kiddie show, made wisecracks as host of a late night TV show called \"Freeze-Dried Movies\" (he once acted out a scene from \"Godzilla\" using plastic dinosaurs), and hosted a talk show that aired early on Saturday mornings called \"Clover Power\", in which he interviewed 4-H members about their projects.\n\nIn 1971 Letterman appeared as a pit road reporter for ABC Sports' tape-delayed coverage of the Indianapolis 500 (his first nationally telecast appearance; WLWI was the local ABC affiliate at the time). Letterman was initially introduced as Chris Economaki, although this was corrected at the end of the interview (Jim McKay announced his name as Dave Letterman). Letterman interviewed Mario Andretti, who had just crashed out of the race.\n\nIn 1975, encouraged by his then-wife Michelle and several of his Sigma Chi fraternity brothers, Letterman moved to Los Angeles, with hope of becoming a comedy writer. He and Michelle packed their belongings in his pickup truck and headed west. As of 2012, he still owned the truck. In Los Angeles, he began performing comedy at The Comedy Store. Jimmie Walker saw him on stage; with an endorsement from George Miller, Letterman joined a group of comedians whom Walker hired to write jokes for his stand-up act, a group that at various times would also include Jay Leno, Paul Mooney, Robert Schimmel, Richard Jeni, Louie Anderson, Elayne Boosler, Byron Allen, Jack Handey, and Steve Oedekerk.\n\nBy the summer of 1977, Letterman was a writer and regular on the six-week summer series \"The Starland Vocal Band Show\", broadcast on CBS. He hosted a 1977 pilot for a game show entitled \"The Riddlers\" (that was never picked up), and co-starred in the Barry Levinson-produced comedy special \"Peeping Times\" that aired in January 1978. Later that year, Letterman was a cast member on Mary Tyler Moore's variety show, \"Mary\". Letterman made a guest appearance on \"Mork & Mindy\" (as a parody of EST leader Werner Erhard) and appearances on game shows such as \"The $20,000 Pyramid\", \"The Gong Show\", \"Hollywood Squares\", \"Password Plus\" and \"Liar's Club\", as well as the Canadian cooking show \"Celebrity Cooks\" (November 1977), talk shows such as \"90 Minutes Live\" (February 24 and April 14, 1978), and \"The Mike Douglas Show\" (April 3, 1979 and February 7, 1980). He was also screen tested for the lead role in the 1980 film \"Airplane!\", a role that eventually went to Robert Hays.\n\nHis dry, sarcastic humor caught the attention of scouts for \"The Tonight Show Starring Johnny Carson\", and Letterman was soon a regular guest on the show. Letterman became a favorite of Carson and was a regular guest host for the show beginning in 1978. Letterman credits Carson as the person who influenced his career the most.\n\nOn June 23, 1980, Letterman was given his own morning comedy show on NBC, \"The David Letterman Show\". It was originally 90 minutes long, but was shortened to 60 minutes in August 1980. The show was a critical success, winning two Emmy Awards, but was a ratings disappointment and was canceled, the last show airing October 24, 1980.\n\nNBC kept Letterman under contract (paying him) to be able to try him in a different time slot. \"Late Night with David Letterman\" debuted February 1, 1982; the first guest on the first show was Bill Murray. Murray later went on to become one of Letterman's most recurrent guests, guesting on the show's 30th anniversary episode, which aired January 31, 2012 and on the very last show, which aired May 20, 2015. The show ran Monday through Thursday at 12:30 a.m. Eastern Time, immediately following \"The Tonight Show Starring Johnny Carson\" (a Friday night broadcast was added in June 1987). It was seen as being edgy and unpredictable, and soon developed a cult following (particularly among college students). Letterman's reputation as an acerbic interviewer was borne out in verbal sparring matches with Cher (who even called him an asshole on the show), Shirley MacLaine, Charles Grodin, and Madonna. The show also featured comedy segments and running characters, in a style heavily influenced by the 1950s and 1960s programs of Steve Allen.\n\nThe show often featured quirky, genre-mocking regular features, including \"Stupid Pet Tricks\" (which had its origins on Letterman's morning show), Stupid Human Tricks, dropping various objects off the roof of a five-story building, demonstrations of unorthodox clothing (such as suits made of Alka-Seltzer, Velcro and suet), a recurring Top 10 list, the Monkey-Cam (and the Audience Cam), a facetious letter-answering segment, several \"Film[s] by My Dog Bob\" in which a camera was mounted on Letterman's own dog (often with comic results) and Small Town News, all of which would eventually move with Letterman to CBS.\n\nOther memorable moments included Letterman using a bullhorn to interrupt a live interview on \"The Today Show\", announcing that he was the NBC News president and that he was not wearing any pants; walking across the hall to Studio 6B, at the time the news studio for WNBC-TV, and interrupting Al Roker's weather segments during \"Live at Five\"; and staging \"elevator races\", complete with commentary by NBC Sports' Bob Costas. In one infamous appearance, in 1982, Andy Kaufman (who was already wearing a neck brace) appeared with professional wrestler Jerry Lawler, who slapped and knocked the comedian to the ground (though Lawler and Kaufman's friend Bob Zmuda later revealed that the event was staged).\n\nIn 1992, Johnny Carson retired, and many fans believed that Letterman would become host of \"The Tonight Show\". When NBC instead gave the job to Jay Leno, Letterman departed NBC to host his own late-night show on CBS, opposite \"The Tonight Show\" at 11:30 p.m., called the \"Late Show with David Letterman\". The new show debuted on August 30, 1993, and was taped at the historic Ed Sullivan Theater, where Ed Sullivan broadcast his eponymous variety series from 1948 to 1971. For Letterman's arrival, CBS spent  million in renovations. In addition to that cost, CBS also signed Letterman to a lucrative three-year,  million/year contract, doubling his \"Late Night\" salary. The total cost for everything (renovations, negotiation right paid to NBC, signing Letterman, announcer Bill Wendell, Paul Shaffer, the writers and the band) was over  million.\n\nBut while the expectation was that Letterman would retain his unique style and sense of humor with the move, \"Late Show\" was not an exact replica of his old NBC program. Recognizing the more formal mood (and wider audience) of his new time slot and studio, Letterman eschewed his trademark blazer with khaki pants and white wrestling shoes wardrobe combination in favor of expensive shoes, tailored suits and light-colored socks. The monologue was lengthened. Paul Shaffer and the World's Most Dangerous Band followed Letterman to CBS, but they added a brass section and were rebranded the CBS Orchestra (Shaffer's request); a small band had been mandated by Carson while Letterman occupied the 12:30 slot. Additionally, because of intellectual property disagreements, Letterman was unable to import many of his \"Late Night\" segments verbatim, but he sidestepped this problem by simply renaming them (the \"Top Ten List\" became the \"Late Show Top Ten\", \"Viewer Mail\" became the \"CBS Mailbag\", etc.) \"Time\" magazine stated that \"Letterman's innovation ... gained power from its rigorous formalism\", as his biographer Jason Zinoman puts it, he was \"a fascinatingly disgruntled eccentric trapped inside a more traditional talk show.\"\n\nThe main competitor of the \"Late Show\" was NBC's \"The Tonight Show\", which was hosted by Jay Leno for 22 years, but from June 1, 2009, to January 22, 2010, was hosted by Conan O'Brien. In 1993 and 1994, the \"Late Show\" consistently gained higher ratings than \"The Tonight Show\". But in 1995, ratings dipped and Leno's show consistently beat Letterman's in the ratings from the time that Hugh Grant came on Leno's show after Grant's arrest for soliciting a prostitute.\n\nLeno typically attracted about five million nightly viewers between 1999 and 2009. The \"Late Show\" lost nearly half its audience during its competition with Leno, attracting 7.1 million viewers nightly in its 1993–94 season and about 3.8 million per night as of Leno's departure in 2009. In the final months of his first stint as host of \"The Tonight Show\", Leno beat Letterman in the ratings by a 1.3 million viewer margin (5.2 million to 3.9 million), and \"Nightline\" and the \"Late Show\" were virtually tied. Once O'Brien took over \"Tonight\", however, Letterman closed the gap in the ratings. O'Brien initially drove the median age of \"Tonight Show\" viewers from 55 to 45, with most older viewers opting to watch the \"Late Show\" instead. Following Leno's return to \"The Tonight Show\", however, Leno regained his lead.\n\nLetterman's shows have garnered both critical and industry praise, receiving 67 Emmy Award nominations, winning 12 times in his first 20 years in late night television. From 1993 to 2009, Letterman ranked higher than Leno in the annual Harris Poll of \"Nation's Favorite TV Personality\" 12 times. For example, in 2003 and 2004 Letterman ranked second in that poll, behind only Oprah Winfrey, a year that Leno was ranked fifth. Leno was higher than Letterman on that poll three times during the same period, in 1998, 2007, and 2008.\n\nOn March 27, 1995, Letterman acted as the host for the 67th Academy Awards ceremony. Critics blasted Letterman for what they deemed a poor hosting of the Oscars, noting that his irreverent style undermined the traditional importance and glamor of the event. In a joke about their unusual names (inspired by a celebrated comic essay in \"The New Yorker\", \"Yma Dream\" by Thomas Meehan), he started off by introducing Uma Thurman to Oprah Winfrey, and then both of them to Keanu Reeves: \"Oprah...Uma. Uma...Oprah,\" \"Have you kids met Keanu?\" This and many of his other jokes fell flat. Although Letterman attracted the highest ratings to the annual telecast since 1983, many felt that the bad publicity garnered by Letterman's hosting caused a decline in the \"Late Show\"'s ratings.\n\nLetterman recycled the apparent debacle into a long-running gag. On his first show after the Oscars, he joked, \"Looking back, I had no idea that thing was being televised.\" He lampooned his stint two years later, during Billy Crystal's opening Oscar skit, which also parodied the plane-crashing scenes from that year's chief nominated film, \"The English Patient\".\n\nFor years afterward, Letterman recounted his hosting the Oscars, although the Academy of Motion Picture Arts and Sciences continued to hold Letterman in high regard and they had invited him to host the Oscars again. On September 7, 2010, he made an appearance on the premiere of the 14th season of \"The View\", and confirmed that he had been considered for hosting again.\n\nOn January 14, 2000, a routine check-up revealed that an artery in Letterman's heart was severely obstructed. He was rushed to emergency surgery for a quintuple bypass.\n\nDuring the initial weeks of his recovery, reruns of the \"Late Show\" were shown and introduced by friends of Letterman including Norm MacDonald, Drew Barrymore, Ray Romano, Robin Williams, Bonnie Hunt, Megan Mullally, Bill Murray, Regis Philbin, Charles Grodin, Nathan Lane, Julia Roberts, Bruce Willis, Jerry Seinfeld, Martin Short, Steven Seagal, Hillary Clinton, Danny DeVito, Steve Martin, and Sarah Jessica Parker.\n\nSubsequently, while still recovering from surgery, Letterman revived the late night tradition that had virtually disappeared on network television during the 1990s of 'guest hosts' by allowing Bill Cosby, Kathie Lee Gifford, Dana Carvey, Janeane Garofalo, and others to host new episodes of the \"Late Show\".\n\nUpon his return to the show on February 21, 2000, Letterman brought all but one of the doctors and nurses on stage who had participated in his surgery and recovery (with extra teasing of a nurse who had given him bed baths—\"This woman has seen me naked!\"), including Dr. O. Wayne Isom and physician Louis Aronne, who frequently appeared on the show. In a show of emotion, Letterman was nearly in tears as he thanked the health care team with the words \"These are the people who saved my life!\" The episode earned an Emmy nomination.\n\nFor a number of episodes, Letterman continued to crack jokes about his bypass, including saying, \"Bypass surgery: it's when doctors surgically create new blood flow to your heart. A bypass is what happened to me when I didn't get \"The Tonight Show!\" It's a whole different thing.\" In a later running gag he lobbied his home state of Indiana to rename the freeway circling Indianapolis (I-465) \"The David Letterman Bypass.\" He also featured a montage of faux news coverage of his bypass surgery, which included a clip of Letterman's heart for sale on the Home Shopping Network. Letterman became friends with his doctors and nurses. In 2008, a \"Rolling Stone\" interview stated he hosted a doctor and nurse who'd helped perform the emergency quintuple-bypass heart surgery that saved his life in 2000. 'These are people who were complete strangers when they opened my chest,' he says. 'And now, eight years later, they're among my best friends.'\n\nAdditionally, Letterman invited the band Foo Fighters to play \"Everlong\", introducing them as \"my favorite band, playing my favorite song.\" During a later Foo Fighters appearance, Letterman said that Foo Fighters had been in the middle of a South American tour which they canceled to come play on his comeback episode.\n\nLetterman again handed over the reins of the show to several guest hosts (including Bill Cosby, Brad Garrett, Whoopi Goldberg, Elvis Costello, John McEnroe, Vince Vaughn, Will Ferrell, Bonnie Hunt, Luke Wilson and bandleader Paul Shaffer) in February 2003, when he was diagnosed with a severe case of shingles. Later that year, Letterman made regular use of guest hosts—including Tom Arnold and Kelsey Grammer—for new shows broadcast on Fridays. In March 2007, Adam Sandler—who had been scheduled to be the lead guest—served as a guest host while Letterman was ill with a stomach virus.\n\nIn March 2002, as Letterman's contract with CBS neared expiration, ABC offered him the time slot for long-running news program \"Nightline\" with Ted Koppel. Letterman was interested as he believed he could never match Leno's ratings at CBS due to Letterman's complaint of weaker lead-ins from the network's late local news programs, but was reluctant to replace Koppel. Letterman addressed his decision to re-sign on the air, stating that he was content at CBS and that he had great respect for Koppel.\n\nOn December 4, 2006, CBS revealed that Letterman signed a new contract to host \"Late Show with David Letterman\" through the fall of 2010. \"I'm thrilled to be continuing on at CBS,\" said Letterman. \"At my age you really don't want to have to learn a new commute.\" Letterman further joked about the subject by pulling up his right pants leg, revealing a tattoo, presumably temporary, of the ABC logo.\n\n\"Thirteen years ago, David Letterman put CBS late night on the map and in the process became one of the defining icons of our network,\" said Leslie Moonves, president and CEO of CBS Corporation. His presence on our air is an ongoing source of pride, and the creativity and imagination that the \"Late Show\" puts forth every night is an ongoing display of the highest quality entertainment. We are truly honored that one of the most revered and talented entertainers of our time will continue to call CBS 'home.'\n\nAccording to a 2007 article in \"Forbes\" magazine, Letterman earned  million a year. A 2009 article in \"The New York Times\", however, said his salary was estimated at  million per year. In June 2009, Letterman's Worldwide Pants and CBS reached agreement to continue the \"Late Show\" until at least August 2012. The previous contract had been set to expire in 2010, and the two-year extension is shorter than the typical three-year contract period negotiated in the past. Worldwide Pants agreed to lower its fee for the show, though it had remained a \"solid moneymaker for CBS\" under the previous contract.\n\nOn the February 3, 2011, edition of the \"Late Show\", during an interview with Howard Stern, Letterman said he would continue to do his talk show for \"maybe two years, I think.\"\n\nIn April 2012, CBS announced it had extended its contract with Letterman through 2014. His contract was subsequently extended to 2015.\n\nDuring the taping of his April 3, 2014, show, Letterman announced that he had informed CBS president Leslie Moonves that he would retire from hosting \"Late Show\" by May 20, 2015. It was announced soon after that comedian and political satirist Stephen Colbert would succeed Letterman. Letterman's last episode aired on May 20, 2015, and opened with a presidential send off featuring four of the five living American presidents, George H. W. Bush, Bill Clinton, George W. Bush and Barack Obama, each mimicking the late president Gerald Ford's statement that \"Our long national nightmare is over.\" It also featured cameos from \"The Simpsons\" and \"Wheel of Fortune\" (the latter with a puzzle saying \"Good riddance to David Letterman\"), a Top Ten List of \"things I wish I could have said to David Letterman\" performed by regular guests including Alec Baldwin, Barbara Walters, Steve Martin, Jerry Seinfeld, Jim Carrey, Chris Rock, Julia Louis-Dreyfus, Peyton Manning, Tina Fey, and Bill Murray, and closed with a montage of scenes from both his CBS and NBC series set to a live performance of \"Everlong\" by Foo Fighters.\n\nThe final episode of \"Late Show with David Letterman\" was watched by 13.76 million viewers in the United States with an audience share of 9.3/24, earning the show its highest ratings since following the 1994 Olympics on February 25, 1994, and the show's highest demo numbers (4.1 in adults 25–54 and 3.1 in adults 18–49) since Oprah Winfrey's first \"Late Show\" appearance following the ending of her feud with Letterman on December 1, 2005. Bill Murray, who had been his first guest on \"Late Night\", was his final guest on \"Late Show\". In a rarity for a late-night show, it was also the highest-rated program on network television that night, beating out all prime-time shows. In total, Letterman hosted 6,028 episodes of \"Late Night\" and \"Late Show\", surpassing friend and mentor Johnny Carson as the longest-serving late night talk show host in American television history.\n\nIn the months following the end of \"Late Show\" Letterman has been seen occasionally at sports events such as the Indianapolis 500, during which he submitted to an interview with a local publication. He made a surprise appearance on stage in San Antonio, Texas when he was invited up for an extended segment during Steve Martin and Martin Short's \"A Very Stupid Conversation\" show saying \"I retired, and...I have no regrets,\" Letterman told the crowd after walking on stage. \"I was happy. I'll make actual friends. I was complacent. I was satisfied. I was content, and then a couple of days ago Donald Trump said he was running for president. I have made the biggest mistake of my life, ladies and gentlemen\" and then delivering a Top Ten List roasting Donald Trump's presidential campaign followed by an on-stage conversation with Martin and Short. Cell phone recordings of the appearance were posted on YouTube by audience members and were widely reported in the media.\n\nIn 2016, Letterman joined the climate change documentary show \"Years of Living Dangerously\" as one of the show's celebrity correspondents. In season two's premiere episode, Letterman traveled to India to investigate the country's efforts to expand its inadequate energy grid, power its booming economy and bring electricity for the first time to 300 million citizens. He also interviewed Indian Prime Minister Narendra Modi, and traveled to rural villages where power is a scarce luxury and explored the United States' role in India's energy future.\n\nOn April 7, 2017, Letterman gave the induction speech for the band Pearl Jam into the Rock & Roll Hall Of Fame at a ceremony held at the Barclays Center in Brooklyn, New York City. Also in 2017, Letterman and Alec Baldwin co-hosted \"The Essentials\" on Turner Classic Movies. Letterman and Baldwin introduced seven films for the series.\n\nIn 2018, Letterman has been hosting a six-episode monthly series of hour-long programs on Netflix consisting of long-form interviews and field segments. The show, \"My Next Guest Needs No Introduction with David Letterman\", premiered January 12, 2018, featuring Barack Obama.\n\nIn spite of Johnny Carson's clear intention to pass his title to Letterman, NBC selected Jay Leno to host \"The Tonight Show\" after Carson's departure. Letterman maintained a close relationship with Carson through his break with NBC. Three years after he left for CBS, HBO produced a made-for-television movie called \"The Late Shift\", based on a book by \"The New York Times\" reporter Bill Carter, chronicling the battle between Letterman and Leno for the coveted \"Tonight Show\" hosting spot.\n\nCarson later made a few cameo appearances as a guest on Letterman's show. Carson's final television appearance came May 13, 1994, on a \"Late Show\" episode taped in Los Angeles, when he made a surprise appearance during a 'Top 10 list' segment. In early 2005, it was revealed that Carson occasionally sent jokes to Letterman, who used these jokes in his monologue; according to CBS senior vice president Peter Lassally (a one-time producer for both men), Carson got \"a big kick out of it.\" Letterman would do a characteristic Johnny Carson golf swing after delivering one of Carson's jokes. In a tribute to Carson, all of the opening monologue jokes during the first show following Carson's death were written by Carson.\n\nLassally also claimed that Carson had always believed Letterman, not Leno, to be his \"rightful successor.\" During the early years of the \"Late Show\"s run, Letterman occasionally used some of Carson's trademark bits, including \"Carnac the Magnificent\" (with Paul Shaffer as Carnac), \"Stump the Band\", and the \"Week in Review.\"\n\nOprah Winfrey appeared on Letterman's show when he was hosting NBC's \"Late Night\" on May 2, 1989. Following that appearance, the two had a 16-year feud which arose, as Winfrey explained to Letterman after the feud had been resolved, as a result of the acerbic tone of their 1989 interview of which she said that it \"felt so uncomfortable to me that I didn't want to have that experience again\".\n\nThe feud apparently ended in 2005 when Winfrey appeared on CBS's \"Late Show with David Letterman\" on December 2, in an event Letterman jokingly referred to as \"the Super Bowl of Love\".\n\nWinfrey and Letterman also appeared together in a \"Late Show\" promo that aired during CBS's coverage of Super Bowl XLI in February 2007, with the two sitting next to each other on the couch watching the game. Since the game was played between the Indianapolis Colts and Chicago Bears, the Indianapolis-born Letterman wears a Peyton Manning jersey, while Winfrey—whose show was taped in Chicago—wears a Brian Urlacher jersey. On September 10, 2007, Letterman made his first appearance on \"The Oprah Winfrey Show\" at Madison Square Garden in New York City.\n\nThree years later, during CBS's coverage of Super Bowl XLIV, the two appeared again in a \"Late Show\" promo, this time with Winfrey sitting on a couch between Letterman and Jay Leno. This time Letterman was wearing the retired 70 jersey of Colts' Hall of Fame and Letterman regular guest, Art Donovan (the Colts faced the New Orleans Saints in this Super Bowl). The appearance was Letterman's idea: Leno flew to New York City on an NBC corporate jet, sneaking into the Ed Sullivan Theater during the \"Late Show\"'s February 4 taping wearing a disguise, meeting Winfrey and Letterman at a living room set created in the theater's balcony where they taped their promo.\n\nWinfrey interviewed Letterman in January 2013 on \"Oprah's Next Chapter\". Winfrey and Letterman discussed their feud during the interview and Winfrey revealed that she had had a \"terrible experience\" while appearing on Letterman's show years earlier. Letterman could not recall the incident but apologized.\n\n\"Late Show\" went off air for eight weeks during the months of November and December because of the Writers Guild of America strike. Letterman's production company, Worldwide Pants, was the first company to make an individual agreement with the WGA, thus allowing his show to come back on air on January 2, 2008. On his first episode since being off air, he surprised the viewing audience with his newly grown beard, which signified solidarity with the strike. His beard was shaved off during the show on January 7, 2008.\n\nOn June 8 and 9, 2009, Letterman told two sexually themed jokes about a daughter (never named) of Sarah Palin on his TV show. Palin was in New York City at the time with her then fourteen-year-old daughter, Willow, and some contemporaries thought the jokes to be aimed at Willow, which caused some small amount of controversy.\n\nIn a statement posted on the Internet, Palin said, \"I doubt [Letterman would] ever dare make such comments about anyone else's daughter\" and that \"laughter incited by sexually perverted comments made by a 62-year-old male celebrity aimed at a 14-year-old girl is disgusting.\" On his show of June 10, Letterman responded to the controversy, saying the jokes were meant to be about Palin's eighteen-year-old daughter, Bristol, whose pregnancy as an unmarried teenager had caused some controversy during the United States presidential election of 2008. \"These are not jokes made about (Palin's) 14-year-old daughter ... I would never, never make jokes about raping or having sex of any description with a 14-year-old girl.\"\n\nHis remarks did not put an end to public criticism, however. The National Organization for Women (NOW) released a statement supporting Palin, noting that Letterman had made \"[only] something of an apology.\" When the controversy failed to subside, Letterman addressed the issue again on his show of June 15, faulting himself for the error and apologizing \"especially to the two daughters involved, Bristol and Willow, and also to the governor and her family and everybody else who was outraged by the joke.\"\n\nOn August 17, 2011, it was reported that an Islamist militant had posted a death threat against Letterman on a website frequented by Al-Qaeda supporters, calling on American Muslims to kill Letterman for making a joke about the death of an Al-Qaeda leader, killed in a drone strike in Pakistan in June 2011, Ilyas Kashmiri. In his show on August 22, Letterman joked about the threat, saying \"State Department authorities are looking into this. They're not taking this lightly. They're looking into it. They're questioning, they're interrogating, there's an electronic trail—but everybody knows it's Leno.\"\n\nLetterman was the focus of \"The Avengers on \"Late Night with David Letterman\"\", issue 239 (January 1984) of the Marvel comic book series \"The Avengers\", in which the title characters (specifically Hawkeye, Wonder Man, Black Widow, Beast and Black Panther) are guests on \"Late Night\". A parody of Letterman, named \"David Endochrine\", is gassed to death along with his bandleader named \"Paul\" and their audience in Frank Miller's \"The Dark Knight Returns\". In \"\", Letterman was parodied as \"David Litterbin\".\n\nLetterman appeared in the pilot episode of the short-lived 1986 series \"Coach Toast\", and he appears with a bag over his head as a guest on Bonnie Hunt's 1990s sitcom, \"The Building\". He appeared in \"The Simpsons\" as himself in a couch gag when the Simpsons find themselves (and the couch) in \"Late Night with David Letterman\". He had a cameo in the feature film \"Cabin Boy\", with Chris Elliott, who worked as a writer on Letterman's show. In this and other appearances, Letterman is listed in the credits as \"Earl Hofert\", the name of Letterman's maternal grandfather. He also appeared as himself in the Howard Stern biographical film \"Private Parts\" as well as the 1999 Andy Kaufman biopic \"Man on the Moon\", in a few episodes of Garry Shandling's 1990s TV series \"The Larry Sanders Show\" and in \"The Abstinence\", a 1996 episode of the sitcom \"Seinfeld\".\n\nLetterman provided vocals for the Warren Zevon song \"Hit Somebody\" from \"My Ride's Here\", and provided the voice for Butt-head's father in the 1996 animated film \"Beavis and Butt-Head Do America\", once again credited as Earl Hofert.\n\nIn 2010, a documentary \"Dying to do Letterman\" was released directed by Joke Fincioen and Biagio Messina featuring Steve Mazan, a stand-up comic, who has cancer and wants to appear on the Letterman show. The film won best documentary and jury awards at the Cinequest Film Festival. Steve Mazan published a same-titled book (full title, \"Dying to Do Letterman: Turning Someday into Today\") about his own saga.\n\nLetterman appeared as a guest on CNN's \"Piers Morgan Tonight\" on May 29, 2012, when he was interviewed by Regis Philbin, the guest host and long-time friend. Philbin again interviewed Letterman (and Shaffer) while guest-hosting CBS' \"The Late Late Show\" (between the tenures of Craig Ferguson and James Corden) on January 27, 2015.\n\nIn June 2013, he appeared in the second episode of season two of \"Comedians in Cars Getting Coffee\".\n\nOn November 5, 2013, Letterman and Bruce McCall published a fiction satire book titled \"This Land Was Made for You and Me (But Mostly Me)\". \n\nLetterman started his production company — Worldwide Pants Incorporated — which produced his show and several others, including \"Everybody Loves Raymond\"; \"The Late Late Show\" and two television series for Bonnie Hunt. Worldwide Pants also produced the dramedy program \"Ed\" which aired on NBC from 2000–2004. It was Letterman's first association with NBC since he left the network in 1993. During the run of \"Ed,\" the star, Tom Cavanagh, appeared as a guest on the \"Late Show\" several times.\n\nIn 2005, Worldwide Pants produced its first feature film, \"Strangers with Candy\", which was a prequel to the Comedy Central TV series of the same title. In 2007, Worldwide Pants produced the ABC comedy series, \"Knights of Prosperity\".\n\nWorldwide Pants made significant news in December 2007 when it was announced that Letterman's company had independently negotiated its own contract with the Writers Guild of America, East, thus allowing Letterman, Craig Ferguson, and their writers to return to work, while the union continued its strike against production companies, networks and studios who had not reached an agreement.\n\nIn late April 2010, several music industry websites reported that Letterman started a record label named Clear Entertainment/C.E. Music and signed his first artist, Runner Runner. Lucy Walsh announced on her MySpace page that she has been signed by Letterman and Clear Entertainment/C.E. Music and is working on her album.\n\nRahal Letterman Lanigan Racing (RLLR) is an auto racing team that currently races in the United SportsCar Championship (formerly the American Le Mans Series), and full-time in the Verizon IndyCar Series. It is co-owned by 1986 Indianapolis 500 winner Bobby Rahal, businessman Mike Lanigan, and Letterman himself, and is based in Hilliard, Ohio. The team won the 2004 Indianapolis 500 with driver Buddy Rice.\n\nThe Letterman Foundation for Courtesy and Grooming is a private foundation through which Letterman has donated millions of dollars to charities and other non-profits in Indiana and Montana, celebrity-affiliated organizations such as Paul Newman's Hole in the Wall Gang Camp, universities such as Ball State, and other organizations such as the American Cancer Society, Salvation Army, and Doctors Without Borders.\n\nLetterman's biggest influence and his mentor was Johnny Carson. Other comedians that influenced Letterman were Paul Dixon, Steve Allen, Jonathan Winters, Garry Moore, Jack Paar, Don Rickles, and David Brenner. Although Ernie Kovacs has also been mentioned as an influence, Letterman has denied this.\n\nComedians that were influenced by Letterman include: Stephen Colbert, Ray Romano, Jimmy Kimmel, Jay Leno, Conan O'Brien, Jon Stewart, Arsenio Hall, Larry Wilmore, Seth Meyers, Jimmy Fallon, John Oliver, and James Corden.\n\nIn 2015, Forbes estimated that Letterman's annual income was $35 million.\n\nOn July 2, 1968, Letterman married his college sweetheart, Michelle Cook (born July 2, 1946), in Muncie, Indiana; their marriage ended in divorce by October 1977. He also had a long-term live-in relationship with the former head writer and producer on \"Late Night\", Merrill Markoe (born August 13, 1948), from 1978 to 1988. Markoe was the mind behind several \"Late Night\" staples, such as \"Stupid Pet/Human Tricks\". \"Time\" magazine stated that theirs was the defining relationship of Letterman's career with Merrill also acting as his writing partner. She \"put the surrealism in Letterman's comedy.\"\n\nLetterman and Regina Lasko (born November 20, 1960) started dating in February 1986, while he was still living with Markoe. He has a son, Harry Joseph Letterman (born November 3, 2003), with her. Harry is named after Letterman's father. In 2005, police discovered a plot to kidnap Harry Letterman and demand a ransom of  million. Kelly Frank, a house painter who had worked for Letterman, was charged in the conspiracy.\n\nLetterman and Lasko wed on March 19, 2009, during a quiet courthouse civil ceremony in Choteau, Montana, where he had purchased a ranch in 1999. Letterman announced the marriage during the taping of his show of March 23, shortly after congratulating Bruce Willis for his marriage the week before. Letterman told the audience he nearly missed the ceremony because his truck became stuck in mud two miles from their house. The family resides in North Salem, New York, on a estate.\n\nLetterman suffers from tinnitus (ringing in the ears), which is a symptom of hearing loss. On the \"Late Show\" in 1996, Letterman talked about his tinnitus in an interview he did with actor William Shatner, who has severe tinnitus himself, caused from an on-set explosion. Letterman said at first he could not figure out where the noise in his head was coming from and that he hears constant noises and ringing in his ears 24 hours a day.\n\nLetterman no longer drinks alcohol. On more than one occasion, he said that he had once been a \"horrible alcoholic\" and had begun drinking around the age of 13 and continued until 1981 when he was 34. He recounts in 1981, \"I was drunk 80% of the time. ... I loved it. I was one of those guys, I looked around, and everyone else had stopped drinking and I couldn't understand why.\" When he is shown drinking on the \"Late Show\" (or, before that, on \"Late Night\") what appears to be alcohol, it is actually replaced with apple juice by the crew. In 2015, he said that \"For years and years and years – 30, 40 years – I was anxious and hypochondriacal and an alcoholic, and many, many other things that made me different from other people.\" He became calmer through a combination of transcendental meditation and low doses of medication.\n\nHe stated in 2017 that he is a Presbyterian, a religious tradition he was originally brought up in by his mother. However, he once said he is motivated by \"Lutheran, Midwestern guilt\".\n\nLetterman's sister is a journalist, as is her husband. Their son, Liam Letterman Shelton, attended Letterman's \"alma mater\", Ball State University in Muncie, Indiana, where Letterman funded the journalism school, and studied a four-year double major in journalism news/telecommunications news.\n\nBeginning in May 1988, Letterman was stalked by Margaret Mary Ray, a woman suffering from schizophrenia. She stole his Porsche, camped out on his tennis court, and repeatedly broke into his house. Her exploits drew national attention, with Letterman occasionally joking about her on his show, although he never referred to her by name. After she committed suicide in October 1998, Letterman told \"The New York Times\" that he had great compassion for her. A spokesperson for Letterman said: \"This is a sad ending to a confused life.\"\n\nOn October 1, 2009, Letterman announced on his show that he had been the victim of a blackmail attempt by someone threatening to reveal that he'd had sex with several of his female employees, and at the same time, he confirmed that he had had such relationships. He stated that three weeks earlier (on September 9, 2009) someone had left a package in his car with material he said he would write into a screenplay and a book if Letterman did not pay him  million. Letterman said that he contacted the Manhattan District Attorney's office, ultimately cooperating with them to conduct a sting operation involving giving the man a phony check. Subsequently, Robert J. \"Joe\" Halderman, a producer of the CBS true crime journalism series \"48 Hours\", was arrested after trying to deposit the check. He was indicted by a Manhattan grand jury and pleaded not guilty to a charge of attempted grand larceny on October 2, 2009. Eventually, on March 9, 2010, he pleaded guilty to this same felony and served a six-month jail sentence, followed by probation and community service.\n\nA central figure in the case and one of the women with whom Letterman had had a sexual relationship was his longtime personal assistant Stephanie Birkitt, who often appeared with him on his show. She had also worked for \"48 Hours\". Until a month prior to the revelations, she had shared a residence with Halderman, who allegedly had copied her personal diary and used it, along with private emails, in the blackmail package.\n\nIn the days following the initial announcement of the affairs and the arrest, several prominent women, including Kathie Lee Gifford, co-host of NBC's \"Today Show\", and NBC news anchor Ann Curry questioned whether Letterman's affairs with subordinates created an unfair working environment. A spokesman for Worldwide Pants said that the company's sexual harassment policy did not prohibit sexual relationships between managers and employees. According to business news reporter Eve Tahmincioglu, \"CBS suppliers are supposed to follow the company's business conduct policies\" and the CBS 2008 Business Conduct Statement states that \"If a consenting romantic or sexual relationship between a supervisor and a direct or indirect subordinate should develop, CBS requires the supervisor to disclose this information to his or her Company's Human Resources Department...\".\n\nOn October 3, 2009, a former CBS employee, Holly Hester, announced that she and Letterman had engaged in a year-long \"secret\" affair in the early 1990s while she was his intern and a student at New York University.\n\nOn October 5, 2009, Letterman devoted a segment of his show to a public apology to his wife and staff. Three days later, Worldwide Pants announced that Birkitt had been placed on a \"paid leave of absence\" from the \"Late Show\". On October 15, CBS News announced that the company's Chief Investigative Correspondent, Armen Keteyian, had been assigned to conduct an \"in-depth investigation\" into Letterman.\n\nLetterman is a car enthusiast, and owns an extensive collection. In 2012, it was reported that the collection consisted of ten Ferraris, eight Porsches, four Austin Healeys, two Honda motorcycles, a Chevy pickup and one car each from automakers Mercedes-Benz, Jaguar, MG, Volvo, and Pontiac.\n\nIn his 2013 appearance on \"Comedians in Cars Getting Coffee\", part of Jerry Seinfeld's conversation with Letterman was filmed in Letterman's outwardly unassuming 1995 Volvo 960 station wagon that is powered by a 380-horsepower racing engine. Paul Newman had the car built for Letterman.\n\nLetterman shares a close relationship with the rock and roll band Foo Fighters since their appearance on his first show upon his return from heart surgery (see section \"Heart surgery hiatus\" for more information). The band appeared many times on the \"Late Show\" (see section \"Retirement from Late Show\" for more information), including a week-long stint in October 2014.\n\nWhile introducing the band's performance of \"Miracle\" on the show of October 17, 2014, Letterman told the story of how a souvenir video of himself and his four-year-old son learning to ski used the song as background music, unbeknownst to Letterman until he saw it. He said \"This is the second song of theirs that will always have great, great meaning for me for the rest of my life\". This was the first time the band had heard this story.\n\nWorldwide Pants co-produced Dave Grohl's \"\" TV series. \"Letterman was the first person to get behind this project,\" Grohl admitted.\n\nOn September 7, 2007, Letterman visited his \"alma mater\", Ball State University in Muncie, Indiana, for the dedication of a communications facility named in his honor for his dedication to the university. The  million, David Letterman Communication and Media Building opened for the 2007 fall semester. Thousands of Ball State students, faculty, and local residents welcomed Letterman back to Indiana. Letterman's emotional speech touched on his struggles as a college student and his late father, and also included the \"top ten good things about having your name on a building\", finishing with \"if reasonable people can put my name on a  million building, anything is possible.\" Over many years Letterman \"has provided substantial assistance to [Ball State's] Department of Telecommunications, including an annual scholarship that bears his name.\"\n\nAt the same time, Letterman received a Sagamore of the Wabash award given by Indiana Governor Mitch Daniels, which recognizes distinguished service to the state of Indiana.\n\nIn his capacities as either a performer, producer, or as part of a writing team, Letterman is among the most nominated people in the history of the Emmy Awards with 52 nominations, winning two Daytime Emmys and ten Primetime Emmys since 1981. He won four American Comedy Awards and in 2011 became the first recipient of the Johnny Carson Award for Comedic Excellence at The Comedy Awards.\n\nLetterman was a recipient of the 2012 Kennedy Center Honors, where he was called \"one of the most influential personalities in the history of television, entertaining an entire generation of late-night viewers with his unconventional wit and charm.\" On May 16, 2017, Letterman was named the next recipient of the Mark Twain Prize for American Humor, the award granted annually by the John F. Kennedy Center for the Performing Arts. He was scheduled to receive the prize in a ceremony slated for October 22.\n\n\n"}
{"id": "8341", "url": "https://en.wikipedia.org/wiki?curid=8341", "title": "Delroy Lindo", "text": "Delroy Lindo\n\nDelroy George Lindo (born 18 November 1952) is a British-American actor and theatre director. Lindo has been nominated for Tony and Screen Actors Guild awards and has won a Satellite Award. He is perhaps best known for his roles in three Spike Lee films, having portrayed West Indian Archie in Lee's \"Malcolm X\" (1992), Woody Carmichael in \"Crooklyn\" (1994), and Rodney Little in Clockers (1995). Lindo also played Catlett in \"Get Shorty\", Arthur Rose in \"The Cider House Rules\", and Detective Castlebeck in \"Gone in 60 Seconds\" (2000). Lindo starred as Alderman Ronin Gibbons in the TV series \"The Chicago Code\" (2011) and as Winter on the series \"Believe,\" which premiered in 2014.\n\nDelroy Lindo was born in 1952 in Lewisham, south east London, the son of Jamaican parents who had emigrated to Britain. Lindo became interested in acting as a child during a Nativity play. His mother was a nurse and his father worked in various jobs. As a teenager, he and his mother moved to Toronto, Ontario, Canada. When he was sixteen, they moved to San Francisco. At the age of 24, Lindo started acting studies at the American Conservatory Theater, graduating in 1979.\n\nLindo's film debut came in 1976 with the British comedy \"Find the Lady\", followed by two other roles in films, including an Army Sergeant in \"More American Graffiti\" (1979).\n\nHe stopped his film career for 10 years to concentrate on theatre acting. In 1982 he debuted on Broadway in \"\"Master Harold\"...and the Boys,\" directed by the play's South African author Athol Fugard. By 1988 Lindo had earned a Tony nomination for his portrayal of Herald Loomis in August Wilson's \"Joe Turner's Come and Gone\".\n\nLindo returned to film in the 1990s, acting alongside Rutger Hauer and Joan Chen in the science fiction film \"Salute of the Jugger\" (1990), which has become a cult classic. Although he had turned down Spike Lee for a role in his debut \"Do the Right Thing\", Lee cast him as Woody Carmichael in the drama \"Crooklyn\" (1994), which brought him notice. Together with his other roles with Lee - as the West Indian Archie, a psychotic gangster, in \"Malcolm X\", and a starring role as a neighbourhood drug dealer in \"Clockers\" - he became established in his film career.\n\nOther films in which he has starring roles are Barry Sonnenfeld's \"Get Shorty\" (1995), Ron Howard's \"Ransom\" (1996) and \"Soul of the Game\" (1996), as the baseball player Satchel Paige.\n\nIn 1998 Lindo co-starred as African-American explorer Matthew Henson, in the TV film \"Glory & Honor\", directed by Kevin Hooks. It portrayed his nearly 20-year partnership with Commander Robert Peary in Arctic exploration and their effort to find the Geographic North Pole in 1909. He received a Satellite Award as best actor. Lindo continues to work in television and was most recently seen on the short-lived NBC drama \"Kidnapped\".\n\nLindo played an angel in the comedy film \"A Life Less Ordinary\" (1997).\n\nHe guest-starred on \"The Simpsons\" in the episode \"Brawl in the Family\", playing a similar character named Gabriel.\n\nLindo had a small role in the 1995 science fiction/action film \"Congo,\" playing the corrupt Captain Wanta. Lindo was not credited for the role.\n\nIn the British film, \"Wondrous Oblivion\" (2003), directed by Paul Morrison, he starred as Dennis Samuels, the father of a Jamaican immigrant family in London in the 1950s; he coaches his children and the son of a neighbour Jewish family in cricket, earning their admiration in a time of strained social relations. Lindo said he made the film in honour of his parents, who had similarly moved to London in those years.\n\nIn 2007, Lindo began an association with Berkeley Repertory Theatre in Berkeley, California, when he directed Tanya Barfield's play \"The Blue Door\". In the autumn of 2008, Lindo revisited August Wilson's play, \"Joe Turner's Come and Gone\", directing a production at the Berkeley Rep. In 2010, he played the role of elderly seer Bynum in David Lan's production of \"Joe Turner\" at the Young Vic Theatre in London.\n\nLindo is poised to play Marcus Garvey in an upcoming biopic of the black nationalist historical figure.\n\n"}
{"id": "8343", "url": "https://en.wikipedia.org/wiki?curid=8343", "title": "David Janssen", "text": "David Janssen\n\nDavid Janssen (born David Harold Meyer, March 27, 1931 – February 13, 1980) was an American film and television actor who is best known for his starring role as Richard Kimble in the television series \"The Fugitive\" (1963–1967). Janssen also had the title roles in three other series: \"Richard Diamond, Private Detective\"; \"Harry O\"; and \"O'Hara, U.S. Treasury\".\n\nIn 1996 \"TV Guide\" ranked him number 36 on its \"50 Greatest TV Stars of All Time\" list.\n\nJanssen was born in 1931 in Naponee, a village in Franklin County in southern Nebraska, to Harold Edward Meyer, a banker (May 12, 1906 – November 4, 1990) and Berniece Graf (May 11, 1910 – November 26, 1995). Janssen was of Irish and Jewish descent. Following his parents' divorce in 1935, his mother moved with five-year-old David to Los Angeles, California, and later married Eugene Janssen (February 18, 1918 – March 30, 1996) in 1940 in Los Angeles. Young David used his stepfather's name after he entered show business as a child.\n\nHe attended Fairfax High School in Los Angeles, where he excelled on the basketball court, setting a school-scoring record that lasted over 20 years. His first film part was at the age of thirteen, and by the age of twenty-five he had appeared in twenty films and served two years as an enlisted man in the United States Army. During his Army days, Janssen became friends with fellow enlistees Martin Milner and Clint Eastwood while posted at Fort Ord, California.\n\nJanssen appeared in many television series before he landed programs of his own. In 1956, he and Peter Breck appeared in John Bromfield's syndicated series \"Sheriff of Cochise\" in the episode \"The Turkey Farmers\". Later, he guest-starred on NBC's medical drama \"The Eleventh Hour\" in the role of Hal Kincaid in the 1962 episode \"Make Me a Place\", with series co-stars Wendell Corey and Jack Ging. He joined friend Martin Milner in a 1962 episode of \"Route 66\" as the character Kamo in the episode \"One Tiger to a Hill.\"\n\nJanssen starred in four television series of his own:\n\nAt the time, the final episode of \"The Fugitive\" held the record for the greatest number of American homes with television sets to watch a series finale, at 72 percent in August 1967. David Janssen was well liked by everyone, but more loved by his fans. He fit the perfect role of \"why me?\" One could not help feeling sorry for his Fugitive character of being quiet, unassuming, afraid, but mainly caring for others. On an episode, he stopped to help an old lady cross the street, on another; he helped a young, attractive woman start up her stalled car in the middle of nowhere.\n\nHis films include \"To Hell and Back\", the biography of Audie Murphy, who was the most decorated American soldier of World War II; John Wayne's Vietnam war film \"The Green Berets\"; opposite Gregory Peck in the space story \"Marooned\", in which Janssen played an astronaut sent to rescue three stranded men in space, and \"The Shoes of the Fisherman\", as a television journalist in Rome reporting on the election of a new Pope (Anthony Quinn).\n\nHe starred as a Los Angeles police detective trying to clear himself in the killing of an apparently innocent doctor in the 1967 film \"Warning Shot\". The film was shot during a break in the spring and summer of 1966 between the third and fourth seasons of \"The Fugitive.\"\n\nJanssen played an alcoholic in the 1977 TV movie \"A Sensitive, Passionate Man\", which co-starred Angie Dickinson, and an engineer who devises an unbeatable system for blackjack in the 1978 made-for-TV movie \"Nowhere to Run\", co-starring Stefanie Powers and Linda Evans. Janssen's impressively husky voice was used to good effect as the narrator for the TV mini-series \"Centennial\" (1978–79); he also appeared in the final episode. He starred in the made for tv mini series \"S.O.S. Titanic\" as John Jacob Astor, playing opposite Beverly Ross as his wife, Madeleine, in 1979.\n\nThough Janssen's scenes were cut from the final release, he also appeared as a journalist in the film \"Inchon\", which he accepted to work with Laurence Olivier who played General Douglas MacArthur. At the time of his death, Janssen had just begun filming a television movie playing the part of Father Damien, the priest who dedicated himself to the leper colony on the island of Molokai, Hawaii. The part was eventually reassigned to actor Ken Howard of the CBS series \"The White Shadow\".\n\nIn 1996 \"TV Guide\" ranked him number 36 on its 50 Greatest TV Stars of All Time list.\n\nJanssen was married twice. His first marriage was to model and interior decorator Ellie Graham, whom he married in Las Vegas on August 25, 1958. They divorced in 1968. In 1975, he married actress and model Dani Crayne Greco. They remained married until Janssen's death.\n\nA heavy drinker and a four-pack-a-day smoker, Janssen died of a heart attack in the early morning of February 13, 1980, at his home in Malibu, California at the age of 48. At the time of his death, Janssen was filming the television movie \"Father Damien\". Janssen was buried at the Hillside Memorial Park Cemetery in Culver City, California. A non-denominational funeral was held at the Jewish chapel of the cemetery on February 17. Suzanne Pleshette delivered the eulogy at the request of Janssen's widow. Milton Berle, Johnny Carson, Tommy Gallagher, Richard Harris, Stan Herman, Rod Stewart and Gregory Peck were among Janssen's pallbearers. Honorary pallbearers included Jack Lemmon, George Peppard, James Stewart and Danny Thomas.\n\nFor his contribution to the television industry, David Janssen has a star on the Hollywood Walk of Fame located on the 7700 block of Hollywood Boulevard.\n\n"}
{"id": "8344", "url": "https://en.wikipedia.org/wiki?curid=8344", "title": "Docetism", "text": "Docetism\n\nIn Christianity, docetism (from the \"dokeĩn\" \"to seem\", \"dókēsis\" \"apparition, phantom\", is the doctrine that the phenomenon of Jesus, his historical and bodily existence, and above all the human form of Jesus, was mere semblance without any true reality. Broadly it is taken as the belief that Jesus only seemed to be human, and that his human form was an illusion.\n\nThe word \"Dokētaí\" (\"Illusionists\") referring to early groups who denied Jesus's humanity, first occurred in a letter by Bishop Serapion of Antioch (197–203), who discovered the doctrine in the Gospel of Peter, during a pastoral visit to a Christian community using it in Rhosus, and later condemned it as a forgery.. It appears to have arisen over theological contentions concerning the meaning, figurative or literal, of a sentence from the Gospel of John: \"the Word was made Flesh\".\n\nDocetism was unequivocally rejected at the First Council of Nicaea in 325 and is regarded as heretical by the Catholic Church, Eastern Orthodox Church, Coptic Orthodox Church of Alexandria and the Orthodox Tewahedo, and many other Christian denominations that accept and hold to the statements of these early church councils.\n\nDocetism is broadly defined as any teaching that claims that Jesus' body was either absent or illusory. The term 'docetic' is rather nebulous. Two varieties were widely known. In one version, as in Marcionism, Christ was so divine that he could not have been human, since God lacked a material body, which therefore could not physically suffer. Jesus only \"appeared\" to be a flesh-and-blood man; his body was a phantasm. Other groups who were accused of docetism held that Jesus was a man in the flesh, but Christ was a separate entity who entered Jesus's body in the form of a dove at his baptism, empowered him to perform miracles, and abandoned him upon his death on the cross.\n\nDocetism's origin within Christianity is obscure. Ernst Käsemann controversially defined the Christology of St John’s Gospel as \"naïve docetism\" in 1968. The ensuing debate reached an impasse as awareness grew that the very term \"docetism\", like \"gnosticism\", was difficult to define within the religio-historical framework of the debate. It has occasionally been argued that its origins were in heterodox Judaism or Oriental and Grecian philosophies. The alleged connection with Jewish Christianity would have reflected Jewish Christian concerns with the inviolability of (Jewish) monotheism. Docetic opinions seem to have circulated from very early times, 1 John 4:2 appearing explicitly to reject them. Some 1stcentury Christian groups developed docetic interpretations partly as a way to make Christian teachings more acceptable to pagan ways of thinking about divinity.\n\nIn his critique of the theology of Clement of Alexandria, Photius in his Myriobiblon held that Clement's views reflected a quasi-docetic view of the nature of Christ, writing that \"[Clement] hallucinates that the Word was not incarnate but \"only seems to be\".\" (ὀνειροπολεῖ καὶ μὴ σαρκωθῆναι τὸν λόγον ἀλλὰ \"δόξαι\".) In Clement's time, some disputes contended over whether Christ assumed the \"psychic\" flesh of mankind as heirs to Adam, or the \"spiritual\" flesh of the resurrection. Docetism largely died out during the first millennium AD.\n\nThe opponents against whom Ignatius of Antioch inveighs are often taken to be Monophysite docetists. In his letter to the Smyrnaeans, 7:1, written around 110AD, he writes:\nWhile these characteristics fit a Monophysite framework, a slight majority of scholars consider that Ignatius was waging a polemic on two distinct fronts, one Jewish, the other docetic; a minority holds that he was concerned with a group that commingled Judaism and docetism. Others, however, doubt that there was actual docetism threatening the churches, arguing that he was merely criticizing Christians who lived Jewishly or that his critical remarks were directed at an Ebionite or Cerinthian possessionist Christology, according to which Christ was a heavenly spirit that temporarily possessed Jesus.\n\nSome commentators have attempted to make a connection between Islam and Docetism using the following Quranic verse:\n\nThe Quran does not state that Jesus suffered in a false body or more generally support \"discarnate principles of Docetism\". Christian commentators have often argued that in its denial of killing or crucifixion of Jesus the Quran was influenced by Docetic ideas, but this is a hypothesis that has no real proof.\n\nSince Arthur Drews published his \"The Christ Myth\" (Die Christusmythe) in 1909, occasional connections have been drawn between docetist theories and the modern idea that Christ was a myth. Shailer Mathews called Drews' theory a \"modern docetism\". Frederick Cornwallis Conybeare thought any connection to be based on a misunderstanding of docetism. The idea recurred in classicist Michael Grant's 1977 review of the evidence for Jesus, who compared modern scepticism about a historical Jesus to the ancient docetic idea that Jesus only \"seemed\" to come into the world \"in the flesh\". Modern theories did away with \"seeming\".\n\n\n\n\n"}
{"id": "8347", "url": "https://en.wikipedia.org/wiki?curid=8347", "title": "Greek drachma", "text": "Greek drachma\n\nDrachma ( , ; pl. \"drachmae\" or \"drachmas\") was the currency used in Greece during several periods in its history:\n\nIt was also a small unit of weight.\n\nThe name \"drachma\" is derived from the verb (, \"(I) grasp\"). It is believed that the same word with the meaning of \"handful\" or \"handle\" is found in Linear B tablets of the Mycenean Pylos. Initially a drachma was a fistful (a \"grasp\") of six \"oboloí\" or \"obeloí\" (metal sticks, literally \"spits\") used as a form of currency as early as 1100 BC and being a form of \"bullion\": bronze, copper, or iron ingots denominated by weight. A hoard of over 150 rod-shaped obeloi was uncovered at Heraion of Argos in Peloponnese. Six of them are displayed at the Numismatic Museum of Athens.\n\nIt was the standard unit of silver coinage at most ancient Greek mints, and the name \"obol\" was used to describe a coin that was one-sixth of a drachma. The notion that \"drachma\" derived from the word for fistful was recorded by Herakleides of Pontos (387–312 BC) who was informed by the priests of Heraion that Pheidon, king of Argos, dedicated rod-shaped obeloi to Heraion. Similar information about Pheidon's obeloi was also recorded at the Parian Chronicle.\n\nAncient Greek coins normally had distinctive names in daily use. The Athenian tetradrachm was called owl, the Aeginetic stater was called chelone, the Corinthian stater was called \"hippos\" (horse) and so on. Each city would mint its own and have them stamped with recognizable symbols of the city, known as badge in numismatics, along with suitable inscriptions, and they would often be referred to either by the name of the city or of the image depicted. The exact exchange value of each was determined by the quantity and quality of the metal, which reflected on the reputation of each mint.\n\nAmong the Greek cities that used the drachma were: Abdera, Abydos, Alexandria, Aetna, Antioch, Athens, Chios, Cyzicus, Corinth, Ephesus, Eretria, Gela, Catana, Kos, Maronia, Naxos, Pella, Pergamum, Rhegion, Salamis, Smyrni, Sparta, Syracuse, Tarsus, Thasos, Tenedos, Troy and more.\n\nThe 5th century BC Athenian \"tetradrachm\" (\"four drachmae\") coin was perhaps the most widely used coin in the Greek world prior to the time of Alexander the Great (along with the Corinthian stater). It featured the helmeted profile bust of Athena on the obverse (front) and an owl on the reverse (back). In daily use they were called \"glaukes\" (owls), hence the proverb , 'an owl to Athens', referring to something that was in plentiful supply, like 'coals to Newcastle'. The reverse is featured on the national side of the modern Greek 1 euro coin.\n\nDrachmae were minted on different weight standards at different Greek mints. The standard that came to be most commonly used was the Athenian or Attic one, which weighed a little over 4.3 grams.\n\nAfter Alexander the Great's conquests, the name \"drachma\" was used in many of the Hellenistic kingdoms in the Middle East, including the Ptolemaic kingdom in Alexandria and the Parthian Empire based in what is modern-day Iran. The Arabic unit of currency known as \"dirham\" (), known from pre-Islamic times and afterwards, inherited its name from the drachma or didrachm (, 2 drachmae); the dirham is still the name of the official currencies of Morocco and the United Arab Emirates. The Armenian dram () also derives its name from the drachma.\n\nIt is difficult to estimate comparative exchange rates with modern currency because the range of products produced by economies of centuries gone by were different from today, which makes purchasing power parity (PPP) calculations very difficult; however, some historians and economists have estimated that in the 5th century BC a drachma had a rough value of 25 U.S. dollars (in the year 1990 – equivalent to 46.50 USD in 2015), whereas classical historians regularly say that in the heyday of ancient Greece (the fifth and fourth centuries) the daily wage for a skilled worker or a hoplite was one drachma, and for a heliast (juror) half a drachma since 425 BC.\n\nModern commentators derived from Xenophon that half a drachma per day (360 days per year) would provide \"a comfortable subsistence\" for \"the poor citizens\" (for the head of a household in 355 BC). Earlier in 422 BC, we also see in Aristophanes (\"Wasps\", line 300–302) that the daily half-drachma of a juror is just enough for the daily subsistence of a family of three.\n\nA modern person might think of one drachma as the rough equivalent of a skilled worker's daily pay in the place where they live, which could be as low as US$1, or as high as $100, depending on the country.\n\nFractions and multiples of the drachma were minted by many states, most notably in Ptolemaic Egypt, which minted large coins in gold, silver and bronze.\n\nNotable Ptolemaic coins included the gold \"pentadrachm\" and \"octadrachm\", and silver \"tetradrachm\", \"decadrachm\" and \"pentakaidecadrachm\". This was especially noteworthy as it would not be until the introduction of the Guldengroschen in 1486 that coins of substantial size (particularly in silver) would be minted in significant quantities.\n\nFor the Roman successors of the drachma, see Roman provincial coins.\n\nThe weight of the silver drachma was approximately 4.3 grams or 0.15 ounces, although weights varied significantly from one city-state to another. It was divided into six obols of 0.72 grams, which were subdivided into four tetartemoria of 0.18 grams, one of the smallest coins ever struck, approximately 5–7 mm in diameter.\n\nMinae and talents were never actually minted: they represented weight measures used for commodities (e.g. grain) as well as metals like silver or gold. The New Testament mentions both didrachma and, by implication, tetradrachma in context of the Temple tax. Luke's Gospel includes a parable told by Jesus of a woman with 10 drachmae, who lost one and searched her home until she found it.\n\nThe drachma was reintroduced in May 1832, shortly before the establishment of the modern state of Greece (with the exception of the subdivision Taurus). It replaced the \"phoenix\" at par. The drachma was subdivided into 100 lepta.\n\nThe first coinage consisted of copper denominations of 1, 2, 5 and 10 lepta, silver denominations of , , 1 and 5 drachmae and a gold coin of 20 drachmae. The drachma coin weighed 4.5 g and contained 90% silver, with the 20-drachma coin containing 5.8 g of gold.\n\nIn 1868, Greece joined the Latin Monetary Union and the drachma became equal in weight and value to the French franc. The new coinage issued consisted of copper coins of 1, 2, 5 and 10 lepta, with the 5- and 10-lepta coins bearing the names \"obolos\" () and \"diobolon\" (), respectively; silver coins of 20 and 50 lepta, 1, 2 and 5 drachmae and gold coins of 5, 10 and 20 drachmae. (Very small numbers of 50- and 100-drachma coins in gold were also issued.)\n\nIn 1894, cupro-nickel 5-, 10- and 20-lepta coins were introduced. No 1-lepton or 2-lepta coin had been issued since the late 1870s. Silver coins of 1 and 2 drachmae were last issued in 1911, and no coins were issued between 1912 and 1922, during which time the Latin Monetary Union collapsed due to World War I.\n\nBetween 1926 and 1930, a new coinage was introduced for the new Hellenic Republic, consisting of cupro-nickel coins in denominations of 20 lepta, 50 lepta, 1 drachma, and 2 drachmae; nickel coins of 5 drachmae; and silver coins of 10 and 20 drachmae. These were the last coins issued for the first modern drachma, and none were issued for the second.\n\nNotes were issued by the National Bank of Greece from 1841 until 2001 when Greece joined the Euro. Early denominations ranged from 10 to 500 drachmae. Smaller denominations (1, 2, 3 and 5 drachmae) were issued from 1885, with the first 5-drachma notes being made by cutting 10-drachma notes in half.\n\nWhen Greece finally achieved its independence from the Ottoman Empire in 1828, the phoenix was introduced as the monetary unit; its use was short-lived, however, and in 1832 the phoenix was replaced by the drachma, adorned with the image of King Otto of Greece, who reigned as modern Greece's first king from 1832 to 1862. The drachma was divided into 100 lepta. In 2002 the drachma ceased to be legal tender after the euro, the monetary unit of the European Union, became Greece's sole currency.\n\nBetween 1917 and 1920, the Greek government issued paper money in denominations of 10 lepta, 50 lepta, 1 drachma, 2 drachmae, and 5 drachmae. The National Bank of Greece introduced 1000-drachma notes in 1901, and the Bank of Greece introduced 5000-drachma notes in 1928. The Greek government again issued notes between 1940 and 1944, in denominations ranging from 50 lepta to 20 drachmae.\n\nIn 1922, the Greek government issued a forced loan in order to finance the budget deficit. On April 1, 1922, the government decreed that half of all bank notes had to be surrendered and exchanged for 6.5% bonds. The notes were then cut in half, with the portion bearing the Greek crown standing in for the bonds while the other half was exchanged for a new issue of central bank notes (at half the original value). The forced loan raised 1.6 billion drachma, roughly the size of the deficit. \n\nDuring the German-Italian occupation of Greece from 1941 to 1944, catastrophic hyperinflation and Nazi looting of the Greek treasury caused much higher denominations to be issued, culminating in 100,000,000,000-drachma notes in 1944.\n\nIn November 1944, after Greece was liberated from Germany, old drachmae were exchanged for new ones at the rate of 50,000,000,000 to 1. Only paper money was issued. The government issued notes of 1, 5, 10 and 20 drachmae, with the Bank of Greece issuing 50-, 100-, 500-, 1000-, 5000-, and 10,000-drachma notes. This drachma also suffered from high inflation. The government later issued 100-, 500-, and 1000-drachma notes, and the Bank of Greece issued 20,000-and 50,000-drachma notes.\n\nIn 1953, in an effort to halt inflation, Greece joined the Bretton Woods system. In 1954, the drachma was revalued at a rate of 1000 to 1. The new currency was pegged at 30 drachmae = 1 United States dollar. In 1973, the Bretton Woods System was abolished; over the next 25 years the official exchange rate gradually declined, reaching 400 drachmae to 1 U. S. dollar. On 1 January 2002, the Greek drachma was officially replaced as the circulating currency by the euro, and it has not been legal tender since 1 March 2002.\n\nThe first issue of coins minted in 1954 consisted of holed aluminium 5-, 10- and 20-lepton pieces, with 50-lepton, 1-, 2-, 5- and 10-drachma pieces in cupro-nickel. A silver 20-drachma piece was issued in 1960, replacing the 20-drachma banknote, and also minted only in collector sets in 1965. Coins in denominations from 50 lepta to 20 drachmae carried a portrait of King Paul (1947–1964). New coins were introduced in 1966, ranging from 50 lepta to 10 drachmae, depicting King Constantine II (1964–1974). A silver 30 drachma coin for the centennial of Greece's royal dynasty was minted in 1963. The following year a non-circulating coin of this value was produced to commemorate the royal wedding. The reverse of all coins was altered in 1971 to reflect the military junta which was in power from 1967 to 1974. This design included a soldier standing in front of the flames of the rising phoenix.\n\nA 20-drachmae coin in cupro-nickel with an image of Europa on the obverse was issued in 1973. In the latter part of 1973, several new coin types were introduced: unholed aluminium (10 and 20 lepta), nickel-brass (50 lepta, 1 drachma, and 2 drachmae) and cupro-nickel (5, 10, and 20 drachmae). These provisional coins carried the design of the phoenix rising from the flame on the obverse, and used the country's new designation as the \"Hellenic Republic\", replacing the coins also issued in 1973 as the Kingdom of Greece with King Constantine II's portrait. A new series of all 8 denominations was introduced in 1976 carrying images of early national heroes on the smaller values.\n\nCupro-nickel 50-drachmae coins were introduced in 1980. In 1986, nickel-brass 50-drachma coins were introduced, followed by copper 1- and 2-drachma pieces in 1988 and nickel-brass coins of 20 and 100 drachmae in 1990. In 2000, a set of 6 themed 500-drachma coins was issued to commemorate the 2004 Athens Olympic Games.\n\nCoins in circulation at the time of the adoption of the euro were\n\nThe first issues of banknotes were in denominations of 10, 20 and 50 drachmae, soon followed by 100, 500 and 1000 drachmae by 1956. 5000-drachma notes were introduced in 1984, followed by 10,000-drachma notes in 1995 and 200-drachma notes in 1997.\n\nBanknotes in circulation at the time of the adoption of the euro were\n\nIn Unicode, the currency symbol is . There is a special Attic numeral, for the value of one drachma but it fails to render in most browsers.\n\nThe Drachmi Greek Democratic Movement Five Stars which was founded in 2013, aims to restore the Drachma, as Greece's currency.\n\n\n\n \n"}
{"id": "8349", "url": "https://en.wikipedia.org/wiki?curid=8349", "title": "Denarius", "text": "Denarius\n\nThe denarius (, dēnāriī, ) was the standard Roman silver coin from its introduction in the Second Punic War c. 211 BC to the reign of Gordian III (AD 238–244), when it was gradually replaced by the Antoninianus. It continued to be minted in very small quantities, likely for ceremonial purposes, until and through the tetrarchy (293–313).\n\nThe word \"dēnārius\" is derived from the Latin \"dēnī\" \"containing ten\", as its value was originally of 10 assēs. The word for \"money\" descends from it in Italian (\"denaro\"), Slovene (\"denar\"), Portuguese (\"dinheiro\"), and Spanish (\"dinero\"). Its name also survives in the dinar currency.\n\nIts symbol is represented in Unicode as 𐆖 (U+10196), however it can also be represented as X̶ (capital letter X with combining long stroke overlay).\n\nA predecessor of the \"denarius\" was first struck in 267 BC, five years before the First Punic War, with an average weight of 6.81 grams, or of a Roman pound. Contact with the Greeks prompted a need for silver coinage in addition to the bronze currency that the Romans were using at that time. The predecessor of the \"denarius\" was a Greek-styled silver coin called the \"didrachm\" which was struck in Neapolis and other Greek cities in southern Italy. These coins were inscribed for Rome but closely resemble their Greek counterparts. They were most likely used for trade purposes and were seldom used in Rome.\n\nThe first distinctively Roman silver coin appeared around 226 BC. Classic historians sometimes called these coins \"denarii\", but they are classified by modern numismatists as \"quadrigati\", which is derived from the quadriga, or four-horse chariot, on the reverse, and which with a two-horse chariot or \"biga\" was the prototype for the most common designs used on Roman silver coins for the next 150 years.\n\nRome overhauled its coinage around 211 BC and introduced the denarius alongside a short-lived denomination called the victoriatus. This denarius contained an average 4.5 grams, or of a Roman pound, of silver. It formed the backbone of Roman currency throughout the Roman republic.\n\nThe denarius began to undergo slow debasement toward the end of the republican period. Under the rule of Augustus (31 BC-AD 14) its silver content fell to 3.9 grams (a theoretical weight of of a Roman pound). It remained at nearly this weight until the time of Nero (AD 37–68), when it was reduced to of a pound, or 3.4 grams. Debasement of the coin's silver content continued after Nero. Later Roman emperors reduced its content to 3 grams around the late 3rd century.\n\nThe value at its introduction was 10 asses, giving the denarius its name, which translates as \"containing ten\". In about 141 BC, it was re-tariffed at 16 asses, to reflect the decrease in weight of the as. The denarius continued to be the main coin of the Roman Empire until it was replaced by the antoninianus in the middle of the 3rd century. The coin was last issued, in bronze, under Aurelian between AD 270 and 275, and in the first years of the reign of Diocletian. ('Denarius', in \"A Dictionary of Ancient Roman Coins\", by John R. Melville-Jones (1990)).\n\nIt is difficult to give even rough comparative values for money from before the 20th century, as the range of products and services available for purchase was so different. Classical historians often say that in the late Roman Republic and early Roman Empire (~27 BC) the daily wage for an unskilled laborer and common soldier was 1 denarius (with no tax deductions) or about US$2.80 in bread. During the republic (509–27 BC), legionary pay was 112.5 denarii per year (0.3 per day), later doubled by Julius Caesar to 225 denarii (0.6 per day), with soldiers having to pay for their own food and arms. Centurions received considerably higher pay: under Augustus, the lowest rank of centurion was paid 3,750 denarii per year, and the highest rank, 15,000 denarii.\n\nThe silver content of the denarius under the Roman Empire (after Nero) was about 50 grains, 3.24 grams, or (0.105ozt) troy ounce. On June 6, 2011, this was about US$3.62 in value if the silver were 0.999 pure.\n\nThe fineness of the silver content varied with political and economic circumstances. From a purity of greater than 90% silver in the 1st century AD, the denarius fell to under 60% purity by the year 200, and plummeted to 5% purity by the year 300. By the reign of Gallienus, the \"antoninianus\" was a copper coin with a thin silver wash.\n\nBy comparison, a laborer earning the minimum wage in the United States in January 2014 made US$58 for an 8-hour day, before taxes (based on the mode value of $7.25 per hour, which was true then in 20 states) and an employee earning the minimum wage in the United Kingdom in 2014 made £52 for an 8-hour day, before taxes.\n\nIn the final years of the 1st century BC Tincomarus, a local ruler in southern Britain, started issuing coins that appear to have been made from melted down \"denarii\". The coins of Eppillus, issued around Calleva Atrebatum around the same time, appear to have derived design elements from various \"denarii\" such as those of Augustus and M. Volteius.\n\nEven after the \"denarius\" was no longer regularly issued, it continued to be used as a unit of account, and the name was applied to later Roman coins in a way that is not understood. The Arabs who conquered large parts of the land that once belonged to the Eastern Roman Empire issued their own gold dinar. The lasting legacy of the \"denarius\" can be seen in the use of \"d\" as the abbreviation for the British penny until 1971. It also survived in France as the name of a coin, the denier. The denarius also survives in the common Arabic name for a currency unit, the \"dinar\" used from pre-Islamic times, and still used in several modern Arab nations. The major currency unit in former Principality of Serbia, Kingdom of Serbia and former Yugoslavia was \"dinar\", and it is still used in present-day Serbia. The Macedonian currency \"denar\" is also derived from the Roman denarius. The Italian word \"denaro\", the Spanish word \"dinero\", the Portuguese word \"dinheiro\", and the Slovene word \"\", all meaning money, are also derived from Latin \"denarius\".\n\n1 gold aureus = 2 gold quinarii = 25 silver denarii = 50 silver quinarii = 100 bronze sestertii = 200 bronze dupondii = 400 copper asses = 800 copper semisses = 1600 copper quadrantes\n\nIn the New Testament, the gospels refer to the denarius as a day's wage for a common laborer (Matthew 20:2, John 12:5). In the Book of Revelation, during the Third Seal: Black Horse, a choinix (or quart) of wheat and three quarts of barley were each valued at one denarius. Bible scholar Robert H. Mounce says the price of the wheat and barley as described in the vision appears to be ten to twelve times their normal cost in ancient times. Revelation describes a condition where basic goods are sold at greatly inflated prices. Thus, the black horse rider depicts times of deep scarcity or famine but not of starvation. The English word \"quart\" translates \"choinix\". Apparently, a choinix of wheat was the daily ration of one adult. Thus, in the conditions pictured by Revelation 6 the normal income for a working-class family would buy enough food for only one person. The less costly barley would feed three people for one day's wages.\n\nThe denarius is also mentioned in the Parable of the Good Samaritan (Luke 10:25–37) has also been commonly identified as the tribute penny held by Jesus in the Render unto Caesar passage Matthew 22:15–22 and Mark 12:13–17.\n\n\n"}
{"id": "8350", "url": "https://en.wikipedia.org/wiki?curid=8350", "title": "Della Rovere", "text": "Della Rovere\n\nThe Della Rovere family (; literally \"of the oak tree\") was a noble family of Italy. It had humble origins in Savona, in Liguria, and acquired power and influence through nepotism and ambitious marriages arranged by two Della Rovere popes: Francesco Della Rovere, who ruled as Sixtus IV from 1471 to 1484) and his nephew Giuliano, who became Julius II in 1503. Sixtus IV built the Sistine Chapel, which is named for him. The Basilica of San Pietro in Vincoli in Rome is the family church of the Della Rovere. Members of the family were influential in the Church of Rome, and as dukes of Urbino; that title was extinguished with the death of Francesco Maria II in 1631, and the family died out with the death of his grand-daughter Vittoria, Grand Duchess of Tuscany.\n\nFrancesco Della Rovere was born into a poor family in Liguria in north-west Italy in 1414, the son of Leonardo della Rovere of Savona. He was elected pope in 1471. As Sixtus IV he was both wealthy and powerful, and at once set about giving power and wealth to his nephews of the Della Rovere and Riario families. Within months of his election, he had made Giuliano della Rovere (the future pope Julius II) and Pietro Riario both cardinals and bishops; four other nephews were also made cardinals. He made Giovanni Della Rovere, who was not a priest, prefect of Rome, and arranged for him to marry into the da Montefeltro family, dukes of Urbino. Sixtus claimed descent from a noble Della Rovere family, the counts of Vinovo in Piemonte, and adopted their coat-of-arms.\n\nGuidobaldo da Montefeltro adopted Francesco Maria I della Rovere, his sister's child and nephew of Pope Julius II. Guidobaldo I, who was heirless, called Francesco Maria at his court, and named him as heir of the Duchy of Urbino in 1504, this through the intercession of Julius II. In 1508, Francesco Maria inherited the duchy thereby starting the line of Rovere Dukes of Urbino. That dynasty ended in 1626 when Pope Urban VIII incorporated Urbino into the papal dominions. As compensation to the last sovereign duke, the title only could be continued by Francesco Maria II, and after his death by his heir, Federico Ubaldo.\n\nVittoria, last descendant of the della Rovere family (she was the only child of Federico Ubaldo), married Ferdinando II de' Medici, Grand Duke of Tuscany. They had two children: Cosimo III, Tuscany's longest reigning monarch, and Francesco Maria de' Medici, a prince of the Church.\n\n\nAmong the many people who did not belong to this family, but bore the same name, are:\nand various artists, including:\n\n"}
{"id": "8351", "url": "https://en.wikipedia.org/wiki?curid=8351", "title": "David Mamet", "text": "David Mamet\n\nDavid Alan Mamet (; born November 30, 1947) is an American playwright, film director, screenwriter and author. He won a Pulitzer Prize and received Tony nominations for his plays \"Glengarry Glen Ross\" (1984) and \"Speed-the-Plow\" (1988). He first gained critical acclaim for a trio of off-Broadway 70s plays: \"The Duck Variations,\" \"Sexual Perversity in Chicago,\" and \"American Buffalo.\" His plays \"Race\" and \"The Penitent\", respectively, opened on Broadway in 2009 and previewed off-Broadway in 2017.\n\nFeature films that Mamet both wrote and directed include \"House of Games\" (1987), \"Homicide\" (1991), \"The Spanish Prisoner\" (1997), \"Heist\" (2001), and \"Redbelt\" (2008). His screenwriting credits include \"The Postman Always Rings Twice\" (1981), \"The Verdict\" (1982), \"The Untouchables\" (1987), \"Hoffa\" (1992), \"Wag the Dog\" (1997), and \"Hannibal\" (2001). Mamet himself wrote the screenplay for the 1992 adaptation of \"Glengarry Glen Ross\", and wrote and directed the 1994 adaptation of his play \"Oleanna\" (1992). He was the executive producer and frequent writer for the TV show \"The Unit\" (2006–2009).\n\nMamet's books include: \"The Old Religion\" (1997), a novel about the lynching of Leo Frank; \"Five Cities of Refuge: Weekly Reflections on Genesis, Exodus, Leviticus, Numbers and Deuteronomy\" (2004), a Torah commentary with Rabbi Lawrence Kushner; \"The Wicked Son\" (2006), a study of Jewish self-hatred and antisemitism; \"Bambi vs. Godzilla\", a commentary on the movie business; \"The Secret Knowledge: On the Dismantling of American Culture\" (2011), a commentary on cultural and political issues; and \"Three War Stories\" (2013), a trio of novellas about the physical and psychological effects of war.\n\nMamet was born in 1947 in Chicago to Lenore June (née Silver), a teacher, and Bernard Morris Mamet, a labor attorney. One of his earliest jobs was as a busboy at Chicago's London House and The Second City. He also worked as an actor, editor for \"Oui\" magazine and as a cab-driver. He was educated at the progressive Francis W. Parker School and at Goddard College in Plainfield, Vermont. At the Chicago Public Library Foundation 20th anniversary fundraiser in 2006, though, Mamet announced \"My alma mater is the Chicago Public Library. I got what little educational foundation I got in the third-floor reading room, under the tutelage of a Coca-Cola sign\".\n\nAfter a move to Chicago's North Side neighborhood, Mamet encountered theater director Robert Sickinger, and began to work occasionally at Sickinger's Hull House Theatre. This represented the beginning of Mamet's lifelong involvement with the theater.\n\nMamet is a founding member of the Atlantic Theater Company; he first gained acclaim for a trio of off-Broadway plays in 1976, \"The Duck Variations,\" \"Sexual Perversity in Chicago,\" and \"American Buffalo.\" He was awarded the Pulitzer Prize in 1984 for \"Glengarry Glen Ross,\" which received its first Broadway revival in the summer of 2005. His play \"Race\", which opened on Broadway on December 6, 2009 and featured James Spader, David Alan Grier, Kerry Washington, and Richard Thomas in the cast, received mixed reviews. His play \"The Anarchist\", starring Patti LuPone and Debra Winger, in her Broadway debut, opened on Broadway on November 13, 2012 in previews and was scheduled to close on December 16, 2012. His 2017 play \"The Penitent\" previewed off-Broadway on February 8, 2017.\n\nIn 2002, Mamet was inducted into the American Theater Hall of Fame. Mamet later received the PEN/Laura Pels International Foundation for Theater Award for Grand Master of American Theater in 2010.\n\nIn 2017, Mamet released an online class for writers entitled \"David Mamet teaches dramatic writing\".\n\nIt was announced in 2019 that David Mamet will return to the London West End with his new play Bitter Wheat starring John Malkovich<ref>\n"}
{"id": "8352", "url": "https://en.wikipedia.org/wiki?curid=8352", "title": "December 6", "text": "December 6\n\n\n\n\n"}
{"id": "8353", "url": "https://en.wikipedia.org/wiki?curid=8353", "title": "December 5", "text": "December 5\n\n\n\n"}
{"id": "8354", "url": "https://en.wikipedia.org/wiki?curid=8354", "title": "December 4", "text": "December 4\n\n\n\n\n"}
{"id": "8355", "url": "https://en.wikipedia.org/wiki?curid=8355", "title": "December 3", "text": "December 3\n\n\n\n"}
{"id": "8356", "url": "https://en.wikipedia.org/wiki?curid=8356", "title": "December 2", "text": "December 2\n\n\n\n\n"}
{"id": "8357", "url": "https://en.wikipedia.org/wiki?curid=8357", "title": "December 1", "text": "December 1\n\n\n\n"}
{"id": "8359", "url": "https://en.wikipedia.org/wiki?curid=8359", "title": "December 24", "text": "December 24\n\n\n\n"}
{"id": "8360", "url": "https://en.wikipedia.org/wiki?curid=8360", "title": "December 26", "text": "December 26\n\n\n\n\n\n"}
{"id": "8361", "url": "https://en.wikipedia.org/wiki?curid=8361", "title": "Definable real number", "text": "Definable real number\n\nInformally, a definable real number is a real number that can be uniquely specified by its description. The description may be expressed as a construction or as a formula of a formal language. For example, the positive square root of 2, formula_1, can be defined as the unique positive solution to the equation formula_2, and it can be constructed with a compass and straightedge.\n\nDifferent choices of a formal language or its interpretation can give rise to different notions of definability. Specific varieties of definable numbers include the constructible numbers of geometry, the algebraic numbers, and the computable numbers.\n\nOne way of specifying a real number uses geometric techniques. A real number \"r\" is a constructible number if there is a method to construct a line segment of length \"r\" using a compass and straightedge, beginning with a fixed line segment of length 1.\n\nEach positive integer, and each positive rational number, is constructible. The positive square root of 2 is constructible. However, the cube root of 2 is not constructible; this is related to the impossibility of doubling the cube.\n\nA real number \"r\" is called an algebraic number if there is a polynomial \"p\"(\"x\"), with only integer coefficients, so that \"r\" is a root of \"p\", that is, \"p\"(\"r\")=0. \nEach algebraic number can be defined individually using the order relation on the reals. For example, if a polynomial \"q\"(\"x\") has 5 roots, the third one can be defined as the unique \"r\" such that \"q\"(\"r\") = 0 and such that there are two distinct numbers less than \"r\" for which \"q\" is zero.\n\nAll rational numbers are algebraic, and all constructible numbers are algebraic. There are numbers such as the cube root of 2 which are algebraic but not constructible.\n\nThe algebraic numbers form a subfield of the real numbers. This means that 0 and 1 are algebraic numbers and, moreover, if \"a\" and \"b\" are algebraic numbers, then so are \"a\"+\"b\", \"a\"−\"b\", \"ab\" and, if \"b\" is nonzero, \"a\"/\"b\".\n\nThe algebraic numbers also have the property, which goes beyond being a subfield of the reals, that for each positive integer \"n\" and each algebraic number \"a\", all of the \"n\"th roots of \"a\" that are real numbers are also algebraic.\n\nThere are only countably many algebraic numbers, but there are uncountably many real numbers, so in the sense of cardinality most real numbers are not algebraic. This nonconstructive proof that not all real numbers are algebraic was first published by\nGeorg Cantor in his 1874 paper \"On a Property of the Collection of All Real Algebraic Numbers\".\n\nNon-algebraic numbers are called transcendental numbers. Specific examples of transcendental numbers include π and Euler's number \"e\".\n\nA real number is a computable number if there is an algorithm that, given a natural number \"n\", produces a decimal expansion for the number accurate to \"n\" decimal places. This notion was introduced by Alan Turing in 1936.\n\nThe computable numbers include the algebraic numbers along with many transcendental numbers including π and \"e\". Like the algebraic numbers, the computable numbers also form a subfield of the real numbers, and the positive computable numbers are closed under taking \"n\"th roots for each positive \"n\".\n\nNot all real numbers are computable. The entire set of computable numbers is countable, so most reals are not computable. Specific examples of noncomputable real numbers include the limits of Specker sequences, and algorithmically random real numbers such as Chaitin's Ω numbers.\n\nAnother notion of definability comes from the formal theories of arithmetic, such as Peano arithmetic. The language of arithmetic has symbols for 0, 1, the successor operation, addition, and multiplication, intended to be interpreted in the usual way over the natural numbers. Because no variables of this language range over the real numbers, a different sort of definability is needed to refer to real numbers. A real number \"a\" is \"definable in the language of arithmetic\" (or \"arithmetical\") if its Dedekind cut can be defined as a predicate in that language; that is, if there is a first-order formula \"φ\" in the language of arithmetic, with three free variables, such that\n\nA real number \"a\" is first-order definable in the language of set theory, without parameters, if there is a formula \"φ\" in the language of set theory, with one free variable, such that \"a\" is the unique real number such that \"φ\"(\"a\") holds (see ). This notion cannot be expressed as a formula in the language of set theory.\n\nAll analytical numbers, and in particular all computable numbers, are definable in the language of set theory. Thus the real numbers definable in the language of set theory include all familiar real numbers such as 0, 1, π, \"e\", et cetera, along with all algebraic numbers. Assuming that they form a set in the model, the real numbers definable in the language of set theory over a particular model of ZFC form a field. \nEach set model \"M\" of ZFC set theory that contains uncountably many real numbers must contain real numbers that are not definable within \"M\" (without parameters). This follows from the fact that there are only countably many formulas, and so only countably many elements of \"M\" can be definable over \"M\". Thus, if \"M\" has uncountably many real numbers, we can prove from \"outside\" \"M\" that not every real number of \"M\" is definable over \"M\". \nThis argument becomes more problematic if it is applied to class models of ZFC, such as the von Neumann universe . The argument that applies to set models cannot be directly generalized to class models in ZFC because the property \"the real number \"x\" is definable over the class model \"N\"\" cannot be expressed as a formula of ZFC. Similarly, the question whether the von Neumann universe contains real numbers that it cannot define cannot be expressed as a sentence in the language of ZFC. Moreover, there are countable models of ZFC in which all real numbers, all sets of real numbers, functions on the reals, etc. are definable .\n\n\n"}
{"id": "8362", "url": "https://en.wikipedia.org/wiki?curid=8362", "title": "Diego de Almagro", "text": "Diego de Almagro\n\nDiego de Almagro (; – July 8, 1538), also known as El Adelantado and El Viejo, was a Spanish conquistador known for his exploits in western South America. He participated with Francisco Pizarro in the Spanish conquest of Peru. From Peru Almagro led an expedition that made him the second European to set foot in central Chile (after ). Back in Peru a longstanding conflict with Pizarro over the control of the former Inca capital of Cuzco erupted into a civil war between the two bands of conquistadores. In the battle of Las Salinas in 1538 Almagro was defeated by the Pizarro brothers and months later he was executed.\n\nThe origins of Diego de Almagro remain obscure. He was born in 1475 in the village of Almagro, 1 in Ciudad Real, where he took the surname for being the illegitimate son of Juan de Montenegro and Elvira Gutiérrez. In order to save the honor of the mother, her relatives took her infant and moved him to the nearby town of Bolaños de Calatrava, being raised in this town and in Aldea del Rey, run by Sancha López del Peral.\n\nWhen he turned 4 he returned to Almagro, being under the tutelage of an uncle named Hernán Gutiérrez until he was 15 years old, when due to his uncle's hardness he ran away from home. He went to the home of his mother, who was now living with her new husband, to tell her what had happened and that she was going to travel the world, asking for some bread to help her live in her misery. His mother, anguished, gave him a piece of bread and some coins and said: \"\"Take, son, and do not give me more pressure, and go, and God help in your adventure.\"\"\n\nHe went to Seville and after probably stealing to survive the boy becomes a \"criado\" or servant and raised by Don Luis de Polanco, one of the four mayors of the Catholic Kings and later his counselor, and who was mayor of that city. While performing his duties as a servant, Almagro stabbed another servant for certain differences, leaving him with injuries so serious that they motivated that a trial against him be promoted.\n\nBeing wanted for justice, Don Luis de Polanco, making use of his influence, got Don Pedro Arias de Avila to allow him to embark in one of the ships that would go to the New World from the port of Sanlucar de Barrameda. The Casa de Contratacion demanded that the men who crossed the Indies carry their own weapons, clothes, and farming tools, which Don Polanco provided to his servant.\nDiego de Almagro arrived in the New World on June 30, 1514, under the expedition that Ferdinand II of Aragon had sent under the guidance of Pedrarias Dávila. The expedition had landed in the city of Santa María la Antigua del Darién, Panama, where many other future conquistadors had already arrived, among them Francisco Pizarro.\n\nThere are not many details of Almagro's activities during this period, but it is known that he accompanied various sailors who departed from the city of Darien between 1514 and 1515. De Almagro eventually returned and settled in Darien, where he was granted an encomienda. He built a house and made a living from agriculture.\n\nDe Almagro undertook his first conquest on November 1515, commanding 260 men as he founded Villa del Acla, named after the Indian place. Due to illness he had to leave behind this mission to the licenciate Gaspar de Espinosa.\n\nEspinosa decided to undertake a new expedition, which departed in December 1515 with 200 men, including De Almagro and Francisco Pizarro, who for the first time was designated as a captain. During this expedition, which lasted 14 months, De Almagro, Pizarro and Hernando de Luque became close friends.\n\nAlso during this time De Almagro established a friendship with Vasco Núñez de Balboa, who was in charge of Acla. De Almagro wanted to have a ship built with the remaining materials of the Espinosa expedition, to be finished on the coast of the \"Great South Sea\", as the Pacific Ocean was first called by the Spanish. Current historians do not believe that De Almagro was expected to participate in Balboa's expedition and probably returned to Darien.\n\nDe Almagro took part in the various expeditions that took place in the Gulf of Panama, taking part again in Espinosa's parties. Espinosa was supported by using Balboa's ships. De Almagro was recorded as a witness on the lists of natives whom Espinosa ordered to be carried. De Almagro remained as an early settler in the newly founded city of Panama. For four years he stayed there, working at the management of his properties and those of Pizarro. He took Ana Martínez, an indigenous woman, as a common-law wife. In this period, his first son, el \"Mozo\", was born to them.\n\nBy 1524 an association of conquest regarding South America was formalized among Almagro, Pizarro and Luque. By the beginning of August 1524, they had received the requisite permission to discover and conquer lands further south. De Almagro would remain in Panama to recruit men and gather supplies for the expeditions led by Pizarro.\n\nAfter several expeditions to South America, Pizarro secured his stay in Peru with the \"Capitulation\" on 6 July 1529. During Pizarro's continued exploration of Incan territory, he and his men succeeded in defeating the Inca army under Emperor Atahualpa during the Battle of Cajamarca in 1532. De Almagro joined Pizarro soon afterward, bringing more men and arms.\n\nAfter Peru fell to the Spanish, both Pizarro and De Almagro initially worked together in the founding of new cities to consolidate their dominions. As such, Pizarro dispatched De Almagro to pursue Quizquiz, fleeing to the Inca Empire's northern city of Quito. Their fellow conquistador Sebastián de Belalcázar, who had gone forth without Pizarro's approval, had already reached Quito and witnessed the destruction of the city by Inca general Rumiñawi. The Inca warrior had ordered the city to be burned and its gold to be buried at an undisclosed location where the Spanish could never find it. The arrival of Pedro de Alvarado from Guatemala, in search of Inca gold further complicated the situation for Almagro and Belalcázar. Alvarado's presence, however, did not last long as he left South America in exchange for monetary compensation from Pizarro.\n\nIn an attempt to claim Quito ahead of Belalcázar, in August 1534 De Almagro founded a city on the shores of Laguna de Colta (Colta Lake) in the foothills of Chimborazo, some south of present-day Quito, and named it \"Santiago de Quito.\" Four months later would come the foundation of the Peruvian city of Trujillo, which Almagro named as \"Villa Trujillo de Nueva Castilla\" (the Village of Trujillo in New Castille) in honor of Francisco Pizarro's birthplace, Trujillo in Extremadura, Spain. These events were the height of the Pizarro-Almagro friendship, which historians describe as one of the last events in which their friendship soon faded and entered a period of turmoil for the control of the Incan capital of Cuzco.\n\nAfter splitting the treasure of Inca emperor Atahualpa, both Pizarro and Almagro left towards Cuzco and took the city in 1533. However, De Almagro's friendship with Pizarro showed signs of deterioration in 1526 when Pizarro, in the name of the rest of the conquistadors, called forth the \"Capitulacion de Toledo\" law in which King Charles I of Spain had laid out his authorization for the conquest of Peru and the awards every conquistador would receive from it. Long before, however, each conquistador had promised to equally split the benefits. Pizarro managed to have a larger stake and awards for himself. Despite this, De Almagro still obtained an important fortune for his services, and the King awarded him in November 1532 the noble title of \"Don\" and he was assigned a personal coat of arms.\n\nAlthough by this time Diego de Almagro had already acquired sufficient wealth in the conquest of Peru and was living a luxurious life in Cuzco, the prospect of conquering the lands further south was very attractive to him. Given that the dispute with Pizarro over Cuzco had kept intensifying, Almagro spent a great deal of time and money equipping a company of 500 men for a new exploration south of Peru.\n\nBy 1534 the Spanish crown had determined to split the region in two parallel lines, forming the governorship of \"Nueva Castilla\" (from the 1° to the 14° latitude, close to Pisco), and that of \"Nueva Toledo\" (from the 14° to the 25° latitude, in Taltal, Chile), assigning the first to Francisco Pizarro and the second to Diego de Almagro. The crown had previously assigned Almagro the governorship of Cuzco, and as such De Almagro was heading there when Charles V divided the territory between Nueva Castilla and Nuevo Toledo. This might have been the reason why Almagro did not immediately confront Pizarro for Cuzco, and promptly decided to embark on his new quest for the discovery of the riches of Chile.\n\nCharles V had given Diego a grant extending two hundred leagues south of Francisco Pizarro's. Francisco and Diego concluded a new contract on 12 June 1535, in which they agreed to share future discoveries equally. Diego raised an expedition for Chile, expecting it \"would lead to even greater riches than they had found in Peru.\" Almagro prepared the way by sending ahead three of his Spanish soldiers, the religious chief of the Inca empire, Willaq Umu, and Paullo Topa, brother of Manco Inca Yupanqui. De Almagro sent Juan de Saavedra forward with one hundred and fifty men, and soon followed them with additional forces. Saavedra established on January 23, 1535 the first Spanish settlement in Bolivia near the Inca regional capital of Paria.\n\nAlmagro left Cuzco on July 3, 1535 with his supporters and stopped at Moina until the 20th of that month. Meanwhile, Francisco Pizarro's brother, Juan Pizarro, had arrested Inca Manco Inca Yupanqui, further complicating De Almagro's plans as it heavily increased the dissatisfaction of the Indians submitted to Spanish rule. Not having formally been appointed governor of any territories in the Capitulation of Toledo in 1528, however, forcing him to declare himself \"adelantado\" (governor) of Nueva Toledo, or southern Peru and present-day Chile. Some sources suggest Almagro received such a requirement in 1534 by the Spanish king and was officially declared governor of New Toledo.\n\nOnce he left Moina, De Almagro followed the Inca trail followed by 750 Spaniards deciding to join him in quest for the gold lost in the ransom of Atahualpa, which had mainly benefited the Pizarro brothers and their supporters. After crossing the Bolivian mountain range and traveling past Lake Titicaca, Almagro arrived on the shores of the Desaguadero River and finally set up camp in Tupiza. From there, the expedition stopped at Chicoana and then turned to the southeast to cross the Andes mountains.\n\nThe expedition turned out to be a difficult and exhausting endeavor. The hardest phase was the crossing of the Andean cordilleras: the cold, hunger and tiredness meant the death of various Spanish and natives, but mainly slaves who were not accustomed to such rigorous climate.\n\nUpon this point, De Almagro determined everything was a failure. He ordered a small group under Rodrigo Orgonez on a reconnaissance of the country to the south.\n\nBy luck, these men found the Valley of Copiapó, where Gonzalo Calvo Barrientos, a Spanish soldier whom Pizarro had expelled from Peru for stealing objects the Inca had offered for his ransom, had already established a friendship with the local natives. There, in the valley of the river Copiapó, Almagro took official possession of Chile and claimed it in the name of King Charles V.\n\nDe Almagro promptly initiated the exploration of the new territory, starting up the valley the Aconcagua River, where he was well received by the natives. However, the intrigues of his interpreter, Felipillo, who had previously helped Pizarro in dealing with \"Atahualpa\", almost thwarted De Almagro's efforts. Felipillo had secretly urged the local natives to attack the Spanish, but they desisted, not understanding the dangers that they posed. De Almagro directed Gómez de Alvarado along with 100 horsemen and 100 foot to continue the exploration, which ended in the confluence of the Ñuble and Itata rivers. The Battle of Reinohuelén between the Spanish and hostile Mapuche Indians forced the explorers to return to the north.\n\nDe Almagro's own reconnaissance of the land and the bad news of Gómez de Alvarado's encounter with the fierce Mapuche, along with the bitter cold winter that settled ferociously upon them, only served to confirm that everything had failed. He never found gold or the cities which Incan scouts had told him lay ahead, only communities of the indigenous population who lived from subsistence agriculture. Local tribes put up fierce resistance to the Spanish forces. The exploration of the territories of Nueva Toledo, which lasted 2 years, was marked by a complete failure for De Almagro. Despite this, at first he thought staying and founding a city would serve well for his honor. The initial optimism that led Almagro to bring his son he had with the indigenous Panamanian Ana Martínez to Chile had faded.\n\nSome historians have suggested that, but for the urging of his senior explorers, De Almagro would probably have stayed permanently in Chile. He was urged to return to Peru and this time take definitive possession of Cuzco, so as to consolidate an inheritance for his son. Dismayed with his experience in the south, Almagro made plans of return to Peru. He never officially founded a city in the territory of what is now Chile.\n\nThe withdrawal of the Spanish from valleys of Chile was violent: Almagro authorized his soldiers to ransack the natives' properties, leaving their soil desolate. In addition, the Spanish soldiers took natives captive to serve as slaves. The locals were captured, tied together, and forced to carry the heavy loads belonging to the conquistadors.\n\nAfter the exhausting crossing of the Atacama Desert, mainly due to the weather conditions, Almagro finally reached Cuzco, Peru, in 1537. According to some authors, it was during this time that the Spanish term \"\"roto\"\" (torn), used by Peruvians to refer to Chileans, was first coined. De Almagro's disappointed troops returned to Cuzco with their \"torn clothes\" due to the extensive and laborious passage on foot by the Atacama Desert.\n\nAfter his return, De Almagro was surprised to learn of the Inca Manco's rebellion. Diego de Almagro sent an embassy to the Inca, but they mistrusted all of the Spaniards by this time. Hernando Pizarro's men formed an uneasy truce with De Almagro's men, surveying to determine the boundaries of their leaders' royal grants. They needed to determine in which portion the city of Cuzco was located. However, De Almagro's troops quickly took the city and imprisoned the Pizarro brothers, Hernando and Gonzalo, on the night of 8 April 1537.\n\nAfter occupying Cuzco, De Almagro confronted an army sent by Francisco Pizarro to liberate his brothers. Alonso de Alvarado commanded it and was defeated during the Battle of Abancay on July 12, 1537. He and some of his men were imprisoned. Later, Gonzalo Pizarro and De Alvarado escaped prison. Subsequent negotiations between Francisco Pizarro and De Almagro concluded with the liberation of Hernando, the third Pizarro brother, in return for conceding control and administration of Cuzco to De Almagro. Pizarro never intended to give up the city permanently, but was buying time to organize an army strong enough to defeat Almagro's troops.\n\nDuring this time Almagro fell ill, and Pizarro and his brothers grabbed the opportunity to defeat him and his followers. The Almagristas were defeated at Las Salinas in April 1538, with Orgóñez being killed on the field of battle. De Almagro fled to Cuzco, still in the hands of his loyal supporters, but found only temporary refuge; the forces of the Pizarro brothers entered the city without resistance. Once captured, Almagro was humiliated by Hernando Pizarro and his requests to appeal to the King were ignored.\n\nWhen Diego de Almagro begged for his life, Hernando responded:\n\n\"-he was surprised to see Almagro demean himself in a manner so unbecoming a brave cavalier, that his fate was no worse than had befallen many a soldier before him; and that, since God had given him the grace to be a Christian, he should employ his remaining moments in making up his account with Heaven!\"\n\nAlmagro was condemned to death and executed by \"garrote\" in his dungeon, and then decapitated, on July 8, 1538. His corpse was taken to the public Plaza Mayor of Cuzco, where a herald proclaimed his crimes. Hernan Ponce de Leon took his body and buried him in the church of Our Lady of Mercy in Cuzco.\n\nDiego de Almagro II (1520–1542), known as \"El Mozo\" (The Lad), son of Diego de Almagro I, whose mother was an Indian girl of Panama, became the foil of the conspirators who had put Pizarro to the sword. Pizarro was murdered on June 26, 1541; the conspirators promptly proclaimed the lad De Almagro Governor of Peru. From various causes, all of the conspirators either died or were killed except for one, who was executed after the lad Almagro gave an order. The lad De Almagro fought the desperate battle of Chupas on September 16, 1542, escaped to Cuzco, but was arrested, immediately condemned to death, and executed in the great square of the city.\n\n\n\n"}
{"id": "8363", "url": "https://en.wikipedia.org/wiki?curid=8363", "title": "Divinity", "text": "Divinity\n\nIn religion, divinity or Godhead is the state of things that are believed to come from a supernatural power or deity, such as God, the supreme being, creator deity, or spirits, and are therefore regarded as sacred and holy.\nSuch things are regarded as divine due to their transcendental origins or because their attributes or qualities are superior or supreme relative to things of the Earth. Divine things are regarded as eternal and based in truth, while material things are regarded as ephemeral and based in illusion. Such things that may qualify as divine are apparitions, visions, prophecies, miracles, and in some views also the soul, or more general things like resurrection, immortality, grace, and salvation. Otherwise what is or is not divine may be loosely defined, as it is used by different belief systems.\n\nThe root of the word \"divine\" is literally \"godly\" (from the Latin \"deus\", cf. \"Dyaus\", closely related to Greek \"zeus\", \"div\" in Persian and \"deva\" in Sanskrit), but the use varies significantly depending on which deity is being discussed. This article outlines the major distinctions in the conventional use of the terms.\n\nFor specific related academic terms, see Divinity (academic discipline), or Divine (Anglican).\n\nDivinity as a quality has two distinct usages:\nOverlap occurs between these usages because deities or godly entities are often identical with or identified by the powers and forces that are credited to them — in many cases a deity is merely a power or force personified — and these powers and forces may then be extended or granted to mortal individuals. For instance, Jehovah is closely associated with storms and thunder throughout much of the Old Testament. He is said to speak in thunder, and thunder is seen as a token of his anger. This power was then extended to prophets like Moses and Samuel, who caused thunderous storms to rain down on their enemies. (See and 1 Samuel 12:18.)\n\nDivinity always carries connotations of goodness, beauty, beneficence, justice, and other positive, pro-social attributes. In monotheistic faiths there is an equivalent cohort of malefic supernatural beings and powers, such as demons, devils, afreet, etc., which are not conventionally referred to as divine; \"demonic\" is often used instead. Pantheistic and polytheistic faiths make no such distinction; gods and other beings of transcendent power often have complex, ignoble, or even irrational motivations for their acts. Note that while the terms \"demon\" and \"demonic\" are used in monotheistic faiths as antonyms to \"divine\", they are in fact derived from the Greek word \"daimón\" (δαίμων), which itself translates as \"divinity\".\n\nThere are three distinct usages of \"divinity\" and \"divine\" in religious discourse:\n\nIn monotheistic faiths, the word \"divinity\" is often used to refer to the singular God central to that faith. Often the word takes the definite article and is capitalized — \"\"the Divinity\"\" — as though it were a proper name or definitive honorific. \n\"Divine\" — capitalized — may be used as an adjective to refer to the manifestations of such a Divinity or its powers: e.g. \"basking in the Divine presence...\"\n\nThe terms \"divinity\" and \"divine\" — uncapitalized, and lacking the definite article — are sometimes used as to denote 'god(s) or certain other beings and entities which fall short of absolute Godhood but lie outside the human realm. These include (by no means an exhaustive list):\n\nAs previously noted, divinities are closely related to the transcendent force(s) or power(s) credited to them, so much so that in some cases the powers or forces may themselves be invoked independently. This leads to the second usage of the word \"divine\" (and a less common usage of \"divinity\"): to refer to the operation of transcendent power in the world.\n\nIn its most direct form, the operation of transcendent power implies some form of divine intervention. For pan- and polytheistic faiths this usually implies the direct action of one god or another on the course of human events. In Greek legend, for instance, it was Poseidon (god of the sea) who raised the storms which blew Odysseus' craft off course on his return journey, and Japanese tradition holds that a god-sent wind saved them from Mongol invasion. Prayers or propitiations are often offered to specific gods of pantheisms to garner favorable interventions in particular enterprises: e.g. safe journeys, success in war, or a season of bountiful crops. Many faiths around the world — from Japanese Shinto and Chinese traditional religion, to certain African practices and the faiths derived from those in the Caribbean, to Native American beliefs — hold that ancestral or household deities offer daily protection and blessings. In monotheistic religions, divine intervention may take very direct forms: miracles, visions, or intercessions by blessed figures.\n\nTranscendent force or power may also operate through more subtle and indirect paths. Monotheistic faiths generally support some version of divine providence, which acknowledges that the divinity of the faith has a profound but unknowable plan always unfolding in the world. Unforeseeable, overwhelming, or seemingly unjust events are often thrown on 'the will of the Divine', in deferences like the Muslim \"inshallah\" ('as God wills it') and Christian 'God works in mysterious ways'. Often such faiths hold out the possibility of divine retribution as well, where the divinity will unexpectedly bring evil-doers to justice through the conventional workings of the world; from the subtle redressing of minor personal wrongs, to such large-scale havoc as the destruction of Sodom and Gomorrah or the biblical Great Flood. Other faiths are even more subtle: the doctrine of \"karma\" shared by Buddhism and Hinduism is a divine law similar to divine retribution but without the connotation of punishment: our acts, good or bad, intentional or unintentional, reflect back on us as part of the natural working of the universe. Philosophical Taoism also proposes a transcendent operant principle — transliterated in English as \"tao\" or \"dao\", meaning 'the way' — which is neither an entity or a being per se, but reflects the natural ongoing process of the world. Modern western mysticism and new age philosophy often use the term 'the Divine' as a noun in this latter sense: a non-specific principle or being that gives rise to the world, and acts as the source or wellspring of life. In these latter cases the faiths do not promote deference, as happens in monotheisms; rather each suggests a path of action that will bring the practitioner into conformance with the divine law: \"ahimsa\" — 'no harm' — for Buddhist and Hindu faiths; \"de\" or \"te\" — 'virtuous action' — in Taoism; and any of numerous practices of peace and love in new age thinking.\n\nIn the third usage, extensions of divinity and divine power are credited to living, mortal individuals. Political leaders are known to have claimed actual divinity in certain early societies — the ancient Egyptian Pharaohs being the premier case — taking a role as objects of worship and being credited with superhuman status and powers. More commonly, and more pertinent to recent history, leaders merely claim some form of divine mandate, suggesting that their rule is in accordance with the will of God. The doctrine of the divine right of kings was introduced as late as the 17th century, proposing that kings rule by divine decree; Japanese Emperors ruled by divine mandate until the inception of the Japanese constitution after World War II.\n\nLess politically, most faiths have any number of people that are believed to have been touched by divine forces: saints, prophets, heroes, oracles, martyrs, and enlightened beings, among others. Saint Francis of Assisi, in Catholicism, is said to have received instruction directly from God and it is believed that he grants plenary indulgence to all who confess their sins and visit his chapel on the appropriate day. In Greek mythology, Achilles' mother bathed him in the river Styx to give him immortality, and Hercules — as the son of Zeus — inherited near-godly powers. In religious Taoism, Lao Tsu is venerated as a saint with his own powers. Various individuals in the Buddhist faith, beginning with Siddhartha, are considered to be enlightened, and in religious forms of Buddhism they are credited with divine powers. Christ is said to have performed divine miracles.\n\nIn general, mortals with divine qualities are carefully distinguished from the deity or deities in their religion's main pantheon. Even the Christian faith, which generally holds Christ to be identical to God, distinguishes between God the Father and Christ the begotten Son. There are, however, certain esoteric and mystical schools of thought, present in many faiths — Sufis in Islam, Gnostics in Christianity, Advaitan Hindus, Zen Buddhists, as well as several non-specific perspectives developed in new age philosophy — which hold that all humans are in essence divine, or unified with the Divine in a non-trivial way. Such divinity, in these faiths, would express itself naturally if it were not obscured by the social and physical worlds we live in; it needs to be brought to the fore through appropriate spiritual practices.\n\nIn traditional Christian theology, the concept and nature of divinity always has its source ultimately from God himself. It's the state or quality of being divine, and the term can denote Godly nature or character. In Hebrew, the terms would usually be \"el\", \"elohim\", and in Greek usually \"theos\", or \"theias\". The divinity in the Bible is considered the Godhead itself, or God in general. Or it may have reference to a deity. Even angels in the Psalms are considered divine or \"elohim\", as spirit beings, in God's form. Redeemed Christians born-again or believers, according to Biblical verses, are said to partake of the \"divine nature\" through the \"exceeding great and precious promises\" of Jesus Christ (2 Peter 1:4).\n\nIn the Christian Greek Scriptures of the Bible, the Greek word θεῖον (\"theion\") in the Douay Version, is translated as \"divinity\". Examples are below:\n\nThe word translated as either \"deity\", \"Godhead\", or \"divinity\" in the Greek New Testament is also the Greek word θεότητος (\"theotētos\"), and the one Verse that contains it is this:\nColossians 2:9\n\nThe word \"divine\" in the New Testament is the Greek word θείας (\"theias\"), and is the adjective form of \"divinity\". Biblical examples from the King James Bible are below:\n\nThe most prominent conception of divine entities in The Church of Jesus Christ of Latter-day Saints (LDS Church) is the Godhead, a divine council of three distinct beings: Elohim (the Father), Jehovah (the Son, or Jesus), and the Holy Spirit. Joseph Smith described a nontrinitarian Godhead, with God the Father and Jesus Christ each having individual physical bodies, and the Holy Spirit as a distinct personage with a spirit body. Smith also introduced the existence of a Heavenly Mother in the King Follett Discourse, but very little is acknowledged or known beyond her existence.\n\nMormons hold a belief in the divine potential of humanity; Smith taught a form of divinization where mortal men and women can become like god through salvation and exaltation. Lorenzo Snow succinctly summarized this using a couplet, which is often repeated within the LDS Church: \"As man now is, God once was: As God now is, man may be.\"\n\n"}
{"id": "8367", "url": "https://en.wikipedia.org/wiki?curid=8367", "title": "Depth of field", "text": "Depth of field\n\nIn optics, particularly as it relates to film and photography, the optical phenomenon known as depth of field (DOF), is the distance about the plane of focus (POF) where objects appear acceptably sharp in an image. Although an optical imaging system can precisely focus on only one plane at a time, the decrease in sharpness is gradual on each side of the POF, so that within the DOF the unsharpness is imperceptible under normal viewing conditions.\n\nIn some cases, it may be desirable to have the entire image sharp, and a large DOF is appropriate. In other cases, a small DOF may be more effective, emphasizing the subject while de-emphasizing the foreground and background. In cinematography, a large DOF is often called deep focus, and a small DOF is often called shallow focus.\n\nDepth of field is the distance between the nearest and the furthest objects that are in acceptably sharp focus. \"Acceptably sharp focus\" is defined using a property called the \"circle of confusion\".\n\nPrecise focus is only possible at an exact distance from the lens; at that distance, a point object will produce a point image. Otherwise, a point object will produce a blur spot shaped like the aperture, typical a circle, approximately. When this circular spot is sufficiently small, it is visually indistinguishable from a point, and appears to be in focus. The diameter of the largest circle that is indistinguishable from a point is known as the acceptable circle of confusion, or informally, simply as the circle of confusion. Points that produce a blur spot smaller than this acceptable circle of confusion are considered acceptably sharp. \n\nThe acceptable circle of confusion depends on how the final image will be used. It is generally accepted to be 0.25 mm for an image viewed from 25cm away.\n\nFor 35 mm motion pictures, the image area on the film is roughly 22 mm by 16 mm. The limit of tolerable error was traditionally set at 0.05 mm (0.002 in) diameter, while for 16 mm film, where the size is about half as large, the tolerance is stricter, 0.025 mm (0.001 in). More modern practice for 35 mm productions set the circle of confusion limit at 0.025 mm (0.001 in).\n\nTraditional depth-of-field formulas and tables assume equal circles of confusion for near and far objects. Some authors, such as Merklinger (1992), have suggested that distant objects often need to be much sharper to be clearly recognizable, whereas closer objects, being larger on the film, do not need to be so sharp. The loss of detail in distant objects may be particularly noticeable with extreme enlargements. Achieving this additional sharpness in distant objects usually requires focusing beyond the hyperfocal distance, sometimes almost at infinity. For example, if photographing a cityscape with a traffic bollard in the foreground, this approach, termed the \"object field method\" by Merklinger, would recommend focusing very close to infinity, and stopping down to make the bollard sharp enough. With this approach, foreground objects cannot always be made perfectly sharp, but the loss of sharpness in near objects may be acceptable if recognizability of distant objects is paramount.\nOther authors such as Ansel Adams have taken the opposite position, maintaining that slight unsharpness in foreground objects is usually more disturbing than slight unsharpness in distant parts of a scene.\n\nMoritz von Rohr also used an object field method, but unlike Merklinger, he used the conventional criterion of a maximum circle of confusion diameter in the image plane, leading to unequal front and rear depths of field.\n\nThe depth of field is determined by focal length, distance to subject, the acceptable circle of confusion size, and aperture.\n\nAs focal length, distance, or the size of the acceptable circle of confusion increases, the depth of field increases; however, increasing the size of the aperture reduces the depth of field. Sensor size affects DOF only in that changing the sensor size on a camera requires changing the focal length to get the same picture. It is the change in focal length that then affects the DOF.\n\nFor a given subject framing and camera position, the DOF is controlled by the lens aperture diameter, which is usually specified as the f-number (the ratio of lens focal length to aperture diameter). Reducing the aperture diameter (increasing the f-number) increases the DOF because the only the light travelling at shallower angles passes through the aperture. Because the angles are shallow, the light rays are within the circle of confusion for a greater distance.\n\nMotion pictures make only limited use of this control; to produce a consistent image quality from shot to shot, cinematographers usually choose a single aperture setting for interiors and another for exteriors, and adjust exposure through the use of camera filters or light levels. Aperture settings are adjusted more frequently in still photography, where variations in depth of field are used to produce a variety of special effects.\n\nThe plane of focus is normally parallel to the image plane. However, moving the lens relative to the sensor can rotate the plane of focus.\n\nWhen the plane of focus is rotated, the near and far limits of DOF are no longer parallel; the DOF becomes wedge-shaped, with the apex of the wedge nearest the camera (Merklinger 1993, 31–32; Tillmanns 1997, 71).\n\nIn some cases, rotating the POF can better fit the DOF to the scene, and achieve the required sharpness at a smaller f-number. Alternatively, rotating the POF, in combination with a small f-number, can minimize the part of an image that is within the DOF.\n\nThe advent of digital technology in photography has provided additional means of controlling the extent of image sharpness; some methods allow extended DOF that would be impossible with traditional techniques, and some allow the DOF to be determined after the image is made.\n\nFocus stacking is a digital image processing technique which combines multiple images taken at different focal distances to give a resulting image with a greater depth of field than any of the individual source images. Wavefront coding is a method that convolves rays in such a way that it provides an image where fields are in focus simultaneously with all planes out of focus by a constant amount.\n\nA plenoptic camera uses a microlens array to capture 4D light field information about a scene.\n\nColour apodization is a technique combining a modified lens design with image processing to achieve an increased depth of field. The lens is modified such that each colour channel has a different lens aperture. For example, the red channel may be \"f\"/2.4, green may be \"f\"/2.4, whilst the blue channel may be \"f\"/5.6. Therefore, the blue channel will have a greater depth of field than the other colours. The image processing identifies blurred regions in the red and green channels and in these regions copies the sharper edge data from the blue channel. The result is an image that combines the best features from the different \"f\"-numbers, (Kay 2011).\n\nIn 2013, Nokia implemented DOF control in some of its high-end smartphones, called Refocus, which can change a picture's depth of field after the picture is taken. It works best when there are close-up and distant objects in the frame.\n\nDiffraction causes images to lose sharpness at extremely high F-numbers, and hence limits the potential depth of field.(Gibson 1975, 64). In general photography this is rarely an issue; because large f-numbers typically require long exposure times, motion blur may cause greater loss of sharpness than the loss from diffraction. However, diffraction is a greater issue in close-up photography, and the tradeoff between DOF and overall sharpness can become quite noticeable as photographers are trying to maximise depth of field with very short focal lengths.(Gibson 1975, 53; Lefkowitz 1979, 84).\n\nMany lenses for small- and medium-format cameras include scales that indicate the DOF for a given focus distance and f-number; the 35 mm lens in the image is typical. That lens includes distance scales in feet and meters; when a marked distance is set opposite the large white index mark, the focus is set to that distance. The DOF scale below the distance scales includes markings on either side of the index that correspond to f-numbers. When the lens is set to a given f-number, the DOF extends between the distances that align with the f-number markings.\n\nSome cameras have the DOF scale not on lens barrel, but on focusing knob or dial; for example, the Rolleiflex TLR has its DOF scale on the focusing knob; the subminiature camera Tessina has DOF a scale on the focusing dial.\n\nPhotographers can use the lens scales to work backwards from the desired depth of field to find the necessary focus distance and aperture. (Ray 1994, 315). For the 35 mm lens above, if it were desired for the DOF to extend from 1 m to 2 m, focus would be set so that index mark was centered between the marks for those distances, and the aperture would be set to f/11.\n\nIf the marks for the near and far distances fall outside the marks for the largest f-number on the DOF scale, the desired DOF cannot be obtained; for example, with the 35 mm lens above, it is not possible to have the DOF extend from 0.7 m to infinity. The DOF limits can be determined visually, by focusing on the farthest object to be within the DOF and noting the distance mark on the lens distance scale, and repeating the process for the nearest object to be within the DOF.\n\nSome distance scales have markings for only a few distances; for example, the 35 mm lens above shows only 3 ft and 5 ft on its upper scale. Using other distances for DOF limits requires visual interpolation between marked distances. Since the distance scale is nonlinear, accurate interpolation can be difficult. In most cases, English and metric distance markings are not coincident, so using both scales to note focused distances can sometimes lessen the need for interpolation. Many autofocus lenses have smaller distance and DOF scales and fewer markings than do comparable manual-focus lenses, so that determining focus and f-number from the scales on an autofocus lens may be more difficult than with a comparable manual-focus lens. In most cases, determining these settings using the lens DOF scales on an autofocus lens requires that the lens or camera body be set to manual focus.\n\nOn a view camera, the focus and f-number can be obtained by measuring the \"focus spread\" and performing simple calculations. The procedure is described in more detail in the section Focus and f-number from DOF limits. Some view cameras include DOF calculators that indicate focus and f-number without the need for any calculations by the photographer (Tillmanns 1997, 67–68; Ray 2002, 230–31).\n\n \n\nSome cameras have their hyperfocal distance marked on the focus dial. For example, on the Minox LX focusing dial there is a red dot between 2 m and infinity; when the lens is set at the red dot, that is, focused at the hyperfocal distance, the depth of field stretches from 2 m to infinity.\n\nThe DOF beyond the subject is always greater than the DOF in front of the subject. When the subject is at the hyperfocal distance or beyond, the far DOF is infinite, so the ratio is 1:∞; as the subject distance decreases, near:far DOF ratio increases, approaching unity at high magnification. For large apertures at typical portrait distances, the ratio is still close to 1:1.\n\nIn semiconductor photolithography applications, depth of field is extremely important as integrated circuit layout features must be printed with high accuracy at extremely small size. The difficulty is that the wafer surface is not perfectly flat, but may vary by several micrometres. Even this small variation causes some distortion in the projected image, and results in unwanted variations in the resulting pattern. Thus photolithography engineers take extreme measures to maximize the optical depth of field of the photolithography equipment. To minimize this distortion further, semiconductor manufacturers may use chemical mechanical polishing to make the wafer surface even flatter before lithographic patterning.\n\nA person may sometimes experience better vision in daylight than at night because of an increased depth of field due to constriction of the pupil (i.e., miosis).\n\nLet formula_1 be the lens focal length, formula_2 be the lens f-number, and formula_3 be the circle of confusion for a given image format. The hyperfocal distance formula_4 is given by\n\nLet formula_6 be the distance at which the camera is focused (the \"subject distance\"). When formula_6 is large in comparison with the lens focal length, the depth of field formula_8 is\n\nFor formula_10, the far limit of DOF is at infinity and the DOF is infinite; of course, only objects at or beyond the near limit of DOF will be recorded with acceptable sharpness.\n\nFor close-up work, the hyperfocal distance has little applicability, and it usually is more convenient to express DOF in terms of image magnification. Let formula_11 be the magnification; when the subject distance is small in comparison with the hyperfocal distance,\n\nso that for a given magnification, DOF is independent of focal length.\n\nWhen formula_13, the DOF for an asymmetrical lens is\n\nwhere formula_15 is the pupil magnification. When the pupil magnification is unity, this equation reduces to that for a symmetrical lens.\n\nIf only working f-number is directly available, the following formula can be used instead:\n\nFor given near and far DOF limits formula_17 and formula_18, the required f-number is smallest when focus is set to\n\nthe harmonic mean of the near and far distances. When the subject distance is large in comparison with the lens focal length, the required f-number is\n\nIn practice, these settings usually are determined on the image side of the lens, using measurements on the bed or rail with a view camera, or using lens DOF scales on manual-focus lenses for small- and medium-format cameras. If formula_21 and formula_22 are the image distances that correspond to the near and far limits of DOF, the required f-number is minimized when the image distance\nformula_23 is\n\nIn practical terms, focus is set to halfway between the near and far image distances. The required f-number is\n\nThe image distances are measured from the camera's image plane to the lens's image nodal plane. Sometimes, view camera users refer to the difference formula_26 as the \"focus spread\" (Hansma 1996, 55).\n\nThe focus spread is related to the depth of focus and may be defined as either the tolerance of the position of the image plane for which an object remains acceptably sharp or the limits of depth of focus are the image-side conjugates of the near and far limits of DOF (Ray (2000, 56).\n\nIf a subject is at distance formula_6 and the foreground or background is at distance formula_28, let the distance between the subject and the foreground or background be indicated by\n\nThe blur disk diameter formula_30 of a detail at distance formula_31 from the subject can be expressed as a function of the subject magnification formula_32, focal length formula_1, f-number formula_2, or alternatively the aperture formula_35, according to\n\nThe minus sign applies to a foreground object, and the plus sign applies to a background object.\n\nThe blur increases with the distance from the subject; when formula_37, the detail is within the depth of field, and the blur is imperceptible.\n\nFor a given subject magnification, f-number, and distance from the subject of the foreground or background detail, the degree of detail blur varies with the lens focal length. For a background detail, the blur increases with focal length; for a foreground detail, the blur decreases with focal length.\n\nFor a reasonably distant background detail, the blur disk diameter is\n\nMost DOF formulas employ several simplifications:\n\nLens designer do not restrict analysis to Gaussian optics and do not ignore lens aberrations but despite the simplifications employed in development of most DOF formulas, these formulas are used to determine camera settings that result in acceptably sharp pictures.\n\n\n"}
{"id": "8368", "url": "https://en.wikipedia.org/wiki?curid=8368", "title": "Dumnonii", "text": "Dumnonii\n\nThe Dumnonii or Dumnones were a British tribe who inhabited Dumnonia, the area now known as Devon and Cornwall (and some areas of present-day Dorset and Somerset) in the further parts of the South West peninsula of Britain, from at least the Iron Age up to the early Saxon period. They were bordered to the east by the Durotriges tribe.\n\nWilliam Camden, in his 1607 edition of \"Britannia\", describes Cornwall and Devon as being two parts of the same 'country' which:\nCamden had learnt some Welsh during the course of his studies and it would appear that he is the origin of the interpretation of Dumnonii as \"deep valley dwellers\" from his understanding of the Welsh of his time. John Rhys later theorized that the tribal name was derived from the name of a goddess, \"Domnu\", probably meaning \"the goddess of the deep\". The proto-Celtic root *dubno- or *dumno- meaning \"the deep\" or \"the earth\" (or alternatively meaning \"dark\" or \"gloomy\") appears in personal names such as Dumnorix and Dubnovellaunus. Another group with a similar name but with no known links were the Fir Domnann of Connacht.\n\nThe Roman name of the town of Exeter, \"Isca Dumnoniorum\" (\"Isca of the Dumnonii\"), contains the root \"*iska-\" \"water\" for \"Water of the Dumnonii\". The Latin name suggests that the city was already an \"oppidum\", or walled town, on the banks on the River Exe before the foundation of the Roman city, in about AD 50. The Dumnonii gave their name to the English county of Devon, and their name is represented in Britain's two extant Brythonic languages as \"Dewnans\" in Cornish and \"Dyfnaint\" in Welsh. Amédée Thierry (\"Histoire des Gaulois\", 1828), one of the inventors of the \"historic race\" of Gauls, could confidently equate them with the Cornish (\"les Cornouailles\").\n\nVictorian historians often referred to the tribe as the Damnonii, which is also the name of another people from lowland Scotland, although there are no known links between the two populations.\n\nThe people of Dumnonia spoke a Southwestern Brythonic dialect similar to the forerunner of more recent Cornish and Breton. Irish immigrants, the Déisi, are evidenced by the Ogham-inscribed stones they have left behind, confirmed and supplemented by toponymical studies. The stones are sometimes inscribed in Latin, sometimes in both scripts. Tristram Risdon suggested the continuance of a Brythonic dialect in the South Hams, Devon, as late as the 14th century, in addition to its use in Cornwall.\n\nPtolemy's 2nd century \"Geography\" places the Dumnonii to the west of the Durotriges. The name \"purocoronavium\" that appears in the Ravenna Cosmography implies the existence of a sub-tribe called the Cornavii or Cornovii, perhaps the ancestors of the Cornish people.\n\nIn the sub-Roman period a Brythonic kingdom called Dumnonia emerged, covering the entire peninsula, although it is believed by some to have effectively been a collection of sub-kingdoms.\n\nA kingdom of Domnonée (and of Cornouaille alongside) was established in the province of Armorica directly across the English Channel, and has apparent links with the British population, suggesting an ancient connection of peoples along the western Atlantic seaboard.\n\nThe Latin name for Exeter is Isca Dumnoniorum (\"Water of the Dumnonii\"). This oppidum (a Latin term meaning an important town) on the banks of I River Exe certainly existed prior to the foundation of the Roman city in about AD 50. \"Isca\" is derived from the Brythonic word for flowing water, which was given to the River Exe. This is reflected in the Welsh name for Exeter: \"Caerwysg\" meaning \"fortified settlement on the river Uisc\".\n\nIsca Dumnoniorum originated with a settlement that developed around the Roman fortress of the Legio II Augusta and is one of the four \"poleis\" (cities) attributed to the tribe by Ptolemy. It is also listed in two routes of the late 2nd century Antonine Itinerary.\n\nA legionary bath-house was built inside the fortress sometime between 55 and 60 and underwent renovation shortly afterwards (c. 60-65) but by c. 68 (perhaps even 66) the legion had transferred to a newer fortress at Gloucester. This saw the dismantling of the Isca fortress, and the site was then abandoned. Around AD 75, work on the \"civitas forum\" and \"basilica\" had commenced on the site of the former \"principia\" and by the late 2nd century the \"civitas\" walls had been completed. They were 3 metres thick and 6 metres high and enclosed exactly the same area as the earlier fortress. However, by the late 4th century the \"civitas\" was in decline.\n\nAs well as Isca Dumnoniorum, Ptolemy's 2nd century \"Geography\" names three other towns:\n\nThe Ravenna Cosmography includes the last two names (in slightly different forms, as \"Tamaris\" and \"Uxelis\"), and adds several more names which may be settlements in the territory. These include:\n\nOther Romano-British sites in Dumnonia include:\n\nNew settlements continued to be built throughout the Roman period, including sites at Chysauster and Trevelgue Head. The style is native in form with no Romanised features. Near Padstow, a site of some importance that was inhabited from the late Bronze/early Iron Age to the mid 6th century now lies buried under the sands on the opposite side of the Camel estuary near St. Enodoc's Church, and may have been a western coastal equivalent of a Saxon Shore Fort. Byzantine and African pottery has been discovered at the site. At Magor Farm in Illogan, near Camborne, an archaeological site has been identified as being a villa.\n\nThe Dumnonii are thought to have occupied relatively isolated territory in Cornwall, Devon, Somerset and possibly part of Dorset. Their cultural connections, as expressed in their ceramics, were with the peninsula of Armorica across the Channel, rather than with the southeast of Britain. They do not seem to have been politically centralised: coins are relatively rare, none of them locally minted, and the structure, distribution and construction of Bronze Age and Iron Age hill forts, \"rounds\" and defensible farmsteads in the south west point to a number of smaller tribal groups living alongside each other.\n\nDumnonia is noteworthy for its many settlements that have survived from the Romano-British period, but also for its lack of a villa system. Local archaeology has revealed instead the isolated enclosed farmsteads known locally as \"rounds\". These seem to have survived the Roman abandonment of Britain, but were subsequently replaced, in the 6th and 7th centuries, by the unenclosed farms taking the Brythonic toponymic \"tre-\".\n\nAs in most other Brythonic areas, Iron Age hill forts, such as Hembury Castle, were refortified for the use of chieftains or kings. Other high-status settlements such as Tintagel seem to have been reconstructed during this period. Post-Roman imported pottery has been excavated from many sites across the region, and the apparent surge in late 5th century Mediterranean and/or Byzantine imports is yet to be explained satisfactorily.\n\nApart from fishing and agriculture, the main economic resource of the Dumnonii was tin mining. The area of Dumnonia had been mined since ancient times, and the tin was exported from the ancient trading port of Ictis (St Michael's Mount). Tin extraction (mainly by streaming) had existed here from the early Bronze Age around the 22nd century BC. West Cornwall, around Mount's Bay, was traditionally thought to have been visited by metal traders from the eastern Mediterranean\n\nDuring the first millennium BC trade became more organised, first with the Phoenicians, who settled Gades (Cadiz) around 1100 BC, and later with the Greeks, who had settled Massilia (Marseilles) and Narbo (Narbonne) around 600 BC. Smelted Cornish tin was collected at Ictis whence it was conveyed across the Bay of Biscay to the mouth of the Loire and then to Gades via the Loire and Rhone valleys. It went then through the Mediterranean Sea in ships to Gades.\n\nDuring the period c. 500-450 BC, the tin deposits seem to have become more important, and fortified settlements appear such as at Chun Castle and Kenidjack Castle, to protect both the tin smelters and mines.\n\nThe earliest account of Cornish tin mining was written by Pytheas of Massilia late in the 4th century BC after his circumnavigation of the British Isles. Underground mining was described in this account, although it cannot be determined when it had started. Pytheas's account was noted later by other writers including Pliny the Elder and Diodorus Siculus.\n\nIt is likely that tin trade with the Mediterranean was later on under the control of the Veneti. Britain was one of the places proposed for the \"Cassiterides\", that is Tin Islands. Tin working continued throughout Roman occupation although it appears that output declined because of new supplies brought in from the deposits discovered in Iberia (Spain and Portugal). However, when these supplies diminished, production in Dumnonia increased and appears to have reached a peak during the 3rd century AD.\n\nThe Sub-Roman or Post-Roman history of Dumnonia comes from a variety of sources and is considered exceedingly difficult to interpret given that historical fact, legend and confused pseudo-history are compounded by a variety of sources in Middle Welsh and Latin. The main sources available for discussion of this period include Gildas's \"De Excidio Britanniae\" and Nennius's \"Historia Brittonum\", the \"Annales Cambriae\", \"Anglo-Saxon Chronicle\", William of Malmesbury's \"Gesta Regum Anglorum\" and \"De Antiquitate Glastoniensis Ecclesiae\", along with texts from the \"Black Book of Carmarthen\" and the \"Red Book of Hergest\", and Bede's \"Historia ecclesiastica gentis Anglorum\" as well as \"The Descent of the Men of the North\" (\"Bonedd Gwŷr y Gogledd\", in Peniarth MS 45 and elsewhere) and the \"Book of Baglan\".\n\n\n\n\n"}
{"id": "8372", "url": "https://en.wikipedia.org/wiki?curid=8372", "title": "Declaration of independence", "text": "Declaration of independence\n\nA declaration of independence or declaration of statehood is an assertion by a defined territory that it is independent and constitutes a state. Such places are usually declared from part or all of the of another nation or failed nation, or are breakaway territories from within the larger state. In 2010, the UN's International Court of Justice ruled in an advisory opinion in Kosovo that \"International law contains no prohibition on declarations of independence\", though the state from which the territory wishes to secede may regard the declaration as rebellion, which may lead to a war of independence or a constitutional settlement to resolve the crisis.\n\n"}
{"id": "8373", "url": "https://en.wikipedia.org/wiki?curid=8373", "title": "Drag racing", "text": "Drag racing\n\nDrag racing is a type of motor racing in which automobiles or motorcycles (usually specially prepared for the purpose) compete, usually two at a time, to be first to cross a set finish line. The race follows a short, straight course from a standing start over a measured distance, most commonly , with a shorter () becoming increasingly popular, as it has become the standard for Top Fuel dragsters and funny cars, where some major bracket races and other sanctioning bodies have adopted it as the standard, while the is also popular in some circles. Electronic timing and speed sensing systems have been used to record race results since the 1960s.\n\nThe history of automobiles and motorcycles being used for drag racing is nearly as long as the history of motorized vehicles themselves, and has taken the form of both illegal street racing, and as an organized and regulated motorsport. This article covers the legal sport.\n\nPush starts to get engines running were necessary until the National Hot Rod Association (NHRA) mandated self-starters in 1976. After burnouts, cars would be pushed back by crews; this persisted until NHRA required reversing systems in 1980. Don Garlits was the first to do burnouts across the starting line, which is now standard practise. Each driver then backs up to and stages at the starting line.\n\nBefore each race (commonly known as a pass), each driver is allowed to perform a burnout, which heats the driving tires and lays rubber down at the beginning of the track, improving traction. The cars run through a \"water box\" (formerly a \"bleach box\", before bleach was replaced by flammable traction compound, which produced spectacular, and dangerous, flame burnouts; the hazard led NHRA to mandate use of water in the 1970s).\n\nModern races are started electronically by a system known as a \"Christmas tree\", which consists of a column of lights for each driver/lane, and two light beam sensors per lane on the track at the starting line. Current NHRA trees, for example, feature one blue light (split into halves), then three amber, one green, and one red. When the first light beam is broken by a vehicle's front tire(s), the vehicle is \"pre-staged\" (approximately from the starting line), and the pre-stage indicator on the tree is lit. When the second light beam is broken, the vehicle is \"staged\", and the stage indicator on the tree is lit. Vehicles may then leave the pre-stage beam, but must remain in the stage beam until the race starts.\n\nOnce one competitor is staged, their opponent has a set amount of time to stage or they will be instantly disqualified, indicated by a red light on the tree. Otherwise, once both drivers are staged, the system chooses a short delay at random (to prevent a driver being able to anticipate the start), then starts the race. The light sequence at this point varies slightly. For example, in NHRA Professional classes, three amber lights on the tree flash simultaneously, followed 0.4 seconds later by a green light (this is also known as a \"pro tree\"). In NHRA Sportsman classes, the amber lights illuminate in sequence from top to bottom, 0.5 seconds apart, followed 0.5 seconds later by the green light (this is also known as a \"sportsman tree\" or \"full tree\"). If a vehicle leaves the starting line before the green light illuminates, the red light for that lane illuminates instead, and the driver is disqualified (also known as \"red lighting\"). In a handicap start, the green light automatically lights up for the first driver, and the red light is only lit in the proper lane after both cars have launched if one driver leaves early, or if both drivers left early, the driver whose reaction time is worse (if one lane has a -.015 and the other lane has a -.022, the lane of the driver who committed a 0.022 is given the red light after both cars have left), as a red light infraction is only assessed to the driver with the worse infraction, if both drivers leave early. Even if both drivers leave early, the green light is automatically lit for the driver that left last, and they still may win the pass (as in the 2014 NHRA Auto Club Pro Stock final, Erica Enders-Stevens and Jason Line both committed red light infractions; only Line was assessed with a red light, as he was -.011 versus Enders-Stevens' -.002).\n\nSeveral measurements are taken for each race: reaction time, elapsed time, and speed. Reaction time is the period from the green light illuminating to the vehicle leaving the starting line. Elapsed time is the period from the vehicle leaving the starting line to crossing the finish line. Speed is measured through a speed trap covering the final to the finish line, indicating average speed of the vehicle in that distance.\n\nExcept where a breakout rule is in place, the winner is the first vehicle to cross the finish line, and therefore the driver with the lowest combined reaction time and elapsed time. Because these times are measured separately, a driver with a slower elapsed time can actually win if that driver's advantage in reaction time exceeds the elapsed time difference. In heads-up racing, this is known as a \"holeshot win\". In categories where a breakout rule is in effect (for example, NHRA Junior Dragster, Super Comp, Super Gas, Super Stock, and Stock classes, as well as some dial-in classes), if a competitor is faster than his or her predetermined time (a \"breakout\"), that competitor loses. If both competitors are faster than their predetermined times, the competitor who breaks out by less time wins. Regardless, a red light foul is worse than a breakout, except in Junior Dragster where exceeding the absolute limit is a cause for disqualification.\n\nMost race events use a traditional bracket system, where the losing car and driver are eliminated from the event while the winner advances to the next round, until a champion is crowned. Events can range from 16 to over 100 car brackets. Drivers are typically seeded by elapsed times in qualifying. In bracket racing without a breakout (such as NHRA Competition Eliminator), pairings are based on times compared to their index (faster than index for class is better). In bracket racing with a breakout (Stock, Super Stock, but also the NHRA's Super classes), the closest to the index is favourable.\n\nA popular alternative to the standard eliminations format is the Chicago Style format (also called the Three Round format in Australia), named for the US 30 Dragstrip in suburban Gary, Indiana where a midweek meet featured this format. All entered cars participate in one qualifying round, and then are paired for the elimination round. The two fastest times among winners from this round participate in the championship round. Depending on the organisation, the next two fastest times may play for third, then fifth, and so forth, in consolation rounds. Currently, an IHRA 400 Thunder championship race in Australia uses the format.\n\nThe standard distance of a drag race is 1,320 feet, 402 m, or 1/4 mile. However, due to safety concerns, certain sanctioning bodies (notably the NHRA for its Top Fuel and Funny Car classes) have shortened races to 1,000 feet. Some drag strips are even shorter and run 660 feet, 201 m, or 1/8 mile. The 1,000 foot distance is now also popular with bracket racing, especially in meets where there are 1/8 mile cars and 1/4 mile cars racing together, and is used by the revived American Drag Racing League for its primary classes (not Jr Dragster). Some organisations that deal with Pro Modified and \"Mountain Motor\" Pro Stock cars (Professional Drag Racers Association) use the 1/8 mile distance, even if the tracks are 1/4 mile tracks.\n\nThe National Hot Rod Association (NHRA) oversees the majority of drag racing events in North America. The next largest organization is the International Hot Rod Association (IHRA). Nearly all drag strips are associated with one sanctioning body or the other.\n\nBesides NHRA and IHRA, there are niche organizations for muscle cars and nostalgia vehicles. The Nostalgia Drag Racing League (NDRL) based in Brownsburg, IN, runs a series of 1/4 mile (402m) drag races in the Midwest for 1979 and older nostalgic appearing cars, with four classes of competition running in an index system. Pro 7.0 and Pro 7.50 run heads up 200 mile per hour (320 kilometre per hour) passes, while Pro Comp and Pro Gas run 8.0 to 10.0 indices. NDRL competition vehicles typically include Front Engine Dragsters, Altereds, Funny Cars, early Pro Stock clones, Super Stocks and Gassers.\n\nThe National Electric Drag Racing Association (NEDRA) races electric vehicles against high performance gasoline-powered vehicles such as Dodge Vipers or classic muscle cars in 1/4 and 1/8 mile (402m & 201m) races. The current electric drag racing record is 6.940 seconds at 201.37 mph (324.0736 kph) for a quarter mile (402m). Another niche organization is the VWDRC which run a VW-only championship with vehicles running under 7 seconds.\n\nPrior to the founding of the NHRA and IHRA, smaller organizations sanctioned drag racing in the early years, which included the competing AHRA in the United States from 1955 to 2005.\n\nThe first Australian Nationals event was run in 1965 at Riverside raceway, near Melbourne. The Australian National Drag Racing Association (ANDRA) was established in 1973, and today they claim they are the \"best in the world outside the United States\". ANDRA sanctions races throughout Australia and throughout the year at all levels, from Junior Dragster to Top Fuel.\n\nThe ANDRA Pro Series is for professional drivers and riders and includes Top Fuel, Top Alcohol, Top Doorslammer (similar to the USA Pro Modified class), Pro Stock (using 400 cubic inch engines (6.5 litres)), Top Bike and Pro Stock Motorcycle.\n\nThe Rocket Allstars Racing Series is for ANDRA sportsman drivers and riders and includes Competition, Super Stock, Super Compact, Competition Bike, Supercharged Outlaws, Modified, Super Sedan, Modified Bike, Super Street and Junior Dragster.\n\nBroadcasting is provided on SBS Speedweek.\n\nIn 2015, after a dispute with ANDRA, Sydney Dragway, Willowbank Raceway and the Perth Motorplex invited the International Hot Rod Association (IHRA) to sanction events at their tracks. Since then the Perth Motorplex has reverted to an ANDRA sanction and Springmount Raceway has embraced the IHRA umbrella. The 400 Thunder Series now attracts professional racers to its races at Sydney Dragway and Willowbank Raceway and is the premiere series in Australia.\n\nCommunications Provider OVO Mobile provides a live stream of all 400 Thunder Australian Professional Drag Racing Series events to fans globally.\nThe 400 Thunder Series is aired on Fox Sports with each professional bracket having its own half hour program from each 400 Thunder Series event.\n\nDrag racing was imported to Europe by American NATO troops during the Cold War. Races were held in West Germany beginning in the 1960s at the airbases at Ramstein and Sembach and in the UK at various airstrips and racing circuits before the opening of Europe's first permanent drag strip at Santa Pod Raceway in 1966.\n\nThe FIA organises a Europe-wide four wheeled championship for the Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock classes. FIM Europe organises a similar championship for bike classes. In addition, championships are run for sportsman classes in many countries throughout Europe by the various national motorsport governing bodies.\n\nDrag racing in New Zealand started in the 1960s. The New Zealand Hot Rod Association (NZHRA) sanctioned what is believed to have been the first drag meeting at an open cut coal mine at Kopuku, south of Auckland, sometime in 1966. In 1973, the first and only purpose built drag strip opened in Meremere by the Pukekohe Hot Rod Club. In April 1993 the governance of drag racing was separated from the NZHRA and the New Zealand Drag Racing Association (NZDRA) was formed. In 2014, New Zealand's second purpose built drag strip - Masterton Motorplex - opened.\n\nThe first New Zealand Drag Racing Nationals was held in the 1966/67 season at Kopuku, near Auckland.\n\nThere are now two governing bodies operating drag racing in New Zealand with the Florida-based International Hot Rod Association sanctioning both of New Zealands major tracks at Ruapuna (Pegasus Bay Drag Racing Association) in the South Island and Meremere Dragway Inc in the North Island. However, the official ASN of the sport, per FIA regulations, is the New Zealand Drag Racing Association.\n\nMany countries in South America race 200 meters, unlike in the United States and Australia, where 400 meters or 1/4 mile is typical.\n\nOrganized drag racing in Colombia is the responsibility of Club G3, a private organization. The events take place at Autódromo de Tocancipá.\n\nCuraçao\n\nOn the island of Curaçao, organization of drag racing events is handled by the Curaçao Autosport Foundation (FAC)\nAll racing events, including street legal competitions, happen at the Curaçao International Raceway.\n\n'Aruba'\n\nOn the island of Aruba all racing events, including street legal competitions, happen at Palomarga international raceway.\n\nBarbados\n\nOn the island of Barbados, organization of drag racing events is done by the Barbados Association of Dragsters and Drifters. Currently the drag racing is done at Bushy Park racing circuit over 1/8 mile, while \"acceleration tests\" of 1/4 mile are done at the Paragon military base.\n\nSaint Lucia\n\nOn the Island of Saint Lucia, organization of drag racing events is done by Time Line Events, currently races are held at the US Old military base also known as the \"Ca Ca Beff\", \"The Base\" near the Hewanorra International Airport in Vieux Fort.\n\nDominican Republic\n\nOn Santo Domingo, organization of drag racing events is done by Autodromo Sunix and they happen at the Autodromo Sunix, close to the Airport SDQ.\n\nOrganized drag racing is rapidly growing in India. \"Autocar India\" organised the country's first drag race meet in Mumbai in 2002.\n\nDrag racing is also gaining popularity in Pakistan, with private organizations organizing such events. The Bahria Town housing project recently organized a drag racing event in Rawalpindi, with the help of some of the country's best drivers.\n\nSri Lanka has seen an immense growth in Drag racing through legal meets held by the Ceylon Motor Sports Club, an FiA sanctioned body. In recent years, exotic cars and Japanese power houses have been taking part in these popular events.\n\nDrag racing is an established sport in South Africa, with a number of strips around the country including Tarlton International Raceway and ODI Raceway. Drag racing is controlled by Motorsport South Africa and all drivers are required to hold a valid Motorsport South Africa license. Drivers can compete in a number of categories including Top Eliminator, Senior Eliminator, Super Competition Eliminator, Competition Eliminator, Pro Street Bikes, Superbike Eliminator, Supersport Shootout (motorcycle), Street Modified, and Factory Stock.\n\nThere are hundreds of classes in drag racing, each with different requirements and restrictions on things such as weight, engine size, body style, modifications, and many others. NHRA and IHRA share some of these classes, but many are solely used by one sanctioning body or the other. The NHRA boasts over 200 classes, while the IHRA has fewer. Some IHRA classes have multiple sub-classes in them to differentiate by engine components and other features. There is even a class for aspiring youngsters, Junior Dragster, which typically uses an eighth-mile track, also favored by VW racers.\n\nIn 1997, the FIA (cars) and UEM (bikes) began sanctioning drag racing in Europe with a fully established European Drag Racing Championship, in cooperation (and rules compliance) with NHRA. The major European drag strips include Santa Pod Raceway in Podington, England; Alastaro Circuit, Finland; Mantorp Park, Sweden; Gardermoen Raceway, Norway and the Hockenheimring in Germany.\n\nThere is a somewhat arbitrary definition of what constitutes a \"professional\" class. The NHRA includes 5 pro classes; Top Fuel, Funny Car, Pro Stock, Pro Modified and Pro Stock Motorcycle. The FIA features a different set of 5 pro classes; Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock. Other sanctioning bodies have similarly different definitions. A partial list of classes includes:\n \nA complete listing of all classes can be found on the respective NHRA and IHRA official websites.\n\nThe UEM also has a different structure of professional categories with Top Fuel Bike, Super Twin Top Fuel Bike, and Pro Stock Bike contested, leaving the entire European series with a total of 8 professional categories.\n\nTo allow different cars to compete against each other, some competitions are raced on a handicap basis, with faster cars delayed on the starting line enough to theoretically even things up with the slower car. This may be based on rule differences between the cars in stock, super stock, and modified classes, or on a competitor's chosen \"dial-in\" in bracket racing.\n\nFor a list of drag racing world records in each class, see Dragstrip#Quarter mile times.\n\nA 'dial-in' is a time the driver estimates it will take his or her car to cross the finish line, and is generally displayed on one or more windows so the starter can adjust the starting lights on the tree accordingly. The slower car will then get a head start equal to the difference in the two dial-ins, so if both cars perform perfectly, they would cross the finish line dead even. If either car goes faster than its dial-in (called breaking out), it is disqualified regardless of who has the lower elapsed time; if both cars break out, the one who breaks out by the smallest amount wins. However, if a driver had jump-started (red light) or crossed a boundary line, both violations override any break out (except in some classes with an absolute break out rule such as Junior classes). \n\nThe effect of the bracket racing rules is to place a premium on consistency of performance of the driver and car rather than on raw speed, in that victory goes to the driver able to precisely predict elapsed time, whether it is fast or slow. This in turn makes victory much less dependent on budget, and more dependent on skill, making it popular with casual weekend racers.\n\nThe National Hot Rod Association (NHRA) was founded in 1951, to take illegal racing off the street.\n\nThe organization banned the use of nitromethane in 1957, calling it unsafe, in part through the efforts of C. J. Hart; the ban would be lifted in 1963.\n\n\n\n\n\n"}
{"id": "8375", "url": "https://en.wikipedia.org/wiki?curid=8375", "title": "Draugr", "text": "Draugr\n\nThe draugr or draug (, plural ; modern , and Danish, Swedish, and ) is an undead creature from Norse mythology, also called , literally \"again-walker\" ().\n\nThe word \"draugr\" can be traced to a Proto-Indo European stem \"*\" \"phantom\", from \"*\" \"deceive\" (see also Avestan \"druj\").\nThe Old Norse meaning of the word is a revenant. In Swedish, \"draug\" is a modern loan word from West Norse, as the native Swedish form \"drög\" has acquired the meaning of \"a pale, ineffectual, and slow-minded person that drags himself along\".\n\nThe will appears to be strong, strong enough to draw the \"hugr\" [animate will] back to one's body. These reanimated individuals were known as \"draugar\". However, though the dead might live again, they could also die again. \"Draugar\" die a \"second death\" as Chester Gould calls it, when their bodies decay, are burned, dismembered or otherwise destroyed.\n\nDraugar live in their graves, often guarding treasure buried with them in their burial mound. They are animated corpses with a corporeal body, unlike ghosts, with similar physical abilities as in life. Older literature makes clear distinctions between sea-draugar and land-draugar.\n\nDraugar possess superhuman strength, can increase their size at will, and carry the unmistakable stench of decay. According to Gregg Smith, \"The appearance of a \"draugr\" was that of a dead body: swollen, blackened and generally hideous to look at.\" They are undead figures from Norse and Icelandic mythology which appear to retain some semblance of intelligence. They exist to guard their treasure, wreak havoc on living beings, or torment those who wronged them in life. The draugr's ability to increase its size also increased its weight, and the body of the draugr was described as being extremely heavy. Thorolf of Eyrbyggja saga was \"uncorrupted, and with an ugly look about him… swollen to the size of an ox,\" and his body was so heavy that it could not be raised without levers. They are also noted for the ability to rise from the grave as wisps of smoke and \"swim\" through solid rock. \n\nIn folklore, draugar slay their victims through various methods including crushing them with their enlarged forms, devouring their flesh, devouring them whole in their enlarged forms, indirectly killing them by driving them mad, and by drinking their blood. Animals feeding near the grave of a draugr might be driven mad by the creature's influence. They may also die from being driven mad. Thorolf, for example, caused birds to drop dead when they flew over his bowl barrow.\n\nThe draugr's victims were not limited to trespassers in its home. The roaming undead decimated livestock by running the animals to death either by riding them or pursuing them in some hideous, half-flayed form. Shepherds' duties kept them outdoors at night, and they were particular targets for the hunger and hatred of the undead:\nDraugar are noted for having numerous magical abilities (referred to as \"trollskap\") resembling those of living witches and wizards, such as shape-shifting, controlling the weather, and seeing into the future. A draugr can change into a seal, a great flayed bull, a grey horse with a broken back but no ears or tail, and a cat that would sit upon a sleeper's chest and grow steadily heavier until the victim suffocated. The draugr Þráinn (Thrain) shape-shifted into a cat-like creature (\"kattakyn\") in \"Hrómundar saga Gripssonar\":\nDraugar have the ability to enter into the dreams of the living, and they will frequently leave a gift behind so that \"the living person may be assured of the tangible nature of the visit\". Draugar also have the ability to curse a victim, as shown in the Grettis saga, where Grettir is cursed to be unable to become any stronger. Draugar also brought disease to a village and could create temporary darkness in daylight hours. They preferred to be active during the night, although it did not appear to be vulnerable to sunlight like some other revenants. Draugr can also kill people with bad luck.\n\nA draugr's presence might be shown by a great light that glowed from the mound like foxfire. This fire would form a barrier between the land of the living and the land of the dead. The draugr could also move magically through the earth, swimming through solid stone as does Killer-Hrapp:\n\nSome draugar are immune to weapons, and only a hero has the strength and courage needed to stand up to so formidable an opponent. In legends, the hero would often have to wrestle the draugr back to his grave, thereby defeating him, since weapons would do no good. A good example of this is found in \"Hrómundar saga Gripssonar\". Iron could injure a draugr, as is the case with many supernatural creatures, although it would not be sufficient to stop it. Sometimes the hero is required to dispose of the body in unconventional ways. The preferred method is to cut off the draugr's head, burn the body, and dump the ashes in the sea—the emphasis being on making absolutely sure that the draugr was dead and gone.\n\nThe draugar were said to be either \"hel-blár\" (\"death-blue\") or \"nár-fölr\" (\"corpse-pale\"). The death-blue color was not actually grey but was a dark blue or maroon hue which covered the entire body. Glámr, the undead shepherd of \"Grettis saga\", was reported to be dark blue, and Laxdæla saga describes how bones were dug up belonging to a dead sorceress who had appeared in dreams, and they were \"blue and evil looking.\"\n\nThe resting place of the draugr was a tomb which they were able to leave during the night to visit the living. Such visits are supposed to be horrible events that often end in death for one or more of the living, which would then warrant the exhumation of the draugr by a hero.\n\nThe draugr's motivation was primarily jealousy and greed. Greed causes it to viciously attack any would-be grave robbers, but the draugr also expresses an innate jealousy of the living stemming from a longing for the things of life which it once had. They also exhibit an immense and nearly insatiable appetite, as shown in the encounter of Aran and Asmund, sword brothers who made an oath that, if one should die, the other would sit vigil with him for three days inside the burial mound. When Aran died, Asmund brought his own possessions into the barrow—banners, armor, hawk, hound, and horse—then set himself to wait the three days:\n\nThe main indication that a deceased person will become a draugr is that the corpse is not in a horizontal position but is found in an upright or sitting position, indicating that the dead might return. Any mean, nasty, or greedy person can become a draugr. As Ármann notes, \"most medieval Icelandic ghosts are evil or marginal people. If not dissatisfied or evil, they are unpopular\".\n\nTraditionally, a pair of open iron scissors was placed on the chest of the recently deceased, and straws or twigs might be hidden among their clothes. The big toes were tied together or needles were driven through the soles of the feet in order to keep the dead from being able to walk. Tradition also held that the coffin should be lifted and lowered in three different directions as it was carried from the house to confuse a possible draugr's sense of direction.\n\nThe most effective means of preventing the return of the dead was believed to be a corpse door, a special door through which the corpse was carried feet-first with people surrounding it so that the corpse couldn't see where it was going. The door was then bricked up to prevent a return. It is speculated that this belief began in Denmark and spread throughout the Norse culture, founded on the idea that the dead could only leave through the way they entered.\n\nIn \"Eyrbyggja saga\", draugar are driven off by holding a \"door-doom\". One by one, they are summoned to the door-doom and given judgment and forced out of the home by this legal method. The home was then purified with holy water to ensure that they never came back.\n\nA variation of the draugr is the \"haugbui\" (from Old Norse \"haugr\"' \"howe, barrow, tumulus\") which was a mound-dweller, the dead body living on within its tomb. The notable difference between the two was that the haugbui is unable to leave its grave site and only attacks those who trespass upon their territory.\n\nThe haugbui was rarely found far from its burial place and is a type of undead commonly found in Norse sagas. The creature is said to either swim alongside boats or sail around them in a partially submerged vessel, always on their own. In some accounts, witnesses portray them as shapeshifters who take on the appearance of seaweed or moss-covered stones on the shoreline.\n\nOne of the best-known draugar is Glámr, who is defeated by the hero in \"Grettis saga\". After Glámr dies on Christmas Eve, \"people became aware that Glámr was not resting in peace. He wrought such havoc that some people fainted at the sight of him, while others went out of their minds\". After a mundane battle, Grettir eventually gets Glámr on his back. Just before Grettir kills him, Glámr curses Grettir because \"Glámr was endowed with more evil force than most other ghosts\", and thus he was able to speak and leave Grettir with his curse after his death.\n\nA somewhat ambivalent, alternative view of the draugr is presented by the example of Gunnar Hámundarson in \"Njáls saga\": \"It seemed as though the howe was agape, and that Gunnar had turned within the howe to look upwards at the moon. They thought that they saw four lights within the howe, but not a shadow to be seen. Then they saw that Gunnar was merry, with a joyful face.\"\n\nIn the \"Eyrbyggja saga\", a shepherd is assaulted by a blue-black draugr. The shepherd's neck is broken during the ensuing scuffle. The shepherd rises the next night as a draugr.\n\nIn more recent Scandinavian folklore, the draug (the modern spelling used in Denmark, Norway, and Sweden) is often identified with the spirits of mariners drowned at sea. The creature is said to possess a distinctly human form, with the exception that its head is composed entirely of seaweed. In other tellings, the draug is described as being a headless fisherman, dressed in oilskin and sailing in half a boat (the Norwegian municipality of Bø, Nordland has the half-boat in its coat-of-arms). This trait is common in the northernmost part of Norway, where life and culture was based on fishing more than anywhere else. The reason for this may be that the fishermen often drowned in great numbers, and the stories of restless dead coming in from sea were more common in the north than any other region of the country.\n\nA recorded legend from Trøndelag tells how a cadaver lying on a beach became the object of a quarrel between the two types of draug (headless and seaweed-headed). A similar source even tells of a third type, the \"gleip\", known to hitch themselves to sailors walking ashore and make them slip on the wet rocks.\n\nBut, though the draug usually presages death, there is an amusing account in Northern Norway of a northerner who managed to outwit him:\n\nThe modern and popular connection between the draug and the sea can be traced back to authors like Jonas Lie and Regine Nordmann, whose works include several books of fairy tales, as well as the drawings of Theodor Kittelsen, who spent some years living in Svolvær. Up north, the tradition of sea-draugs is especially vivid.\n\nArne Garborg describes land-draugs coming fresh from the graveyards, and the term \"draug\" is even used of vampires. The notion of draugs who live in the mountains is present in the poetic works of Henrik Ibsen (\"Peer Gynt\"), and Aasmund Olavsson Vinje. The Nynorsk translation of \"The Lord of the Rings\" used the term for both Nazgûl and the dead men of Dunharrow. Tolkien's Barrow-Wights bear obvious similarity to, and were inspired by the haugbui.\n\nThe term \"draug\" has come to be used to describe any type of revenant in Nordic folklore.\n\n\n\n"}
{"id": "8376", "url": "https://en.wikipedia.org/wiki?curid=8376", "title": "Day", "text": "Day\n\nA day, a unit of time, is approximately the period of time during which the Earth completes one rotation around its axis with respect to the Sun (\"solar day\"). In 1960, the second was redefined in terms of the orbital motion of the Earth in year 1900, and was designated the SI base unit of time. The unit of measurement \"day\", was redefined as 86 400 SI seconds and symbolized \"d\". In 1967, the second and so the day were redefined by atomic electron transition. A civil day is usually 86 400 seconds, plus or minus a possible leap second in Coordinated Universal Time (UTC), and occasionally plus or minus an hour in those locations that change from or to daylight saving time.\n\nDay can be defined as each of the twenty-four-hour periods, reckoned from one midnight to the next, into which a week, month, or year is divided, and corresponding to a rotation of the earth on its axis. However its use depends on its context, for example when people say 'day and night', 'day' will have a different meaning. It will mean the interval of light between two successive nights; the time between sunrise and sunset. People tend to sleep during the night and are awake at a day, in this instance 'day' will mean time of light between one night and the next. However, in order to be clear when using 'day' in that sense, \"daytime\" should be used to distinguish it from \"day\" referring to a 24-hour period; this is since daytime typically always means 'the time of the day between sunrise and sunset. The word \"day\" may also refer to a day of the week or to a calendar date, as in answer to the question, \"On which day?\" The life patterns (circadian rhythms) of humans and many other species are related to Earth's solar day and the day-night cycle.\n\nSeveral definitions of this universal human concept are used according to context, need and convenience. Besides the day of 24 hours (86 400 seconds), the word \"day\" is used for several different spans of time based on the rotation of the Earth around its axis. An important one is the solar day, defined as the time it takes for the Sun to return to its culmination point (its highest point in the sky). Because celestial orbits are not perfectly circular, and thus objects travel at different speeds at various positions in their orbit, a solar day is not the same length of time throughout the orbital year. Because the Earth orbits the Sun elliptically as the Earth spins on an inclined axis, this period can be up to 7.9 seconds more than (or less than) 24 hours. In recent decades, the average length of a solar day on Earth has been about 86 400.002 seconds (24.000 000 6 hours) and there are about 365.2422 solar days in one mean tropical year.\n\nAncient custom has a new day start at either the rising or setting of the Sun on the local horizon (Italian reckoning, for example, being 24 hours from sunset, oldstyle). The exact moment of, and the interval between, two sunrises or sunsets depends on the geographical position (longitude as well as latitude), and the time of year (as indicated by ancient hemispherical sundials).\n\nA more constant day can be defined by the Sun passing through the local meridian, which happens at local noon (upper culmination) or midnight (lower culmination). The exact moment is dependent on the geographical longitude, and to a lesser extent on the time of the year. The length of such a day is nearly constant (24 hours ± 30 seconds). This is the time as indicated by modern sundials.\n\nA further improvement defines a fictitious mean Sun that moves with constant speed along the celestial equator; the speed is the same as the average speed of the real Sun, but this removes the variation over a year as the Earth moves along its orbit around the Sun (due to both its velocity and its axial tilt).\n\nA \"day\", understood as the span of time it takes for the Earth to make one entire rotation with respect to the celestial background or a distant star (assumed to be fixed), is called a \"stellar day\". This period of rotation is about 4 minutes less than 24 hours (23 hours 56 minutes and 4.1 seconds) and there are about 366.2422 stellar days in one mean tropical year (one stellar day more than the number of solar days). Other planets and moons have stellar and solar days of different lengths from Earth's.\n\nA day, in the sense of daytime that is distinguished from night-time, is commonly defined as the period during which sunlight directly reaches the ground, assuming that there are no local obstacles. The length of daytime averages slightly more than half of the 24-hour day. Two effects make daytime on average longer than nights. The Sun is not a point, but has an apparent size of about 32 minutes of arc. Additionally, the atmosphere refracts sunlight in such a way that some of it reaches the ground even when the Sun is below the horizon by about 34 minutes of arc. So the first light reaches the ground when the centre of the Sun is still below the horizon by about 50 minutes of arc. Thus, daytime is on average around 7 minutes longer than 12 hours.\n\nThe term comes from the Old English \"dæg\", with its cognates such as \"dagur\" in Icelandic, \"Tag\" in German, and \"dag\" in Norwegian, Danish, Swedish and Dutch. All of them from the Indo-European root dyau which explains the similarity with Latin dies though the word is known to come from the Germanic branch. , \"day\" is the 205th most common word in US English, and the 210th most common in UK English.\n\nA day, symbol \"d\", defined as 86 400 seconds, is not an SI unit, but is accepted for use with SI. The Second is the base unit of time in SI units.\n\nIn 1967–68, during the 13th CGPM (Resolution 1), the International Bureau of Weights and Measures (BIPM) redefined a second as … the duration of 9 192 631 770 periods of the radiation corresponding to the transition between two hyperfine levels of the ground state of the caesium 133 atom.\nThis makes the SI-based day last exactly 794 243 384 928 000 of those periods.\n\nMainly due to tidal effects, the Earth's rotational period is not constant, resulting in minor variations for both solar days and stellar \"days\". The Earth's day has increased in length over time. This phenomenon is due to tides raised by the Moon which slow Earth's rotation. Because of the way the second is defined, the mean length of a day is now about 86 400.002 seconds, and is increasing by about 1.7 milliseconds per century (an average over the last 2 700 years). (See tidal acceleration for details.) The length of a day circa 620 million years ago has been estimated from rhythmites (alternating layers in sandstone) as having been about 21.9 hours. The length of day for the Earth before the moon was created is still unknown.\n\nIn order to keep the civil day aligned with the apparent movement of the Sun, a day according to Coordinated Universal Time (UTC) can include a negative or positive leap second. Therefore, although typically 86 400 SI seconds in duration, a civil day can be either 86 401 or 86 399 SI seconds long on such a day.\n\nLeap seconds are announced in advance by the International Earth Rotation and Reference Systems Service (IERS), which measures the Earth's rotation and determines whether a leap second is necessary. Leap seconds occur only at the end of a UTC-calculated month, and have only ever been inserted at the end of June 30 or December 31.\n\nFor civil purposes, a common clock time is typically defined for an entire region based on the local mean solar time at a central meridian. Such \"time zones\" began to be adopted about the middle of the 19th century when railroads with regularly occurring schedules came into use, with most major countries having adopted them by 1929. As of 2015, throughout the world, 40 such zones are now in use: the central zone, from which all others are defined as offsets, is known as , which uses Coordinated Universal Time (UTC).\n\nThe most common convention starts the civil day at midnight: this is near the time of the lower culmination of the Sun on the central meridian of the time zone. Such a day may be referred to as a calendar day.\n\nA day is commonly divided into 24 hours of 60 minutes, with each minute composed of 60 seconds.\n\nIn the 19th century, an idea circulated to make a decimal fraction ( or ) of an astronomical day the base unit of time. This was an afterglow of the short-lived movement toward a decimalisation of timekeeping and the calendar, which had been given up already due to its difficulty in transitioning from traditional, more familiar units. The most successful alternative is the \"centiday\", equal to 14.4 minutes (864 seconds), being not only a shorter multiple of an hour (0.24 vs 2.4) but also closer to the SI multiple \"kilosecond\" (1 000 seconds) and equal to the traditional Chinese unit, \"kè\".\n\nThe word refers to various similarly defined ideas, such as:\n\nFor most diurnal animals, the day naturally begins at dawn and ends at sunset. Humans, with their cultural norms and scientific knowledge, have employed several different conceptions of the day's boundaries. Common convention among the ancient Romans, ancient Chinese and in modern times is for the civil day to begin at midnight, i.e. 00:00, and last a full 24 hours until 24:00 (i.e. 00:00 of the next day). \nIn ancient Egypt, the day was reckoned from sunrise to sunrise.\n\nThe Jewish day begins at either sunset or nightfall (when three second-magnitude stars appear). The \"Damascus Document\", copies of which were also found among the Dead Sea scrolls, states regarding the observance of the Sabbath that \"No one is to do any work on Friday \"from the moment that the Sun's disk stands distant from the horizon by the length of its own diameter\",\" presumably indicating that the monastic community responsible for producing this work counted the day as ending shortly before the Sun had begun to set. \n\nMedieval Europe also followed this tradition, known as Florentine reckoning: in this system, a reference like \"two hours into the day\" meant \"two hours after sunset\" and thus times during the evening need to be shifted back one calendar day in modern reckoning. Days such as Christmas Eve, Halloween, and the Eve of Saint Agnes are remnants of the older pattern when holidays began during the prior evening. Prior to 1926, Turkey had two time systems: Turkish (counting the hours from sunset) and French (counting the hours from midnight).\n\nIn many cultures, nights are named after the previous day. For example,\"Friday night\" usually means the entire night between Friday and Saturday. This difference from the civil day often leads to confusion. Events starting at midnight are often announced as occurring the day before. TV-guides tend to list nightly programs at the previous day, although programming a VCR requires the strict logic of starting the new day at 00:00 (to further confuse the issue, VCRs set to the 12-hour clock notation will label this \"12:00 AM\"). Expressions like \"today\", \"yesterday\" and \"tomorrow\" become ambiguous during the night. Because Jews and Muslims begin their days at nightfall, \"Saturday\" night, for example, is what most people would call Friday night.\n\nValidity of tickets, passes, etc., for a day or a number of days may end at midnight, or closing time, when that is earlier. However, if a service (e.g., public transport) operates from for example, 6:00 to 1:00 the next day (which may be noted as 25:00), the last hour may well count as being part of the previous day. For services depending on the day (\"closed on Sundays\", \"does not run on Fridays\", and so on) there is a risk of ambiguity. For example, a day ticket on the Nederlandse Spoorwegen (Dutch Railways) is valid for 28 hours, from 0:00 to 28:00 (that is, 4:00 the next day); the validity of a pass on Transport for London (TfL) services is until the end of the \"transport day\" – that is to say, until 4:30 am on the day after the \"expiry\" date stamped on the pass.\n\nIn places which experience the midnight sun (polar day), daytime may extend beyond one 24 hour period and could even extend to months\n\nBesides a stellar day on Earth, determined to be 23 hours 56 minutes and 4.1 seconds, there are related such days for bodies in the Solar System other than the Earth. For example:\n\n"}
{"id": "8377", "url": "https://en.wikipedia.org/wiki?curid=8377", "title": "Database", "text": "Database\n\nA database is an organized collection of data, generally stored and accessed electronically from a computer system. Where databases are more complex they are often developed using formal design and modeling techniques.\n\nThe database management system (DBMS) is the software that interacts with end users, applications, and the database itself to capture and analyze the data. The DBMS software additionally encompasses the core facilities provided to administer the database. The sum total of the database, the DBMS and the associated applications can be referred to as a \"database system\". Often the term \"database\" is also used to loosely refer to any of the DBMS, the database system or an application associated with the database.\n\nComputer scientists may classify database-management systems according to the database models that they support. Relational databases became dominant in the 1980s. These model data as rows and columns in a series of tables, and the vast majority use SQL for writing and querying data. In the 2000s, non-relational databases became popular, referred to as NoSQL because they use different query languages.\n\nFormally, a \"database\" refers to a set of related data and the way it is organized. Access to this data is usually provided by a \"database management system\" (DBMS) consisting of an integrated set of computer software that allows users to interact with one or more databases and provides access to all of the data contained in the database (although restrictions may exist that limit access to particular data). The DBMS provides various functions that allow entry, storage and retrieval of large quantities of information and provides ways to manage how that information is organized.\n\nBecause of the close relationship between them, the term \"database\" is often used casually to refer to both a database and the DBMS used to manipulate it.\n\nOutside the world of professional information technology, the term \"database\" is often used to refer to any collection of related data (such as a spreadsheet or a card index) as size and usage requirements typically necessitate use of a database management system.\n\nExisting DBMSs provide various functions that allow management of a database and its data which can be classified into four main functional groups:\n\n\nBoth a database and its DBMS conform to the principles of a particular database model. \"Database system\" refers collectively to the database model, database management system, and database.\n\nPhysically, database servers are dedicated computers that hold the actual databases and run only the DBMS and related software. Database servers are usually multiprocessor computers, with generous memory and RAID disk arrays used for stable storage. RAID is used for recovery of data if any of the disks fail. Hardware database accelerators, connected to one or more servers via a high-speed channel, are also used in large volume transaction processing environments. DBMSs are found at the heart of most database applications. DBMSs may be built around a custom multitasking kernel with built-in networking support, but modern DBMSs typically rely on a standard operating system to provide these functions.\n\nSince DBMSs comprise a significant market, computer and storage vendors often take into account DBMS requirements in their own development plans.\n\nDatabases and DBMSs can be categorized according to the database model(s) that they support (such as relational or XML), the type(s) of computer they run on (from a server cluster to a mobile phone), the query language(s) used to access the database (such as SQL or XQuery), and their internal engineering, which affects performance, scalability, resilience, and security.\n\nThe sizes, capabilities, and performance of databases and their respective DBMSs have grown in orders of magnitude. These performance increases were enabled by the technology progress in the areas of processors, computer memory, computer storage, and computer networks. The development of database technology can be divided into three eras based on data model or structure: navigational, SQL/relational, and post-relational.\n\nThe two main early navigational data models were the hierarchical model and the CODASYL model (network model)\n\nThe relational model, first proposed in 1970 by Edgar F. Codd, departed from this tradition by insisting that applications should search for data by content, rather than by following links. The relational model employs sets of ledger-style tables, each used for a different type of entity. Only in the mid-1980s did computing hardware become powerful enough to allow the wide deployment of relational systems (DBMSs plus applications). By the early 1990s, however, relational systems dominated in all large-scale data processing applications, and they remain dominant: IBM DB2, Oracle, MySQL, and Microsoft SQL Server are the most searched DBMS. The dominant database language, standardised SQL for the relational model, has influenced database languages for other data models.\n\nObject databases were developed in the 1980s to overcome the inconvenience of object-relational impedance mismatch, which led to the coining of the term \"post-relational\" and also the development of hybrid object-relational databases.\n\nThe next generation of post-relational databases in the late 2000s became known as NoSQL databases, introducing fast key-value stores and document-oriented databases. A competing \"next generation\" known as NewSQL databases attempted new implementations that retained the relational/SQL model while aiming to match the high performance of NoSQL compared to commercially available relational DBMSs.\n\nThe introduction of the term \"database\" coincided with the availability of direct-access storage (disks and drums) from the mid-1960s onwards. The term represented a contrast with the tape-based systems of the past, allowing shared interactive use rather than daily batch processing. The Oxford English Dictionary cites a 1962 report by the System Development Corporation of California as the first to use the term \"data-base\" in a specific technical sense.\n\nAs computers grew in speed and capability, a number of general-purpose database systems emerged; by the mid-1960s a number of such systems had come into commercial use. Interest in a standard began to grow, and Charles Bachman, author of one such product, the Integrated Data Store (IDS), founded the \"Database Task Group\" within CODASYL, the group responsible for the creation and standardization of COBOL. In 1971, the Database Task Group delivered their standard, which generally became known as the \"CODASYL approach\", and soon a number of commercial products based on this approach entered the market.\n\nThe CODASYL approach relied on the \"manual\" navigation of a linked data set which was formed into a large network. Applications could find records by one of three methods:\n\nLater systems added B-trees to provide alternate access paths. Many CODASYL databases also added a very straightforward query language. However, in the final tally, CODASYL was very complex and required significant training and effort to produce useful applications.\n\nIBM also had their own DBMS in 1966, known as Information Management System (IMS). IMS was a development of software written for the Apollo program on the System/360. IMS was generally similar in concept to CODASYL, but used a strict hierarchy for its model of data navigation instead of CODASYL's network model. Both concepts later became known as navigational databases due to the way data was accessed, and Bachman's 1973 Turing Award presentation was \"The Programmer as Navigator\". IMS is classified as a hierarchical database. IDMS and Cincom Systems' TOTAL database are classified as network databases. IMS remains in use .\n\nEdgar Codd worked at IBM in San Jose, California, in one of their offshoot offices that was primarily involved in the development of hard disk systems. He was unhappy with the navigational model of the CODASYL approach, notably the lack of a \"search\" facility. In 1970, he wrote a number of papers that outlined a new approach to database construction that eventually culminated in the groundbreaking \"A Relational Model of Data for Large Shared Data Banks\".\n\nIn this paper, he described a new system for storing and working with large databases. Instead of records being stored in some sort of linked list of free-form records as in CODASYL, Codd's idea was to use a \"table\" of fixed-length records, with each table used for a different type of entity. A linked-list system would be very inefficient when storing \"sparse\" databases where some of the data for any one record could be left empty. The relational model solved this by splitting the data into a series of normalized tables (or \"relations\"), with optional elements being moved out of the main table to where they would take up room only if needed. Data may be freely inserted, deleted and edited in these tables, with the DBMS doing whatever maintenance needed to present a table view to the application/user.\nThe relational model also allowed the content of the database to evolve without constant rewriting of links and pointers. The relational part comes from entities referencing other entities in what is known as one-to-many relationship, like a traditional hierarchical model, and many-to-many relationship, like a navigational (network) model. Thus, a relational model can express both hierarchical and navigational models, as well as its native tabular model, allowing for pure or combined modeling in terms of these three models, as the application requires.\n\nFor instance, a common use of a database system is to track information about users, their name, login information, various addresses and phone numbers. In the navigational approach, all of this data would be placed in a single record, and unused items would simply not be placed in the database. In the relational approach, the data would be \"normalized\" into a user table, an address table and a phone number table (for instance). Records would be created in these optional tables only if the address or phone numbers were actually provided.\n\nLinking the information back together is the key to this system. In the relational model, some bit of information was used as a \"key\", uniquely defining a particular record. When information was being collected about a user, information stored in the optional tables would be found by searching for this key. For instance, if the login name of a user is unique, addresses and phone numbers for that user would be recorded with the login name as its key. This simple \"re-linking\" of related data back into a single collection is something that traditional computer languages are not designed for.\n\nJust as the navigational approach would require programs to loop in order to collect records, the relational approach would require loops to collect information about any \"one\" record. Codd's suggestions was a set-oriented language, that would later spawn the ubiquitous SQL. Using a branch of mathematics known as tuple calculus, he demonstrated that such a system could support all the operations of normal databases (inserting, updating etc.) as well as providing a simple system for finding and returning \"sets\" of data in a single operation.\n\nCodd's paper was picked up by two people at Berkeley, Eugene Wong and Michael Stonebraker. They started a project known as INGRES using funding that had already been allocated for a geographical database project and student programmers to produce code. Beginning in 1973, INGRES delivered its first test products which were generally ready for widespread use in 1979. INGRES was similar to System R in a number of ways, including the use of a \"language\" for data access, known as QUEL. Over time, INGRES moved to the emerging SQL standard.\n\nIBM itself did one test implementation of the relational model, PRTV, and a production one, Business System 12, both now discontinued. Honeywell wrote MRDS for Multics, and now there are two new implementations: Alphora Dataphor and Rel. Most other DBMS implementations usually called \"relational\" are actually SQL DBMSs.\n\nIn 1970, the University of Michigan began development of the MICRO Information Management System based on D.L. Childs' Set-Theoretic Data model. MICRO was used to manage very large data sets by the US Department of Labor, the U.S. Environmental Protection Agency, and researchers from the University of Alberta, the University of Michigan, and Wayne State University. It ran on IBM mainframe computers using the Michigan Terminal System. The system remained in production until 1998.\n\nIn the 1970s and 1980s, attempts were made to build database systems with integrated hardware and software. The underlying philosophy was that such integration would provide higher performance at lower cost. Examples were IBM System/38, the early offering of Teradata, and the Britton Lee, Inc. database machine.\n\nAnother approach to hardware support for database management was ICL's CAFS accelerator, a hardware disk controller with programmable search capabilities. In the long term, these efforts were generally unsuccessful because specialized database machines could not keep pace with the rapid development and progress of general-purpose computers. Thus most database systems nowadays are software systems running on general-purpose hardware, using general-purpose computer data storage. However this idea is still pursued for certain applications by some companies like Netezza and Oracle (Exadata).\n\nIBM started working on a prototype system loosely based on Codd's concepts as \"System R\" in the early 1970s. The first version was ready in 1974/5, and work then started on multi-table systems in which the data could be split so that all of the data for a record (some of which is optional) did not have to be stored in a single large \"chunk\". Subsequent multi-user versions were tested by customers in 1978 and 1979, by which time a standardized query language – SQL – had been added. Codd's ideas were establishing themselves as both workable and superior to CODASYL, pushing IBM to develop a true production version of System R, known as \"SQL/DS\", and, later, \"Database 2\" (DB2).\n\nLarry Ellison's Oracle Database (or more simply, Oracle) started from a different chain, based on IBM's papers on System R. Though Oracle V1 implementations were completed in 1978, it wasn't until Oracle Version 2 when Ellison beat IBM to market in 1979.\n\nStonebraker went on to apply the lessons from INGRES to develop a new database, Postgres, which is now known as PostgreSQL. PostgreSQL is often used for global mission critical applications (the .org and .info domain name registries use it as their primary data store, as do many large companies and financial institutions).\n\nIn Sweden, Codd's paper was also read and Mimer SQL was developed from the mid-1970s at Uppsala University. In 1984, this project was consolidated into an independent enterprise.\n\nAnother data model, the entity–relationship model, emerged in 1976 and gained popularity for database design as it emphasized a more familiar description than the earlier relational model. Later on, entity–relationship constructs were retrofitted as a data modeling construct for the relational model, and the difference between the two have become irrelevant.\n\nThe 1980s ushered in the age of desktop computing. The new computers empowered their users with spreadsheets like Lotus 1-2-3 and database software like dBASE. The dBASE product was lightweight and easy for any computer user to understand out of the box. C. Wayne Ratliff, the creator of dBASE, stated: \"dBASE was different from programs like BASIC, C, FORTRAN, and COBOL in that a lot of the dirty work had already been done. The data manipulation is done by dBASE instead of by the user, so the user can concentrate on what he is doing, rather than having to mess with the dirty details of opening, reading, and closing files, and managing space allocation.\" dBASE was one of the top selling software titles in the 1980s and early 1990s.\n\nThe 1990s, along with a rise in object-oriented programming, saw a growth in how data in various databases were handled. Programmers and designers began to treat the data in their databases as objects. That is to say that if a person's data were in a database, that person's attributes, such as their address, phone number, and age, were now considered to belong to that person instead of being extraneous data. This allows for relations between data to be relations to objects and their attributes and not to individual fields. The term \"object-relational impedance mismatch\" described the inconvenience of translating between programmed objects and database tables. Object databases and object-relational databases attempt to solve this problem by providing an object-oriented language (sometimes as extensions to SQL) that programmers can use as alternative to purely relational SQL. On the programming side, libraries known as object-relational mappings (ORMs) attempt to solve the same problem.\n\nXML databases are a type of structured document-oriented database that allows querying based on XML document attributes. XML databases are mostly used in applications where the data is conveniently viewed as a collection of documents, with a structure that can vary from the very flexible to the highly rigid: examples include scientific articles, patents, tax filings, and personnel records.\n\nNoSQL databases are often very fast, do not require fixed table schemas, avoid join operations by storing denormalized data, and are designed to scale horizontally.\n\nIn recent years, there has been a strong demand for massively distributed databases with high partition tolerance, but according to the CAP theorem it is impossible for a distributed system to simultaneously provide consistency, availability, and partition tolerance guarantees. A distributed system can satisfy any two of these guarantees at the same time, but not all three. For that reason, many NoSQL databases are using what is called eventual consistency to provide both availability and partition tolerance guarantees with a reduced level of data consistency.\n\nNewSQL is a class of modern relational databases that aims to provide the same scalable performance of NoSQL systems for online transaction processing (read-write) workloads while still using SQL and maintaining the ACID guarantees of a traditional database system.\n\nDatabases are used to support internal operations of organizations and to underpin online interactions with customers and suppliers (see Enterprise software).\n\nDatabases are used to hold administrative information and more specialized data, such as engineering data or economic models. Examples include computerized library systems, flight reservation systems, computerized parts inventory systems, and many content management systems that store websites as collections of webpages in a database.\n\nOne way to classify databases involves the type of their contents, for example: bibliographic, document-text, statistical, or multimedia objects. Another way is by their application area, for example: accounting, music compositions, movies, banking, manufacturing, or insurance. A third way is by some technical aspect, such as the database structure or interface type. This section lists a few of the adjectives used to characterize different kinds of databases.\n\n\n\n\nConnolly and Begg define Database Management System (DBMS) as a \"software system that enables users to define, create, maintain and control access to the database\".\n\nThe DBMS acronym is sometime extended to indicated the underlying database model, with RDBMS for relational, OODBMS or ORDBMS for the object (orientated) model and ORDBMS for Object-Relational. Other extensions can indicate some other characteristic, such as DDBMS for a distributed database management systems.\n\nThe functionality provided by a DBMS can vary enormously. The core functionality is the storage, retrieval and update of data. Codd proposed the following functions and services a fully-fledged general purpose DBMS should provide:\n\nIt is also generally to be expected the DBMS will provide a set of utilities for such purposes as may be necessary to administer the database effectively, including import, export, monitoring, defragmentation and analysis utilities. The core part of the DBMS interacting between the database and the application interface sometimes referred to as the database engine.\n\nOften DBMSs will have configuration parameters that can be statically and dynamically tuned, for example the maximum amount of main memory on a server the database can use. The trend is to minimise the amount of manual configuration, and for cases such as embedded databases the need to target zero-administration is paramount.\n\nThe large major enterprise DBMSs have tended to increase in size and functionality and can have involved thousands of human years of development effort through their lifetime.\n\nEarly multi-user DBMS typically only allowed for the application to reside on the same computer with access via terminals or terminal emulation software. The client–server architecture was a development where the application resided on a client desktop and the database on a server allowing the processing to be distributed. This evolved into a multitier architecture incorporating application servers and web servers with the end user interface via a web browser with the database only directly connected to the adjacent tier.\n\nA general-purpose DBMS will provide public application programming interfaces (API) and optionally a processor for database languages such as SQL to allow applications to be written to interact with the database. A special purpose DBMS may use a private API and be specifically customised and linked to a single application. For example an email system performing many of the functions of a general-purpose DBMS such as message insertion, message deletion, attachment handling, blocklist lookup, associating messages an email address and so forth however these functions are limited to what is required to handle email.\n\nExternal interaction with the database will be via an application program that interfaces with the DBMS. This can range from a database tool that allows users to execute SQL queries textually or graphically, to a web site that happens to use a database to store and search information.\n\nA programmer will code interactions to the database (sometimes referred to as a datasource) via an application program interface (API) or via a database language. The particular API or language chosen will need to be supported by DBMS, possible indirectly via a pre-processor or a bridging API. Some API's aim to be database independent, ODBC being a commonly known example. Other common API's include JDBC and ADO.NET.\n\nDatabase languages are special-purpose languages, which allow one or more of the following tasks, sometimes distinguished as sublanguages:\n\n\nDatabase languages are specific to a particular data model. Notable examples include:\n\n\nA database language may also incorporate features like:\n\nDatabase storage is the container of the physical materialization of a database. It comprises the \"internal\" (physical) \"level\" in the database architecture. It also contains all the information needed (e.g., metadata, \"data about the data\", and internal data structures) to reconstruct the \"conceptual level\" and \"external level\" from the internal level when needed. Putting data into permanent storage is generally the responsibility of the database engine a.k.a. \"storage engine\". Though typically accessed by a DBMS through the underlying operating system (and often using the operating systems' file systems as intermediates for storage layout), storage properties and configuration setting are extremely important for the efficient operation of the DBMS, and thus are closely maintained by database administrators. A DBMS, while in operation, always has its database residing in several types of storage (e.g., memory and external storage). The database data and the additional needed information, possibly in very large amounts, are coded into bits. Data typically reside in the storage in structures that look completely different from the way the data look in the conceptual and external levels, but in ways that attempt to optimize (the best possible) these levels' reconstruction when needed by users and programs, as well as for computing additional types of needed information from the data (e.g., when querying the database).\n\nSome DBMSs support specifying which character encoding was used to store data, so multiple encodings can be used in the same database.\n\nVarious low-level database storage structures are used by the storage engine to serialize the data model so it can be written to the medium of choice. Techniques such as indexing may be used to improve performance. Conventional storage is row-oriented, but there are also column-oriented and correlation databases.\n\nOften storage redundancy is employed to increase performance. A common example is storing \"materialized views\", which consist of frequently needed \"external views\" or query results. Storing such views saves the expensive computing of them each time they are needed. The downsides of materialized views are the overhead incurred when updating them to keep them synchronized with their original updated database data, and the cost of storage redundancy.\n\nOccasionally a database employs storage redundancy by database objects replication (with one or more copies) to increase data availability (both to improve performance of simultaneous multiple end-user accesses to a same database object, and to provide resiliency in a case of partial failure of a distributed database). Updates of a replicated object need to be synchronized across the object copies. In many cases, the entire database is replicated.\n\nDatabase security deals with all various aspects of protecting the database content, its owners, and its users. It ranges from protection from intentional unauthorized database uses to unintentional database accesses by unauthorized entities (e.g., a person or a computer program).\n\nDatabase access control deals with controlling who (a person or a certain computer program) is allowed to access what information in the database. The information may comprise specific database objects (e.g., record types, specific records, data structures), certain computations over certain objects (e.g., query types, or specific queries), or using specific access paths to the former (e.g., using specific indexes or other data structures to access information). Database access controls are set by special authorized (by the database owner) personnel that uses dedicated protected security DBMS interfaces.\n\nThis may be managed directly on an individual basis, or by the assignment of individuals and privileges to groups, or (in the most elaborate models) through the assignment of individuals and groups to roles which are then granted entitlements. Data security prevents unauthorized users from viewing or updating the database. Using passwords, users are allowed access to the entire database or subsets of it called \"subschemas\". For example, an employee database can contain all the data about an individual employee, but one group of users may be authorized to view only payroll data, while others are allowed access to only work history and medical data. If the DBMS provides a way to interactively enter and update the database, as well as interrogate it, this capability allows for managing personal databases.\n\nData security in general deals with protecting specific chunks of data, both physically (i.e., from corruption, or destruction, or removal; e.g., see physical security), or the interpretation of them, or parts of them to meaningful information (e.g., by looking at the strings of bits that they comprise, concluding specific valid credit-card numbers; e.g., see data encryption).\n\nChange and access logging records who accessed which attributes, what was changed, and when it was changed. Logging services allow for a forensic database audit later by keeping a record of access occurrences and changes. Sometimes application-level code is used to record changes rather than leaving this to the database. Monitoring can be set up to attempt to detect security breaches.\n\nDatabase transactions can be used to introduce some level of fault tolerance and data integrity after recovery from a crash. A database transaction is a unit of work, typically encapsulating a number of operations over a database (e.g., reading a database object, writing, acquiring lock, etc.), an abstraction supported in database and also other systems. Each transaction has well defined boundaries in terms of which program/code executions are included in that transaction (determined by the transaction's programmer via special transaction commands).\n\nThe acronym ACID describes some ideal properties of a database transaction: atomicity, consistency, isolation, and durability.\n\nA database built with one DBMS is not portable to another DBMS (i.e., the other DBMS cannot run it). However, in some situations, it is desirable to move, migrate a database from one DBMS to another. The reasons are primarily economical (different DBMSs may have different total costs of ownership or TCOs), functional, and operational (different DBMSs may have different capabilities). The migration involves the database's transformation from one DBMS type to another. The transformation should maintain (if possible) the database related application (i.e., all related application programs) intact. Thus, the database's conceptual and external architectural levels should be maintained in the transformation. It may be desired that also some aspects of the architecture internal level are maintained. A complex or large database migration may be a complicated and costly (one-time) project by itself, which should be factored into the decision to migrate. This in spite of the fact that tools may exist to help migration between specific DBMSs. Typically, a DBMS vendor provides tools to help importing databases from other popular DBMSs.\n\nAfter designing a database for an application, the next stage is building the database. Typically, an appropriate general-purpose DBMS can be selected to be used for this purpose. A DBMS provides the needed user interfaces to be used by database administrators to define the needed application's data structures within the DBMS's respective data model. Other user interfaces are used to select needed DBMS parameters (like security related, storage allocation parameters, etc.).\n\nWhen the database is ready (all its data structures and other needed components are defined), it is typically populated with initial application's data (database initialization, which is typically a distinct project; in many cases using specialized DBMS interfaces that support bulk insertion) before making it operational. In some cases, the database becomes operational while empty of application data, and data are accumulated during its operation.\n\nAfter the database is created, initialised and populated it needs to be maintained. Various database parameters may need changing and the database may need to be tuned (tuning) for better performance; application's data structures may be changed or added, new related application programs may be written to add to the application's functionality, etc.\n\nSometimes it is desired to bring a database back to a previous state (for many reasons, e.g., cases when the database is found corrupted due to a software error, or if it has been updated with erroneous data). To achieve this, a backup operation is done occasionally or continuously, where each desired database state (i.e., the values of its data and their embedding in database's data structures) is kept within dedicated backup files (many techniques exist to do this effectively). When this state is needed, i.e., when it is decided by a database administrator to bring the database back to this state (e.g., by specifying this state by a desired point in time when the database was in this state), these files are used to restore that state.\n\nStatic analysis techniques for software verification can be applied also in the scenario of query languages. In particular, the *Abstract interpretation framework has been extended to the field of query languages for relational databases as a way to support sound approximation techniques. The semantics of query languages can be tuned according to suitable abstractions of the concrete domain of data. The abstraction of relational database system has many interesting applications, in particular, for security purposes, such as fine grained access control, watermarking, etc.\n\nOther DBMS features might include:\n\nIncreasingly, there are calls for a single system that incorporates all of these core functionalities into the same build, test, and deployment framework for database management and source control. Borrowing from other developments in the software industry, some market such offerings as \"DevOps for database\".\n\nThe first task of a database designer is to produce a conceptual data model that reflects the structure of the information to be held in the database. A common approach to this is to develop an entity-relationship model, often with the aid of drawing tools. Another popular approach is the Unified Modeling Language. A successful data model will accurately reflect the possible state of the external world being modeled: for example, if people can have more than one phone number, it will allow this information to be captured. Designing a good conceptual data model requires a good understanding of the application domain; it typically involves asking deep questions about the things of interest to an organization, like \"can a customer also be a supplier?\", or \"if a product is sold with two different forms of packaging, are those the same product or different products?\", or \"if a plane flies from New York to Dubai via Frankfurt, is that one flight or two (or maybe even three)?\". The answers to these questions establish definitions of the terminology used for entities (customers, products, flights, flight segments) and their relationships and attributes.\n\nProducing the conceptual data model sometimes involves input from business processes, or the analysis of workflow in the organization. This can help to establish what information is needed in the database, and what can be left out. For example, it can help when deciding whether the database needs to hold historic data as well as current data.\n\nHaving produced a conceptual data model that users are happy with, the next stage is to translate this into a schema that implements the relevant data structures within the database. This process is often called logical database design, and the output is a logical data model expressed in the form of a schema. Whereas the conceptual data model is (in theory at least) independent of the choice of database technology, the logical data model will be expressed in terms of a particular database model supported by the chosen DBMS. (The terms \"data model\" and \"database model\" are often used interchangeably, but in this article we use \"data model\" for the design of a specific database, and \"database model\" for the modeling notation used to express that design.)\n\nThe most popular database model for general-purpose databases is the relational model, or more precisely, the relational model as represented by the SQL language. The process of creating a logical database design using this model uses a methodical approach known as normalization. The goal of normalization is to ensure that each elementary \"fact\" is only recorded in one place, so that insertions, updates, and deletions automatically maintain consistency.\n\nThe final stage of database design is to make the decisions that affect performance, scalability, recovery, security, and the like, which depend on the particular DBMS. This is often called \"physical database design\", and the output is the physical data model. A key goal during this stage is data independence, meaning that the decisions made for performance optimization purposes should be invisible to end-users and applications. There are two types of data independence: Physical data independence and logical data independence. Physical design is driven mainly by performance requirements, and requires a good knowledge of the expected workload and access patterns, and a deep understanding of the features offered by the chosen DBMS.\n\nAnother aspect of physical database design is security. It involves both defining access control to database objects as well as defining security levels and methods for the data itself.\n\nA database model is a type of data model that determines the logical structure of a database and fundamentally determines in which manner data can be stored, organized, and manipulated. The most popular example of a database model is the relational model (or the SQL approximation of relational), which uses a table-based format.\n\nCommon logical data models for databases include:\n\nAn object-relational database combines the two related structures.\n\nPhysical data models include:\n\nOther models include:\n\nSpecialized models are optimized for particular types of data:\n\nA database management system provides three views of the database data:\n\n\nWhile there is typically only one conceptual (or logical) and physical (or internal) view of the data, there can be any number of different external views. This allows users to see database information in a more business-related way rather than from a technical, processing viewpoint. For example, a financial department of a company needs the payment details of all employees as part of the company's expenses, but does not need details about employees that are the interest of the human resources department. Thus different departments need different \"views\" of the company's database.\n\nThe three-level database architecture relates to the concept of \"data independence\" which was one of the major initial driving forces of the relational model. The idea is that changes made at a certain level do not affect the view at a higher level. For example, changes in the internal level do not affect application programs written using conceptual level interfaces, which reduces the impact of making physical changes to improve performance.\n\nThe conceptual view provides a level of indirection between internal and external. On one hand it provides a common view of the database, independent of different external view structures, and on the other hand it abstracts away details of how the data are stored or managed (internal level). In principle every level, and even every external view, can be presented by a different data model. In practice usually a given DBMS uses the same data model for both the external and the conceptual levels (e.g., relational model). The internal level, which is hidden inside the DBMS and depends on its implementation, requires a different level of detail and uses its own types of data structure types.\n\nSeparating the \"external\", \"conceptual\" and \"internal\" levels was a major feature of the relational database model implementations that dominate 21st century databases.\n\nDatabase technology has been an active research topic since the 1960s, both in academia and in the research and development groups of companies (for example IBM Research). Research activity includes theory and development of prototypes. Notable research topics have included models, the atomic transaction concept, and related concurrency control techniques, query languages and query optimization methods, RAID, and more.\n\nThe database research area has several dedicated academic journals (for example, \"ACM Transactions on Database Systems\"-TODS, \"Data and Knowledge Engineering\"-DKE) and annual conferences (e.g., ACM SIGMOD, ACM PODS, VLDB, IEEE ICDE).\n\n\n"}
{"id": "8378", "url": "https://en.wikipedia.org/wiki?curid=8378", "title": "Dipole", "text": "Dipole\n\nIn electromagnetism, there are two kinds of dipoles:\n\nDipoles can be characterized by their dipole moment, a vector quantity. For the simple electric dipole given above, the electric dipole moment points from the negative charge towards the positive charge, and has a magnitude equal to the strength of each charge times the separation between the charges. (To be precise: for the definition of the dipole moment, one should always consider the \"dipole limit\", where, for example, the distance of the generating charges should \"converge\" to 0 while simultaneously, the charge strength should \"diverge\" to infinity in such a way that the product remains a positive constant.)\n\nFor the current loop, the magnetic dipole moment points through the loop (according to the right hand grip rule), with a magnitude equal to the current in the loop times the area of the loop.\n\nIn addition to current loops, the electron, among other fundamental particles, has a magnetic dipole moment. That is because it generates a magnetic field that is identical to that generated by a very small current loop. However, the electron's magnetic moment is not due to a current loop, but is instead an intrinsic property of the electron. It is also possible that the electron has an \"electric\" dipole moment although it has not yet been observed (see electron electric dipole moment for more information).\nA permanent magnet, such as a bar magnet, owes its magnetism to the intrinsic magnetic dipole moment of the electron. The two ends of a bar magnet are referred to as poles (not to be confused with monopoles), and may be labeled \"north\" and \"south\". In terms of the Earth's magnetic field, they are respectively \"north-seeking\" and \"south-seeking\" poles: if the magnet were freely suspended in the Earth's magnetic field, the north-seeking pole would point towards the north and the south-seeking pole would point towards the south. The dipole moment of the bar magnet points from its magnetic south to its magnetic north pole. The north pole of a bar magnet in a compass points north. However, that means that Earth's geomagnetic north pole is the \"south\" pole (south-seeking pole) of its dipole moment and vice versa.\n\nThe only known mechanisms for the creation of magnetic dipoles are by current loops or quantum-mechanical spin since the existence of magnetic monopoles has never been experimentally demonstrated.\n\nThe term comes from the Greek (\"dis\"), \"twice\" and (\"polos\"), \"axis\".\n\nA \"physical dipole\" consists of two equal and opposite point charges: in the literal sense, two poles. Its field at large distances (i.e., distances large in comparison to the separation of the poles) depends almost entirely on the dipole moment as defined above. A \"point (electric) dipole\" is the limit obtained by letting the separation tend to 0 while keeping the dipole moment fixed. The field of a point dipole has a particularly simple form, and the order-1 term in the multipole expansion is precisely the point dipole field.\n\nAlthough there are no known magnetic monopoles in nature, there are magnetic dipoles in the form of the quantum-mechanical spin associated with particles such as electrons (although the accurate description of such effects falls outside of classical electromagnetism). A theoretical magnetic \"point dipole\" has a magnetic field of exactly the same form as the electric field of an electric point dipole. A very small current-carrying loop is approximately a magnetic point dipole; the magnetic dipole moment of such a loop is the product of the current flowing in the loop and the (vector) area of the loop.\n\nAny configuration of charges or currents has a 'dipole moment', which describes the dipole whose field is the best approximation, at large distances, to that of the given configuration. This is simply one term in the multipole expansion when the total charge (\"monopole moment\") is 0—as it \"always\" is for the magnetic case, since there are no magnetic monopoles. The dipole term is the dominant one at large distances: Its field falls off in proportion to , as compared to for the next (quadrupole) term and higher powers of for higher terms, or for the monopole term.\n\nMany molecules have such dipole moments due to non-uniform distributions of positive and negative charges on the various atoms. Such is the case with polar compounds like hydrogen fluoride (HF), where electron density is shared unequally between atoms. Therefore, a molecule's dipole is an electric dipole with an inherent electric field which should not be confused with a magnetic dipole which generates a magnetic field.\n\nThe physical chemist Peter J. W. Debye was the first scientist to study molecular dipoles extensively, and, as a consequence, dipole moments are measured in units named \"debye\" in his honor.\n\nFor molecules there are three types of dipoles:\n\nMore generally, an induced dipole of \"any\" polarizable charge distribution \"ρ\" (remember that a molecule has a charge distribution) is caused by an electric field external to \"ρ\". This field may, for instance, originate from an ion or polar molecule in the vicinity of \"ρ\" or may be macroscopic (e.g., a molecule between the plates of a charged capacitor). The size of the induced dipole moment is equal to the product of the strength of the external field and the dipole polarizability of \"ρ\".\n\nDipole moment values can be obtained from measurement of the dielectric constant. Some typical gas phase values in debye units are:\n\nPotassium bromide (KBr) has one of the highest dipole moments because it is an ionic compound that exists as a molecule in the gas phase.\nThe overall dipole moment of a molecule may be approximated as a vector sum of bond dipole moments. As a vector sum it depends on the relative orientation of the bonds, so that from the dipole moment information can be deduced about the molecular geometry.\n\nFor example, the zero dipole of CO implies that the two C=O bond dipole moments cancel so that the molecule must be linear. For HO the O−H bond moments do not cancel because the molecule is bent. For ozone (O) which is also a bent molecule, the bond dipole moments are not zero even though the O−O bonds are between similar atoms. This agrees with the Lewis structures for the resonance forms of ozone which show a positive charge on the central oxygen atom. \nAn example in organic chemistry of the role of geometry in determining dipole moment is the \"cis\" and \"trans\" isomers of 1,2-dichloroethene. In the \"cis\" isomer the two polar C−Cl bonds are on the same side of the C=C double bond and the molecular dipole moment is 1.90 D. In the \"trans\" isomer, the dipole moment is zero because the two C−Cl bonds are on opposite sides of the C=C and cancel (and the two bond moments for the much less polar C−H bonds also cancel).\n\nAnother example of the role of molecular geometry is boron trifluoride, which has three polar bonds with a difference in electronegativity greater than the traditionally cited threshold of 1.7 for ionic bonding. However, due to the equilateral triangular distribution of the fluoride ions about the boron cation center, the molecule as a whole does not exhibit any identifiable pole: one cannot construct a plane that divides the molecule into a net negative part and a net positive part.\n\nConsider a collection of \"N\" particles with charges \"q\" and position vectors r. For instance, this collection may be a molecule consisting of electrons, all with charge −\"e\", and nuclei with charge \"eZ\", where \"Z\" is the atomic number of the \"i\" th nucleus.\nThe dipole observable (physical quantity) has the quantum mechanical dipole operator:\nNotice that this definition is valid only for non-charged dipoles, i.e. total charge equal to zero. To a charged dipole we have the next equation:\nwhere formula_3 is the center of mass of the molecule/group of particles.\n\nA non-degenerate (\"S\"-state) atom can have only a zero permanent dipole. This fact follows quantum mechanically from the inversion symmetry of atoms. All 3 components of the dipole operator are antisymmetric under inversion with respect to the nucleus,\n\nwhere formula_5 is the dipole operator and formula_6 is the inversion operator.\n\nThe permanent dipole moment of an atom in a non-degenerate state (see degenerate energy level) is given as the expectation (average) value of the dipole operator,\n\nwhere formula_8 is an \"S\"-state, non-degenerate, wavefunction, which is symmetric or antisymmetric under inversion: formula_9. Since the product of the wavefunction (in the ket) and its complex conjugate (in the bra) is always symmetric under inversion and its inverse,\n\nit follows that the expectation value changes sign under inversion. We used here the fact that formula_11, being a symmetry operator, is unitary: formula_12 and by definition the Hermitian adjoint formula_13 may be moved from bra to ket and then becomes formula_14. Since the only quantity that is equal to minus itself is the zero, the expectation value vanishes,\n\nIn the case of open-shell atoms with degenerate energy levels, one could define a dipole moment by the aid of the first-order Stark effect. This gives a non-vanishing dipole (by definition proportional to a non-vanishing first-order Stark shift) only if some of the wavefunctions belonging to the degenerate energies have opposite parity; i.e., have different behavior under inversion. This is a rare occurrence, but happens for the excited H-atom, where 2s and 2p states are \"accidentally\" degenerate (see article Laplace–Runge–Lenz vector for the origin of this degeneracy) and have opposite parity (2s is even and 2p is odd).\n\nThe far-field strength, \"B\", of a dipole magnetic field is given by\n\nwhere\n\nConversion to cylindrical coordinates is achieved using and\n\nwhere \"ρ\" is the perpendicular distance from the \"z\"-axis. Then,\n\nThe field itself is a vector quantity:\n\nwhere\n\nThis is \"exactly\" the field of a point dipole, \"exactly\" the dipole term in the multipole expansion of an arbitrary field, and \"approximately\" the field of any dipole-like configuration at large distances.\n\nThe vector potential A of a magnetic dipole is\n\nwith the same definitions as above.\n\nThe electrostatic potential at position r due to an electric dipole at the origin is given by:\n\nwhere\n\nThis term appears as the second term in the multipole expansion of an arbitrary electrostatic potential Φ(r). If the source of Φ(r) is a dipole, as it is assumed here, this term is the only non-vanishing term in the multipole expansion of Φ(r). The electric field from a dipole can be found from the gradient of this potential:\n\nwhere E is the electric field and \"δ\" is the 3-dimensional delta function. This is formally identical to the magnetic H field of a point magnetic dipole with only a few names changed.\n\nSince the direction of an electric field is defined as the direction of the force on a positive charge, electric field lines point away from a positive charge and toward a negative charge.\n\nWhen placed in an electric or magnetic field, equal but opposite forces arise on each side of the dipole creating a torque }:\n\nfor an electric dipole moment p (in coulomb-meters), or\n\nfor a magnetic dipole moment m (in ampere-square meters).\n\nThe resulting torque will tend to align the dipole with the applied field, which in the case of an electric dipole, yields a potential energy of\n\nThe energy of a magnetic dipole is similarly\n\nIn addition to dipoles in electrostatics, it is also common to consider an electric or magnetic dipole that is oscillating in time. It is an extension, or a more physical next-step, to spherical wave radiation.\n\nIn particular, consider a harmonically oscillating electric dipole, with angular frequency \"ω\" and a dipole moment \"p\" along the ẑ direction of the form\n\nIn vacuum, the exact field produced by this oscillating dipole can be derived using the retarded potential formulation as:\n\nFor  ≫ 1, the far-field takes the simpler form of a radiating \"spherical\" wave, but with angular dependence embedded in the cross-product:\n\nThe time-averaged Poynting vector\n\nis not distributed isotropically, but concentrated around the directions lying perpendicular to the dipole moment, as a result of the non-spherical electric and magnetic waves. In fact, the spherical harmonic function (sin \"θ\") responsible for such toroidal angular distribution is precisely the \"l\" = 1 \"p\" wave.\n\nThe total time-average power radiated by the field can then be derived from the Poynting vector as\n\nNotice that the dependence of the power on the fourth power of the frequency of the radiation is in accordance with the Rayleigh scattering, and the underlying effects why the sky consists of mainly blue colour.\n\nA circular polarized dipole is described as a superposition of two linear dipoles.\n\n\n"}
{"id": "8386", "url": "https://en.wikipedia.org/wiki?curid=8386", "title": "Dynamics", "text": "Dynamics\n\nDynamics (from Greek δυναμικός \"dynamikos\" \"powerful\", from δύναμις \"dynamis\" \"power\") or dynamic may refer to:\n\n\n\n\n\n"}
{"id": "8387", "url": "https://en.wikipedia.org/wiki?curid=8387", "title": "Draught beer", "text": "Draught beer\n\nDraught beer, also spelt draft, is beer served from a cask or keg rather than from a bottle or can. Draught beer served from a pressurised keg is also known as \n\nUntil Joseph Bramah patented the beer engine in 1785, beer was served directly from the barrel and carried to the customer. The Old English \"\" (\"carry; pull\") developed into a series of related words including \"drag\", \"draw\", and \"draught\". By the time Bramah's beer pumps became popular, the use of the term \"draught\" to refer to the acts of serving or drinking beer was well established and transferred easily to beer served via the hand pumps. In time, the word came to be restricted to only such beer. The usual spelling is now \"draught\" in the United Kingdom, Ireland, Australia, and New Zealand and more commonly \"draft\" in North America, although it can be spelt either way. Regardless of spelling, the word is pronounced or depending on the region the speaker is from.\n\nCanned draught is beer served from a pressurised container featuring a widget. Smooth flow (also known as cream flow, nitrokeg, or smooth) is the name brewers give to draught beers pressurised with a partial nitrogen gas blend.\n\nIn 1691, an article in the \"London Gazette\" mentioned John Lofting, who held a patent for a fire engine: \"The said patentee has also projected a very useful engine for starting of beer, and other liquors which will draw from 20 to 30 barrels an hour, which are completely fixed with brass joints and screws at reasonable rates\".\n\nIn the early 20th century, draught beer started to be served from pressurised containers. Artificial carbonation was introduced in the United Kingdom in 1936, with Watney’s experimental pasteurised beer Red Barrel. Though this method of serving beer did not take hold in the U.K. until the late 1950s, it did become the favored method in the rest of Europe, where it is known by such terms as \"en pression\". The carbonation method of serving beer subsequently spread to the rest of the world; by the early 1970s the term \"draught beer\" almost exclusively referred to beer served under pressure as opposed to the traditional cask or barrel beer.\n\nIn Britain, the Campaign for Real Ale (CAMRA) was founded in 1971 to protect traditional - unpressurised beer and brewing methods. The group devised the term \"real ale\" to differentiate between beer served from the cask and beer served under pressure. The term \"real ale\" has since been expanded to include bottle-conditioned beer.\n\nKeg beer is often filtered and/or pasteurised, both of which are processes that render the yeast inactive.\n\nIn brewing parlance, a keg is different from a cask. A cask has a tap hole near the edge of the top, and a spile hole on the side used for conditioning the unfiltered and unpasteurised beer. A keg has a single opening in the centre of the top to which a flow pipe is attached. Kegs are artificially pressurised after fermentation with carbon dioxide or a mixture of carbon dioxide and nitrogen gas.\n\n\"Keg\" has become a term of contempt used by some, particularly in Britain, since the 1960s when pasteurised draught beers started replacing traditional cask beers.\n\nKeg beer was replacing traditional cask ale in all parts of the UK, primarily because it requires less care to handle. Since 1971, CAMRA has conducted a consumer campaign on behalf of those who prefer traditional cask beer. CAMRA has lobbied the British Parliament to ensure support for cask ale and microbreweries have sprung up to serve those consumers who prefer traditional cask beer.\n\nPressurised CO in the keg's headspace maintains carbonation in the beer. The CO pressure varies depending on the amount of CO already in the beer and the keg storage temperature. Occasionally the CO gas is blended with nitrogen gas. CO / nitrogen blends are used to allow a higher operating pressure in complex dispensing systems.\n\nNitrogen is used under high pressure when dispensing dry stouts (such as Guinness) and other creamy beers because it displaces CO to (artificially) form a rich tight head and a less carbonated taste. This makes the beer feel smooth on the palate and gives a foamy appearance. Premixed bottled gas for creamy beers is usually 75% nitrogen and 25% CO. This premixed gas which only works well with creamy beers is often referred to as Guinness Gas, Beer Gas, or Aligal. Using \"Beer Gas\" with other beer styles can cause the last 5% to 10% of the beer in each keg to taste very flat and lifeless. In the UK, the term \"keg beer\" would imply the beer is pasteurised, in contrast to unpasteurised cask ale. Some of the newer microbreweries may offer a nitro keg stout which is filtered but not pasteurized.\n\nCask beer should be stored and served at a cellar temperature of . Once a cask is opened, it should be consumed within three days. Keg beer is given additional cooling just prior to being served either by flash coolers or a remote cooler in the cellar. This chills the beer down to temperatures between .\n\nThe words \"draft\" and \"draught\" have been used as marketing terms to describe canned or bottled beers, implying that they taste and appear like beers from a cask or keg. Commercial brewers use this as a marketing tool although it is incorrect to call any beer not drawn from a cask or keg \"draught\". Two examples are Miller Genuine Draft, a pale lager which is produced using a cold filtering system, and Guinness stout in patented \"Draught-flow\" cans and bottles. Guinness is an example of beers that use a nitrogen widget to create a smooth beer with a very dense head. Guinness has recently replaced the widget system from their bottled \"draught\" beer with a coating of cellulose fibres on the inside of the bottle. Statements indicate a new development in bottling technology that enables the mixture of nitrogen and carbon dioxide to be present in the beer without using a widget, making it according to Guinness \"more drinkable\" from the bottle.\n\nIn some countries such as Japan, the term \"draft\" applied to canned or bottled beer indicates that the beer is not pasteurized (though it may be filtered), giving it a fresher taste but shorter shelf life than conventional packaged beers.\n\n\n"}
{"id": "8388", "url": "https://en.wikipedia.org/wiki?curid=8388", "title": "Director", "text": "Director\n\nDirector may refer to:\n\n\n\n\n\n\n\n\n"}
{"id": "8389", "url": "https://en.wikipedia.org/wiki?curid=8389", "title": "Major depressive disorder", "text": "Major depressive disorder\n\nMajor depressive disorder (MDD), also known simply as depression, is a mental disorder characterized by at least two weeks of low mood that is present across most situations. It is often accompanied by low self-esteem, loss of interest in normally enjoyable activities, low energy, and pain without a clear cause. People may also occasionally have false beliefs or see or hear things that others cannot. Some people have periods of depression separated by years in which they are normal, while others nearly always have symptoms present. Major depressive disorder can negatively affect a person's personal life, work life, or education, as well as sleeping, eating habits, and general health. Between 2–8% of adults with major depression die by suicide, and about 50% of people who die by suicide had depression or another mood disorder.\nThe cause is believed to be a combination of genetic, environmental, and psychological factors. Risk factors include a family history of the condition, major life changes, certain medications, chronic health problems, and substance abuse. About 40% of the risk appears to be related to genetics. The diagnosis of major depressive disorder is based on the person's reported experiences and a mental status examination. There is no laboratory test for major depression. Testing, however, may be done to rule out physical conditions that can cause similar symptoms. Major depression is more severe and lasts longer than sadness, which is a normal part of life. The United States Preventive Services Task Force (USPSTF) recommends screening for depression among those over the age 12, while a prior Cochrane review found that the routine use of screening questionnaires has little effect on detection or treatment.\nTypically, people are treated with counseling and antidepressant medication. Medication appears to be effective, but the effect may only be significant in the most severely depressed. It is unclear whether medications affect the risk of suicide. Types of counseling used include cognitive behavioral therapy (CBT) and interpersonal therapy. If other measures are not effective, electroconvulsive therapy (ECT) may be considered. Hospitalization may be necessary in cases with a risk of harm to self and may occasionally occur against a person's wishes.\nMajor depressive disorder affected approximately 216 million people (3% of the world's population) in 2015. The percentage of people who are affected at one point in their life varies from 7% in Japan to 21% in France. Lifetime rates are higher in the developed world (15%) compared to the developing world (11%). It causes the second-most years lived with disability, after lower back pain. The most common time of onset is in a person's 20s and 30s. Females are affected about twice as often as males. The American Psychiatric Association added \"major depressive disorder\" to the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM-III) in 1980. It was a split of the previous depressive neurosis in the DSM-II, which also encompassed the conditions now known as dysthymia and adjustment disorder with depressed mood. Those currently or previously affected may be stigmatized.\n\nMajor depression significantly affects a person's family and personal relationships, work or school life, sleeping and eating habits, and general health. Its impact on functioning and well-being has been compared to that of other chronic medical conditions, such as diabetes.\n\nA person having a major depressive episode usually exhibits a very low mood, which pervades all aspects of life, and an inability to experience pleasure in activities that were formerly enjoyed. Depressed people may be preoccupied with, or ruminate over, thoughts and feelings of worthlessness, inappropriate guilt or regret, helplessness, hopelessness, and self-hatred. In severe cases, depressed people may have symptoms of psychosis. These symptoms include delusions or, less commonly, hallucinations, usually unpleasant. Other symptoms of depression include poor concentration and memory (especially in those with melancholic or psychotic features), withdrawal from social situations and activities, reduced sex drive, irritability, and thoughts of death or suicide. Insomnia is common among the depressed. In the typical pattern, a person wakes very early and cannot get back to sleep. Hypersomnia, or oversleeping, can also happen. Some antidepressants may also cause insomnia due to their stimulating effect.\n\nA depressed person may report multiple physical symptoms such as fatigue, headaches, or digestive problems; physical complaints are the most common presenting problem in developing countries, according to the World Health Organization's criteria for depression. Appetite often decreases, with resulting weight loss, although increased appetite and weight gain occasionally occur. Family and friends may notice that the person's behavior is either agitated or lethargic. Older depressed people may have cognitive symptoms of recent onset, such as forgetfulness, and a more noticeable slowing of movements. Depression often coexists with physical disorders common among the elderly, such as stroke, other cardiovascular diseases, Parkinson's disease, and chronic obstructive pulmonary disease.\n\nDepressed children may often display an irritable mood rather than a depressed one, and show varying symptoms depending on age and situation. Most lose interest in school and show a decline in academic performance. They may be described as clingy, demanding, dependent, or insecure. Diagnosis may be delayed or missed when symptoms are interpreted as \"normal moodiness.\"\n\nMajor depression frequently co-occurs with other psychiatric problems. The 1990–92 \"National Comorbidity Survey\" (US) reports that half of those with major depression also have lifetime anxiety and its associated disorders such as generalized anxiety disorder. Anxiety symptoms can have a major impact on the course of a depressive illness, with delayed recovery, increased risk of relapse, greater disability and increased suicide attempts. There are increased rates of alcohol and drug abuse and particularly dependence, and around a third of individuals diagnosed with ADHD develop comorbid depression. Post-traumatic stress disorder and depression often co-occur. Depression may also coexist with attention deficit hyperactivity disorder (ADHD), complicating the diagnosis and treatment of both. Depression is also frequently comorbid with alcohol abuse and personality disorders. Depression can also be exacerbated during particular months (usually winter) for those with seasonal affective disorder.\n\nDepression and pain often co-occur. One or more pain symptoms are present in 65% of depressed patients, and anywhere from 5 to 85% of patients with pain will be suffering from depression, depending on the setting; there is a lower prevalence in general practice, and higher in specialty clinics. The diagnosis of depression is often delayed or missed, and the outcome can worsen if the depression is noticed but completely misunderstood.\n\nDepression is also associated with a 1.5- to 2-fold increased risk of cardiovascular disease, independent of other known risk factors, and is itself linked directly or indirectly to risk factors such as smoking and obesity. People with major depression are less likely to follow medical recommendations for treating and preventing cardiovascular disorders, which further increases their risk of medical complications. In addition, cardiologists may not recognize underlying depression that complicates a cardiovascular problem under their care.\n\nThe cause of major depressive disorder is unknown. The biopsychosocial model proposes that biological, psychological, and social factors all play a role in causing depression. The diathesis–stress model specifies that depression results when a preexisting vulnerability, or diathesis, is activated by stressful life events. The preexisting vulnerability can be either genetic, implying an interaction between nature and nurture, or schematic, resulting from views of the world learned in childhood.\n\nChildhood abuse, either physical, sexual or psychological, are all risk factors for depression, among other psychiatric issues that co-occur such as anxiety and drug abuse. Childhood trauma also correlates with severity of depression, lack of response to treatment and length of illness. However, some are more susceptible to developing mental illness such as depression after trauma, and various genes have been suggested to control susceptibility.\n\nThe 5-HTTLPR, or serotonin transporter promoter gene's short allele has been associated with increased risk of depression. However, since the 1990s, results have been inconsistent, with three recent reviews finding an effect and two finding none. Other genes that have been linked to a gene-environment interaction include CRHR1, FKBP5 and BDNF, the first two of which are related to the stress reaction of the HPA axis, and the latter of which is involved in neurogenesis. A 2018 study found 44 areas within the chromosomes that were linked to MDD.\n\nDepression may also come secondary to a chronic or terminal medical condition, such as HIV/AIDS or asthma, and may be labeled \"secondary depression.\" It is unknown whether the underlying diseases induce depression through effect on quality of life, of through shared etiologies (such as degeneration of the basal ganglia in Parkinson's disease or immune dysregulation in asthma). Depression may also be iatrogenic (the result of healthcare), such as drug-induced depression. Therapies associated with depression include interferons, beta-blockers, isotretinoin, contraceptives, cardiac agents, anticonvulsants, antimigraine drugs, antipsychotics, and hormonal agents such as gonadotropin-releasing hormone agonist. Drug abuse in early age is also associated with increased risk of developing depression later in life. Depression that occurs as a result of pregnancy is called postpartum depression, and is thought to be the result of hormonal changes associated with pregnancy. Seasonal affective disorder, a type of depression associated with seasonal changes in sunlight, is thought to be the result of decreased sunlight.\n\nThe pathophysiology of depression is not yet understood, but the current theories center around monoaminergic systems, the circadian rhythm, immunological dysfunction, HPA axis dysfunction and structural or functional abnormalities of emotional circuits.\n\nThe monoamine theory, derived from the efficacy of monoaminergic drugs in treating depression, was the dominant theory until recently. The theory postulates that insufficient activity of monoamine neurotransmitters is the primary cause of depression. Evidence for the monoamine theory comes from multiple areas. Firstly, acute depletion of tryptophan, a necessary precursor of serotonin, a monoamine, can cause depression in those in remission or relatives of depressed patients; this suggests that decreased serotonergic neurotransmission is important in depression. Secondly, the correlation between depression risk and polymorphisms in the 5-HTTLPR gene, which codes for serotonin receptors, suggests a link. Third, decreased size of the locus coeruleus, decreased activity of tyrosine hydroxylase, increased density of alpha-2 adrenergic receptor, and evidence from rat models suggest decreased adrenergic neurotransmission in depression. Furthermore, decreased levels of homovanillic acid, altered response to dextroamphetamine, responses of depressive symptoms to dopamine receptor agonists, decreased dopamine receptor D1 binding in the striatum, and polymorphism of dopamine receptor genes implicate dopamine, another monoamine, in depression. Lastly, increased activity of monoamine oxidase, which degrades monoamines, has been associated with depression. However, this theory is inconsistent with the fact that serotonin depletion does not cause depression in healthy persons, the fact that antidepressants instantly increase levels of monoamines but take weeks to work, and the existence of atypical antidepressants which can be effective despite not targeting this pathway. One proposed explanation for the therapeutic lag, and further support for the deficiency of monoamines, is a desensitization of self-inhibition in raphe nuclei by the increased serotonin mediated by antidepressants. However, disinhibition of the dorsal raphe has been proposed to occur as a result of \"decreased\" serotonergic activity in tryptophan depletion, resulting in a depressed state mediated by increased serotonin. Further countering the monoamine hypothesis is the fact that rats with lesions of the dorsal raphe are not more depressive than controls, the finding of increased jugular 5-HIAA in depressed patients that normalized with SSRI treatment, and the preference for carbohydrates in depressed patients. Already limited, the monoamine hypothesis has been further oversimplified when presented to the general public.\n\nImmune system abnormalities have been observed, including increased levels of cytokines involved in generating sickness behavior (which shares overlap with depression). The effectiveness of nonsteroidal anti-inflammatory drugs (NSAIDs) and cytokine inhibitors in treating depression, and normalization of cytokine levels after successful treatment further suggest immune system abnormalities in depression.\n\nHPA axis abnormalities have been suggested in depression given the association of CRHR1 with depression and the increased frequency of dexamethasone test non-suppression in depressed patients. However, this abnormality is not adequate as a diagnosis tool, because its sensitivity is only 44%. These stress-related abnormalities have been hypothesized to be the cause of hippocampal volume reductions seen in depressed patients. Furthermore, a meta-analysis yielded decreased dexamethasone suppression, and increased response to psychological stressors. Further abnormal results have been obscured with the cortisol awakening response, with increased response being associated with depression.\n\nTheories unifying neuroimaging findings have been proposed. The first model proposed is the \"Limbic Cortical Model\", which involves hyperactivity of the ventral paralimbic regions and hypoactivity of frontal regulatory regions in emotional processing. Another model, the \"Corito-Striatal model\", suggests that abnormalities of the prefrontal cortex in regulating striatal and subcortical structures results in depression. Another model proposes hyperactivity of salience structures in identifying negative stimuli, and hypoactivity of cortical regulatory structures resulting in a negative emotional bias and depression, consistent with emotional bias studies.\n\nA diagnostic assessment may be conducted by a suitably trained general practitioner, or by a psychiatrist or psychologist, who records the person's current circumstances, biographical history, current symptoms, and family history. The broad clinical aim is to formulate the relevant biological, psychological, and social factors that may be impacting on the individual's mood. The assessor may also discuss the person's current ways of regulating mood (healthy or otherwise) such as alcohol and drug use. The assessment also includes a mental state examination, which is an assessment of the person's current mood and thought content, in particular the presence of themes of hopelessness or pessimism, self-harm or suicide, and an absence of positive thoughts or plans. Specialist mental health services are rare in rural areas, and thus diagnosis and management is left largely to primary-care clinicians. This issue is even more marked in developing countries. The mental health examination may include the use of a rating scale such as the Hamilton Rating Scale for Depression, the Beck Depression Inventory or the Suicide Behaviors Questionnaire-Revised. The score on a rating scale alone is insufficient to diagnose depression to the satisfaction of the DSM or ICD, but it provides an indication of the severity of symptoms for a time period, so a person who scores above a given cut-off point can be more thoroughly evaluated for a depressive disorder diagnosis. Several rating scales are used for this purpose.\n\nPrimary-care physicians and other non-psychiatrist physicians have more difficulty with underrecognition and undertreatment of depression compared to psychiatric physicians, in part because of the physical symptoms that often accompany depression, in addition to many potential patient, provider, and system barriers. A review found that non-psychiatrist physicians miss about two-thirds of cases, though this has improved somewhat in more recent studies.\n\nBefore diagnosing a major depressive disorder, in general a doctor performs a medical examination and selected investigations to rule out other causes of symptoms. These include blood tests measuring TSH and thyroxine to exclude hypothyroidism; basic electrolytes and serum calcium to rule out a metabolic disturbance; and a full blood count including ESR to rule out a systemic infection or chronic disease. Adverse affective reactions to medications or alcohol misuse are often ruled out, as well. Testosterone levels may be evaluated to diagnose hypogonadism, a cause of depression in men. Vitamin D levels might be evaluated, as low levels of vitamin D have been associated with greater risk for depression.\n\nSubjective cognitive complaints appear in older depressed people, but they can also be indicative of the onset of a dementing disorder, such as Alzheimer's disease. Cognitive testing and brain imaging can help distinguish depression from dementia. A CT scan can exclude brain pathology in those with psychotic, rapid-onset or otherwise unusual symptoms. In general, investigations are not repeated for a subsequent episode unless there is a medical indication.\n\nNo biological tests confirm major depression. Biomarkers of depression have been sought to provide an objective method of diagnosis. There are several potential biomarkers, including brain-derived neurotrophic factor and various functional MRI (fMRI) techniques. One study developed a decision tree model of interpreting a series of fMRI scans taken during various activities. In their subjects, the authors of that study were able to achieve a sensitivity of 80% and a specificity of 87%, corresponding to a negative predictive value of 98% and a positive predictive value of 32% (positive and negative likelihood ratios were 6.15, 0.23, respectively). However, much more research is needed before these tests can be used clinically.\n\nThe most widely used criteria for diagnosing depressive conditions are found in the American Psychiatric Association's revised fourth edition of the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM-IV-TR), and the World Health Organization's \"International Statistical Classification of Diseases and Related Health Problems\" (ICD-10), which uses the name \"depressive episode\" for a single episode and \"recurrent depressive disorder\" for repeated episodes. The latter system is typically used in European countries, while the former is used in the US and many other non-European nations, and the authors of both have worked towards conforming one with the other.\n\nBoth DSM-IV-TR and ICD-10 mark out typical (main) depressive symptoms. ICD-10 defines three typical depressive symptoms (depressed mood, anhedonia, and reduced energy), two of which should be present to determine the depressive disorder diagnosis. According to DSM-IV-TR, there are two main depressive symptoms—depressed mood and anhedonia. At least one of these must be present to make a diagnosis of major depressive episode.\n\nMajor depressive disorder is classified as a mood disorder in DSM-IV-TR. The diagnosis hinges on the presence of single or recurrent major depressive episodes. Further qualifiers are used to classify both the episode itself and the course of the disorder. The category Depressive Disorder Not Otherwise Specified is diagnosed if the depressive episode's manifestation does not meet the criteria for a major depressive episode. The ICD-10 system does not use the term \"major depressive disorder\" but lists very similar criteria for the diagnosis of a depressive episode (mild, moderate or severe); the term \"recurrent\" may be added if there have been multiple episodes without mania.\n\nA major depressive episode is characterized by the presence of a severely depressed mood that persists for at least two weeks. Episodes may be isolated or recurrent and are categorized as mild (few symptoms in excess of minimum criteria), moderate, or severe (marked impact on social or occupational functioning). An episode with psychotic features—commonly referred to as \"psychotic depression\"—is automatically rated as severe. If the patient has had an episode of mania or markedly elevated mood, a diagnosis of bipolar disorder is made instead. Depression without mania is sometimes referred to as \"unipolar\" because the mood remains at one emotional state or \"pole\".\n\nDSM-IV-TR excludes cases where the symptoms are a result of bereavement, although it is possible for normal bereavement to evolve into a depressive episode if the mood persists and the characteristic features of a major depressive episode develop. The criteria have been criticized because they do not take into account any other aspects of the personal and social context in which depression can occur. In addition, some studies have found little empirical support for the DSM-IV cut-off criteria, indicating they are a diagnostic convention imposed on a continuum of depressive symptoms of varying severity and duration: Excluded are a range of related diagnoses, including dysthymia, which involves a chronic but milder mood disturbance; recurrent brief depression, consisting of briefer depressive episodes; minor depressive disorder, whereby only some symptoms of major depression are present; and adjustment disorder with depressed mood, which denotes low mood resulting from a psychological response to an identifiable event or stressor.\n\nThe DSM-IV-TR recognizes five further subtypes of MDD, called \"specifiers\", in addition to noting the length, severity and presence of psychotic features:\n\nIn 2016, the United States Preventive Services Task Force (USPSTF) recommended screening in the adult populations with evidence that it increases the detection of people with depression and with proper treatment improves outcomes. They recommend screening in those between the age of 12 to 18 as well.\n\nA Cochrane review from 2005 found screening programs do not significantly improve detection rates, treatment, or outcome.\n\nTo confirm major depressive disorder as the most likely diagnosis, other potential diagnoses must be considered, including dysthymia, adjustment disorder with depressed mood, or bipolar disorder. Dysthymia is a chronic, milder mood disturbance in which a person reports a low mood almost daily over a span of at least two years. The symptoms are not as severe as those for major depression, although people with dysthymia are vulnerable to secondary episodes of major depression (sometimes referred to as \"double depression\"). Adjustment disorder with depressed mood is a mood disturbance appearing as a psychological response to an identifiable event or stressor, in which the resulting emotional or behavioral symptoms are significant but do not meet the criteria for a major depressive episode. Bipolar disorder, also known as \"manic–depressive disorder\", is a condition in which depressive phases alternate with periods of mania or hypomania. Although depression is currently categorized as a separate disorder, there is ongoing debate because individuals diagnosed with major depression often experience some hypomanic symptoms, indicating a mood disorder continuum. Further differential diagnoses involve chronic fatigue syndrome.\n\nOther disorders need to be ruled out before diagnosing major depressive disorder. They include depressions due to physical illness, medications, and substance abuse. Depression due to physical illness is diagnosed as a mood disorder due to a general medical condition. This condition is determined based on history, laboratory findings, or physical examination. When the depression is caused by a medication, drug of abuse, or exposure to a toxin, it is then diagnosed as a specific mood disorder (previously called \"substance-induced mood disorder\" in the DSM-IV-TR).\n\nPreventative efforts may result in decreases in rates of the condition of between 22 and 38%. Eating large amounts of fish may also reduce the risk.\n\nBehavioral interventions, such as interpersonal therapy and cognitive-behavioral therapy, are effective at preventing new onset depression. Because such interventions appear to be most effective when delivered to individuals or small groups, it has been suggested that they may be able to reach their large target audience most efficiently through the Internet.\n\nHowever, an earlier meta-analysis found preventive programs with a competence-enhancing component to be superior to behavior-oriented programs overall, and found behavioral programs to be particularly unhelpful for older people, for whom social support programs were uniquely beneficial. In addition, the programs that best prevented depression comprised more than eight sessions, each lasting between 60 and 90 minutes, were provided by a combination of lay and professional workers, had a high-quality research design, reported attrition rates, and had a well-defined intervention.\n\nThe Netherlands mental health care system provides preventive interventions, such as the \"Coping with Depression\" course (CWD) for people with sub-threshold depression. The course is claimed to be the most successful of psychoeducational interventions for the treatment and prevention of depression (both for its adaptability to various populations and its results), with a risk reduction of 38% in major depression and an efficacy as a treatment comparing favorably to other psychotherapies.\n\nThe three most common treatments for depression are psychotherapy, medication, and electroconvulsive therapy. Psychotherapy is the treatment of choice (over medication) for people under 18. The UK National Institute for Health and Care Excellence (NICE) 2004 guidelines indicate that antidepressants should not be used for the initial treatment of mild depression, because the risk-benefit ratio is poor. The guidelines recommend that antidepressants treatment in combination with psychosocial interventions should be considered for:\n\nThe guidelines further note that antidepressant treatment should be continued for at least six months to reduce the risk of relapse, and that SSRIs are better tolerated than tricyclic antidepressants.\n\nAmerican Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors including severity of symptoms, co-existing disorders, prior treatment experience, and patient preference. Options may include pharmacotherapy, psychotherapy, exercise, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. Antidepressant medication is recommended as an initial treatment choice in people with mild, moderate, or severe major depression, and should be given to all patients with severe depression unless ECT is planned. There is evidence that collaborative care by a team of health care practitioners produces better results than routine single-practitioner care.\n\nTreatment options are much more limited in developing countries, where access to mental health staff, medication, and psychotherapy is often difficult. Development of mental health services is minimal in many countries; depression is viewed as a phenomenon of the developed world despite evidence to the contrary, and not as an inherently life-threatening condition. A 2014 Cochrane review found insufficient evidence to determine the effectiveness of psychological versus medical therapy in children.\n\nPhysical exercise is recommended for management of mild depression, and has a moderate effect on symptoms. Exercise has also been found to be effective for (unipolar) major depression. It is equivalent to the use of medications or psychological therapies in most people. In older people it does appear to decrease depression. Exercise may be recommended to people who are willing, motivated, and physically healthy enough to participate in an exercise program as treatment.\n\nThere is a small amount of evidence that skipping a night's sleep may improve depressive symptoms, with the effects usually showing up within a day. This effect is usually temporary. Besides sleepiness, this method can cause a side effect of mania or hypomania.\n\nIn observational studies, smoking cessation has benefits in depression as large as or larger than those of medications.\n\nBesides exercise, sleep and diet may play a role in depression, and interventions in these areas may be an effective add-on to conventional methods.\n\nPsychotherapy can be delivered to individuals, groups, or families by mental health professionals. A 2015 review found that cognitive behavioral therapy appears to be similar to antidepressant medication in terms of effect. A 2012 review found psychotherapy to be better than no treatment but not other treatments. With more complex and chronic forms of depression, a combination of medication and psychotherapy may be used. A 2014 Cochrane review found that work-directed interventions combined with clinical interventions helped to reduce sick days taken by people with depression. There is moderate-quality evidence that psychological therapies are a useful addition to standard antidepressant treatment of treatment-resistant depression in the short term.\n\nPsychotherapy has been shown to be effective in older people. Successful psychotherapy appears to reduce the recurrence of depression even after it has been terminated or replaced by occasional booster sessions.\n\nCognitive behavioral therapy (CBT) currently has the most research evidence for the treatment of depression in children and adolescents, and CBT and interpersonal psychotherapy (IPT) are preferred therapies for adolescent depression. In people under 18, according to the National Institute for Health and Clinical Excellence, medication should be offered only in conjunction with a psychological therapy, such as CBT, interpersonal therapy, or family therapy. Cognitive behavioral therapy has also been shown to reduce the number of sick days taken by people with depression, when used in conjunction with primary care.\n\nThe most-studied form of psychotherapy for depression is CBT, which teaches clients to challenge self-defeating, but enduring ways of thinking (cognitions) and change counter-productive behaviors. Research beginning in the mid-1990s suggested that CBT could perform as well as or better than antidepressants in patients with moderate to severe depression. CBT may be effective in depressed adolescents, although its effects on severe episodes are not definitively known. Several variables predict success for cognitive behavioral therapy in adolescents: higher levels of rational thoughts, less hopelessness, fewer negative thoughts, and fewer cognitive distortions. CBT is particularly beneficial in preventing relapse.\n\nCognitive behavioral therapy and occupational programs (including modification of work activities and assistance) have been shown to be effective in reducing sick days taken by workers with depression.\n\nSeveral variants of cognitive behavior therapy have been used in those with depression, the most notable being rational emotive behavior therapy, and mindfulness-based cognitive therapy. Mindfulness-based stress reduction programs may reduce depression symptoms. Mindfulness programs also appear to be a promising intervention in youth.\n\nPsychoanalysis is a school of thought, founded by Sigmund Freud, which emphasizes the resolution of unconscious mental conflicts. Psychoanalytic techniques are used by some practitioners to treat clients presenting with major depression. A more widely practiced therapy, called psychodynamic psychotherapy, is in the tradition of psychoanalysis but less intensive, meeting once or twice a week. It also tends to focus more on the person's immediate problems, and has an additional social and interpersonal focus. In a meta-analysis of three controlled trials of Short Psychodynamic Supportive Psychotherapy, this modification was found to be as effective as medication for mild to moderate depression.\n\nConflicting results have arisen from studies that look at the effectiveness of antidepressants in people with acute, mild to moderate depression. Stronger evidence supports the usefulness of antidepressants in the treatment of depression that is chronic (dysthymia) or severe.\n\nWhile small benefits were found, researchers Irving Kirsch and Thomas Moore state they may be due to issues with the trials rather than a true effect of the medication. In a later publication, Kirsch concluded that the overall effect of new-generation antidepressant medication is below recommended criteria for clinical significance. Similar results were obtained in a meta-analysis by Fornier.\n\nA review commissioned by the National Institute for Health and Care Excellence (UK) concluded that there is strong evidence that selective serotonin reuptake inhibitors (SSRIs), such as escitalopram, paroxetine, and sertraline, have greater efficacy than placebo on achieving a 50% reduction in depression scores in moderate and severe major depression, and that there is some evidence for a similar effect in mild depression. Similarly, a Cochrane systematic review of clinical trials of the generic tricyclic antidepressant amitriptyline concluded that there is strong evidence that its efficacy is superior to placebo.\n\nIn 2014 the U.S. Food and Drug Administration published a systematic review of all antidepressant maintenance trials submitted to the agency between 1985 and 2012. The authors concluded that maintenance treatment reduced the risk of relapse by 52% compared to placebo, and that this effect was primarily due to recurrent depression in the placebo group rather than a drug withdrawal effect.\n\nTo find the most effective antidepressant medication with minimal side-effects, the dosages can be adjusted, and if necessary, combinations of different classes of antidepressants can be tried. Response rates to the first antidepressant administered range from 50–75%, and it can take at least six to eight weeks from the start of medication to remission. Antidepressant medication treatment is usually continued for 16 to 20 weeks after remission, to minimize the chance of recurrence, and even up to one year of continuation is recommended. People with chronic depression may need to take medication indefinitely to avoid relapse.\n\nSSRIs are the primary medications prescribed, owing to their relatively mild side-effects, and because they are less toxic in overdose than other antidepressants. People who do not respond to one SSRI can be switched to another antidepressant, and this results in improvement in almost 50% of cases. Another option is to switch to the atypical antidepressant bupropion. Venlafaxine, an antidepressant with a different mechanism of action, may be modestly more effective than SSRIs. However, venlafaxine is not recommended in the UK as a first-line treatment because of evidence suggesting its risks may outweigh benefits, and it is specifically discouraged in children and adolescents.\nFor children, some research has supported the use of the SSRI antidepressant fluoxetine. The benefit however appears to be slight in children, while other antidepressants have not been shown to be effective. Medications are not recommended in children with mild disease. There is also insufficient evidence to determine effectiveness in those with depression complicated by dementia. Any antidepressant can cause low blood sodium levels; nevertheless, it has been reported more often with SSRIs. It is not uncommon for SSRIs to cause or worsen insomnia; the sedating atypical antidepressant mirtazapine can be used in such cases.\n\nIrreversible monoamine oxidase inhibitors, an older class of antidepressants, have been plagued by potentially life-threatening dietary and drug interactions. They are still used only rarely, although newer and better-tolerated agents of this class have been developed. The safety profile is different with reversible monoamine oxidase inhibitors, such as moclobemide, where the risk of serious dietary interactions is negligible and dietary restrictions are less strict.\nFor children, adolescents, and probably young adults between 18 and 24 years old, there is a higher risk of both suicidal ideations and suicidal behavior in those treated with SSRIs. For adults, it is unclear whether SSRIs affect the risk of suicidality. One review found no connection; another an increased risk; and a third no risk in those 25–65 years old and a decreased risk in those more than 65. A black box warning was introduced in the United States in 2007 on SSRIs and other antidepressant medications due to the increased risk of suicide in patients younger than 24 years old. Similar precautionary notice revisions were implemented by the Japanese Ministry of Health.\n\nThere is some evidence that omega-3 fatty acids fish oil supplements containing high levels of eicosapentaenoic acid (EPA) to docosahexaenoic acid (DHA) are effective in the treatment of, but not the prevention of major depression. However, a Cochrane review determined there was insufficient high quality evidence to suggest omega-3 fatty acids were effective in depression. There is limited evidence that vitamin D supplementation is of value in alleviating the symptoms of depression in individuals who are vitamin D-deficient. There is some preliminary evidence that COX-2 inhibitors, such as celecoxib, have a beneficial effect on major depression. Lithium appears effective at lowering the risk of suicide in those with bipolar disorder and unipolar depression to nearly the same levels as the general population. There is a narrow range of effective and safe dosages of lithium thus close monitoring may be needed. Low-dose thyroid hormone may be added to existing antidepressants to treat persistent depression symptoms in people who have tried multiple courses of medication. Limited evidence suggests stimulants, such as amphetamine and modafinil, may be effective in the short term, or as adjuvant therapy. Also, it is suggested that folate supplements may have a role in depression management.\n\nElectroconvulsive therapy (ECT) is a standard psychiatric treatment in which seizures are electrically induced in patients to provide relief from psychiatric illnesses. ECT is used with informed consent as a last line of intervention for major depressive disorder.\n\nA round of ECT is effective for about 50% of people with treatment-resistant major depressive disorder, whether it is unipolar or bipolar. Follow-up treatment is still poorly studied, but about half of people who respond relapse within twelve months.\n\nAside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia. Immediately following treatment, the most common adverse effects are confusion and memory loss. ECT is considered one of the least harmful treatment options available for severely depressed pregnant women.\n\nA usual course of ECT involves multiple administrations, typically given two or three times per week, until the patient is no longer suffering symptoms. ECT is administered under anesthesia with a muscle relaxant. Electroconvulsive therapy can differ in its application in three ways: electrode placement, frequency of treatments, and the electrical waveform of the stimulus. These three forms of application have significant differences in both adverse side effects and symptom remission. After treatment, drug therapy is usually continued, and some patients receive maintenance ECT.\n\nECT appears to work in the short term via an anticonvulsant effect mostly in the frontal lobes, and longer term via neurotrophic effects primarily in the medial temporal lobe.\n\nTranscranial magnetic stimulation (TMS) or deep transcranial magnetic stimulation is a noninvasive method used to stimulate small regions of the brain. TMS was approved by the FDA for treatment-resistant major depressive disorder (trMDD) in 2008 and as of 2014 evidence supports that it is probably effective. The American Psychiatric Association the Canadian Network for Mood and Anxiety Disorders, and the Royal Australia and New Zealand College of Psychiatrists have endorsed TMS for trMDD.\n\nBright light therapy reduces depression symptom severity, with benefit for both seasonal affective disorder and for nonseasonal depression, and an effect similar to those for conventional antidepressants. For nonseasonal depression, adding light therapy to the standard antidepressant treatment was not effective. For nonseasonal depression, where light was used mostly in combination with antidepressants or wake therapy, a moderate effect was found, with response better than control treatment in high-quality studies, in studies that applied morning light treatment, and with people who respond to total or partial sleep deprivation. Both analyses noted poor quality, short duration, and small size of most of the reviewed studies. There is insufficient evidence for Reiki and dance movement therapy in depression.\n\nMajor depressive episodes often resolve over time whether or not they are treated. Outpatients on a waiting list show a 10–15% reduction in symptoms within a few months, with approximately 20% no longer meeting the full criteria for a depressive disorder. The median duration of an episode has been estimated to be 23 weeks, with the highest rate of recovery in the first three months.\n\nStudies have shown that 80% of those suffering from their first major depressive episode will suffer from at least one more during their life, with a lifetime average of 4 episodes. Other general population studies indicate that around half those who have an episode recover (whether treated or not) and remain well, while the other half will have at least one more, and around 15% of those experience chronic recurrence. Studies recruiting from selective inpatient sources suggest lower recovery and higher chronicity, while studies of mostly outpatients show that nearly all recover, with a median episode duration of 11 months. Around 90% of those with severe or psychotic depression, most of whom also meet criteria for other mental disorders, experience recurrence.\n\nA high proportion of people who experience full symptomatic remission still have at least one not fully resolved symptom after treatment. Recurrence or chronicity is more likely if symptoms have not fully resolved with treatment. Current guidelines recommend continuing antidepressants for four to six months after remission to prevent relapse. Evidence from many randomized controlled trials indicate continuing antidepressant medications after recovery can reduce the chance of relapse by 70% (41% on placebo vs. 18% on antidepressant). The preventive effect probably lasts for at least the first 36 months of use.\n\nPeople experiencing repeated episodes of depression require ongoing treatment in order to prevent more severe, long-term depression. In some cases, people must take medications for the rest of their lives.\n\nCases when outcome is poor are associated with inappropriate treatment, severe initial symptoms including psychosis, early age of onset, previous episodes, incomplete recovery after one year of treatment, pre-existing severe mental or medical disorder, and family dysfunction.\n\nDepressed individuals have a shorter life expectancy than those without depression, in part because depressed patients are at risk of dying of suicide. However, they also have a higher rate of dying from other causes, being more susceptible to medical conditions such as heart disease. Up to 60% of people who die of suicide have a mood disorder such as major depression, and the risk is especially high if a person has a marked sense of hopelessness or has both depression and borderline personality disorder. The lifetime risk of suicide associated with a diagnosis of major depression in the US is estimated at 3.4%, which averages two highly disparate figures of almost 7% for men and 1% for women (although suicide attempts are more frequent in women). The estimate is substantially lower than a previously accepted figure of 15%, which had been derived from older studies of hospitalized patients.\n\nDepression is often associated with unemployment and poverty. Major depression is currently the leading cause of disease burden in North America and other high-income countries, and the fourth-leading cause worldwide. In the year 2030, it is predicted to be the second-leading cause of disease burden worldwide after HIV, according to the WHO. Delay or failure in seeking treatment after relapse and the failure of health professionals to provide treatment are two barriers to reducing disability.\n\nMajor depressive disorder affects approximately 216 million people in 2015 (3% of the global population). The percentage of people who are affected at one point in their life varies from 7% in Japan to 21% in France. In most countries the number of people who have depression during their lives falls within an 8–18% range. In North America, the probability of having a major depressive episode within a year-long period is 3–5% for males and 8–10% for females. Major depression is about twice as common in women as in men, although it is unclear why this is so, and whether factors unaccounted for are contributing to this. The relative increase in occurrence is related to pubertal development rather than chronological age, reaches adult ratios between the ages of 15 and 18, and appears associated with psychosocial more than hormonal factors. Depression is a major cause of disability worldwide.\n\nPeople are most likely to develop their first depressive episode between the ages of 30 and 40, and there is a second, smaller peak of incidence between ages 50 and 60. The risk of major depression is increased with neurological conditions such as stroke, Parkinson's disease, or multiple sclerosis, and during the first year after childbirth. It is also more common after cardiovascular illnesses, and is related more to those with a poor cardiac disease outcome than to a better one. Studies conflict on the prevalence of depression in the elderly, but most data suggest there is a reduction in this age group. Depressive disorders are more common in urban populations than in rural ones and the prevalence is increased in groups with poorer socioeconomic factors, e.g., homelessness.\n\nThe Ancient Greek physician Hippocrates described a syndrome of melancholia as a distinct disease with particular mental and physical symptoms; he characterized all \"fears and despondencies, if they last a long time\" as being symptomatic of the ailment. It was a similar but far broader concept than today's depression; prominence was given to a clustering of the symptoms of sadness, dejection, and despondency, and often fear, anger, delusions and obsessions were included.\n\nThe term \"depression\" itself was derived from the Latin verb \"deprimere\", \"to press down\". From the 14th century, \"to depress\" meant to subjugate or to bring down in spirits. It was used in 1665 in English author Richard Baker's \"Chronicle\" to refer to someone having \"a great depression of spirit\", and by English author Samuel Johnson in a similar sense in 1753. The term also came into use in physiology and economics. An early usage referring to a psychiatric symptom was by French psychiatrist Louis Delasiauve in 1856, and by the 1860s it was appearing in medical dictionaries to refer to a physiological and metaphorical lowering of emotional function. Since Aristotle, melancholia had been associated with men of learning and intellectual brilliance, a hazard of contemplation and creativity. The newer concept abandoned these associations and through the 19th century, became more associated with women.\nAlthough \"melancholia\" remained the dominant diagnostic term, \"depression\" gained increasing currency in medical treatises and was a synonym by the end of the century; German psychiatrist Emil Kraepelin may have been the first to use it as the overarching term, referring to different kinds of melancholia as \"depressive states\".\n\nSigmund Freud likened the state of melancholia to mourning in his 1917 paper \"Mourning and Melancholia\". He theorized that objective loss, such as the loss of a valued relationship through death or a romantic break-up, results in subjective loss as well; the depressed individual has identified with the object of affection through an unconscious, narcissistic process called the \"libidinal cathexis\" of the ego. Such loss results in severe melancholic symptoms more profound than mourning; not only is the outside world viewed negatively but the ego itself is compromised. The patient's decline of self-perception is revealed in his belief of his own blame, inferiority, and unworthiness. He also emphasized early life experiences as a predisposing factor. Adolf Meyer put forward a mixed social and biological framework emphasizing \"reactions\" in the context of an individual's life, and argued that the term \"depression\" should be used instead of \"melancholia\". The first version of the DSM (DSM-I, 1952) contained \"depressive reaction\" and the DSM-II (1968) \"depressive neurosis\", defined as an excessive reaction to internal conflict or an identifiable event, and also included a depressive type of manic-depressive psychosis within Major affective disorders.\n\nIn the mid-20th century, researchers theorized that depression was caused by a chemical imbalance in neurotransmitters in the brain, a theory based on observations made in the 1950s of the effects of reserpine and isoniazid in altering monoamine neurotransmitter levels and affecting depressive symptoms. The chemical imbalance theory has never been proven.\n\nThe term \"unipolar\" (along with the related term \"bipolar\") was coined by the neurologist and psychiatrist Karl Kleist, and subsequently used by his disciples Edda Neele and Karl Leonhard.\n\nThe term \"Major depressive disorder\" was introduced by a group of US clinicians in the mid-1970s as part of proposals for diagnostic criteria based on patterns of symptoms (called the \"Research Diagnostic Criteria\", building on earlier Feighner Criteria), and was incorporated into the DSM-III in 1980. To maintain consistency the ICD-10 used the same criteria, with only minor alterations, but using the DSM diagnostic threshold to mark a \"mild depressive episode\", adding higher threshold categories for moderate and severe episodes. The ancient idea of \"melancholia\" still survives in the notion of a melancholic subtype.\n\nThe new definitions of depression were widely accepted, albeit with some conflicting findings and views. There have been some continued empirically based arguments for a return to the diagnosis of melancholia. There has been some criticism of the expansion of coverage of the diagnosis, related to the development and promotion of antidepressants and the biological model since the late 1950s.\n\nThe term \"depression\" is used in a number of different ways. It is often used to mean this syndrome but may refer to other mood disorders or simply to a low mood. People's conceptualizations of depression vary widely, both within and among cultures. \"Because of the lack of scientific certainty,\" one commentator has observed, \"the debate over depression turns on questions of language. What we call it—'disease,' 'disorder,' 'state of mind'—affects how we view, diagnose, and treat it.\" There are cultural differences in the extent to which serious depression is considered an illness requiring personal professional treatment, or is an indicator of something else, such as the need to address social or moral problems, the result of biological imbalances, or a reflection of individual differences in the understanding of distress that may reinforce feelings of powerlessness, and emotional struggle.\n\nThe diagnosis is less common in some countries, such as China. It has been argued that the Chinese traditionally deny or somatize emotional depression (although since the early 1980s, the Chinese denial of depression may have modified). Alternatively, it may be that Western cultures reframe and elevate some expressions of human distress to disorder status. Australian professor Gordon Parker and others have argued that the Western concept of depression \"medicalizes\" sadness or misery. Similarly, Hungarian-American psychiatrist Thomas Szasz and others argue that depression is a metaphorical illness that is inappropriately regarded as an actual disease. There has also been concern that the DSM, as well as the field of descriptive psychiatry that employs it, tends to reify abstract phenomena such as depression, which may in fact be social constructs. American archetypal psychologist James Hillman writes that depression can be healthy for the soul, insofar as \"it brings refuge, limitation, focus, gravity, weight, and humble powerlessness.\" Hillman argues that therapeutic attempts to eliminate depression echo the Christian theme of resurrection, but have the unfortunate effect of demonizing a soulful state of being.\n\nHistorical figures were often reluctant to discuss or seek treatment for depression due to social stigma about the condition, or due to ignorance of diagnosis or treatments. Nevertheless, analysis or interpretation of letters, journals, artwork, writings, or statements of family and friends of some historical personalities has led to the presumption that they may have had some form of depression. People who may have had depression include English author Mary Shelley, American-British writer Henry James, and American president Abraham Lincoln. Some well-known contemporary people with possible depression include Canadian songwriter Leonard Cohen and American playwright and novelist Tennessee Williams. Some pioneering psychologists, such as Americans William James and John B. Watson, dealt with their own depression.\n\nThere has been a continuing discussion of whether neurological disorders and mood disorders may be linked to creativity, a discussion that goes back to Aristotelian times. British literature gives many examples of reflections on depression. English philosopher John Stuart Mill experienced a several-months-long period of what he called \"a dull state of nerves\", when one is \"unsusceptible to enjoyment or pleasurable excitement; one of those moods when what is pleasure at other times, becomes insipid or indifferent\". He quoted English poet Samuel Taylor Coleridge's \"Dejection\" as a perfect description of his case: \"A grief without a pang, void, dark and drear, / A drowsy, stifled, unimpassioned grief, / Which finds no natural outlet or relief / In word, or sigh, or tear.\" English writer Samuel Johnson used the term \"the black dog\" in the 1780s to describe his own depression, and it was subsequently popularized by depression sufferer former British Prime Minister Sir Winston Churchill.\n\nSocial stigma of major depression is widespread, and contact with mental health services reduces this only slightly. Public opinions on treatment differ markedly to those of health professionals; alternative treatments are held to be more helpful than pharmacological ones, which are viewed poorly. In the UK, the Royal College of Psychiatrists and the Royal College of General Practitioners conducted a joint Five-year Defeat Depression campaign to educate and reduce stigma from 1992 to 1996; a MORI study conducted afterwards showed a small positive change in public attitudes to depression and treatment.\n\nTrials are looking at the effects of botulinum toxins on depression. The idea is that the drug is used to make the person look less frowning and that this stops the negative facial feedback from the face. In 2015 results showed, however, that the partly positive effects that had been observed until then could have been due to placebo effects.\n\nMRI scans of patients with depression have revealed a number of differences in brain structure compared to those who are not depressed. Meta-analyses of neuroimaging studies in major depression reported that, compared to controls, depressed patients had increased volume of the lateral ventricles and adrenal gland and smaller volumes of the basal ganglia, thalamus, hippocampus, and frontal lobe (including the orbitofrontal cortex and gyrus rectus). Hyperintensities have been associated with patients with a late age of onset, and have led to the development of the theory of vascular depression.\n\nDepression is especially common among those over 65 years of age and increases in frequency beyond this age. In addition, the risk of depression increases in relation to the frailty of the individual. Depression is one the most important factors which negatively impact quality of life in adults, as well as the elderly. Both symptoms and treatment among the elderly differ from those of the rest of the population.\n\nAs with many other diseases, it is common among the elderly not to present with classical depressive symptoms. Diagnosis and treatment is further complicated in that the elderly are often simultaneously treated with a number of other drugs, and often have other concurrent diseases. Treatment differs in that studies of SSRIs have shown lesser and often inadequate effects among the elderly, while other drugs, such as duloxetine (an serotonin-norepinephrine reuptake inhibitor), with more clear effects have adverse effects, such as dizziness, dryness of the mouth, diarrhea and constipation, which can be especially difficult to handle among the elderly.\n\nProblem solving therapy was, as of 2015, the only psychological therapy with proven effect, and can be likened to a simpler form of cognitive behavioral therapy. However, elderly with depression are seldom offered any psychological treatment, and the evidence proving other treatments effective is incomplete. ECT has been used in the elderly, and register-studies suggest it is effective, although less so as compared to the rest of the population.\n\nThe risks involved with treatment of depression among the elderly as opposed to benefits are not entirely clear.\n\nModels of depression in animals for the purpose of study include iatrogenic depression models (such as drug-induced), forced swim tests, tail suspension test, and learned helplessness models. Criteria frequently used to assess depression in animals include expression of despair, neurovegetative changes, and anhedonia, as many other criteria for depression are untestable in animals, such as guilt and suicidality.\n\n"}
{"id": "8391", "url": "https://en.wikipedia.org/wiki?curid=8391", "title": "Diana (mythology)", "text": "Diana (mythology)\n\nDiana (Classical Latin: ) is a Roman goddess of the hunt, the moon, and nature, associated with wild animals and woodland. She is equated with the Greek goddess Artemis, and absorbed much of Artemis' mythology early in Roman history, including a birth on the island of Delos to parents Jupiter and Latona, and a twin brother, Apollo, though she had an independent origin in Italy.\n\nDiana was known as the virgin goddess of childbirth and women. She was one of the three maiden goddesses, along with Minerva and Vesta, who swore never to marry. Oak groves and deer were especially sacred to her. Diana made up a triad with two other Roman deities; Egeria the water nymph, her servant and assistant midwife; and Virbius, the woodland god.\n\nDiana is revered in modern Neopagan religions including Roman Neopaganism, Stregheria, and Wicca. From the medieval to the modern period, as folklore attached to her developed and was eventually adapted into neopagan religions, the mythology surrounding Diana grew to include a consort (Lucifer) and daughter (Aradia), figures sometimes recognized by modern traditions. In the ancient, medieval, and modern periods, Diana has been considered a triple deity, merged with a goddess of the moon (Luna/Selene) and the underworld (usually Hecate).\n\nDīāna is an adjectival form developed from an ancient *\"divios\", corresponding to later \"dīvus\", \"dius\", as in Dius Fidius, Dea Dia, and in the neuter form \"dium\" 'sky'.\nIt is derived from Proto-Indo-European \"*dyew-\" '(bright) sky'; the same word is also the root behind the name of the Vedic sky god Dyaus, as well as the Latin words \"deus\" 'god', \"diēs\" 'day, daylight', and \"diurnus\" 'daily'.\n\nOn the tablets of Pylos a theonym \"di-wi-ja\" is supposed as referring to a deity precursor of Artemis. Modern scholars mostly accept the identification.\n\nThe ancient Latin writers Varro and Cicero considered the etymology of Dīāna as allied to that of \"dies\" and connected to the shine of the Moon.\n\n... people regard Diana and the moon as one and the same. ... the moon \"(luna)\" is so called from the verb to shine \"(lucere)\". Lucina is identified with it, which is why in our country they invoke Juno Lucina in childbirth, just as the Greeks call on Diana the Light-bearer. Diana also has the name \"Omnivaga\" (\"wandering everywhere\"), not because of her hunting but because she is numbered as one of the seven planets; her name Diana derives from the fact that she turns darkness into daylight \"(dies)\". She is invoked at childbirth because children are born occasionally after seven, or usually after nine, lunar revolutions ...\n\nThe persona of Diana is complex, and contains a number of archaic features. Diana was originally considered to be a goddess of the wilderness and of the hunt, a central sport in both Roman and Greek culture. Early Roman inscriptions to Diana celebrated her primarily as a huntress and patron of hunters. Later, in the Hellenistic period, Diana came to be equally or more revered as a goddess not of the wild woodland but of the \"tame\" countryside, or \"villa rustica\", the idealization of which was common in Greek thought and poetry. This dual role as goddess of both civilization and the wild, and therefore the civilized countryside, first applied to the Greek goddess Artemis (for example, in the 3rd century BCE poetry of Anacreon). By the 3rd century CE, after Greek influence had a profound impact on Roman religion, Diana had been almost fully combined with Artemis and took on many of her attributes, both in her spiritual domains and in the description of her appearance. The Roman poet Nemesianus wrote a typical description of Diana: She carried a bow and a quiver full of golden arrows, wore a golden cloak, purple half-boots, and a belt with a jeweled buckle to hold her tunic together, and wore her hair gathered in a ribbon.\n\nDiana was often considered an aspect of a triple goddess, known as \"Diana triformis\": Diana, Luna, and Hecate. According to historian C.M. Green, \"these were neither different goddesses nor an amalgamation of different goddesses. They were Diana...Diana as huntress, Diana as the moon, Diana of the underworld.\" At her sacred grove on the shores of Lake Nemi, Diana was venerated as a triple goddess beginning in the late 6th century BCE.\n\nAndreas Alföldi interpreted an image on a late Republican coin as the Latin Diana \"conceived as a threefold unity of the divine huntress, the Moon goddess and the goddess of the nether world, Hekate\". This coin, minted by P. Accoleius Lariscolus in 43 BCE, has been acknowledged as representing an archaic statue of Diana Nemorensis. It represents Artemis with the bow at one extremity, Luna-Selene with flowers at the other and a central deity not immediately identifiable, all united by a horizontal bar. The iconographical analysis allows the dating of this image to the 6th century at which time there are Etruscan models. The coin shows that the triple goddess cult image still stood in the \"lucus\" of Nemi in 43 BCE. Lake Nemi was called \"Triviae lacus\" by Virgil (\"Aeneid\" 7.516), while Horace called Diana \"montium custos nemoremque virgo\" (\"keeper of the mountains and virgin of Nemi\") and \"diva triformis\" (\"three-form goddess\").\n\nTwo heads found in the sanctuary and the Roman theatre at Nemi, which have a hollow on their back, lend support to this interpretation of an archaic triple Diana. \n\nThe earliest epithet of Diana was \"Trivia\", and she was addressed with that title by Virgil, Catullus, and many others. \"Trivia\" comes from the Latin \"trivium\", \"triple way\", and refers to Diana's guardianship over roadways, particularly Y-junctions or three-way crossroads. This role carried a somewhat dark and dangerous connotation, as it metaphorically pointed the way to the underworld. In the 1st-century CE play \"Medea\", Seneca's title character calls on Trivia to cast a spell, evokes the triple goddess of Diana, Selene, and Hecate, and specifies that she requires the powers of the latter. The symbol of the crossroads is relevant to several aspects of Diana's domain. It can symbolize the paths hunters may encounter in the forest, lit only by the full moon; this symbolizes making choices \"in the dark\" without the light of guidance.\n\nDiana's role as a goddess of the underworld, or at least of ushering people between life and death, caused her early on to be conflated with Hecate (and occasionally also with Proserpina). However, her role as an underworld goddess appears to pre-date strong Greek influence (though the early Greek colony of Cumae had a cult of Hekate and certainly had contacts with the Latins). A theater in her sanctuary at Lake Nemi included a pit and tunnel that would have allowed actors to easily descend on one side of the stage and ascend on the other, indicating a connection between the phases of the moon and a descent by the moon goddess into the underworld. It is likely that her underworld aspect in her original Latin worship did not have a distinct name, like Luna was for her moon aspect. This is due to a seeming reluctance or taboo by the early Latins to name underworld deities, and the fact that they believed the underworld to be silent, precluding naming. Hekate, a Greek goddess also associated with the boundary between the earth and the underworld, became attached to Diana as a name for her underworld aspect following Greek influence.\n\nDiana was often considered to be a goddess associated with fertility and childbirth, and the protection of women during labor. This probably arose as an extension of her association with the moon, whose cycles were believed to parallel the menstrual cycle, and which was used to track the months during pregnancy. At her shrine in Aricia, worshipers left votive terracotta offerings for the goddess in the shapes of babies and wombs, and the temple there also offered care of pups and pregnant dogs. This care of infants also extended to the training of both young people and dogs, especially for hunting. In her role as a protector of childbirth, Diana was called \"Diana Lucina\" or even \"Juno Lucina\", because her domain overlapped with that of the goddess Juno. The title of Juno may also have had an independent origin as it applied to Diana, with the literal meaning of \"helper\" - Diana as \"Juno Lucina\" would be the \"helper of childbirth\".\n\nAccording to a theory proposed by Georges Dumézil, Diana falls into a particular subset of celestial gods, referred to in histories of religion as \"frame gods\". Such gods, while keeping the original features of celestial divinities (i.e. transcendent heavenly power and abstention from direct rule in worldly matters), did not share the fate of other celestial gods in Indoeuropean religions - that of becoming \"dei otiosi\", or gods without practical purpose, since they did retain a particular sort of influence over the world and mankind. The celestial character of Diana is reflected in her connection with inaccessibility, virginity, light, and her preference for dwelling on high mountains and in sacred woods. Diana, therefore, reflects the heavenly world in its sovereignty, supremacy, impassibility, and indifference towards such secular matters as the fates of mortals and states. At the same time, however, she is seen as active in ensuring the succession of kings and in the preservation of humankind through the protection of childbirth. These functions are apparent in the traditional institutions and cults related to the goddess:\n\nAccording to Dumezil, the forerunner of all \"frame gods\" is an Indian epic hero who was the image (avatar) of the Vedic god Dyaus. Having renounced the world, in his roles of father and king, he attained the status of an immortal being while retaining the duty of ensuring that his dynasty is preserved and that there is always a new king for each generation. The Scandinavian god Heimdallr performs an analogous function: he is born first and will die last. He too gives origin to kingship and the first king, bestowing on him regal prerogatives.\nDiana, although a female deity, has exactly the same functions, preserving mankind through childbirth and royal succession.\n\nF. H. Pairault, in her essay on Diana, qualified Dumézil's theory as \"\"impossible to verify\"\".\n\nUnlike the Greek gods, Roman gods were originally considered to be numina: divine powers of presence and will that did not necessarily have physical form. At the time Rome was founded, Diana and the other major Roman gods probably did not have much mythology per se, or any depictions in human form. The idea of gods as having anthropomorphic qualities and human-like personalities and actions developed later, under the influence of Greek and Etruscan religion.\n\nBy the 3rd century BCE, Diana is found listed among the twelve major gods of the Roman pantheon by the poet Ennius. Though the Capitoline Triad were the primary state gods of Rome, early Roman myth did not assign a strict hierarchy to the gods the way Greek mythology did, though the Greek hierarchy would eventually be adopted by Roman religion as well.\n\nOnce Greek influence had caused Diana to be considered identical to the Greek goddess Artemis, Diana acquired Artemis' physical description, attributes, and variants of her myths as well. Like Artemis, Diana is usually depicted in art wearing a short skirt, with a hunting bow and quiver, and often accompanied by hunting dogs. A 1st-century BCE Roman coin (see above) depicted her with a unique, short hairstyle, and in triple form, with one form holding a bow and another holding a poppy.\n\nWhen worship of Apollo was first introduced to Rome, Diana became conflated with Apollo's sister Artemis as in the earlier Greek myths, and as such she became identified as the daughter of Apollo's parents Latona and Jupiter. Though Diana was usually considered to be a virgin goddess like Artemis, later authors sometimes attributed consorts and children to her. According to Cicero and Ennius, Trivia (an epithet of Diana) and Caelus were the parents of Janus, as well as of Saturn and Ops.\n\nAccording to Macrobius (who cited Nigidius Figulus and Cicero), Janus and Jana (Diana) are a pair of divinities, worshiped as the sun and moon. Janus was said to receive sacrifices before all the others because, through him, the way of access to the desired deity is made apparent.\n\nDiana's mythology incorporated stories which were variants of earlier stories about Artemis. Possibly the most well-known of these is the myth of Actaeon. In Ovid's version of this myth, part of his poem \"Metamorphoses\", he tells of a pool or grotto hidden in the wooded valley of Gargaphie. There, Diana, the goddess of the woods, would bathe and rest after a hunt. Actaeon, a young hunter, stumbled across the grotto and accidentally witnessed the goddess bathing without invitation. In retaliation, Diana splashed him with water from the pool, cursing him, and he transformed into a deer. His own hunting dogs caught his scent, and tore him apart.\n\nOvid's version of the myth of Actaeon differs from most earlier sources. Unlike earlier myths about Artemis, Actaeon is killed for an innocent mistake, glimpsing Diana bathing. An earlier variant of this myth, known as the Bath of Pallas, had the hunter intentionally spy on the bathing goddess Pallas (Athena), and earlier versions of the myth involving Artemis did not involve the bath at all.\n\nDiana was an ancient goddess common to all Latin tribes. Therefore, many sanctuaries were dedicated to her in the lands inhabited by Latins. Her primary sanctuary was a woodland grove overlooking Lake Nemi, a body of water also known as \"Diana's Mirror\", where she was worshiped as Diana Nemorensis, or \"Diana of the Wood\". In Rome, the cult of Diana may have been almost as old as the city itself. Varro mentions her in the list of deities to whom king Titus Tatius promised to build a shrine. His list included Luna and Diana Lucina as separate entities. Another testimony to the antiquity of her cult is to be found in the \"lex regia\" of King Tullus Hostilius that condemns those guilty of incest to the \"sacratio\" to Diana. She had a temple in Rome on the Aventine Hill, according to tradition dedicated by king Servius Tullius. Its location is remarkable as the Aventine is situated outside the pomerium, i.e. original territory of the city, in order to comply with the tradition that Diana was a goddess common to all Latins and not exclusively of the Romans. Being placed on the Aventine, and thus outside the \"pomerium\", meant that Diana's cult essentially remained a \"foreign\" one, like that of Bacchus; she was never officially \"transferred\" to Rome as Juno was after the sack of Veii.\n\nOther known sanctuaries and temples to Diana include Colle di Corne near Tusculum, where she is referred to with the archaic Latin name of \"deva Cornisca\" and where existed a collegium of worshippers; at Évora, Portugal; Mount Algidus, also near Tusculum; at Lavinium; and at Tibur (Tivoli), where she is referred to as \"Diana Opifera Nemorensis\". Diana was also worshiped at a sacred wood mentioned by Livy - \"ad compitum Anagninum\" (near Anagni), and on Mount Tifata in Campania.\n\nDiana's worship may have originated at an open-air sanctuary overlooking Lake Nemi in the Alban Hills near Aricia, where she was worshiped as Diana Nemorensis, or (\"Diana of the Sylvan Glade\"). According to legendary accounts, the sanctuary was founded by Orestes and Iphigenia after they fled from the Tauri. In this tradition, the Nemi sanctuary was supposedly built on the pattern of an earlier Temple of Artemis Tauropolos, and the first cult statue at Nemi was said to have been stolen from the Tauri and brought to Nemi by Orestes. Historical evidence suggests that worship of Diana at Nemi flourished from at least the 6th century BCE until the 2nd century CE. Her cult there was first attested in Latin literature by Cato the Elder, in a surviving quote by the late grammarian Priscian. By the 4th century BCE, the simple shrine at Nemi had been joined by a temple complex. The sanctuary served an important political role as it was held in common by the Latin League.\n\nLegend has it that Diana's high priest at Nemi, known as the Rex Nemorensis, was always an escaped slave who could only obtain the position by defeating his predecessor in a fight to the death. Sir James George Frazer wrote of this sacred grove in \"The Golden Bough\", basing his interpretation on brief remarks in Strabo (5.3.12), Pausanias (2,27.24) and Servius' commentary on the \"Aeneid\" (6.136). Legend tells of a tree that stood in the center of the grove and was heavily guarded. No one was allowed to break off its limbs, with the exception of a runaway slave, who was allowed, if he could, to break off one of the boughs. He was then in turn granted the privilege to engage the Rex Nemorensis, the current king and priest of Diana, in a fight to the death. If the slave prevailed, he became the next king for as long as he could defeat his challengers. However, Joseph Fontenrose criticised Frazer's assumption that a rite of this sort actually occurred at the sanctuary. \n\nA festival to Diana, the Nemoralia, was held yearly at Nemi on the Ides of August (August 13-15). Worshipers traveled to Nemi carrying torches and garlands, and once at the lake, they left pieces of thread tied to fences and tablets inscribed with prayers. Diana's festival eventually became widely celebrated throughout Italy, which was unusual given the provincial nature of Diana's cult. The poet Statius wrote of the festival:\n\nStatius describes the triple nature of the goddess by invoking heavenly (the stars), earthly (the grove itself) and underworld (Hecate) imagery. He also suggests by the garlanding of the dogs and polishing of the spears that no hunting was allowed during the festival.\n\nRome hoped to unify into and control the Latin tribes around Nemi, so Diana's worship was imported to Rome as a show of political solidarity. Diana soon afterwards became Hellenized, and combined with the Greek goddess Artemis, \"a process which culminated with the appearance of Diana beside Apollo [the brother of Artemis] in the first \"lectisternium\" at Rome\" in 399 BCE. The process of identification between the two goddesses probably began when artists who were commissioned to create new cult statues for Diana's temples outside Nemi were struck by the similar attributes between Diana and the more familiar Artemis, and sculpted Diana in a manner inspired by previous depictions of Artemis. Sibyllene influence and trade with Massilia, where similar cult statues of Artemis existed, would have completed the process.\n\nAccording to Françoise Hélène Pairault's study, historical and archaeological evidence point to the fact that the characteristics given to both Diana of the Aventine Hill and Diana Nemorensis were the product of the direct or indirect influence of the cult of Artemis, which was spread by the Phoceans among the Greek towns of Campania Cuma and Capua, who in turn had passed it over to the Etruscans and the Latins by the 6th and 5th centuries BCE.\n\nEvidence suggests that a confrontation occurred between two groups of Etruscans who fought for supremacy, those from Tarquinia, Vulci and Caere (allied with the Greeks of Capua) and those of Clusium. This is reflected in the legend of the coming of Orestes to Nemi and of the inhumation of his bones in the Roman Forum near the temple of Saturn. The cult introduced by Orestes at Nemi is apparently that of the Artemis Tauropolos. The literary amplification reveals a confused religious background: different versions of Artemis were conflated under the epithet. As far as Nemi's Diana is concerned there are two different versions, by Strabo and Servius Honoratus. Strabo's version looks to be the most authoritative as he had access to first-hand primary sources on the sanctuaries of Artemis, i.e. the priest of Artemis Artemidoros of Ephesus. The meaning of \"Tauropolos\" denotes an Asiatic goddess with lunar attributes, lady of the herds. The only possible \"interpretatio graeca\" of high antiquity concerning \"Diana Nemorensis\" could have been the one based on this ancient aspect of a deity of light, master of wildlife. \"Tauropolos\" is an ancient epithet attached to Artemis, Hecate, and even Athena. According to the legend Orestes founded Nemi together with Iphigenia. At Cuma the Sybil is the priestess of both Phoibos and Trivia. Hesiod and Stesichorus tell the story according to which after her death Iphigenia was divinised under the name of Hecate, a fact which would support the assumption that Artemis Tauropolos had a real ancient alliance with the heroine, who was her priestess in Taurid and her human paragon. This religious complex is in turn supported by the triple statue of Artemis-Hecate.\n\nIn Rome, Diana was regarded with great reverence and was a patroness of lower-class citizens, called plebeians, as well as slaves, who could receive asylum in her temples. Georg Wissowa proposed that this might be because the first slaves of the Romans were Latins of the neighboring tribes. However, the Temple of Artemis at Ephesus had the same custom of the asylum.\n\nWorship of Diana probably spread into the city of Rome beginning around 550 BCE, during her Hellenization and combination with the Greek goddess Artemis. Diana was first worshiped along with her brother and mother, Apollo and Latona, in their temple in the Campus Martius, and later in the Temple of Apollo Palatinus.\n\nThe first major temple dedicated primarily to Diana in the vicinity of Rome was the Temple of Diana Aventina (Diana of the Aventine Hill). According to the Roman historian Livy, the construction of this temple began in the 6th century BCE and was inspired by stories of the massive Temple of Artemis at Ephesus, which was said to have been built through the combined efforts of all the cities of Asia Minor. Legend has it that Servius Tullius was impressed with this act of massive political and economic cooperation, and convinced the cities of the Latin League to work with the Romans to build their own temple to the goddess. However, there is no compelling evidence for such an early construction of the temple, and it is more likely that it was built in the 3rd century BCE, following the influence of the temple at Nemi, and probably about the same time the first temples to Vertumnus (who was associated with Diana) were built in Rome (264 BCE). The misconception that the Aventine Temple was inspired by the Ephesian Temple might originate in the fact that the cult images and statues used at the former were based heavily on those found in the latter. Whatever its initial construction date, records show that the Avantine Temple was rebuilt by Lucius Cornificius in 32 BCE. If it was still in use by the 4th century CE, the Aventine temple would have been permanently closed during the persecution of pagans in the late Roman Empire. Today, a short street named the \"Via del Tempio di Diana\" and an associated plaza, \"Piazza del Tempio di Diana\", commemorates the site of the temple. Part of its wall is located within one of the halls of the Apuleius restaurant.\n\nLater temple dedications often were based on the model for ritual formulas and regulations of the Temple of Diana. Roman politicians built several minor temples to Diana elsewhere in Rome to secure public support. One of these was built in the Campus Martius in 187 BCE; no Imperial period records of this temple have been found, and it is possible it was one of the temples demolished around 55 BCE in order to build a theater. Diana also had a public temple on the Quirinal Hill, the sanctuary of Diana Planciana. It was dedicated by Plancius in 55 BCE, though it is unclear which Plancius.\n\nIn their worship of Artemis, Greeks filled their temples with sculptures of the goddess created by well-known sculptors, and many were adapted for use in the worship of Diana by the Romans, beginning around the 2nd century BCE (the beginning of a period of strong Hellenistic influence on Roman religion). The earliest depictions of the Artemis of Ephesus are found on Ephesian coins from this period. By the Imperial period, small marble statues of the Ephesian Artemis were being produced in the Western region of the Mediterranean and were often bought by Roman patrons. The Romans obtained a large copy of an Ephesian Artemis statue for their temple on the Aventine Hill. Diana was usually depicted for educated Romans in her Greek guise. If she was shown accompanied by a deer, as in the \"Diana of Versailles\", this is because Diana was the patroness of hunting. The deer may also offer a covert reference to the myth of Acteon (or Actaeon), who saw her bathing naked. Diana transformed Acteon into a stag and set his own hunting dogs to kill him.\n\nIn Campania, Diana had a major temple at Mount Tifata, near Capua. She was worshiped there as \"Diana Tifatina\". This was one of the oldest sanctuaries in Campania. As a rural sanctuary, it included lands and estates that would have been worked by slaves following the Roman conquest of Campania, and records show that expansion and renovation projects at her temple were funded in part by other conquests by Roman military campaigns. The modern Christian church of Sant'Angelo in Formis was built on the ruins of the Tifata temple.\n\nIn the Roman provinces, Diana was widely worshiped alongside local deities. Over 100 inscriptions to Diana have been cataloged in the provinces, mainly from Gaul, Upper Germania, and Britannia. Diana was commonly invoked alongside another forest god, Silvanus, as well as other \"mountain gods\". In the provinces, she was occasionally conflated with local goddesses such as Abnoba, and was given high status, with \"Augusta\" and \"regina\" (\"queen\") being common epithets.\n\nDiana was not only regarded as a goddess of the wilderness and the hunt, but was often worshiped as a patroness of families. She served a similar function to the hearth goddess Vesta, and was sometimes considered to be a member of the Penates, the deities most often invoked in household rituals. In this role, she was often given a name reflecting the tribe of family who worshiped her and asked for her protection. For example, in what is now Wiesbaden, Diana was worshiped as \"Diana Mattiaca\" by the Mattiaci tribe. Other family-derived named attested in the ancient literature include \"Diana Cariciana\", \"Diana Valeriana\", and \"Diana Plancia\". As a house goddess, Diana often became reduced in stature compared to her official worship by the Roman state religion. In personal or family worship, Diana was brought to the level of other household spirits, and was believed to have a vested interest in the prosperity of the household and the continuation of the family. The Roman poet Horace regarded Diana as a household goddess in his \"Odes\", and had an altar dedicated to her in his villa where household worship could be conducted. In his poetry, Horace deliberately contrasted the kinds of grand, elevated hymns to Diana on behalf of the entire Roman state, the kind of worship that would have been typical at her Aventine temple, with a more personal form of devotion.\n\nImages of Diana and her associated myths have been found on sarcophagi of wealthy Romans. They often included scenes depicting sacrifices to the goddess, and on at least one example, the deceased man is shown joining Diana's hunt.\n\nDiana was initially a hunting goddess and goddess of the local woodland at Nemi, but as her worship spread, she acquired attributes of other similar goddesses. As she became conflated with Artemis, she became a moon goddess, supplanting the earlier Titan goddess Luna. She also became the goddess of childbirth and ruled over the countryside. Catullus wrote a poem to Diana in which she has more than one alias: Latonia, Lucina, Juno, Trivia, Luna.\n\nAlong with Mars, Diana was often venerated at games held in Roman amphitheaters, and some inscriptions from the Danubian provinces show that she was conflated with Nemesis in this role, as \"Diana Nemesis\".\n\nOutside of Italy, Diana had important centers of worship where she was syncretised with similar local deities in Gaul, Upper Germania, and Britannia. Diana was particularly important in the region in and around the Black Forest, where she was conflated with the local goddess Abnoba and worshiped as \"Diana Abnoba\".\n\nSome late antique sources went even further, syncretizing many local \"great goddesses\" into a single \"Queen of Heaven\". The Platonist philosopher Apuleius, writing in the late 2nd century, depicted the goddess declaring:\n\"I come, Lucius, moved by your entreaties: I, mother of the universe, mistress of all the elements, first-born of the ages, highest of the gods, queen of the shades, first of those who dwell in heaven, representing in one shape all gods and goddesses. My will controls the shining heights of heaven, the health-giving sea-winds, and the mournful silences of hell; the entire world worships my single godhead in a thousand shapes, with divers rites, and under many a different name. The Phrygians, first-born of mankind, call me the Pessinuntian Mother of the gods; the native Athenians the Cecropian Minerva; the island-dwelling Cypriots Paphian Venus; the archer Cretans Dictynnan Diana; the triple-tongued Sicilians Stygian Proserpine; the ancient Eleusinians Actaean Ceres; some call me Juno, some Bellona, others Hecate, others Rhamnusia; but both races of Ethiopians, those on whom the rising and those on whom the setting sun shines, and the Egyptians who excel in ancient learning, honour me with the worship which is truly mine and call me by my true name: Queen Isis.\"\n\nLater poets and historians looked to Diana's identity as a triple goddess to merge her with triads heavenly, earthly, and underworld (cthonic) goddesses. Maurus Servius Honoratus said that the same goddess was called Luna in heaven, Diana on earth, and Proserpina in hell.\nMichael Drayton praises the Triple Diana in poem \"The Man in the Moone\" (1606): \"So these great three most powerful of the rest, Phoebe, Diana, Hecate, do tell. Her sovereignty in Heaven, in Earth and Hell\".\n\nReverence for Diana and other Roman gods appears to have persisted into the Early Middle Ages in areas of Europe. Evidence for such surviving practices in the Low Countries region comes from the \"Vita Eligii\", or \"Life of Saint Eligius\", written by Saint Ouen in the 7th century. Ouen drew together the familiar admonitions of Eligius to the people of Flanders. In his sermons, he denounced \"pagan customs\" that the people continued to follow. In particular, he denounced several Roman gods and goddesses alongside Druidic mythological beliefs and objects:\n\n\"I denounce and contest, that you shall observe no sacrilegious pagan customs. For no cause or infirmity should you consult magicians, diviners, sorcerers or incantators. ..Do not observe auguries ... No influence attaches to the first work of the day or the [phase of the] moon. ... [Do not] make vetulas, little deer or iotticos or set tables at night or exchange New Year gifts or supply superfluous drinks... No Christian... performs solestitia or dancing or leaping or diabolical chants. No Christian should presume to invoke the name of a demon, not Neptune or Orcus or Diana or Minerva or Geniscus... No one should observe Jove's day in idleness. ... No Christian should make or render any devotion to the gods of the trivium, where three roads meet, to the fanes or the rocks, or springs or groves or corners. None should presume to hang any phylacteries from the neck of man nor beast. ..None should presume to make lustrations or incantations with herbs, or to pass cattle through a hollow tree or ditch ... No woman should presume to hang amber from her neck or call upon Minerva or other ill-starred beings in their weaving or dyeing. .. None should call the sun or moon lord or swear by them. .. No one should tell fate or fortune or horoscopes by them as those do who believe that a person must be what he was born to be.\"\n\nDiana is the only pagan goddess mentioned by name in the New Testament (Acts 19). As a result, she became associated with many folk beliefs involving goddess-like supernatural figures that Catholic clergy wished to demonize. In the Middle Ages, legends of night-time processions of spirits led by a female figure are recorded in the church records of Northern Italy, western Germany, and southern France. The spirits were said to enter houses and consume food which then miraculously re-appeared. They would sing and dance, and dispense advise regarding healing herbs and the whereabouts of lost objects. If the house was in good order, they would bring fertility and plenty. If not, they would bring curses to the family. Some women reported participating in these processions while their bodies still lay in bed. Historian Carlo Ginzburg has referred to these legendary spirit gatherings as \"The Society of Diana\".\n\nLocal clergy complained that women believed they were following Diana or Herodias, riding out on appointed nights to join the processions or carry out instructions from the goddess. The earliest reports of these legends appear in the writings of Regino of Prüm in the year 899, followed by many additional reports and variants of the legend in documents by Ratherius and others. By 1310, the names of the goddess figures attached to the legend were sometimes combined as Herodiana. It is likely that the clergy of this time used the identification of the procession's leader as Diana or Herodias in order to fit an older folk belief into a Biblical framework, as both are featured and demonized in the New Testament. Herodias was often conflated with her daughter Salame in legend, which also holds that, upon being presented with the severed head of John the Baptist, she was blown into the air by wind from the saint's mouth, through which she continued to wander for eternity. Diana was often conflated with Hecate, a goddess associated with the spirits of the dead and with witchcraft. These associations, and the fact that both figures are attested to in the Bible, made them a natural fit for the leader of the ghostly procession. Clergy used this identification to assert that the spirits were evil, and that the women who followed them were inspired by demons. As was typical of this time period, though pagan beliefs and practices were near totally eliminated from Europe, the clergy and other authorities still treated paganism as a real threat, in part thanks to biblical influence; much of the Bible had been written when various forms of paganism were still active if not dominant, so medieval clergy applied the same kinds of warnings and admonitions for any non-standard folk beliefs and practices they encountered. Based on analysis of church documents and parishioner confessions, it is likely that the spirit identified by the Church as Diana or Herodias was called by names of pre-Christian figures like Holda (a Germanic goddess of the winter solstice), or with names referencing her bringing of prosperity, like the Latin Abundia (meaning \"plenty\"), Satia (meaning \"full\" or \"plentiful\") and the Italian Richella (meaning \"rich\"). Some of the local titles for her, such as \"bonae res\" (meaning \"good things\"), are similar to late classical titles for Hecate, like \"bona dea\". This might indicate a cultural mixture of medieval folk ideas with holdovers from earlier pagan belief systems. Whatever her true origin, by the 13th century, the leader of the legendary spirit procession had come to be firmly identified with Diana and Herodias through the influence of the Church.\n\nIn his wide-ranging, comparative study of mythology and religion, \"The Golden Bough\", anthropologist James George Frazer drew on various lines of evidence to re-interpret the legendary rituals associated with Diana at Nemi, particularly that of the \"rex Nemorensis\". Frazer developed his ideas in relation to J. M. W. Turner's painting, also titled \"The Golden Bough\", depicting a dream-like vision of the woodland lake of Nemi. According to Frazer, the \"rex Nemorensis\" or king at Nemi was the incarnation of a dying and reviving god, a solar deity who participated in a mystical marriage to a goddess. He died at the harvest and was reincarnated in the spring. Frazer claimed that this motif of death and rebirth is central to nearly all of the world's religions and mythologies. In Frazer's theory, Diana functioned as a goddess of fertility and childbirth, who, assisted by the sacred king, ritually returned life to the land in spring. The king in this scheme served not only as a high priest but as a god of the grove. Frazer identifies this figure with Virbius, of which little is known, but also with Jupiter via an association with sacred oak trees. Frazer argued furthemore that Jupiter and Juno were simply duplicate names of Jana and Janus; that is, Diana and Dianus, all of whom had identical functions and origins.\n\nFrazer's speculatively reconstructed folklore of Diana's origins and the nature of her cult at Nemi were not well received even by his contemporaries. Godfrey Lienhardt noted that even during Frazer's lifetime, other anthropologists had \"for the most part distanced themselves from his theories and opinions\", and that the lasting influence of \"The Golden Bough\" and Frazer's wider body of work \"has been in the literary rather than the academic world.\" Robert Ackerman wrote that, for anthropologists, Frazer is \"an embarrassment\" for being \"the most famous of them all\" and that most distance themselves from his work. While \"The Golden Bough\" achieved wide \"popular appeal\" and exerted a \"disproportionate\" influence \"on so many [20th century] creative writers\", Frazer's ideas played \"a much smaller part\" in the history of academic social anthropology.\n\nFolk legends like the one above, linking Diana to forbidden gatherings of women with spirits, may have influenced later works of folklore like Charles Godfrey Leland's \"Aradia, or the Gospel of the Witches\", which prominently featured Diana at the center of an Italian witch-cult. In Leland's interpretation of supposed Italian folk witchcraft, Diana is considered Queen of the Witches. In this belief system, Diana is said to have created the world of her own being having in herself the seeds of all creation yet to come. It was said that out of herself she divided the darkness and the light, keeping for herself the darkness of creation and creating her brother Lucifer. Diana was believed to have loved and ruled with her brother, and with him bore a daughter, Aradia (a name likely derived from Herodias), who leads and teaches the witches on earth.\n\nLeland's claim that \"Aradia\" represented an authentic tradition from an underground witch-cult, which had secretly worshiped Diana since ancient times has been dismissed by most scholars of folklore, religion, and medieval history. After the 1921 publication of Margaret Murray's \"The Witch-cult in Western Europe\", which hypothesized that the European witch trials were actually a persecution of a pagan religious survival, American sensationalist author Theda Kenyon's 1929 book \"Witches Still Live\" connected Murray's thesis with the witchcraft religion in \"Aradia\". Arguments against Murray's thesis would eventually include arguments against Leland. Witchcraft scholar Jeffrey Russell devoted some of his 1980 book \"A History of Witchcraft: Sorcerers, Heretics and Pagans\" to arguing against the claims Leland presented in \"Aradia\". Historian Elliot Rose's \"A Razor for a Goat\" dismissed \"Aradia\" as a collection of incantations unsuccessfully attempting to portray a religion. In his book \"Triumph of the Moon\", historian Ronald Hutton doubted not only of the existence of the religion that \"Aradia\" claimed to represent, and that the traditions Leland presented were unlike anything found in actual medieval literature. but also of the existence of Leland's sources, arguing that it is more likely that Leland created the entire story than that Leland could be so easily \"duped\". Religious scholar Chas S. Clifton took exception to Hutton's position, writing that it amounted to an accusation of \"serious literary fraud\" made by an \"argument from absence\".\n\nBecause Leland's claims about an Italian witch-cult are questionable, the first verifiable worship of Diana in the modern age was probably begun by Wicca. The earliest known practitioners of Neopagan witchcraft were members of a tradition begun by Gerald Gardner. Published versions of the devotional materials used by Gardner's group, dated to 1949, are heavily focused on the worship of Aradia, the daughter of Diana in Leland's folklore. Diana herself was recognized as an aspect of a single \"great goddess\" in the tradition of Apuleius, as described in the Wiccan Charge of the Goddess (itself adapted from Leland's text). Some later Wiccans, such as Scott Cunningham, would replace Aradia with Diana as the central focus of worship.\n\nIn the early 1960s, Victor Henry Anderson founded the Feri Tradition, a form of Wicca that draws from both Charles Leland's folklore and the Gardnerian tradition. Anderson claimed that he had first been initiated into a witchcraft tradition as a child in 1926, and that he had been told the name of the goddess worshiped by witches was Tana. The name Tana originated in Leland's \"Aradia\", where he claimed it was an old Etruscan name for Diana. The Feri Tradition founded by Anderson continues to recognize Tana/Diana as an aspect of the Star Goddess related to the element of fire, and representing \"the fiery womb that gives birth to and transforms all matter.\" (In \"Aradia\", Diana is also credited as the creatrix of the material world and Queen of Faeries).\n\nA few Wiccan traditions would elevate Diana to a more prominent position of worship, and there are two distinct modern branches of Wicca focused primarily on Diana. The first, founded during the early 1970s in the United States by Morgan McFarland and Mark Roberts, has a feminist theology and only occasionally accepts male participants, and leadership is limited to female priestesses. McFarland Dianic Wiccans base their tradition primarily on the work of Robert Graves and his book \"The White Goddess\", and were inspired by references to the existence of medieval European \"Dianic cults\" in Margaret Murray's book \"The Witch-Cult in Western Europe\". The second Dianic tradition, founded by Zsuzsanna Budapest in the mid 1970s, is characterized by an exclusive focus on the feminine aspect of the divine, and as a result is exclusively female. This tradition combines elements from British Traditional Wicca, Italian folk-magic based on the work of Charles Leland, feminist values, and healing practices drawn from a variety of different cultures.\n\nA third Neopagan tradition heavily inspired by the worship of Diana through the lens of Italian folklore is Stregheria, founded in the 1980s. It centers around a pair of deities regarded as divine lovers, who are known by several variant names including Diana and Dianus, alternately given as Tana and Tanus or Jana and Janus (the later two deity names were mentioned by James Frazer in \"The Golden Bough\" as later corruptions of Diana and Dianus, which themselves were alternate and possibly older names for Juno and Jupiter). The tradition was founded by author Raven Grimassi, and influenced by Italian folktales he was told by his mother. One such folktale describes the moon being impregnated by her lover the morning star, a parallel to Leland's mythology of Diana and her lover Lucifer.\n\nDiana was also a subject of worship in certain Feraferian rites, particularly those surrounding the autumnal equinox, beginning in 1967.\n\nBoth the Romanian words for \"fairy\" \"Zână\" and Sânziană, the Leonese and Portuguese word for \"water nymph\" \"xana\", and the Spanish word for \"shooting target\" and \"morning call\" (\"diana\") seem to come from the name of Diana.\n\nSince the Renaissance, Diana's myths have often been represented in the visual and dramatic arts, including the opera \"L'arbore di Diana\". In the 16th century, Diana's image figured prominently at the châteaus of Fontainebleau, Chenonceau, & at Anet, in deference to Diane de Poitiers, mistress of Henri of France. At Versailles she was incorporated into the Olympian iconography with which Louis XIV, the Apollo-like \"Sun King\" liked to surround himself. Diana is also a character in the 1876 Léo Delibes ballet \"Sylvia\". The plot deals with Sylvia, one of Diana's nymphs and sworn to chastity, and Diana's assault on Sylvia's affections for the shepherd Amyntas.\n\n\n\nDiana has been one of the most popular themes in art. Painters like Titian, Peter Paul Rubens, François Boucher, Nicholas Poussin and made use of her myth as a major theme. Most depictions of Diana in art featured the stories of Diana and Actaeon, or Callisto, or depicted her resting after hunting. Some famous work of arts with a Diana theme are:\n\n\n\n\n\n"}
{"id": "8396", "url": "https://en.wikipedia.org/wiki?curid=8396", "title": "December 11", "text": "December 11\n\n\n\n"}
{"id": "8397", "url": "https://en.wikipedia.org/wiki?curid=8397", "title": "Danny Elfman", "text": "Danny Elfman\n\nDaniel Robert Elfman (born May 29, 1953) is an American composer, singer, songwriter, and record producer. Elfman first became known for being the lead singer and songwriter for the band Oingo Boingo from 1974 to 1995. He is well known for scoring films and television shows, particularly his frequent collaborations with director Tim Burton.\n\nIn 1976, Elfman entered the film industry as an actor. In 1980, he scored his first film, \"Forbidden Zone\", directed by his older brother Richard Elfman. Among his honors are four Oscar nominations, a Grammy for \"Batman\", an Emmy for \"Desperate Housewives\", six Saturn Awards for Best Music, the 2002 Richard Kirk Award, and the Disney Legend Award.\n\nDanny Elfman was born on May 29, 1953 in Los Angeles, California to a Jewish family of Polish and Russian ancestry. He is the son of Blossom Elfman (née Bernstein), a writer and teacher, and Milton Elfman, a teacher who was in the Air Force. He was raised in a racially mixed affluent community in Baldwin Hills, California. He spent much of his time in the neighborhood's local movie theater, adoring the music of such film composers as Bernard Herrmann and Franz Waxman. Stating that he hung out with the \"band geeks\" in high school, he started a ska band. After dropping out of high school, he followed his brother Richard to France, where he performed with Le Grand Magic Circus, an avant-garde musical theater group.\n\nHe was never officially a student at the CalArts, but an instructor there encouraged him to continue learning. Elfman stated, \"He just laughed, and said, 'Sit. Play.' I continued to sit and play for a couple years.\" At this time, his brother Richard was forming a new musical theater group.\n\nIn 1972 Richard Elfman founded the American new wave band/performance art group, originally called The Mystic Knights of the Oingo Boingo. They played several shows throughout the 1970s until Richard Elfman left the band to become a filmmaker. As a send-off to the band's original concept, Richard Elfman created the film \"Forbidden Zone\" based on their stage performances. Danny Elfman composed his first score for the film and played the role of Satan (the other band members played his minions). By the time the movie was completed, they had taken the name Oingo Boingo and begun recording and touring as a rock group. From 1976 and on, it was led by Danny Elfman, until 1995 when they suddenly retired. The semi-theatrical music and comedy troupe had transformed into a ska-influenced new wave band in 1979, and then changed again towards a more guitar-oriented rock sound, in the late 1980s.. Oingo Boingo, still led by Danny Elfman, performed as themselves in the 1986 movie \"Back to School\". Additionally, Danny Elfman and Oingo Boingo guitarist Steve Bartek reunited on October 31, 2015 to perform the song \"Dead Man's Party\" – \"for the first time in 20 years to the day\", as Elfman said to the audience – during an encore at a Halloween celebration at the Hollywood Bowl.\n\nIn 1985, Tim Burton and Paul Reubens invited Elfman to write the score for their first feature film, \"Pee-wee's Big Adventure\". Elfman was apprehensive at first, because of his lack of formal training, but with orchestration assistance from Oingo Boingo guitarist and arranger Steve Bartek, he achieved his goal of emulating the mood of such composers as Nino Rota and Bernard Herrmann. In the booklet for the first volume of \"Music for a Darkened Theatre\", Elfman described the first time he heard his music played by a full orchestra as one of the most thrilling experiences of his life. Elfman immediately developed a rapport with Burton and has gone on to score all but three of Burton's major studio releases: \"Ed Wood\", which was under production while Elfman and Burton were having a serious disagreement, \"\" and, most recently, \"Miss Peregrine's Home for Peculiar Children\". Elfman also provided the singing voice for Jack Skellington in Tim Burton's \"The Nightmare Before Christmas\" and the voices of both Barrel and the \"Clown with the Tear-Away Face\". In 1990, Elfman composed the iconic orchestra piece, \"Ice Dance\", for the Tim Burton film \"Edward Scissorhands\". Years later he provided the voice for Bonejangles the skeleton in \"Corpse Bride\" and the voices of the Oompa-Loompas in \"Charlie and the Chocolate Factory\".\n\nOne of Elfman's notable compositions is \"The Simpsons\" theme, which he wrote in 1989.\n\nIn 2002 Elfman composed the soundtracks for the Sam Raimi \"Spider-Man\" series, except for \"Spider-Man 3\", to which he contributed a variety of work on the soundtrack, but did not compose the soundtrack.\n\nIn October 2013, Elfman returned to the stage to sing his vocal parts to a handful of \"Nightmare Before Christmas\" songs as part of a concert titled \"Danny Elfman's Music from the Films of Tim Burton\". He composed the film score for \"Oz the Great and Powerful\" (2013), and composed additional music for \"\" (2015) together with Brian Tyler.\n\nElfman composed the score for all three of the \"Fifty Shades\" films (2015–2018).\n\nElfman's film scores were featured in the 2017 production \"SCORE: A Film Music Documentary\". Also that year, he took over the place of composer in the DCEU's \"Justice League\" and was able to reprise parts of his own score from Tim Burton's 1989 \"Batman\" for the new incarnation of the character.\n\nIn 2004 Elfman composed \"Serenada Schizophrana\" for the American Composers Orchestra. It was conducted by John Mauceri on its recording and by Steven Sloane at its premiere at Carnegie Hall in New York City on February 23, 2005. After its premiere, it was recorded in studio and released onto SACD on October 3, 2006. The meeting with Mauceri proved fruitful as the composer was encouraged then to write a new concert piece for Mauceri and the Hollywood Bowl Orchestra. Elfman composed an \"overture to a non-existent musical\" and called the piece \"The Overeager Overture\".\n\n2017 saw the premiere of his 40-minute Concerto for Violin & Orchestra ('Eleven Eleven') in Prague, with soloist Sandy Cameron (for whom it was written) and conducted by John Mauceri with the Czech National Symphony Orchestra. It was jointly commissioned by Prague Proms, Stanford Symphony and the Royal Scottish National Orchestra and has subsequently been performed in Germany and the US, with further dates and a recording planned. A 4-movement, 21-minute Piano Quartet was premiered by the Berlin Philharmonic Piano Quartet as part of their US tour in 2018. Elfman continues to compose his film scores in addition to these other projects.\n\nIn November 2010, it was reported that Danny Elfman was writing the music for a planned musical based on the life of Harry Houdini, but, , he was no longer attached to the project.\n\nIn 2011 Elfman composed the music for the Cirque du Soleil show \"Iris\", which was performed at the Dolby Theatre in Hollywood from July 21, 2011 to January 19, 2013.\n\nIn October 2016, Elfman composed a horror score for when Donald Trump \"loom[ed]\" behind Hillary Clinton at the second United States presidential election debates, 2016.\n\nThe style of Elfman's music has been influenced by modern composers including Béla Bartók, Philip Glass, Lou Harrison, Carl Orff, Harry Partch, Sergei Prokofiev, Maurice Ravel, Erik Satie, Igor Stravinsky, as well as Romantic composer Pyotr Ilyich Tchaikovsky. Elfman has said that the first time he noticed film music was when he heard Bernard Herrmann's score to \"The Day the Earth Stood Still\" as an eleven-year-old; afterwards he became a fan of film music. Elfman's influences in film music include the work of Erich Wolfgang Korngold, Max Steiner, David Tamkin, Franz Waxman, and Nino Rota, who served as a significant influence and the main inspiration for Elfman's score for \"Pee-wee's Big Adventure\". Elfman's work in pop music was influenced by The Specials, Madness, the Selecter, and XTC.\n\nAs a teenager, Elfman dated his classmate Kim Gordon, who would later become one of the members of the rock band Sonic Youth.\n\nOn November 29, 2003, Elfman married actress Bridget Fonda. They have a son, Oliver. In 1998, Elfman scored \"A Simple Plan\", starring Fonda.\n\nHe is the uncle of actor Bodhi Elfman, who is married to actress Jenna Elfman.\n\nElfman has been an atheist since the age of 11 or 12. According to him, he is a cynicologist.\n\nDescribing his politics during the 1980s, Elfman said, \"I'm not a doomist. My attitude is always to be critical of what's around you, but not ever to forget how lucky we are. I've traveled around the world. I left thinking I was a revolutionary. I came back real right-wing patriotic. Since then, I've kind of mellowed in between.\" In 2008, he expressed support for Barack Obama and said that Sarah Palin was his \"worst nightmare\".\n\nDuring the 18 years with Oingo Boingo, Elfman developed significant hearing damage as a result of the continuous exposure to the high noise levels involved in performing in a rock band. Afraid of worsening his condition, he decided to leave the band, saying that he would never return to that kind of performance. His impairment was so bad that he could not \"even sit in a loud restaurant or bar anymore.\" However, he found performing in front of orchestras more tolerable, and returned several times to reprise his live performance of Jack Skellington.\n\nElfman's scores for \"Batman\" and \"Edward Scissorhands\" were nominated for AFI's 100 Years of Film Scores.\n\n\n"}
{"id": "8398", "url": "https://en.wikipedia.org/wiki?curid=8398", "title": "Dimension", "text": "Dimension\n\nIn physics and mathematics, the dimension of a mathematical space (or object) is informally defined as the minimum number of coordinates needed to specify any point within it. Thus a line has a dimension of one because only one coordinate is needed to specify a point on itfor example, the point at 5 on a number line. A surface such as a plane or the surface of a cylinder or sphere has a dimension of two because two coordinates are needed to specify a point on itfor example, both a latitude and longitude are required to locate a point on the surface of a sphere. The inside of a cube, a cylinder or a sphere is three-dimensional because three coordinates are needed to locate a point within these spaces.\n\nIn classical mechanics, space and time are different categories and refer to absolute space and time. That conception of the world is a four-dimensional space but not the one that was found necessary to describe electromagnetism. The four dimensions of spacetime consist of events that are not absolutely defined spatially and temporally, but rather are known relative to the motion of an observer. Minkowski space first approximates the universe without gravity; the pseudo-Riemannian manifolds of general relativity describe spacetime with matter and gravity. Ten dimensions are used to describe superstring theory, eleven dimensions can describe supergravity and M-theory, and the state-space of quantum mechanics is an infinite-dimensional function space.\n\nThe concept of dimension is not restricted to physical objects. s frequently occur in mathematics and the sciences. They may be parameter spaces or configuration spaces such as in Lagrangian or Hamiltonian mechanics; these are abstract spaces, independent of the physical space we live in.\n\nIn mathematics, the dimension of an object is, roughly speaking, the number of degrees of freedom of a point that moves on this object. In other words, the dimension is the number of independent parameters or coordinates that are needed for defining the position of a point that is constrained to be on the object. For example, the dimension of a point is zero; the dimension of a line is one, as a point can move on a line in only one direction (or its opposite); the dimension of a plane is two, etc.\n\nThe dimension is an intrinsic property of an object, in the sense that it is independent of the dimension of the space in which the object is or can be embedded. For example, a curve, such as a circle is of dimension one, because the position of a point on a curve is determined by its signed distance along the curve to a fixed point on the curve. This is independent from the fact that a curve cannot be embedded in a Euclidean space of dimension lower than two, unless if it is a line.\n\nThe dimension of Euclidean -space is . When trying to generalize to other types of spaces, one is faced with the question \"what makes -dimensional?\" One answer is that to cover a fixed ball in by small balls of radius , one needs on the order of such small balls. This observation leads to the definition of the Minkowski dimension and its more sophisticated variant, the Hausdorff dimension, but there are also other answers to that question. For example, the boundary of a ball in looks locally like and this leads to the notion of the inductive dimension. While these notions agree on , they turn out to be different when one looks at more general spaces.\n\nA tesseract is an example of a four-dimensional object. Whereas outside mathematics the use of the term \"dimension\" is as in: \"A tesseract \"has four dimensions\"\", mathematicians usually express this as: \"The tesseract \"has dimension 4\"\", or: \"The dimension of the tesseract \"is\" 4\".\n\nAlthough the notion of higher dimensions goes back to René Descartes, substantial development of a higher-dimensional geometry only began in the 19th century, via the work of Arthur Cayley, William Rowan Hamilton, Ludwig Schläfli and Bernhard Riemann. Riemann's 1854 Habilitationsschrift, Schläfli's 1852 \"Theorie der vielfachen Kontinuität\", and Hamilton's discovery of the quaternions and John T. Graves' discovery of the octonions in 1843 marked the beginning of higher-dimensional geometry.\n\nThe rest of this section examines some of the more important mathematical definitions of dimension.\n\nThe dimension of a vector space is the number of vectors in any basis for the space, i.e. the number of coordinates necessary to specify any vector. This notion of dimension (the cardinality of a basis) is often referred to as the \"Hamel dimension\" or \"algebraic dimension\" to distinguish it from other notions of dimension. \n\nFor the non-free case, this generalizes to the notion of the length of a module.\n\nThe uniquely defined dimension of every connected topological manifold can be calculated. A connected topological manifold is locally homeomorphic to Euclidean -space, in which the number is the manifold's dimension.\n\nFor connected differentiable manifolds, the dimension is also the dimension of the tangent vector space at any point.\n\nIn geometric topology, the theory of manifolds is characterized by the way dimensions 1 and 2 are relatively elementary, the high-dimensional cases are simplified by having extra space in which to \"work\"; and the cases and are in some senses the most difficult. This state of affairs was highly marked in the various cases of the Poincaré conjecture, where four different proof methods are applied.\n\nThe dimension of a manifold depends on the base field with respect to which Euclidean space is defined. While analysis usually assumes a manifold to be over the real numbers, it is sometimes useful in the study of complex manifolds and algebraic varieties to work over the complex numbers instead. A complex number (\"x\" + \"iy\") has a real part \"x\" and an imaginary part \"y\", where x and y are both real numbers; hence, the complex dimension is half the real dimension. \n\nConversely, in algebraically unconstrained contexts, a single complex coordinate system may be applied to an object having two real dimensions. For example, an ordinary two-dimensional spherical surface, when given a complex metric, becomes a Riemann sphere of one complex dimension.\n\nThe dimension of an algebraic variety may be defined in various equivalent ways. The most intuitive way is probably the dimension of the tangent space at any Regular point of an algebraic variety. Another intuitive way is to define the dimension as the number of hyperplanes that are needed in order to have an intersection with the variety that is reduced to a finite number of points (dimension zero). This definition is based on the fact that the intersection of a variety with a hyperplane reduces the dimension by one unless if the hyperplane contains the variety.\n\nAn algebraic set being a finite union of algebraic varieties, its dimension is the maximum of the dimensions of its components. It is equal to the maximal length of the chains formula_1 of sub-varieties of the given algebraic set (the length of such a chain is the number of \"formula_2\").\n\nEach variety can be considered as an algebraic stack, and its dimension as variety agrees with its dimension as stack. There are however many stacks which do not correspond to varieties, and some of these have negative dimension. Specifically, if \"V\" is a variety of dimension \"m\" and \"G\" is an algebraic group of dimension \"n\" acting on \"V\", then the quotient stack [\"V\"/\"G\"] has dimension \"m\"−\"n\".\n\nThe Krull dimension of a commutative ring is the maximal length of chains of prime ideals in it, a chain of length \"n\" being a sequence formula_3 of prime ideals related by inclusion. It is strongly related to the dimension of an algebraic variety, because of the natural correspondence between sub-varieties and prime ideals of the ring of the polynomials on the variety.\n\nFor an algebra over a field, the dimension as vector space is finite if and only if its Krull dimension is 0.\n\nFor any normal topological space , the Lebesgue covering dimension of is defined to be \"n\" if \"n\" is the smallest integer for which the following holds: any open cover has an open refinement (a second open cover where each element is a subset of an element in the first cover) such that no point is included in more than elements. In this case dim . For a manifold, this coincides with the dimension mentioned above. If no such integer exists, then the dimension of is said to be infinite, and one writes dim . Moreover, has dimension −1, i.e. dim if and only if is empty. This definition of covering dimension can be extended from the class of normal spaces to all Tychonoff spaces merely by replacing the term \"open\" in the definition by the term \"functionally open\".\n\nAn inductive dimension may be defined inductively as follows. Consider a discrete set of points (such as a finite collection of points) to be 0-dimensional. By dragging a 0-dimensional object in some direction, one obtains a 1-dimensional object. By dragging a 1-dimensional object in a \"new direction\", one obtains a 2-dimensional object. In general one obtains an ()-dimensional object by dragging an -dimensional object in a \"new\" direction. The inductive dimension of a topological space may refer to the \"small inductive dimension\" or the \"large inductive dimension\", and is based on the analogy that balls have -dimensional boundaries, permitting an inductive definition based on the dimension of the boundaries of open sets.\n\nSimilarly, for the class of CW complexes, the dimension of an object is the largest for which the -skeleton is nontrivial. Intuitively, this can be described as follows: if the original space can be continuously deformed into a collection of higher-dimensional triangles joined at their faces with a complicated surface, then the dimension of the object is the dimension of those triangles.\n\nThe Hausdorff dimension is useful for studying structurally complicated sets, especially fractals. The Hausdorff dimension is defined for all metric spaces and, unlike the dimensions considered above, can also have non-integer real values. The box dimension or Minkowski dimension is a variant of the same idea. In general, there exist more definitions of fractal dimensions that work for highly irregular sets and attain non-integer positive real values. Fractals have been found useful to describe many natural objects and phenomena.\n\nEvery Hilbert space admits an orthonormal basis, and any two such bases for a particular space have the same cardinality. This cardinality is called the dimension of the Hilbert space. This dimension is finite if and only if the space's Hamel dimension is finite, and in this case the two dimensions coincide.\n\nClassical physics theories describe three physical dimensions: from a particular point in space, the basic directions in which we can move are up/down, left/right, and forward/backward. Movement in any other direction can be expressed in terms of just these three. Moving down is the same as moving up a negative distance. Moving diagonally upward and forward is just as the name of the direction implies; \"i.e.\", moving in a linear combination of up and forward. In its simplest form: a line describes one dimension, a plane describes two dimensions, and a cube describes three dimensions. (See Space and Cartesian coordinate system.)\n\nA temporal dimension is a dimension of time. Time is often referred to as the \"fourth dimension\" for this reason, but that is not to imply that it is a spatial dimension. A temporal dimension is one way to measure physical change. It is perceived differently from the three spatial dimensions in that there is only one of it, and that we cannot move freely in time but subjectively move in one direction.\n\nThe equations used in physics to model reality do not treat time in the same way that humans commonly perceive it. The equations of classical mechanics are symmetric with respect to time, and equations of quantum mechanics are typically symmetric if both time and other quantities (such as charge and parity) are reversed. In these models, the perception of time flowing in one direction is an artifact of the laws of thermodynamics (we perceive time as flowing in the direction of increasing entropy).\n\nThe best-known treatment of time as a dimension is Poincaré and Einstein's special relativity (and extended to general relativity), which treats perceived space and time as components of a four-dimensional manifold, known as spacetime, and in the special, flat case as Minkowski space.\n\nIn physics, three dimensions of space and one of time is the accepted norm. However, there are theories that attempt to unify the four fundamental forces by introducing extra dimensions. Most notably, superstring theory requires 10 spacetime dimensions, and originates from a more fundamental 11-dimensional theory tentatively called M-theory which subsumes five previously distinct superstring theories. To date, no experimental or observational evidence is available to support the existence of these extra dimensions. If extra dimensions exist, they must be hidden from us by some physical mechanism. One well-studied possibility is that the extra dimensions may be \"curled up\" at such tiny scales as to be effectively invisible to current experiments. Limits on the size and other properties of extra dimensions are set by particle experiments such as those at the Large Hadron Collider.\n\nAt the level of quantum field theory, Kaluza–Klein theory unifies gravity with gauge interactions, based on the realization that gravity propagating in small, compact extra dimensions is equivalent to gauge interactions at long distances. In particular when the geometry of the extra dimensions is trivial, it reproduces electromagnetism. However at sufficiently high energies or short distances, this setup still suffers from the same pathologies that famously obstruct direct attempts to describe quantum gravity. Therefore, these models still require a UV completion, of the kind that string theory is intended to provide. In particular, superstring theory requires six compact dimensions forming a Calabi–Yau manifold. Thus Kaluza-Klein theory may be considered either as an incomplete description on its own, or as a subset of string theory model building.\n\nIn addition to small and curled up extra dimensions, there may be extra dimensions that instead aren't apparent because the matter associated with our visible universe is localized on a subspace. Thus the extra dimensions need not be small and compact but may be large extra dimensions. D-branes are dynamical extended objects of various dimensionalities predicted by string theory that could play this role. They have the property that open string excitations, which are associated with gauge interactions, are confined to the brane by their endpoints, whereas the closed strings that mediate the gravitational interaction are free to propagate into the whole spacetime, or \"the bulk\". This could be related to why gravity is exponentially weaker than the other forces, as it effectively dilutes itself as it propagates into a higher-dimensional volume.\n\nSome aspects of brane physics have been applied to cosmology. For example, brane gas cosmology attempts to explain why there are three dimensions of space using topological and thermodynamic considerations. According to this idea it would be because three is the largest number of spatial dimensions where strings can generically intersect. If initially there are lots of windings of strings around compact dimensions, space could only expand to macroscopic sizes once these windings are eliminated, which requires oppositely wound strings to find each other and annihilate. But strings can only find each other to annihilate at a meaningful rate in three dimensions, so it follows that only three dimensions of space are allowed to grow large given this kind of initial configuration.\n\nExtra dimensions are said to be universal if all fields are equally free to propagate within them.\n\nSome complex networks are characterized by fractal dimensions. The concept of dimension can be generalized to include networks embedded in space. The dimension characterize their spatial constraints.\n\nScience fiction texts often mention the concept of \"dimension\" when referring to parallel or alternate universes or other imagined planes of existence. This usage is derived from the idea that to travel to parallel/alternate universes/planes of existence one must travel in a direction/dimension besides the standard ones. In effect, the other universes/planes are just a small distance away from our own, but the distance is in a fourth (or higher) spatial (or non-spatial) dimension, not the standard ones.\n\nOne of the most heralded science fiction stories regarding true geometric dimensionality, and often recommended as a starting point for those just starting to investigate such matters, is the 1884 novella \"Flatland\" by Edwin A. Abbott. Isaac Asimov, in his foreword to the Signet Classics 1984 edition, described \"Flatland\" as \"The best introduction one can find into the manner of perceiving dimensions.\"\n\nThe idea of other dimensions was incorporated into many early science fiction stories, appearing prominently, for example, in Miles J. Breuer's \"The Appendix and the Spectacles\" (1928) and Murray Leinster's \"The Fifth-Dimension Catapult\" (1931); and appeared irregularly in science fiction by the 1940s. Classic stories involving other dimensions include Robert A. Heinlein's \"—And He Built a Crooked House\" (1941), in which a California architect designs a house based on a three-dimensional projection of a tesseract; and Alan E. Nourse's \"Tiger by the Tail\" and \"The Universe Between\" (both 1951). Another reference is Madeleine L'Engle's novel \"A Wrinkle In Time\" (1962), which uses the fifth dimension as a way for \"tesseracting the universe\" or \"folding\" space in order to move across it quickly. The fourth and fifth dimensions are also a key component of the book \"The Boy Who Reversed Himself\" by William Sleator.\n\nImmanuel Kant, in 1783, wrote: \"That everywhere space (which is not itself the boundary of another space) has three dimensions and that space in general cannot have more dimensions is based on the proposition that not more than three lines can intersect at right angles in one point. This proposition cannot at all be shown from concepts, but rests immediately on intuition and indeed on pure intuition \"a priori\" because it is apodictically (demonstrably) certain.\"\n\n\"Space has Four Dimensions\" is a short story published in 1846 by German philosopher and experimental psychologist Gustav Fechner under the pseudonym \"Dr. Mises\". The protagonist in the tale is a shadow who is aware of and able to communicate with other shadows, but who is trapped on a two-dimensional surface. According to Fechner, this \"shadow-man\" would conceive of the third dimension as being one of time. The story bears a strong similarity to the \"Allegory of the Cave\" presented in Plato's \"The Republic\" (c. 380 BC).\n\nSimon Newcomb wrote an article for the \"Bulletin of the American Mathematical Society\" in 1898 entitled \"The Philosophy of Hyperspace\". Linda Dalrymple Henderson coined the term \"hyperspace philosophy\", used to describe writing that uses higher dimensions to explore metaphysical themes, in her 1983 thesis about the fourth dimension in early-twentieth-century art. Examples of \"hyperspace philosophers\" include Charles Howard Hinton, the first writer, in 1888, to use the word \"tesseract\"; and the Russian esotericist P. D. Ouspensky.\n\nZero\nOne\nTwo\nThree\nFour\nHigher dimensionsin mathematics\nInfinite\n\n"}
{"id": "8400", "url": "https://en.wikipedia.org/wiki?curid=8400", "title": "Duodecimal", "text": "Duodecimal\n\nThe duodecimal system (also known as base 12 or dozenal) is a positional notation numeral system using twelve as its base. The number twelve (that is, the number written as \"12\" in the base ten numerical system) is instead written as \"10\" in duodecimal (meaning \"1 dozen and 0 units\", instead of \"1 ten and 0 units\"), whereas the digit string \"12\" means \"1 dozen and 2 units\" (i.e. the same number that in decimal is written as \"14\"). Similarly, in duodecimal \"100\" means \"1 gross\", \"1000\" means \"1 great gross\", and \"0.1\" means \"1 twelfth\" (instead of their decimal meanings \"1 hundred\", \"1 thousand\", and \"1 tenth\").\n\nThe number twelve, a superior highly composite number, is the smallest number with four non-trivial factors (2, 3, 4, 6), and the smallest to include as factors all four numbers (1 to 4) within the subitizing range, and the smallest abundant number. As a result of this increased factorability of the radix and its divisibility by a wide range of the most elemental numbers (whereas ten has only two non-trivial factors: 2 and 5, and not 3, 4, or 6), duodecimal representations fit more easily than decimal ones into many common patterns, as evidenced by the higher regularity observable in the duodecimal multiplication table. As a result, duodecimal has been described as the optimal number system. Of its factors, 2 and 3 are prime, which means the reciprocals of all 3-smooth numbers (such as 2, 3, 4, 6, 8, 9, 12, 16, 18, 24, 27, 32, 36, ...) have a terminating representation in duodecimal. In particular, the five most elementary fractions (, , , and ) all have a short terminating representation in duodecimal (0.6, 0.4, 0.8, 0.3 and 0.9, respectively), and twelve is the smallest radix with this feature (because it is the least common multiple of 3 and 4). This all makes it a more convenient number system for computing fractions than most other number systems in common use, such as the decimal, vigesimal, binary, octal and hexadecimal systems. Although the trigesimal and sexagesimal systems (where the reciprocals of all 5-smooth numbers terminate) do even better in this respect, this is at the cost of unwieldy multiplication tables and a much larger number of symbols to memorize.\n\nLanguages using duodecimal number systems are uncommon. Languages in the Nigerian Middle Belt such as Janji, Gbiri-Niragu (Gure-Kahugu), Piti, and the Nimbia dialect of Gwandara; the Chepang language of Nepal and the Maldivian language (Dhivehi) of the people of the Maldives and Minicoy Island in India are known to use duodecimal numerals. \n\nGermanic languages have special words for 11 and 12, such as \"eleven\" and \"twelve\" in English. However, they are considered to come from Proto-Germanic *\"ainlif\" and *\"twalif\" (respectively \"one left\" and \"two left\"), both of which were decimal.\n\nHistorically, units of time in many civilizations are duodecimal. There are twelve signs of the zodiac, twelve months in a year, and the Babylonians had twelve hours in a day (although at some point this was changed to 24.) Traditional Chinese calendars, clocks, and compasses are based on the twelve Earthly Branches. There are 12 inches in an imperial foot, 12 troy ounces in a troy pound, 12 old British pence in a shilling, 24 (12×2) hours in a day, and many other items counted by the dozen, gross (144, square of 12) or great gross (1728, cube of 12). The Romans used a fraction system based on 12, including the uncia which became both the English words \"ounce\" and \"inch\". Pre-decimalisation, Ireland and the United Kingdom used a mixed duodecimal-vigesimal currency system (12 pence = 1 shilling, 20 shillings or 240 pence to the pound sterling or Irish pound), and Charlemagne established a monetary system that also had a mixed base of twelve and twenty, the remnants of which persist in many places.\n\nThe importance of 12 has been attributed to the number of lunar cycles in a year, and also to the fact that humans have 12 finger bones (phalanges) on one hand (three on each of four fingers). It is possible to count to 12 with the thumb acting as a pointer, touching each finger bone in turn. A traditional finger counting system still in use in many regions of Asia works in this way, and could help to explain the occurrence of numeral systems based on 12 and 60 besides those based on 10, 20 and 5. In this system, the one (usually right) hand counts repeatedly to 12, displaying the number of iterations on the other (usually left), until five dozens, i. e. the 60, are full.\n\nIn a duodecimal place system twelve is written as 10, but there are numerous proposals for how to write ten and eleven. \n\nThe simplified notations use only basic and easy to access letters such as \"A\" and \"B\" (as in the hexadecimal and vigesimal), \"T\" and \"E\" (initials of Ten and Eleven), \"X\" and \"Z\". Some employ Greek letters such as δ (standing for Greek δέκα 'ten') and ε (for Greek ένδεκα 'eleven'), or τ and ε. Frank Emerson Andrews, an early American advocate for duodecimal, suggested and used in his book \"New Numbers\" an X (from the Roman numeral for ten) and a script E (ℰ, ).\nThe Dozenal Society of Great Britain proposes a rotated digit two 2 for ten and a reversed or rotated digit three 3 for eleven. This notation was introduced by Sir Isaac Pitman. These digit forms are available as Unicode characters since June 2015 as (↊, ) and (↋, ) respectively.\n\nUntil 2015, the Dozenal Society of America (DSA) used and , the symbols devised by William Addison Dwiggins. After the Pitman digits (32) were added to Unicode the DSA took a vote and then began publishing content using the Pitman digits instead. They still use the letters X and E as the equivalent in ASCII text.\n\nOther proposals are more creative or aesthetic, for example, Edna Kramer in her 1951 book \"The Main Stream of Mathematics\" used a six-pointed asterisk (sextile) ⚹ for ten and a hash (or octothorpe) # for eleven. The symbols were chosen because they are available in typewriters and already present in telephone dials. This notation was used in publications of the Dozenal Society of America in the period 1974–2008. Many don't use any Arabic numerals under the principle of \"separate identity.\"\n\nThere are also varying proposals of how to distinguish a duodecimal number from a decimal one, or one in a different base. They include italicizing duodecimal numbers (\"54\" = 64), adding a \"Humphrey point\" (a semicolon \";\" instead of a decimal point \".\") to duodecimal numbers (54; = 64.) (54;0 = 64.0), or some combination of the two. More also add extra marking to one or more bases. Others use subscript or affixed labels to indicate the base, allowing for more than decimal and duodecimal to be represented:\n\nThis allows one to write \"54 = 64,\" \"54 = 64\" or \"doz 54 = dec 64.\" In programming, binary, octal, and hexadecimal often use a similar scheme: a binary number starts with codice_1, octal with codice_2, and hexadecimal with codice_3.\n\nThe Dozenal Society of America suggests the pronunciation of ten and eleven as \"dek\" and \"el\", each order has its own name and the prefix \"e\"- is added for fractions. The symbol corresponding to the decimal point or decimal comma, separating the whole number part from the fractional part, is the semicolon \";\". The overall system is:\nMultiple digits in this are pronounced differently. 12 is \"one do two\", 30 is \"three do\", 100 is \"one gro\", BA9 (ET9) is \"el gro dek do nine\", B8,65A,300 (E8,65T,300) is \"el do eight bi-mo, six gro five do dek mo, three gro\", and so on.\n\nWilliam James Sidis used 12 as the base for his constructed language Vendergood in 1906, noting it being the smallest number with four factors and the prevalence in commerce.\n\nThe case for the duodecimal system was put forth at length in F. Emerson Andrews' 1935 book \"New Numbers: How Acceptance of a Duodecimal Base Would Simplify Mathematics\". Emerson noted that, due to the prevalence of factors of twelve in many traditional units of weight and measure, many of the computational advantages claimed for the metric system could be realized \"either\" by the adoption of ten-based weights and measure \"or\" by the adoption of the duodecimal number system.\nBoth the Dozenal Society of America and the Dozenal Society of Great Britain promote widespread adoption of the base-twelve system. They use the word \"dozenal\" instead of \"duodecimal\" to avoid the more overtly base-ten terminology. It should be noted that the etymology of 'dozenal' is itself also an expression based on base-ten terminology since 'dozen' is a direct derivation of the French word 'douzaine' which is a derivative of the French word for twelve, \"douze\" which is related to the old French word 'doze' from Latin 'duodecim'. \n\nIt has been suggested by some members of the Dozenal Society of America and Duodecimal Society of Great Britain that a more apt word would be 'uncial'. Uncial is a derivation of the Latin word 'one-twelfth' which is 'uncia' and also the base-twelve analogue of the Latin word 'one-tenth' which is 'decima'. In the same manner as \"decimal\" comes from the Latin word for one-tenth decima, (Latin for ten was decem), the direct analogue for a base-twelve system is \"uncial\". An early use of this word can be found in Vol 1 Issue 2 of \"The Duodecimal Bulletin\" of the DSA dated June 1945 in which a submission on page 9 by a Pvt William S. Crosby titled \"The Uncial Jottings of a Harried Infantryman\", he includes the same argument for the word 'uncial'. Although not accepted by either of these two 'Uncial' societies, the use is beginning to grow.\n\nThe renowned mathematician and mental calculator Alexander Craig Aitken was an outspoken advocate of the advantages and superiority of duodecimal over decimal:\n\nIn Jorge Luis Borges' short story \"Tlön, Uqbar, Orbis Tertius\" Herbert Ashe, a melancholy English engineer, working for the Southern Argentine Railway company, is converting a duodecimal number system to a hexadecimal system. He leaves behind on his death in 1937 a manuscript Orbis Tertius that posthumously identifies him as one of the anonymous authors of the encyclopaedia of Tlön.\n\nIn Leo Frankowski's Conrad Stargard novels, Conrad introduces a duodecimal system of arithmetic at the suggestion of a merchant, who is accustomed to buying and selling goods in dozens and grosses, rather than tens or hundreds. He then invents an entire system of weights and measures in base twelve, including a clock with twelve hours in a day, rather than twenty-four hours.\n\nIn Lee Carroll's \"Kryon: Alchemy of the Human Spirit\", a chapter is dedicated to the advantages of the duodecimal system. The duodecimal system is supposedly suggested by Kryon (a fictional entity believed in by New Age circles) for all-round use, aiming at better and more natural representation of nature of the Universe through mathematics. An individual article \"Mathematica\" by James D. Watt (included in the above publication) exposes a few of the unusual symmetry connections between the duodecimal system and the golden ratio, as well as provides numerous number symmetry-based arguments for the universal nature of the base-12 number system.\n\nIn \"Little Twelvetoes\", American television series \"Schoolhouse Rock!\" portrayed an alien child using base-twelve arithmetic, using \"dek\", \"el\" and \"doh\" as names for ten, eleven and twelve, and Andrews' script-X and script-E for the digit symbols.\n\nIn March 2013, a proposal was submitted to include the digit forms for ten and eleven propagated by the Dozenal Societies of Great Britain and America in the Unicode Standard. Of these, the British forms were accepted for encoding as characters at code points () and (). They were included in the Unicode 8.0 release in June 2015. Few fonts support these new characters, but some that do include EB Garamond, Everson Mono, and Squarish Sans CT.\n\nThe turned digits two and three are available in LaTeX as codice_4 and codice_5.\n\nSystems of measurement proposed by dozenalists include:\n\nThe number 12 has six factors, which are 1, 2, 3, 4, 6, and 12, of which 2 and 3 are prime. The decimal system has only four factors, which are 1, 2, 5, and 10, of which 2 and 5 are prime. Vigesimal (base 20) adds two factors to those of ten, namely 4 and 20, but no additional prime factor. Although twenty has 6 factors, 2 of them prime, similarly to twelve, it is also a much larger base, and so the digit set and the multiplication table are much larger. Binary has only two factors, 1 and 2, the latter being prime. Hexadecimal (base 16) has five factors, adding 4, 8 and 16 to those of 2, but no additional prime. Trigesimal (base 30) is the smallest system that has three different prime factors (all of the three smallest primes: 2, 3 and 5) and it has eight factors in total (1, 2, 3, 5, 6, 10, 15, and 30). Sexagesimal—which the ancient Sumerians and Babylonians among others actually used—adds the four convenient factors 4, 12, 20, and 60 to this but no new prime factors. The smallest system that has four different prime factors is base 210 and the pattern follows the primorials. In all base systems, there are similarities to the representation of multiples of numbers which are one less than the base.\n\nTo convert numbers between bases, one can use the general conversion algorithm (see the relevant section under positional notation). Alternatively, one can use digit-conversion tables. The ones provided below can be used to convert any duodecimal number between 0.01 and ƐƐƐ,ƐƐƐ.ƐƐ to decimal, or any decimal number between 0.01 and 999,999.99 to duodecimal. To use them, the given number must first be decomposed into a sum of numbers with only one significant digit each. For example:\n\nThis decomposition works the same no matter what base the number is expressed in. Just isolate each non-zero digit, padding them with as many zeros as necessary to preserve their respective place values. If the digits in the given number include zeroes (for example, 102,304.05), these are, of course, left out in the digit decomposition (102,304.05 = 100,000 + 2,000 + 300 + 4 + 0.05). Then the digit conversion tables can be used to obtain the equivalent value in the target base for each digit. If the given number is in duodecimal and the target base is decimal, we get:\n\nNow, because the summands are already converted to base ten, the usual decimal arithmetic is used to perform the addition and recompose the number, arriving at the conversion result:\n\nThat is, 123,456.78 equals 296,130.63 ≈ 296,130.64\n\nIf the given number is in decimal and the target base is duodecimal, the method is basically same. Using the digit conversion tables:\n\nHowever, in order to do this sum and recompose the number, now the addition tables for the duodecimal system have to be used, instead of the addition tables for decimal most people are already familiar with, because the summands are now in base twelve and so the arithmetic with them has to be in duodecimal as well. In decimal, 6 + 6 equals 12, but in duodecimal it equals 10; so, if using decimal arithmetic with duodecimal numbers one would arrive at an incorrect result. Doing the arithmetic properly in duodecimal, one gets the result:\n\nThat is, 123,456.78 equals 5Ɛ,540.9... ≈ 5Ɛ,540.94\n\nThis section is about the divisibility rules in duodecimal.\n\nAny integer is divisible by 1.\n\nIf a number is divisible by 2 then the unit digit of that number will be 0, 2, 4, 6, 8 or ᘔ.\n\nIf a number is divisible by 3 then the unit digit of that number will be 0, 3, 6 or 9.\n\nIf a number is divisible by 4 then the unit digit of that number will be 0, 4 or 8.\n\nTo test for divisibility by 5, double the units digit and subtract the result from the number formed by the rest of the digits. If the result is divisible by 5 then the given number is divisible by 5.\n\nThis rule comes from 21(5*5)\n\nExamples: <br>\n13     rule => |1-2*3| = 5 which is divisible by 5.<br>\n2Ɛᘔ5   rule => |2Ɛᘔ-2*5| = 2Ɛ0(5*70) which is divisible by 5(or apply the rule on 2Ɛ0).\n\nOR\n\nTo test for divisibility by 5, subtract the units digit and triple of the result to the number formed by the rest of the digits. If the result is divisible by 5 then the given number is divisible by 5.\n\nThis rule comes from 13(5*3)\n\nExamples: <br>\n13     rule => |3-3*1| = 0 which is divisible by 5.<br>\n2Ɛᘔ5   rule => |5-3*2Ɛᘔ| = 8Ɛ1(5*195) which is divisible by 5(or apply the rule on 8Ɛ1).\n\nOR\n\nForm the alternating sum of blocks of two from right to left. If the result is divisible by 5 then the given number is divisible by 5.\n\nThis rule comes from 101, since 101 = 5*25, thus this rule can be also tested for the divisibility by 25.\n\nExample:<br>\n\n97,374,627 => 27-46+37-97 = -7Ɛ which is divisible by 5.\n\nIf a number is divisible by 6 then the unit digit of that number will be 0 or 6.\n\nTo test for divisibility by 7, triple the units digit and add the result to the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.\n\nThis rule comes from 2Ɛ(7*5)\n\nExamples:<br>\n12     rule => |3*2+1| = 7 which is divisible by 7.<br>\n271Ɛ    rule => |3*Ɛ+271| = 29ᘔ(7*4ᘔ) which is divisible by 7(or apply the rule on 29ᘔ).<br>\n\nOR\n\nTo test for divisibility by 7, subtract the units digit and double the result from the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.\n\nThis rule comes from 12(7*2)\n\nExamples:<br>\n12     rule => |2-2*1| = 0 which is divisible by 7.<br>\n271Ɛ    rule => |Ɛ-2*271| = 513(7*89) which is divisible by 7(or apply the rule on 513).<br>\n\nOR\n\nTo test for divisibility by 7, 4 times the units digit and subtract the result from the number formed by the rest of the digits. If the result is divisible by 7 then the given number is divisible by 7.\n\nThis rule comes from 41(7*7)\n\nExamples:<br>\n12     rule => |4*2-1| = 7 which is divisible by 7.<br>\n271Ɛ    rule => |4*Ɛ-271| = 235(7*3Ɛ) which is divisible by 7(or apply the rule on 235).<br>\n\nOR\n\nForm the alternating sum of blocks of three from right to left. If the result is divisible by 7 then the given number is divisible by 7.\n\nThis rule comes from 1001, since 1001 = 7*11*17, thus this rule can be also tested for the divisibility by 11 and 17.\n\nExample:<br>\n\n386,967,443 => 443-967+386 = -168 which is divisible by 7.\n\nIf the 2-digit number formed by the last 2 digits of the given number is divisible by 8 then the given number is divisible by 8.\n\nExample: 1Ɛ48, 4120\n\nIf the 2-digit number formed by the last 2 digits of the given number is divisible by 9 then the given number is divisible by 9.\n\nExample: 7423, 8330\n\nIf the number is divisible by 2 and 5 then the number is divisible by ᘔ.\n\nIf the sum of the digits of a number is divisible by Ɛ then the number is divisible by Ɛ (the equivalent of casting out nines in decimal).\n\nExample: 29, 61Ɛ13\n\nIf a number is divisible by 10 then the unit digit of that number will be 0.\n\nSum the alternate digits and subtract the sums. If the result is divisible by 11 the number is divisible by 11 (the equivalent of divisibility by eleven in decimal).\n\nExample: 66, 9427\n\nIf the number is divisible by 2 and 7 then the number is divisible by 12.\n\nIf the number is divisible by 3 and 5 then the number is divisible by 13.\n\nIf the 2-digit number formed by the last 2 digits of the given number is divisible by 14 then the given number is divisible by 14.\n\nExample: 1468, 7394\n\nDuodecimal fractions may be simple:\n\nor complicated:\n\nAs explained in recurring decimals, whenever an irreducible fraction is written in radix point notation in any base, the fraction can be expressed exactly (terminates) if and only if all the prime factors of its denominator are also prime factors of the base. Thus, in base-ten (= 2×5) system, fractions whose denominators are made up solely of multiples of 2 and 5 terminate:  = ,  =  and  =  can be expressed exactly as 0.125, 0.05 and 0.002 respectively. and , however, recur (0.333... and 0.142857142857...). In the duodecimal (= 2×2×3) system, is exact; and recur because they include 5 as a factor; is exact; and recurs, just as it does in decimal.\n\nThe number of denominators which give terminating fractions within a given number of digits, say \"n\", in a base \"b\" is the number of factors (divisors) of \"b\", the \"n\"th power of the base \"b\" (although this includes the divisor 1, which does not produce fractions when used as the denominator). The number of factors of \"b\" is given using its prime factorization.\n\nFor decimal, 10 = 2 * 5. The number of divisors is found by adding one to each exponent of each prime and multiplying the resulting quantities together.\nFactors of 10 = (\"n\"+1)(\"n\"+1) = (\"n\"+1).\n\nFor example, the number 8 is a factor of 10 (1000), so 1/8 and other fractions with a denominator of 8 can not require more than 3 fractional decimal digits to terminate. 5/8 = 0.625\n\nFor duodecimal, 12 = 2 * 3. This has (2\"n\"+1)(\"n\"+1) divisors. The sample denominator of 8 is a factor of a gross (12 = 144), so eighths can not need more than two duodecimal fractional places to terminate. 5/8 = 0.76\n\nBecause both ten and twelve have two unique prime factors, the number of divisors of \"b\" for \"b\" = 10 or 12 grows quadratically with the exponent \"n\" (in other words, of the order of \"n\").\n\nThe Dozenal Society of America argues that factors of 3 are more commonly encountered in real-life division problems than factors of 5. Thus, in practical applications, the nuisance of repeating decimals is encountered less often when duodecimal notation is used. Advocates of duodecimal systems argue that this is particularly true of financial calculations, in which the twelve months of the year often enter into calculations.\n\nHowever, when recurring fractions \"do\" occur in duodecimal notation, they are less likely to have a very short period than in decimal notation, because 12 (twelve) is between two prime numbers, 11 (eleven) and 13 (thirteen), whereas ten is adjacent to the composite number 9. Nonetheless, having a shorter or longer period doesn't help the main inconvenience that one does not get a finite representation for such fractions in the given base (so rounding, which introduces inexactitude, is necessary to handle them in calculations), and overall one is more likely to have to deal with infinite recurring digits when fractions are expressed in decimal than in duodecimal, because one out of every three consecutive numbers contains the prime factor 3 in its factorization, whereas only one out of every five contains the prime factor 5. All other prime factors, except 2, are not shared by either ten or twelve, so they do not\ninfluence the relative likeliness of encountering recurring digits (any irreducible fraction that contains any of these other factors in its denominator will recur in either base). Also, the prime factor 2 appears twice in the factorization of twelve, whereas only once in the factorization of ten; which means that most fractions whose denominators are powers of two will have a shorter, more convenient terminating representation in duodecimal than in decimal representation (e.g. 1/(2) = 0.25 = 0.3 ; 1/(2) = 0.125 = 0.16 ; 1/(2) = 0.0625 = 0.09 ; 1/(2) = 0.03125 = 0.046 ; etc.).\n\nValues in bold indicate that value is exact.\n\nThe duodecimal period length of 1/\"n\" are\n\nThe duodecimal period length of 1/(\"n\"th prime) are\n\nSmallest prime with duodecimal period \"n\" are\n\nThe representations of irrational numbers in any positional number system (including decimal and duodecimal) neither terminate nor repeat. The following table gives the first digits for some important algebraic and transcendental numbers in both decimal and duodecimal.\n\n\n\n"}
{"id": "8401", "url": "https://en.wikipedia.org/wiki?curid=8401", "title": "David Hayes Agnew", "text": "David Hayes Agnew\n\nDavid Hayes Agnew (November 24, 1818March 22, 1892) was an American surgeon.\n\nAgnew was born on November 24, 1818, Nobleville, Pennsylvania (present-day Christiana). His parents were Robert Agnew and Agnes Noble. Agnew grew up as a Christian. He was surrounded by a family of doctors and had always known he was going to become a physician. As a young boy, he had a sharp sense of humor and was very intelligent. \n\nHe graduated from the University of Pennsylvania School of Medicine in 1838. He returned to Nobleville to help his father in his clinic. He worked there for two years. His father was an asthmatic and moved to Maryland in 1840 because the climate was more suited to his condition. Agnew moved with him. On November 21, 1841, he married Margaret Irwin. In 1852, he bought and revived the Philadelphia School of Anatomy. He held responsibility for ten years until 1862. During the American Civil War he was consulting surgeon in the Mower Army Hospital, near Philadelphia, and acquired a considerable reputation for his operations in cases of gunshot wounds.On December 21, 1863, he became the Demonstrator of Anatomy and Assistant Lecturer on Clinical Surgery at The University of Pennsylvania. Later, he was requested to assist the Professor of Surgery in the Conduct of the surgical clinics. In the year 1865, he gave summer instruction courses. For the next seven years, he worked for the University as Demonstrator of Anatomy. A large portion of his success was due to his wife's energy, intelligence, and determination. She gave him an impetus to try harder and not be satisfied with his first try.\n\nOn July 2, 1881, President James A. Garfield was shot by Charles J. Guiteau. He held the position of chief consulting surgeon. When a committee came to give him his money for helping, Agnew said, \"Gentlemen, I present no bill for my attendance to President Garfield. I gave my services freely and gratuitously\". He was never optimistic about the President's case and was not fooled by fallacious beliefs. This procedure helped create Agnew's reputation.\n\n\"The Agnew Clinic\" is an 1889 painting by Thomas Eakins which depicts Agnew conducting a mastectomy operation before a gallery of students and doctors.\n\nDavid Agnew wrote \"The Principles and Practice of Surgery\". It was a three-volume set that he published from 1878–1883. He also helped found the Irwin & Agnew Iron Foundry in 1846.\n\nAgnew caught a severe attack of epidemic influenza in 1890. He never fully recovered. Following this, he had an attack of broncho-vesicular catarrh. On March 9, 1892, he was put to bed for a series of medical problems. After a few days his condition began to improve, but suddenly, on March 12 it became much worse. On March 20, he fell into a comatose condition. Agnew stayed like this until he died at 3:20 p.m. on March 22, 1892. He is now buried in West Laurel Hill Cemetery.\n\n\n"}
{"id": "8402", "url": "https://en.wikipedia.org/wiki?curid=8402", "title": "Diving (sport)", "text": "Diving (sport)\n\nDiving is the sport of jumping or falling into water from a platform or springboard, usually while performing acrobatics. Diving is an internationally recognized sport that is part of the Olympic Games. In addition, unstructured and non-competitive diving is a recreational pastime.\n\nDiving is one of the most popular Olympic sports with spectators. Competitors possess many of the same characteristics as gymnasts and dancers, including strength, flexibility, kinaesthetic judgment and air awareness. Some professional divers were originally gymnasts or dancers as both the sports have similar characteristics to diving. Dmitri Sautin holds the record for most Olympic diving medals won, by winning eight medals in total between 1992 and 2008.\n\nAlthough diving has been a popular pastime across the world since ancient times, the first modern diving competitions were held in England in the 1880s. The exact origins of the sport are unclear, though it likely derives from the act of diving at the start of swimming races. The 1904 book \"Swimming\" by Ralph Thomas notes English reports of plunging records dating back to at least 1865. The 1877 edition to \"British Rural Sports\" by John Henry Walsh makes note of a \"Mr. Young\" plunging 56 feet in 1870, and also states that 25 years prior, a swimmer named Drake could cover 53 feet.\n\nThe English Amateur Swimming Association (at the time called the Swimming Association of Great Britain) first started a \"plunging championship\" in 1883. The Plunging Championship was discontinued in 1937.\n\nDiving into a body of water had also been a method used by gymnasts in Germany and Sweden since the early 19th century. The soft landing allowed for more elaborate gymnastic feats in midair as the jump could be made from a greater height. This tradition evolved into 'fancy diving', while diving as a preliminary to swimming became known as 'Plain diving'.\n\nIn England, the practice of high diving – diving from a great height – gained popularity; the first diving stages were erected at the Highgate Ponds at a height of 15 feet in 1893 and the first world championship event, the National Graceful Diving Competition, was held there by the Royal Life Saving Society in 1895. The event consisted of standing and running dives from either 15 or 30 feet.\n\nIt was at this event that the Swedish tradition of fancy diving was introduced to the sport by the athletes Otto Hagborg and C F Mauritzi. They demonstrated their acrobatic techniques from the 10m diving board at Highgate Pond and stimulated the establishment of the Amateur Diving Association in 1901, the first organization devoted to diving in the world (later amalgamated with the Amateur Swimming Association). Fancy diving was formally introduced into the championship in 1903.\n\nPlain diving was first introduced into the Olympics at the 1904 event. The 1908 Olympics in London added 'fancy diving' and introduced elastic boards rather than fixed platforms. Women were first allowed to participate in the diving events for the 1912 Olympics in Stockholm.\n\nIn the 1928 Olympics, 'plain' and 'fancy' diving was amalgamated into one event – 'Highboard Diving'. The diving event was first held indoors in the Empire Pool for the 1934 British Empire Games and 1948 Summer Olympics in London.\n\nMost diving competitions consist of three disciplines: 1 m and 3 m springboards, and the platform. Competitive athletes are divided by gender, and often by age group. In platform events, competitors are allowed to perform their dives on either the five, seven and a half (generally just called seven), nine, or ten meter towers. In major diving meets, including the Olympic Games and the World Championships, platform diving is from the 10 meter height.\nDivers have to perform a set number of dives according to established requirements, including somersaults and twists. Divers are judged on whether and how well they completed all aspects of the dive, the conformance of their body to the requirements of the dive, and the amount of splash created by their entry to the water. A possible score out of ten is broken down into three points for the takeoff (meaning the hurdle), three for the flight (the actual dive), and three for the entry (how the diver hits the water), with one more available to give the judges flexibility.\n\nThe raw score is multiplied by a degree of difficulty factor, derived from the number and combination of movements attempted. The diver with the highest total score after a sequence of dives is declared the winner.\n\nSynchronized diving was adopted as an Olympic sport in 2000. Two divers form a team and perform dives simultaneously. The dives are identical. It used to be possible to dive opposites, also known as a pinwheel, but this is no longer part of competitive synchronized diving. For example, one diver would perform a forward dive and the other an inward dive in the same position, or one would do a reverse and the other a back movement. In these events, the diving would be judged both on the quality of execution and the synchronicity – in timing of take-off and entry, height and forward travel.\n\nThere are rules governing the scoring of a dive. Usually a score considers three elements of the dive: the approach, the flight, and the entry. The primary factors affecting the scoring are:\n\n\nEach dive is assigned a \"degree of difficulty\" (DD), which is determined from a combination of the moves undertaken, position used, and height. The DD value is multiplied by the scores given by the judges.\n\nTo reduce the subjectivity of scoring in major meets, panels of five or seven judges are assembled; major international events such as the Olympics use seven-judge panels. For a five-judge panel, the highest and lowest scores are discarded and the middle three are summed and multiplied by the DD. For seven-judge panels, as of the 2012 London Olympics, the two highest scores and two lowest are discarded, leaving three to be summed and multiplied by the DD. (Prior to the London Olympics, the highest and lowest scores were eliminated, and the remaining five scores were multiplied by , to allow for comparison to five-judge panels.) The canceling of scores is used to make it difficult for a single judge to manipulate scores.\n\nThere is a general misconception about scoring and judging. In serious meets, the absolute score is somewhat meaningless. It is the relative score, not the absolute score that wins meets. Accordingly, good judging implies consistent scoring across the dives. Specifically, if a judge consistently gives low scores for all divers, or consistently gives high scores for the same divers, the judging will yield fair relative results and will cause divers to place in the correct order. However, absolute scores have significance to the individual divers. Besides the obvious instances of setting records, absolute scores are also used for rankings and qualifications for higher level meets.\n\nIn synchronised diving events, there is a panel of seven, nine, or eleven judges; two or three to mark the execution of one diver, two or three to mark the execution of the other, and the remaining three or five to judge the synchronisation. The execution judges are positioned two on each side of the pool, and they score the diver which is nearer to them. The 2012 London Olympics saw the first use of eleven judges.\n\nThe score is computed similarly to the scores from other diving events, but has been modified starting with the 2012 London Olympics for the use of the larger judging panels. Each group of judges will have the highest and lowest scores dropped, leaving the middle score for each diver's execution and the three middle scores for synchronization. The total is then weighted by and multiplied by the DD. The result is that the emphasis is on the synchronization of the divers.\n\nThe synchronisation scores are based on:\n\nThe judges may also disqualify the diver for certain violations during the dive, including:\n\nTo win dive meets, divers create a dive list in advance of the meet. To win the meet the diver must accumulate more points than other divers. Often, simple dives with low DDs will look good to spectators but will not win meets. The competitive diver will attempt the highest DD dives possible with which they can achieve consistent, high scores. If divers are scoring 8 or 9 on most dives, it may be a sign of their extreme skill, or it may be a sign that their dive list is not competitive, and they may lose the meet to a diver with higher DDs and lower scores.\n\nIn competition, divers must submit their lists beforehand, and once past a deadline (usually when the event is announced or shortly before it begins) they cannot change their dives. If they fail to perform the dive announced, even if they physically cannot execute the dive announced or if they perform a more difficult dive, they will receive a score of zero. Under exceptional circumstances, a redive may be granted, but these are exceedingly rare (usually for very young divers just learning how to compete, or if some event outside the diver's control has caused them to be unable to perform-such as a loud noise).\n\nIn the Olympics or other highly competitive meets, many divers will have nearly the same list of dives as their competitors. The importance for divers competing at this level is not so much the DD, but how they arrange their list. Once the more difficult rounds of dives begin it is important to lead off with a confident dive to build momentum. They also tend to put a very confident dive in front of a very difficult dive to ensure that they will have a good mentality for the difficult dive. Most divers have pre-dive and post-dive rituals that help them either maintain or regain focus. Coaches also play a role in this aspect of the sport. Many divers rely on their coaches to help keep their composure during the meet. In a large meet coaches are rarely allowed on the deck to talk to their athlete so it is common to see coaches using hand gestures or body movements to communicate.\n\nThere are some American meets which will allow changes of the position of the dive even after the dive has been announced immediately before execution, but these are an exception to the rules generally observed internationally.\n\nGenerally, NCAA rules allow for dives to be changed while the diver is on the board, but the diver must request the change directly after the dive is announced. This applies especially in cases where the wrong dive is announced. If the diver pauses during his or her hurdle to ask for a change of dive, it will be declared a balk (when the diver stops mid-hurdle) and the change of dive will not be permitted.\n\nUnder FINA law, no dive may be changed after the deadline for the dive-sheet to be submitted (generally a period ranging from one hour to 24 hours, depending on the rulings made by the event organiser).\n\nIt is the diver's responsibility to ensure that the dive-sheet is filled in correctly, and also to correct the referee or announcer before the dive if they describe it incorrectly. If a dive is performed which is as submitted but not as (incorrectly) announced, it is declared failed and scores zero according to a strict reading of the FINA law. But in practice, a re-dive would usually be granted in these circumstances.\n\nThe global governing body of diving is FINA, which also governs swimming, synchronised swimming, water polo and open water swimming. Almost invariably, at national level, diving shares a governing body with the other aquatic sports.\n\nThis is frequently a source of political friction as the committees are naturally dominated by swimming officials who do not necessarily share or understand the concerns of the diving community. Divers often feel, for example, that they do not get adequate support over issues like the provision of facilities. Other areas of concern are the selection of personnel for the specialised Diving committees and for coaching and officiating at events, and the team selection for international competitions.\n\nThere are sometimes attempts to separate the governing body as a means to resolve these frustrations, but they are rarely successful. For example, in the UK the Great Britain Diving Federation was formed in 1992 with the intention of taking over the governance of Diving from the ASA (Amateur Swimming Association). Although it initially received widespread support from the diving community, the FINA requirement that international competitors had to be registered with their National Governing Body was a major factor in the abandonment of this ambition a few years later.\n\nSince FINA refused to rescind recognition of the ASA as the British governing body for all aquatic sports including diving, this meant that the elite divers had to belong to ASA-affiliated clubs to be eligible for selection to international competition.\n\nIn the United States scholastic diving is almost always part of the school's swim team. Diving is a separate sport in Olympic and Club Diving. The NCAA will separate diving from swimming in special diving competitions after the swim season is completed.\n\nDespite the apparent risk, the statistical incidence of injury in supervised training and competition is extremely low.\n\nThe majority of accidents that are classified as 'diving-related' are incidents caused by individuals jumping from structures such as bridges or piers into water of inadequate depth. Many accidents also occur when divers do not account for rocks and logs in the water. Because of this many beaches and pools prohibit diving in shallow waters or when a lifeguard is not on duty.\n\nAfter an incident in Washington in 1993, most US and other pool builders are reluctant to equip a residential swimming pool with a diving springboard so home diving pools are much less common these days. In the incident, 14-year-old Shawn Meneely made a \"suicide dive\" (holding his hands at his sides, so that his head hit the bottom first) in a private swimming pool and became a tetraplegic. The lawyers for the family, Jan Eric Peterson and Fred Zeder, successfully sued the diving board manufacturer, the pool builder, and the National Spa and Pool Institute over the inappropriate depth of the pool.\nThe NSPI had specified a minimum depth of 7 ft 6 in (2.29 m) which proved to be insufficient in the above case. The pool into which Meneely dived was not constructed to the published standards. The standards had changed after the diving board was installed on the non-compliant pool by the homeowner. But the courts held that the pool \"was close enough\" to the standards to hold NSPI liable. The multimillion-dollar lawsuit was eventually resolved in 2001 for US$6.6 million ($8 million after interest was added) in favor of the plaintiff. The NSPI was held to be liable, and was financially strained by the case. It filed twice for Chapter 11 bankruptcy protection and was successfully reorganized into a new swimming pool industry association.\n\nIn competitive diving, FINA takes regulatory steps to ensure that athletes are protected from the inherent dangers of the sport. For example, they impose restrictions according to age on the heights of platforms which divers may compete on.\n\n\nGroup D divers have only recently been allowed to compete on the tower. In the past, the age group could compete only springboard, to discourage children from taking on the greater risks of tower diving. Group D tower was introduced to counteract the phenomenon of coaches pushing young divers to compete in higher age categories, thus putting them at even greater risk.\n\nHowever, some divers may safely dive in higher age categories to dive on higher platforms. Usually this occurs when advanced Group C divers wish to compete on the 10 m.\n\nPoints on pool depths in connection with safety:\n\n\nThere are six \"groups\" into which dives are classified: \"Forward, Back, Inward, Reverse, Twist,\" and \"Armstand\". The latter applies only to Platform competitions, whereas the other five apply to both Springboard and Platform.\n\nDuring the flight of the dive, one of four positions is assumed:\n\nThese positions are referred to by the letters A, B, C and D respectively.\n\nAdditionally, some dives can be started in a flying position. The body is kept straight with the arms extended to the side, and the regular dive position is assumed at about half the dive.\n\nDifficulty is rated according to the Degree of Difficulty of the dives. Some divers may find pike easier in a flip than tuck, and most find straight the easiest in a front/back dive, although it is still rated the most difficult because of the risk of overrotation.\n\nAn armstand dive may have a higher degree of difficulty outdoors compared to indoors as wind can destabilize the equilibrium of the diver.\n\nIn competition, the dives are referred to by a schematic system of three- or four-digit numbers. The letter to indicate the position is appended to the end of the number.\n\nThe first digit of the number indicates the dive group as defined above.\n\nFor groups 1 to 4, the number consists of three digits and a letter of the alphabet. The third digit represents the number of half-somersaults. The second digit is either 0 or 1, with 0 representing a normal somersault, and 1 signifying a \"flying\" variation of the basic movement (i.e. the first half somersault is performed in the straight position, and then the pike or tuck shape is assumed). No flying dive has been competed at a high level competition for many years.\n\nFor example:\n\nFor Group 5, the dive number has 4 digits. The first digit indicates that it is a twisting dive. The second digit indicates the group (1–4) of the underlying movement; the third digit indicates the number of half-somersaults, and the fourth indicates the number of half-twists.\n\nFor example:\n\nFor Group 6 – Armstand – the dive number has either three or four digits: Three digits for dives without twist and four for dives with twists.\n\nIn non-twisting armstand dives, the second digit indicates the direction of rotation (0 = no rotation, 1 = forward, 2 = backward, 3 = reverse, 4 = inward) and the third digit indicates the number of half-somersaults. Inward-rotating armstand dives have never been performed, and are generally regarded as physically impossible.\n\nFor example:\n\nFor twisting Armstand dives, the dive number again has 4 digits, but rather than beginning with the number 5, the number 6 remains as the first digit, indicating that the \"twister\" will be performed from an Armstand. The second digit indicates the direction of rotation – as above, the third is the number of half-somersaults, and the fourth is the number of half-twists:\n\ne.g. 6243D – armstand back double-somersault with one and a half twists in the free position\n\nAll of these dives come with DD (degree of difficulty) this is an indication of how difficult/complex a dive is. The score that the dive receives is multiplied by the DD (also known as tariff) to give the dive a final score. Before a diver competes they must decide on a \"list\" this is a number of optional dives and compulsory dives. The optionals come with a DD limit. this means that a diver must select X number of dives and the combined DD limit must be no more than the limit set by the competition/organisation etc.\n\nUntil the mid-1990s the tariff was decided by the FINA diving committee, and divers could only select from the range of dives in the published tariff table. Since then, the tariff is calculated by a formula based on various factors such as the number of twist and somersaults, the height, the group etc., and divers are free to submit new combinations. This change was implemented because new dives were being invented too frequently for an annual meeting to accommodate the progress of the sport.\n\nAt the moment of take-off, two critical aspects of the dive are determined, and cannot subsequently be altered during the execution. One is the trajectory of the dive, and the other is the magnitude of the angular momentum.\n\nThe speed of rotation – and therefore the total amount of rotation – may be varied from moment to moment by changing the shape of the body, in accordance with the law of conservation of angular momentum.\n\nThe center of mass of the diver follows a parabolic path in free-fall under the influence of gravity (ignoring the effects of air resistance, which are negligible at the speeds involved).\n\nSince the parabola is symmetrical, the travel away from the board as the diver passes it is twice the amount of the forward travel at the peak of the flight. Excessive forward distance to the entry point is penalized when scoring a dive, but obviously an adequate clearance from the diving board is essential on safety grounds.\n\nThe greatest possible height that can be achieved is desirable for several reasons:\n\n\nThe magnitude of angular momentum remains constant throughout the dive, but since\n\nand the moment of inertia is larger when the body has an increased radius, the speed of rotation may be increased by moving the body into a compact shape, and reduced by opening out into a straight position.\n\nSince the tucked shape is the most compact, it gives the most control over rotational speed, and dives in this position are easier to perform. Dives in the straight position are hardest, since there is almost no scope for altering the speed, so the angular momentum must be created at take-off with a very high degree of accuracy. (A small amount of control is available by moving the position of the arms and by a slight hollowing of the back).\n\nThe opening of the body for the entry does not stop the rotation, but merely slows it down. The vertical entry achieved by expert divers is largely an illusion created by starting the entry slightly short of vertical, so that the legs are vertical as they disappear beneath the surface. A small amount of additional tuning is available by 'entry save' techniques, whereby underwater movements of the upper body and arms against the viscosity of the water affect the position of the legs.\n\nDives with multiple twists and somersaults are some of the most spectacular movements, as well as the most challenging to perform.\n\nThe rules state that twisting 'must not be generated manifestly on take-off'. Consequently, divers must use some of the somersaulting angular momentum to generate twisting movements. The physics of twisting can be explained by looking at the components of the angular momentum vector.\n\nAs the diver leaves the board, the total angular momentum vector is horizontal, pointing directly to the left for a forward dive for example. For twisting rotation to exist, it is necessary to tilt the body sideways after takeoff, so that there is now a small component of this horizontal angular momentum vector along the body's long axis. The tilt can be seen in the photo.\n\nThe tilting is done by the arms, which are outstretched to the sides just before the twist. When one arm is moved up and the other is moved down (like turning a big steering wheel), the body reacts by tilting to the side, which then begins the twisting rotation. At the completion of the required number of twist rotations, the arm motion is reversed (the steering wheel is turned back), which removes the body's tilt and stops the twisting rotation.\n\nAn alternative explanation is that the moving arms have precession torque on them which set the body into twisting rotation. Moving the arms back produces opposite torque which stops the twisting rotation.\n\nThe rules state that the body should be vertical, or nearly so, for entry. Strictly speaking, it is physically impossible to achieve a literally vertical position throughout the entry as there will inevitably still be some rotational momentum while the body is entering the water. Divers therefore attempt to create the illusion of being vertical, especially when performing rapidly rotating multiple somersault movements. For back entries, one technique is to allow the upper body to enter slightly short of vertical so that the continuing rotation leaves the final impression of the legs entering vertically. This is called \"Pike save\". Another is to use \"knee save\" movements of scooping the upper body underwater in the direction of rotation so as to counteract the rotation of the legs.\n\nThe arms must be beside the body for feet-first dives, which are typically competed only on the 1m springboard and only at fairly low levels of 3m springboard, and extended forwards in line for \"head-first\" dives, which are much more common competitively. It used to be common for the hands to be interlocked with the fingers extended towards the water, but a different technique has become favoured during the last few decades. Now the usual practice is for one hand to grasp the other with palms down to strike the water with a flat surface. This creates a vacuum between the hands, arms and head which, with a vertical entry, will pull down and under any splash until deep enough to have minimal effect on the surface of the water (the so-called \"rip entry\").\n\nOnce a diver is completely under the water they may choose to roll or scoop in the same direction their dive was rotating to pull their legs into a more vertical position. Apart from aesthetic considerations, it is important from a safety point of view that divers reinforce the habit of rolling in the direction of rotation, especially for forward and inward entries. Back injuries hyperextention are caused by attempting to re-surface in the opposite direction. Diving from the higher levels increases the danger and likelihood of such injuries.\n\nIn Canada, elite competitive diving is regulated by DPC (Diving Plongeon Canada), although the individual provinces also have organizational bodies. The main competitive season runs from February to July, although some competitions may be held in January or December, and many divers (particularly international level athletes) will train and compete year round.\n\nMost provincial level competitions consist of events for 6 age groups (Groups A, B, C, D, E, and Open) for both genders on each of the three board levels. These age groups roughly correspond to those standardized by FINA, with the addition of a youngest age group for divers 9 and younger, Group E, which does not compete nationally and does not have a tower event (although divers of this age may choose to compete in Group D). The age group Open is so called because divers of any age, including those over 18, may compete in these events, so long as their dives meet a minimum standard of difficulty.\n\nAlthough Canada is internationally a fairly strong country in diving, the vast majority of Canadian high schools and universities do not have diving teams, and many Canadian divers accept athletic scholarships from American colleges.\n\nAdult divers who are not competitive at an elite level may compete in masters diving. Typically, masters are either adults who never practiced the sport as children or teenagers, or former elite athletes who have retired but still seek a way to be involved in the sport. Many diving clubs have masters teams in addition to their primary competitive ones, and while some masters dive only for fun and fitness, there are also masters competitions, which range from the local to world championship level.\n\nDivers can qualify to compete at the age group national championships, or junior national championships, in their age groups as assigned by FINA up to the age of 18. This competition is held annually in July. Qualification is based on achieving minimum scores at earlier competitions in the season, although athletes who place very highly at a national championship will be automatically qualified to compete at the next. Divers must qualify at two different competitions, at least one of which must be a level 1 competition, i.e. a competition with fairly strict judging patterns. Such competitions include the Polar Bear Invitational in Winnipeg, the Sting in Victoria, and the Alberta Provincial Championships in Edmonton or Calgary. The qualifying scores are determined by DPC according to the results of the preceding year's national competition, and typically do not have much variation from year to year.\n\nDivers older than 18, or advanced divers of younger ages, can qualify for the senior national championships, which are held twice each year, once roughly in March and once in June or July. Once again, qualification is based on achieving minimum scores at earlier competitions (in this case, within the 12 months preceding the national championships, and in an Open age group event), or high placements in previous national championships or international competitions. It is no longer the case that divers may use results from age group events to qualify for senior nationals, or results from Open events to qualify for age group nationals.\n\nIn the Republic of Ireland facilities are limited to one pool at the National Aquatic Centre in Dublin.\n\nNational championships take place late in the year, usually during November. The competition is held at the National Aquatic Centre in Dublin and consists of four events:\n\nIn the United Kingdom, diving competitions on all boards run throughout the year. National Masters' Championships are held two or three times per year.\n\nIn the United States, summer diving is usually limited to one meter diving at community or country club pools. Some pools organize to form intra-pool competitions. These competitions are usually designed to accommodate all school-age children. One of the largest and oldest summer leagues in the United States is found in the Northern Virginia area where teams from 47 pools compete against each other every summer. NVSL-Dive annually holds the Wally Martin 3-Meter Championship and concludes the season with its Individual All Stars Championship. In addition, NVSL-Dive annually hosts the largest one-day dive meet in the world, with over 350 developmental divers in NVSL's \"Cracker Jack\" Invitational! Champions from each of these events have gone on to compete at the collegiate and Olympic levels.\n\nIn the United States scholastic diving at the high school level is usually limited to one meter diving (but some schools use three meter springboards.). Scores from those one meter dives contribute to the swim team's overall score. High school diving and swimming concludes their season with a state competition. Depending on the state and the number of athletes competing in the state, certain qualifications must be achieved to compete in the state's championship meet. There are often regional championships and district championships which are necessary to compete in before reaching the state meet to narrow the field to only the most competitive athletes. Most state championship meets consist of eleven dives. The eleven dives are usually split up between two categories: five required (voluntary) dives and six optional dives.\n\nIn the United States, pre-college divers interested in learning one and three meter or platform diving should consider a club sanctioned by either USA Diving or AAU Diving. In USA Diving, Future Champions is the entry level or novice diver category with 8 levels of competition. From Future Champions, divers graduate to \"Junior Olympic\", or JO. JO divers compete in age groups at inter-club competitions, at invitationals, and if qualified, at regional, zone and national competitions. Divers over the age of 19 years of age cannot compete in these events as a JO diver.\n\nUSA Diving sanctions the Winter Nationals championship with one, three meter, and platform events. In the summer USA Diving sanctions the Summer Nationals including all three events with both Junior and Senior divers. USA Diving is sanctioned by the United States Olympic Committee to select team representatives for international diving competitions including the World Championships and Olympic Games.\n\nAAU Diving sanctions one national event per year in the summer. AAU competes on the one, three, and tower to determine the All-American team.\n\nIn the United States scholastic diving at the college level requires one and three meter diving. Scores from the one and three meter competition contribute to the swim team's overall meet score. College divers interested in tower diving may compete in the NCAA separate from swim team events. NCAA Divisions II and III do not usually compete platform; if a diver wishes to compete platform in college, he or she must attend a Division I school.\n\nEach division also has rules on the number of dives in each competition. Division II schools compete with 10 dives in competition whereas Division III schools compete with 11. Division I schools only compete with 6 dives in competition. These 6 dives consist of either 5 optionals and 1 voluntary, or 6 optionals. If the meet is a 5 optional meet, then the divers will perform 1 optional from each category (Front, Back, Inward, Reverse, and Twister) and then 1 voluntary from the category of their choice. The voluntary in this type of meet is always worth a DD (Degree of Difficulty) of 2.0 even if the real DD is worth more or less on a DD sheet. In a 6 optional meet, the divers will yet again perform one dive from each category, but this time they will perform a 6th optional from the category of their choosing, which is worth its actual DD from the DD sheet.\n\nThe highest level of collegiate competition is the NCAA Division 1 Swimming and Diving Championship. Events at the championship include 1 meter springboard, 3 meter springboard, and platform, as well as various swimming individual and relay events. The points scored by swimmers and divers are combined to determine a team swimming & diving champion. To qualify for a diving event at the NCAA championships, a competitor must first finish in the top three at one of five zone championships, which are held after the various conference championship meets. A diver who scores at least 310 points on the 3 meter springboard and 300 points on the 1 meter springboard in a 6 optional meet can participate in the particular zone championship corresponding to the geographic region in which his or her school lies.\n\nA number of colleges and universities offer scholarships to men and women who have competitive diving skills. These scholarships are usually offered to divers with age-group or club diving experience.\n\nThe NCAA limits the number of years a college student can represent any school in competitions. The limit is four years, but could be less under certain circumstances.\n\nDivers who continue diving past their college years can compete in Masters' Diving programs. Masters' diving programs are frequently offered by college or club programs.\n\nMasters' Diving events are normally conducted in age-groups separated by five or ten years, and attract competitors of a wide range of ages and experience (many, indeed, are newcomers to the sport); the oldest competitor in a Masters' Diving Championship was Viola Krahn, who at the age of 101 was the first person in any sport, male or female, anywhere in the world, to compete in an age-group of 100+ years in a nationally organized competition.\n\n\nDiving is also popular as a non-competitive activity. Such diving usually emphasizes the airborne experience, and the height of the dive, but does not emphasize what goes on once the diver enters the water. The ability to dive underwater can be a useful emergency skill, and is an important part of watersport and navy safety training. Entering water from a height is an enjoyable leisure activity, as is underwater swimming.\n\nSuch non-competitive diving can occur indoors and outdoors. Outdoor diving typically takes place from cliffs or other rock formations either into fresh or salt water. However, man-made diving platforms are sometimes constructed in popular swimming destinations. Outdoor diving requires knowledge of the water depth and currents as conditions can be dangerous.\nOn occasion, the diver will inadvertently belly flop, entering the water horizontally or nearly so. The diver typically displaces a larger than usual amount of water.\n\nA recently developing section of the sport is \"High Diving\" (e.g. see 2013 World Aquatics Championships), conducted in open air locations, usually from improvised platforms up to high (as compared with as used in Olympic and World Championship events). Entry to the water is invariably feet-first to avoid the risk of injury that would be involved in head-first entry from that height. The final half-somersault is almost always performed backwards, enabling the diver to spot the entry point and control their rotation.\n\n\n"}
{"id": "8406", "url": "https://en.wikipedia.org/wiki?curid=8406", "title": "Dative case", "text": "Dative case\n\nThe dative case (abbreviated , or sometimes when it is a core argument) is a grammatical case used in some languages to indicate, among other uses, the noun to which something is given, as in \"Maria Jacobo potum dedit\", Latin for \"Maria gave Jacob a drink\". In these examples, the dative marks what would be considered the indirect object of a verb in English.\n\nSometimes the dative has functions unrelated to giving. In Scottish Gaelic and Irish, the term \"dative case\" is used in traditional grammars to refer to the prepositional case-marking of nouns following simple prepositions and the definite article. In Georgian, the dative case also marks the subject of the sentence with some verbs and some tenses. This is called the dative construction.\n\nThe dative was common among early Indo-European languages and has survived to the present in the Balto-Slavic branch and the Germanic branch, among others. It also exists in similar forms in several non-Indo-European languages, such as the Uralic family of languages. In some languages, the dative case has assimilated the functions of other, now extinct cases. In Ancient Greek, the dative has the functions of the Proto-Indo-European locative and instrumental as well as those of the original dative.\n\nUnder the influence of English, which uses the preposition \"to\" for (among other uses) both indirect objects (\"give to\") and directions of movement (\"go to\"), the term \"dative\" has sometimes been used to describe cases that in other languages would more appropriately be called lative.\n\n\"Dative\" comes from Latin \"cāsus datīvus\" (\"case for giving\"), a translation of Greek δοτικὴ πτῶσις, \"dotikē ptôsis\" (\"inflection for giving\"), from its use with the verb \"didónai\" \"to give\". Dionysius Thrax in his Art of Grammar also refers to it as \"epistaltikḗ\" \"for sending (a letter)\", from the verb \"epistéllō\" \"send to\", a word from the same root as epistle.\n\nThe Old English language, which continued in use until after the Norman Conquest of 1066, had a dative case; however, the English case system gradually fell into disuse during the Middle English period, when the accusative and dative of pronouns merged into a single oblique case that was also used with all prepositions. This conflation of case in Middle and Modern English has led most modern grammarians to discard the \"accusative\" and \"dative\" labels as obsolete in reference to English, often using the term \"objective\" for oblique.\n\nThe dative case is rare in modern English usage, but it can be argued that it survives in a few set expressions. One example is the word \"methinks\", with the meaning \"it seems to me\". It survives in this fixed form from Old English (having undergone, however, phonetic changes with the rest of the language), in which it was constructed as \"[it]\" + \"me\" (the dative case of the personal pronoun) + \"thinks\" (i.e., \"seems\", < Old English þyncan, \"to seem\", a verb closely related to the verb þencan, \"to think\", but distinct from it in Old English; later it merged with \"think\" and lost this meaning).\n\nThe modern objective case pronoun whom is derived from the dative case in Old English, specifically the Old English dative pronoun \"hwām\" (as opposed to the modern subjective \"who\", which descends from Old English \"hwā\") — though \"whom\" \"also\" absorbed the functions of the Old English accusative pronoun \"hwone\". It is also cognate to the word \"\"wem\"\" (the dative form of \"\"wer\"\") in German. The OED defines all classical uses of the word \"whom\" in situations where the indirect object \"is not known\" – in effect, indicating the anonymity of the indirect object.\n\nLikewise, some of the object forms of personal pronouns are remnants of Old English datives. For example, \"him\" goes back to the Old English dative \"him\" (accusative was \"hine\"), and \"her\" goes back to the dative \"hire\" (accusative was \"hīe\"). These pronouns are not datives in modern English; they are also used for functions previously indicated by the accusative.\n\nA grammatical \"object\" is an object \"of something\", either an object \"of a preposition\" or an object \"of a verb\". Objects of verbs can be either \"direct\" or \"indirect\", while objects of prepositions are neither direct nor indirect. The indirect object of the verb is expressed between the verb and the direct object of the verb: \"he gave me a book\" or \"he wrote me a poem.\"\n\nAn indirect object can often be \"re-worded\" with a prepositional phrase using \"to\" or \"for\", but it is then no longer an indirect object. For example, \"He gave a book to me\" and \"He wrote a poem for me\" have the same meaning the examples above, but are now \"adverbial prepositional phrases\". Of course it is not unusual that two \"different grammatical structures\" can describe the \"same situation\"; however referring to these \"prepositional objects\" mistakenly as \"indirect objects\" is a common error.\n\nIn general, the dative (German: \"Dativ\") is used to mark the indirect object of a German sentence. For example:\n\nIn English, the first sentence can be rendered as \"I sent the book \"to the man\"\" and as \"I sent \"the man\" the book\", where the indirect object is identified in English by standing in front of the direct object. The normal word order in German is to put the dative in front of the accusative (as in the example above). However, since the German dative is marked in form, it can also be put \"after\" the accusative: \"Ich schickte das Buch dem Mann(e). The (e)\" after \"Mann\" and \"Kind\" signifies a now largely archaic -e ending for certain nouns in the dative. It survives today almost exclusively in set phrases such as \"zu Hause\" (going home, \"lit.\" to the house), \"im Zuge\" (in the course of), and \"am Tage\" (during the day, \"lit.\" at the day), as well as in occasional usage in formal prose, poetry, and song lyrics.\n\nSome masculine nouns (and one neuter noun, \"Herz\" [heart]), referred to as \"weak nouns\" or \"n-nouns\", take an -n or -en in the dative singular and plural. Many are masculine nouns ending in -e in the nominative (such as \"Name\" [name], \"Beamte\" [officer], and \"Junge\" [boy]), although not all such nouns follow this rule. Many also, whether or not they fall into the former category, refer to people, animals, professions, or titles; exceptions to this include the aforementioned \"Herz\" and \"Name\", as well as \"Buchstabe\" (letter), \"Friede\" (peace), \"Obelisk\" (obelisk), \"Planet\" (planet), and others.\n\nCertain German prepositions require the dative: \"aus\" (from), \"außer\" (out of), \"bei\" (at, near), \"entgegen\" (against), \"gegenüber\" (opposite), \"mit\" (with), \"nach\" (after, to), \"seit\" (since), \"von\" (from), and \"zu\" (at, in, to). Some other prepositions (\"an\" [at], \"auf\" [on], \"entlang\" [along], \"hinter\" [behind], \"in\" [in, into], \"neben\" (beside, next to), \"über\" [over, across], \"unter\" [under, below], \"vor\" [in front of], and \"zwischen\" [among, between]) may be used with dative (indicating current location), or accusative (indicating direction toward something). \"Das Buch liegt auf dem Tisch(e)\" (dative: The book is lying on the table), but \"Ich lege das Buch auf den Tisch\" (accusative: I put the book onto the table).\n\nIn addition the four prepositions \"[an]statt\" (in place of), \"trotz\" (in spite of), \"während\" (during), and \"wegen\" (because of) which require the genitive in modern formal language, are most commonly used with the dative in colloquial German. For example, \"because of the weather\" is expressed as \"wegen dem Wetter\" instead of the formally correct \"wegen des Wetters\". Other prepositions requiring the genitive in formal language, are combined with \"von\" (\"of\") in colloquial style, e.g. \"außerhalb vom Garten\" instead of \"außerhalb des Gartens\" (\"outside the garden\").\n\nNote that the concept of an indirect object may be rendered by a prepositional phrase. In this case, the noun's or pronoun's case is determined by the preposition, NOT by its function in the sentence. Consider this sentence:\nHere, the subject, \"Ich\", is in the nominative case, the direct object, \"das Buch\", is in the accusative case, and \"zum Verleger\" is in the dative case, since \"zu\" always requires the dative (\"zum\" is a contraction of \"zu\" + \"dem\"). However:\nIn this sentence, \"Freund\" is the indirect object, but, because it follows \"an\" (direction), the accusative is required, not the dative.\n\nAll of the articles change in the dative case.\nSome German verbs require the dative for their direct objects. Common examples are \"antworten\" (to answer), \"danken\" (to thank), \"gefallen\" (to please), \"folgen\" (to follow), \"glauben\" (to believe), \"helfen\" (to help), and \"raten\" (to advise). In each case, the direct object of the verb is rendered in the dative. For example:\n\nThese verbs cannot be used in normal passive constructions, because German allows these only for verbs with accusative objects. It is therefore ungrammatical to say: *\"Ich werde geholfen.\" \"I am helped.\" Instead a special construction called \"impersonal passive\" must be used: \"Mir wird geholfen\", literally: \"To me is helped.\" A colloquial (non-standard) and rarely used way to form the passive voice for dative verbs is the following: \"Ich kriege geholfen\", or: \"Ich bekomme geholfen\", literally: \"I get helped\". The use of the verb \"to get\" here reminds us that the dative case has something to do with giving and receiving. In German, help is not something you \"perform on\" somebody, but rather something you \"offer\" them.\n\nThe dative case is also used with reflexive (\"sich\") verbs when specifying what part of the self the verb is being done to:\nCf. the respective \"accord\" in French: \"Les enfants se sont lavés\" (\"the children have washed themselves\") vs. \"Les enfants se sont lavé\" [uninflected] \"les mains\" (\"... their hands\").\n\nGerman can use two datives to make sentences like: \"Sei mir meinem Sohn(e) gnädig!\" \"For my sake, have mercy on my son!\" Literally: \"Be for me to my son merciful.\" The first dative \"mir\" (\"for me\") expresses the speaker's commiseration (much like the \"dativus ethicus\" in Latin, see below). The second dative \"meinem Sohn(e)\" (\"to my son\") names the actual object of the plea. Mercy is to be given \"to\" the son \"for\" or \"on behalf of\" his mother/father.\n\nAdjective endings also change in the dative case. There are three inflection possibilities depending on what precedes the adjective. They most commonly use \"weak inflection\" when preceded by a definite article (the), \"mixed inflection\" after an indefinite article (a/an), and \"strong inflection\" when a quantity is indicated (many green apples).\n\nThere are several uses for the dative case (\"Dativus\"):\n\nIn addition to its main function as the \"dativus\", the dative case has other functions in Classical Greek: (The chart below uses the Latin names for the types of dative; the Greek name for the dative is δωτική πτώση, like its Latin equivalent, derived from the verb \"to give\"; in Ancient Greek, δίδωμι.)\n\nThe articles in the Greek dative are\nThe dative case, strictly speaking, no longer exists in Modern Greek, except in fossilized expressions like δόξα τω Θεώ (from the ecclesiastical τῷ Θεῷ δόξα, \"Glory to God\") or εν τάξει (ἑν τάξει, lit. \"in order\", i.e. \"all right\" or \"OK\"). Otherwise, most of the functions of the dative have been subsumed in the accusative.\n\nIn Russian, the dative case is used for indicating the indirect object of an action (that to which something is given, thrown, read, etc.). In the instance where a person is the goal of motion, dative is used instead of accusative to indicate motion toward. This is usually achieved with the preposition \"κ\" + destination in dative case; \"К врачу\", meaning \"to the doctor.\"\n\nDative is also the necessary case taken by certain prepositions when expressing certain ideas. For instance, when the preposition \"по\" is used to mean \"along,\" its object is always in dative case, as in \"По бокам\", meaning \"along the sides.\"\n\nOther Slavic languages apply the dative case (and the other cases) more or less the same way as does Russian; some languages may use the dative in other ways. The following examples are from Polish:\n\n\nSome other kinds of dative use as found in the Serbo-Croatian language are: \"Dativus finalis\" (Titaniku u pomoć \"to Titanic's rescue\"), \"Dativus commodi/incommodi\" (Operi svojoj majci suđe \"Wash the dishes for your mother\"), \"Dativus possessivus\" (Ovcama je dlaka gusta \"Sheep's hair is thick\"), \"Dativus ethicus\" (Šta mi radi Boni? \"What is Boni doing? (I am especially interested in what it is)\") and Dativus auctoris (Izgleda mi okej \"It seems okay to me\").\n\nUnusual in other Indo-European branches but common among Slavic languages, endings of nouns and adjectives are different based on grammatical function. Other factors are gender and number. In some cases, the ending may not be obvious, even when those three factors (function, gender, number) are considered. For example, in Polish, 'syn' (\"son\") and 'ojciec' (\"father\") are both masculine singular nouns, yet appear as \"syn → synowi and \"ojciec → ojcu in the dative.\n\nBoth Lithuanian and Latvian have a distinct dative case in the system of nominal declensions.\n\nLithuanian nouns preserve Indo-European inflections in the dative case fairly well: (o-stems) vaikas -> sg. vaikui, pl. vaikams; (ā-stems) ranka -> sg. rankai, pl. rankoms; (i-stems) viltis -> sg. vilčiai, pl. viltims; (u-stems) sūnus -> sg. sūnui, pl. sūnums; (consonant stems) vanduo -> sg. vandeniui, pl. vandenims.\n\nAdjectives in the dative case receive pronominal endings (this might be the result of a more recent development): tas geras vaikas -> sg. tam geram vaikui, pl. tiems geriems vaikams.\n\nThe dative case in Latvian underwent further simplifications - the original masculine endings of \"both\" nouns and adjectives have been replaced with pronominal inflections: tas vīrs -> sg. tam vīram, pl. vīriem. Also, the final \"s\" in all Dative forms has been dropped. The only exception is personal pronouns in the plural: mums (to us), jums (to you). Note that in colloquial Lithuanian the final \"s\" in the dative is often omitted, as well: time geriem vaikam.\n\nIn both Latvian and Lithuanian, the main function of the dative case is to render the indirect object in a sentence: (lt) aš duodu vyrui knygą; (lv) es dodu [duodu] vīram grāmatu - \"I am giving a book to the man\".\n\nThe dative case can also be used with gerundives to indicate an action preceding or simultaneous with the main action in a sentence: (lt) jam įėjus, visi atsistojo - \"when he walked in, everybody stood up\", lit. \"to him having walked in, all stood up\"; (lt) jai miegant, visi dirbo - \"while she slept, everybody was working\", lit. \"to her sleeping, all were working\".\n\nIn modern standard Lithuanian, Dative case is not required by prepositions, although in many dialects it is done frequently: (dial.) iki (+D) šiai dienai, (stand.) iki (+G) šios dienos - \"up until this day\".\n\nIn Latvian, the dative case is taken by several prepositions in the singular and all prepositions in the plural (due to peculiar historical changes): sg. bez (+G) tevis \"(without thee)\" ~ pl. bez (+D) jums \"(without you)\"; sg. pa (+A) ceļu \"(along the road)\" ~ pl. pa (+D) ceļiem \"(along the roads)\".\n\nIn modern Eastern Armenian, the dative is attained by adding any article to the genitive:\n\n\"dog\" = շուն\n\nGEN > շան \"(of the dog; dog's)\" with no articles\n\nDAT > շանը or շանն \"(to the dog)\" with definite articles (-ն if preceding a vowel)\n\nDAT > մի շան \"(to a dog)\" with indefinite article\n\nDAT > շանս \"(to my dog)\" with 1st person possessive article\n\nDAT > շանդ \"(to your dog)\" with 2nd person possessive article\n\nThere is a general tendency to view -ին as the standard dative suffix, but only because that is its most productive (and therefore common) form. The suffix -ին as a dative marker is nothing but the standard, most common, genitive suffix -ի accompanied by the definite article -ն. But the dative case encompasses indefinite objects as well, which will not be marked by -ին:\n\nDefinite DAT > Ես գիրքը տվեցի տղային: \"(I gave the book to the boy)\"\n\nIndefinite DAT> Ես գիրքը տվեցի մի տղայի: \"(I gave the book to a boy)\"\n\nThe main function of the dative marking in Armenian is to indicate the receiving end of an action, more commonly the indirect object which in English is preceded by the preposition \"to\". In the use of \"giving\" verbs like \"give, donate, offer, deliver, sell, bring...\" the dative marks the recipient. With communicative verbs like \"tell, say, advise, explain, ask, answer...\" the dative marks the listener. Other verbs whose indirect objects are marked by the dative case in Armenian are \"show, reach, look, approach...\"\n\nEastern Armenian also uses the dative case to mark the time of an event, in the same way English uses the preposition \"at\", as in \"Meet me at nine o' clock.\"\n\nThe dative case is known as the \"fourth case\" (chaturthi-vibhakti) in the usual procedure in the declension of nouns. Its use is mainly for the indirect object.\n\nAs with many other languages, the dative case is used in Hungarian to show the indirect object of a verb. For example, \"Dánielnek adtam ezt a könyvet\" (I gave this book to Dániel).\n\nIt has two suffixes, \"-nak\" and \"-nek\"; the correct one is selected by vowel harmony. The personal dative pronouns follow the \"-nek\" version: \"nekem\", \"neked\", etc.\n\nThis case is also used to express \"for\" in certain circumstances, such as \"I bought a gift for Mother\".\n\nIn possessive constructions the nak/nek endings are also used but this is NOT the dative form (rather, the attributive or possessive case)\n\nFinnish does not have a separate dative case. However, the allative case can fulfill essentially the same role as dative, beyond its primary meaning of directional movement (that is, going somewhere or approaching someone). For example: \"He lahjoittivat kaikki rahansa köyhille (They donated all their money to the poor.)\n\nIn the Northeast Caucasian languages, such as Tsez, the dative also takes the functions of the lative case in marking the direction of an action. By some linguists, they are still regarded as two separate cases in those languages, although the suffixes are exactly the same for both cases. Other linguists list them separately only for the purpose of separating syntactic cases from locative cases. An example with the ditransitive verb \"show\" (literally: \"make see\") is given below:\n\nThe dative/lative is also used to indicate possession, as in the example below, because there is no such verb as \"to have\".\nAs in the examples above, the dative/lative case usually occurs in combination with another suffix as poss-lative case; this should not be regarded as a separate case, however, as many of the locative cases in Tsez are constructed analytically; hence, they are, in fact, a combination of two case suffixes. See Tsez language#Locative case suffixes for further details.\n\nVerbs of perception or emotion (like \"see\", \"know\", \"love\", \"want\") also require the logical subject to stand in the dative/lative case. Note that in this example the \"pure\" dative/lative without its POSS-suffix is used.\n\n\n"}
{"id": "8407", "url": "https://en.wikipedia.org/wiki?curid=8407", "title": "Dodecahedron", "text": "Dodecahedron\n\nIn geometry, a dodecahedron (Greek , from \"dōdeka\" \"twelve\" + \"hédra\" \"base\", \"seat\" or \"face\") is any polyhedron with twelve flat faces. The most familiar dodecahedron is the regular dodecahedron, which is a Platonic solid. There are also three regular star dodecahedra, which are constructed as stellations of the convex form. All of these have icosahedral symmetry, order 120.\n\nThe pyritohedron, a common crystal form in pyrite, is an irregular pentagonal dodecahedron, having the same topology as the regular one but pyritohedral symmetry while the tetartoid has tetrahedral symmetry. The rhombic dodecahedron, seen as a limiting case of the pyritohedron, has octahedral symmetry. The elongated dodecahedron and trapezo-rhombic dodecahedron variations, along with the rhombic dodecahedra, are space-filling. There are a large number of other dodecahedra.\n\nThe convex regular dodecahedron is one of the five regular Platonic solids and can be represented by its Schläfli symbol {5, 3}.\n\nThe dual polyhedron is the regular icosahedron {3, 5}, having five equilateral triangles around each vertex.\nThe convex regular dodecahedron also has three stellations, all of which are regular star dodecahedra. They form three of the four Kepler–Poinsot polyhedra. They are the small stellated dodecahedron {5/2, 5}, the great dodecahedron {5, 5/2}, and the great stellated dodecahedron {5/2, 3}. The small stellated dodecahedron and great dodecahedron are dual to each other; the great stellated dodecahedron is dual to the great icosahedron {3, 5/2}. All of these regular star dodecahedra have regular pentagonal or pentagrammic faces. The convex regular dodecahedron and great stellated dodecahedron are different realisations of the same abstract regular polyhedron; the small stellated dodecahedron and great dodecahedron are different realisations of another abstract regular polyhedron.\n\nIn crystallography, two important dodecahedra can occur as crystal forms in some symmetry classes of the cubic crystal system that are topologically equivalent to the regular dodecahedron but less symmetrical: the pyritohedron with pyritohedral symmetry, and the tetartoid with tetrahedral symmetry:\nA pyritohedron is a dodecahedron with pyritohedral (T) symmetry. Like the regular dodecahedron, it has twelve identical pentagonal faces, with three meeting in each of the 20 vertices. However, the pentagons are not constrained to be regular, and the underlying atomic arrangement has no true fivefold symmetry axes. Its 30 edges are divided into two sets – containing 24 and 6 edges of the same length. The only axes of rotational symmetry are three mutually perpendicular twofold axes and four threefold axes.\n\nAlthough regular dodecahedra do not exist in crystals, the pyritohedron form occurs in the crystals of the mineral pyrite, and it may be an inspiration for the discovery of the regular Platonic solid form. The true regular dodecahedron can occur as a shape for quasicrystals (such as holmium–magnesium–zinc quasicrystal) with icosahedral symmetry, which includes true fivefold rotation axes.\n\nIts name comes from one of the two common crystal habits shown by pyrite, the other one being the cube.\n\nThe coordinates of the eight vertices of the original cube are:\n\nThe coordinates of the 12 vertices of the cross-edges are:\n\nwhere \"h\" is the height of the wedge-shaped \"roof\" above the faces of the cube. When \"h\" = 1, the six cross-edges degenerate to points and a rhombic dodecahedron is formed. When \"h\" = 0, the cross-edges are absorbed in the facets of the cube, and the pyritohedron reduces to a cube. When \"h\" = , the multiplicative inverse of the golden ratio, the result is a regular dodecahedron. When \"h\" = , the conjugate of this value, the result is a regular great stellated dodecahedron.\n\nA reflected pyritohedron is made by swapping the nonzero coordinates above. The two pyritohedra can be superimposed to give the compound of two dodecahedra. The image to the left shows the case where the pyritohedra are convex regular dodecahedra.\n\nThe pyritohedron has a geometric degree of freedom with limiting cases of a cubic convex hull at one limit of colinear edges, and a rhombic dodecahedron as the other limit as 6 edges are degenerated to length zero. The regular dodecahedron represents a special intermediate case where all edges and angles are equal.\n\nA tetartoid (also tetragonal pentagonal dodecahedron, pentagon-tritetrahedron, and tetrahedric pentagon dodecahedron) is a dodecahedron with chiral tetrahedral symmetry (T). Like the regular dodecahedron, it has twelve identical pentagonal faces, with three meeting in each of the 20 vertices. However, the pentagons are not regular and the figure has no fivefold symmetry axes.\n\nAlthough regular dodecahedra do not exist in crystals, the tetartoid form does. The name tetartoid comes from the Greek root for one-fourth because it has one fourth of full octahedral symmetry, and half of pyritohedral symmetry. The mineral cobaltite can have this symmetry form.\nIts topology can be as a cube with square faces bisected into 2 rectangles like the pyritohedron, and then the bisection lines are slanted retaining 3-fold rotation at the 8 corners.\n\nThe following points are vertices of a tetartoid pentagon under tetrahedral symmetry:\nunder the following conditions:\n\nIt can be seen as a tetrahedron, with edges divided into 3 segments, along with a center point of each triangular face. In Conway polyhedron notation it can be seen as gT, a gyro tetrahedron.\n\nA lower symmetry form of the regular dodecahedron can be constructed as the dual of a polyhedra constructed from two triangular anticupola connected base-to-base, called a \"triangular gyrobianticupola.\" It has D symmetry, order 12. It has 2 sets of 3 identical pentagons on the top and bottom, connected 6 pentagons around the sides which alternate upwards and downwards. This form has a hexagonal cross-section and identical copies can be connected as a partial hexagonal honeycomb, but all vertices will not match.\n\nThe \"rhombic dodecahedron\" is a zonohedron with twelve rhombic faces and octahedral symmetry. It is dual to the quasiregular cuboctahedron (an Archimedean solid) and occurs in nature as a crystal form. The rhombic dodecahedron packs together to fill space.\n\nThe \"rhombic dodecahedron\" can be seen as a degenerate pyritohedron where the 6 special edges have been reduced to zero length, reducing the pentagons into rhombic faces.\n\nThe rhombic dodecahedron has several stellations, the first of which is also a parallelohedral spacefiller.\n\nAnother important rhombic dodecahedron, the Bilinski dodecahedron, has twelve faces congruent to those of the rhombic triacontahedron, i.e. the diagonals are in the ratio of the golden ratio. It is also a zonohedron and was described by Bilinski in 1960. This figure is another spacefiller, and can also occur in non-periodic spacefillings along with the rhombic triacontahedron, the rhombic icosahedron and rhombic hexahedra.\n\nThere are 6,384,634 topologically distinct \"convex\" dodecahedra, excluding mirror images—the number of vertices ranges from 8 to 20. (Two polyhedra are \"topologically distinct\" if they have intrinsically different arrangements of faces and vertices, such that it is impossible to distort one into the other simply by changing the lengths of edges or the angles between edges or faces.)\n\nTopologically distinct dodecahedra (excluding pentagonal and rhombic forms)\n\n\n"}
{"id": "8408", "url": "https://en.wikipedia.org/wiki?curid=8408", "title": "Darwin, Northern Territory", "text": "Darwin, Northern Territory\n\nDarwin ( ) is the capital city of the Northern Territory of Australia, situated on the Timor Sea. It is the largest city in the sparsely populated Northern Territory, with a population of 145,916. It is the smallest and most northerly of the Australian capital cities, and acts as the Top End's regional centre.\n\nDarwin's proximity to South East Asia makes it a link between Australia and countries such as Indonesia and East Timor. The Stuart Highway begins in Darwin, extends southerly across central Australia through Tennant Creek and Alice Springs, concluding in Port Augusta, South Australia. The city is built upon a low bluff overlooking the harbour. Its suburbs begin at Lee Point in the north and stretch to Berrimah in the east. Past Berrimah, the Stuart Highway goes on to Darwin's satellite city Palmerston and its suburbs. \n\nThe Darwin region, like much of the Top End, experiences a tropical climate with a wet and dry season. A period known locally as \"the build up\" leading up to Darwin's wet season sees temperature and humidity increase. Darwin's wet season typically arrives in late November to early December and brings with it heavy monsoonal downpours, spectacular lightning displays, and increased cyclone activity. During the dry season, the city has clear skies and mild sea breezes from the harbour.\n\nThe greater Darwin area is the ancestral home of the Larrakia people. On 9 September 1839, sailed into Darwin harbour during its survey of the area. John Clements Wickham named the region \"Port Darwin\" in honour of their former shipmate Charles Darwin, who had sailed with them on the ship's previous voyage which ended in October 1836. The settlement there became the town of Palmerston in 1869, but it was renamed Darwin in 1911. The city has been almost entirely rebuilt four times, following devastation caused by the 1897 cyclone, the 1937 cyclone, Japanese air raids during World War II, and Cyclone Tracy in 1974.\n\nThe Aboriginal people of the Larrakia language group are the traditional custodians and the first inhabitants of the greater Darwin area. They had trading routes with Southeast Asia (see Macassan contact with Australia), and imported goods from as far afield as South and Western Australia. Established songlines penetrated throughout the country, allowing stories and histories to be told and retold along the routes. The extent of shared songlines and history of multiple clan groups within this area is still contestable.\n\nThe Dutch visited Australia's northern coastline in the 1600s and landed on the Tiwi Islands only to be repelled by the Tiwi peoples. The Dutch created the first European maps of the area. This accounts for the Dutch names in the area, such as Arnhem Land and Groote Eylandt. The first British person to see Darwin harbour appears to have been Lieutenant John Lort Stokes of on 9 September 1839. The ship's captain, Commander John Clements Wickham, named the port after Charles Darwin, the British naturalist who had sailed with them both on the earlier second expedition of the \"Beagle\".\n\nIn 1863, the Northern Territory was transferred from New South Wales to South Australia. In 1864 South Australia sent B. T. Finniss north as Government Resident to survey and found a capital for its new territory. Finniss chose a site at Escape Cliffs, near the entrance to Adelaide River, about northeast of the modern city. This attempt was short-lived, however, and the settlement abandoned by 1865. On 5 February 1869, George Goyder, the Surveyor-General of South Australia, established a small settlement of 135 people at Port Darwin between Fort Hill and the escarpment. Goyder named the settlement Palmerston, after the British Prime Minister Lord Palmerston. In 1870, the first poles for the Overland Telegraph were erected in Darwin, connecting Australia to the rest of the world. The discovery of gold by employees of the Australian Overland Telegraph Line digging holes for telegraph poles at Pine Creek in the 1880s spawned a gold rush which further boosted the young colony's development.\n\nIn February 1872 the brigatine \"Alexandra\" was the first private vessel to set sail from an English port directly to Darwin, carrying people many of whom were coming to recent gold finds.\n\nIn early 1875 Darwin's white population had grown to approximately 300 because of the gold rush. On 17 February 1875 the left Darwin \"en route\" for Adelaide. The approximately 88 passengers and 34 crew (surviving records vary) included government officials, circuit-court judges, Darwin residents taking their first furlough, and miners. While travelling south along the north Queensland coast, the \"Gothenburg\" encountered a cyclone-strength storm and was wrecked on a section of the Great Barrier Reef. Only 22 men survived, while between 98 and 112 people perished. Many passengers who perished were Darwin residents and news of the tragedy severely affected the small community, which reportedly took several years to recover.\n\nIn the 1870s, relatively large numbers of Chinese settled at least temporarily in the Northern Territory; many were contracted to work the goldfields and later to build the Palmerston to Pine Creek railway. By 1888 there were 6122 Chinese in the Northern Territory, mostly in or around Darwin. The early Chinese settlers were mainly from the Kwantung Province in south China. However at the end of the nineteenth century anti-Chinese feelings grew in response to the 1890s economic depression and the White Australia policy meant many Chinese left the Territory. However, some families stayed and became Australian citizens, and established a commercial base in Darwin.\n\nDarwin became the city's official name in 1911.\n\nThe period between 1911 and 1919 was filled with political turmoil, particularly with trade union unrest, which culminated on 17 December 1918. Led by Harold Nelson, some 1000 demonstrators marched to Government House at Liberty Square in Darwin where they burnt an effigy of the Administrator of the Northern Territory John Gilruth and demanded his resignation. The incident became known as the 'Darwin Rebellion'. Their grievances were against the two main Northern Territory employers: Vestey's Meatworks and the federal government. Both Gilruth and the Vestey company left Darwin soon afterwards.\n\nAround 10,000 Australian and other Allied troops arrived in Darwin at the outset of World War II, in order to defend Australia's northern coastline. On 19 February 1942 at 0957, 188 Japanese warplanes attacked Darwin in two waves. It was the same fleet that had bombed Pearl Harbor, though a considerably larger number of bombs were dropped on Darwin than on Pearl Harbor. The attack killed at least 243 people and caused immense damage to the town, airfields and aircraft. These were by far the most serious attacks on Australia in time of war, in terms of fatalities and damage. They were the first of many raids on Darwin.\nDarwin was further developed after the war, with sealed roads constructed connecting the region to Alice Springs to the south and Mount Isa to the south-east, and Manton Dam built in the south to provide the city with water. On Australia Day (26 January) 1959, Darwin was granted city status.\n\nOn 25 December 1974, Darwin was struck by Cyclone Tracy, which killed 71 people and destroyed over 70% of the city's buildings, including many old stone buildings such as the Palmerston Town Hall, which could not withstand the lateral forces generated by the strong winds. After the disaster, 30,000 people of the population of 46,000 were evacuated, in what turned out to be the biggest airlift in Australia's history. The town was subsequently rebuilt with newer materials and techniques during the late 1970s by the Darwin Reconstruction Commission, led by former Brisbane Lord mayor Clem Jones. A satellite city of Palmerston was built east of Darwin in the early 1980s.\n\nOn 17 September 2003 the Adelaide–Darwin railway was completed, with the opening of the Alice Springs-Darwin standard gauge line.\n\nDarwin has played host to many of aviation's early pioneers. On 10 December 1919 Captain Ross Smith and his crew landed in Darwin and won a £10,000 Prize from the Australian Government for completing the first flight from London to Australia in under thirty days. Smith and his Crew flew a Vickers Vimy, G-EAOU and landed on an airstrip that has now become Ross Smith Avenue.\n\nOther aviation pioneers include Amy Johnson, Amelia Earhart, Sir Charles Kingsford Smith and Bert Hinkler. The original QANTAS Empire Airways Ltd Hangar, a registered heritage site, was part of the original Darwin Civil Aerodrome in Parap and is now a museum and still bears scars from the bombing of Darwin during World War II.\n\nDarwin was home to Australian and US pilots during the war, with air strips being built in and around Darwin. Today Darwin provides a staging ground for military exercises.\n\nDarwin was a compulsory stop over/check point in the London to Melbourne Centenary Air Race in 1934. The official name of the race was the MacRobertson Air Race. Winners of the great race were Tom Campbell Black and C. W. A. Scott.\n\nThe following is an excerpt from \"Time\" magazine, 29 October 1934, Volume XXIV, Number 18.\n\nThe Australian Aviation Heritage Centre is located approximately from the City centre on the Stuart Highway and is one of only two places outside the United States where a B-52 bomber (on permanent loan from the United States Air Force) is on public display.\nDarwin lies in the Northern Territory, on the Timor Sea. The city proper occupies a low bluff overlooking Darwin Harbour, flanked by Frances Bay to the east and Cullen Bay to the west. The remainder of the city is flat and low-lying, and coastal areas are home to recreational reserves, extensive beaches, and excellent fishing.\n\nDarwin and its suburbs spread in an approximately triangular shape, with the older south-western suburbs—and the city itself—forming one corner, the newer northern suburbs another, and the eastern suburbs, progressing towards Palmerston, forming the third.\n\nThe older part of Darwin is separated from the newer northern suburbs by Darwin International Airport and RAAF Base Darwin. Palmerston is a satellite city east of Darwin that was established in the 1980s and is one of the fastest growing municipalities in Australia. The rural areas of Darwin including Howard Springs, Humpty Doo and Berry Springs are experiencing strong growth.\n\nDarwin's CBD is bounded by Daly Street in the north-west, McMinn Street in the north-east, Mitchell Street on the south-west and Bennett Street on the south-east. The CBD has been the focus of a number of major projects, including the billion dollar redevelopment of the Stokes Hill wharf waterfront area including a convention centre with seating for 1500 people and approximately of exhibition space. The developers have announced that this will include hotels, residential apartments, and public space. The city's main industrial areas are along the Stuart Highway going towards Palmerston, centred on Winnellie. The largest shopping precinct in the area is Casuarina Square.\n\nThe most expensive residential areas stand along the coast in suburbs such as the marina of Cullen Bay part of Larrakeyah, Bayview and Brinkin, despite the risk these low-lying regions face during cyclones and higher tides, adequate drainage and stringent building regulations have reduced the potential damage to buildings or injury to residents. The inner northern suburbs are home to lower-income households, although low-income Territory Housing units are scattered throughout the metropolitan area. The suburb of Lyons was part of a multi-stage land release and development in the Northern Suburbs; planning, development and construction took place from 2004 to 2009. More recent developments near Lyons subdivision includes the suburb of Muirhead.\n\nDarwin has a tropical savanna climate (Köppen \"Aw\") with distinct wet and dry seasons and the average maximum temperature is similar all year round. The dry season runs from about May to September, during which nearly every day is sunny, and afternoon relative humidity averages around 30%.\n\nThe driest period of the year, seeing only approximately of monthly rainfall on average, is between May and September. In the coolest months of June and July, the daily minimum temperature may dip as low as , but very rarely lower, and a temperature lower than has never been recorded in the city centre. Outer suburbs away from the coast, however, can occasionally record temperatures as low as in the dry season. For an exceedingly lengthy 147‑day period during the 2012 dry season, from 5 May to 29 September, Darwin recorded no precipitation whatsoever. Prolonged periods of no precipitation are common in the dry season in Northern Australia (particularly in the Northern Territory and northern regions of Western Australia) although a no-rainfall event of this extent is rare. The 3pm dewpoint average in the wet season is at around .\n\nExtreme temperatures at the Darwin Post Office Station have ranged from on 17 October 1892 to on 25 June 1891; while extreme temperatures at the Darwin Airport station (which is further from the coast and routinely records cooler temperatures than the post office station which is located in Darwin's CBD) have ranged from on 18 October 1982 to on 29 July 1942. The highest minimum temperature on record is on 18 January 1928 for the post office station and on both 25 November 1987 and 17 December 2014 for the airport station; while the lowest maximum temperature on record is on 3 June 1904 for the post office station and on 14 July 1968 for the airport station.\n\nThe wet season is associated with tropical cyclones and monsoon rains. The majority of rainfall occurs between December and March (the southern hemisphere summer), when thunderstorms are common and afternoon relative humidity averages over 70 percent during the wettest months. It does not rain every day during the wet season, but most days have plentiful cloud cover; January averages under 6 hours of bright sunshine daily. Darwin's highest Bureau of Meteorology verified daily rainfall total is , which fell when Cyclone Carlos bore down on the Darwin area on 16 February 2011. February 2011 was also Darwin's wettest month ever recorded, with recorded for the month at the airport.\n\nThe hottest month is November, just before the onset of the main rain season. The heat index sometimes rises above , while the actual temperature is usually below , because of humidity levels that most would find uncomfortable. Because of its long dry season, Darwin has the second most daily average sunshine hours (8.4) of any Australian capital with the most sunshine from April to November; only Perth, Western Australia averages more (8.8). The sun passes directly overhead in mid October and mid February.\n\nThe average temperature of the sea ranges from in July to in December.\n\nDarwin occupies one of the most lightning-prone areas in Australia. On 31 January 2002 an early-morning squall line produced over 5,000 cloud-to-ground lightning strikes within a radius of Darwin alone – about three times the amount of lightning that Perth, Western Australia, experiences on average in an entire year.\n\nIn 2006, the largest ancestry groups in Darwin were Australian (42,221 or 36.9%), English (29,766 or 26%), Indigenous Australians (10,259 or 9.7%), Irish (9,561 or 8.3%), Scottish (7,815 or 6.8%), Chinese (3,502 or 3%), Greek (2,828 or 2.4%), and Italian (2,367 or 2%).\n\nDarwin's population is notable for the highest proportional population of Indigenous Australians of any Australian capital city. In the 2006 census, 10,259 (9.7 per cent) of Darwin's population was Aboriginal.\n\nDarwin's population changed after the Second World War. Darwin, like many other Australian cities, experienced influxes from Europe, with significant numbers of Italians and Greeks during the 1960s and 1970s. Darwin also started to experience an influx from other European countries, which included the Dutch, Germans, and many others. A significant percentage of Darwin's residents are recent immigrants from South East Asia (Asian Australians were 9.3% of Darwin's population in 2001).\n\nDarwin's population comprises people from many ethnic backgrounds. The 2006 Census revealed that the most common places of birth for overseas migrants were the United Kingdom (3.4 per cent), New Zealand (2.1 per cent), the Philippines (1.4 per cent) and East Timor (0.9 per cent). 18.3 percent of the city's population was born overseas, which is less than the Australian average of 22%.\n\nDarwin has a youthful population with an average age of 33 years (compared to the national average of around 37 years) assisted to a large extent by the military presence and the fact that many people opt to retire elsewhere.\n\nThe most common languages spoken in Darwin after English are Greek, Australian Aboriginal languages, Italian, Indonesian, Vietnamese and Cantonese.\n\nChristianity has the most adherents in Darwin, with 56,613 followers accounting for 49.5 per cent of the population of the city. The largest denominations of Christianity are Roman Catholicism (24,538 or 21.5 per cent), Anglicanism (14,028 or 12.3 per cent) and Greek Orthodoxy (2,964 or 2.6 per cent). Buddhists, Muslims, Hindus and Jews account for 3.2 per cent of Darwin's population. There were 26,695 or 23.3 per cent of people professing no religion.\n\nDarwin is one of the fastest growing capital cities in Australia, with an annual growth rate of 2.6 per cent since the 2006 census. In recent years, the Palmerston and Litchfield parts of the Darwin statistical division have recorded the highest growth in population of any Northern Territory local government area and by 2016 Litchfield could overtake Palmerston as the second largest municipality in metropolitan Darwin. It is predicted by 2021 that the combined population of both Palmerston and Litchfield would be 101,546 people.\n\nThe Darwin City Council (Incorporated under the Northern Territory Local Government Act 1993) governs the City of Darwin which takes in the CBD and the suburbs. The Darwin City Council has governed the City of Darwin since 1957. The Darwin City Council consists of 13 elected members, the Lord Mayor and 12 aldermen.\n\nThe City of Darwin electorate is organised into four electoral units or wards. The names of the wards are Chan, Lyons, Richardson, and Waters. The constituents of each ward are directly responsible for electing three aldermen. Constituents of all wards are directly responsible for electing the Lord Mayor of Darwin. The mayor is Kon Vatskalis after council elections in August 2017.\n\nThe rest of the Darwin area is divided into 2 local government areas—the Palmerston City Council and the Shire of Coomalie. These areas have elected councils which are responsible for functions delegated to them by the Northern Territory Government, such as planning and garbage collection.\n\nThe Legislative Assembly of the Northern Territory convenes in Darwin in the Northern Territory Parliament House. Government House, the official residence of the Administrator of the Northern Territory, is located on The Esplanade.\n\nAlso located on the Esplanade is the Supreme Court of the Northern Territory. Darwin has a Magistrate's Court which is also located on the corner of Cavenagh and Bennett Streets quite close to the Darwin City Council Chambers.\n\nDarwin's police force are members of the Northern Territory Police Force. Darwin's Mitchell Street, with its numerous pubs, clubs and other entertainment venues, is policed by the CitySafe Unit. The CitySafe unit was recently credited with reducing violent crime in and around Darwin City. Darwin has a long record of alcohol abuse and violent crime with 6,000 assaults in 2009, of which 350 resulted in broken jaws and noses – more than anywhere else in the world, according to the Royal Darwin Hospital.\n\nDarwin is split between nine electoral divisions in the Legislative Assembly—Port Darwin, Fannie Bay, Fong Lim, Nightcliff, Sanderson, Johnston, Casuarina, Wanguri, and Karama. Historically, Darwin voters elected Country Liberal Party members. However, since the turn of the 21st century, voters have often selected Labor members, particularly in the more diverse northern section.\n\nThe two largest economic sectors are mining and tourism. Given its location, Darwin serves as a \"gateway\" for Australian travellers to Asia.\n\nMining and energy industry production exceeds $2.5 billion per annum. The most important mineral resources are gold, zinc and bauxite, along with manganese and many others. The energy production is mostly off shore with oil and natural gas from the Timor Sea, although there are significant uranium deposits near Darwin. Tourism employs 8% of Darwin residents, and is expected to grow as domestic and international tourists are now spending time in Darwin during the Wet and Dry seasons. Federal spending is also a major contributor to the local economy.\n\nDarwin's importance as a port is expected to grow, due to the increased exploitation of petroleum in the nearby Timor Sea, and to the completion of the railway link and continued expansion in trade with Asia.\nDuring 2005, a number of major construction projects started in Darwin. One is the redevelopment of the Wharf Precinct, which includes a large convention and exhibition centre, apartment housing including Outrigger Pandanas and Evolution on Gardiner, retail and entertainment outlets including a large wave pool and safe swimming lagoon. The Chinatown project has also started with plans to construct Chinese-themed retail and dining outlets.\n\nTourism is one of Darwin's largest industries. Tourism is a major industry and employment sector for the Northern Territory.\nIn 2005/06, 1.38 million people visited the Northern Territory. They stayed for 9.2 million nights and spent over $1.5 billion.\nThe tourism industry directly employed 8,391 Territorians in June 2006 and when indirect employment is included, tourism typically accounts for more than 14,000 jobs across the Territory.\n\nDarwin is a hub for tours to Kakadu National Park, Litchfield National Park and Katherine Gorge.\nThe Territory is traditionally divided into the wet and dry, but there are up to six traditional seasons in Darwin.\nIt is warm and sunny from May to September. Humidity rises during the green season, from October to April bringing thunderstorms and monsoonal rains which rejuvenates the landscape. Tourism is largely seasonal with most tourists visiting during the cooler dry season which runs from April to September.\n\nThe military presence that is maintained both within Darwin, and the wider Northern Territory, is a substantial source of employment. \nOn 16 November 2011, Prime Minister Julia Gillard and President Barack Obama announced that the United States would station troops in Australia for the first time since World War II. The agreement between the United States and Australia would involve a contingent of 250 Marines arriving in Darwin in 2012, with the total number rising to a maximum of 2,500 troops by 2017 on six-month rotations as well as a supporting air element including F-22 Raptors, F-35 Joint Strike Fighters and KC-135 refuelers. China and Indonesia have expressed concern about the decision. Some analysts have argued that an expanded U.S. presence could pose a threat to security.\nGillard announced that the first 200 U.S. Marines had arrived in Darwin from Hawaii on late 3 April 2012. In 2013, further news of other expansion vectors was aired in USA media, with no comment or confirmation from Australian authorities. The agreement between the two governments remains hidden from public scrutiny. Marine numbers based in Darwin increased to more than 1,150 troops by 2014.\n\nDarwin hosts biennial multi-nation exercises named \"Pitch Black\"; in 2014 this involved military personnel from Australia, New Zealand, Singapore, Thailand, United Arab Emirates, and the United States.\n\nEducation is overseen territory-wide by the Department of Education and Training (DET), whose role is to continually improve education outcomes for all students, with a focus on Indigenous students.\n\nDarwin is served by a number of public and private schools that cater to local and overseas students. Over 16,500 primary and secondary students are enrolled in schools in Darwin, with 10,524 students attending primary education, and 5,932 students attending secondary education. There are over 12,089 students enrolled in government schools and 2,124 students enrolled in independent schools.\nThere were 9,764 students attending schools in the City of Darwin area. 6,045 students attended primary schools and 3,719 students attended secondary schools. There are over 7,161 students enrolled in government schools and 1,108 students enrolled in independent schools. There are over 35 primary and pre – schools, and 12 secondary schools including both government and non-government. Most schools in the city are secular, but there are a small number of Christian, Catholic and Lutheran institutions. Students intending to complete their secondary education can work towards either the Northern Territory Certificate of Education or the International Baccalaureate (only offered at Kormilda College). Schools have been restructured into Primary, Middle and High schools since the beginning of 2007.\n\nDarwin's largest University is the Charles Darwin University, which is the central provider of tertiary education in the Northern Territory. It covers both vocational and academic courses, acting as both a university and an Institute of TAFE. There are over 5,500 students enrolled in tertiary and further education courses.\n\nOn 1 July, Territorians celebrate Territory Day. This is the only day of the year, apart from the Chinese New Year and New Year's Eve, when fireworks are permitted. In Darwin, the main celebrations occur at Mindil Beach, where a large firework display is commissioned by the government.\n\nWeekly markets include Mindil Beach Sunset Markets (Thursdays and Sundays during the dry season), Parap Market, Nightcliff Market and Rapid Creek market. Mindil Beach Sunset Markets are very popular with locals and tourists alike and feature food, souvenirs, clothes and local performing artists.\n\nThe Darwin Festival held annually, includes comedy, dance, theatre, music, film and visual art and the NT Indigenous Music Awards. Other festivals include the Glenti, which showcases Darwin's large Greek community, and India@Mindil, a similar festival held by the smaller Indian community. The Chinese New Year is also celebrated with great festivity, highlighting the Asian influence in Darwin.\n\nThe Seabreeze festival, which first started in 2005, is held on the second week of May in the suburb of Nightcliff. It offers the opportunity for local talent to be showcased and a popular event is Saturday family festivities along the Nightcliff foreshore which is one of Darwin's most popular fitness tracks.\n\nThe Speargrass Festival is held annually the week prior to July's first full moon and celebrates the alternative Top End lifestyle. The festival activities include music, screening of locally produced films, screen printing, basket weaving, sweat lodge, water slides, human pyramid, hot tub, frisbee golf, spear throwing, Kubb competition, bingo, communal organic cooking, morning yoga, meditation, greasy pig and healing circles. The festival occurs at the Speargrass property, northeast of Pine Creek.\n\nThe Darwin beer-can regatta, held in August, celebrates Darwin's love affair with beer and contestants' race boats made exclusively of beer cans. Also in Darwin during the month of August, are the Darwin Cup horse race, and the Rodeo and Mud Crab Tying Competition.\n\nThe World Solar Challenge race attracts teams from around the world, most of which are fielded by universities or corporations although some are fielded by high schools. The race has a 20-year history spanning nine races, with the inaugural event taking place in 1987.\n\nThe Royal Darwin Show is held annually in July at the Winnellie Showgrounds. Exhibitions include agriculture and livestock. Horse events. Entertainment and side shows are also included over the 3 days of the event.\n\nThe Darwin Symphony Orchestra was first assembled in 1989, and has performed throughout the Territory. The Darwin Theatre Company is a locally produced professional theatre production company, performing locally and nationally.\n\nThe Darwin Entertainment Centre is the city's main concert venue and hosts theatre and orchestral performances. Other theatres include the Darwin Convention Centre, opened in July 2008. The Darwin Convention Centre is part of the $1.1 billion Darwin Waterfront project.\n\nDarwin's only casino opened in 1979 as the \"Don Casino\" operating out of the Don Hotel on Cavenagh Street. The present site of the hotel and casino on Darwin's Mindil Beach opened in 1983 at which point gambling operations ceased at the Don Hotel and commenced at the newly built facilities. The new hotel and casino was named \"Mindil Beach Casino\" up until 1985 when the name changed to the \"Diamond Beach Hotel Casino\". Upon the acquisition by MGM Grand the hotel was re-branded as the MGM Grand Darwin, before it changed to Skycity Darwin after Skycity Entertainment Group purchased the hotel in 2004.\n\nThe Northern Territory Museum and Art Gallery (MAGNT) in Darwin gives an overview of the history of the area, including exhibits on Cyclone Tracy and the boats of the Pacific Islands. The MAGNT also organises the annual Telstra National Aboriginal and Torres Strait Islander Art Award, the longest running Indigenous art award in Australia. The MAGNT also manages the Defence of Darwin Experience, a multi-media installation that tells the story of the Japanese air raids on Darwin during World War II.\n\nThe Darwin Festival and the Darwin Fringe Festival are annual events. A range of art galleries including specialised Aboriginal art galleries are a feature of Darwin.\n\nLocal and visiting musical bands can be heard at venues including the Darwin Entertainment Centre, The Vic Hotel, Happy Yess, and Brown's Mart. A yearly music festival, Bass in the Grass, is very popular with youth from the surrounding area. Artists such as Jessica Mauboy and The Groovesmiths call Darwin home.\n\nThere have been no major films set in Darwin; however, some scenes for \"Australia\" by Baz Luhrmann and \"Black Water\" were both shot in Darwin in 2007\n\nMitchell Street in the central business district is lined with nightclubs, takeaways, and restaurants. This is the city's entertainment hub. There are several smaller theatres, three cinema complexes (CBD, Casuarina, and Palmerston), and the Deckchair Cinema. This is an open-air cinema which operates through the dry season, from April to October, and screens independent and arthouse films.\n\nThe city has many kilometres of beaches, including the Casuarina Beach and renowned Mindil Beach, home of the Mindil Beach markets. Darwin City Council has designated an area of Casuarina Beach as a free beach which has been designated as a nudist beach area since 1976.\nDuring the months of October–May the sea contains deadly box jellyfish, known locally as Stingers or Sea Wasps.\n\nSaltwater crocodiles are common in all waterways surrounding Darwin and are even occasionally found swimming in Darwin Harbour and on local beaches. An active trapping program is carried out by the NT Government to limit numbers of crocodiles within the Darwin urban waterway area.\n\nFishing is one of the recreations of Darwin locals. Visitors fish for the barramundi, an iconic fish for the region. This fish thrives in the Mary River, Daly River, South and East Alligator River.\n\nBlue-water fishing is also available off the coast of Darwin; Spanish mackerel, Black Jewfish, queenfish, and snapper are found in the area. Lake Alexander is a man-made swimming lake which is located at East Point Reserve. It has been considered crocodile and jellyfish safe. An outbreak of non-deadly jellyfish in 2003 caused its closure for a brief period of time. \n\nThe Darwin Surf Lifesaving Club operates long boats and surf skis and provides events and lifesaving accreditations.\n\nDarwin has extensive parks and gardens. These include the George Brown Darwin Botanic Gardens, East Point Reserve, Casuarina Coastal Reserve, Charles Darwin National Park, Knuckey Lagoons Conservation Reserve, Leanyer Recreation Park, the Nightcliff Foreshore, Bicentennial Park and the Jingili Water Gardens.\n\nThe Marrara Sports Complex near the airport has stadiums for Aussie Rules (TIO Stadium), cricket, rugby union, basketball (and indoor court sports), soccer, athletics and field hockey. Every two years since 1991 (excluding 2003 due to the SARS outbreak), Darwin has played host to the Arafura Games, a major regional sporting event. In July 2003, the city hosted its first international test cricket match between Australia and Bangladesh, followed by Australia and Sri Lanka in 2004.\n\nAustralian-rules football is played all year round. Melbourne's Western Bulldogs Australian Football League side plays one home game at Marrara Oval each year. The ATSIC Aboriginal All-Stars also participate in the AFL pre-season competition. In 2003, a record crowd of 17,500 attended a pre-season game between the All-Stars and Carlton Football Club at Marrara.\n\nRugby League and Rugby Union club competitions are played in Darwin each year, organised by the NTRL and NTRU respectively. The Heineken Hottest 7s in the World tournament is hosted in Darwin each January, with Rugby Sevens club teams from countries including Australia, New Zealand, Papua New Guinea, Malaysia, and Singapore competing. Darwin's Hottest 7s is the richest Rugby 7s tournament in the Southern Hemisphere.\n\nDarwin hosts a round of the Supercars Championship every year bringing thousands of motorsports fans to the Hidden Valley Raceway. Also located Hidden Valley, adjacent to the road racing circuit, is Darwin's Dirt track racing venue, Northline Speedway. The speedway has hosted a number of Australian Championships over the years for different categories including Sprintcars, Speedcars, and Super Sedans.\n\nThe Darwin Cup culminating on the first Monday of August is a very popular horse race event for Darwin and draws large crowds every year to Fannie Bay Racecourse. While it is not as popular as the Melbourne Cup, it does draw a crowd and, in 2003, Sky Racing began televising most of the races. The Darwin Cup day is a public holiday for the Northern Territory (Picnic Day public holiday).\n\nDarwin's major newspapers are the \"Northern Territory News\" (Monday – Saturday), \"The Sunday Territorian\" (Sunday), and the national daily, \"The Australian\" (Monday–Friday) and \"The Weekend Australian\" (Saturday), all published by News Limited. Free weekly community newspapers include \"Sun Newspapers\" (delivered in Darwin, Palmerston, and Litchfield), and published by the \"NT News\". Another newspaper, the \"Centralian Advocate\" (1947-present) is printed in Darwin and trucked to Alice Springs.\n\nFormer publications in (or connected to) Darwin include:\n\nFive free-to-air channels service Darwin. Commercial television channels are provided by Seven Darwin (Seven Network affiliate), Nine Darwin (formerly branded as Channel 8) and Ten Darwin (Network Ten relay), which launched on 28 April 2008. The two Government owned national broadcast services in Darwin are the ABC and SBS. Subscription Television (Pay TV) service Austar is available via cable in the Darwin region.\n\nDarwin has radio stations on both AM and FM frequencies. ABC stations include ABC News Radio (102.5FM), ABC Local Radio (105.7FM), ABC Radio National (657AM), ABC Classic FM (107.3FM) and Triple J (103.3FM). SBS (100.9FM) also broadcasts its national radio network to Darwin. Darwin has two commercial radio stations Hot 100 and Mix 104.9. Other stations in Darwin include university-based station 104.1 Territory FM, dance music station KIK FM 91.5, Italian-language channel Rete Italia 1611AM, community based stations includes Radio Larrakia 94.5 and Yolngu Radio 1530AM and Rhema FM 97.7.\n\nThe Government of the Northern Territory Department of Health and Families oversees one public hospital in the Darwin metropolitan region. The Royal Darwin Hospital, located in Tiwi, is the city's major teaching and referral hospital, and the largest in the Northern Territory.\n\nThere is one major private hospital, Darwin Private Hospital, located at Tiwi, adjacent to the Royal Darwin Hospital.\nDarwin Private Hospital is operated and owned by Healthscope Ltd, a private hospital corporation.\n\nA new hospital called Palmerston Regional Hospital was opened in August 2018 to help ease the pressure of patient numbers at the Royal Darwin Hospital.\n\nThe Territory's public transport services are managed by the Department of Lands and Planning, Public Transport Division. Darwin has a bus network serviced by a range of contracted bus operators, which provides transport to the main suburbs of Darwin.\n\nDarwin has no commuter rail system; however, long-distance passenger rail services do operate out of the city. The Alice Springs to Darwin rail line was completed in 2003 linking Darwin to Adelaide. The first service ran in 2004. The Ghan passenger train service from Adelaide via Alice Springs and Katherine runs once per week in each direction with some exceptions.\n\nDarwin International Airport, located in the suburb of Marrara, is Darwin's only airport, which shares its runways with the Royal Australian Air Force's RAAF Base Darwin.\n\nDarwin can be reached via the Stuart Highway which runs the length of the Northern Territory from Darwin through Katherine, Tennant Creek, Alice Springs and on to Adelaide. Other major roads in Darwin include, Tiger Brennan Drive, Amy Johnson Avenue, Dick Ward Drive, Bagot Road, Trower Road and McMillans Road. Bus service in the greater Darwin area is served by Darwinbus.\n\nFerries leave from Port Darwin to island locations, mainly for tourists. A ferry service to the Tiwi Islands, the \"Arafura Pearl\" operates from Cullen Bay.\n\nDarwin has a new deepwater port, East Arm Wharf, which opened in 2000. It has 754-metres of wharfline and is capable of handling Panamax-sized ships of a maximum length of 274 metres and a DWT of up to 80,000 tonnes.\n\nWater storage, supply and Power for Darwin is managed by Power and Water Corporation, which is owned by the Government of the Northern Territory. The corporation is also responsible for management of sewage and the major water catchments in the region. Water is mainly stored in the largest dam, The Darwin River Dam which holds up to 90% of Darwin's water supply. For many years, Darwin's principal water supply came from Manton Dam.\n\nDarwin, its suburbs, Palmerston and Katherine are powered by the Channel Island Power Station, the largest power plant in the Northern Territory.\n\nA new power plant, the Weddell Power Station, is near completion. The first two generators came on line in 2008–09. The third generator is due to be completed in 2011–12. When the power station is fully operational, it will add 30% capacity to Darwin's power supply.\n\n\n"}
{"id": "8409", "url": "https://en.wikipedia.org/wiki?curid=8409", "title": "Dictator", "text": "Dictator\n\nA dictator is a political leader who possesses absolute power. A state which is ruled by a dictator is called a dictatorship. The word originated as the title of a magistrate in the Roman Republic appointed by the Senate to rule the republic in times of emergency (see Roman dictator and \"justitium\").\n\nLike the term \"tyrant\" (which was originally a respectable Ancient Greek title), and to a lesser degree \"autocrat\", \"dictator\" came to be used almost exclusively as a non-titular term for oppressive, even abusive rule. Thus, in modern usage, the term \"dictator\" is generally used to describe a leader who holds or abuses an extraordinary amount of personal power. Dictatorships are often characterised by some of the following: suspension of elections and civil liberties; proclamation of a state of emergency; rule by decree; repression of political opponents; not abiding by the rule of law procedures, and cult of personality. Dictatorships are often one-party or dominant-party states.\n\nA wide variety of leaders coming to power in different kinds of regimes, such as military juntas, one-party states, dominant-party states, and civilian governments under a personal rule, have been described as dictators. They may hold left or right-wing views, or may be apolitical.\n\nOriginally an emergency legal appointment in the Roman Republic, the term \"Dictator\" did not have the negative meaning it has now. A Dictator was a magistrate given sole power for a limited duration. At the end of the term, the Dictator's power was returned to normal Consular rule whereupon a dictator provided accountability, though not all dictators accepted a return to power sharing.\n\nThe term started to get its modern negative meaning with Cornelius Sulla's ascension to the dictatorship following Sulla's second civil war, making himself the first Dictator in Rome in more than a century (during which the office was ostensibly abolished) as well as \"de facto\" eliminating the time limit and need of senatorial acclamation. He avoided a major constitutional crisis by resigning the office after about one year, dying a few years later. Julius Caesar followed Sulla's example in 49 BC and in February 44 BC was proclaimed \"Dictator perpetuo\", \"Dictator in perpetuity\", officially doing away with any limitations on his power, which he kept until his assassination the following month.\n\nFollowing Julius' assassination, his heir Augustus was offered the title of dictator, but he declined it. Later successors also declined the title of dictator, and usage of the title soon diminished among Roman rulers.\n\nAs late as the second half of the 19th century, the term \"dictator\" had occasional positive implications. For example, when creating a provisional executive in Sicily during the Expedition of the Thousand in 1860, Giuseppe Garibaldi officially assumed the title of \"Dictator\" (see Dictatorship of Garibaldi). Shortly afterwards, during the 1863 January Uprising in Poland, \"Dictator\" was also the official title of four leaders, the first being Ludwik Mierosławski. \nPast that time, however, the term \"dictator\" assumed an invariably negative connotation. In popular usage, a \"dictatorship\" is often associated with brutality and oppression. As a result, it is often also used as a term of abuse against political opponents. The term has also come to be associated with megalomania. Many dictators create a cult of personality around themselves and they have also come to grant themselves increasingly grandiloquent titles and honours. For instance, Idi Amin Dada, who had been a British army lieutenant prior to Uganda's independence from Britain in October 1962, subsequently styled himself \"\"His Excellency, President for Life, Field Marshal Al Hadji Doctor Idi Amin Dada, VC, DSO, MC, Conqueror of the British Empire in Africa in General and Uganda in Particular\"\". In the movie \"The Great Dictator\" (1940), Charlie Chaplin satirized not only Adolf Hitler but the institution of dictatorship itself.\n\nA benevolent dictatorship refers to a government in which an authoritarian leader exercises absolute political power over the state but is perceived to do so with regard for benefit of the population as a whole, standing in contrast to the decidedly malevolent stereotype of a dictator. A benevolent dictator may allow for some economic liberalization or democratic decision-making to exist, such as through public referenda or elected representatives with limited power, and often makes preparations for a transition to genuine democracy during or after their term. It might be seen as a republican form of enlightened despotism.\n\nThe label has been applied to leaders such as Mustafa Kemal Atatürk of Turkey, Josip Broz Tito of Yugoslavia, Lee Kuan Yew of Singapore, \n\nThe association between a dictator and the military is a common one; many dictators take great pains to emphasize their connections with the military and they often wear military uniforms. In some cases, this is perfectly legitimate; Francisco Franco was a lieutenant general in the Spanish Army before he became Chief of State of Spain; Manuel Noriega was officially commander of the Panamanian Defense Forces. In other cases, the association is mere pretense.\n\nSome dictators have been masters of crowd manipulation, such as Mussolini and Hitler. Others were more prosaic speakers, such as Stalin and Franco. Typically the dictator's people seize control of all media, censor or destroy the opposition, and give strong doses of propaganda daily, often built around a cult of personality.\n\nBecause of its negative associations, modern leaders very rarely (if ever) use the term \"dictator\" in their formal titles. In the 19th century, however, its official usage was more common:\nRussia during the Civil War\n\nUnder the Soviet leaders Vladimir Lenin and Joseph Stalin, government policy was enforced by extrajudicial killings, secret police (originally known as the \"Cheka\") and the notorious Gulag system of concentration camps. Most Gulag inmates were not political prisoners, although significant numbers of political prisoners could be found in the camps at any one time. Data collected from Soviet archives gives the death toll from Gulags at 1,053,829. Other human rights abuses by the Soviet state included human experimentation, the use of psychiatry as a political weapon and the denial of freedoms of religion, assembly, speech and association.\n\nPol Pot became dictator of Cambodia in 1975. In all, an estimated 1.7 million people (out of a population of 7 million) died due to the policies of his four-year dictatorship. As a result, Pol Pot is sometimes described as \"the Hitler of Cambodia\" and \"a genocidal tyrant\".\nThe International Criminal Court issued an arrest warrant for Sudan's military dictator Omar al-Bashir over alleged war crimes in Darfur.\n\nIn social choice theory, the notion of a dictator is formally defined as a person who can achieve any feasible social outcome he/she wishes. The formal definition yields an interesting distinction between two different types of dictators.\nNote that these definitions disregard some alleged dictators who are not interested in the actual achieving of social goals, as much as in propaganda and controlling public opinion. Monarchs and military dictators are also excluded from these definitions, because their rule relies on the consent of other political powers (the nobility or the army).\n\n\n\n\n"}
{"id": "8410", "url": "https://en.wikipedia.org/wiki?curid=8410", "title": "Decibel", "text": "Decibel\n\nThe decibel (symbol: dB) is a unit of measurement used to express the ratio of one value of a physical property to another on a logarithmic scale, called the level. It can be used to express a change in value (e.g., +1 dB or −1 dB) or an absolute value. In the latter case, it expresses the ratio of a value to a fixed reference value; when used in this way, a suffix that indicates the reference value is often appended to the decibel symbol. For example, if the reference value is 1 volt, then the suffix is \"V\" (e.g., \"20 dBV\"), and if the reference value is one milliwatt, then the suffix is \"m\" (e.g., \"20 dBm\").\n\nTwo different scales are used when expressing a ratio in decibels, depending on the nature of the quantities: power and field (root-power). When expressing a power ratio, the number of decibels is ten times its logarithm to base 10. That is, a change in \"power\" by a factor of 10 corresponds to a 10 dB change in level. When expressing field (root-power) quantities, a change in \"amplitude\" by a factor of 10 corresponds to a 20 dB change in level. The extra factor of two is due to the logarithm of the quadratic relationship between power and amplitude in most systems. The decibel scales differ so that the related power and field quantities change by the same number of decibels.\n\nThe definition of the decibel is based on the measurement of power in telephony of the early 20th century in the Bell System in the United States. One decibel is one tenth (deci-) of one bel, named in honor of Alexander Graham Bell; however, the bel is seldom used. Today, the decibel is used for a wide variety of measurements in science and engineering, most prominently in acoustics, electronics, and control theory. In electronics, the gains of amplifiers, attenuation of signals, and signal-to-noise ratios are often expressed in decibels.\n\nIn the International System of Quantities, the decibel is defined as a unit of measurement for quantities of type level or level difference, which are defined as the logarithm of the ratio of power- or field-type quantities.\n\nThe decibel originates from methods used to quantify signal loss in telegraph and telephone circuits. The unit for loss was originally \"Miles of Standard Cable\" (MSC). 1 MSC corresponded to the loss of power over a 1 mile (approximately 1.6 km) length of standard telephone cable at a frequency of 5000 radians per second (795.8 Hz), and matched closely the smallest attenuation detectable to the average listener. The standard telephone cable implied was \"a cable having uniformly distributed resistance of 88 Ohms per loop-mile and uniformly distributed shunt capacitance of 0.054 microfarads per mile\" (approximately corresponding to 19 gauge wire).\n\nIn 1924, Bell Telephone Laboratories received favorable response to a new unit definition among members of the International Advisory Committee on Long Distance Telephony in Europe and replaced the MSC with the \"Transmission Unit\" (TU). 1 TU was defined such that the number of TUs was ten times the base-10 logarithm of the ratio of measured power to a reference power.\nThe definition was conveniently chosen such that 1 TU approximated 1 MSC; specifically, 1 MSC was 1.056 TU. In 1928, the Bell system renamed the TU into the decibel, being one tenth of a newly defined unit for the base-10 logarithm of the power ratio. It was named the \"bel\", in honor of the telecommunications pioneer Alexander Graham Bell.\nThe bel is seldom used, as the decibel was the proposed working unit.\n\nThe naming and early definition of the decibel is described in the NBS Standard's Yearbook of 1931:\n\nIn 1954, C. W. Horton argued that the use of the decibel as a unit for quantities other than transmission loss led to confusion, and suggested the name 'logit' for \"standard magnitudes which combine by addition\".\n\nIn April 2003, the International Committee for Weights and Measures (CIPM) considered a recommendation for the inclusion of the decibel in the International System of Units (SI), but decided against the proposal. However, the decibel is recognized by other international bodies such as the International Electrotechnical Commission (IEC) and International Organization for Standardization (ISO). The IEC permits the use of the decibel with field quantities as well as power and this recommendation is followed by many national standards bodies, such as NIST, which justifies the use of the decibel for voltage ratios. The term \"field quantity\" is deprecated by ISO 80000-1, which favors root-power. In spite of their widespread use, suffixes (such as in dBA or dBV) are not recognized by the IEC or ISO.\n\nISO 80000-3 describes definitions for quantities and units of space and time. The decibel for use in acoustics is defined in . The major difference from the article below is that for acoustics the decibel has no absolute value.\n\nThe ISO Standard 80000-3:2006 defines the following quantities. The decibel (dB) is one-tenth of a bel: . The bel (B) is  ln(10) nepers: . The neper is the change in the level of a field quantity when the field quantity changes by a factor of \"e\", that is , thereby relating all of the units as nondimensional natural log of field-quantity ratios, . Finally, the level of a quantity is the logarithm of the ratio of the value of that quantity to a reference value of the same kind of quantity.\n\nTherefore, the bel represents the logarithm of a ratio between two power quantities of 10:1, or the logarithm of a ratio between two field quantities of :1.\n\nTwo signals whose levels differ by one decibel have a power ratio of 10, which is approximately 1.25893, and an amplitude (field quantity) ratio of 10 (1.12202).\n\nThe bel is rarely used either without a prefix or with SI unit prefixes other than \"deci\"; it is preferred, for example, to use \"hundredths of a decibel\" rather than \"millibels\". Thus, five one-thousandths of a bel would normally be written '0.05 dB', and not '5 mB'.\n\nThe method of expressing a ratio as a level in decibels depends on whether the measured property is a \"power quantity\" or a \"root-power quantity\"; see \"Field, power, and root-power quantities\" for details.\n\nWhen referring to measurements of \"power\" quantities, a ratio can be expressed as a level in decibels by evaluating ten times the base-10 logarithm of the ratio of the measured quantity to reference value. Thus, the ratio of \"P\" (measured power) to \"P\" (reference power) is represented by \"L\", that ratio expressed in decibels, which is calculated using the formula:\n\nThe base-10 logarithm of the ratio of the two power quantities is the number of bels. The number of decibels is ten times the number of bels (equivalently, a decibel is one-tenth of a bel). \"P\" and \"P\" must measure the same type of quantity, and have the same units before calculating the ratio. If in the above equation, then \"L\" = 0. If \"P\" is greater than \"P\" then \"L\" is positive; if \"P\" is less than \"P\" then \"L\" is negative.\n\nRearranging the above equation gives the following formula for \"P\" in terms of \"P\" and \"L\":\n\nWhen referring to measurements of field quantities, it is usual to consider the ratio of the squares of \"F\" (measured field) and \"F\" (reference field). This is because in most applications power is proportional to the square of field, and historically their definitions were formulated to give the same value for relative ratios in such typical cases. Thus, the following definition is used:\n\nThe formula may be rearranged to give\n\nSimilarly, in electrical circuits, dissipated power is typically proportional to the square of voltage or current when the impedance is constant. Taking voltage as an example, this leads to the equation for power gain level \"L\":\nwhere \"V\" is the root-mean-square (rms) output voltage, \"V\" is the rms input voltage. A similar formula holds for current.\n\nThe term \"root-power quantity\" is introduced by ISO Standard 80000-1:2009 as a substitute of \"field quantity\". The term \"field quantity\" is deprecated by that standard.\n\nSince logarithm differences measured in these units are used to represent power ratios and field ratios, the values of the ratios represented by each unit are also included in the table.\n\nThe unit dBW is often used to denote a ratio for which the reference is 1 W, and similarly dBm for a reference point.\n, illustrating the consequence from the definitions above that \"L\" has the same value, 30 dB, regardless of whether it is obtained from powers or from amplitudes, provided that in the specific system being considered power ratios are equal to amplitude ratios squared.\n\nA change in power ratio by a factor of 10 corresponds to a change in level of . A change in power ratio by a factor of 2 or is approximately a change of 3 dB. More precisely, the change is ±3.0103 dB, but this is almost universally rounded to \"3 dB\" in technical writing. This implies an increase in voltage by a factor of . Likewise, a doubling or halving of the voltage, and quadrupling or quartering of the power, is commonly described as \"6 dB\" rather than ±6.0206 dB.\n\nShould it be necessary to make the distinction, the number of decibels is written with additional significant figures. 3.000 dB is a power ratio of 10, or 1.9953, about 0.24% different from exactly 2, and a voltage ratio of 1.4125, 0.12% different from exactly . Similarly, an increase of 6.000 dB is the power ratio is , about 0.5% different from 4.\n\nThe decibel is useful for representing large ratios and for simplifying representation of multiplied effects such as attenuation from multiple sources along a signal chain. Its application in systems with additive effects is less intuitive.\n\nThe logarithmic scale nature of the decibel means that a very large range of ratios can be represented by a convenient number, in a manner similar to scientific notation. This allows one to clearly visualize huge changes of some quantity. See \"Bode plot\" and \"Semi-log plot\". For example, 120 dB SPL may be clearer than \"a trillion times more intense than the threshold of hearing\".\n\nLevel values in decibels can be added instead of multiplying the underlying power values, which means that the overall gain of a multi-component system, such as a series of amplifier stages, can be calculated by summing the gains in decibels of the individual components, rather than multiply the amplification factors; that is, = log(\"A\") + log(\"B\") + log(\"C\"). Practically, this means that, armed only with the knowledge that 1 dB is a power gain of approximately 26%, 3 dB is approximately 2× power gain, and 10 dB is 10× power gain, it is possible to determine the power ratio of a system from the gain in dB with only simple addition and multiplication. For example:\nHowever, according to its critics, the decibel creates confusion, obscures reasoning, is more related to the era of slide rules than to modern digital processing, and is cumbersome and difficult to interpret.\n\nAccording to Mitschke, \"The advantage of using a logarithmic measure is that in a transmission chain, there are many elements concatenated, and each has its own gain or attenuation. To obtain the total, addition of decibel values is much more convenient than multiplication of the individual factors.\" However, for the same reason that humans excel at additive operation over multiplication, decibels are awkward in inherently additive operations: \"if two machines each individually produce a [sound pressure] level of, say, 90 dB at a certain point, then when both are operating together we should expect the combined sound pressure level to increase to 93 dB, but certainly not to 180 dB!\"; \"suppose that the noise from a machine is measured (including the contribution of background noise) and found to be 87 dBA but when the machine is switched off the background noise alone is measured as 83 dBA. [...] the machine noise [level (alone)] may be obtained by 'subtracting' the 83 dBA background noise from the combined level of 87 dBA; i.e., 84.8 dBA.\"; \"in order to find a representative value of the sound level in a room a number of measurements are taken at different positions within the room, and an average value is calculated. [...] Compare the logarithmic and arithmetic averages of [...] 70 dB and 90 dB: logarithmic average = 87 dB; arithmetic average = 80 dB.\"\n\nAddition on a logarithmic scale is called logarithmic addition, and can be defined by taking exponentials to convert to a linear scale, adding there, and then taking logarithms to return. For example, where operations on decibels are logarithmic addition/subtraction and logarithmic multiplication/division, while operations on the linear scale are the usual operations:\nNote that the logarithmic mean is obtained from the logarithmic sum by subtracting formula_12, since logarithmic division is linear subtraction.\nQuantities in decibels are not necessarily additive, thus being \"of unacceptable form for use in dimensional analysis\".\n\nThe human perception of the intensity of sound and light approximates the logarithm of intensity rather than a linear relationship (Weber–Fechner law), making the dB scale a useful measure.\n\nThe decibel is commonly used in acoustics as a unit of sound pressure level. The reference pressure for sound in air is set at the typical threshold of perception of an average human and there are common comparisons used to illustrate different levels of sound pressure. Sound pressure is a field quantity, therefore the field version of the unit definition is used:\nwhere \"p\" is the root mean square of the measured sound pressure and \"p\" is the standard reference sound pressure of 20 micropascals in air or 1 micropascal in water.\n\nUse of the decibel in underwater acoustics leads to confusion, in part because of this difference in reference value.\n\nThe human ear has a large dynamic range in sound reception. The ratio of the sound intensity that causes permanent damage during short exposure to that of the quietest sound that the ear can hear is greater than or equal to 1 trillion (10). Such large measurement ranges are conveniently expressed in logarithmic scale: the base-10 logarithm of 10 is 12, which is expressed as a sound pressure level of 120 dB re 20 μPa.\n\nSince the human ear is not equally sensitive to all sound frequencies, noise levels at maximum human sensitivity, somewhere between 2 and 4 kHz, are factored more heavily into some measurements using frequency weighting. (See also Stevens' power law.)\n\nThe main instrument used for measuring sound levels in the environment and in the workplace is the Sound Level Meter. Most sound level meters provide readings in A, C, and Z-weighted decibels and must meet international standards such as IEC 61672-2013.\n\nAccording to Hickling, \"Decibels are a useless affectation, which is impeding the development of noise control as an engineering discipline.\"\nIn electronics, the decibel is often used to express power or amplitude ratios (as for gains) in preference to arithmetic ratios or percentages. One advantage is that the total decibel gain of a series of components (such as amplifiers and attenuators) can be calculated simply by summing the decibel gains of the individual components. Similarly, in telecommunications, decibels denote signal gain or loss from a transmitter to a receiver through some medium (free space, waveguide, coaxial cable, fiber optics, etc.) using a link budget.\n\nThe decibel unit can also be combined with a reference level, often indicated via a suffix, to create an absolute unit of electric power. For example, it can be combined with \"m\" for \"milliwatt\" to produce the \"dBm\". A power level of 0 dBm corresponds to one milliwatt, and 1 dBm is one decibel greater (about 1.259 mW).\n\nIn professional audio specifications, a popular unit is the dBu. This is relative to the root mean square voltage which delivers 1 mW (0 dBm) into a 600-ohm resistor, or ≈ 0.775 V. When used in a 600-ohm circuit (historically, the standard reference impedance in telephone circuits), dBu and dBm are identical.\n\nIn an optical link, if a known amount of optical power, in dBm (referenced to 1 mW), is launched into a fiber, and the losses, in dB (decibels), of each component (e.g., connectors, splices, and lengths of fiber) are known, the overall link loss may be quickly calculated by addition and subtraction of decibel quantities.\n\nIn spectrometry and optics, the blocking unit used to measure optical density is equivalent to −1 B.\n\nIn connection with video and digital image sensors, decibels generally represent ratios of video voltages or digitized light intensities, using 20 log of the ratio, even when the represented intensity (optical power) is directly proportional to the voltage generated by the sensor, not to its square, as in a CCD imager where response voltage is linear in intensity.\nThus, a camera signal-to-noise ratio or dynamic range quoted as 40 dB represents a ratio of 100:1 between signal intensity and noise intensity, not 10,000:1.\nSometimes the 20 log ratio definition is applied to electron counts or photon counts directly, which are proportional to sensor signal amplitude without the need to consider whether the voltage response to intensity is linear.\n\nHowever, as mentioned above, the 10 log intensity convention prevails more generally in physical optics, including fiber optics, so the terminology can become murky between the conventions of digital photographic technology and physics. Most commonly, quantities called \"dynamic range\" or \"signal-to-noise\" (of the camera) would be specified in 20 log dB, but in related contexts (e.g. attenuation, gain, intensifier SNR, or rejection ratio) the term should be interpreted cautiously, as confusion of the two units can result in very large misunderstandings of the value.\n\nPhotographers typically use an alternative base-2 log unit, the stop, to describe light intensity ratios or dynamic range.\n\nSuffixes are commonly attached to the basic dB unit in order to indicate the reference value by which the ratio is calculated. For example, dBm indicates power measurement relative to 1 milliwatt.\n\nIn cases where the unit value of the reference is stated, the decibel value is known as \"absolute\". If the unit value of the reference is not explicitly stated, as in the dB gain of an amplifier, then the decibel value is considered relative.\n\nThe SI does not permit attaching qualifiers to units, whether as suffix or prefix, other than standard SI prefixes. Therefore, even though the decibel is accepted for use alongside SI units, the practice of attaching a suffix to the basic dB unit, forming compound units such as dBm, dBu, dBA, etc., is not. The proper way, according to the IEC 60027-3, is either as \"L\" (re \"x\") or as \"L\", where \"x\" is the quantity symbol and \"x\" is the value of the reference quantity, e.g., \"L\" (re 1 μV/m) = \"L\" for the electric field strength \"E\" relative to 1 μV/m reference value.\n\nOutside of documents adhering to SI units, the practice is very common as illustrated by the following examples. There is no general rule, with various discipline-specific practices. Sometimes the suffix is a unit symbol (\"W\",\"K\",\"m\"), sometimes it is a transliteration of a unit symbol (\"uV\" instead of μV for microvolt), sometimes it is an acronym for the unit's name (\"sm\" for square meter, \"m\" for milliwatt), other times it is a mnemonic for the type of quantity being calculated (\"i\" for antenna gain with respect to an isotropic antenna, \"λ\" for anything normalized by the EM wavelength), or otherwise a general attribute or identifier about the nature of the quantity (\"A\" for A-weighted sound pressure level). The suffix is often connected with a dash (dB-Hz), with a space (dB HL), with no intervening character (dBm), or enclosed in parentheses (dB(sm)).\n\nSince the decibel is defined with respect to power, not amplitude, conversions of voltage ratios to decibels must square the amplitude, or use the factor of 20 instead of 10, as discussed above.\n\n\n\n\n\n\nProbably the most common usage of \"decibels\" in reference to sound level is dB SPL, sound pressure level referenced to the nominal threshold of human hearing: The measures of pressure (a field quantity) use the factor of 20, and the measures of power (e.g. dB SIL and dB SWL) use the factor of 10.\n\nSee also dBV and dBu above.\n\n\n\n\n\n\n\n\n\n\n\n\nAttenuation constants, in fields such as optical fiber communication and radio propagation path loss, are often expressed as a fraction or ratio to distance of transmission. dB/m represents decibel per meter, dB/mi represents decibel per mile, for example. These quantities are to be manipulated obeying the rules of dimensional analysis, e.g., a 100-meter run with a 3.5 dB/km fiber yields a loss of 0.35 dB = 3.5 dB/km × 0.1 km.\n\n\n\n"}
{"id": "8411", "url": "https://en.wikipedia.org/wiki?curid=8411", "title": "Darwinism", "text": "Darwinism\n\nDarwinism is a theory of biological evolution developed by the English naturalist Charles Darwin (1809–1882) and others, stating that all species of organisms arise and develop through the natural selection of small, inherited variations that increase the individual's ability to compete, survive, and reproduce. Also called Darwinian theory, it originally included the broad concepts of transmutation of species or of evolution which gained general scientific acceptance after Darwin published \"On the Origin of Species\" in 1859, including concepts which predated Darwin's theories. It subsequently referred to the specific concepts of natural selection, the Weismann barrier, or the central dogma of molecular biology. Though the term usually refers strictly to biological evolution, creationists have appropriated it to refer to the origin of life, and it has even been applied to concepts of cosmic evolution, both of which have no connection to Darwin's work. It is therefore considered the belief and acceptance of Darwin's and of his predecessors' work—in place of other theories, including divine design and extraterrestrial origins.\n\nEnglish biologist Thomas Henry Huxley coined the term \"Darwinism\" in April 1860. It was used to describe evolutionary concepts in general, including earlier concepts published by English philosopher Herbert Spencer. Many of the proponents of Darwinism at that time, including Huxley, had reservations about the significance of natural selection, and Darwin himself gave credence to what was later called Lamarckism. The strict neo-Darwinism of German evolutionary biologist August Weismann gained few supporters in the late 19th century. During the approximate period of the 1880s to about 1920, sometimes called \"the eclipse of Darwinism\", scientists proposed various alternative evolutionary mechanisms which eventually proved untenable. The development of the modern synthesis in the early 20th century, incorporating natural selection with population genetics and Mendelian genetics, revived Darwinism in an updated form.\n\nWhile the term \"Darwinism\" has remained in use amongst the public when referring to modern evolutionary theory, it has increasingly been argued by science writers such as Olivia Judson and Eugenie Scott that it is an inappropriate term for modern evolutionary theory. For example, Darwin was unfamiliar with the work of the Moravian scientist and Augustinian friar Gregor Mendel, and as a result had only a vague and inaccurate understanding of heredity. He naturally had no inkling of later theoretical developments and, like Mendel himself, knew nothing of genetic drift, for example. In the United States, creationists often use the term \"Darwinism\" as a pejorative term in reference to beliefs such as scientific materialism, but in the United Kingdom the term has no negative connotations, being freely used as a shorthand for the body of theory dealing with evolution, and in particular, with evolution by natural selection.\n\nWhile the term \"Darwinism\" had been used previously to refer to the work of Erasmus Darwin in the late 18th century, the term as understood today was introduced when Charles Darwin's 1859 book \"On the Origin of Species\" was reviewed by Thomas Henry Huxley in the April 1860 issue of the \"Westminster Review\". Having hailed the book as \"a veritable Whitworth gun in the armoury of liberalism\" promoting scientific naturalism over theology, and praising the usefulness of Darwin's ideas while expressing professional reservations about Darwin's gradualism and doubting if it could be proved that natural selection could form new species, Huxley compared Darwin's achievement to that of Nicolaus Copernicus in explaining planetary motion:\nThese are the basic tenets of evolution by natural selection as defined by Darwin:\n\n\nAnother important evolutionary theorist of the same period was the Russian geographer and prominent anarchist Peter Kropotkin who, in his book \"\" (1902), advocated a conception of Darwinism counter to that of Huxley. His conception was centred around what he saw as the widespread use of co-operation as a survival mechanism in human societies and animals. He used biological and sociological arguments in an attempt to show that the main factor in facilitating evolution is cooperation between individuals in free-associated societies and groups. This was in order to counteract the conception of fierce competition as the core of evolution, which provided a rationalization for the dominant political, economic and social theories of the time; and the prevalent interpretations of Darwinism, such as those by Huxley, who is targeted as an opponent by Kropotkin. Kropotkin's conception of Darwinism could be summed up by the following quote:\n\n\"Darwinism\" soon came to stand for an entire range of evolutionary (and often revolutionary) philosophies about both biology and society. One of the more prominent approaches, summed in the 1864 phrase \"survival of the fittest\" by Herbert Spencer, later became emblematic of Darwinism even though Spencer's own understanding of evolution (as expressed in 1857) was more similar to that of Jean-Baptiste Lamarck than to that of Darwin, and predated the publication of Darwin's theory in 1859. What is now called \"Social Darwinism\" was, in its day, synonymous with \"Darwinism\"—the application of Darwinian principles of \"struggle\" to society, usually in support of anti-philanthropic political agenda. Another interpretation, one notably favoured by Darwin's half-cousin Francis Galton, was that \"Darwinism\" implied that because natural selection was apparently no longer working on \"civilized\" people, it was possible for \"inferior\" strains of people (who would normally be filtered out of the gene pool) to overwhelm the \"superior\" strains, and voluntary corrective measures would be desirable—the foundation of eugenics.\nIn Darwin's day there was no rigid definition of the term \"Darwinism\", and it was used by opponents and proponents of Darwin's biological theory alike to mean whatever they wanted it to in a larger context. The ideas had international influence, and Ernst Haeckel developed what was known as \"Darwinismus\" in Germany, although, like Spencer's \"evolution\", Haeckel's \"Darwinism\" had only a rough resemblance to the theory of Charles Darwin, and was not centered on natural selection. In 1886, Alfred Russel Wallace went on a lecture tour across the United States, starting in New York and going via Boston, Washington, Kansas, Iowa and Nebraska to California, lecturing on what he called \"Darwinism\" without any problems.\n\nIn his book \"Darwinism\" (1889), Wallace had used the term \"pure-Darwinism\" which proposed a \"greater efficacy\" for natural selection. George Romanes dubbed this view as \"Wallaceism\", noting that in contrast to Darwin, this position was advocating a \"pure theory of natural selection to the exclusion of any supplementary theory.\" Taking influence from Darwin, Romanes was a proponent of both natural selection and the inheritance of acquired characteristics. The latter was denied by Wallace who was a strict selectionist. Romanes' definition of Darwinism conformed directly with Darwin's views and was contrasted with Wallace's definition of the term.\n\nThe term \"Darwinism\" is often used in the United States by promoters of creationism, notably by leading members of the intelligent design movement, as an epithet to attack evolution as though it were an ideology (an \"ism\") of philosophical naturalism, or atheism. For example, UC Berkeley law professor and author Phillip E. Johnson makes this accusation of atheism with reference to Charles Hodge's book \"What Is Darwinism?\" (1874). However, unlike Johnson, Hodge confined the term to exclude those like American botanist Asa Gray who combined Christian faith with support for Darwin's natural selection theory, before answering the question posed in the book's title by concluding: \"It is Atheism.\" Creationists use the term \"Darwinism\", often pejoratively, to imply that the theory has been held as true only by Darwin and a core group of his followers, whom they cast as dogmatic and inflexible in their belief. In the 2008 documentary film \"\", which promotes intelligent design (ID), American writer and actor Ben Stein refers to scientists as Darwinists. Reviewing the film for \"Scientific American\", John Rennie says \"The term is a curious throwback, because in modern biology almost no one relies solely on Darwin's original ideas... Yet the choice of terminology isn't random: Ben Stein wants you to stop thinking of evolution as an actual science supported by verifiable facts and logical arguments and to start thinking of it as a dogmatic, atheistic ideology akin to Marxism.\" \n\nHowever, \"Darwinism\" is also used neutrally within the scientific community to distinguish the modern evolutionary synthesis, sometimes called \"neo-Darwinism\", from those first proposed by Darwin. \"Darwinism\" also is used neutrally by historians to differentiate his theory from other evolutionary theories current around the same period. For example, \"Darwinism\" may be used to refer to Darwin's proposed mechanism of natural selection, in comparison to more recent mechanisms such as genetic drift and gene flow. It may also refer specifically to the role of Charles Darwin as opposed to others in the history of evolutionary thought—particularly contrasting Darwin's results with those of earlier theories such as Lamarckism or later ones such as the modern evolutionary synthesis.\n\nIn political discussions in the United States, the term is mostly used by its enemies. \"It's a rhetorical device to make evolution seem like a kind of faith, like 'Maoism,'\" says Harvard University biologist E. O. Wilson. He adds, \"Scientists don't call it 'Darwinism'.\" In the United Kingdom the term often retains its positive sense as a reference to natural selection, and for example British ethologist and evolutionary biologist Richard Dawkins wrote in his collection of essays \"A Devil's Chaplain\", published in 2003, that as a scientist he is a Darwinist.\n\nIn his 1995 book \"Darwinian Fairytales\", Australian philosopher David Stove used the term \"Darwinism\" in a different sense than the above examples. Describing himself as non-religious and as accepting the concept of natural selection as a well-established fact, Stove nonetheless attacked what he described as flawed concepts proposed by some \"Ultra-Darwinists.\" Stove alleged that by using weak or false \"ad hoc\" reasoning, these Ultra-Darwinists used evolutionary concepts to offer explanations that were not valid (e.g., Stove suggested that sociobiological explanation of altruism as an evolutionary feature was presented in such a way that the argument was effectively immune to any criticism). Philosopher Simon Blackburn wrote a rejoinder to Stove, though a subsequent essay by Stove's protegee James Franklin's suggested that Blackburn's response actually \"confirms Stove's central thesis that Darwinism can 'explain' anything.\"\n\n\n"}
{"id": "8412", "url": "https://en.wikipedia.org/wiki?curid=8412", "title": "Doraemon", "text": "Doraemon\n\nDoraemon () is a Japanese manga series written and illustrated by Fujiko F. Fujio. The series has also been adapted into a successful anime series and media franchise. The story revolves around a robotic cat named Doraemon, who travels back in time from the 22nd century to aid a boy named .\n\nThe Doraemon manga series was first published in December 1969 in six different magazines. A total of 1,345 stories were created in the original series, which are published by Shogakukan. It is one of the best-selling manga in the world, having sold over 100 million copies .\n\nThe volumes are collected in the Takaoka Central Library in Toyama, Japan, where Fujiko Fujio was born. Turner Broadcasting System bought the rights to the Doraemon anime series in the mid-1980s for an English-language release in the United States, but cancelled it without explanation before broadcasting any episodes. In July 2013, Voyager Japan announced the manga would be released digitally in English via the Amazon Kindle e-book service. \n\nAwards for Doraemon include the Japan Cartoonists Association Award for excellence in 1973, the first Shogakukan Manga Award for children's manga in 1982, and the first Osamu Tezuka Culture Award in 1997. In March 2008, Japan's Foreign Ministry appointed Doraemon as the nation's first \"anime ambassador.\" A Ministry spokesperson explained the novel decision as an attempt to help people in other countries understand Japanese anime better and to deepen their interest in Japanese culture. \n\nThe Foreign Ministry action confirms that Doraemon has come to be considered a Japanese cultural icon. In India, its Hindi, Telugu and Tamil translation has been telecasted, where the anime version is the highest-rated kids' show; winning the \"Best Show For Kids\" award twice at the Nickelodeon Kids' Choice Awards India in 2013 and 2015. In 2002 \"Time Asia\" magazine acclaimed the character as an \"Asian Hero\" in a special feature survey. An edited English dub distributed by TV Asahi aired on Disney XD in the United States started on July 7, 2014. In Epcot, Doraemon toys are on the Japan shop. On August 17, 2015, another English dubbed version distributed by Luk Internacional began broadcasting on Boomerang UK. The film series is the largest by number of admissions in Japan.\n\nNobita Nobi is a young boy who suffers from poor grades, frequent bullying and negative emotions like sadness and jealousy. Many years in the future, one of his descendants sends the robotic cat Doraemon back in time to protect and guide Nobita. Doraemon has a four-dimensional pocket in which he stores innumerable items known as \"gadgets\", which range from toys and medicine, to technology from the future. Examples include the \"Bamboo-Copter\" (Japanese: \"Take-Koputa\"), a small piece of headgear that allows flight and the \"Anywhere Door\" (Japanese: \"Doko Demo Doa\"), a door that opens up to any place the user wishes.\n\nNobita's closest friend is Shizuka Minamoto, who also serves as his romantic interest and eventually becomes his wife. Nobita is usually tormented by the bullying Takeshi Goda (nicknamed \"Gian\"), and the cunning and arrogant Suneo Honekawa. A typical story consists of Doraemon using one of his gadgets in order to assist Nobita in various ways, often causing more trouble than he was trying to solve.\n\nIn December 1969 the \"Doraemon\" manga appeared in six different children's monthly magazines published by Shogakukan. The magazines were aimed at children from nursery school to fourth grade. In 1977 \"CoroCoro Comic\" was launched as the flagship magazine of \"Doraemon.\"\n\nSince the debut of \"Doraemon\" in 1969, the stories have been selectively collected into forty-five tankōbon volumes, which were published under Shogakukan's \"Tentōmushi Comics\" imprint, from 1974 to 1996. Shogakukan published a \"master works\" collection consisting of Twenty volumes between July 24, 2009 and September 25, 2012.\n\nIn addition, Doraemon has appeared in a variety of manga series by Shōgakukan. In 2005 Shōgakukan published a series of five more manga volumes under the title \"Doraemon+\" (\"Doraemon Plus\"), which were not found in the forty-five original volumes. On December 1, 2014, a sixth volume of \"Doraemon Plus\" was published. This was the first volume in eight years.\n\nThere have been two series of bilingual, Japanese and English, volumes of the manga by SHOGAKUKAN ENGLISH COMICS under the title \"Doraemon: Gadget Cat from the Future\", and two audio versions. The first series has ten volumes and the second six.\n\nIn July 2013, Fujiko Fujio Productions announced that they would be collaborating with ebook publisher Voyager Japan and localization company AltJapan Co., Ltd. to release an English language version of the manga in full-color digitally via the Amazon Kindle platform in North America. Shogakukan released the first volume in November 2013. This English version incorporates a variety of changes to character names; Nobita is \"Noby\", Shizuka is \"Sue\", Suneo is \"Sneech\", and Gian is \"Big G\", while dorayaki is \"Yummy Bun/Fudgy Pudgy Pie.\" A total of 200 volumes have been released.\n\nThe manga has been published in English in print by Shogakukan Asia, using the same translation as the manga available on Amazon Kindle. Unlike the Amazon Kindle releases these volumes are in black and white instead of color. They have released four volumes.\n\nShogakukan started digital distribution of all forty-five original volumes throughout Japan from July 16, 2015.\n\nAfter a brief animated series in 1973 by Nippon Television, \"Doraemon\" remained fairly exclusive in manga form until 1979 when a newly formed animation studio, Shin-Ei Animation (now owned by TV Asahi) produced an anime series of \"Doraemon.\" This series became incredibly popular, and ended with 1,787 episodes on March 25, 2005. In Asia, this version is sometimes referred to as the Ōyama Edition, after the voice actress who voiced Doraemon in this series.\n\nCelebrating the anniversary of the franchise, a new \"Doraemon\" series began airing on TV Asahi on April 15, 2005 with new voice actors and staff, and updated character designs. This version is sometimes referred to in Asia as the Mizuta Edition, as Wasabi Mizuta is the voice actress for Doraemon in this series.\n\nOn May 12, 2014, TV Asahi Corporation announced an agreement with The Walt Disney Company to beginning in the summer of that year. Besides using the name changes that were used in AltJapan's English adaptation of the original manga, other changes and edits have also been made to make the show more relatable to an American audience, such as Japanese text being replaced with English text on certain objects like signs and graded papers, items such as yen notes being replaced by US dollar bills, and the setting being changed from Tokyo to a small town in the state of North Carolina. Confirmed cast member of the new American adaptation include veteran anime voice actress Mona Marshall of \"South Park\" fame in the title role of Doraemon and Johnny Yong Bosch of \"Power Rangers\" and \"Bleach\" fame as Noby. The English dub is produced by Bang Zoom! Entertainment. Initial response to the edited dub was positive. The Disney adaptation began broadcast in Japan on Disney Channel from February 1, 2016. The broadcast offered the choice of the English voice track or a newly recorded Japanese track by the US cast.\n\nIn EMEA regions, the series is licensed by LUK International. The series began broadcast in the United Kingdom on August 17, 2015 on Boomerang.\n\nIn 1980, Toho released the first of a series of annual feature length animated films based on the lengthy special volumes published annually. Unlike the anime and manga (some based on the stories in select volumes), they are more action-adventure oriented and have more of a shōnen demographic, taking the familiar characters of \"Doraemon\" and placing them in a variety of exotic and perilous settings. Nobita and his friends have visited the age of the dinosaurs, the far reaches of the galaxy, the heart of darkest Africa (where they encountered a race of sentient bipedal dogs), the depths of the ocean, and a world of magic. Some of the films are based on legends such as Atlantis, and on literary works including \"Journey to the West\" and \"Arabian Nights.\" Some films also have serious themes, especially on environmental topics and the use of technology. Overall, the films have a somewhat darker tone in their stories, unlike the manga and anime.\n\nThere are a total of 63 Japanese-only video games ranging from platformer games to RPG games, which began with the Emerson's Arcadia 2001 system. Doraemon can also be seen in Namco's popular \"Taiko no Tatsujin\" rhythm game series like \"Taiko no Tatsujin\" (11 – 14 only), \"\", \"Taiko no Tatsujin Wii\", \"Taiko no Tatsujin Plus\", and \"\". The Japanese version of Microsoft's \"3D Movie Maker\" contained a Doraemon-themed expansion pack.\n\n was a 2008 musical based on the 1990 anime film . It debuted at Tokyo Metropolitan Art Space on September 4, 2008 running through September 14. Wasabi Mizuta voiced Doraemon.\n\nThe \"Doraemon \" franchise has had numerous licensed merchandise. In 1999, \"Doraemon\" licensed merchandise sold in Japan, where it was the fifth highest-grossing franchise annually. \"Doraemon\" licensed merchandise in Japan later sold in 2000, in 2001, in 2003, during 20042008, and during 20102012, adding up to at least () licensed merchandise sales in Japan by 2012. Global retail sales of \"Doraemon\" licensed merchandise later generated in 2015, and in 2016. , \"Doraemon\" has generated at least in licensed merchandise sales.\n\nUntil 2015, more than 100million tankobon copies of the manga have been sold, and the anime series is available in over 30 countries. The \"Doraemon\" film series sold more than 103million tickets at the Japanese box office by 2015, surpassing \"Godzilla\" as the highest-grossing film franchise in Japan, and the films grossed over at the worldwide box office, making \"Doraemon\" the highest-grossing anime film franchise. The \"Doraemon\" anime series is India's highest-rated children's television show , with a total of 478.5million viewers across Hungama TV and Disney Channel India.\n\nDoraemon was awarded the first Shogakukan Manga Award for children's manga in 1982. In 1997, it was awarded the first Osamu Tezuka Culture Award. In 2008, the Japanese Ministry of Foreign Affairs appointed Doraemon as the first anime cultural ambassador.\n\nOn 22 April 2002, on the special issue of \"Asian Hero\" in \"Time\" magazine, Doraemon was selected as one of the 22 Asian Heroes. Being the only anime character selected, Doraemon was described as \"The Cuddliest Hero in Asia\". In 2005, the Taiwan Society of New York selected \"Doraemon\" as a culturally significant work of Japanese otaku pop-culture in its exhibit \"Little Boy: The Arts of Japan's Exploding Subculture\", curated by renowned artist Takashi Murakami.\n\nJason Thompson praised the \"silly situations\" and \"old fashioned, simple artwork\", with Doraemon's expression and comments adding to the \"surrounding elementary-school mischief\".\n\nOn September 3, 2012, Doraemon was granted official residence in the city of Kawasaki, one hundred years before he was born.\n\nWith the 2013 film, \"\", Doraemon has surpassed Godzilla in terms of overall ticket sales for a film franchise as Toho's most lucrative movie property. The 33-year series (1980–2013) has sold a combined 100 million tickets vs. the 50-year Godzilla series (1954–2004), which sold a combined 99 million tickets. It also became the largest franchise by numbers of admissions in Japan.\n\nIn Pakistan, the series has been targeted by Pakistan Tehreek-e-Insaf as having a negative impact on children, because of Nobita's constant reliance on Doraemon's gadgets to solve problems. It also attempts to ban the Hindi dub of the series for teaching kids Hindi words not in Urdu (Pakistan's official language). It also intends to ban 24 hour cartoon channels in general, because of their supposed ruining of children's minds. Legal notice also been served against several companies in India against Doraemon and Crayon Shin-chan as having an adverse effect on children.\n\nA Fujiko F. Fujio museum opened in Kawasaki on September 3, 2011, featuring Doraemon as the star of the museum.\n\nAs one of the oldest, continuously running icons, Doraemon is a recognizable character in this contemporary generation. Nobita, the show's protagonist, is a break from other characters typically portrayed as special or extraordinary, and this portrayal has been seen as reasons of its appeal as well as the contrary, especially in the United States. Mexican filmmaker Guillermo del Toro considers \"Doraemon\" to be \"the greatest kids series ever created\".\n\nESP Guitars have made several Doraemon guitars aimed at children.\n\nIn late 2011, Shogakukan and Toyota joined forces to create a series of live-action commercials as part of Toyota's ReBorn ad campaign. The commercials depict the characters nearly 20 years older. Hollywood actor Jean Reno plays Doraemon.\n\nDoraemon has become a prevalent part of popular culture in Japan. Newspapers also regularly make references to Doraemon and his pocket as something with the ability to satisfy all wishes. The series is frequently referenced in other series such as \"Gin Tama\" and \"Great Teacher Onizuka\".\n\nDoraemon appears in appeals for charity. TV Asahi launched the \"Doraemon Fund\" charity fund to raise money for natural disasters.\n\nDoraemon, Nobita, and the other characters also appear in various educational manga.\n\nDoraemon appeared in the 2016 Summer Olympics closing ceremony to promote the 2020 Summer Olympics in Tokyo. In his appearance, he helped prime minister Shinzō Abe by planting a Warp Pipe from Shibuya Crossing to Maracanã Stadium.\n\nCharacters \n\nIn this show there are several characters like Nobita's best friend Shizuka and Nobita's frenemy named Gian.\n\n\n"}
{"id": "8414", "url": "https://en.wikipedia.org/wiki?curid=8414", "title": "Dartmoor Preservation Association", "text": "Dartmoor Preservation Association\n\nDartmoor Preservation Association (DPA) is one of the oldest environmental or amenity bodies in the UK. It was founded in 1883. It concerns itself with Dartmoor, a National Park in Devon, south-west England. It began with two main areas of concern. Firstly, commoners’ rights were being eroded through army use, including the firing of live artillery shells, and piecemeal enclosure of land around the margins. Secondly, there was increasing public interest in Dartmoor's scenery, archaeology, history and wildlife\n\nThe DPA has opposed what it considered to be unsuitable developments on Dartmoor throughout its history. In its founding year, the secretary, Robert Burnard persuaded the War Department not to fire on the Okehampton Firing Range on Saturdays to allow access to the public. Many battles have been fought since, particularly against the military presence and the proposed building of reservoirs on the moor, notably under the Chairmanship of Lady Sayer, granddaughter of Robert Burnard.\n\nThe DPA continues to follow the same objectives as when it was founded. For example, in June 2015, it supported the inhabitants of Widecombe-in-the-Moor against the erecting of a telecommunications mast in an area of pristine countryside against the wishes of the local population.\n\nDartmoor Preservation Association is a registered charity, Number 215665.\n\nDartmoor is said to be one of the last remaining areas of wilderness in Britain, but it has been a managed landscape since the late Neolithic (3,000-2,500 BCE). The Bronze Age inhabitants (from 2,500 to 750 BCE) cleared ancient forest and developed farming. They made extensive use of surface moorstone in the construction of roundhouses (their remains now seen as \"hut circles\"), enclosures, land-dividing reaves, stone rows, stone circles, menhirs and kistvaens.\n\nFarming has continued through the Medieval period to the present day, but a more disruptive activity to the landscape was the appearance of tin-mining, firstly by stream-working, then by lode-working and finally by underground mining. Many valleys have been dug over and scarred, leaving a rich industrial archaeology. Other activities such as newtake wall building, peat cutting, rabbit warrening, quarrying, clay extraction and the building of a prominent prison have all left marks on the moor. Recent undertakings have left more obvious changes: the building of reservoirs and the planting of conifer forests.\n\nThe use of moorstone continued up to recent times with the extensive building of dry stone walls around farm newtakes. Later, stone was cut and dressed. The use of moorstone continued to such an extent that in 1847 boundary markers were cut around Pew Tor to protect it. Marker stones were erected around Roos Tor. The taking of stone started to change the Dartmoor landscape: for example Eric Hemery (writing in 1983) stated that Swell Tor had been \"decapitated and disembowelled by the quarrymen\".\n\nIn August 1881, a public meeting was convened by the Portreeve of Tavistock in the Guildhall to discuss the continued taking of stone, particularly from landmark tors. The DPA was founded in 1883. The protected area around Pew Tor was extended in December 1896. In 1901, the DPA commissioned a report into damage to ancient monuments, caused by the taking of stone for building and road-mending, and into unlawful enclosures of common land.\n\nThe first publication of the DPA, in 1890, was a short history of commoners’ rights on Dartmoor and the commons of Devon. This notes a decrease in the numbers of animals even in medieval times: in 1296 – 5,000 cattle, 487 horses, 131 folds of sheep; in 1316 – 3,292 cattle, 368 horses, 100 folds of sheep. \"An important battle occurred in 1894 when the Corporation of London attempted to buy the whole of Dartmoor in order to pipe its water to Paddington alongside Brunel’s recently converted railway, when it went from broad gauge to standard gauge. The DPA led the revolt against this\". In 1897, the DPA went to court to fight successfully the enclosure of a section of Peter Tavy Great Common, in support of a farmer. Commoners rights seem to have been a settled issue in recent years: except for where they are impinged upon by the military presence.\n\nDartmoor Training Area has been used regularly for military training since 1873, although it was used earlier during the Napoleonic and Crimean Wars. In 1906-07, seven miles of roads were built on the north moor to facilitate the movement of guns. There are three established firing ranges at Okehampton, Willsworthy and Merrivale. The area taken up with live firing ranges is 9,187 hectares (22,664 acres) and they are used on average 120 days each year. They are used for small arms, mortars and artillery smoke and illuminating shells.\n\nThe use of the moor by the military has been a major concern of the DPA since its founding. In its first year, Robert Burnard (DPA Secretary) persuaded the War Department not to fire on the Okehampton Firing Range on Saturdays so that there may be some public access to the area. Lady Sylvia Sayer was very outspoken about it being totally at odds with the area being designated as a National Park. In 1963 the DPA published a widely circulated 24-page booklet entitled \"Misuse of a National Park\" which includes photographs of unexploded shells lying on the open moor, corrugated iron buildings, large craters, a derelict tank used as a target, bullet marks on standing stones, etc. It also contains details of a 1958 incident in which a young boy was killed by a mortar shell near Cranmere Pool.\n\nSince the 1960s there has been much less military damage and litter as a result of the DPA persuading the Services to be more cautious. The military have changed since the Victorian era, they now have 120 conservation groups across the Ministry of Defence (MOD), including Dartmoor Military Conservation Group. The current leases run for many years, with Cramber Tor most recently being granted a further 40-year licence.\n\nEarly afforestation occurred when Brimpts was planted with trees in 1862. The Forestry Commission was founded in 1919, following World War I and in that year the Duchy of Cornwall planted 800 acres of conifers at Fernworthy. In 1921, Plymouth Corporation planted conifers around Burrator Reservoir. The Forestry Commission planted Bellever and Laughter Tor farms in 1930-32 and in 1944-1945 Soussons Down was also planted. The DPA opposed these post-war plantings and R. Hansford Worth (1868-1950, a Plymouth engineer, scientist and antiquarian) delivered a lecture fiercely critical of the Duchy of Cornwall as the landowners at The Plymouth Athenaeum, using the argument of encroachment on the rights of common and loss of ancient monuments. DPA opposition to forestry on Dartmoor arose again in 1953 when it wrote a policy on woodlands in the then-new national park. Opposition was exercised when Hawn, Dendles and High House Wastes, all near Cornwood, were designated for tree planting in 1959. Argument continued while Hawns and Dendles Wastes were ploughed in 1960. High House Waste was purchased by the DPA in 1964 and the Nature Conservancy (UK) bought neighbouring Dendles in 1965. The situation in 2015 is that some of the Dartmoor plantations have been affected by the fungal disease Phytophthora ramorum which results in widespread clear felling to prevent further spread of the disease. The policy now is to replant with more native hardwood trees although more resistant conifers are also being used.\n\nThere are eight Dartmoor reservoirs, with the earliest being Tottiford Reservoir, 1861. Three were built in the mid-20th century: Fernworthy, 1942; Avon, 1957 and Meldon, 1972, and the DPA fought many battles over these. It opposed plans for reservoirs on Brent Moor (1899) and Holne Moor (1901) where, later, the Avon Reservoir and Venford Reservoirs were respectively built. The DPA's opposition was supported in the House of Commons with argument made regarding the effects on the local water table. The DPA was one of many local and national amenity bodies that fought the building of the Meldon dam. The preservation battle for the Meldon valley was recorded in a DPA publication. The DPA offered a viable alternative site, Gorhuish Valley, for various reasons, including the fact that minerals such as arsenic would leach into the water supply if Meldon were selected. The Meldon story was discussed many times in Parliament. Another battle was fought against the flooding of the Swincombe valley to form another reservoir. This was rejected in parliament in 1970, revived in 1974 and finally resolved by the building of the Roadford Reservoir to the west of the moor. In 1985 the DPA used funds from a bequest to purchase 50 acres of land where the dam of a reservoir at Swincombe would have to be.\n\nThe National Parks and Access to the Countryside Act 1949 led to Dartmoor being one of the first four parks to be designated, by an order made on 15 August 1951 and confirmed on 30 October 1951. Shortly after this, the DPA tried to ensure that the new National Park was run by an independent committee and not by the Dartmoor Standing Committee that was a subcommittee of Devon County Council Planning Committee. The committee was reformed as Dartmoor National Park Committee under the Local Government Act 1972 but it was still a subcommittee of Devon County Council and as such it was not seen to be an independent guardian of the moor by the DPA. It was not until 1997 that an independent Dartmoor National Park Authority was enabled under the Environment Act 1995 as a free-standing local authority, forty-four years after the park was created, although it is still dominated by local authorities and government appointees.\n\nThe DPA learned in October 1951 that the BBC planned to build a 750-foot television mast on North Hessary Tor, near Princetown, that was erected in 1955. This was to be a relay from a transmitting station at Wenvoe, South Wales. The DPA objected to this threat and sought expert opinion, offered alternative solutions, pressed for a public enquiry, engaged a lawyer, held public meetings, distributed pamphlets, wrote to the press and petitioned parliament. Eventually, a public enquiry was announced. When the decision was made to permit the mast, there were a number of conditions, included among them was that the development was built near the tor, leaving it still intact, and that its new approach road should not be fenced. During the process of obtaining land for the transmitter, one MP asked in the House of Commons: \"Will the Assistant Postmaster-General bear in mind that we have no desire to hinder the provision of this station but that it is felt that ancient common rights such as these, that have existed for a thousand years, should be adequately protected or properly extinguished by due process of law?\"\n\nDuring World War II, the Royal Air Force (RAF) built a mast and buildings on Peek Hill, as RAF Sharpitor. In 1956, permission was granted to rebuild the station as part of the \"Gee\" radio navigation system, to be occupied for ten years. There followed delay in leaving and a proposal was made in 1970 by Devon & Cornwall Police to use the mast, which was rejected. Then later that year Plymouth Corporation wanted to use the exposed site for housing juvenile offenders. This was also rejected, but Plymouth appealed. At a public enquiry in June 1973 Lady Sylvia Sayer represented the DPA and permission for development on the site was refused. A few years later, DPA fought successfully in support of South West Water (SWW) against renewed calls for a new reservoir at Swincombe. To mark the victory, Sylvia Sayer asked SWW if DPA could purchase the rocky outcrop of Sharpitor. The DPA purchased 32 acres in February 1984.\n\nOkehampton lies on the A30 main road, the shortest route from London to west Devon and Cornwall. The need for a bypass was mooted in 1963. In 1975, three routes were considered: a northern route through mainly farmland, a central route using a railway, and a southern route through Dartmoor National Park. In August 1976, the Department of the Environment announced the preferred route was through the National Park. A major event on the timeline of this project was a 96-day public enquiry from 1 May 1979 to 4 February 1980 held in Okehampton. In March 1984, the DPA with other organisations petitioned Parliament opposing compulsory purchase orders on public open spaces. The Secretary of State announced in July 1985 that he was introducing a bill to reverse the decision of a Joint Parliamentary Committee and confirm a route through the National Park. This was followed by a confirmation bill in November 1985 that was passed in the House of Lords on 5 December 1985. Construction started in November 1986 and the road was opened on 19 July 1988.\n\nThe DPA continues to follow the same objectives as when it was founded. The activities have widened, involving local partners, it has a calendar of events, walks and work days with its Conservation Team undertaking a variety of moorland projects, it funds the supply of walking boots to some children who need them for the Duke of Edinburgh Award Scheme through the Moor Boots Scheme, it collaborates with the Campaign for National Parks, it monitors the activities of Dartmoor National Park Authority who run the National Park. It objected to eight planning proposals (with success in seven cases), with many other achievements in the DPA Director's Annual Report. The DPA remains true to its original objectives and has also added other activities in support of Dartmoor and its inhabitants.\n\nThe china clay industry on Dartmoor was established long before the DPA was founded. The earliest record of a china clay pit refers to Hook Lake in 1502. The area was surveyed around 1827 by Cornishmen with thirty years experience in the clay industry. They obtained a 21-year lease in 1830, from the Earl of Morley who owned the land, to work the area between Lee Moor and Shaugh Moor. A rival pit was opened at Leftlake in about 1850 and at Hemerdon and Broomage in about 1855. Further pits were opened at Cholwichtown, Whitehill Yeo and Wigford Down/Brisworthy (circa 1860). Others followed at Smallhanger and Headon in the 1870s. Redlake started working in 1910. China clay pits are open cast mines that result in large holes in the ground accompanied by large waste tips. Over time, the pits become larger and more ground is needed for the waste, changing the landscape: the effect of this can be seen from space.\n\nThe DPA argues that this is an activity that does not agree with the ethos of a National Park, whose purpose is to protect landscape from unsuitable development. In 1994, the National Park boundaries were changed to include common land at Shaugh Moor and exclude china clay worked land at Lee Moor. The DPA revived its campaign with the publication of a booklet in 1999 when the Blackabrook Valley, Crownhill Down and Shaugh Moor, near the popular tourist area of Cadover Bridge, all came under threat from exploitation or dumping of waste. The china clay companies relinquished planning permissions in 2001. However, in November 2009, the clay companies, Sibelco and Imerys, produced a report reviewing old mineral permissions under the Environment Act 1995 with a view to joining up two pits. A presumed Bronze Age barrow, known as Emmets Post, was to be removed and three other monuments may be affected. The DPA were recorded twice, with other bodies, in a Devon County Council Development Management Committee Report for their representations in securing the future of the three areas where planning permissions were relinquished in 2001. Oxford Archaeology held an open day during their excavation of Emmets Post in 2014 prior to its removal.\n\nThe DPA and Exmoor Society held a joint reception at the House of Lords on 6 November 2008, hosted by Baroness Mallalieu, to lobby members of both Houses of Parliament and relevant Ministers about ensuring that environmental schemes for the uplands are \"fit for purpose\". Both organisations funded an invited number of upland hill farmers to attend.\n\nThe excavation in August 2011 on the north moor of a Bronze Age burial kistvaen, or cist, that was originally uncovered in 2001 was part-funded by the DPA, along with other bodies.\n\nA conference for the upland farmers of Bodmin Moor, Exmoor and Dartmoor was held as a joint venture between the South West Uplands Federation and the DPA. It was run by the DPA at Exeter Racecourse in October 2012, with 150 delegates. Speakers came from the Foundation for Common Land, the Forest of Dartmoor Commoners, the University of Gloucestershire, the National Farmers Union of England and Wales and the Open Spaces Society. The CEO raised sponsorship from Dartmoor National Park, Exmoor National Park, Natural England, Duchy of Cornwall and the Exmoor Society - this reflecting the standing of the DPA with those bodies.\n\nTwo major projects to underground overhead power cables in Dartmoor National Park have been completed in a joint project between Western Power Distribution, the South West Protected Landscapes Forum (SWPLF) and Dartmoor National Park Authority. The two schemes on Holne Moor and Walkhampton Common between them remove nearly 6 km of overhead line from open moorland. At nearly 5 km, the Walkhampton scheme is the largest to be undertaken in the South West region by Western Power Distribution. The old overhead line was readily visible from the B3212 Princetown to Yelverton Road, strung across Walkhampton Common from Devil's Elbow to just above Horseyeatt at Peek Hill. The works to provide the new underground supply were mainly undertaken on the highway to minimise the impact on the sensitive moorland landscape, its archaeology, wildlife and livestock. The DPA has supported the undergrounding of these visually intrusive power lines for many years.\n\nThe Dartmoor Conservation Garden is a joint project between DPA and Dartmoor National Park Authority (DNPA) and is located in the Jack Wigmore Garden behind the High Moorland Centre in Princetown: this is a memorial garden to a former Chair of the Authority. It is planted with a cross-section of typical native Dartmoor plants. It also houses some typical Dartmoor archaeological features, such as a 4,000-year-old Bronze Age burial kistvaen (or cist) and a Medieval granite cross from Ter Hill. This marked the Monk's Path but was constantly being pushed over by cattle. The purpose of the Garden is to illustrate the biodiversity on Dartmoor. The project came online in June 2015.\n\nThe DPA were involved in a campaign in June 2015 against four telecommunications masts planned for Dartmoor, with the first to be erected in the village of Widecombe. At short notice, the DPA banners were taken out, letters written, press interviews given and support given to the villagers when an inflatable mast was demonstrated – with the effect that the planning application was withdrawn.\n\nIn common with other amenity bodies, such as those for the Lake District, Peak District, Pembrokeshire Coast, Yorkshire Dales Three Peaks and the New Forest Trust, the image of Dartmoor Preservation Association is evolving from its Victorian origins, although the original name is being retained. Friends of Dartmoor projects a more modern image of preservation where several years of diplomacy have achieved good relations with the partner agencies that operate in the Dartmoor arena. This is due mainly to the efforts of the previous CEO, James Paxman and his successor, Phil Hutt.\n\nThe DPA Constitution, objectives and policies are published on the DPA web site.\n\nThe objectives enshrined in the constitution are the protection, preservation and enhancement in the public interest of the landscape, antiquities, flora and fauna, natural beauty, cultural heritage and scientific interest of Dartmoor. Also the protection and preservation of public access to and on Dartmoor subject to the ancient rights of commoners. Co-operation with the commoners and any organisation in achieving DPA objectives, also the study of and the recording and publication of information upon the antiquities, history and natural history of Dartmoor. There is also an interest in the acquisition of land and rights to further DPA objectives, concomitant with being a charity.\n\nThe DPA has twenty-two policies listed on its web site: regarding access and rights of way, fencing, protecting monuments, diverse habitats, bracken, china clay quarrying, military training and live firing, hill farming and small scale traditional local industries, quarrying, television and telephone masts, wind farms, planning applications, housing developments, woodlands and forestry, ponies, swaling, and recreational activities.\n\nThe DPA logo incorporates a representation of a Dartmoor rock feature known as Bowerman's Nose. The logo that includes a representation of Nun's Cross appeared on the DPA Dartmoor Newsletter No. 48, October 1966, with a comment that designs based on the initial letters DPA had been exhausted. The simpler logo appeared in November 1969, when Newsletter 52 carried the logo with \"DPA\" on it. This was replaced in 2004 with the multicoloured logo.\n\n\n"}
{"id": "8418", "url": "https://en.wikipedia.org/wiki?curid=8418", "title": "Dartmouth College", "text": "Dartmouth College\n\nDartmouth College ( ) is a private Ivy League research university in Hanover, New Hampshire, United States. Established in 1769 by Eleazar Wheelock, it is the ninth-oldest institution of higher education in the United States and one of the nine colonial colleges chartered before the American Revolution. Although founded as a school to educate Native Americans in Christian theology and the English way of life, Dartmouth primarily trained Congregationalist ministers throughout its early history. The university gradually secularized, and by the turn of the 20th century it had risen from relative obscurity into national prominence as one of the top centers of higher education.\n\nFollowing a liberal arts curriculum, the university provides undergraduate instruction in 40 academic departments and interdisciplinary programs including 57 majors in the humanities, social sciences, natural sciences, and engineering, and enables students to design specialized concentrations or engage in dual degree programs. Dartmouth comprises five constituent schools: the original undergraduate college, the Geisel School of Medicine, the Thayer School of Engineering, the Tuck School of Business, and the Guarini School of Graduate and Advanced Studies. The university also has affiliations with the Dartmouth–Hitchcock Medical Center, the Rockefeller Institute for Public Policy, and the Hopkins Center for the Arts. With a student enrollment of about 6,400, Dartmouth is the smallest university in the Ivy League. Undergraduate admissions is highly competitive, with an acceptance rate of 8.7% for the Class of 2022.\n\nSituated on a hill above the Connecticut River, Dartmouth's 269-acre main campus is in the rural Upper Valley region of New England. The university functions on a quarter system, operating year-round on four ten-week academic terms. Dartmouth is known for its undergraduate focus, strong Greek culture, and wide array of enduring campus traditions. Its 34 varsity sports teams compete intercollegiately in the Ivy League conference of the NCAA Division I.\n\nDartmouth is consistently included among the highest-ranked universities in the United States by several institutional rankings, and has been cited as a leading university for undergraduate teaching and research by \"U.S. News & World Report\". In 2018, the Carnegie Classification of Institutions of Higher Education listed Dartmouth as the only \"majority-undergraduate,\" \"arts-and-sciences focused,\" \"doctoral university\" in the country that has \"some graduate coexistence\" and \"very high research activity.\" In a \"New York Times\" corporate study, Dartmouth graduates ranked 41st in terms of the most sought-after and valued in the world.\n\nThe university has produced many prominent alumni, including 170 members of the U.S. Senate and the U.S. House of Representatives, 24 U.S. governors, 10 billionaire alumni, 10 U.S. Cabinet secretaries, 3 Nobel Prize laureates, 2 U.S. Supreme Court justices, and a U.S. vice president. Other notable alumni include 79 Rhodes Scholars, 26 Marshall Scholarship recipients, 13 Pulitzer Prize winners, and numerous MacArthur Genius fellows, Fulbright Scholars, CEOs and founders of Fortune 500 corporations, high-ranking U.S. diplomats, scholars in academia, literary and media figures, professional athletes, and Olympic medalists.\n\nDartmouth was founded by Eleazar Wheelock, a Congregational minister from Columbia, Connecticut, who had sought to establish a school to train Native Americans as Christian missionaries. Wheelock's ostensible inspiration for such an establishment resulted from his relationship with Mohegan Indian Samson Occom. Occom became an ordained minister after studying under Wheelock from 1743 to 1747, and later moved to Long Island to preach to the Montauks.\n\nWheelock founded Moor's Indian Charity School in 1755. The Charity School proved somewhat successful, but additional funding was necessary to continue school's operations, and Wheelock sought the help of friends to raise money. The first major donation to the school was given by Dr. John Phillips in 1762, who would go on to found Phillips Exeter Academy. Occom, accompanied by the Reverend Nathaniel Whitaker, traveled to England in 1766 to raise money from churches. With these funds, they established a trust to help Wheelock. The head of the trust was a Methodist named William Legge, 2nd Earl of Dartmouth.\nAlthough the fund provided Wheelock ample financial support for the Charity School, Wheelock initially had trouble recruiting Indians to the institution, primarily because its location was far from tribal territories. In seeking to expand the school into a college, Wheelock relocated it to Hanover, in the Province of New Hampshire. The move from Connecticut followed a lengthy and sometimes frustrating effort to find resources and secure a charter. The Royal Governor of New Hampshire, John Wentworth, provided the land upon which Dartmouth would be built and on December 13, 1769, issued a royal charter in the name of King George III establishing the College. That charter created a college \"for the education and instruction of Youth of the Indian Tribes in this Land in reading, writing & all parts of Learning which shall appear necessary and expedient for civilizing & christianizing Children of Pagans as well as in all liberal Arts and Sciences and also of English Youth and any others.\" The reference to educating Native American youth was included to connect Dartmouth to the Charity School and enable use of the Charity School's unspent trust funds. Named for William Legge, 2nd Earl of Dartmouth—an important supporter of Eleazar Wheelock's earlier efforts but who, in fact, opposed creation of the College and never donated to it—Dartmouth is the nation's ninth oldest college and the last institution of higher learning established under Colonial rule. The College granted its first degrees in 1771.\n\nGiven the limited success of the Charity School, however, Wheelock intended his new college as one primarily for whites. Occom, disappointed with Wheelock's departure from the school's original goal of Indian Christianization, went on to form his own community of New England Indians called Brothertown Indians in New York.\n\nIn 1819, Dartmouth College was the subject of the historic Dartmouth College case, which challenged New Hampshire's 1816 attempt to amend the college' charter to make the school a public university. An institution called Dartmouth University occupied the college buildings and began operating in Hanover in 1817, though the college continued teaching classes in rented rooms nearby. Daniel Webster, an alumnus of the class of 1801, presented the College's case to the Supreme Court, which found the amendment of Dartmouth's charter to be an illegal impairment of a contract by the state and reversed New Hampshire's takeover of the college. Webster concluded his peroration with the famous words: \"It is, Sir, as I have said, a small college. And yet there are those who love it.\"\n\nIn 1866, the New Hampshire College of Agriculture and the Mechanic Arts was incorporated in Hanover, in connection with Dartmouth College. The institution was officially associated with Dartmouth and was directed by Dartmouth's president. The new college was moved to Durham, New Hampshire, in 1891, and later became known as the University of New Hampshire.\n\nDartmouth emerged onto the national academic stage at the turn of the 20th century. Prior to this period, the college had clung to traditional methods of instruction and was relatively poorly funded. Under President William Jewett Tucker (1893–1909), Dartmouth underwent a major revitalization of facilities, faculty, and the student body, following large endowments such as the $10,000 given by Dartmouth alumnus and law professor John Ordronaux. 20 new structures replaced antiquated buildings, while the student body and faculty both expanded threefold. Tucker is often credited for having \"refounded Dartmouth\" and bringing it into national prestige. Presidents Ernest Fox Nichols (1909–16) and Ernest Martin Hopkins (1916–45) continued Tucker's trend of modernization, further improving campus facilities and introducing selective admissions in the 1920s. In 1945, Hopkins was subject to no small amount of controversy, as he openly admitted to Dartmouth's practice of using racial quotas to deny Jews entry into the university. John Sloan Dickey, serving as president from 1945 until 1970, strongly emphasized the liberal arts, particularly public policy and international relations. During World War II, Dartmouth was one of 131 colleges and universities nationally that took part in the V-12 Navy College Training Program which offered students a path to a navy commission.\n\nIn 1970, longtime professor of mathematics and computer science John George Kemeny became president of Dartmouth. Kemeny oversaw several major changes at the college. Dartmouth, which had been a men's institution, began admitting women as full-time students and undergraduate degree candidates in 1972 amid much controversy. At about the same time, the college adopted its \"Dartmouth Plan\" of academic scheduling, permitting the student body to increase in size within the existing facilities. In 1988, Dartmouth's alma mater song's lyrics changed from \"Men of Dartmouth\" to \"Dear old Dartmouth\".\n\nDuring the 1990s, the college saw a major academic overhaul under President James O. Freedman and a controversial (and ultimately unsuccessful) 1999 initiative to encourage the school's single-sex Greek houses to go coed. The first decade of the 21st century saw the commencement of the $1.3 billion Campaign for the Dartmouth Experience, the largest capital fundraising campaign in the college's history, which surpassed $1 billion in 2008. The mid- and late first decade of the 21st century have also seen extensive campus construction, with the erection of two new housing complexes, full renovation of two dormitories, and a forthcoming dining hall, life sciences center, and visual arts center. In 2004, Booz Allen Hamilton selected Dartmouth College as a model of institutional endurance \"whose record of endurance has had implications and benefits for all American organizations, both academic and commercial,\" citing \"Trustees of Dartmouth College v. Woodward\" and Dartmouth's successful self-reinvention in the late 19th century.\n\nSince the election of a number of petition-nominated trustees to the Board of Trustees starting in 2004, the role of alumni in Dartmouth governance has been the subject of ongoing conflict. President James Wright announced his retirement in February 2008 and was replaced by Harvard University professor and physician Jim Yong Kim on July 1, 2009.\n\nIn May 2010 Dartmouth joined the Matariki Network of Universities (MNU) together with Durham University (UK), Queen's University (Canada), University of Otago (New Zealand), University of Tübingen (Germany), University of Western Australia (Australia) and Uppsala University (Sweden).\n\nDartmouth's close association and involvement in the development of the downhill skiing industry is featured in the 2010 book \"Passion for Skiing\" as well as the 2013 documentary based on the book \"Passion for Snow\".\n\nDartmouth, a liberal arts institution, offers a four-year Bachelor of Arts and ABET-accredited Bachelor of Engineering degree to undergraduate students. The college has 39 academic departments offering 56 major programs, while students are free to design special majors or engage in dual majors. For the graduating class of 2017, the most popular majors were economics, government, computer science, engineering sciences, and history. The Government Department, whose prominent professors include Stephen Brooks, Richard Ned Lebow, and William Wohlforth, was ranked the top solely undergraduate political science program in the world by researchers at the London School of Economics in 2003. The Economics Department, whose prominent professors include David Blanchflower and Andrew Samwick, also holds the distinction as the top-ranked bachelor's-only economics program in the world.\n\nIn order to graduate, a student must complete 35 total courses, eight to ten of which are typically part of a chosen major program. Other requirements for graduation include the completion of ten \"distributive requirements\" in a variety of academic fields, proficiency in a foreign language, and completion of a writing class and first-year seminar in writing. Many departments offer honors programs requiring students seeking that distinction to engage in \"independent, sustained work,\" culminating in the production of a thesis. In addition to the courses offered in Hanover, Dartmouth offers 57 different off-campus programs, including Foreign Study Programs, Language Study Abroad programs, and Exchange Programs.\n\nThrough the Graduate Studies program, Dartmouth grants doctorate and master's degrees in 19 Arts & Sciences graduate programs. Although the first graduate degree, a PhD in classics, was awarded in 1885, many of the current PhD programs have only existed since the 1960s. Furthermore, Dartmouth is home to three professional schools: the Geisel School of Medicine (established 1797), Thayer School of Engineering (1867)—which also serves as the undergraduate department of engineering sciences—and Tuck School of Business (1900). With these professional schools and graduate programs, conventional American usage would accord Dartmouth the label of \"Dartmouth University\"; however, because of historical and nostalgic reasons (such as \"Dartmouth College v. Woodward\"), the school uses the name \"Dartmouth College\" to refer to the entire institution.\n\nDartmouth employs a total of 607 tenured or tenure-track faculty members, including the highest proportion of female tenured professors among the Ivy League universities. Faculty members have been at the forefront of such major academic developments as the Dartmouth Workshop, the Dartmouth Time Sharing System, Dartmouth BASIC, and Dartmouth ALGOL 30. In 2005, sponsored project awards to Dartmouth faculty research amounted to $169 million.\n\nDartmouth serves as the host institution of the University Press of New England, a university press founded in 1970 that is supported by a consortium of schools that also includes Brandeis University, the University of New Hampshire, Northeastern University, Tufts University and the University of Vermont.\n\nDartmouth was ranked 11th among undergraduate programs at national universities by \"U.S. News & World Report\" in its 2018 rankings. Dartmouth's strength in undergraduate education is highlighted by \"U.S. News\" when in 2009 through 2013 it ranked Dartmouth first in undergraduate teaching at national universities. It was ranked 2nd in this area in the 2018 rankings. The institution also ranked 5th in High School Counselor Rankings in 2018. The college ranks 7th in \"The Wall Street Journal\"s ranking of top feeder schools.\n\nThe 2017 Academic Ranking of World Universities ranked Dartmouth among the 71-99th best universities in the nation, alongside institution such as Georgetown University and University of Notre Dame. AWRU ranks Dartmouth among the 76–100 best schools in the world for Business Administration and 101–150 for Management and Psychology.\n\nIn \"Forbes\" 2019 rankings of colleges, Dartmouth ranked 9th overall in the combined liberal arts college and national universities ranking. In the Forbes 2018 \"grateful graduate\" rankings, Dartmouth came 1st.\n\nThe 2006 Carnegie Foundation classification listed Dartmouth as the only \"majority-undergraduate\", \"arts-and-sciences focus[ed]\", \"research university\" in the country that also had \"some graduate coexistence\" and \"very high research activity.\"\n\nFor its graduate programs, \"U.S. News\" ranks Dartmouth's MBA program 9th overall and 6th for management. Among its other highly ranked graduate offerings, the school is ranked 40th in computer science, 29th in medicine for primary care, and 37th in medicine for research. Its global ranking places is at 242nd.\n\nUndergraduate admission to Dartmouth College is characterized by the Carnegie Foundation and \"U.S. News & World Report\" as \"most selective.\" The \"Princeton Review\", in its 2018 edition, gave the university an admissions selectivity rating of 98 out of 99.\n\nFor the freshman class entering Fall 2018, Dartmouth received 22,033 applications of which 1,925 were accepted for an 8.7% admissions rate. Of those admitted students who reported class rank, a record 46.3% were valedictorian or salutatorian, with 97% ranking in the top decile of their class. The admitted students' academic profile showed an all-time high SAT average score of 1497, while the average composite ACT score remained at 33. More than 51% identified as being students of color, 15% are among the first generation in their families to matriculate to college, 11% are international students, and 9% are legacies.\n\nAdditionally, for the 2016–2017 academic year, Dartmouth received 685 transfer applications of which 5.1% were accepted, with an average SAT composite score of 1490, average composite ACT score of 34, and average college GPA of about 3.85. Dartmouth meets 100% of students' demonstrated financial need in order to attend the College, and currently admits all students, with the exception of internationals, on a need-blind basis.\n\nDartmouth guarantees to meet 100% of the demonstrated need of every admitted student who applies for financial aid at the time of admission. Dartmouth practices need-blind admissions for all applicants who are U.S. citizens, permanent residents, and undocumented students in the U.S. These applicants are admitted to the college without regard to their financial circumstances. For international students, financial need is taken into consideration as one of many factors at the time of admission. At Dartmouth, free tuition is provided for students from families with total incomes of $100,000 or less and possessing typical assets. In 2015, $88.8 million in need-based scholarships were awarded to Dartmouth students.\n\nDartmouth functions on a quarter system, operating year-round on four ten-week academic terms. The Dartmouth Plan (or simply \"D-Plan\") is an academic scheduling system that permits the customization of each student's academic year. All undergraduates are required to be in residence for the fall, winter, and spring terms of their freshman and senior years, as well as the summer term of their sophomore year. However, students may petition to alter this plan so that they may be off during their freshman, senior, or sophomore summer terms. During all terms, students are permitted to choose between studying on-campus, studying at an off-campus program, or taking a term off for vacation, outside internships, or research projects. The typical course load is three classes per term, and students will generally enroll in classes for 12 total terms over the course of their academic career.\n\nThe D-Plan was instituted in the early 1970s at the same time that Dartmouth began accepting female undergraduates. It was initially devised as a plan to increase the enrollment without enlarging campus accommodations, and has been described as \"a way to put 4,000 students into 3,000 beds.\" Although new dormitories have been built since, the number of students has also increased and the D-Plan remains in effect. It was modified in the 1980s in an attempt to reduce the problems of lack of social and academic continuity.\n\nDartmouth is governed by a Board of Trustees comprising the college president (\"ex officio\"), the state governor (\"ex officio\"), 13 trustees nominated and elected by the board (called \"charter trustees\"), and eight trustees nominated by alumni and elected by the board (\"alumni trustees\"). The nominees for alumni trustee are determined by a poll of the members of the Association of Alumni of Dartmouth College, selecting from among names put forward by the Alumni Council or by alumni petition.\n\nAlthough the board elected its members from the two sources of nominees in equal proportions between 1891 and 2007, the board decided in 2007 to add several new members, all charter trustees. In the controversy that followed the decision, the Association of Alumni filed a lawsuit, although it later withdrew the action. In 2008, the Board added five new charter trustees.\n\nDartmouth College is situated in the rural town of Hanover, New Hampshire, located in the Upper Valley along the Connecticut River in New England. Its campus is centered on a \"Green\", a former field of pine trees cleared in 1771. Dartmouth is the largest private landowner of the town of Hanover, and its total landholdings and facilities are worth an estimated $434 million. In addition to its campus in Hanover, Dartmouth owns of Mount Moosilauke in the White Mountains and a tract of land in northern New Hampshire known as the Second College Grant.\n\nDartmouth's campus buildings vary in age from Wentworth and Thornton Halls of the 1820s (the oldest surviving buildings constructed by the college) to new dormitories and mathematics facilities completed in 2006. Most of Dartmouth's buildings are designed in the Georgian colonial architecture style, a theme which has been preserved in recent architectural additions. The College has actively sought to reduce carbon emissions and energy usage on campus, earning it the grade of A- from the Sustainable Endowments Institute on its College Sustainability Report Card 2008.\n\nA notable feature of the Dartmouth campus is its many trees which (despite Dutch elm disease) include some 200 American elms.\n\nThe college's creative and performing arts facility is the Hopkins Center for the Arts (\"the Hop\"). Opened in 1962, the Hop houses the College's drama, music, film, and studio arts departments, as well as a woodshop, pottery studio, and jewelry studio which are open for use by students and faculty. The building was designed by the famed architect Wallace Harrison, who would later design the similar-looking façade of Manhattan's Metropolitan Opera House at Lincoln Center. Its facilities include two theaters and one 900-seat auditorium. The Hop is also the location of all student mailboxes (\"Hinman boxes\") and the Courtyard Café dining facility. The Hop is connected to the Hood Museum of Art, arguably North America's oldest museum in continuous operation, and the Loew Auditorium, where films are screened.\nIn addition to its 19 graduate programs in the arts and sciences, Dartmouth is home to three separate graduate schools. The Geisel School of Medicine is located in a complex on the north side of campus and includes laboratories, classrooms, offices, and a biomedical library. The Dartmouth–Hitchcock Medical Center, located several miles to the south in Lebanon, New Hampshire, contains a 396-bed teaching hospital for the Medical School. The Thayer School of Engineering and the Tuck School of Business are both located at the end of Tuck Mall, west of the center of campus and near the Connecticut River. The Thayer School comprises two buildings; Tuck has seven academic and administrative buildings, as well as several common areas. The two graduate schools share a library, the Feldberg Business & Engineering Library.\n\nDartmouth's nine libraries are all part of the collective Dartmouth College Library, which comprises 2.48 million volumes and 6 million total resources, including videos, maps, sound recordings, and photographs. Its specialized libraries include the Biomedical Libraries, Evans Map Room, Feldberg Business & Engineering Library, Jones Media Center, Kresge Physical Sciences Library, Paddock Music Library, Rauner Special Collections Library, and Sherman Art Library. Baker-Berry Library is the main library at Dartmouth, consisting of a merger of the Baker Memorial Library (opened 1928) and the Berry Library (completed 2002). Located on the northern side of the Green, Baker's tower is an iconic symbol of the College.\n\nDartmouth's original sports field was the Green, where students played cricket and old division football during the 19th century. Today, two of Dartmouth's athletic facilities are located in the southeast corner of campus. The center of athletic life is the Alumni Gymnasium, which includes the Karl Michael Competition Pool and the Spaulding Pool, a state of the art fitness center, a weight room, and a 1/13th-mile (123 m) indoor track. Attached to Alumni Gymnasium is the Berry Sports Center, which contains basketball and volleyball courts (Leede Arena), as well as the Kresge Fitness Center. Behind the Alumni Gymnasium is Memorial Field, a 15,600-seat stadium overlooking Dartmouth's football field and track. The nearby Thompson Arena, designed by Italian engineer Pier Luigi Nervi and constructed in 1975, houses Dartmouth's ice rink. Also visible from Memorial Field is the Nathaniel Leverone Fieldhouse, home to the indoor track. The new softball field, Dartmouth Softball Park, was constructed in 2012, sharing parking facilities with Thompson arena and replacing Sachem Field, located over a mile from campus, as the primary softball facility.\n\nDartmouth's other athletic facilities in Hanover include the Friends of Dartmouth Rowing Boathouse and the old rowing house storage facility (both located along the Connecticut River), the Hanover Country Club, Dartmouth's oldest remaining athletic facility (established in 1899), and the Corey Ford Rugby Clubhouse. The college also maintains the Dartmouth Skiway, a skiing facility located over two mountains near the Hanover campus in Lyme Center, New Hampshire, that serves as the winter practice grounds for the Dartmouth ski team, which is a perennial contender for the NCAA Division I championship.\n\nBeginning in the fall term of 2016, Dartmouth placed all undergraduate students in one of six House communities, similar to residential colleges, including Allen House, East Wheelock House, North Park House, School House, South House, and West House, alongside independent Living Learning Communities. Dartmouth used to have nine residential communities located throughout campus, instead of ungrouped dormitories or residential colleges. The dormitories varied in design from modern to traditional Georgian styles, and room arrangements range from singles to quads and apartment suites. Since 2006, the college has guaranteed housing for students during their freshman and sophomore years. More than 3,000 students elect to live in housing provided by college.\n\nCampus meals are served by Dartmouth Dining Services, which operates 11 dining establishments around campus. Four of them are located at the center of campus in the Class of 1953 Commons, formerly Thayer Dining Hall.\n\nThe Collis Center is the center of student life and programming, serving as what would be generically termed the \"student union\" or \"campus center.\" It contains a café, study space, common areas, and a number of administrative departments, including the Academic Skills Centre. Robinson Hall, next door to both Collis and Thayer, contains the offices of a number of student organizations including the Dartmouth Outing Club and \"The Dartmouth\" daily newspaper.\n\nIn 2006, \"The Princeton Review\" ranked Dartmouth third in its \"Quality of Life\" category, and sixth for having the \"Happiest Students.\" Athletics and participation in the Greek system are the most popular campus activities. In all, Dartmouth offers more than 350 organizations, teams, and sports. The school is also home to a variety of longstanding traditions and celebrations and has a loyal alumni network; Dartmouth ranked #2 in \"The Princeton Review\" in 2006 for Best Alumni Network.\n\nIn 2014, Dartmouth College was the third highest in the nation in \"total of reports of rape\" on their main campus, with 42 reports of rape. The \"Washington Post\" attributed the high number of rape reports to the fact that a growing number of sexual assault victims feel comfortable enough to report sexual assaults that would have gone unreported in previous years. In 2015, the Huffington Post reported that Dartmouth College had the highest rate of bystander intervention of any college surveyed, with 57.7% of Dartmouth students reporting that they would take some sort of action if they saw someone acting in a \"sexually violent or harassing manner,\" compared to 45.5% of students nationally.\n\nDartmouth fraternities have an extensive history of hazing and alcohol abuse, leading to police raids and accusations of sexual harassment.\n\nDartmouth's more than 200 student organizations and clubs cover a wide range of interests. In 2007, the college hosted eight academic groups, 17 cultural groups, two honor societies, 30 \"issue-oriented\" groups, 25 performing groups, 12 pre-professional groups, 20 publications, and 11 recreational groups. Notable student groups include the nation's largest and oldest collegiate outdoors club, the Dartmouth Outing Club, which includes the nationally recognized Big Green Bus; the campus's oldest a cappella group, The Dartmouth Aires; the controversial conservative newspaper \"The Dartmouth Review\"; and \"The Dartmouth\", arguably the nation's oldest university newspaper. \"The Dartmouth\" describes itself as \"America's Oldest College Newspaper, Founded 1799.\"\n\nPartially because of Dartmouth's rural, isolated location, the Greek system dating from the 1840s is one of the most popular social outlets for students. Dartmouth is home to 32 recognized Greek houses: 17 fraternities, 12 sororities, and three coeducational organizations. In 2007, roughly 70% of eligible students belonged to a Greek organization; since 1987, students have not been permitted to join Greek organizations until their sophomore year. Dartmouth College was among the first institutions of higher education to desegregate fraternity houses in the 1950s, and was involved in the movement to create coeducational Greek houses in the 1970s. In the early first decade of the 21st century, campus-wide debate focused on a Board of Trustees recommendation that Greek organizations become \"substantially coeducational\"; this attempt to change the Greek system eventually failed. The fraternities have an extensive history of hazing and alcohol abuse, leading to police raids and accusations of sexual harassment.\n\nDartmouth also has a number of secret societies, which are student- and alumni-led organizations often focused on preserving the history of the college and initiating service projects. Most prominent among them is the Sphinx society, housed in a prominent Egyptian tomb-like building near the center of campus. The Sphinx has been the subject of numerous rumors as to its facilities, practices, and membership.\n\nThe college has an additional classification of social/residential organizations known as undergraduate societies.\n\nApproximately 20% of students participate in a varsity sport, and nearly 80% participate in some form of club, varsity, intramural, or other athletics. In 2007, Dartmouth College fielded 34 intercollegiate varsity teams: 16 for men, 16 for women, and coeducational sailing and equestrian programs. Dartmouth's athletic teams compete in the National Collegiate Athletic Association (NCAA) Division I eight-member Ivy League conference; some teams also participate in the Eastern College Athletic Conference (ECAC). As is mandatory for the members of the Ivy League, Dartmouth College does not offer athletic scholarships. In addition to the traditional American team sports (football, basketball, baseball, and ice hockey), Dartmouth competes at the varsity level in many other sports including track and field, softball, squash, sailing, tennis, rowing, soccer, skiing, and lacrosse.\n\nThe college also offers 26 club and intramural sports such as fencing, rugby, water polo, figure skating, boxing, volleyball, ultimate frisbee, and cricket, leading to a 75% participation rate in athletics among the undergraduate student body. The Dartmouth Fencing Team, despite being entirely self-coached, won the USACFC club national championship in 2014. The Dartmouth Men's Rugby Team, founded in 1951, has been ranked among the best collegiate teams in that sport, winning for example the Ivy Rugby Conference every year between 2008 and 2015. The figure skating team won the national championship five straight times from 2004 through 2008. In addition to the academic requirements for graduation, Dartmouth requires every undergraduate to complete a swim and three terms of physical education.\n\nIt is often pointed out that the charter of Dartmouth College, granted to Eleazar Wheelock in 1769, proclaims that the institution was created \"for the education and instruction of Youth of the Indian Tribes in this Land in reading, writing and all parts of Learning ... as well as in all liberal Arts and Sciences; and also of English Youth and any others.\" However, Wheelock primarily intended the college to educate White youth, and the few Native students that attended Dartmouth experienced much difficulty in an institution ostensibly dedicated to their education. The funds for the Charity School for Native Americans that preceded Dartmouth College were raised primarily by the efforts of a Native American named Samson Occom, and at least some of those funds were used to help found the college.\n\nThe college graduated only 19 Native Americans during its first two hundred years. In 1970, the college established Native American academic and social programs as part of a \"new dedication to increasing Native American enrollment.\" Since then, Dartmouth has graduated over 700 Native American students from over 200 different tribes, more than the other seven Ivy League universities combined.\n\nDartmouth is well known for its fierce school spirit and many traditions. The college functions on a quarter system, and one weekend each term is set aside as a traditional celebratory event, known on campus as \"big weekends\" or \"party weekends\". In the fall term, Homecoming (officially called Dartmouth Night) is marked by a bonfire on the Green constructed by the freshman class. Winter term is celebrated by Winter Carnival, a tradition started in 1911 by the Dartmouth Outing Club to promote winter sports. This tradition is the oldest in the United States, and subsequently went on to catch on at other New England colleges. In the spring, Green Key is a weekend mostly devoted to campus parties and celebration.\n\nThe summer term was formerly marked by Tubestock, an unofficial tradition in which the students used wooden rafts and inner tubes to float on the Connecticut River. Begun in 1986, Tubestock was ended in 2006 by town ordinance. The Class of 2008, during their summer term on campus in 2006, replaced the defunct Tubestock with Fieldstock. This new celebration includes a barbecue, live music, and the revival of the 1970s and 1980s tradition of racing homemade chariots around the Green. Unlike Tubestock, Fieldstock is funded and supported by the College.\n\nAnother longstanding tradition is four-day, student-run Dartmouth Outing Club trips for incoming freshmen, begun in 1935. Each trip concludes at the Moosilauke Ravine Lodge. In 2011, over 96% of freshmen elected to participate.\n\nDartmouth's motto, chosen by Eleazar Wheelock, is \"Vox clamantis in deserto\". The Latin motto is literally translated as \"A calling voice in the wilderness\", but is more often rendered as \"A voice crying out in the wilderness\". The phrase appears five times in the Bible and is a reference to the college's location on what was once the frontier of European settlement. Richard Hovey's \"Men of Dartmouth\" was elected as the best of Dartmouth's songs in 1896, and became the school's official song in 1926. The song was retitled to \"Alma Mater\" in the 1980s when its lyrics were changed to refer to women as well as men.\n\nDartmouth's 1769 royal charter required the creation of a seal for use on official documents and diplomas. The college's founder Eleazar Wheelock designed a seal for his college bearing a striking resemblance to the seal of the Society for the Propagation of the Gospel, a missionary society founded in London in 1701, in order to maintain the illusion that his college was more for mission work than for higher education. Engraved by a Boston silversmith, the seal was ready by commencement of 1773. The trustees officially accepted the seal on August 25, 1773, describing it as:\n\nOn October 28, 1926, the trustees affirmed the charter's reservation of the seal for official corporate documents alone. The College Publications Committee commissioned noted typographer William Addison Dwiggins to create a line drawing version of the seal in 1940 that saw widespread use. Dwiggins' design was modified during 1957 to change the date from \"1770\" to \"1769\", to accord with the date of the college charter. The trustees commissioned a new set of dies with a date of \"1769\" to replace the old dies, now badly worn after almost two hundred years of use. The 1957 design continues to be used under trademark number 2305032.\n\nOn October 28, 1926, the trustees approved a \"Dartmouth College Shield\" for general use. Artist and engraver W. Parke Johnson designed this emblem on the basis of the shield that is depicted at the center of the original seal. This design does not survive. On June 9, 1944, the trustees approved another coat of arms based on the shield part of the seal, this one by Canadian artist and designer Thoreau MacDonald. That design was used widely and, like Dwiggins' seal, had its date changed from \"1770\" to \"1769\" around 1958. That version continues to be used under trademark registration number 3112676 and others.\n\nCollege designer John Scotford made a stylized version of the shield during the 1960s, but it did not see the success of MacDonald's design. The shield appears to have been used as the basis of the shield of Dartmouth Medical School, and it has been reproduced in sizes as small as 20 micrometers across. The design has appeared on Rudolph Ruzicka's Bicentennial Medal (Philadelphia Mint, 1969) and elsewhere.\n\nDartmouth has never had an official mascot. The nickname \"The Big Green,\" originating in the 1860s, is based on students' adoption of a shade of forest green (\"Dartmouth Green\") as the school's official color in 1866. Beginning in the 1920s, the Dartmouth College athletic teams were known by their unofficial nickname \"the Indians\", a moniker that probably originated among sports journalists. This unofficial mascot and team name was used until the early 1970s, when its use came under criticism. In 1974, the Trustees declared the \"use of the [Indian] symbol in any form to be inconsistent with present institutional and academic objectives of the College in advancing Native American education.\" Some alumni and students, as well as the conservative student newspaper, \"The Dartmouth Review\", have sought to return the Indian symbol to prominence, but never succeeded in doing so.\n\nVarious student initiatives have been undertaken to adopt a mascot, but none has become \"official.\" One proposal devised by the college humor magazine the \"Dartmouth Jack-O-Lantern\" was Keggy the Keg, an anthropomorphic beer keg who makes occasional appearances at college sporting events. Despite student enthusiasm for Keggy, the mascot has received approval from only the student government. In November 2006, student government attempted to revive the \"Dartmoose\" as a potential replacement amid renewed controversy surrounding the former unofficial Indian mascot.\n\nDartmouth's alumni are known for their devotion to the college. Most start by giving to the Senior Class Gift. According to a 2008 article in \"The Wall Street Journal\" based on data from payscale.com, Dartmouth graduates also earn higher median salaries at least 10 years after graduation than alumni of any other American university surveyed.\n\nBy 2008, Dartmouth had graduated 238 classes of students and has over 60,000 living alumni in a variety of fields.\n\nNelson A. Rockefeller, 41st Vice President of the United States and 49th Governor of New York, graduated \"cum laude\" from Dartmouth with a degree in economics in 1930. Over 164 Dartmouth graduates have served in the United States Senate and United States House of Representatives, such as Massachusetts statesman Daniel Webster. Cabinet members of American presidents include Attorney General Amos T. Akerman, Secretary of Defense James V. Forrestal, Secretary of Labor Robert Reich, former Secretary of the Treasury Henry Paulson, and former Secretary of the Treasury Timothy Geithner. C. Everett Koop was the Surgeon General of the United States under President Ronald Reagan. Two Dartmouth alumni have served as justices on the Supreme Court of the United States: Salmon P. Chase and Levi Woodbury. Eugene Norman Veasey (class of 1954) served as the Chief Justice of Delaware. The 46th and current Governor of Pennsylvania Tom Wolf, and the 42nd and current Governor of Illinois, businessman Bruce Rauner, are also Dartmouth alumni.\n\nIn literature and journalism, Dartmouth has produced thirteen Pulitzer Prize winners: Thomas M. Burton, Richard Eberhart, Dan Fagin, Paul Gigot, Frank Gilroy, Jake Hooker, Nigel Jaquiss, Joseph Rago, Martin J. Sherwin, David K. Shipler, David Shribman, Justin Harvey Smith and Robert Frost. Frost, who received four Pulitzer Prizes for Poetry in his lifetime, attended but did not graduate from Dartmouth; he is, however, the only person to have received two honorary degrees from Dartmouth.\n\nOther authors and media personalities include ABC Senior White House correspondent Jake Tapper, novelist and founding editor of \"The Believer\" Heidi Julavits, \"Dean of rock critics\" Robert Christgau, National Book Award winners Louise Erdrich and Phil Klay, novelist/screenwriter Budd Schulberg, political analyst Dinesh D'Souza, radio talk show host Laura Ingraham, commentator Mort Kondracke, and journalist James Panero. Norman Maclean, a former professor at the University of Chicago and author of \"A River Runs Through It and Other Stories\", graduated from Dartmouth in 1924. Theodor Geisel, better known as children's author Dr. Seuss, was a member of the class of 1925.\n\nIn the area of religion and theology, Dartmouth alumni include priests and ministers Ebenezer Porter, Jonathan Clarkson Gibbs, Caleb Sprague Henry, Arthur Whipple Jenks, Solomon Spalding, and Joseph Tracy; and rabbis Marshall Meyer, Arnold Resnicoff, and David E. Stern. Hyrum Smith, brother of Mormon Prophet Joseph Smith, attended the college in his teens. He was Patriarch of the LDS Church.\n\nDartmouth alumni in academia include Stuart Kauffman and Jeffrey Weeks, both recipients of MacArthur Fellowships (commonly called \"genius grants\"). Dartmouth has also graduated three Nobel Prize winners: Owen Chamberlain (Physics, 1959), K. Barry Sharpless (Chemistry, 2001), and George Davis Snell (Physiology or Medicine, 1980). Educators include founder and first president of Bates College, Oren Burbank Cheney (1839), the current chancellor of the University of California, San Diego, Marye Anne Fox (PhD. in Chemistry, 1974), founding president of Vassar College Milo Parker Jewett, founder and first president of Kenyon College Philander Chase, first professor of Wabash College Caleb Mills, and former president of Union College Charles Augustus Aiken. Nine of Dartmouth's 17 presidents were alumni of the College.\n\nDartmouth alumni serving as CEOs or company presidents and executives include Charles Alfred Pillsbury, founder of the Pillsbury Company and patriarch of the Pillsbury family, Sandy Alderson (San Diego Padres), John Donahoe (eBay), Louis V. Gerstner, Jr. (IBM), Charles E. Haldeman (Putnam Investments), Donald J. Hall, Sr. (Hallmark Cards), Jeffrey R. Immelt (General Electric), Gail Koziara Boudreaux (United Health Care), Grant Tinker (NBC), and Brian Goldner (Hasbro).\n\nIn film, entertainment, and television, Dartmouth is represented by Budd Schulberg, Academy Award-winning screenwriter of \"On the Waterfront\", Michael Phillips, who won the Academy Award for best picture as co-producer of \"The Sting\", Rachel Dratch, a cast member of \"Saturday Night Live\", Shonda Rhimes creator of \"Grey's Anatomy, Private Practice\" and \"Scandal\", Chris Meledandri Executive Producer of \"Ice Age\", \"Horton Hears a Who!\", and \"Despicable Me\", and the title character of \"Mister Rogers' Neighborhood\", Fred Rogers. Other notable film and television figures include Sarah Wayne Callies (\"Prison Break\"), Emmy Award winner Michael Moriarty, Andrew Shue of \"Melrose Place\", Aisha Tyler of \"Friends\" and \"24\", Connie Britton of \"Spin City\", \"The West Wing\" and \"Friday Night Lights\", Mindy Kaling of \"The Office\" and \"The Mindy Project\", and David Harbour of \"Stranger Things\".\n\nA number of Dartmouth alumni have found success in professional sports. In baseball, Dartmouth alumni include All-Star and three-time Gold Glove winner and manager Brad Ausmus, All-Star reliever Mike Remlinger, and pitcher Kyle Hendricks. Professional football players include former Miami Dolphins quarterback Jay Fiedler, linebacker Reggie Williams, three-time Pro Bowler Nick Lowery, quarterback Jeff Kemp, and Tennessee Titans tight end Casey Cramer, plus Miami Dolphins defensive coordinator Matt Burke. Dartmouth has also produced a number of Olympic competitors. Adam Nelson won the silver medal in the shot put in the 2000 Sydney Olympics and the gold medal at the 2004 Athens Olympics to go along with his gold medal in the 2005 World Championships in Athletics in Helsinki. Kristin King and Sarah Parsons were members of the United States' 2006 bronze medal-winning ice hockey team. Cherie Piper, Gillian Apps, and Katie Weatherston were among Canada's ice hockey gold medalists in 2006.\n\nDick Durrance and Tim Caldwell competed for the United States in skiing in the 1936 and 1976 Winter Olympics, respectively. Arthur Shaw, Earl Thomson, Edwin Myers, Marc Wright, Adam Nelson, Gerry Ashworth, and Vilhjálmur Einarsson have all won medals in track and field events. Former heavyweight rower Dominic Seiterle is a member of the Canadian national rowing team and won a gold medal at the 2008 Summer Olympics in the men's 8+ event.\n\nDartmouth College has appeared in or been referenced by a number of popular media. Most notably, the 1978 comedy film \"National Lampoon's Animal House\" was co-written by Chris Miller '63, and is based loosely on a series of stories he wrote about his fraternity days at Dartmouth. In a CNN interview, John Landis said the movie was \"based on Chris Miller's real fraternity at Dartmouth\", Alpha Delta Phi. Dartmouth's Winter Carnival tradition was the subject of the 1939 film \"Winter Carnival\" starring Ann Sheridan and written by Budd Schulberg '36 and F. Scott Fitzgerald.\n\n"}
{"id": "8419", "url": "https://en.wikipedia.org/wiki?curid=8419", "title": "Dartmouth, Devon", "text": "Dartmouth, Devon\n\nDartmouth is a town and civil parish in the English county of Devon. It is a tourist destination set on the western bank of the estuary of the River Dart, which is a long narrow tidal ria that runs inland as far as Totnes. It lies within the South Devon Area of Outstanding Natural Beauty and South Hams district, and had a population of 5,512 in 2001, reducing to 5,064 at the 2011 census There are two electoral wards in the \"Dartmouth\" area (Townstal & Kingswear). Their combined population at the above census was 6,822.\n\nIn 1086, the Domesday Book lists \"Dunestal\" as the only settlement in the area which now makes up the parish of Dartmouth. It was held by Walter of Douai. It paid tax on half a hide, and had two plough teams, two slaves, five villagers and four smallholders. There were six cattle, 40 sheep and 15 goats. At this time Townstal (as the name became) was apparently a purely agricultural settlement, centred around the church. Walter of Douai rebelled against William II, and his lands were confiscated and added to the honour of Marshwood (Dorset), which sublet Townstal and Dartmouth to the FitzStephens. It was probably during the early part of their proprietorship that Dartmouth began to grow as a port, as it was of strategic importance as a deep-water port for sailing vessels. The port was used as the sailing point for the Crusades of 1147 and 1190, and Warfleet Creek, close to Dartmouth Castle is supposed by some to be named for the vast fleets which assembled there. Dartmouth was a home of the Royal Navy from the reign of Edward III and was twice surprised and sacked during the Hundred Years' War, after which the mouth of the estuary was closed every night with a great chain. The narrow mouth of the Dart is protected by two fortified castles, Dartmouth Castle and Kingswear Castle. Originally Dartmouth's only wharf was Bayard's Cove, a relatively small area protected by a fort at the southern end of the town.\n\nIn 1373 Geoffrey Chaucer visited and among the pilgrims in his Canterbury Tales\n\nNotwithstanding Dartmouth's connections with the crown and respectable society, it was a major base for privateering in medieval times. John Hawley or Hauley, a licensed privateer and sometime mayor of Dartmouth is reputed to be a model for Chaucer's \"schipman\".\n\nThe earliest street in Dartmouth to be recorded by name (in the 13th century) is Smith Street. Several of the houses on the street are originally late 16th century or early 17th century and probably rebuilt on the site of earlier medieval dwellings. The street name undoubtedly derives from the smiths and shipwrights who built and repaired ships here when the tidal waters reached as far as this point. Smith Street was also the site of the town pillory in medieval times.\n\nThe first church in the parish was St Clement's, Townstal, which may have existed in some form before the 1190s. It was granted by the FitzStephens to Torre Abbey in about 1198, the Abbey having been founded in 1196, and the present stone-built church was probably started shortly after this.\n\nManorial transactions are first recorded in 1220, when the manor house was at Norton, about half a mile west of Townstal. Names of occupations also started to appear, including taverner, tailor, coggar, korker, goldsmith, glover, skinner and baker. The \"Fosse\", now Foss Street, a dam across the creek known later as The Mill Pool, was first mentioned in 1243. The flow of water out of the pool through the Mill Gullet powered a tidal mill. The dam was used as an unofficial footpath linking Clifton, to the south, with Hardness, to the north. Before this it was necessary to go westwards to the head of the creek at Ford to travel between the two settlements. The lord of the manor was given the rights to hold a weekly market and an annual fair in 1231. In 1281, a legal case proved that the Lord of Totnes had the right to charge tolls on ships using the river, and this right was bought by Nicholas of Tewkesbury in 1306, who conveyed the town, river and port to the king in 1327, so making Dartmouth a Royal Borough. The king gave the river to the Duchy of Cornwall in 1333, who still own the \"fundus\" or bed of the river. In 1335 Edward III granted Dartmouth to Joan of Carew, whose husband was Lord of Stoke Fleming, and almost immediately she obediently passed the lordship to Guy de Bryan, one of the king's leading ministers. In 1341, the town was granted a Royal Charter, which allowed for the election of a mayor. The borough was required to provide two ships for forty days per year. After 1390, no more is heard of lordship rights, and the borough became effectively independent of any lord.\n\nSt Saviour's Church was constructed in 1335 and consecrated in 1372. It contains a pre-Reformation oak rood screen built in 1480 and several monuments including the tomb of John Hawley (d. 1408) and his two wives, covered with a large brass plate effigy of all three. A large medieval ironwork door is decorated with two leopards of the Plantagenets and is possibly the original portal. Although it is dated \"1631\", this is thought to be the date of a subsequent refurbishment coincidental with major renovations of the church in the 17th century. The gallery of the church is decorated with the heraldic crests of prominent local families and is reputed to be constructed of timbers from ships captured during the defeat of the Spanish Armada, although this has not been categorically substantiated. An engraving of the interior of the church and showing the screen provided the inspiration for Letitia Elizabeth Landon's poetical illustration \"Dartmouth Church\" in Fisher's Drawing Room scrap Book, 1833.\nIn mediaeval times, land access from the Totnes direction passed the manor at Norton and the parish church at Townstal before falling steeply along what are now Church Road, Mount Boone and Ridge Hill to the river at Hardness. There were steeper routes via Townstal Hill and Clarence Street and also via Brown's Hill. These were all too steep for vehicles, so the only land access was by packhorse. In 1671 there is the first mention of the building of the \"New Ground\". A previously existing sandbank was built up using ships' ballast, and a quay wall was built around it to provide more mooring space. The area proved too unstable to be built on, and is now the Royal Avenue Gardens. It was originally linked to the corner of the Quay by a bridge, opposite Duke Street. At the other end of The Quay, Spithead extended into the river for a few yards. \nIn 1592 the \"Madre de Deus\", a Portuguese treasure ship captured by the English in the Azores, docked at Dartmouth Harbour. It attracted all manner of traders, dealers, cutpurses and thieves and by the time Sir Walter Raleigh arrived to reclaim the Crown's share of the loot, a cargo estimated at half a million pounds had been reduced to £140,000. Still, ten freighters were needed to carry the treasure to London.\n\nHenry Hudson put into Dartmouth on his return from North America, and was arrested for sailing under a foreign flag. The Pilgrim Fathers put into Dartmouth's Bayard's Cove, en route from Southampton to America. They rested a while before setting off on their journey in the \"Mayflower\" and the \"Speedwell\" on 20 August 1620. About 300 miles west of Land's End, upon realising that the \"Speedwell\" was unseaworthy, it returned to Plymouth. The \"Mayflower\" departed alone to complete the crossing to Cape Cod. Dartmouth's sister city is Dartmouth, Massachusetts.\n\nThe town contains many medieval and Elizabethan streetscapes and is a patchwork of narrow lanes and stone stairways. A significant number of the historic buildings are listed. One of the most obvious is the Butterwalk, built 1635 to 1640. Its intricately carved wooden fascia is supported on granite columns. Charles II held court in the Butterwalk whilst sheltering from storms in 1671 in a room which now forms part of Dartmouth Museum. Much of the interior survives from that time.\n\nThe Royal Castle Hotel was built in 1639 on the then new quay. The building was re-fronted in the 19th century, and as the new frontage is itself listed, it is not possible to see the original which lies beneath. A claimant for the oldest building is a former merchant's house in Higher Street, now a Good Beer Guide listed public house called \"the Cherub\", built circa 1380. Agincourt House (next to the Lower Ferry) is also 14th century.\n\nDartmouth sent numerous ships to join the English fleet that attacked the Spanish Armada, including the Roebuck, Crescent and Hart. The Nuestra Señora del Rosario, the Spanish Armada's \"payship\" commanded by Admiral Pedro de Valdés, was captured along with all its crew by Sir Francis Drake. It was reportedly anchored in the River Dart for more than a year and the crew were used as labourers on the nearby Greenway Estate which was the home of Sir Humphrey Gilbert and his half-brother Sir Walter Raleigh. Greenway was later the home of Dame Agatha Christie.\n\nThe remains of a fort at Gallants Bower just outside the town are some of the best preserved remains of a Civil War defensive structure. The fort was built by Royalist occupation forces in c. 1643 to the south east of the town, with a similar fort at Mount Ridley on the opposite slopes of what is now Kingswear. The Parliamentarian General Fairfax attacked from the north in 1646, taking the town and forcing the Royalists to surrender, after which Gallants Bower was demolished.\n\nBefore 1671, what is now the town centre was almost entirely tidal mud flats. The New Road (now Victoria Road) was constructed across the bed of the (silted up) Mill Pool and up the Ford valley after 1823. Spithead was extended in 1864 when the Dartmouth and Torbay Railway arrived in Kingswear and a pontoon was constructed, linked to Spithead by a bridge. The railway directors and others formed the Dartmouth Harbour Commissioners. \nAt this time, all the roads in those parts of Dartmouth which were not land reclamations were very narrow. In 1864-7 Higher Street was widened into Southtown and linked to Lower Street, which was also widened, with the northern part renamed Fairfax Place. Some of the buildings were rebuilt further back with decorative frontages.\nIn 1881 the Harbour Commissioners produced a scheme for an embankment or esplanade from near the Lower Ferry to Hardness, across the remains of The Pool, to provide an attraction for tourists and further mooring space. It was completed in 1885 after much disagreement between the Borough, the Commissioners and the Railway (now the Great Western Railway). A new station was also built at this time. The building of the Embankment left a section of river isolated between Spithead and the New Ground, which is known as The Boatfloat, and is linked to the river by a bridge for small vessels under the road.\n\nThe coming of steam ships led to Dartmouth being used as a bunkering port, with coal being brought in by ship or train. Coal lumpers were members of gangs, who competed to bunker the ships by racing to be first to a ship. This led to the men living as close as possible to the river, and their tenements became grossly overcrowded, with the families living in slum conditions, with up to 15 families in one house, one family to a room.\n\nThe Royal National Lifeboat Institution opened the Dart Lifeboat Station at the Sand Quay in 1878, but it was closed in 1896. In all this time only one effective rescue was made by the lifeboat.\n\nThe area to the north of Ridge Hill was a shallow and muddy bay (\"Coombe Mud\") with a narrow road running along the shore linking with the Higher Ferry. The mud was a dumping ground for vessels, including a submarine. The reclamation was completed in 1937 by the extension of the Embankment and the reclamation of the mud behind it, which became Coronation Park. \n\nIn the 1920s, aided by government grants, the council made a start on clearing the slums. This was aided by the decline in the use of coal as a fuel for ships. The slums were demolished, and the inhabitants were rehoused in new houses in the Britannia Avenue area, to the west of the old village or hamlet of Townstal. The process was interrupted by the second world war, but was resumed with the construction of many prefabs, and later more houses. Community facilities were minimal at first, but a central area was reserved for a church, which was used by the Baptists and opened in 1954, together with a speedway track. The latter was later used for housing, but a new community centre was opened nearby, together with a leisure centre, an outdoor swimming pool, and later an indoor pool, and supermarkets. There are also light industrial units.\n\nIn the latter part of the Second World War the town was a base for American forces and one of the departure points for Utah Beach in the D Day landings. Slipways and harbour improvements were also constructed. Much of the surrounding countryside and notably Slapton Sands was closed to the public while it was used by US troops for practise landings and manoeuvres. \nBetween 1985 and 1990 the Embankment was widened by 6 metres and raised to prevent flooding at spring tides. A tidal lock gate was provided at the Boatfloat bridge, which could be closed at such times.\n\nDart Lifeboat Station was reopened in 2007, the first time that a lifeboat had been stationed in the town since 1896. It has initially been kept in a temporary building in Coronation Park.\n\nIn 2010, a fire seriously damaged numerous historical properties in Fairfax Place and Higher Street. Several were Tudor and Grade I or Grade II listed buildings.\n\nThe town was an ancient borough, incorporated by Edward III, known formally as Clifton-Dartmouth-Hardness, and consisting of the three parishes of \"St Petrox\", \"St Saviour\" and \"Townstal\", and incorporating the hamlets of Ford, Old Mill and Norton. It was reformed under the Municipal Corporations Act 1835. The town returned two members of parliament from the 13th century until 1835, after which one MP was elected until the town was disenfranchised in 1868. It remained a municipal borough until 1974, when it was merged into the South Hams district, and became a successor parish of Dartmouth with a town council.\n\nDartmouth Town Council is the lowest of three tiers of local government. It consists of 16 councillors representing the two wards of Clifton and Townstal. At the second tier, Dartmouth forms part of the Dartmouth and Kingswear ward of South Hams District Council, which returns three councillors. At the upper tier of local government Dartmouth and Kingswear Electoral Division elects one member to Devon County Council.\n\nThe Port of Dartmouth Royal Regatta takes place annually over three days at the end of August. The event sees the traditional regatta boat races along with markets, fun fairs, community games, musical performances, air displays including the Red Arrows and fireworks. A Royal Navy guard ship is often present at the event.\nOther cultural events include beer festivals in February and July (the latter in Kingswear), a music festival and an art and craft weekend in June, a food festival in October and a Christmas candlelit event.\n\nThe Flavel Centre incorporates the public library and performance spaces, featuring films, live music and comedy and exhibitions.\n\nBayard's Cove has been used in several television productions, including \"The Onedin Line\" a popular BBC television drama series that ran from 1971 to 1980. Many of the scenes from the BBC's popular series 'Down to Earth', starring Ricky Tomlinson, were filmed at various locations around the town.\n\nNotable tourist attractions include the Dartmouth Royal Naval College, Dartmouth Castle and the Dartmouth Steam Railway which terminates at Kingswear on the opposite bank of the river.\n\nBoat cruises to nearby places along the coast (such as Torbay and Start Bay) and up the river (to Totnes, Dittisham and the Greenway Estate) are provided by several companies. The paddlesteamer PS Kingswear Castle returned to the town in 2013. The South West Coast Path National Trail passes through the town, and also through extensive National Trust coastal properties at Little Dartmouth and Brownstone (Kingswear). The Dart Valley Trail starts in Dartmouth, with routes either side of the River Dart as far as Dittisham, and continuing to Totnes via Cornworthy, Tuckenhay and Ashprington. The area has long been well regarded for yachting, and there are extensive marinas at Sandquay, Kingswear and Noss (approximately one mile north of Kingswear).\n\nThe nearest Met Office weather station is Slapton, about 5 miles south-south west of Dartmouth and a similar distance from the coast. As with the rest of the British Isles and South West England, the area experiences a maritime climate with warm summers and mild winters - this is particularly pronounced due to its position near the coast - extremes range from a record low of just in January 1987 up to a record high of during June 1976.\n\nDartmouth is linked to Kingswear, on the other side of the River Dart, by three ferries. The Higher Ferry and the Lower Ferry are both vehicular ferries. The Passenger Ferry, as its name suggests, carries only passengers, principally to connect with the Dartmouth Steam Railway at Kingswear railway station. The nearest bridge across the Dart is in Totnes, some away by road.\n\nThe A379 road runs through Dartmouth, linking the town to Slapton and Kingsbridge to the southwest and to Torbay to the east across the Higher Ferry. The A3122 connects Dartmouth to a junction with the A381, and hence to both Totnes and a more direct route to Kingsbridge.\nStagecoach Devon provides local town bus services and links to Plymouth, Totnes and Exeter, and Kingsbridge. In addition Stagecoach Devon provides links to the Torbay resorts of Brixham, Paignton and Torquay from Kingswear via the ferry.\n\nNo railway has ever run to Dartmouth, but the town does have a railway station, opened on 31st March 1890 to replace the original facility on the pontoon, although it is now a restaurant. The railway line to Kingswear was opened in 1864. As a result of shortage of capital, a deviation from the original scheme to run the line from Churston to Greenway with a steamer service to Dartmouth was proposed, but defeated in Parliament. It had been suggested that this could, at a later date, be used as a jumping off point for a bridge to the west bank of the Dart and a line direct to Dartmouth.In 1900, a Light Railway scheme was proposed for a crossing of the Dart near Maypool to join another line from Totnes and then proceed to Kingsbridge and Yealmpton, with a branch to Salcombe. This was also defeated by lack of funds. The railway terminated at a station called \"Kingswear for Dartmouth\" (now on the Dartmouth Steam Railway) and a ferry took passengers across the river to the station at Dartmouth railway station, which had a dedicated pontoon. British Railways formally closed the line to mainline passenger trains in 1973, but it immediately re-opened as a heritage line and has run as one ever since.\n\nThe town is home to the Royal Navy's officer training college (Britannia Royal Naval College), where all officers of the Royal Navy and many foreign naval officers are trained.\n\nDartmouth has one secondary school — formerly (Dartmouth Community College) now Dartmouth Academy — an all-through school for those aged 3–16, and two primary schools: (Dartmouth Primary school (now part of Dartmouth Academy) and St John the Baptist R.C. Primary School). Dartmouth Community College and Dartmouth Primary School are part of the Dartmouth Learning Campus; as from September 2007, Dartmouth Community College is part of a federation with Dartmouth Primary School and Nursery, meaning that the two schools share one governing body for pupils aged 1 to 16. Dartmouth also has a pre-school in the centre of town, established for over 40 years and based in the old Victorian school rooms at South Ford Road. It provides care for 2- to 5-year-olds and is run as a charitable organisation.\n\nDartmouth has a Non-League football club Dartmouth A.F.C. who play at Long Cross.\n\nDartmouth also hosts the annual \"World Indoor Rally Championship\", based on slot car racing in the late summer.\n\nAt the end of August and early September there is the annual Port of Dartmouth Royal Regatta.\n\nSince 1905 Dartmouth has had a greenhouse as part of the Royal Avenue Gardens. In May 2013 this building, used for the previous 10 years by Dartmouth in Bloom, a not-for-profit organisation affiliated with Britain in Bloom, was closed as structurally unsound. There are proposals to restore the greenhouse to its prior Edwardian style.\n\nThomas Newcomen, the inventor of the atmospheric engine – the first successful steam-powered pumping engine – was born in Dartmouth in 1663. The location of his house in Lower Street is marked with a plaque, although the building itself was demolished (and elements incorporated into local architect Thomas Lidstone's house on Ridge Hill) in the 19th century to make way for a new road which was named after Newcomen. An 18th-century working Newcomen steam engine is on display in the town.\n\nThe town was home to the civil engineer and calculating prodigy George Parker Bidder (1806–1878), who is notable for his work on railways over much of the world, as well as the docks of the East End in the Port of London. Bidder served on the town council, and his expertise was instrumental in draining the area which is now the centre of the town. He also undertook pioneering work with Samuel Lake on steam trawling whilst living in the town. Bidder died at his home at Paradise Point near Warfleet Creek and is buried at nearby Stoke Fleming.\n\nFlora Thompson lived in Above Town between 1928 and 1940, writing \"Lark Rise\" and \"Over to Candleford\" during this time. The books were later combined into a single volume with \"Candleford Green\" and published as \"Lark Rise to Candleford\". She is buried at Longcross Cemetery.\n\nThe stage and film actress Rachel Kempson (1910–2003) was born in Dartmouth. She was the wife of Sir Michael Redgrave and mother of Vanessa, Lynn and Corin, and published her autobiography, \"Life Among the Redgraves\", in 1988.\n\nGordon Onslow Ford (1912–2003), a leading British surrealist painter, attended the Royal Naval College.\n\nSir John Harvey Jones (1924-2008), Businessman and television presenter, attended the Royal Naval College.\n\nChristopher Robin Milne, son of A. A. Milne, after whom the character Christopher Robin in the Winnie-the-Pooh books was named, used to own the Harbour Bookshop. The bookshop was reported as facing closure in September 2011 and the report was fulfilled.\n\nTheodore Veale, recipient of the Victoria Cross during the First World War.\n\n"}
{"id": "8420", "url": "https://en.wikipedia.org/wiki?curid=8420", "title": "Dodo", "text": "Dodo\n\nThe dodo (\"Raphus cucullatus\") is an extinct flightless bird that was endemic to the island of Mauritius, east of Madagascar in the Indian Ocean. The dodo's closest genetic relative was the also-extinct Rodrigues solitaire, the two forming the subfamily Raphinae of the family of pigeons and doves. The closest living relative of the dodo is the Nicobar pigeon. A white dodo was once thought to have existed on the nearby island of Réunion, but this is now thought to have been confusion based on the Réunion ibis and paintings of white dodos.\n\nSubfossil remains show the dodo was about tall and may have weighed in the wild. The dodo's appearance in life is evidenced only by drawings, paintings, and written accounts from the 17th century. Because these vary considerably, and because only some illustrations are known to have been drawn from live specimens, its exact appearance in life remains unresolved, and little is known about its behaviour. Though the dodo has historically been considered fat and clumsy, it is now thought to have been well-adapted for its ecosystem. It has been depicted with brownish-grey plumage, yellow feet, a tuft of tail feathers, a grey, naked head, and a black, yellow, and green beak. It used gizzard stones to help digest its food, which is thought to have included fruits, and its main habitat is believed to have been the woods in the drier coastal areas of Mauritius. One account states its clutch consisted of a single egg. It is presumed that the dodo became flightless because of the ready availability of abundant food sources and a relative absence of predators on Mauritius.\n\nThe first recorded mention of the dodo was by Dutch sailors in 1598. In the following years, the bird was hunted by sailors and invasive species, while its habitat was being destroyed. The last widely accepted sighting of a dodo was in 1662. Its extinction was not immediately noticed, and some considered it to be a mythical creature. In the 19th century, research was conducted on a small quantity of remains of four specimens that had been brought to Europe in the early 17th century. Among these is a dried head, the only soft tissue of the dodo that remains today. Since then, a large amount of subfossil material has been collected on Mauritius, mostly from the Mare aux Songes swamp. The extinction of the dodo within less than a century of its discovery called attention to the previously unrecognised problem of human involvement in the disappearance of entire species. The dodo achieved widespread recognition from its role in the story of \"Alice's Adventures in Wonderland\", and it has since become a fixture in popular culture, often as a symbol of extinction and obsolescence.\n\nThe dodo was variously declared a small ostrich, a rail, an albatross, or a vulture, by early scientists. In 1842, Danish zoologist Johannes Theodor Reinhardt proposed that dodos were ground pigeons, based on studies of a dodo skull he had discovered in the collection of the Natural History Museum of Denmark. This view was met with ridicule, but was later supported by English naturalists Hugh Edwin Strickland and Alexander Gordon Melville in their 1848 monograph \"The Dodo and Its Kindred\", which attempted to separate myth from reality. After dissecting the preserved head and foot of the specimen at the Oxford University Museum and comparing it with the few remains then available of the extinct Rodrigues solitaire (\"Pezophaps solitaria\") they concluded that the two were closely related. Strickland stated that although not identical, these birds shared many distinguishing features of the leg bones, otherwise known only in pigeons.\n\nStrickland and Melville established that the dodo was anatomically similar to pigeons in many features. They pointed to the very short keratinous portion of the beak, with its long, slender, naked basal part. Other pigeons also have bare skin around their eyes, almost reaching their beak, as in dodos. The forehead was high in relation to the beak, and the nostril was located low on the middle of the beak and surrounded by skin, a combination of features shared only with pigeons. The legs of the dodo were generally more similar to those of terrestrial pigeons than of other birds, both in their scales and in their skeletal features. Depictions of the large crop hinted at a relationship with pigeons, in which this feature is more developed than in other birds. Pigeons generally have very small clutches, and the dodo is said to have laid a single egg. Like pigeons, the dodo lacked the vomer and septum of the nostrils, and it shared details in the mandible, the zygomatic bone, the palate, and the hallux. The dodo differed from other pigeons mainly in the small size of the wings and the large size of the beak in proportion to the rest of the cranium.\n\nThroughout the 19th century, several species were classified as congeneric with the dodo, including the Rodrigues solitaire and the Réunion solitaire, as \"Didus solitarius\" and \"Raphus solitarius\", respectively (\"Didus\" and \"Raphus\" being names for the dodo genus used by different authors of the time). An atypical 17th-century description of a dodo and bones found on Rodrigues, now known to have belonged to the Rodrigues solitaire, led Abraham Dee Bartlett to name a new species, \"Didus nazarenus\", in 1852. Based on solitaire remains, it is now a synonym of that species. Crude drawings of the red rail of Mauritius were also misinterpreted as dodo species; \"Didus broeckii\" and \"Didus herberti\".\n\nFor many years the dodo and the Rodrigues solitaire were placed in a family of their own, the Raphidae (formerly Dididae), because their exact relationships with other pigeons were unresolved. Each was also placed in its own monotypic family (Raphidae and Pezophapidae, respectively), as it was thought that they had evolved their similarities independently. Osteological and DNA analysis has since led to the dissolution of the family Raphidae, and the dodo and solitaire are now placed in their own subfamily, Raphinae, within the family Columbidae.\n\nIn 2002, American geneticist Beth Shapiro and colleagues analysed the DNA of the dodo for the first time. Comparison of mitochondrial cytochrome \"b\" and 12S rRNA sequences isolated from a tarsal of the Oxford specimen and a femur of a Rodrigues solitaire confirmed their close relationship and their placement within the Columbidae. The genetic evidence was interpreted as showing the Southeast Asian Nicobar pigeon (\"Caloenas nicobarica\") to be their closest living relative, followed by the crowned pigeons (\"Goura\") of New Guinea, and the superficially dodo-like tooth-billed pigeon (\"Didunculus strigirostris\") from Samoa (its scientific name refers to its dodo-like beak). This clade consists of generally ground-dwelling island endemic pigeons. The following cladogram shows the dodo's closest relationships within the Columbidae, based on Shapiro et al., 2002:\n\nA similar cladogram was published in 2007, inverting the placement of \"Goura\" and \"Dicunculus\" and including the pheasant pigeon (\"Otidiphaps nobilis\") and the thick-billed ground pigeon (\"Trugon terrestris\") at the base of the clade. The DNA used in these studies was obtained from the Oxford specimen, and since this material is degraded, and no usable DNA has been extracted from subfossil remains, these findings still need to be independently verified. Based on behavioural and morphological evidence, Jolyon C. Parish proposed that the dodo and Rodrigues solitaire should be placed in the subfamily Gourinae along with the \"Groura\" pigeons and others, in agreement with the genetic evidence. In 2014, DNA of the only known specimen of the recently extinct spotted green pigeon (\"Caloenas maculata\") was analysed, and it was found to be a close relative of the Nicobar pigeon, and thus also the dodo and Rodrigues solitaire.\n\nThe 2002 study indicated that the ancestors of the dodo and the solitaire diverged around the Paleogene-Neogene boundary. The Mascarene Islands (Mauritius, Réunion, and Rodrigues), are of volcanic origin and are less than 10 million years old. Therefore, the ancestors of both birds probably remained capable of flight for a considerable time after the separation of their lineage. The Nicobar and spotted green pigeon were placed at the base of a lineage leading to the Raphinae, which indicates the flightless raphines had ancestors that were able to fly, were semi-terrestrial, and inhabited islands. This in turn supports the hypothesis that the ancestors of those birds reached the Mascarene islands by island hopping from South Asia. The lack of mammalian herbivores competing for resources on these islands allowed the solitaire and the dodo to attain very large sizes and flightlessness. Despite its divergent skull morphology and adaptations for larger size, many features of its skeleton remained similar to those of smaller, flying pigeons. Another large, flightless pigeon, the Viti Levu giant pigeon (\"Natunaornis gigoura\"), was described in 2001 from subfossil material from Fiji. It was only slightly smaller than the dodo and the solitaire, and it too is thought to have been related to the crowned pigeons.\n\nOne of the original names for the dodo was the Dutch \"\"Walghvogel\"\", first used in the journal of Vice Admiral Wybrand van Warwijck, who visited Mauritius during the Second Dutch Expedition to Indonesia in 1598. \"Walghe\" means \"tasteless\", \"insipid\", or \"sickly\", and \"vogel\" means \"bird\". The name was translated into German as \"Walchstök\" or \"Walchvögel\", by Jakob Friedlib. The original Dutch report titled \"Waarachtige Beschryving\" was lost, but the English translation survived:\nAnother account from that voyage, perhaps the first to mention the dodo, states that the Portuguese referred to them as penguins. The meaning may not have been derived from \"penguin\" (the Portuguese referred to them as \"\"fotilicaios\"\" at the time), but from \"pinion\", a reference to the small wings. The crew of the Dutch ship \"Gelderland\" referred to the bird as \"Dronte\" (meaning \"swollen\") in 1602, a name that is still used in some languages. This crew also called them \"griff-eendt\" and \"kermisgans\", in reference to fowl fattened for the Kermesse festival in Amsterdam, which was held the day after they anchored on Mauritius.\n\nThe etymology of the word \"dodo\" is unclear. Some ascribe it to the Dutch word \"dodoor\" for \"sluggard\", but it is more probably related to \"Dodaars\", which means either \"fat-arse\" or \"knot-arse\", referring to the knot of feathers on the hind end. The first record of the word \"Dodaars\" is in Captain Willem Van West-Zanen's journal in 1602. The English writer Sir Thomas Herbert was the first to use the word \"dodo\" in print in his 1634 travelogue, claiming it was referred to as such by the Portuguese, who had visited Mauritius in 1507. Another Englishman, Emmanuel Altham, had used the word in a 1628 letter, in which he also claimed the origin was Portuguese. The name \"dodar\" was introduced into English at the same time as dodo, but was only used until the 18th century. As far as is known, the Portuguese never mentioned the bird. Nevertheless, some sources still state that the word \"dodo\" derives from the Portuguese word \"doudo\" (currently \"doido\"), meaning \"fool\" or \"crazy\". It has also been suggested that \"dodo\" was an onomatopoeic approximation of the bird's call, a two-note pigeon-like sound resembling \"doo-doo\".\n\nThe Latin name \"cucullatus\" (\"hooded\") was first used by Juan Eusebio Nieremberg in 1635 as \"Cygnus cucullatus\", in reference to Carolus Clusius's 1605 depiction of a dodo. In his 18th-century classic work \"Systema Naturae\", Carl Linnaeus used \"cucullatus\" as the specific name, but combined it with the genus name \"Struthio\" (ostrich). Mathurin Jacques Brisson coined the genus name \"Raphus\" (referring to the bustards) in 1760, resulting in the current name \"Raphus cucullatus\". In 1766, Linnaeus coined the new binomial \"Didus ineptus\" (meaning \"inept dodo\"). This has become a synonym of the earlier name because of nomenclatural priority.\n\nAs no complete dodo specimens exist, its external appearance, such as plumage and colouration, is hard to determine. Illustrations and written accounts of encounters with the dodo between its discovery and its extinction (1598–1662) are the primary evidence for its external appearance. According to most representations, the dodo had greyish or brownish plumage, with lighter primary feathers and a tuft of curly light feathers high on its rear end. The head was grey and naked, the beak green, black and yellow, and the legs were stout and yellowish, with black claws. A study of the few remaining feathers on the Oxford specimen head showed that they were pennaceous rather than plumaceous (downy) and most similar to those of other pigeons.\n\nSubfossil remains and remnants of the birds that were brought to Europe in the 17th century show that dodos were very large birds, up to tall. \nThe bird was sexually dimorphic; males were larger and had proportionally longer beaks. Weight estimates have varied from study to study. In 1993, Bradley C. Livezey proposed that males would have weighed and females . Also in 1993, Andrew C. Kitchener attributed a high contemporary weight estimate and the roundness of dodos depicted in Europe to these birds having been overfed in captivity; weights in the wild were estimated to have been in the range of , and fattened birds could have weighed . A 2011 estimate by Angst and colleagues gave an average weight as low as . This has also been questioned, and there is still controversy over weight estimates. A 2016 study estimated the weight at , based on CT scans of composite skeletons. It has also been suggested that the weight depended on the season, and that individuals were fat during cool seasons, but less so during hot.\n\nThe skull of the dodo differed much from those of other pigeons, especially in being more robust, the bill having a hooked tip, and in having a short cranium compared to the jaws. The upper bill was nearly twice as long as the cranium, which was short compared to those of its closest pigeon relatives. The openings of the bony nostrils were elongated along the length of the beak, and they contained no bony septum. The cranium (excluding the beak) was wider than it was long, and the frontal bone formed a dome-shape, with the highest point above the hind part of the eye sockets. The skull sloped downwards at the back. The eye sockets occupied much of the hind part of the skull. The sclerotic rings inside the eye were formed by eleven ossicles (small bones), similar to the amount in other pigeons. The mandible was slightly curved, and each half had a single fenestra (opening), as in other pigeons.\n\nThe dodo had about nineteen presynsacral vertebrae (those of the neck and thorax, including three fused into a notarium), sixteen synsacral vertebrae (those of the lumbar region and sacrum), six free tail (caudal) vertebrae, and a pygostyle. The neck had well-developed areas for muscle and ligament attachment, probably to support the heavy skull and beak. On each side, it had six ribs, four of which articulated with the sternum through sternal ribs. The sternum was large, but small in relation to the body compared to those of much smaller pigeons that are able to fly. The sternum was highly pneumatic, broad, and relatively thick in cross-section. The bones of the pectoral girdle, shoulder blades, and wing bones were reduced in size compared to those of flighted pigeon, and were more gracile compared to those of the Rodrigues solitaire, but none of the individual skeletal components had disappeared. The carpometacarpus of the dodo was more robust than that of the solitaire, however. The pelvis was wider than that of the solitaire and other relatives, yet was comparable to the proportions in some smaller, flighted pigeons. Most of the leg bones were more robust than those of extant pigeons and the solitaire, but the length proportions were little different.\n\nMany of the skeletal features that distinguish the dodo and the Rodrigues solitaire, its closest relative, from pigeons have been attributed to their flightlessness. The pelvic elements were thicker than those of flighted pigeons to support the higher weight, and the pectoral region and the small wings were paedomorphic, meaning that they were underdeveloped and retained juvenile features. The skull, trunk and pelvic limbs were peramorphic, meaning that they changed considerably with age. The dodo shared several other traits with the Rodrigues solitaire, such as features of the skull, pelvis, and sternum, as well as their large size. It differed in other aspects, such as being more robust and shorter than the solitaire, having a larger skull and beak, a rounded skull roof, and smaller orbits. The dodo's neck and legs were proportionally shorter, and it did not possess an equivalent to the knob present on the solitaire's wrists.\n\nMost contemporary descriptions of the dodo are found in ship's logs and journals of the Dutch East India Company vessels that docked in Mauritius when the Dutch Empire ruled the island. These records were used as guides for future voyages. Few contemporary accounts are reliable, as many seem to be based on earlier accounts, and none were written by scientists. One of the earliest accounts, from van Warwijck's 1598 journal, describes the bird as follows:\n\nOne of the most detailed descriptions is by Sir Thomas Herbert in \"A Relation of Some Yeares Travaille into Afrique and the Greater Asia\" from 1634:\n\nThe travel journal of the Dutch ship \"Gelderland\" (1601–1603), rediscovered in the 1860s, contains the only known sketches of living or recently killed specimens drawn on Mauritius. They have been attributed to the professional artist Joris Joostensz Laerle, who also drew other now-extinct Mauritian birds, and to a second, less refined artist. Apart from these sketches, it is unknown how many of the twenty or so 17th-century illustrations of the dodos were drawn from life or from stuffed specimens, which affects their reliability.\n\nThe traditional image of the dodo is of a very fat and clumsy bird, but this view may be exaggerated. The general opinion of scientists today is that many old European depictions were based on overfed captive birds or crudely stuffed specimens. It has also been suggested that the images might show dodos with puffed feathers, as part of display behaviour. The Dutch painter Roelant Savery was the most prolific and influential illustrator of the dodo, having made at least twelve depictions, often showing it in the lower corners. A famous painting of his from 1626, now called \"Edwards's Dodo\" as it was once owned by the ornithologist George Edwards, has since become the standard image of a dodo. It is housed in the Natural History Museum, London. The image shows a particularly fat bird and is the source for many other dodo illustrations.\n\nAn Indian Mughal painting rediscovered in St. Petersburg in the 1950s shows a dodo along with native Indian birds. It depicts a slimmer, brownish bird, and its discoverer A. Iwanow and dodo specialist Julian Hume regard it as one of the most accurate depictions of the living dodo; the surrounding birds are clearly identifiable and depicted with appropriate colouring. It is believed to be from the 17th century and has been attributed to artist Ustad Mansur. The bird depicted probably lived in the menagerie of Mughal Emperor Jahangir, located in Surat, where English traveller Peter Mundy also claimed to have seen two dodos sometime between 1628 and 1633. In 2014, another Indian illustration of a dodo was reported, but it was found to be derivative of an 1836 German illustration.\n\nAll post-1638 depictions appear to be based on earlier images, around the time reports mentioning dodos became rarer. Differences in the depictions led authors such as Anthonie Cornelis Oudemans and Masauji Hachisuka to speculate about sexual dimorphism, ontogenic traits, seasonal variation, and even the existence of different species, but these theories are not accepted today. Because details such as markings of the beak, the form of the tail feathers, and colouration vary from account to account, it is impossible to determine the exact morphology of these features, whether they signal age or sex, or if they even reflect reality. Dodo specialist Julian Hume argued that the nostrils of the living dodo would have been slits, as seen in the \"Gelderland\", Cornelis Saftleven, Savery's Crocker Art Gallery, and Ustad Mansur images. According to this claim, the gaping nostrils often seen in paintings indicate that taxidermy specimens were used as models. Most depictions show that the wings were held in an extended position, unlike flighted pigeons, but similar to ratites such as the ostrich and kiwi.\n\nLittle is known of the behaviour of the dodo, as most contemporary descriptions are very brief. Based on weight estimates, it has been suggested the male could reach the age of 21, and the female 17. Studies of the cantilever strength of its leg bones indicate that it could run quite fast. The legs were robust and strong to support the bulk of the bird, and also made it agile and manoeuvrable in the dense, pre-human landscape. Though the wings were small, well-developed muscle scars on the bones show that they were not completely vestigial, and may have been used for display behaviour and balance; extant pigeons also use their wings for such purposes. Unlike the Rodrigues solitaire, there is no evidence that the dodo used its wings in intraspecific combat. Though some dodo bones have been found with healed fractures, it had weak pectoral muscles and more reduced wings in comparison. The dodo may instead have used its large, hooked beak in territorial disputes. Since Mauritius receives more rainfall and has less seasonal variation than Rodrigues, which would have affected the availability of resources on the island, the dodo would have less reason to evolve aggressive territorial behaviour. The Rodrigues solitaire was therefore probably the more aggressive of the two.\n\nThe preferred habitat of the dodo is unknown, but old descriptions suggest that it inhabited the woods on the drier coastal areas of south and west Mauritius. This view is supported by the fact that the Mare aux Songes swamp, where most dodo remains have been excavated, is close to the sea in south-eastern Mauritius. Such a limited distribution across the island could well have contributed to its extinction. A 1601 map from the \"Gelderland\" journal shows a small island off the coast of Mauritius where dodos were caught. Julian Hume has suggested this island was l'île aux Benitiers in Tamarin Bay, on the west coast of Mauritius. Subfossil bones have also been found inside caves in highland areas, indicating that it once occurred on mountains. Work at the Mare aux Songes swamp has shown that its habitat was dominated by tambalacoque and \"Pandanus\" trees and endemic palms. The near-coastal placement and wetness of the Mare aux Songes led to a high diversity of plant species, whereas the surrounding areas were drier.\n\nMany endemic species of Mauritius became extinct after the arrival of humans, so the ecosystem of the island is badly damaged and hard to reconstruct. Before humans arrived, Mauritius was entirely covered in forests, but very little remains of them today, because of deforestation. The surviving endemic fauna is still seriously threatened. The dodo lived alongside other recently extinct Mauritian birds such as the flightless red rail, the broad-billed parrot, the Mascarene grey parakeet, the Mauritius blue pigeon, the Mauritius owl, the Mascarene coot, the Mauritian shelduck, the Mauritian duck, and the Mauritius night heron. Extinct Mauritian reptiles include the saddle-backed Mauritius giant tortoise, the domed Mauritius giant tortoise, the Mauritian giant skink, and the Round Island burrowing boa. The small Mauritian flying fox and the snail \"Tropidophora carinata\" lived on Mauritius and Réunion, but vanished from both islands. Some plants, such as \"Casearia tinifolia\" and the palm orchid, have also become extinct.\n\nA 1631 Dutch letter (long thought lost, but rediscovered in 2017) is the only account of the dodo's diet, and also mentions that it used its beak for defence. The document uses word-play to refer to the animals described, with dodos presumably being an allegory for wealthy mayors:\n\nIn addition to fallen fruits, the dodo probably subsisted on nuts, seeds, bulbs, and roots. It has also been suggested that the dodo might have eaten crabs and shellfish, like their relatives the crowned pigeons. Its feeding habits must have been versatile, since captive specimens were probably given a wide range of food on the long sea journeys. Oudemans suggested that as Mauritius has marked dry and wet seasons, the dodo probably fattened itself on ripe fruits at the end of the wet season to survive the dry season, when food was scarce; contemporary reports describe the bird's \"greedy\" appetite. France Staub suggested that they mainly fed on palm fruits, and he attempted to correlate the fat-cycle of the dodo with the fruiting regime of the palms.\n\nSkeletal elements of the upper jaw appear to have been rhynchokinetic (movable in relation to each other), which must have affected its feeding behaviour. In extant birds, such as frugivorous (fruit-eating) pigeons, kinetic premaxillae help with consuming large food items. The beak also appears to have been able to withstand high force loads, which indicates a diet of hard food. In 2016, the first 3D endocast was made from the brain of the dodo; examination found that though the brain was similar to that of other pigeons in most respects, the dodo had a comparatively large olfactory bulb. This gave the dodo a good sense of smell, which may have aided in locating fruit and small prey.\n\nSeveral contemporary sources state that the dodo used Gastroliths (gizzard stones) to aid digestion. The English writer Sir Hamon L'Estrange witnessed a live bird in London and described it as follows:\n\nIt is not known how the young were fed, but related pigeons provide crop milk. Contemporary depictions show a large crop, which was probably used to add space for food storage and to produce crop milk. It has been suggested that the maximum size attained by the dodo and the solitaire was limited by the amount of crop milk they could produce for their young during early growth.\n\nIn 1973, the tambalacoque, also known as the dodo tree, was thought to be dying out on Mauritius, to which it is endemic. There were supposedly only 13 specimens left, all estimated to be about 300 years old. Stanley Temple hypothesised that it depended on the dodo for its propagation, and that its seeds would germinate only after passing through the bird's digestive tract. He claimed that the tambalacoque was now nearly coextinct because of the disappearance of the dodo. Temple overlooked reports from the 1940s that found that tambalacoque seeds germinated, albeit very rarely, without being abraded during digestion. Others have contested his hypothesis and suggested that the decline of the tree was exaggerated, or seeds were also distributed by other extinct animals such as \"Cylindraspis\" tortoises, fruit bats or the broad-billed parrot. According to Wendy Strahm and Anthony Cheke, two experts in the ecology of the Mascarene Islands, the tree, while rare, has germinated since the demise of the dodo and numbers several hundred, not 13 as claimed by Temple, hence discrediting Temple's view as to the dodo and the tree's sole survival relationship.\n\nIt has been suggested that the broad-billed parrot may have depended on dodos and \"Cylindraspis\" tortoises to eat palm fruits and excrete their seeds, which became food for the parrots. \"Anodorhynchus\" macaws depended on now-extinct South American megafauna in the same way, but now rely on domesticated cattle for this service.\n\nAs it was flightless and terrestrial and there were no mammalian predators or other kinds of natural enemy on Mauritius, the dodo probably nested on the ground. The account by François Cauche from 1651 is the only description of the egg and the call:\nCauche's account is problematic, since it also mentions that the bird he was describing had three toes and no tongue, unlike dodos. This led some to believe that Cauche was describing a new species of dodo (\"\"Didus nazarenus\"\"). The description was most probably mingled with that of a cassowary, and Cauche's writings have other inconsistencies. A mention of a \"young ostrich\" taken on board a ship in 1617 is the only other reference to a possible juvenile dodo. An egg claimed to be that of a dodo is stored in the museum of East London, South Africa. It was donated by Marjorie Courtenay-Latimer, whose great aunt had received it from a captain who claimed to have found it in a swamp on Mauritius. In 2010, the curator of the museum proposed using genetic studies to determine its authenticity. It may instead be an aberrant ostrich egg.\n\nBecause of the possible single-egg clutch and the bird's large size, it has been proposed that the dodo was K-selected, meaning that it produced a low number of altricial offspring, which required parental care until they matured. Some evidence, including the large size and the fact that tropical and frugivorous birds have slower growth rates, indicates that the bird may have had a protracted development period. The fact that no juvenile dodos have been found in the Mare aux Songes swamp may indicate that they produced little offspring, that they matured rapidly, that the breeding grounds were far away from the swamp, or that the risk of miring was seasonal.\n\nA 2017 study examined the histology of thin-sectioned dodo bones, modern Mauritian birds, local ecology, and contemporary accounts, to recover information about the life history of the dodo. The study suggested that dodos bred around August, after having potentially fattened themselves, corresponding with the fat and thin cycles of many vertebrates of Mauritius. The chicks grew rapidly, reaching robust, almost adult, sizes, and sexual maturity before Austral summer or the cyclone season. Adult dodos which had just bred moulted after Austral summer, around March. The feathers of the wings and tail were replaced first, and the moulting would have completed at the end of July, in time for the next breeding season. Different stages of moulting may also account for inconsistencies in contemporary descriptions of dodo plumage.\n\nMauritius had previously been visited by Arab vessels in the Middle Ages and Portuguese ships between 1507 and 1513, but was settled by neither. No records of dodos by these are known, although the Portuguese name for Mauritius, \"Cerne (swan) Island\", may have been a reference to dodos. The Dutch Empire acquired Mauritius in 1598, renaming it after Maurice of Nassau, and it was used for the provisioning of trade vessels of the Dutch East India Company henceforward. The earliest known accounts of the dodo were provided by Dutch travelers during the Second Dutch Expedition to Indonesia, led by admiral Jacob van Neck in 1598. They appear in reports published in 1601, which also contain the first published illustration of the bird. Since the first sailors to visit Mauritius had been at sea for a long time, their interest in these large birds was mainly culinary. The 1602 journal by Willem Van West-Zanen of the ship \"Bruin-Vis\" mentions that 24–25 dodos were hunted for food, which were so large that two could scarcely be consumed at mealtime, their remains being preserved by salting. An illustration made for the 1648 published version of this journal, showing the killing of dodos, a dugong, and possibly Mascarene grey parakeets, was captioned with a Dutch poem, here in Hugh Strickland's 1848 translation:\nSome early travellers found dodo meat unsavoury, and preferred to eat parrots and pigeons; others described it as tough but good. Some hunted dodos only for their gizzards, as this was considered the most delicious part of the bird. Dodos were easy to catch, but hunters had to be careful not to be bitten by their powerful beaks.\n\nThe appearance of the dodo and the red rail led Peter Mundy to speculate, 230 years before Charles Darwin's theory of evolution:\n\nThe dodo was found interesting enough that living specimens were sent to Europe and the East. The number of transported dodos that reached their destinations alive is uncertain, and it is unknown how they relate to contemporary depictions and the few non-fossil remains in European museums. Based on a combination of contemporary accounts, paintings, and specimens, Julian Hume has inferred that at least eleven transported dodos reached their destinations alive.\n\nHamon L'Estrange's description of a dodo that he saw in London in 1638 is the only account that specifically mentions a live specimen in Europe. In 1626 Adriaen van de Venne drew a dodo that he claimed to have seen in Amsterdam, but he did not mention if it were alive, and his depiction is reminiscent of Savery's \"Edwards's Dodo\". Two live specimens were seen by Peter Mundy in Surat, India, between 1628 and 1634, one of which may have been the individual painted by Ustad Mansur around 1625. In 1628, Emmanuel Altham visited Mauritius and sent a letter to his brother in England:\n\nWhether the dodo survived the journey is unknown, and the letter was destroyed by fire in the 19th century.\nThe earliest known picture of a dodo specimen in Europe is from a collection of paintings depicting animals in the royal menagerie of Emperor Rudolph II in Prague. This collection includes paintings of other Mauritian animals as well, including a red rail. The dodo, which may be a juvenile, seems to have been dried or embalmed, and had probably lived in the emperor's zoo for a while together with the other animals. That whole stuffed dodos were present in Europe indicates they had been brought alive and died there; it is unlikely that taxidermists were on board the visiting ships, and spirits were not yet used to preserve biological specimens. Most tropical specimens were preserved as dried heads and feet.\n\nOne dodo was reportedly sent as far as Nagasaki, Japan in 1647, but it was long unknown whether it arrived. Contemporary documents first published in 2014 proved the story, and showed that it had arrived alive. It was meant as a gift, and, despite its rarity, was considered of equal value to a white deer and a bezoar stone. It is the last recorded live dodo in captivity.\n\nLike many animals that evolved in isolation from significant predators, the dodo was entirely fearless of humans. This fearlessness and its inability to fly made the dodo easy prey for sailors. Although some scattered reports describe mass killings of dodos for ships' provisions, archaeological investigations have found scant evidence of human predation. Bones of at least two dodos were found in caves at Baie du Cap that sheltered fugitive slaves and convicts in the 17th century, which would not have been easily accessible to dodos because of the high, broken terrain. The human population on Mauritius (an area of ) never exceeded 50 people in the 17th century, but they introduced other animals, including dogs, pigs, cats, rats, and crab-eating macaques, which plundered dodo nests and competed for the limited food resources. At the same time, humans destroyed the forest habitat of the dodos. The impact of the introduced animals on the dodo population, especially the pigs and macaques, is today considered more severe than that of hunting. Rats were perhaps not much of a threat to the nests, since dodos would have been used to dealing with local land crabs.\n\nIt has been suggested that the dodo may already have been rare or localised before the arrival of humans on Mauritius, since it would have been unlikely to become extinct so rapidly if it had occupied all the remote areas of the island. A 2005 expedition found subfossil remains of dodos and other animals killed by a flash flood. Such mass mortalities would have further jeopardised a species already in danger of becoming extinct. Yet the fact that the dodo survived hundreds of years of volcanic activity and climactic changes shows the bird was resilient within its ecosystem.\n\nSome controversy surrounds the date of their extinction. The last widely accepted record of a dodo sighting is the 1662 report by shipwrecked mariner Volkert Evertsz of the Dutch ship \"Arnhem\", who described birds caught on a small islet off Mauritius, now suggested to be Amber Island:\nThe dodos on this islet may not necessarily have been the last members of the species. The last claimed sighting of a dodo was reported in the hunting records of Isaac Johannes Lamotius in 1688. Statistical analysis of these records by Roberts and Solow gives a new estimated extinction date of 1693, with a 95% confidence interval of 1688–1715. The authors also pointed out that because the last sighting before 1662 was in 1638, the dodo was probably already quite rare by the 1660s, and thus a disputed report from 1674 by an escaped slave cannot be dismissed out of hand.\n\nCheke pointed out that some descriptions after 1662 use the names \"Dodo\" and \"Dodaers\" when referring to the red rail, indicating that they had been transferred to it after the disappearance of the dodo itself. Cheke therefore points to the 1662 description as the last credible observation. A 1668 account by English traveller John Marshall, who used the names \"Dodo\" and \"Red Hen\" interchangeably for the red rail, mentioned that the meat was \"hard\", which echoes the description of the meat in the 1681 account. Even the 1662 account has been questioned by the writer Errol Fuller, as the reaction to distress cries matches what was described for the red rail. Until this explanation was proposed, a description of \"dodos\" from 1681 was thought to be the last account, and that date still has proponents. Recently accessible Dutch manuscripts indicate that no dodos were seen by settlers in 1664–1674. It is unlikely the issue will ever be resolved, unless late reports mentioning the name alongside a physical description are rediscovered. The IUCN Red List accepts Cheke's rationale for choosing the 1662 date, taking all subsequent reports to refer to red rails. In any case, the dodo was probably extinct by 1700, about a century after its discovery in 1598. The Dutch left Mauritius in 1710, but by then the dodo and most of the large terrestrial vertebrates there had become extinct.\n\nEven though the rareness of the dodo was reported already in the 17th century, its extinction was not recognised until the 19th century. This was partly because, for religious reasons, extinction was not believed possible until later proved so by Georges Cuvier, and partly because many scientists doubted that the dodo had ever existed. It seemed altogether too strange a creature, and many believed it a myth. The bird was first used as an example of human-induced extinction in \"Penny Magazine\" in 1833, and has since been referred to as an \"icon\" of extinction.\n\nThe only extant remains of dodos taken to Europe in the 17th century are a dried head and foot in the Oxford University Museum of Natural History, a foot once housed in the British Museum but now lost, a skull in the University of Copenhagen Zoological Museum, and an upper jaw and leg bones in the National Museum, Prague. The last two were rediscovered and identified as dodo remains in the mid-19th century. Several stuffed dodos were also mentioned in old museum inventories, but none are known to have survived. Apart from these remains, a dried foot, which belonged to the Dutch professor Pieter Pauw, was mentioned by Carolus Clusius in 1605. Its provenance is unknown, and it is now lost, but it may have been collected during the Van Neck voyage.\n\nThe only known soft tissue remains, the Oxford head (specimen OUM 11605) and foot, belonged to the last known stuffed dodo, which was first mentioned as part of the Tradescant collection in 1656 and was moved to the Ashmolean Museum in 1659. It has been suggested that this might be the remains of the bird that Hamon L'Estrange saw in London, the bird sent by Emanuel Altham, or a donation by Thomas Herbert. Since the remains do not show signs of having been mounted, the specimen might instead have been preserved as a study skin. In 2018, it was reported that scans of the Oxford dodo's head showed that its skin and bone contained lead shot, pellets which were used to hunt birds in the 17th century. This indicates that the Oxford dodo was shot either before being transported to Britain, or some time after arriving. The circumstances of its killing are unknown, and the pellets are to be examined to identify where the lead was mined from.\n\nMany sources state that the Ashmolean Museum burned the stuffed dodo around 1755 because of severe decay, saving only the head and leg. Statute 8 of the museum states \"That as any particular grows old and perishing the keeper may remove it into one of the closets or other repository; and some other to be substituted.\" The deliberate destruction of the specimen is now believed to be a myth; it was removed from exhibition to preserve what remained of it. This remaining soft tissue has since degraded further; the head was dissected by Strickland and Melville, separating the skin from the skull in two halves. The foot is in a skeletal state, with only scraps of skin and tendons. Very few feathers remain on the head. It is probably a female, as the foot is 11% smaller and more gracile than the London foot, yet appears to be fully grown. The specimen was exhibited at the Oxford museum from at least the 1860s and until 1998, where-after it was mainly kept in storage to prevent damage. Casts of the head can today be found in many museums worldwide.\n\nThe dried London foot, first mentioned in 1665, and transferred to the British Museum in the 18th century, was displayed next to Savery's \"Edwards's Dodo\" painting until the 1840s, and it too was dissected by Strickland and Melville. It was not posed in a standing posture, which suggests that it was severed from a fresh specimen, not a mounted one. By 1896 it was mentioned as being without its integuments, and only the bones are believed to remain today, though its present whereabouts are unknown.\n\nThe Copenhagen skull (specimen ZMUC 90-806) is known to have been part of the collection of Bernardus Paludanus in Enkhuizen until 1651, when it was moved to the museum in Gottorf Castle, Schleswig. After the castle was occupied by Danish forces in 1702, the museum collection was assimilated into the Royal Danish collection. The skull was rediscovered by J. T. Reinhardt in 1840. Based on its history, it may be the oldest known surviving remains of a dodo brought to Europe in the 17th century. It is shorter than the Oxford skull, and may have belonged to a female. It was mummified, but the skin has perished.\n\nThe front part of a skull (specimen NMP P6V-004389, a syntype of this species) in the National Museum of Prague was found in 1850 among the remains of the Böhmisches Museum. Other elements supposedly belonging to this specimen have been listed in the literature, but it appears only the partial skull was ever present. It may be what remains of one of the stuffed dodos known to have been at the menagerie of Emperor Rudolph II, possibly the specimen painted by Hoefnagel or Savery there.\n\nUntil 1860, the only known dodo remains were the four incomplete 17th-century specimens. Philip Burnard Ayres found the first subfossil bones in 1860, which were sent to Richard Owen at the British Museum, who did not publish the findings. In 1863, Owen requested the Mauritian Bishop Vincent Ryan to spread word that he should be informed if any dodo bones were found. In 1865, George Clark, the government schoolmaster at Mahébourg, finally found an abundance of subfossil dodo bones in the swamp of Mare aux Songes in Southern Mauritius, after a 30-year search inspired by Strickland and Melville's monograph. In 1866, Clark explained his procedure to \"The Ibis\", an ornithology journal: he had sent his coolies to wade through the centre of the swamp, feeling for bones with their feet. At first they found few bones, until they cut away herbage that covered the deepest part of the swamp, where they found many fossils. The swamp yielded the remains of over 300 dodos, but very few skull and wing bones, possibly because the upper bodies were washed away or scavenged while the lower body was trapped. The situation is similar to many finds of moa remains in New Zealand marshes. Most dodo remains from the Mare aux Songes have a medium to dark brown colouration.\n\nClark's reports about the finds rekindled interest in the bird. Sir Richard Owen and Alfred Newton both wanted to be first to describe the post-cranial anatomy of the dodo, and Owen bought a shipment of dodo bones originally meant for Newton, which led to rivalry between the two. Owen described the bones in \"Memoir on the Dodo\" in October 1866, but erroneously based his reconstruction on the \"Edwards's Dodo\" painting by Savery, making it too squat and obese. In 1869 he received more bones and corrected its stance, making it more upright. Newton moved his focus to the Réunion solitaire instead. The remaining bones not sold to Owen or Newton were auctioned off or donated to museums. In 1889, Théodor Sauzier was commissioned to explore the \"historical souvenirs\" of Mauritius and find more dodo remains in the Mare aux Songes. He was successful, and also found remains of other extinct species.\n\nIn 2005, after a hundred years of neglect, a part of the Mare aux Songes swamp was excavated by an international team of researchers (International Dodo Research Project). To prevent malaria, the British had covered the swamp with hard core during their rule over Mauritius, which had to be removed. Many remains were found, including bones of at least 17 dodos in various stages of maturity (though no juveniles), and several bones obviously from the skeleton of one individual bird, which have been preserved in their natural position. These findings were made public in December 2005 in the Naturalis museum in Leiden. 63% of the fossils found in the swamp belonged to turtles of the extinct genus \"Cylindraspis\", and 7.1% belonged to dodos, which had been deposited within several centuries, 4,000 years ago. Subsequent excavations suggested that dodos and other animals became mired in the Mare aux Songes while trying to reach water during a long period of severe drought about 4,200 years ago. Furthermore, cyanobacteria thrived in the conditions created by the excrements of animals gathered around the swamp, which died of intoxication, dehydration, trampling, and miring. Though many small skeletal elements were found during the recent excavations of the swamp, few were found during the 19th century, probably owing to the employment of less refined methods when collecting.\n\nLouis Etienne Thirioux, an amateur naturalist at Port Louis, also found many dodo remains around 1900 from several locations. They included the first articulated specimen, which is the first subfossil dodo skeleton found outside the Mare aux Songes, and the only remains of a juvenile specimen, a now lost tarsometatarsus. The former specimen was found in 1904 in a cave near Le Pouce mountain, and is the only known complete skeleton of an individual dodo. Thirioux donated the specimen to the Museum Desjardins (now Natural History Museum at Mauritius Institute). Thrioux's heirs sold a second mounted composite skeleton (composed of at least two skeletons, with a mainly reconstructed skull) to the Durban Museum of Natural Science in South Africa in 1918. Together, these two skeletons represent the most completely known dodo remains, including bone elements previously unrecorded (such as knee-caps and various wing bones). Though some contemporary writers noted the importance of Thrioux's specimens, they were not scientifically studied, and were largely forgotten until 2011, when sought out by a group of researchers. The mounted skeletons were laser scanned, from which 3-D models were reconstructed, which became the basis of a 2016 monograph about the osteology of the dodo. In 2006, explorers discovered a complete skeleton of a dodo in a lava cave in Mauritius. This was only the second associated skeleton of an individual specimen everfound, and the only one in recent times.\n\nWorldwide, 26 museums have significant holdings of dodo material, almost all found in the Mare aux Songes. The Natural History Museum, American Museum of Natural History, Cambridge University Museum of Zoology, the Senckenberg Museum, and others have almost complete skeletons, assembled from the dissociated subfossil remains of several individuals. In 2011, a wooden box containing dodo bones from the Edwardian era was rediscovered at the Grant Museum at University College London during preparations for a move. They had been stored with crocodile bones until then.\n\nThe supposed \"white dodo\" (or \"solitaire\") of Réunion is now considered an erroneous conjecture based on contemporary reports of the Réunion ibis and 17th-century paintings of white, dodo-like birds by Pieter Withoos and Pieter Holsteyn that surfaced in the 19th century. The confusion began when Willem Ysbrandtszoon Bontekoe, who visited Réunion around 1619, mentioned fat, flightless birds that he referred to as \"Dod-eersen\" in his journal, though without mentioning their colouration. When the journal was published in 1646, it was accompanied by an engraving of a dodo from Savery's \"Crocker Art Gallery sketch\". A white, stocky, and flightless bird was first mentioned as part of the Réunion fauna by Chief Officer J. Tatton in 1625. Sporadic mentions were subsequently made by Sieur Dubois and other contemporary writers.\n\nBaron Edmond de Sélys Longchamps coined the name \"Raphus solitarius\" for these birds in 1848, as he believed the accounts referred to a species of dodo. When 17th-century paintings of white dodos were discovered by 19th-century naturalists, it was assumed they depicted these birds. Oudemans suggested that the discrepancy between the paintings and the old descriptions was that the paintings showed females, and that the species was therefore sexually dimorphic. Some authors also believed the birds described were of a species similar to the Rodrigues solitaire, as it was referred to by the same name, or even that there were white species of both dodo and solitaire on the island.\n\nThe Pieter Withoos painting, which was discovered first, appears to be based on an earlier painting by Pieter Holsteyn, three versions of which are known to have existed. According to Hume, Cheke, and Valledor de Lozoya, it appears that all depictions of white dodos were based on Roelant Savery's painting \"Landscape with Orpheus and the animals\", or on copies of it. The painting has generally been dated to 1611, though a post-1614, or even post-1626, date has also been proposed. The painting shows a whitish specimen and was apparently based on a stuffed specimen then in Prague; a \"walghvogel\" described as having a \"dirty off-white colouring\" was mentioned in an inventory of specimens in the Prague collection of the Holy Roman Emperor Rudolf II, to whom Savery was contracted at the time (1607–1611). Savery's several later images all show greyish birds, possibly because he had by then seen another specimen. Cheke and Hume believe the painted specimen was white, owing to albinism. Valledor de Lozoya has instead suggested that the light plumage was a juvenile trait, a result of bleaching of old taxidermy specimens, or simply artistic license.\n\nIn 1987, scientists described fossils of a recently extinct species of ibis from Réunion with a relatively short beak, \"Borbonibis latipes\", before a connection to the solitaire reports had been made. Cheke suggested to one of the authors, Francois Moutou, that the fossils may have been of the Réunion solitaire, and this suggestion was published in 1995. The ibis was reassigned to the genus \"Threskiornis\", now combined with the specific epithet \"\" from the binomial \"R. solitarius\". Birds of this genus are also white and black with slender beaks, fitting the old descriptions of the Réunion solitaire. No fossil remains of dodo-like birds have ever been found on the island.\n\nThe dodo's significance as one of the best-known extinct animals and its singular appearance led to its use in literature and popular culture as a symbol of an outdated concept or object, as in the expression \"dead as a dodo,\" which has come to mean unquestionably dead or obsolete. Similarly, the phrase \"to go the way of the dodo\" means to become extinct or obsolete, to fall out of common usage or practice, or to become a thing of the past. \"Dodo\" is also a slang term for a stupid, dull-witted person, as it was supposedly stupid and easily caught.\n\nThe dodo appears frequently in works of popular fiction, and even before its extinction, it was featured in European literature, as symbol for exotic lands, and of gluttony, due to its apparent fatness. In 1865, the same year that George Clark started to publish reports about excavated dodo fossils, the newly vindicated bird was featured as a character in Lewis Carroll's \"Alice's Adventures in Wonderland\". It is thought that he included the dodo because he identified with it and had adopted the name as a nickname for himself because of his stammer, which made him accidentally introduce himself as \"Do-do-dodgson\", his legal surname. Carroll and the girl who served as inspiration for Alice, Alice Liddell, had enjoyed visiting the Oxford museum to see the dodo remains there. The book's popularity made the dodo a well-known icon of extinction.\nThe dodo is used as a mascot for many kinds of products, especially in Mauritius. It appears as a supporter on the coat of arms of Mauritius, on Mauritius coins, is used as a watermark on all Mauritian rupee banknotes, and features as the background of the Mauritian immigration form. A smiling dodo is the symbol of the Brasseries de Bourbon, a popular brewer on Réunion, whose emblem displays the white species once thought to have lived there.\n\nThe dodo is used to promote the protection of endangered species by environmental organisations, such as the Durrell Wildlife Conservation Trust and the Durrell Wildlife Park. The Center for Biological Diversity gives an annual 'Rubber Dodo Award', to \"those who have done the most to destroy wild places, species and biological diversity\". In 2011, the nephiline spider \"Nephilengys dodo\", which inhabits the same woods as the dodo once did, was named after the bird to raise awareness of the urgent need for protection of the Mauritius biota. Two species of ant from Mauritius have been named after the dodo: \"Pseudolasius dodo\" in 1946 and \"Pheidole dodo\" in 2013. A species of isopod from a coral reef off Réunion was named \"Hansenium dodo\" in 1991. The name dodo has been used by scientists naming genetic elements, honoring the dodo's flightless nature. A fruitfly gene within a region of a chromosome required for flying ability was named \"dodo\". In addition, a defective transposable element family from \"Phytophthora infestans\" was named \"DodoPi\" as it contained mutations that eliminated the element's ability to jump to new locations in a chromosome. \n\nIn 2009, a previously unpublished 17th-century Dutch illustration of a dodo went for sale at Christie's and was expected to sell for £6,000. It is unknown whether the illustration was based on a specimen or on a previous image. It sold for £44,450.\n\nThe poet Hilaire Belloc included the following poem about the dodo in his \"Bad Child's Book of Beasts\" from 1896:\n\n\n"}
{"id": "8421", "url": "https://en.wikipedia.org/wiki?curid=8421", "title": "Sideroxylon grandiflorum", "text": "Sideroxylon grandiflorum\n\nSideroxylon grandiflorum, known as tambalacoque or dodo tree, is a long-lived tree in the family Sapotaceae, endemic to Mauritius. It is valued for its timber.\n\nThe \"Sideroxylon grandiflorum\" fruit is analogous to the peach. They are both termed drupes because both have a hard endocarp, or pit, surrounding the seed, with the endocarp naturally splitting along a fracture line during germination.\n\nIn 1973, it was thought that this species was dying out. There were supposedly only 13 specimens left, all estimated to be about 300 years old. The true age could not be determined because tambalacoque has no growth rings. Stanley Temple hypothesized that the dodo, which became extinct in the 17th century, ate tambalacoque fruits, and only by passing through the digestive tract of the dodo could the seeds germinate. Temple (1977) force-fed seventeen tambalacoque fruits to wild turkeys. Seven of the fruits were crushed by the bird's gizzard. The remaining ten were either regurgitated or passed with the bird's feces. Temple planted the remaining ten fruits and three germinated. Temple did not try to germinate any seeds from control fruits not fed to turkeys so the effect of feeding fruits to turkeys was unclear. Reports made on tambalacoque seed germination by Hill (1941) and King (1946) found the seeds germinated without abrading.\n\nTemple's hypothesis that the tree required the dodo has been contested. Others have suggested the decline of the tree was exaggerated, or that other extinct animals may also have been distributing the seeds, such as tortoises, fruit bats or the broad-billed parrot. Wendy Strahm and Anthony Cheke, two experts in Mascarene ecology, claim that while a rare tree, it has germinated since the demise of the dodo and numbers a few hundred, not 13. The difference in numbers is because young trees are not distinct in appearance and may easily be confused with similar species. The decline of the tree may possibly be due to introduction of domestic pigs and crab-eating macaques and competition with introduced plants. Catling (2001) in a summary cites Owadally and Temple (1979), and Witmer (1991). Hershey (2004) reviewed the flaws in Temple's dodo-tambalacoque hypothesis.\n\nIn 2004, Botanical Society of America's Plant Science Bulletin disputed Dr. Temple's research as flawed which published evidence as to why the dodo's extinction did not directly cause the increasing disappearance of young trees including suggestion that tortoises would have been more likely to disperse the seeds than dodo hence discrediting Temple's view as to the dodo and the tree's sole survival relationship.\n\nThis dodo tree is highly valued for its wood in Mauritius, which has led some foresters to scrape the pits by hand to make them sprout and grow.\n\n\n"}
{"id": "8425", "url": "https://en.wikipedia.org/wiki?curid=8425", "title": "Dwight Schultz", "text": "Dwight Schultz\n\nWilliam Dwight Schultz (born November 24, 1947) is an American actor and voice artist. He is known for his roles as Captain \"Howling Mad\" Murdock on the 1980s action series \"The A-Team\", and as Reginald Barclay in \"\", \"\" and the film \"\". He is also known in animation as the mad scientist Dr. Animo in the \"Ben 10\" series, Chef Mung Daal in the children's animated series \"Chowder\", and Eddie the Squirrel in \"CatDog\".\n\nSchultz was born in Baltimore, Maryland, of German descent, and is a Roman Catholic. He attended Calvert Hall College High School and Towson University.\n\nSchultz's breakthrough role was the character of Captain \"Howling Mad\" Murdock on \"The A-Team\". He subsequently appeared in several films, including \"The Fan\" (1981), and starred in \"Fat Man and Little Boy\" (1989) as J. Robert Oppenheimer. In the early 1990s, he had a recurring role as Lieutenant Reginald Barclay in \"\", and reprised the role in \"\" and the film \"\".\n\nSchultz also had a role in the \"Babylon 5\" episode 'The Long Dark' (Season 2 Episode 5) as a former soldier still suffering the effects of war.\n\nSchultz played a dramatic change-of-pace role in the 1992 television film \"Child of Rage\", starring opposite Mel Harris as a compassionate couple who adopt a troubled girl who has been sexually abused.\n\nIn November 2009, Schultz confirmed that he and former \"A-Team\" co-star Dirk Benedict would make cameo appearances in the feature film \"The A-Team\". Although their parts were ultimately cut from the film, they were included after the credits as an Easter egg.\n\nShultz hosted a conservative talk radio podcast called \"Howling Mad Radio\", which ended in March 2009. He has also guest-hosted on numerous occasions for Michael Savage on \"The Savage Nation\", Jerry Doyle on \"The Jerry Doyle Show\", and Rusty Humphries on \"The Rusty Humphries Show\".\n\nSchultz married actress Wendy Fulton in 1983. They have one daughter, Ava (born 1987), who serves in the Marines.\n\nSchultz is a conservative and in 2012 began regular appearances on \"The Glazov Gang\", an Internet political talk show hosted by Jamie Glazov, managing editor of FrontPage Magazine. He also posts political commentaries and podcasts on his official fansite.\n\n\n\n"}
{"id": "8429", "url": "https://en.wikipedia.org/wiki?curid=8429", "title": "Density", "text": "Density\n\nThe density, or more precisely, the volumetric mass density, of a substance is its mass per unit volume. The symbol most often used for density is \"ρ\" (the lower case Greek letter rho), although the Latin letter \"D\" can also be used. Mathematically, density is defined as mass divided by volume:\n\nwhere \"ρ\" is the density, \"m\" is the mass, and \"V\" is the volume. In some cases (for instance, in the United States oil and gas industry), density is loosely defined as its weight per unit volume, although this is scientifically inaccurate – this quantity is more specifically called specific weight.\n\nFor a pure substance the density has the same numerical value as its mass concentration.\nDifferent materials usually have different densities, and density may be relevant to buoyancy, purity and packaging. Osmium and iridium are the densest known elements at standard conditions for temperature and pressure but certain chemical compounds may be denser.\n\nTo simplify comparisons of density across different systems of units, it is sometimes replaced by the dimensionless quantity \"relative density\" or \"specific gravity\", i.e. the ratio of the density of the material to that of a standard material, usually water. Thus a relative density less than one means that the substance floats in water.\n\nThe density of a material varies with temperature and pressure. This variation is typically small for solids and liquids but much greater for gases. Increasing the pressure on an object decreases the volume of the object and thus increases its density. Increasing the temperature of a substance (with a few exceptions) decreases its density by increasing its volume. In most materials, heating the bottom of a fluid results in convection of the heat from the bottom to the top, due to the decrease in the density of the heated fluid. This causes it to rise relative to more dense unheated material.\n\nThe reciprocal of the density of a substance is occasionally called its specific volume, a term sometimes used in thermodynamics. Density is an intensive property in that increasing the amount of a substance does not increase its density; rather it increases its mass.\n\nIn a well-known but probably apocryphal tale, Archimedes was given the task of determining whether King Hiero's goldsmith was embezzling gold during the manufacture of a golden wreath dedicated to the gods and replacing it with another, cheaper alloy. Archimedes knew that the irregularly shaped wreath could be crushed into a cube whose volume could be calculated easily and compared with the mass; but the king did not approve of this. Baffled, Archimedes is said to have taken an immersion bath and observed from the rise of the water upon entering that he could calculate the volume of the gold wreath through the displacement of the water. Upon this discovery, he leapt from his bath and ran naked through the streets shouting, \"Eureka! Eureka!\" (Εύρηκα! Greek \"I have found it\"). As a result, the term \"eureka\" entered common parlance and is used today to indicate a moment of enlightenment.\n\nThe story first appeared in written form in Vitruvius' \"books of architecture\", two centuries after it supposedly took place. Some scholars have doubted the accuracy of this tale, saying among other things that the method would have required precise measurements that would have been difficult to make at the time.\n\nFrom the equation for density (\"ρ\" = \"m\"/\"V\"), mass density has units of mass divided by volume. As there are many units of mass and volume covering many different magnitudes there are a large number of units for mass density in use. The SI unit of kilogram per cubic metre (kg/m) and the cgs unit of gram per cubic centimetre (g/cm) are probably the most commonly used units for density. One g/cm is equal to one thousand kg/m. One cubic centimetre (abbreviation cc) is equal to one millilitre. In industry, other larger or smaller units of mass and or volume are often more practical and US customary units may be used. See below for a list of some of the most common units of density.\n\nA number of techniques as well as standards exist for the measurement of density of materials. Such techniques include the use of a hydrometer (a buoyancy method for liquids), Hydrostatic balance (a buoyancy method for liquids and solids), immersed body method (a buoyancy method for liquids), pycnometer (liquids and solids), air comparison pycnometer (solids), oscillating densitometer (liquids), as well as pour and tap (solids). However, each individual method or technique measures different types of density (e.g. bulk density, skeletal density, etc.), and therefore it is necessary to have an understanding of the type of density being measured as well as the type of material in question. \n\nThe density at all points of a homogeneous object equals its total mass divided by its total volume. The mass is normally measured with a scale or balance; the volume may be measured directly (from the geometry of the object) or by the displacement of a fluid. To determine the density of a liquid or a gas, a hydrometer, a dasymeter or a Coriolis flow meter may be used, respectively. Similarly, hydrostatic weighing uses the displacement of water due to a submerged object to determine the density of the object.\n\nIf the body is not homogeneous, then its density varies between different regions of the object. In that case the density around any given location is determined by calculating the density of a small volume around that location. In the limit of an infinitesimal volume the density of an inhomogeneous object at a point becomes: formula_2, where formula_3 is an elementary volume at position formula_4. The mass of the body then can be expressed as\n\nIn practice, bulk materials such as sugar, sand, or snow contain voids. Many materials exist in nature as flakes, pellets, or granules.\n\nVoids are regions which contain something other than the considered material. Commonly the void is air, but it could also be vacuum, liquid, solid, or a different gas or gaseous mixture.\n\nThe bulk volume of a material—inclusive of the void fraction—is often obtained by a simple measurement (e.g. with a calibrated measuring cup) or geometrically from known dimensions.\n\nMass divided by \"bulk\" volume determines bulk density. This is not the same thing as volumetric mass density.\n\nTo determine volumetric mass density, one must first discount the volume of the void fraction. Sometimes this can be determined by geometrical reasoning. For the close-packing of equal spheres the non-void fraction can be at most about 74%. It can also be determined empirically. Some bulk materials, however, such as sand, have a \"variable\" void fraction which depends on how the material is agitated or poured. It might be loose or compact, with more or less air space depending on handling.\n\nIn practice, the void fraction is not necessarily air, or even gaseous. In the case of sand, it could be water, which can be advantageous for measurement as the void fraction for sand saturated in water—once any air bubbles are thoroughly driven out—is potentially more consistent than dry sand measured with an air void.\n\nIn the case of non-compact materials, one must also take care in determining the mass of the material sample. If the material is under pressure (commonly ambient air pressure at the earth's surface) the determination of mass from a measured sample weight might need to account for buoyancy effects due to the density of the void constituent, depending on how the measurement was conducted. In the case of dry sand, sand is so much denser than air that the buoyancy effect is commonly neglected (less than one part in one thousand).\n\nMass change upon displacing one void material with another while maintaining constant volume can be used to estimate the void fraction, if the difference in density of the two voids materials is reliably known.\n\nIn general, density can be changed by changing either the pressure or the temperature. Increasing the pressure always increases the density of a material. Increasing the temperature generally decreases the density, but there are notable exceptions to this generalization. For example, the density of water increases between its melting point at 0 °C and 4 °C; similar behavior is observed in silicon at low temperatures.\n\nThe effect of pressure and temperature on the densities of liquids and solids is small. The compressibility for a typical liquid or solid is 10 bar (1 bar = 0.1 MPa) and a typical thermal expansivity is 10 K. This roughly translates into needing around ten thousand times atmospheric pressure to reduce the volume of a substance by one percent. (Although the pressures needed may be around a thousand times smaller for sandy soil and some clays.) A one percent expansion of volume typically requires a temperature increase on the order of thousands of degrees Celsius.\n\nIn contrast, the density of gases is strongly affected by pressure. The density of an ideal gas is\n\nwhere is the molar mass, is the pressure, is the universal gas constant, and is the absolute temperature. This means that the density of an ideal gas can be doubled by doubling the pressure, or by halving the absolute temperature.\n\nIn the case of volumic thermal expansion at constant pressure and small intervals of temperature the temperature dependence of density is :\n\nwhere formula_8 is the density at a reference temperature, formula_9 is the thermal expansion coefficient of the material at temperatures close to formula_10.\n\nThe density of a solution is the sum of mass (massic) concentrations of the components of that solution.\n\nMass (massic) concentration of each given component ρ in a solution sums to density of the solution.\n\nExpressed as a function of the densities of pure components of the mixture and their volume participation, it allows the determination of excess molar volumes:\nprovided that there is no interaction between the components.\n\nKnowing the relation between excess volumes and activity coefficients of the components, one can determine the activity coefficients.\n\nThe SI unit for density is:\n\nThe litre and metric tons are not part of the SI, but are acceptable for use with it, leading to the following units:\n\nDensities using the following metric units all have exactly the same numerical value, one thousandth of the value in (kg/m). Liquid water has a density of about 1 kg/dm, making any of these SI units numerically convenient to use as most solids and liquids have densities between 0.1 and 20 kg/dm.\n\nIn US customary units density can be stated in:\n\nImperial units differing from the above (as the Imperial gallon and bushel differ from the US units) in practice are rarely used, though found in older documents. The Imperial gallon was based on the concept that an Imperial fluid ounce of water would have a mass of one Avoirdupois ounce, and indeed 1 g/cc ≈ 1.00224129 ounces per Imperial fluid ounce = 10.0224129 pounds per Imperial gallon. The density of precious metals could conceivably be based on Troy ounces and pounds, a possible cause of confusion.\n\n"}
{"id": "8432", "url": "https://en.wikipedia.org/wiki?curid=8432", "title": "Dave Barry", "text": "Dave Barry\n\nDavid McAlister Barry (born July 3, 1947) is an American author and columnist who wrote a nationally syndicated humor column for the \"Miami Herald\" from 1983 to 2005. He has also written numerous books of humor and parody, as well as comic novels. Barry's honors include the Pulitzer Prize for Commentary (1988) and the Walter Cronkite Award for Excellence in Journalism (2005).\n\nBarry was born in Armonk, New York, where his father, David, was a Presbyterian minister. He was educated at Wampus Elementary School, Harold C. Crittenden Junior High School (both in Armonk), and Pleasantville High School, where he was elected \"Class Clown\" in 1965. He earned a Bachelor of Arts degree in English from Haverford College in 1969.\n\nAs an alumnus of a Quaker-affiliated college, he avoided military service during the Vietnam War by registering as a religious conscientious objector. Notwithstanding his father's vocation, Barry decided \"early on\" that he was an atheist. He said, \"The problem with writing about religion is that you run the risk of offending sincerely religious people, and then they come after you with machetes.\"\n\nBarry began his journalism career in 1971, working as a general-assignment reporter for the \"Daily Local News\" in West Chester, Pennsylvania, near his alma mater, Haverford College. He covered local government and civic events and was promoted to City Editor after about two years. He also started writing a weekly humor column for the paper and began to develop his unique style. He remained at the newspaper through 1974. He then worked briefly as a copy editor at the Associated Press's Philadelphia bureau before joining Burger Associates, a consulting firm.\n\nAt Burger, he taught effective writing to business people. In his own words, he \"spent nearly eight years trying to get various businesspersons to...stop writing things like 'Enclosed please find the enclosed enclosures,' but...eventually realized that it was hopeless.\"\n\nIn 1981 he wrote a humorous guest column, about watching the birth of his son, in the \"Philadelphia Inquirer\", which attracted the attention of Gene Weingarten, then an editor of the \"Miami Herald\"s Sunday magazine \"Tropic\". Weingarten hired Barry as a humor columnist in 1983. Barry's column was syndicated nationally. Barry won a Pulitzer Prize for Commentary in 1988 for \"his consistently effective use of humor as a device for presenting fresh insights into serious concerns.\"\n\nBarry's first novel, \"Big Trouble\", was published in 1999. The book was adapted into a motion picture directed by Barry Sonnenfeld and starring Tim Allen, Rene Russo, and Patrick Warburton, with a cameo by Barry (deleted in post-production). The movie was originally due for release in September 2001 but was postponed following the September 11, 2001, attacks because the story involved smuggling a nuclear weapon onto an airplane. The film was released in April 2002.\n\nIn response to a column in which Barry mocked the cities of Grand Forks, North Dakota, and East Grand Forks, Minnesota, for calling themselves the \"Grand Cities\", Grand Forks named a sewage pumping station after Barry in January 2002. Barry traveled to Grand Forks for the dedication ceremony.\n\nArticles written by Barry have appeared in publications such as \"Boating\", \"Home Office Computing\", and \"Reader's Digest\", in addition to the \"Chicken Soup for the Soul\" inspirational book series. Two of his articles have been included in the \"Best American Sportswriting\" series. One of his columns was used as the introduction to the book \"Pirattitude!: So You Wanna Be a Pirate? Here's How!\" (), a follow-up to Barry's role in publicizing International Talk Like a Pirate Day. His books have frequently appeared on the New York Times Best Seller List.\n\nOn October 31, 2004, Barry announced that he would be taking an indefinite leave of absence of at least a year from his weekly column in order to spend more time with his family. In December 2005, Barry said in an interview with \"Editor and Publisher\" that he would not resume his weekly column, although he would continue such features as his yearly gift guide, his year-in-review feature, and his blog, as well as an occasional article or column.\n\nIn 2005, Barry won the Walter Cronkite Award for Excellence in Journalism.\n\nOn Sunday, September 22, 2013, the opening night of the 15th annual Fall for the Book festival in Fairfax, Virginia, Barry was awarded the event's highest honor, the Fairfax Prize, honoring outstanding literary achievement, presented by the Fairfax Library Foundation.\n\nFrom 1993 to 1997, CBS broadcast the sitcom \"Dave's World\" based on the books \"Dave Barry Turns 40\" and \"Dave Barry's Greatest Hits\". The show starred Harry Anderson as Barry and DeLane Matthews as his wife Beth. In an early episode, Barry appeared in a cameo role. After four seasons, the program was canceled shortly after being moved from Monday to the \"Friday night death slot\".\n\nDuring college, Barry was in a band called the Federal Duck. While at the \"Miami Herald\", he and several of his colleagues created a band called the Urban Professionals, with Barry on lead guitar and vocals. They performed an original song called \"The Tupperware Song\" at the Tupperware headquarters in Orlando, Florida.\n\nBeginning in 1992, Barry played lead guitar in the Rock Bottom Remainders, a rock band made up of published authors. \"(Remainder\" is a publishing term for a book that doesn't sell.) The band was founded by Barry's sister-in-law, Kathi Kamen Goldmark, for an American Booksellers Association convention, and has also included Stephen King, Amy Tan, Ridley Pearson, Scott Turow, Mitch Albom, Roy Blount, Jr., Barbara Kingsolver, Matt Groening, and Barry's brother Sam, among others. The band's members \"are not musically skilled, but they are extremely loud,\" according to Barry. Several high-profile musicians, including Al Kooper, Warren Zevon, and Roger McGuinn, have performed with the band, and Bruce Springsteen sat in at least once. The band's road tour resulted in the book \"Mid-Life Confidential: The Rock Bottom Remainders Tour America with Three Chords and an Attitude\". The Rock Bottom Remainders disbanded in 2012 following Goldmark's death from breast cancer. They have reunited at least several times, performing at the Tucson Festival of books in 2016 and 2018.\n\nBeginning in 1984, Barry and \"Tropic\" editors Gene Weingarten and Tom Shroder have organized the Tropic Hunt (now the Herald Hunt), an annual puzzlehunt in Miami. A Washington, D.C., spinoff, the Post Hunt, began in 2008.\n\nBarry has run several mock campaigns for President of the United States, running on a libertarian platform. He has also written for the Libertarian Party's national newsletter.\n\nThe screen adaptation of Barry's book \"Dave Barry's Complete Guide to Guys\" was released in 2005; it premiered at several film festivals and is available on DVD.\n\nBarry has defined a sense of humor as \"a measurement of the extent to which we realize that we are trapped in a world almost totally devoid of reason. Laughter is how we express the anxiety we feel at this knowledge.\"\n\nHe married Lois Ann Shelnutt, his first wife, in 1969. Barry married his second wife, Beth Lenox, in 1976. Barry and Lenox worked together at the \"Daily Local News\", where they began their journalism careers on the same day in September 1971; they had one child, Robert, born October 8, 1980. Barry and Lenox divorced in 1993. Barry experienced tragedy in his family; his father David W and his youngest brother suffered alcoholism, and his father died in 1984, his sister Mary Katherine was institutionalized for schizophrenia, and his mother committed suicide in 1987. In 1996, Barry married \"Miami Herald\" sportswriter Michelle Kaufman; they had a daughter, Sophie, in 2000. Barry has had dogs named Earnest, Zippy, and now Lucy. All have been mentioned regularly in Barry's columns.\n\n\n\n\n\n\n\n\n"}
{"id": "8436", "url": "https://en.wikipedia.org/wiki?curid=8436", "title": "David Angell", "text": "David Angell\n\nDavid Lawrence Angell (April 10, 1946September 11, 2001) was an American television producer and screenwriter. Angell won multiple Emmy Awards as the creator and executive producer, along with Peter Casey and David Lee, of the comedy series \"Frasier\". Angell and his wife Lynn both died heading home from their vacation on Cape Cod aboard American Airlines Flight 11, the first plane to hit the World Trade Center during the September 11 attacks.\n\nAngell was born in Providence, Rhode Island, to Henry and Mae (née Cooney) Angell. He received a bachelor's degree in English Literature from Providence College. He married Lynn Edwards on August 14, 1971. Soon after Angell entered the U.S. Army upon graduation and served at the Pentagon until 1972. He then moved to Boston and worked as a methods analyst at an engineering company and later at an insurance firm in Rhode Island. His brother, the late Most Rev. Kenneth Angell, was a Roman Catholic prelate and former Bishop of Burlington, Vermont.\n\nAngell moved to Los Angeles in 1977. His first script was sold to the producers of the \"Annie Flynn\" series. Five years later, he sold his second script to \"Archie Bunker's Place\". In 1983, he joined \"Cheers\" as a staff writer. In 1985, Angell joined forces with Peter Casey and David Lee as \"Cheers\" supervising producers/writers. The trio received 37 Emmy Award nominations and won 24 Emmy Awards, including the above-mentioned for \"Frasier\", as well as an Outstanding Comedy Series Emmy for \"Cheers\", in 1989, which Angell, Casey, Lee and the series' other producers shared, and Outstanding Writing/Comedy Emmy for \"Cheers\", which Angell received in 1984. After working together as producers on \"Cheers\", Angell, Casey and Lee formed Grub Street Productions. In 1990, they created and executive-produced the comedy series \"Wings\".\n\nAngell and his wife, Lynn, were among the passengers of American Airlines Flight 11 killed in the September 11 attacks on the World Trade Center in New York City in 2001.\n\nThe American Screenwriters Association awards the annual David Angell Humanitarian Award to any individual in the entertainment industry who contributes to global well-being through donations of time, expertise or other support to improve the human condition.\n\nIn 2004, The Angell Foundation of Los Angeles, California awarded Providence College a gift of $2 million for the Smith Center for the Arts.\n\nThe second episode of \"Frasier\" to air after the attacks, \"Don Juan in Hell: Part 2\", airing on September 25, 2001, ended with the memorial tribute, \"In loving memory of our friends Lynn and David Angell\". \"Goodnight, Seattle\", the series finale which aired May 13, 2004, featured the birth of Niles Crane and Daphne Moon’s son, who is named David in tribute.\n\nAt the National 9/11 Memorial, Angell and his wife are memorialized at the North Pool, on Panel N-1, along with other passengers from Flight 11.\n\n"}
{"id": "8437", "url": "https://en.wikipedia.org/wiki?curid=8437", "title": "Diedrich Hermann Westermann", "text": "Diedrich Hermann Westermann\n\nDiedrich Hermann Westermann (June 24, 1875–May 31, 1956) was a German missionary, Africanist, and linguist. He substantially extended and revised the work of Carl Meinhof, his teacher, although he rejected some of Meinhof's theories only implicitly. Westermann is seen as one of the founders of modern African linguistics. \n\nHe carried out extensive linguistic and anthropological research in the area ranging from Senegal eastwards to the Upper Nile. His linguistic publications cover a wide range of African languages, including the Gbe languages, Nuer, Kpelle, Shilluk, Hausa, and Guang. \n\nWestermann's comparative work, begun in 1911, initially brought together much of today's Niger–Congo and Nilo-Saharan language phyla under the name Sudanic languages. His most important later publication \"Die westlichen Sudansprachen\" 1927a divided these into East and West Sudanic languages and laid the basis for what would become Niger–Congo. In this book and a series of associated articles between 1925 and 1928, Westermann both identified a large number of roots that form the basis of our understanding of Niger–Congo and set out the evidence for the coherence of many of the families that constitute it. Much of the classification of African languages associated with Joseph Greenberg actually derives from the work of Westermann.\nIn 1927 Westermann published a \"Practical Orthography of African Languages\" which became later known as the \"Westermann script\". Subsequently he published the influential and oft-reprinted \"Practical Phonetics for Students of African Languages\" in collaboration with Ida C. Ward (1933).\n\nHe was born in Baden near Bremen and also died there.\n\n\n\n"}
{"id": "8439", "url": "https://en.wikipedia.org/wiki?curid=8439", "title": "Diacritic", "text": "Diacritic\n\nA diacritic – also diacritical mark, diacritical point, diacritical sign, or accent – is a glyph added to a letter, or basic glyph. The term derives from the Ancient Greek (\"diakritikós\", \"distinguishing\"), from (\"diakrī́nō\", \"to distinguish\"). \"Diacritic\" is primarily an adjective, though sometimes used as a noun, whereas \"diacritical\" is only ever an adjective. Some diacritical marks, such as the acute ( ´ ) and grave ( ` ), are often called \"accents\". Diacritical marks may appear above or below a letter, or in some other position such as within the letter or between two letters.\n\nThe main use of diacritical marks in the Latin script is to change the sound-values of the letters to which they are added. Examples are the diaereses in the borrowed French words \"naïve\" and \"Noël\", which show that the vowel with the diaeresis mark is pronounced separately from the preceding vowel; the acute and grave accents, which can indicate that a final vowel is to be pronounced, as in \"saké\" and poetic \"breathèd\"; and the cedilla under the \"c\" in the borrowed French word \"façade\", which shows it is pronounced rather than . In other Latin-script alphabets, they may distinguish between homonyms, such as the French \"là\" (\"there\") versus \"la\" (\"the\") that are both pronounced . In Gaelic type, a dot over a consonant indicates lenition of the consonant in question.\n\nIn other alphabetic systems, diacritical marks may perform other functions. Vowel pointing systems, namely the Arabic harakat (  etc.) and the Hebrew niqqud (  etc.) systems, indicate vowels that are not conveyed by the basic alphabet. The Indic virama ( ् etc.) and the Arabic sukūn (  ) mark the absence of vowels. Cantillation marks indicate prosody. Other uses include the Early Cyrillic titlo stroke ( ◌҃ ) and the Hebrew gershayim (  ), which, respectively, mark abbreviations or acronyms, and Greek diacritical marks, which showed that letters of the alphabet were being used as numerals. In the Hanyu Pinyin official romanization system for Chinese, diacritics are used to mark the tones of the syllables in which the marked vowels occur.\n\nIn orthography and collation, a letter modified by a diacritic may be treated either as a new, distinct letter or as a letter–diacritic combination. This varies from language to language, and may vary from case to case within a language. English is the only major modern European language requiring no diacritics for native words (although a diaeresis may be used in words such as \"coöperation\").\n\nIn some cases, letters are used as \"in-line diacritics\", with the same function as ancillary glyphs, in that they modify the sound of the letter preceding them, as in the case of the \"h\" in the English pronunciation of \"sh\" and \"th\".\n\nAmong the types of diacritic used in alphabets based on the Latin script are:\n\nThe tilde, dot, comma, titlo, apostrophe, bar, and colon are sometimes diacritical marks, but also have other uses.\n\nNot all diacritics occur adjacent to the letter they modify. In the Wali language of Ghana, for example, an apostrophe indicates a change of vowel quality, but occurs at the beginning of the word, as in the dialects \"’Bulengee\" and \"’Dolimi\". Because of vowel harmony, all vowels in a word are affected, so the scope of the diacritic is the entire word. In abugida scripts, like those used to write Hindi and Thai, diacritics indicate vowels, and may occur above, below, before, after, or around the consonant letter they modify.\n\nThe tittle (dot) on the letter \"i\" of the Latin alphabet originated as a diacritic to clearly distinguish \"i\" from the minims (downstrokes) of adjacent letters. It first appeared in the 11th century in the sequence \"ii\" (as in \"ingeníí)\", then spread to \"i\" adjacent to \"m, n, u\", and finally to all lowercase \"i\"'s. The \"j\", originally a variant of \"i\", inherited the tittle. The shape of the diacritic developed from initially resembling today's acute accent to a long flourish by the 15th century. With the advent of Roman type it was reduced to the round dot we have today.\n\n\nThese diacritics are used in addition to the acute, grave, and circumflex accents and the diaeresis:\n\n\nThe diacritics >〮 and 〯  , known as Bangjeom (), were used to mark pitch accents in Hangul for Middle Korean. They were written to the left of a syllable in vertical writing and above a syllable in horizontal writing.\n\nThe South Korean government officially revised the romanization of the Korean language in July 2000 to eliminate diacritics.\n\n\nIn addition to the above vowel marks, transliteration of Syriac sometimes includes \"ə\", \"e̊\" or superscript \"\" (or often nothing at all) to represent an original Aramaic schwa that became lost later on at some point in the development of Syriac. Some transliteration schemes find its inclusion necessary for showing spirantization or for historical reasons.\n\nSome non-alphabetic scripts also employ symbols that function essentially as diacritics.\n\nDifferent languages use different rules to put diacritic characters in alphabetical order. French treats letters with diacritical marks the same as the underlying letter for purposes of ordering and dictionaries.\n\nThe Scandinavian languages, by contrast, treat the characters with diacritics \"ä\", \"ö\" and \"å\" as new and separate letters of the alphabet, and sort them after \"z\". Usually \"ä\" is sorted as equal to \"æ\" (ash) and \"ö\" is sorted as equal to \"ø\" (o-slash). Also, \"aa\", when used as an alternative spelling to \"å\", is sorted as such. Other letters modified by diacritics are treated as variants of the underlying letter, with the exception that \"ü\" is frequently sorted as \"y\".\n\nLanguages that treat accented letters as variants of the underlying letter usually alphabetize words with such symbols immediately after similar unmarked words. For instance, in German where two words differ only by an umlaut, the word without it is sorted first in German dictionaries (e.g. \"schon\" and then \"schön\", or \"fallen\" and then \"fällen\"). However, when names are concerned (e.g. in phone books or in author catalogues in libraries), umlauts are often treated as combinations of the vowel with a suffixed \"e\"; Austrian phone books now treat characters with umlauts as separate letters (immediately following the underlying vowel).\n\nIn Spanish, the grapheme \"ñ\" is considered a new letter different from \"n\" and collated between \"n\" and \"o\", as it denotes a different sound from that of a plain \"n\". But the accented vowels \"á\", \"é\", \"í\", \"ó\", \"ú\" are not separated from the unaccented vowels \"a\", \"e\", \"i\", \"o\", \"u\", as the acute accent in Spanish only modifies stress within the word or denotes a distinction between homonyms, and does not modify the sound of a letter.\n\nFor a comprehensive list of the collating orders in various languages, see Collating sequence.\n\nModern computer technology was developed mostly in English-speaking countries, so data formats, keyboard layouts, etc. were developed with a bias favoring English, a language with an alphabet without diacritical marks. This has led some to theorize that the marks and accents may be made obsolete to facilitate the worldwide exchange of data. Efforts have been made to create internationalized domain names that further extend the English alphabet (e.g., \"pokémon.com\").\n\nDepending on the keyboard layout, which differs amongst countries, it is more or less easy to enter letters with diacritics on computers and typewriters. Some have their own keys; some are created by first pressing the key with the diacritic mark followed by the letter to place it on. Such a key is sometimes referred to as a dead key, as it produces no output of its own but modifies the output of the key pressed after it.\n\nIn modern Microsoft Windows and Linux operating systems, the keyboard layouts \"US International\" and \"UK International\" feature dead keys that allow one to type Latin letters with the acute, grave, circumflex, diæresis, tilde, and cedilla found in Western European languages (specifically, those combinations found in the ISO Latin-1 character set) directly: + gives \"ë\", + gives \"õ\", etc. On Apple Macintosh computers, there are keyboard shortcuts for the most common diacritics; followed by a vowel places an acute accent, followed by a vowel gives an umlaut, gives a cedilla, etc. Diacritics can be composed in most X Window System keyboard layouts, as well as other operating systems, such as Microsoft Windows, using additional software.\n\nOn computers, the availability of code pages determines whether one can use certain diacritics. Unicode solves this problem by assigning every known character its own code; if this code is known, most modern computer systems provide a method to input it. With Unicode, it is also possible to combine diacritical marks with most characters.\n\nThe following languages have letters that contain diacritics that are considered independent letters distinct from those without diacritics.\n\n\n\nEnglish is one of the few European languages that does not have many words that contain diacritical marks. Exceptions are unassimilated foreign loanwords, including borrowings from French and, increasingly, Spanish; however, the diacritic is also sometimes omitted from such words. Loanwords that frequently appear with the diacritic in English include \"café\", \"résumé\" or \"resumé\" (a usage that helps distinguish it from the verb \"resume\"), \"soufflé\", and \"naïveté\" (see \"English terms with diacritical marks\"). In older practice (and even among some orthographically conservative modern writers) one may see examples such as \"élite\", \"mêlée\" and \"rôle.\"\n\nEnglish speakers and writers once used the diaeresis more often than now in words such as \"coöperation\" (from Fr. \"coopération\"), \"zoölogy\" (from Grk. \"zoologia\"), and \"seeër\" (now more commonly \"see-er \"or simply\" seer\") as a way of indicating that adjacent vowels belonged to separate syllables, but this practice has become far less common. \"The New Yorker\" magazine is a major publication that continues to use the diaresis in place of a dash for clarity and economy of space.\n\nA few English words, out of context, can only be distinguished from others by a diacritic or modified letter, including exposé, lamé, maté, öre, øre, pâté, and rosé'. The same is true of \"résumé,\" alternately \"\" but nevertheless it is regularly spelled \"resume\". In a few words, diacritics that did not exist in the original have been added for disambiguation, as in maté (from Sp. and Port. \"mate\"), saké (the standard Romanization of the Japanese has no accent mark), and Malé (from Dhivehi މާލެ), to clearly distinguish them from the English words \"mate\", \"sake\", and \"male\".\n\nThe acute and grave accents are occasionally used in poetry and lyrics: the acute to indicate stress overtly where it might be ambiguous (\"rébel\" vs. \"rebél\") or nonstandard for metrical reasons (\"caléndar\"), the grave to indicate that an ordinarily silent or elided syllable is pronounced (\"warnèd,\" \"parlìament\").\n\nIn certain personal names such as \"Renée\" and \"Zoë\", often two spellings exist, and the preference will be known only to those close to the person themselves. Even when the name of a person is spelled with a diacritic, like Charlotte Brontë, this may be dropped in English language articles and even official documents such as passports either due to carelessness, the typist not knowing how to enter letters with diacritical marks, or for technical reasons - California, for example, does not allow names with diacritics as the computer system cannot process such characters. They also appear in some worldwide company names and/or trademarks such as Nestlé or Citroën.\n\nThe following languages have letter-diacritic combinations that are not considered independent letters.\n\nSeveral languages that are not written with the Roman alphabet are transliterated, or romanized, using diacritics. Examples:\n\n\n"}
{"id": "8442", "url": "https://en.wikipedia.org/wiki?curid=8442", "title": "Digraph", "text": "Digraph\n\nDigraph may refer to:\n\n\n"}
{"id": "8443", "url": "https://en.wikipedia.org/wiki?curid=8443", "title": "Didgeridoo", "text": "Didgeridoo\n\nThe didgeridoo (; also known as a didjeridu) is a wind instrument developed by Indigenous Australians of northern Australia potentially within the last 1,500 years and still in widespread use today both in Australia and around the world. It is sometimes described as a natural wooden trumpet or \"drone pipe\". Musicologists classify it as a brass aerophone.\n\nThere are no reliable sources stating the didgeridoo's exact age. Archaeological studies of rock art in Northern Australia suggest that the people of the Kakadu region of the Northern Territory have been using the didgeridoo for less than 1,000 years, based on the dating of paintings on cave walls and shelters from this period. A clear rock painting in Ginga Wardelirrhmeng, on the northern edge of the Arnhem Land plateau, from the freshwater period (that had begun 1500 years ago) shows a didgeridoo player and two songmen participating in an Ubarr Ceremony.\n\nA modern didgeridoo is usually cylindrical or conical, and can measure anywhere from long. Most are around long. Generally, the longer the instrument, the lower its pitch or key. However, flared instruments play a higher pitch than unflared instruments of the same length.\n\nThere are numerous names for the instrument among the Aboriginal peoples of northern Australia, none of which closely resemble the word \"didgeridoo\" (see below). Many didgeridoo enthusiasts and some scholars advocate reserving local names for traditional instruments, and this practice has been endorsed by some Aboriginal community organisations. However, in everyday conversation, bilingual Aboriginal people will often use the word \"didgeridoo\" interchangeably with the instrument's name in their own language.\n\n\"Didgeridoo\" is considered to be an onomatopoetic word of Western invention. The earliest occurrences of the word in print include a 1908 edition of the \"Hamilton Spectator\", a 1914 edition of \"The Northern Territory Times and Gazette\", and a 1919 issue of \"Smith's Weekly\" where it was referred to as an \"infernal didjerry\" which \"produced but one sound – (phonic) didjerry, didjerry, didjerry and so on ad infinitum\".\n\nA rival explanation, that didgeridoo is a corruption of the Irish language (Gaelic) phrase \"dúdaire dubh\" or \"dúidire dúth\", is controversial. \"Dúdaire\"/\"dúidire\" is a noun that may mean, depending on the context, \"trumpeter\", \"hummer\", \"crooner\", \"long-necked person\", \"puffer\", \"eavesdropper\", or \"chain smoker\", while \"dubh\" means \"black\" and \"dúth\" means \"native\".\n\n\"Yiḏaki\" (sometimes spelt \"yirdaki\") is one of the most commonly used names, although – strictly speaking – it refers to a specific type of instrument made and used by the Yolngu people of north-east Arnhem Land. However, since the death, in early 2011, of a Manggalili-clan man whose name sounds similar to \"yiḏaki\", Yolngu themselves now use the synonym \"mandapul\" to refer to the instrument, out of respect for the deceased.\n\nThere are numerous other, regional names for the didgeridoo. The following are some of the more common of these.\nAuthentic Aboriginal didgeridoos are produced in traditionally oriented communities in Northern Australia or by makers who travel to Central and Northern Australia to collect the raw materials. They are usually made from hardwoods, especially the various eucalyptus species that are endemic to the region. Generally the main trunk of the tree is harvested, though a substantial branch may be used instead. Aboriginal didgeridoo craftsmen hunt for suitably hollow live trees in areas with obvious termite activity. Termites attack these living eucalyptus trees, removing only the dead heartwood of the tree, as the living sapwood contains a chemical that repels the insects. Various techniques are employed to find trees with a suitable hollow, including knowledge of landscape and termite activity patterns, and a kind of tap or knock test, in which the bark of the tree is peeled back, and a fingernail or the blunt end of a tool, such as an axe, is knocked against the wood to determine if the hollow produces the right resonance.\n\nOnce a suitably hollow tree is found, it is cut down and cleaned out, the bark is taken off, the ends trimmed, and the exterior is shaped; this results in a finished instrument. This instrument may be painted or left undecorated. A rim of beeswax may be applied to the mouthpiece end. Traditional instruments made by Aboriginal craftsmen in Arnhem Land are sometimes fitted with a \"sugarbag\" mouthpiece. This black beeswax comes from wild bees and has a distinctive aroma.\n\nNon-traditional didgeridoos can also be made from PVC piping, non-native hard woods (typically split, hollowed and rejoined), glass, fiberglass, metal, agave, clay, hemp (in the form of a bioplastic named zelfo), and even carbon fibre. These didges typically have an upper inside diameter of around 1.25\" down to a bell end of anywhere between two and eight inches and have a length corresponding to the desired key. The mouthpiece can be constructed of beeswax, hardwood or simply sanded and sized by the craftsman. In PVC, an appropriately sized rubber stopper with a hole cut into it is equally acceptable, or to finely sand and buff the end of the pipe to create a comfortable mouthpiece.\n\nModern didgeridoo designs are distinct from the traditional Australian Aboriginal didgeridoo, and are innovations recognized by musicologists. Didgeridoo design innovation started in the late 20th century using non-traditional materials and non-traditional shapes.\n\nMany didgeridoos are painted using traditional or modern paints by either their maker or a dedicated artist; however, it is not essential that the instrument be decorated. It is also common to retain the natural wood grain with minimal or no decoration. Some modern makers deliberately avoid decoration if they are not of Indigenous Australian descent, or leave the instrument blank for an Indigenous Australian artist to decorate it at a later stage.\n\nThe didgeridoo is played with continuously vibrating lips to produce the drone while using a special breathing technique called circular breathing. This requires breathing in through the nose whilst simultaneously expelling stored air out of the mouth using the tongue and cheeks. By use of this technique, a skilled player can replenish the air in their lungs, and with practice can sustain a note for as long as desired. Recordings exist of modern didgeridoo players playing continuously for more than 40 minutes; Mark Atkins on \"Didgeridoo Concerto\" (1994) plays for over 50 minutes continuously.\n\nFellow of the British Society Anthony Baines wrote that the didgeridoo functions \"...as an aural kaleidoscope of timbres\" and that \"the extremely difficult virtuoso techniques developed by expert performers find no parallel elsewhere.\"\n\nMore modern approaches to playing the didgeridoo are starting to show up in performances and lessons around the World. One of these techniques involves combining beatboxing with playing the didgeridoo. It was featured on the British children's TV series \"Blue Peter\".\n\nA termite-bored didgeridoo has an irregular shape that, overall, usually increases in diameter towards the lower end. This shape means that its resonances occur at frequencies that are not harmonically spaced in frequency. This contrasts with the harmonic spacing of the resonances in a cylindrical plastic pipe, whose resonant frequencies fall in the ratio 1:3:5 etc. The second resonance of a didgeridoo (the note sounded by overblowing) is usually around an 11th higher than the fundamental frequency (a frequency ratio somewhat less than 3:1).\n\nThe vibration produced by the player's lips has harmonics, i.e., it has frequency components falling exactly in the ratio 1:2:3 etc. However, the non-harmonic spacing of the instrument's resonances means that the harmonics of the fundamental note are not systematically assisted by instrument resonances, as is usually the case for Western wind instruments (e.g., in the low range of the clarinet, the 1st, 3rd, and 5th harmonics of the reed are assisted by resonances of the bore).\n\nSufficiently strong resonances of the vocal tract can strongly influence the timbre of the instrument.\nAt some frequencies, whose values depend on the position of the player's tongue, resonances of the vocal tract inhibit the oscillatory flow of air into the instrument.\nBands of frequencies that are not thus inhibited produce formants in the output sound.\nThese formants, and especially their variation during the inhalation and exhalation phases of circular breathing, give the instrument its readily recognizable sound.\n\nOther variations in the didgeridoo's sound can be made by adding vocalizations to the drone. Most of the vocalizations are related to sounds emitted by Australian animals, such as the dingo or the kookaburra. To produce these sounds, the players simply have to use their vocal folds to produce the sounds of the animals whilst continuing to blow air through the instrument. The results range from very high-pitched sounds to much lower sounds involving interference between the lip and vocal fold vibrations. Adding vocalizations increases the complexity of the playing.\n\nTraditionally and originally, the didgeridoo was primarily played as an accompaniment to ceremonial dancing and singing. However, it was also common for didgeridoos to be played for solo or recreational purposes outside of ceremonial gatherings. For surviving Aboriginal groups of northern Australia, the didgeridoo is still an integral part of ceremonial life, as it accompanies singers and dancers in cultural ceremonies that continue. Today, the majority of didgeridoo playing is for recreational purposes in both Indigenous Australian communities and elsewhere around the world.\n\nPair sticks, sometimes called \"clapsticks\" or \"bilma\", establish the beat for the songs during ceremonies. The rhythm of the didgeridoo and the beat of the clapsticks are precise, and these patterns have been handed down for many generations. In the Wangga genre, the song-man starts with vocals and then introduces \"blima\" to the accompaniment of didgeridoo.\n\nTraditionally, only men play the didgeridoo and sing during ceremonial occasions, although both men and women may dance. Female didgeridoo players do exist, but their playing takes place in an informal context and is not specifically encouraged by Aboriginal elders. Linda Barwick, an ethnomusicologist, says that though traditionally women have not played the didgeridoo in ceremony, in informal situations there is no prohibition in the Dreaming Law. For example, Jemima Wimalu, a Mara woman from the Roper River is very proficient at playing the didgeridoo and is featured on the record \"Aboriginal Sound Instruments\" released in 1978. In 1995, musicologist Steve Knopoff observed Yirrkala women performing \"djatpangarri\" songs that are traditionally performed by men and in 1996, ethnomusicologist Elizabeth MacKinley reported women of the Yanyuwa group giving public performances. In 2008, however, publisher Harper Collins apologized for its book \"The Daring Book for Girls\", which openly encouraged girls to play the instrument after Aboriginal academics described such encouragement as \"extreme cultural insensitivity\" and \"an extreme faux pas... part of a general ignorance that mainstream Australia has about Aboriginal culture.\"\n\nWhile there is no prohibition in the area of the didgeridoo's origin, such restrictions have been applied by other Indigenous communities. The didgeridoo was introduced to the Kimberleys almost a century ago but it is only in the last decade that Aboriginal men have shown adverse reactions to women playing the instrument and prohibitions are especially evident in the South East of Australia. The belief that women are prohibited from playing is widespread among non-Aboriginal people and is also common among Aboriginal communities in Southern Australia; some ethnomusicologists believe that the dissemination of the \"Taboo\" belief and other misconceptions is a result of commercial agendas and marketing. Tourists generally rely on shop employees for information when purchasing a didgeridoo. Additionally, the majority of commercial didgeridoo recordings available are distributed by multinational recording companies and feature non-Aboriginals playing a New Age style of music with liner notes promoting the instrument's spirituality which misleads consumers about the didgeridoo's secular role in traditional Aboriginal culture.\n\nThe Taboo belief is particularly strong among many Indigenous groups in the South East of Australia, where it is forbidden and considered \"cultural theft\" for non-Indigenous women, and especially performers of \"New Age\" music regardless of sex, to play or even touch a didgeridoo.\n\nThe didgeridoo also became a role playing instrument in the experimental and avant-garde music scene. Industrial music bands like Test Department generated sounds from this instrument and used them in their industrial performances, linking ecology to industry, influenced by ethnic music and culture.\n\nIt is very often used in the music project Naakhum which combines Extreme Metal and Ethnic music.\n\nThe acid jazz band Jamiroquai were known for their didgeridoo player Wallis Buchanan. In the early days of the band, many songs explored the theme of ecology and those of native cultures marginalized by colonisation. A notable song featuring a didgeridoo is the band's first single \"When You Gonna Learn\", which features prominent didgeridoo playing in both the introduction and solo sections. When Wallis Buchanan left the band in 1999, the band chose not to replace him, and simply abandoned the use of the instrument in their music.\n\nThe instrument is commonly used by ambient artist Steve Roach as a complement to his produced soundscapes, in both live and recorded formats. It features prominently in his collaborative work \"\" (with Australian Aboriginal artist David Hudson and cellist Sarah Hopkins) as well as \"Dreamtime Return\".\n\nIt is used in the Indian song \"Jaane Kyon\" from the film \"Dil Chahta Hai\".\n\nChris Brooks, lead singer of the New Zealand hard rock band Like a Storm uses the didgeridoo in some of the band's songs including \"Love the Way You Hate Me\" from their album \"\".\n\nKate Bush made extensive use of the didgeridoo (played by Australian musician Rolf Harris) on her album \"The Dreaming\", which was written and recorded after a holiday in Australia.\n\nA 2005 study in the \"British Medical Journal\" found that learning and practising the didgeridoo helped reduce snoring and obstructive sleep apnea by strengthening muscles in the upper airway, thus reducing their tendency to collapse during sleep. In the study, intervention subjects were trained in and practiced didgeridoo playing, including circular breathing and other techniques. Control subjects were asked not to play the instrument. Subjects were surveyed before and after the study period to assess the effects of intervention. A small 2010 study noted improvements in the asthma management of Aboriginal teens when incorporating didgeridoo playing.\n\n\n"}
{"id": "8449", "url": "https://en.wikipedia.org/wiki?curid=8449", "title": "Developmental biology", "text": "Developmental biology\n\nDevelopmental biology is the study of the process by which animals and plants grow and develop. Developmental biology also encompasses the biology of regeneration, asexual reproduction, metamorphosis, and the growth and differentiation of stem cells in the adult organism.\n\nIn the late 20th century, the discipline largely transformed into evolutionary developmental biology.\n\nThe main processes involved in the embryonic development of animals are: regional specification, morphogenesis, cell differentiation, growth, and the overall control of timing explored in evolutionary developmental biology:\n\n\nThe development of plants involves similar processes to that of animals. However plant cells are mostly immotile so morphogenesis is achieved by differential growth, without cell movements. Also, the inductive signals and the genes involved are different from those that control animal development.\n\nCell differentiation is the process whereby different functional cell types arise in development. For example, neurons, muscle fibers and hepatocytes (liver cells) are well known types of differentiated cell. Differentiated cells usually produce large amounts of a few proteins that are required for their specific function and this gives them the characteristic appearance that enables them to be recognized under the light microscope. The genes encoding these proteins are highly active. Typically their chromatin structure is very open, allowing access for the transcription enzymes, and specific transcription factors bind to regulatory sequences in the DNA in order to activate gene expression. For example, NeuroD is a key transcription factor for neuronal differentiation, myogenin for muscle differentiation, and HNF4 for hepatocyte differentiation.\nCell differentiation is usually the final stage of development, preceded by several states of commitment which are not visibly differentiated. A single tissue, formed from a single type of progenitor cell or stem cell, often consists of several differentiated cell types. Control of their formation involves a process of lateral inhibition, based on the properties of the Notch signaling pathway. For example, in the neural plate of the embryo this system operates to generate a population of neuronal precursor cells in which NeuroD is highly expressed.\n\nRegeneration indicates the ability to regrow a missing part. This is very prevalent amongst plants, which show continuous growth, and also among colonial animals such as hydroids and ascidians. But most interest by developmental biologists has been shown in the regeneration of parts in free living animals. In particular four models have been the subject of much investigation. Two of these have the ability to regenerate whole bodies: \"Hydra\", which can regenerate any part of the polyp from a small fragment, and planarian worms, which can usually regenerate both heads and tails. Both of these examples have continuous cell turnover fed by stem cells and, at least in planaria, at least some of the stem cells have been shown to be pluripotent. The other two models show only distal regeneration of appendages. These are the insect appendages, usually the legs of hemimetabolous insects such as the cricket, and the limbs of urodele amphibians. Considerable information is now available about amphibian limb regeneration and it is known that each cell type regenerates itself, except for connective tissues where there is considerable interconversion between cartilage, dermis and tendons. In terms of the pattern of structures, this is controlled by a re-activation of signals active in the embryo.\nThere is still debate about the old question of whether regeneration is a \"pristine\" or an \"adaptive\" property. If the former is the case, with improved knowledge, we might expect to be able to improve regenerative ability in humans. If the latter, then each instance of regeneration is presumed to have arisen by natural selection in circumstances particular to the species, so no general rules would be expected.\n\nThe sperm and egg fuse in the process of fertilization to form a fertilized egg, or zygote. This undergoes a period of divisions to form a ball or sheet of similar cells called a blastula or blastoderm. These cell divisions are usually rapid with no growth so the daughter cells are half the size of the mother cell and the whole embryo stays about the same size. They are called cleavage divisions. Morphogenetic movements convert the cell mass into a three layered structure consisting of multicellular sheets called ectoderm, mesoderm and endoderm, which are known as germ layers. This is the process of gastrulation. During cleavage and gastrulation the first regional specification events occur. In addition to the formation of the three germ layers themselves, these often generate extraembryonic structures, such as the mammalian placenta, needed for support and nutrition of the embryo, and also establish differences of commitment along the anteroposterior axis (head, trunk and tail).\n\nRegional specification is initiated by the presence of cytoplasmic determinants in one part of the zygote. The cells that contain the determinant become a signaling center and emit an inducing factor. Because the inducing factor is produced in one place, diffuses away, and decays, it forms a concentration gradient, high near the source cells and low further away. The remaining cells of the embryo, which do not contain the determinant, are competent to respond to different concentrations by upregulating specific developmental control genes. This results in a series of zones becoming set up, arranged at progressively greater distance from the signaling center. In each zone a different combination of developmental control genes is upregulated. These genes encode transcription factors which upregulate new combinations of gene activity in each region. Among other functions, these transcription factors control expression of genes conferring specific adhesive and motility properties on the cells in which they are active. Because of these different morphogenetic properties, the cells of each germ layer move to form sheets such that the ectoderm ends up on the outside, mesoderm in the middle, and endoderm on the inside. Morphogenetic movements not only change the shape and structure of the embryo, but by bringing cell sheets into new spatial relationships they also make possible new phases of signaling and response between them.\n\nGrowth in embryos is mostly autonomous. For each territory of cells the growth rate is controlled by the combination of genes that are active. Free-living embryos do not grow in mass as they have no external food supply. But embryos fed by a placenta or extraembryonic yolk supply can grow very fast, and changes to relative growth rate between parts in these organisms help to produce the final overall anatomy.\n\nThe whole process needs to be coordinated in time and how this is controlled is not understood. There may be a master clock able to communicate with all parts of the embryo that controls the course of events, or timing may depend simply on local causal sequences of events.\n\nDevelopmental processes are very evident during the process of metamorphosis. This occurs in various types of animal. Well-known are the examples of the frog, which usually hatches as a tadpole and metamorphoses to an adult frog, and certain insects which hatch as a larva and then become remodeled to the adult form during a pupal stage.\n\nAll the developmental processes listed above occur during metamorphosis. Examples that have been especially well studied include tail loss and other changes in the tadpole of the frog \"Xenopus\", and the biology of the imaginal discs, which generate the adult body parts of the fly \"Drosophila melanogaster\".\n\nPlant development is the process by which structures originate and mature as a plant grows. It is studied in plant anatomy and plant physiology as well as plant morphology.\n\nPlants constantly produce new tissues and structures throughout their life from meristems located at the tips of organs, or between mature tissues. Thus, a living plant always has embryonic tissues. By contrast, an animal embryo will very early produce all of the body parts that it will ever have in its life. When the animal is born (or hatches from its egg), it has all its body parts and from that point will only grow larger and more mature.\n\nThe properties of organization seen in a plant are emergent properties which are more than the sum of the individual parts. \"The assembly of these tissues and functions into an integrated multicellular organism yields not only the characteristics of the separate parts and processes but also quite a new set of characteristics which would not have been predictable on the basis of examination of the separate parts.\"\n\nA vascular plant begins from a single celled zygote, formed by fertilisation of an egg cell by a sperm cell. From that point, it begins to divide to form a plant embryo through the process of embryogenesis. As this happens, the resulting cells will organize so that one end becomes the first root, while the other end forms the tip of the shoot. In seed plants, the embryo will develop one or more \"seed leaves\" (cotyledons). By the end of embryogenesis, the young plant will have all the parts necessary to begin in its life.\n\nOnce the embryo germinates from its seed or parent plant, it begins to produce additional organs (leaves, stems, and roots) through the process of organogenesis. New roots grow from root meristems located at the tip of the root, and new stems and leaves grow from shoot meristems located at the tip of the shoot. Branching occurs when small clumps of cells left behind by the meristem, and which have not yet undergone cellular differentiation to form a specialized tissue, begin to grow as the tip of a new root or shoot. Growth from any such meristem at the tip of a root or shoot is termed primary growth and results in the lengthening of that root or shoot. Secondary growth results in widening of a root or shoot from divisions of cells in a cambium.\n\nIn addition to growth by cell division, a plant may grow through cell elongation. This occurs when individual cells or groups of cells grow longer. Not all plant cells will grow to the same length. When cells on one side of a stem grow longer and faster than cells on the other side, the stem will bend to the side of the slower growing cells as a result. This directional growth can occur via a plant's response to a particular stimulus, such as light (phototropism), gravity (gravitropism), water, (hydrotropism), and physical contact (thigmotropism).\n\nPlant growth and development are mediated by specific plant hormones and plant growth regulators (PGRs) (Ross et al. 1983). Endogenous hormone levels are influenced by plant age, cold hardiness, dormancy, and other metabolic conditions; photoperiod, drought, temperature, and other external environmental conditions; and exogenous sources of PGRs, e.g., externally applied and of rhizospheric origin.\n\nPlants exhibit natural variation in their form and structure. While all organisms vary from individual to individual, plants exhibit an additional type of variation. Within a single individual, parts are repeated which may differ in form and structure from other similar parts. This variation is most easily seen in the leaves of a plant, though other organs such as stems and flowers may show similar variation. There are three primary causes of this variation: positional effects, environmental effects, and juvenility.\n\nTranscription factors and transcriptional regulatory networks play key roles in plant morphogenesis and their evolution. During plant landing, many novel transcription factor families emerged and are preferentially wired into the networks of multicellular development, reproduction, and organ development, contributing to more complex morphogenesis of land plants.\n\nMuch of developmental biology research in recent decades has focused on the use of a small number of model organisms. It has turned out that there is much conservation of developmental mechanisms across the animal kingdom. In early development different vertebrate species all use essentially the same inductive signals and the same genes encoding regional identity. Even invertebrates use a similar repertoire of signals and genes although the body parts formed are significantly different. Model organisms each have some particular experimental advantages which have enabled them to become popular among researchers. In one sense they are \"models\" for the whole animal kingdom, and in another sense they are \"models\" for human development, which is difficult to study directly for both ethical and practical reasons. Model organisms have been most useful for elucidating the broad nature of developmental mechanisms. The more detail is sought, the more they differ from each other and from humans.\n\nPlants:\n\nVertebrates:\n\nInvertebrates:\n\n\nAlso popular for some purposes have been sea urchins and ascidians. For studies of regeneration urodele amphibians such as the axolotl \"Ambystoma mexicanum\" are used, and also planarian worms such as \"Schmidtea mediterranea\". Organoids have also been demonstrated as an efficient model for development. Plant development has focused on the thale cress \"Arabidopsis thaliana\" as a model organism.\n\n\n"}
{"id": "8452", "url": "https://en.wikipedia.org/wiki?curid=8452", "title": "December 27", "text": "December 27\n\n\n\n"}
{"id": "8454", "url": "https://en.wikipedia.org/wiki?curid=8454", "title": "Double planet", "text": "Double planet\n\nIn astronomy, a double planet (also binary planet) is a binary system where both objects are of planetary mass. The term is not recognized by the International Astronomical Union (IAU) and is therefore not an official classification. At its 2006 General Assembly, the International Astronomical Union considered a proposal that Pluto and Charon be reclassified as a double planet, but the proposal was abandoned in favor of the current definition of planet. In promotional materials advertising the SMART-1 mission and pre-dating the IAU planet definition, the European Space Agency once referred to the Earth–Moon system as a double planet.\n\nSome binary asteroids with components of roughly equal mass are sometimes informally referred to as double minor planets. These include binary asteroids 69230 Hermes and 90 Antiope and binary Kuiper belt objects (KBOs) 79360 Sila–Nunam and .\n\nThere is debate as to what criteria should be used to distinguish \"double planet\" from a \"planet–moon system\". The following are considerations.\n\nA definition proposed in the Astronomical Journal calls for both bodies to individually satisfy an orbit-clearing criterion in order to be called a double planet.\n\nOne important consideration in defining \"double planet\" is the ratio of the masses of the two bodies. A mass ratio of 1 would indicate bodies of equal mass, and bodies with mass ratios closer to 1 are more attractive to label as \"doubles\". Using this definition, the satellites of Mars, Jupiter, Saturn, Uranus, and Neptune can all easily be excluded; they all have masses less than 0.00025 () of the planets around which they revolve. Some dwarf planets, too, have satellites substantially less massive than the dwarf planets themselves.\n\nThe most notable exception is the Pluto–Charon system. The Charon-to-Pluto mass ratio of 0.117 (≈ ) is close enough to 1 that Pluto and Charon have frequently been described by many scientists as \"double dwarf planets\" (\"double planets\" prior to the 2006 definition of \"planet\"). The International Astronomical Union (IAU) currently calls Charon a satellite of Pluto, but has explicitly expressed a willingness to reconsider the bodies double dwarf planets at a future time.\n\nThe Moon-to-Earth mass ratio of 0.01230 (≈ ) is also notably close to 1 when compared to all other satellite-to-planet ratios. Consequently, some scientists view the Earth-Moon system as a double planet as well, though this is a minority view. Eris's lone satellite, Dysnomia, has a radius somewhere around that of Eris; assuming similar densities (Dysnomia's compositional make-up may or may not differ substantially from Eris's), the mass ratio would be near , a value intermediate to the Moon–Earth and Charon–Pluto ratios.\n\nThe next criteria both attempt to answer the question \"How close to 1 must the mass ratio be?\"\n\nCurrently, the most commonly proposed definition for a double-planet system is one in which the barycenter, around which both bodies orbit, lies outside both bodies. Under this definition, Pluto and Charon are double dwarf planets, since they orbit a point clearly outside of Pluto, as visible in animations created from images of the \"New Horizons\" space probe in June 2015.\n\nUnder this definition, the Earth–Moon system is not currently a double planet; although the Moon is massive enough to cause the Earth to make a noticeable revolution around this center of mass, this point nevertheless lies well within Earth. However, the Moon migrates outward from Earth at a rate of approximately per year; in a few hundred million years, the Earth–Moon system's center of mass will lie outside Earth, which would make it a double-planet system.\n\nThe center of mass of the Jupiter–Sun system lies outside the surface of the Sun, though arguing that Jupiter is a double star is \"not\" analogous to arguing Pluto-Charon is a double dwarf planet. The problem is that Jupiter is not a star, or even a brown dwarf, and due to its low mass it is unable to achieve any form of fusion.\n\nIsaac Asimov suggested a distinction between planet–moon and double-planet structures based in part on what he called a \"tug-of-war\" value, which does not consider their relative sizes. This quantity is simply the ratio of the force exerted on the smaller body by the larger (primary) body to the force exerted on the smaller body by the Sun. This can be shown to equal\n\nwhere m is the mass of the primary (the larger body), m is the mass of the Sun, d is the distance between the smaller body and the Sun, and d is the distance between the smaller body and the primary. Note that the tug-of-war value does not rely on the mass of the satellite (the smaller body).\n\nThis formula actually reflects the relation of the gravitational effects on the smaller body from the larger body and from the Sun. The tug-of-war figure for Saturn's moon Titan is 380, which means that Saturn's hold on Titan is 380 times as strong as the Sun's hold on Titan. Titan's tug-of-war value may be compared with that of Saturn's moon Phoebe, which has a tug-of-war value of just 3.5. So Saturn's hold on Phoebe is only 3.5 times as strong as the Sun's hold on Phoebe.\n\nAsimov calculated tug-of-war values for several satellites of the planets. He showed that even the largest gas giant, Jupiter, had only a slightly better hold than the Sun on its outer captured satellites, some with tug-of-war values not much higher than one. In nearly every one of Asimov's calculations the tug-of-war value was found to be greater than one, so in those cases the Sun loses the tug-of-war with the planets. The one exception was Earth's Moon, where the Sun wins the tug-of-war with a value of 0.46, which means that Earth's hold on the Moon is less than half that of the Sun's. Asimov included this with his other arguments that Earth and the Moon should be considered a binary planet.\nSee the Path of Earth and Moon around Sun section in the \"Orbit of the Moon\" article for a more detailed explanation.\n\nNote that this definition of double planet depends on the pair's distance from the Sun. If the Earth–Moon system happened to orbit farther away from the Sun than it does now, then Earth would win the tug of war. For example, at the orbit of Mars, the Moon's tug-of-war value would be 1.05. Also, several tiny moons discovered since Asimov's proposal would qualify as double planets by this argument. Neptune's small outer moons Neso and Psamathe, for example, have tug-of-war values of 0.42 and 0.44, less than that of Earth's Moon. Yet their masses are tiny compared to Neptune's, with an estimated ratio of 1.5 () and 0.4 ().\n\nA final consideration is the way in which the two bodies came to form a system. Both the Earth-Moon and Pluto-Charon systems are thought to have been formed as a result of giant impacts: one body was impacted by a second body, resulting in a debris disk, and through accretion, either two new bodies formed or one new body formed, with the larger body remaining (but changed). However, a giant impact is not a sufficient condition for two bodies being \"double planets\" because such impacts can also produce tiny satellites, such as the four, small, outer satellites of Pluto.\n\nA now-abandoned hypothesis for the origin of the Moon was actually called the \"double-planet hypothesis\"; the idea was that the Earth and the Moon formed in the same region of the solar system's proto-planetary disk, forming a system under gravitational interaction. This idea, too, is a problematic condition for defining two bodies as \"double planets\" because planets can \"capture\" moons through gravitational interaction. For example, the moons of Mars (Phobos and Deimos) are thought to be asteroids captured long ago by Mars. Such a definition would also deem Neptune-Triton a double planet, since Triton was a Kuiper belt body the same size and of similar composition to Pluto, later captured by Neptune.\n\n\n"}
