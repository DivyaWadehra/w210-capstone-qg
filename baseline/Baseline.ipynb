{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/adityasarvaiya/Automatic_Question_Generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import math\n",
    "import string\n",
    "import operator\n",
    "import sys\n",
    "import collections\n",
    "from itertools import islice\n",
    "from nltk.parse import CoreNLPParser\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "#list(parser.parse('What is the airspeed of an unladen swallow ?'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('squad-dev-v1.1.json') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "data = pd.DataFrame.from_dict(data)\n",
    "df = pd.DataFrame.from_dict(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('squad.json') as json_file:  \n",
    "    annotated = json.load(json_file)\n",
    "annotated = pd.DataFrame.from_dict(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each topic\n",
    "ids = []\n",
    "topics = []\n",
    "paragraphs = []\n",
    "questions =[]\n",
    "answers = []\n",
    "answer_starts = []\n",
    "for a in annotated.index:\n",
    "    original_id = annotated.at[a,'original_id']\n",
    "    for i in range(48):\n",
    "        # for each paragraph\n",
    "        for j in range(len(df['data'][i]['paragraphs'])):\n",
    "            for k in range(len(df['data'][i]['paragraphs'][j]['qas'])):\n",
    "                id_num = df['data'][i]['paragraphs'][j]['qas'][k]['id']\n",
    "                if original_id==id_num:\n",
    "                    annotated.at[a, 'topic'] = df['data'][i]['title']\n",
    "                    annotated.at[a, 'paragraph'] = df['data'][i]['paragraphs'][j]['context']\n",
    "                    annotated.at[a, 'question'] = df['data'][i]['paragraphs'][j]['qas'][k]['question']\n",
    "                    annotated.at[a, 'answer'] = df['data'][i]['paragraphs'][j]['qas'][k]['answers'][0]['text']\n",
    "                    annotated.at[a, 'answer_start'] = df['data'][i]['paragraphs'][j]['qas'][k]['answers'][0]['answer_start']\n",
    "                    ids.append(id_num)\n",
    "skills = []\n",
    "sent_ind = []\n",
    "skill_count = []\n",
    "nonsense = []\n",
    "for row in annotated['annotations']:\n",
    "    skills.append(row[0]['skills'])\n",
    "    sent_ind.append(row[0]['sents_indices'])\n",
    "    skill_count.append(row[0]['skill_count'])\n",
    "    nonsense.append(row[0]['nonsense'])\n",
    "annotated['skills'] = skills\n",
    "annotated['sent_indices'] = sent_ind\n",
    "annotated['skill_count'] = skill_count\n",
    "annotated['nonsense'] = nonsense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Paragraph from SQUaD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Consultant pharmacy practice focuses more on medication regimen review (i.e. \"cognitive services\") than on actual dispensing of drugs. Consultant pharmacists most typically work in nursing homes, but are increasingly branching into other institutions and non-institutional settings. Traditionally consultant pharmacists were usually independent business owners, though in the United States many now work for several large pharmacy management companies (primarily Omnicare, Kindred Healthcare and PharMerica). This trend may be gradually reversing as consultant pharmacists begin to work directly with patients, primarily because many elderly people are now taking numerous medications but continue to live outside of institutional settings. Some community pharmacies employ consultant pharmacists and/or provide consulting services.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paragraph = annotated['paragraph'][21]\n",
    "test_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['consult', 'pharmaci', 'practic', 'focus', 'medic', 'regimen', 'review'], 1: ['e']}\n"
     ]
    }
   ],
   "source": [
    "def clean_sentences(paragraph):\n",
    "        \"\"\"Clean sentences, remove digit, punctuation, upper case to lower\n",
    "        Args: sentences: sentences to be cleaned\n",
    "        Return: sentences_processed: dict of cleaned sentences\n",
    "        \"\"\"\n",
    "        flag = 0\n",
    "        sentence_processed = {}\n",
    "\n",
    "        # Remove all punctuation except periods\n",
    "        punc = set(string.punctuation)\n",
    "        punc.remove('.')\n",
    "        # Remove all digits\n",
    "        paragraph = ''.join([x for x in paragraph if not x.isdigit()])\n",
    "        paragraph = ''.join([x for x in paragraph if x not in punc])\n",
    "        # Lowercase everything\n",
    "        paragraph = ''.join([x.lower() for x in paragraph])\n",
    "        # Split into words\n",
    "        paragraph = ' '.join(paragraph.split())\n",
    "\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        stemmer = nltk.stem.PorterStemmer()\n",
    "        tokenize = nltk.word_tokenize\n",
    "\n",
    "        for sentence in paragraph.split('.'):\n",
    "            sentence = sentence.strip()\n",
    "            sentence = [stemmer.stem(word) for word in tokenize(\n",
    "                sentence) if not word in stop_words]\n",
    "            if sentence:\n",
    "                sentence_processed[flag] = sentence\n",
    "                flag += 1\n",
    "\n",
    "        return sentence_processed\n",
    "cleaned_data = clean_sentences(test_paragraph)\n",
    "first2pairs = {k: cleaned_data[k] for k in list(cleaned_data)[:2]}\n",
    "print(first2pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'consult': 0.07792207792207792, 'pharmaci': 0.03896103896103896}\n"
     ]
    }
   ],
   "source": [
    "def word_distribution(sentence_processed):\n",
    "        \"\"\"Compute word probabilistic distribution which is calculated by \\\n",
    "        term frequency divided by total word count\"\"\"\n",
    "        word_distr = collections.defaultdict(int)\n",
    "        word_count = 0.0\n",
    "        # For each word in each sentence, count number of times each word appears as well as total words in sentence\n",
    "        for k in sentence_processed:\n",
    "            for word in sentence_processed[k]:\n",
    "                word_distr[word] += 1\n",
    "                word_count += 1\n",
    "\n",
    "        for word in word_distr:\n",
    "            word_distr[word] = word_distr[word] / word_count\n",
    "\n",
    "        return word_distr\n",
    "word_distr = word_distribution(cleaned_data)\n",
    "first2pairs = {k: word_distr[k] for k in list(word_distr)[:2]}\n",
    "print(first2pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 0.03607503607503607),\n",
       " (0, 0.02782931354359926),\n",
       " (3, 0.027154663518299885),\n",
       " (5, 0.0218417945690673),\n",
       " (4, 0.021251475796930347),\n",
       " (2, 0.015584415584415586),\n",
       " (1, 0.012987012987012988)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_weight(word_distribution, sentence_processed):\n",
    "        \"\"\"Compute weight with respect to sentences\n",
    "        Args:\n",
    "                word_distribution: probabilistic distribution of terms in document\n",
    "                sentence_processed: dict of processed sentences generated by clean_sentences\n",
    "        Return:\n",
    "                sentence_weight: dict of weight of each sentence\n",
    "        \"\"\"\n",
    "        sentence_weight = {}\n",
    "        # Iterate through each word in each sentence, if word distribution and sentence id are in dictionary, \n",
    "        # add to existing word distribution. Else, sentence weight for given sentence equals current word distribution\n",
    "        for sentence_id in sentence_processed:\n",
    "            for word in sentence_processed[sentence_id]:\n",
    "\n",
    "                if word_distribution[word] and sentence_id in sentence_weight:\n",
    "                    sentence_weight[sentence_id] += word_distribution[word]\n",
    "                else:\n",
    "                    sentence_weight[sentence_id] = word_distribution[word]\n",
    "        # Sentence weight equals sum of word distributions divided by length of cleaned sentence\n",
    "            sentence_weight[sentence_id] = sentence_weight[\n",
    "                sentence_id] / float(len(sentence_processed[sentence_id]))\n",
    "\n",
    "        sentence_weight = sorted(sentence_weight.items(\n",
    "        ), key=operator.itemgetter(1), reverse=True)\n",
    "        return sentence_weight\n",
    "sentence_weight = sentence_weight(word_distr,cleaned_data)\n",
    "# Sentences with higher weight are sentences with more frequently seen words\n",
    "sentence_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(6,\n",
       "              ' Some community pharmacies employ consultant pharmacists and/or provide consulting services')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topically_important_sentence(sentence_weight, paragraph):\n",
    "        \"\"\"Select topically import sentences\n",
    "        Args:\n",
    "                sentence_weight: dict, weight of sentences computed in sentence_weight\n",
    "                sentences: set of sentences\n",
    "        Return:\n",
    "                sentences_selected: dict, topically important sentences selected\n",
    "        \"\"\"\n",
    "        sentence_length = len(sentence_weight)\n",
    "        # how many sentences to retain\n",
    "        num_sentences_selected = math.ceil(float(0.05) * sentence_length)\n",
    "        num_sentences_selected = int(num_sentences_selected)\n",
    "        # key of selected sentences\n",
    "        sentences_selected_key = []\n",
    "        # dictionary of all sentences\n",
    "        sentences_dict = {}\n",
    "        flag = 0\n",
    "        # select num_sentences_selected # of sentences from list of sentence weights\n",
    "        for k, v in sentence_weight[0:num_sentences_selected]:\n",
    "            sentences_selected_key.append(k)\n",
    "        # Iterate through sentences in raw text and assign a id number\n",
    "        for sentence in paragraph.split('.'):\n",
    "            if sentence:\n",
    "                sentences_dict[flag] = sentence\n",
    "                flag += 1\n",
    "        sentences_selected = collections.OrderedDict()\n",
    "        \n",
    "        for key in sentences_selected_key:\n",
    "            sentences_selected[key] = sentences_dict[key]\n",
    "\n",
    "        return sentences_selected\n",
    "important_sentences = topically_important_sentence(sentence_weight, test_paragraph)\n",
    "# Gets the sentences with corresponding heavy sentence weights\n",
    "important_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gap Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Some community pharmacies employ consultant pharmacists and/or provide consulting services\n"
     ]
    }
   ],
   "source": [
    "selected_sent = important_sentences[6]\n",
    "print(selected_sent)\n",
    "select_sent_tree = parser.raw_parse(selected_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('ROOT', [Tree('S', [Tree('NP', [Tree('DT', ['Some']), Tree('NN', ['community']), Tree('NNS', ['pharmacies'])]), Tree('VP', [Tree('VP', [Tree('VBP', ['employ']), Tree('NP', [Tree('NN', ['consultant']), Tree('NNS', ['pharmacists'])])]), Tree('CC', ['and/or']), Tree('VP', [Tree('VBP', ['provide']), Tree('S', [Tree('VP', [Tree('VBG', ['consulting']), Tree('NP', [Tree('NNS', ['services'])])])])])])])])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(parser.raw_parse(selected_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gaps(sentence, tree):\n",
    "    \"\"\"Extract nouns, np, adjp from tree object\n",
    "    - Args:\n",
    "        sentence(str): current sentence\n",
    "        tree(list): list of Tree object, correspond to sentence\n",
    "    - - Returnss:\n",
    "        candidates(list of dict): candidate questions generated by this sentence,\n",
    "        e.g. [{'question':'the capital city of NL is _____', 'gap':'Amsterdam'}]\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    candidate = {}\n",
    "    entities = ['NP', 'ADJP']\n",
    "    entities = list(map(lambda x: list(x.subtrees(\n",
    "        filter=lambda x: x.label() in entities)), tree))[0]\n",
    "    print('entities: ' + str(entities))\n",
    "    if len(entities) > 7:\n",
    "        return False\n",
    "    else:\n",
    "        for entity in entities:\n",
    "            candidate_gap = str(' '.join(entity.leaves()))\n",
    "            print('candidate_gap: ' + str(candidate_gap))\n",
    "            sentence_copy = sentence\n",
    "            # replace sentence candidate_gap with ___\n",
    "            sentence_copy = sentence_copy.replace(candidate_gap, '_____')\n",
    "            candidate['Sentence'] = sentence\n",
    "            candidate['Question'] = sentence_copy\n",
    "            candidate['Answer'] = candidate_gap\n",
    "            if candidate_gap.strip() != sentence.strip():\n",
    "                candidates.append(candidate)\n",
    "            candidate = {}\n",
    "        return candidates\n",
    "\n",
    "def get_candidates(sentences):\n",
    "    \"\"\"Main function, prepare sentences, parse sentence, extract gap\n",
    "    - Args:\n",
    "        sentences(dict): topically important sentences\n",
    "    - - Returnss:\n",
    "            candidates(list of dict): list of dictionary, e.g.\n",
    "            [{'Sentence': .....,'Question':.....,'Answer':...},...]\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    for sentence_id, sentence in sentences.items():\n",
    "        tree = parser.raw_parse(sentence)\n",
    "        current_sentence_candidates = extract_gaps(\n",
    "            sentence, tree)  # build candidate questions\n",
    "        if current_sentence_candidates == False:\n",
    "            continue\n",
    "        candidates = candidates + current_sentence_candidates\n",
    "        print(\"building candidate question/answer pairs %d\" % len(candidates))\n",
    "        # clear current_sentence_candidates\n",
    "        current_sentence_candidates = []\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Fill In The Blank Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities: [Tree('NP', [Tree('DT', ['Some']), Tree('NN', ['community']), Tree('NNS', ['pharmacies'])]), Tree('NP', [Tree('NN', ['consultant']), Tree('NNS', ['pharmacists'])]), Tree('NP', [Tree('NNS', ['services'])])]\n",
      "candidate_gap: Some community pharmacies\n",
      "candidate_gap: consultant pharmacists\n",
      "candidate_gap: services\n",
      "building candidate question/answer pairs 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Sentence': ' Some community pharmacies employ consultant pharmacists and/or provide consulting services',\n",
       "  'Question': ' _____ employ consultant pharmacists and/or provide consulting services',\n",
       "  'Answer': 'Some community pharmacies'},\n",
       " {'Sentence': ' Some community pharmacies employ consultant pharmacists and/or provide consulting services',\n",
       "  'Question': ' Some community pharmacies employ _____ and/or provide consulting services',\n",
       "  'Answer': 'consultant pharmacists'},\n",
       " {'Sentence': ' Some community pharmacies employ consultant pharmacists and/or provide consulting services',\n",
       "  'Question': ' Some community pharmacies employ consultant pharmacists and/or provide consulting _____',\n",
       "  'Answer': 'services'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidates(important_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a member of the Scottish Parliamentary Corporate Body, the Presiding Officer is responsible for ensuring that the Parliament functions effectively and has the staff, property and resources it requires to operate. Convening the Parliamentary Bureau, which allocates time and sets the work agenda in the chamber, is another of the roles of the Presiding Officer. Under the Standing Orders of the Parliament the Bureau consists of the Presiding Officer and one representative from each political parties with five or more seats in the Parliament. Amongst the duties of the Bureau are to agree the timetable of business in the chamber, establish the number, remit and membership of parliamentary committees and regulate the passage of legislation (bills) through the Parliament. The Presiding Officer also represents the Scottish Parliament at home and abroad in an official capacity.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated['paragraph'][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sent = 'As a member of the Scottish Parliamentary Corporate Body, the Presiding Officer is responsible for ensuring that the Parliament functions effectively and has the staff, property and resources it requires to operate.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ner_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='ner')\n",
    "ne_tree = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sample_sent)))\n",
    "print(ne_tree)\n",
    "nlp = en_core_web_sm.load()\n",
    "sent_entities = nlp(sample_sent)\n",
    "print('There are ' + str(len(sent_entities.ents)) + ' entities in this paragraph.')\n",
    "labels = [x.label_ for x in sent_entities.ents]\n",
    "print(Counter(labels))\n",
    "items = [x.text for x in sent_entities.ents]\n",
    "print('These are the most frequent terms: ' + str(Counter(items).most_common(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract chunks from tagged sentence\n",
    "def tree_to_dict(tree):\n",
    "    \"\"\"\n",
    "    Aditya : Convert Tree to a usefull dict[] = <list> format\n",
    "    input : tree\n",
    "    output : dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    tree_dict = dict()\n",
    "    chunk_count = 0\n",
    "    for st in (tree):\n",
    "#         print('st: ' + str(st))\n",
    "#         print(st[0])\n",
    "        input_chunked = \"\"\n",
    "        if isinstance(st, nltk.Tree):\n",
    "#             print('st is tree')\n",
    "#             print(st.label())\n",
    "            input_chunked = \"\"\n",
    "            for d in range(len(st)):\n",
    "                # print \"input__chunked\"+input_chunked\n",
    "                if (d+1) == len(st):\n",
    "                    input_chunked = input_chunked + st[d][0]\n",
    "                else:\n",
    "                    input_chunked = input_chunked + st[d][0] + \" \"\n",
    "            chunk_count +=1\n",
    "\n",
    "            tree_dict[\"Chunk\"+str(chunk_count)] = input_chunked\n",
    "#     print(tree_dict)\n",
    "    return tree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_verb_noun(sent):\n",
    "        \"\"\"\n",
    "        Aditya : Takes the sentence and find the chunk (matches the regex)\n",
    "        input : sentence\n",
    "        output : chuncked short sentence\n",
    "        \"\"\"\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "       \n",
    "        chunkGram = 'Chunk: {<VB.?>+<NN.?>+}'\n",
    "#         r\"\"\"VN: {<VB.?>+<DT>?<JJ.?>?<NN.?>+}\"\"\" \n",
    "        # verb + optional determiner + optional adj + noun\n",
    "        #  NP: {<NNP>+} {<NN><NN>} # chunk sequences of proper nouns\n",
    "        chunkParser = nltk.RegexpParser(chunkGram)\n",
    "        chunked = chunkParser.parse(tagged)\n",
    "        #print('Tree: ' + str(chunked))\n",
    "        chunk = tree_to_dict(chunked)\n",
    "        #print('tree_to_dict: ' + str(chunk))\n",
    "        pattern_strings =[]\n",
    "        if len(chunk) != 0:\n",
    "            for chunk_no in range(len(chunk)):\n",
    "                pattern_string = chunk[\"Chunk\"+str(chunk_no+1)]\n",
    "                pattern_strings.append(pattern_string)\n",
    "                print(\"pattern_string  :  \", str(pattern_string))\n",
    "         \n",
    "        return pattern_strings\n",
    "#pattern_verb_noun(test_paragraph.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Consultant pharmacy practice focuses more on medication regimen review (i\n",
      "[]\n",
      "\n",
      "Sentence: e\n",
      "[]\n",
      "\n",
      "Sentence:  \"cognitive services\") than on actual dispensing of drugs\n",
      "[]\n",
      "\n",
      "Sentence:  Consultant pharmacists most typically work in nursing homes, but are increasingly branching into other institutions and non-institutional settings\n",
      "pattern_string  :   nursing homes\n",
      "[]\n",
      "\n",
      "Sentence:  Traditionally consultant pharmacists were usually independent business owners, though in the United States many now work for several large pharmacy management companies (primarily Omnicare, Kindred Healthcare and PharMerica)\n",
      "[]\n",
      "\n",
      "Sentence:  This trend may be gradually reversing as consultant pharmacists begin to work directly with patients, primarily because many elderly people are now taking numerous medications but continue to live outside of institutional settings\n",
      "[]\n",
      "\n",
      "Sentence:  Some community pharmacies employ consultant pharmacists and/or provide consulting services\n",
      "pattern_string  :   employ consultant pharmacists\n",
      "['What employ  some community pharmacies  and/or provide consulting services?', 'What employ  some community pharmacies  and/or provide consulting services?', 'What employ  some community pharmacies  and/or provide consulting services?']\n",
      "\n",
      "Sentence: \n",
      "Warning: parsing empty text\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "for sentence in test_paragraph.split('.'):\n",
    "    print('\\nSentence: ' + str(sentence))\n",
    "    pattern_strings = pattern_verb_noun(sentence)\n",
    "    tokenized = nltk.word_tokenize(sentence)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english')) \n",
    "    filtered = [w for w in tokenized if not w in stop_words]\n",
    "    #stemmed = [nltk.PorterStemmer.stem(w) for w in filtered]\n",
    "    tagged = nltk.pos_tag(filtered)\n",
    "#     ne_tree = nltk.ne_chunk(tagged)\n",
    "#      print('tree_dict: ' + str(ne_tree))\n",
    "#      print(tagged)\n",
    "    nouns = []\n",
    "    questions = []\n",
    "    for word,pos in tagged:\n",
    "        for pattern_string_no in range(len(pattern_strings)):\n",
    "            if (('NN' == pos) or ('NNP' == pos) or ('NNPS' == pos)):\n",
    "                nouns.append(word)\n",
    "                individual_words = pattern_strings[pattern_string_no].split()\n",
    "#                 print('individual words: ' + str(individual_words))\n",
    "                verb = [word for word in individual_words if word not in nouns]\n",
    "#                 print(\"Verb : \", str(verb))\n",
    "#                 print(\"pattern_strings[pattern_string_no] : \" , str(pattern_strings[pattern_string_no])) \n",
    "                full_ques = sentence.replace(str(pattern_strings[pattern_string_no]), '')\n",
    "                full_ques = \"What \" + str(verb[0]) + \" \" + str(full_ques).lower() + \"?\"\n",
    "                questions.append(full_ques)\n",
    "#                 print(\"word : \" + word + \"  pos : \" + pos)\n",
    "                flag=1\n",
    "    print(questions)\n",
    "               \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.ne_chunk() \n",
    "With the function nltk.ne_chunk(), we can recognize named entities using a classifier, the classifier adds category labels such as PERSON, ORGANIZATION, and GPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  In/IN\n",
      "  (ORGANIZATION Ancient/NNP Greece/NNP)\n",
      "  ,/,\n",
      "  (PERSON Diocles/NNP)\n",
      "  of/IN\n",
      "  (GPE Carystus/NNP)\n",
      "  (/(\n",
      "  4th/JJ\n",
      "  century/NN\n",
      "  BC/NNP\n",
      "  )/)\n",
      "  was/VBD\n",
      "  one/CD\n",
      "  of/IN\n",
      "  several/JJ\n",
      "  men/NNS\n",
      "  studying/VBG\n",
      "  the/DT\n",
      "  medicinal/JJ\n",
      "  properties/NNS\n",
      "  of/IN\n",
      "  plants/NNS)\n"
     ]
    }
   ],
   "source": [
    "test_sent = annotated['paragraph'][20].split('.')[0]\n",
    "ne_tree = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(test_sent)))\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 entities in this paragraph.\n",
      "Counter({'ORG': 4, 'CARDINAL': 2, 'NORP': 2, 'GPE': 1, 'ORDINAL': 1, 'PERSON': 1, 'LOC': 1, 'DATE': 1})\n",
      "These are the most frequent terms: [('Greece', 1), ('Diocles of Carystus', 1), ('4th', 1)]\n",
      "\n",
      "\n",
      "In Ancient Greece, Diocles of Carystus (4th century BC) was one of several men studying the medicinal properties of plants. He wrote several treatises on the topic. The Greek physician Pedanius Dioscorides is famous for writing a five volume book in his native Greek Περί ύλης ιατρικής in the 1st century AD. The Latin translation De Materia Medica (Concerning medical substances) was used a basis for many medieval texts, and was built upon by many middle eastern scientists during the Islamic Golden Age. The title coined the term materia medica.\n"
     ]
    }
   ],
   "source": [
    "#extracting named entities\n",
    "article = nlp(annotated['paragraph'][20])\n",
    "print('There are ' + str(len(article.ents)) + ' entities in this paragraph.')\n",
    "labels = [x.label_ for x in article.ents]\n",
    "print(Counter(labels))\n",
    "items = [x.text for x in article.ents]\n",
    "print('These are the most frequent terms: ' + str(Counter(items).most_common(3)))\n",
    "print('\\n')\n",
    "print(annotated['paragraph'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">In Ancient \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Greece\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Diocles of Carystus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    4th\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " century \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    BC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ") was \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of several men studying the medicinal properties of plants.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannahuang/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">He wrote several treatises on the topic.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">The \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Greek\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " physician \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pedanius Dioscorides\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is famous for writing a \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    five\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " volume book in his native \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Greek Περί\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " ύλης ιατρικής in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the 1st century AD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">The \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Latin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " translation \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    De Materia Medica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (Concerning medical substances) was used a basis for many medieval texts, and was built upon by many middle eastern scientists during \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Islamic Golden Age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joannahuang/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">The title coined the term materia medica.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [x for x in article.sents]\n",
    "for s in range(len(sentences)):\n",
    "    displacy.render(nlp(str(sentences[s])), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"441-0\" class=\"displacy\" width=\"2450\" height=\"437.0\" style=\"max-width: none; height: 437.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">In</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">Ancient</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">Greece,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Diocles</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Carystus (</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">4th</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">century</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">BC)</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">one</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">several</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1610\">men</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1610\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1730\">studying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1730\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1970\">medicinal</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1970\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2090\">properties</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2090\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2210\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2210\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2330\">plants.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2330\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-0\" stroke-width=\"2px\" d=\"M70,302.0 C70,2.0 1130.0,2.0 1130.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,304.0 L62,292.0 78,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-1\" stroke-width=\"2px\" d=\"M190,302.0 C190,242.0 270.0,242.0 270.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,304.0 L182,292.0 198,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-2\" stroke-width=\"2px\" d=\"M70,302.0 C70,182.0 275.0,182.0 275.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M275.0,304.0 L283.0,292.0 267.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-3\" stroke-width=\"2px\" d=\"M430,302.0 C430,62.0 1125.0,62.0 1125.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,304.0 L422,292.0 438,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-4\" stroke-width=\"2px\" d=\"M430,302.0 C430,242.0 510.0,242.0 510.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M510.0,304.0 L518.0,292.0 502.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-5\" stroke-width=\"2px\" d=\"M550,302.0 C550,242.0 630.0,242.0 630.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M630.0,304.0 L638.0,292.0 622.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-6\" stroke-width=\"2px\" d=\"M790,302.0 C790,242.0 870.0,242.0 870.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,304.0 L782,292.0 798,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-7\" stroke-width=\"2px\" d=\"M910,302.0 C910,242.0 990.0,242.0 990.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910,304.0 L902,292.0 918,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-8\" stroke-width=\"2px\" d=\"M670,302.0 C670,122.0 1000.0,122.0 1000.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1000.0,304.0 L1008.0,292.0 992.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-9\" stroke-width=\"2px\" d=\"M1150,302.0 C1150,242.0 1230.0,242.0 1230.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1230.0,304.0 L1238.0,292.0 1222.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-10\" stroke-width=\"2px\" d=\"M1270,302.0 C1270,242.0 1350.0,242.0 1350.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1350.0,304.0 L1358.0,292.0 1342.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-11\" stroke-width=\"2px\" d=\"M1510,302.0 C1510,242.0 1590.0,242.0 1590.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-11\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1510,304.0 L1502,292.0 1518,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-12\" stroke-width=\"2px\" d=\"M1390,302.0 C1390,182.0 1595.0,182.0 1595.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-12\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1595.0,304.0 L1603.0,292.0 1587.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-13\" stroke-width=\"2px\" d=\"M1630,302.0 C1630,242.0 1710.0,242.0 1710.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-13\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1710.0,304.0 L1718.0,292.0 1702.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-14\" stroke-width=\"2px\" d=\"M1870,302.0 C1870,182.0 2075.0,182.0 2075.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-14\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1870,304.0 L1862,292.0 1878,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-15\" stroke-width=\"2px\" d=\"M1990,302.0 C1990,242.0 2070.0,242.0 2070.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-15\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1990,304.0 L1982,292.0 1998,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-16\" stroke-width=\"2px\" d=\"M1750,302.0 C1750,122.0 2080.0,122.0 2080.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-16\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2080.0,304.0 L2088.0,292.0 2072.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-17\" stroke-width=\"2px\" d=\"M2110,302.0 C2110,242.0 2190.0,242.0 2190.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-17\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2190.0,304.0 L2198.0,292.0 2182.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-441-0-18\" stroke-width=\"2px\" d=\"M2230,302.0 C2230,242.0 2310.0,242.0 2310.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-441-0-18\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2310.0,304.0 L2318.0,292.0 2302.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(sentences[0])), style='dep', jupyter = True, options = {'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
