{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Don't forget to activate the appropriate environment!!\n",
    "https://ipython.readthedocs.io/en/stable/install/kernel_install.html#kernels-for-different-environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import ast\n",
    "import string\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "File structure:\n",
    "\n",
    "w210-literacy/\n",
    "├── GenerationQ/\n",
    "│   ├── flask/\n",
    "│   ├── model/\n",
    "│   └── README.md\n",
    "├── DrQA/\n",
    "│   ├── TODO\n",
    "│   └── TODO\n",
    "├── wikipedia_data/\n",
    "│   ├── wikipedia_dump/\n",
    "|       ├── AA/\n",
    "|           ├── wiki_00\n",
    "|           ├── wiki_01\n",
    "|           └── ... etc.\n",
    "|       └── ... etc.\n",
    "│   ├── wikipedia_squad/\n",
    "|       ├── AA/\n",
    "|           ├── wiki_00\n",
    "|           ├── wiki_01\n",
    "|           └── ... etc.\n",
    "|       └── ... etc.\n",
    "|   ├── labeled/\n",
    "|       ├── AA/\n",
    "|       └── ... etc.\n",
    "|   ├── unlabeled/\n",
    "|       ├── AA/\n",
    "|       └── ... etc.\n",
    "|   ├── questions/\n",
    "|       ├── AA/\n",
    "|       └── ... etc.\n",
    "|   ├── answers/\n",
    "|       ├── AA/\n",
    "|       └── ... etc.\n",
    "└── Wikipedia Article Sentence Selection.ipynb [this file!!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Data File Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assuming these directories are already created! If not, need to create them. \n",
    "data_files = './wikipedia_data'\n",
    "\n",
    "# This should contain folders of files with lists of Wikipedia articles\n",
    "wiki_dump = data_files + '/wikipedia_dump/'\n",
    "\n",
    "# These should all be empty\n",
    "wiki_squad = data_files + '/wikipedia_squad/'\n",
    "labeled_sents = data_files + '/labeled_sentences/'\n",
    "unlabeled_sents = data_files + '/unlabeled_sentences/'\n",
    "questions = data_files + '/questions/'\n",
    "answers = data_files + '/answers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wikipedia Article Pre-Processing\n",
    "To move our data through the pipeline and ensure that it is suitable for our app, we will format it like the SQuAD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in AA folder...\n",
      "Skipping article: List of German proverbs\n",
      "Skipping article: Floccinaucinihilipilification\n",
      "Completing files in AA folder... 5280 articles processed.\n",
      "\n",
      "Processing files in AB folder...\n",
      "Skipping article: History of Christianity\n",
      "Skipping article: Klaus Barbie\n",
      "Skipping article: Kyoto Protocol\n",
      "Skipping article: Index of philosophy articles (A–C)\n",
      "Completing files in AB folder... 3358 articles processed.\n",
      "\n",
      "Reformatting complete. Total 8638 articles processed for question generation.\n"
     ]
    }
   ],
   "source": [
    "# iterate through dump of wikipedia articles\n",
    "# grouped (by folder) into 100 files with lists of articles\n",
    "total_articles = 0\n",
    "\n",
    "for foldername in os.listdir(wiki_dump):\n",
    "    \n",
    "    input_subfolder = wiki_dump + foldername\n",
    "    output_subfolder = wiki_squad + foldername\n",
    "    os.mkdir(output_subfolder)\n",
    "\n",
    "    # these are not files, just folders\n",
    "    print(\"Processing files in {} folder...\".format(foldername))\n",
    "    num_articles = 0\n",
    "    \n",
    "    # each file represents several (variable #) wikipedia articles\n",
    "    for filename in os.listdir(input_subfolder):\n",
    "        #print(filename)\n",
    "        f = open(input_subfolder + '/' + filename)\n",
    "        \n",
    "        # each file of articles will become a separate .json of articles\n",
    "        # this helps if we run into issues, we can just discard a whole file and move on\n",
    "        \n",
    "        # set up json format for squad-like listing of articles\n",
    "        wikipedia_data_dict = {\"data\": [], \"version\" : 1.0}\n",
    "        \n",
    "        # save this to the 'wikipedia_squad' folder of correctly-formatted dicts of wikipedia articles\n",
    "        output_file = output_subfolder + '/' + filename\n",
    "       \n",
    "        # each line represents a different wikipedia article\n",
    "        # we will ignore the id and url for now, not needed\n",
    "        \n",
    "        for line in f:\n",
    "            line_dict = ast.literal_eval(line)\n",
    "            title = line_dict['title']\n",
    "                              \n",
    "            # for some reason, empty articles are included. They should be disregarded\n",
    "            try:\n",
    "                text = line_dict['text'].split(\"\\n\\n\",1)[1] # title is duplicated within text as well\n",
    "            except:\n",
    "                print(\"Skipping article:\",title)\n",
    "            else:\n",
    "                # arbitrary length, should eliminate articles like \"disambiguation\" articles, etc. \n",
    "                if len(text) > 1000: \n",
    "                    num_articles += 1\n",
    "                    # Break text up into paragraphs\n",
    "                    paras = text.split(\"\\n\\n\")\n",
    "\n",
    "                    context = [{'context': para.rstrip(), 'qas' : []} for para in paras]\n",
    "\n",
    "                    wikipedia_data_dict['data'].append({'title' : title, 'paragraphs' : context})\n",
    "                    \n",
    "        # in case we don't have any articles in the file to add\n",
    "        if (wikipedia_data_dict['data']): \n",
    "            with open(output_file, 'w') as outfile:  \n",
    "                json.dump(wikipedia_data_dict, outfile)\n",
    "            \n",
    "    total_articles += num_articles\n",
    "    print(\"Completing files in {} folder... {} articles processed.\\n\".format(foldername,num_articles))\n",
    "\n",
    "print(\"Reformatting complete. Total {} articles processed for question generation.\".format(total_articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentence Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Clean sentences, stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sents_and_weights(d,paragraphs):\n",
    "        \"\"\"Clean sentences, remove digit, punctuation, upper case to lower\n",
    "        Args: paragraphs = list of dicts with contexts\n",
    "        Return: sentences_processed: dict of cleaned sentences. key = number of sentence; value = list of stemmed words.\n",
    "        \"\"\"\n",
    "        labeled_sentences = {}\n",
    "        stemmed_sentences = {}\n",
    "        \n",
    "        # this needs to be a default dict so it returns 0 if word not found \n",
    "        word_dict = defaultdict(int)\n",
    "        word_distr = defaultdict(int)\n",
    "\n",
    "        # initialize for stemming\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        stemmer = nltk.stem.PorterStemmer()\n",
    "        tokenize = nltk.word_tokenize\n",
    "\n",
    "        def stem_and_add(wd):\n",
    "            word_dict[wd] += 1\n",
    "            word_dict['total_count'] += 1\n",
    "            return stemmer.stem(wd)\n",
    "        \n",
    "        # need to go through each 'paragraph' (context) to gather info about sentences\n",
    "        for i,context in enumerate(paragraphs):\n",
    "\n",
    "            # split paragraph into sentences, make sure to keep digits, etc. together\n",
    "            sentences = context['context'].split('. ') #last one still has a period at the end\n",
    "\n",
    "            for j,sentence in enumerate(sentences):\n",
    "                # save list of unprocessed sentences for later\n",
    "                labeled_sentences[(d,i,j)] = sentence\n",
    "                            \n",
    "                # Remove all digits\n",
    "                sentence = ''.join([x for x in sentence if not x.isdigit()])\n",
    "                # Remove all punctuation (OK to include periods since it's been split)\n",
    "                sentence = ''.join([x for x in sentence if x not in string.punctuation])\n",
    "                \n",
    "                # Lowercase everything\n",
    "                sentence = sentence.strip()\n",
    "                sentence = sentence.lower()\n",
    "                \n",
    "                # Split into words & rejoin (remove extra spaces)\n",
    "                sentence = ' '.join(sentence.split())\n",
    "                \n",
    "                tokenized_stemmed_sent = [stem_and_add(word) for word in nltk.tokenize.word_tokenize(sentence) \n",
    "                                          if not word in stop_words]\n",
    "                \n",
    "                # keep track of tokenized for calculating sentence weight in next step\n",
    "                stemmed_sentences[(d,i,j)] = tokenized_stemmed_sent\n",
    "                \n",
    "                # update our word dictionary to be relative frequencies rather than absolute values\n",
    "                for word, ct in word_dict.items():\n",
    "                    # but keep our total count, we may want that later (not sure)\n",
    "                    if not word == 'total_count':\n",
    "                        word_distr[word] = word_dict[word] / word_dict['total_count']\n",
    "                \n",
    "        #print(\"article length:\",word_dict['total_count'])\n",
    "        #print(\"word dict:\",word_distr)\n",
    "\n",
    "        return labeled_sentences,stemmed_sentences,word_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_sent_weight(word_dist, stemmed_sents):\n",
    "        \"\"\"Compute weight with respect to sentences\n",
    "        Args:\n",
    "                word_distribution: dict with word: weight\n",
    "                stemmed_sents: list with \n",
    "        Return:\n",
    "                sentence_weight: dict of weight of each sentence. key = sentence #, value = weight\n",
    "        \"\"\"\n",
    "        sentences_weight = {}\n",
    "        # Iterate through each word in each sentence, if word distribution and sentence id are in dictionary, \n",
    "        # add to existing word distribution. Else, sentence weight for given sentence equals current word distribution\n",
    "          \n",
    "        for key, words in stemmed_sents.items():\n",
    "            #print(words)\n",
    "            # Sentence weight equals sum of word distributions divided by length of cleaned sentence\n",
    "            if len(words) == 0:\n",
    "                weight = 0\n",
    "            else:\n",
    "                weight = sum([word_dist[word] for word in words]) / len(words)\n",
    "            \n",
    "            sentences_weight[key] = weight\n",
    "            \n",
    "        sentences_weight = sorted(sentences_weight.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        #print('sentence weight: ',sentences_weight)\n",
    "\n",
    "        return sentences_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topically_important_sentence(sentences_weight, labeled_sentences):\n",
    "        \"\"\"Select topically import sentences\n",
    "        Args:\n",
    "                sentence_weight: list of tuples, (sentence_num, sentence_weight) computed in sentence_weight\n",
    "                paragraph: set of sentences\n",
    "        Return:\n",
    "                sentences_selected: dict, topically important sentences selected\n",
    "        \"\"\"\n",
    "        final_sentences = {}\n",
    "        \n",
    "        total_sentences = len(sentences_weight)\n",
    "        # how many sentences to retain\n",
    "        num_sentences_selected = math.ceil(float(0.05) * total_sentences)\n",
    "        #print('num sentences for this passage:',num_sentences_selected)\n",
    "        \n",
    "        # key of selected sentences (# order of sentence in paragraph)\n",
    "        #sentences_selected_key = []\n",
    "        \n",
    "        # dictionary of all sentences \n",
    "        sentences_dict = {}\n",
    "        flag = 0\n",
    "        \n",
    "        # select num_sentences_selected # of sentences from list of sentence weights\n",
    "        #print(sentence_weight[0])\n",
    "        selected_keys = [k for k,v in sentence_weight[0:num_sentences_selected]]\n",
    "        \n",
    "        #print(\"selected sentence(s):\",selected_keys)\n",
    "\n",
    "\n",
    "        for sent_key in selected_keys:\n",
    "            pre_processed_sentence = labeled_sentences[sent_key]\n",
    "            \n",
    "            processed_sentence = pre_processed_sentence.lower() #lowercase\n",
    "            processed_sentence = processed_sentence.replace('[[','')\n",
    "            processed_sentence = processed_sentence.replace(']]','')\n",
    "            processed_sentence = processed_sentence.replace(']','')\n",
    "            processed_sentence = processed_sentence.replace('[','')\n",
    "            processed_sentence = re.sub('(?<!\\d)([.,!?()])(?<!\\d)', r' \\1 ', processed_sentence)\n",
    "            processed_sentence = re.sub(r'\\(','-lrb- ',processed_sentence) # replace left parens, add space after\n",
    "            processed_sentence = re.sub(r'\\)',' -rrb-',processed_sentence) # replace left parens, add space after\n",
    "            processed_sentence = re.sub(r'\\([^)]*\\)', '',processed_sentence) #replace brackets in links\n",
    "            processed_sentence = re.sub('(?<=\\s)\\\"','`` ',processed_sentence) # replace first double quotes with ``\n",
    "            processed_sentence = re.sub(r'\\\"', \" ''\", processed_sentence) # replace second double quote with two single quotes ''\n",
    "\n",
    "            #print(processed_sentence)\n",
    "\n",
    "            final_sentences[sent_key] = processed_sentence\n",
    "            \n",
    "        return final_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing sentence selection for files in AA folder...\n",
      "Skipping article: Father Christmas\n",
      "Skipping article: Abracadabra\n",
      "Skipping article: Daoism–Taoism romanization issue\n",
      "Skipping article: Dolmen\n",
      "Skipping article: Dictionary\n",
      "Skipping article: Equatorial Guinea\n",
      "Skipping article: Dative case\n",
      "Skipping article: Arabic alphabet\n",
      "Skipping article: Capitalism\n",
      "Skipping article: Cognitive science\n",
      "Skipping article: Dacoity\n",
      "Skipping article: Beastie Boys\n",
      "Skipping article: Gossip\n",
      "Skipping article: Cognate\n",
      "Skipping article: Gnome\n",
      "Skipping article: Ghost\n",
      "Skipping article: Estampie\n",
      "Skipping article: Faroese language\n",
      "Skipping article: First aid\n",
      "Skipping article: N,N-Dimethyltryptamine\n",
      "Completing files in AA folder... 5260 articles processed, 20 articles skipped.\n",
      "\n",
      "Completing sentence selection for files in AB folder...\n",
      "Skipping article: Mummy\n",
      "Skipping article: Mode (music)\n",
      "Skipping article: Hogshead\n",
      "Skipping article: Kludge\n",
      "Skipping article: Internet slang\n",
      "Skipping article: GIF\n",
      "Skipping article: Goddess\n",
      "Skipping article: Lammas\n",
      "Completing files in AB folder... 3350 articles processed, 8 articles skipped.\n",
      "\n",
      "Reformatting complete. Total 8638 articles processed, 28 skipped for question generation.\n"
     ]
    }
   ],
   "source": [
    "total_skipped = 0\n",
    "total_selected = 0\n",
    "\n",
    "for foldername in os.listdir(wiki_squad):\n",
    "    \n",
    "    input_subfolder = wiki_squad + foldername\n",
    "    output_subfolder_labeled = labeled_sents + foldername\n",
    "    output_subfolder_unlabeled = unlabeled_sents + foldername\n",
    "\n",
    "    os.mkdir(output_subfolder_labeled)\n",
    "    os.mkdir(output_subfolder_unlabeled)\n",
    "\n",
    "    # these are not files, just folders\n",
    "    print(\"Completing sentence selection for files in {} folder...\".format(foldername))\n",
    "    \n",
    "    num_skipped = 0\n",
    "    num_selected = 0\n",
    "    \n",
    "    # each file represents several (variable #) wikipedia articles\n",
    "    for filename in os.listdir(input_subfolder):\n",
    "        #print(filename)\n",
    "        input_file = input_subfolder + '/' + filename\n",
    "              \n",
    "        # save this to the 'wikipedia_squad' folder of correctly-formatted dicts of wikipedia articles\n",
    "        output_file_labeled = open(output_subfolder_labeled + '/' + filename, \"w\")\n",
    "        output_file_unlabeled = open(output_subfolder_unlabeled + '/' + filename, \"w\")\n",
    "\n",
    "        with open(input_file) as json_file:  \n",
    "            data = json.load(json_file)\n",
    "\n",
    "        data = pd.DataFrame.from_dict(data)\n",
    "        df = data['data']\n",
    "\n",
    "        # for each article in the file\n",
    "        for row,value in df.iteritems():\n",
    "            # here is where we clean and stem words, build word distribution\n",
    "            try:\n",
    "                labeled_sentences, stemmed_sentences, word_distribution = sents_and_weights(row,value['paragraphs'])\n",
    "\n",
    "                # use this word distribution to get weights for each sentence and calculate most important sentences \n",
    "                sentence_weight = calc_sent_weight(word_distribution,stemmed_sentences)\n",
    "\n",
    "                # pull out most important sentences\n",
    "                # and keep track of where they came from: (doc #, context #, sentence #)\n",
    "                chosen_sentences = topically_important_sentence(sentence_weight,labeled_sentences)\n",
    "            except: \n",
    "                num_skipped += 1\n",
    "                print(\"Skipping article:\",value['title'])\n",
    "            else:\n",
    "                num_selected += 1\n",
    "                for sents in chosen_sentences.items():\n",
    "\n",
    "                    #save selected sentences directly to file, for onmt model\n",
    "                    output_file_unlabeled.write(str(sents[1])+'\\n')\n",
    "                    # keep track of their locations, though\n",
    "                    output_file_labeled.write(str(sents)+'\\n') \n",
    "                    \n",
    "    total_skipped += num_skipped\n",
    "    total_selected += num_selected\n",
    "    print(\"Completing files in {} folder... {} articles processed, {} articles skipped.\\n\".format(foldername,num_selected,num_skipped))\n",
    "\n",
    "print(\"Sentence selection complete. Total {} articles processed, {} skipped for question generation.\".format(total_articles, total_skipped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference: https://github.com/drewserles/GenerationQ. Assuming training has already been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't forget to switch kernels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing question generation for files in AA folder...\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "PRED AVG SCORE: -0.6679, PRED PPL: 1.9502\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "PRED AVG SCORE: -0.6700, PRED PPL: 1.9541\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 7, in <module>\n",
      "    from onmt.utils.logging import init_logger\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/__init__.py\", line 4, in <module>\n",
      "    import onmt.inputters\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/__init__.py\", line 6, in <module>\n",
      "    from onmt.inputters.inputter import collect_feature_vocabs, make_features, \\\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/inputter.py\", line 16, in <module>\n",
      "    from onmt.inputters.image_dataset import ImageDataset\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/image_dataset.py\", line 11, in <module>\n",
      "    import cv2\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "generationq_dir = '~/GenerationQ/model'\n",
    "model = generationq_dir + '/trained/600rnn_step_14000.pt' # update depending on which model has lowest perplexity\n",
    "\n",
    "for foldername in os.listdir(unlabeled_sents):\n",
    "    \n",
    "    input_subfolder = unlabeled_sents + foldername\n",
    "    output_subfolder = questions + foldername\n",
    "    \n",
    "    #os.mkdir(output_subfolder)\n",
    "\n",
    "    # these are not files, just folders\n",
    "    print(\"Completing question generation for files in {} folder...\".format(foldername))\n",
    "        \n",
    "    # each file represents several (variable #) wikipedia articles\n",
    "    for filename in os.listdir(input_subfolder):\n",
    "        \n",
    "        # input file is unlabeled sentence\n",
    "        input_file = input_subfolder + '/' + filename\n",
    "              \n",
    "        # save list of questions\n",
    "        output_file = output_subfolder + '/' + filename\n",
    "        \n",
    "        !python $generationq_dir/test.py -model $model -src $input_file -output $output_file \\\n",
    "        -replace_unk -beam_size 3 -gpu 0 -batch_size 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating questions for file #0\n",
      "./wikipedia_squad/AA/test_sents_qg_00\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "PRED AVG SCORE: -0.6408, PRED PPL: 1.8980\n",
      "generating questions for file #1\n",
      "./wikipedia_squad/AA/test_sents_qg_01\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "generating questions for file #2\n",
      "./wikipedia_squad/AA/test_sents_qg_02\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "generating questions for file #3\n",
      "./wikipedia_squad/AA/test_sents_qg_03\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "generating questions for file #4\n",
      "./wikipedia_squad/AA/test_sents_qg_04\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "generating questions for file #5\n",
      "./wikipedia_squad/AA/test_sents_qg_05\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "generating questions for file #6\n",
      "./wikipedia_squad/AA/test_sents_qg_06\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "generating questions for file #7\n",
      "./wikipedia_squad/AA/test_sents_qg_07\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "generating questions for file #8\n",
      "./wikipedia_squad/AA/test_sents_qg_08\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n",
      "generating questions for file #9\n",
      "./wikipedia_squad/AA/test_sents_qg_09\n",
      "/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py:542: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(a, requires_grad=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 36, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/test.py\", line 24, in main\n",
      "    attn_debug=opt.attn_debug)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/translate/translator.py\", line 229, in translate\n",
      "    for batch in data_iter:\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/iterator.py\", line 157, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/batch.py\", line 34, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 201, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/home/julia_buffinton/anaconda3/envs/pytorch-env/lib/python2.7/site-packages/torchtext/data/field.py\", line 321, in numericalize\n",
      "    arr = self.postprocessing(arr, None)\n",
      "  File \"/home/julia_buffinton/GenerationQ/model/onmt/inputters/text_dataset.py\", line 235, in make_src\n",
      "    src_vocab_size = max([t.max() for t in data]) + 1\n",
      "RuntimeError: invalid argument 1: tensor must have one dimension at /opt/conda/conda-bld/pytorch_1549617926868/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:590\n"
     ]
    }
   ],
   "source": [
    "# update as needed, depending on which model has lowest perplexity\n",
    "generationq_model = '~/GenerationQ/model/trained/600rnn_step_14000.pt'\n",
    "\n",
    "for c in string.ascii_uppercase[:end_letter]:\n",
    "    \n",
    "    output_dir = wiki_output_file_dir + c\n",
    "\n",
    "    for i in range(num_files): \n",
    "    \n",
    "        wiki_squad_file = output_dir + '/wiki_squad_' + '%02d' % i + '.json'\n",
    "        sentences_onmt = output_dir + '/test_sents_qg_' + '%02d' % i\n",
    "        sentences_labeled = output_dir + '/test_sents_labeled_' + '%02d' % i\n",
    "        \n",
    "        question_output = output_dir + '/test_questions_' + '%02d' % i + '.txt'\n",
    "    \n",
    "        print \"generating questions for file #\" + str(i)\n",
    "        print sentences_onmt\n",
    "    \n",
    "        !python $generationq_dir/test.py -model $generationq_model -src $sentences_onmt -output $question_output \\\n",
    "        -replace_unk -beam_size 3 -gpu 0 -batch_size 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Remove \"problem\" files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.3 Label questions, add back to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each letter of the alphabet\n",
    "for c in string.ascii_uppercase[:end_letter]:\n",
    "\n",
    "    output_dir = wiki_output_file_dir + c\n",
    "\n",
    "    # for each file in there (total: 100)\n",
    "    for i in range(num_files): \n",
    "        \n",
    "        sentences_labeled = output_dir + '/test_sents_labeled_' + '%02d' % i\n",
    "\n",
    "        wiki_squad_file = output_dir + '/wiki_squad_' + '%02d' % i + '.json'\n",
    "        \n",
    "        #question_output = output_dir + '/test_sents_qg_' + '%02d' % i # THIS IS JUST FOR TESTING!!! \n",
    "        question_output = output_dir + '/test_questions_' + '%02d' % i + '.txt' # This is final!!\n",
    "        question_output_qs = output_dir + '/test_questions_q_' + '%02d' % i + '.txt'\n",
    "        \n",
    "        with open(question_output) as f:\n",
    "            pred_questions = f.read().splitlines()    \n",
    "            pred_questions = pred_questions[::2] # start with the 1st line\n",
    "            \n",
    "        with open(question_output_qs, 'w') as f:\n",
    "            for item in pred_questions:\n",
    "                f.write(\"%s\" % item) # removed newline character after this?\n",
    "            \n",
    "        with open(wiki_squad_file) as json_file:  \n",
    "            data = json.load(json_file)\n",
    "\n",
    "        #print(type(data))\n",
    "        #data = pd.DataFrame.from_dict(data)\n",
    "        wiki_df = data['data']\n",
    "        #print(type(wiki_df))\n",
    "\n",
    "        with open(question_output_qs) as f1:\n",
    "\n",
    "            with open(sentences_labeled) as f2:\n",
    "                for line_q,line_s in zip(f1,f2):\n",
    "                    \n",
    "                    line_tuple = eval(line_s)\n",
    "                    nums = line_tuple[0]\n",
    "                    #print(nums)\n",
    "                    #sent = line_tuple[1]\n",
    "\n",
    "                    doc = wiki_df[nums[0]] # pull the whole document\n",
    "                    context = doc[\"paragraphs\"][nums[1]]\n",
    "\n",
    "                    context['qas'].append({\"question\": line_q, \"answers\": [], \"id\": str(nums)})\n",
    "            \n",
    "        with open(wiki_squad_file, 'w') as outfile:  \n",
    "            json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Answer Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Filter out paragraphs missing questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_file = './sample_data/AA/wiki_squad_00.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering paragraphs for files in AA folder...\n",
      "Anarchism\n",
      "86\n",
      "17\n",
      "Autism\n",
      "70\n",
      "12\n",
      "Albedo\n",
      "41\n",
      "5\n",
      "A\n",
      "20\n",
      "2\n",
      "Alabama\n",
      "147\n",
      "21\n",
      "Achilles\n",
      "60\n",
      "11\n",
      "Abraham Lincoln\n",
      "148\n",
      "26\n",
      "Aristotle\n",
      "91\n",
      "12\n",
      "An American in Paris\n",
      "16\n",
      "4\n",
      "Academy Awards\n",
      "70\n",
      "12\n",
      "Actrius\n",
      "5\n",
      "1\n",
      "Animalia (book)\n",
      "11\n",
      "2\n",
      "International Atomic Time\n",
      "14\n",
      "3\n",
      "Altruism\n",
      "56\n",
      "8\n",
      "Ayn Rand\n",
      "55\n",
      "13\n",
      "Allan Dwan\n",
      "11\n",
      "2\n",
      "Algeria\n",
      "138\n",
      "19\n",
      "List of Atlas Shrugged characters\n",
      "18\n",
      "3\n",
      "Anthropology\n",
      "82\n",
      "13\n",
      "Agricultural science\n",
      "11\n",
      "1\n",
      "Alchemy\n",
      "75\n",
      "15\n",
      "Astronomer\n",
      "10\n",
      "2\n",
      "ASCII\n",
      "60\n",
      "9\n",
      "Animation\n",
      "47\n",
      "6\n",
      "Apollo\n",
      "178\n",
      "28\n",
      "Andre Agassi\n",
      "82\n",
      "18\n",
      "Austroasiatic languages\n",
      "41\n",
      "5\n",
      "Afroasiatic languages\n",
      "37\n",
      "4\n",
      "Andorra\n",
      "105\n",
      "14\n",
      "Arithmetic mean\n",
      "19\n",
      "3\n",
      "American Football Conference\n",
      "12\n",
      "3\n",
      "Animal Farm\n",
      "53\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for foldername in os.listdir('./sample_data/'):\n",
    "    \n",
    "    input_subfolder = './sample_data/' + foldername\n",
    "    #output_subfolder = questions + foldername\n",
    "    \n",
    "    #os.mkdir(output_subfolder)\n",
    "\n",
    "    # these are not files, just folders\n",
    "    print(\"Filtering paragraphs for files in {} folder...\".format(foldername))\n",
    "        \n",
    "    # each file represents several (variable #) wikipedia articles\n",
    "    for filename in os.listdir(input_subfolder):\n",
    "        #print(filename)\n",
    "        \n",
    "        input_file = input_subfolder + '/' + filename\n",
    "        \n",
    "        with open(input_file) as json_file:  \n",
    "            data = json.load(json_file)\n",
    "\n",
    "        wiki_df = data['data']\n",
    "        \n",
    "        #output_file = output_subfolder + '/' + filename\n",
    "        \n",
    "        for i,v in enumerate(wiki_df):\n",
    "            #print(v['title'])\n",
    "            #print(len(v['paragraphs']))\n",
    "            v['paragraphs'] = [ para for para in v['paragraphs'] if para['qas'] ]\n",
    "            #print(len(v['paragraphs']))\n",
    "            \n",
    "        with open(input_subfolder + '/' + 'wiki_squad_00_abbr.json', 'w') as outfile:  \n",
    "            json.dump(data, outfile)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 DrQA question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't forget to use the right kernel!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_file_abbr = './sample_data/AA/wiki_squad_00_abbr.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"../DrQA/scripts/pipeline/predict.py\", line 16, in <module>\r\n",
      "    from drqa import pipeline\r\n",
      "ImportError: No module named drqa\r\n"
     ]
    }
   ],
   "source": [
    "!python ../DrQA/scripts/pipeline/predict.py $sample_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add answers back to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
