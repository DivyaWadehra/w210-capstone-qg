{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The conda.compat module is deprecated and will be removed in a future release.\n",
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.6.11\n",
      "  latest version: 4.6.12\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/sdatta/anaconda3/envs/py36\n",
      "\n",
      "  added / updated specs:\n",
      "    - seaborn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    patsy-0.5.1                |           py36_0         380 KB  anaconda\n",
      "    seaborn-0.9.0              |           py36_0         379 KB  anaconda\n",
      "    statsmodels-0.9.0          |   py36h035aef0_0         9.0 MB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  patsy              anaconda/linux-64::patsy-0.5.1-py36_0\n",
      "  seaborn            anaconda/linux-64::seaborn-0.9.0-py36_0\n",
      "  statsmodels        anaconda/linux-64::statsmodels-0.9.0-py36h035aef0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "seaborn-0.9.0        | 379 KB    | ##################################### | 100% \n",
      "patsy-0.5.1          | 380 KB    | ##################################### | 100% \n",
      "statsmodels-0.9.0    | 9.0 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# conda install -c anaconda pandas\n",
    "# conda install -c anaconda nltk\n",
    "# conda install -c conda-forge matplotlib\n",
    "# conda install -c conda-forge spacy\n",
    "# conda install -c anaconda scikit-learn spacy download en_core_web_sm\n",
    "# conda install -c conda-forge spacy download en_core_web_sm\n",
    "# conda install -c conda-forge spacy-model-en_core_web_sm\n",
    "# conda install pip\n",
    "#!pip install pywsd\n",
    "# import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('words')\n",
    "#!conda install -c anaconda seaborn --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import ast\n",
    "import string\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import math\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import walk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# from lxml import html\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import nltk\n",
    "#from  nltk.parse.corenlpnltk.pa  import CoreNLPParser\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import spacy    \n",
    "from spacy import displacy\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy\n",
    "#conda install -c conda-forge spacy-model-en_core_web_sm\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import words as nltk_words\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "#nltk.download('wordnet')\n",
    "ps = PorterStemmer()\n",
    "stopWords = set(stopwords.words('english'))\n",
    "stopWords.update(['[',']','the','no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywsd.lesk import simple_lesk\n",
    "#from pywsd import disambiguate\n",
    "from pywsd.similarity import max_similarity as maxsim\n",
    "from pywsd.lesk import cached_signatures\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywsd in /home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages (1.1.7)\n",
      "Requirement already satisfied: pandas in /home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages (from pywsd) (0.24.2)\n",
      "Requirement already satisfied: nltk in /home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages (from pywsd) (3.4)\n",
      "Requirement already satisfied: numpy in /home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages (from pywsd) (1.16.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages (from pandas->pywsd) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages (from pandas->pywsd) (2018.9)\n",
      "Requirement already satisfied: six in /home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages (from nltk->pywsd) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in /home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages (from nltk->pywsd) (3.4.0.3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT_TOKEN_SIZE=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir=\"./input\"\n",
    "out_dir=\"./output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = '/home/sdatta/data/wikipedia_squad'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB/wiki_16\n",
      "AB/wiki_39\n",
      "AB/wiki_47\n",
      "AB/wiki_61\n",
      "AB/wiki_90\n",
      "AB/wiki_15\n",
      "AB/wiki_24\n",
      "AB/wiki_50\n",
      "AB/wiki_57\n",
      "AB/wiki_28\n",
      "AB/wiki_79\n",
      "AB/wiki_96\n",
      "AB/wiki_75\n",
      "AB/wiki_32\n",
      "AB/wiki_87\n",
      "AB/wiki_30\n",
      "AB/wiki_95\n",
      "AB/wiki_31\n",
      "AB/wiki_01\n",
      "AB/wiki_63\n",
      "AB/wiki_56\n",
      "AB/wiki_76\n",
      "AB/wiki_99\n",
      "AB/wiki_67\n",
      "AB/wiki_33\n",
      "AB/wiki_06\n",
      "AB/wiki_72\n",
      "AB/wiki_80\n",
      "AB/wiki_59\n",
      "AB/wiki_14\n",
      "AB/wiki_42\n",
      "AB/wiki_02\n",
      "AB/wiki_19\n",
      "AB/wiki_65\n",
      "AB/wiki_81\n",
      "AB/wiki_55\n",
      "AB/wiki_74\n",
      "AB/wiki_13\n",
      "AB/wiki_34\n",
      "AB/wiki_84\n",
      "AB/wiki_23\n",
      "AB/wiki_36\n",
      "AB/wiki_46\n",
      "AB/wiki_68\n",
      "AB/wiki_51\n",
      "AB/wiki_04\n",
      "AB/wiki_00\n",
      "AB/wiki_66\n",
      "AB/wiki_77\n",
      "AB/wiki_18\n",
      "AB/wiki_48\n",
      "AB/wiki_91\n",
      "AB/wiki_10\n",
      "AB/wiki_26\n",
      "AB/wiki_60\n",
      "AB/wiki_45\n",
      "AB/wiki_85\n",
      "AB/wiki_73\n",
      "AB/wiki_70\n",
      "AB/wiki_62\n",
      "AB/wiki_97\n",
      "AB/wiki_25\n",
      "AB/wiki_49\n",
      "AB/wiki_71\n",
      "AB/wiki_58\n",
      "AB/wiki_52\n",
      "AB/wiki_86\n",
      "AB/wiki_09\n",
      "AB/wiki_43\n",
      "AB/wiki_44\n",
      "AB/wiki_21\n",
      "AB/wiki_92\n",
      "AB/wiki_27\n",
      "AB/wiki_35\n",
      "AB/wiki_38\n",
      "AB/wiki_41\n",
      "AB/wiki_29\n",
      "AB/wiki_69\n",
      "AB/wiki_64\n",
      "AB/wiki_11\n",
      "AB/wiki_88\n",
      "AB/wiki_82\n",
      "AB/wiki_89\n",
      "AB/wiki_40\n",
      "AB/wiki_83\n",
      "AB/wiki_07\n",
      "AB/wiki_93\n",
      "AB/wiki_03\n",
      "AB/wiki_08\n",
      "AB/wiki_37\n",
      "AB/wiki_98\n",
      "AB/wiki_05\n",
      "AB/wiki_12\n",
      "AB/wiki_20\n",
      "AB/wiki_53\n",
      "AB/wiki_17\n",
      "AB/wiki_54\n",
      "AB/wiki_22\n",
      "AB/wiki_94\n",
      "AB/wiki_78\n",
      "AA/wiki_16\n",
      "AA/wiki_39\n",
      "AA/wiki_47\n",
      "AA/wiki_61\n",
      "AA/wiki_90\n",
      "AA/wiki_15\n",
      "AA/wiki_24\n",
      "AA/wiki_50\n",
      "AA/wiki_57\n",
      "AA/wiki_28\n",
      "AA/wiki_79\n",
      "AA/wiki_96\n",
      "AA/wiki_75\n",
      "AA/wiki_32\n",
      "AA/wiki_87\n",
      "AA/wiki_30\n",
      "AA/wiki_95\n",
      "AA/wiki_31\n",
      "AA/wiki_01\n",
      "AA/wiki_63\n",
      "AA/wiki_56\n",
      "AA/wiki_76\n",
      "AA/wiki_99\n",
      "AA/wiki_67\n",
      "AA/wiki_33\n",
      "AA/wiki_06\n",
      "AA/wiki_72\n",
      "AA/wiki_80\n",
      "AA/wiki_59\n",
      "AA/wiki_14\n",
      "AA/wiki_42\n",
      "AA/wiki_02\n",
      "AA/wiki_19\n",
      "AA/wiki_65\n",
      "AA/wiki_81\n",
      "AA/wiki_55\n",
      "AA/wiki_74\n",
      "AA/wiki_13\n",
      "AA/wiki_34\n",
      "AA/wiki_84\n",
      "AA/wiki_23\n",
      "AA/wiki_36\n",
      "AA/wiki_46\n",
      "AA/wiki_68\n",
      "AA/wiki_51\n",
      "AA/wiki_04\n",
      "AA/wiki_00\n",
      "AA/wiki_66\n",
      "AA/wiki_77\n",
      "AA/wiki_18\n",
      "AA/wiki_48\n",
      "AA/wiki_91\n",
      "AA/wiki_10\n",
      "AA/wiki_26\n",
      "AA/wiki_60\n",
      "AA/wiki_45\n",
      "AA/wiki_85\n",
      "AA/wiki_73\n",
      "AA/wiki_70\n",
      "AA/wiki_62\n",
      "AA/wiki_97\n",
      "AA/wiki_25\n",
      "AA/wiki_49\n",
      "AA/wiki_71\n",
      "AA/wiki_58\n",
      "AA/wiki_52\n",
      "AA/wiki_86\n",
      "AA/wiki_09\n",
      "AA/wiki_43\n",
      "AA/wiki_44\n",
      "AA/wiki_21\n",
      "AA/wiki_92\n",
      "AA/wiki_27\n",
      "AA/wiki_35\n",
      "AA/wiki_38\n",
      "AA/wiki_41\n",
      "AA/wiki_29\n",
      "AA/wiki_69\n",
      "AA/wiki_64\n",
      "AA/wiki_11\n",
      "AA/wiki_88\n",
      "AA/wiki_82\n",
      "AA/wiki_89\n",
      "AA/wiki_40\n",
      "AA/wiki_83\n",
      "AA/wiki_07\n",
      "AA/wiki_93\n",
      "AA/wiki_03\n",
      "AA/wiki_08\n",
      "AA/wiki_37\n",
      "AA/wiki_98\n",
      "AA/wiki_05\n",
      "AA/wiki_12\n",
      "AA/wiki_20\n",
      "AA/wiki_53\n",
      "AA/wiki_17\n",
      "AA/wiki_54\n",
      "AA/wiki_22\n",
      "AA/wiki_94\n",
      "AA/wiki_78\n"
     ]
    }
   ],
   "source": [
    "flag_break=0\n",
    "path_to_json = '/home/sdatta/data/wikipedia_squad'\n",
    "\n",
    "df_data=pd.DataFrame(index=None, columns=['data', 'version'])\n",
    "\n",
    "for path, subdirs, files in os.walk(path_to_json):\n",
    "    if flag_break==1:\n",
    "        break\n",
    "    for file_num, name in enumerate(files):\n",
    "        if flag_break==1:\n",
    "            break\n",
    "        if not name.startswith('wiki'):\n",
    "#         if not ( name.startswith('wiki_00') #or  name.startswith('wiki_01') \n",
    "#                ):\n",
    "            continue\n",
    "        dict_temp=dict()\n",
    "        file_path = os.path.join(path, name)\n",
    "        file_name_out = \"/\".join(file_path.split('/')[-2:])\n",
    "        dict_temp = pd.read_json(file_path)\n",
    "        for data_num, ele1 in enumerate(dict_temp['data']):\n",
    "            if flag_break==1:\n",
    "                break\n",
    "            dict_temp['data'][data_num]['filename']=file_name_out\n",
    "        df_data=df_data.append(pd.DataFrame(dict_temp), ignore_index=True)\n",
    "        print(file_name_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Internet has helped autistic individuals bypass nonverbal cues and emotional sharing that they find difficult to deal with, and has given them a way to form online communities and work remotely. Societal and cultural aspects of autism have developed: some in the community seek a cure, while others believe that autism is simply another way of being.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "df_data['data'][1]['paragraphs'][68]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatening all context to all_context\n",
    "for data_num, ele1 in enumerate(df_data['data']):\n",
    "    title=ele1['title']\n",
    "    df_data['data'][data_num]['all_context']=''\n",
    "    for para_num, ele2 in enumerate(ele1['paragraphs']):\n",
    "        df_data['data'][data_num]['all_context']=df_data['data'][data_num]['all_context']+ele2['context']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New dataframe with title, row_num , all_context\n",
    "df_data_2=pd.DataFrame()\n",
    "for data_num, ele1 in enumerate(df_data['data']):\n",
    "    title=df_data['data'][data_num]['title']\n",
    "    row_num=data_num\n",
    "    all_context=df_data['data'][data_num]['all_context']\n",
    "    dict_tmp={'title':title,'row_num':row_num,'raw_context':all_context}    \n",
    "    # The dictionary needs to be in [] brackets\n",
    "    df_data_2=df_data_2.append(pd.DataFrame([dict_tmp]), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10302, 3)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "df_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For development\n",
    "df_data_3=pd.DataFrame()\n",
    "df_data_3=df_data_2.iloc[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_tokenize(in_raw_context: str):\n",
    "    tokenize_cleaned=[lemmatizer.lemmatize(ele) for ele in word_tokenize(in_raw_context.lower()) if (ele not in stopWords and ele.isalpha())]\n",
    "    #tokenize_cleaned=[ele for ele in tokenize_cleaned if ele in nltk_words.words()]\n",
    "    return \" \".join(tokenize_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT USED\n",
    "# def get_cosine_sim(*strs): \n",
    "#     vectors = [t for t in get_vectors(*strs)]\n",
    "#     return cosine_similarity(vectors)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT USED\n",
    "# def get_vectors(*strs):\n",
    "#     text = [t for t in strs]\n",
    "#     vectorizer = CountVectorizer(text)\n",
    "#     vectorizer.fit(text)\n",
    "#     return vectorizer.transform(text).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_data_3['tokenized_context']=df_data_3['raw_context'].apply(f_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    anarchism political philosophy advocate societ...\n",
       "1    autism developmental disorder characterized di...\n",
       "2    albedo meaning measure diffuse reflection sola...\n",
       "3    named plural aes first letter first vowel mode...\n",
       "4    alabama state southeastern region united state...\n",
       "Name: tokenized_context, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_3['tokenized_context']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer() \n",
    "text_transformed = tfidf.fit_transform(df_data_3['tokenized_context'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_similarity = text_transformed * text_transformed.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(pairwise_similarity.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055508</td>\n",
       "      <td>0.019021</td>\n",
       "      <td>0.057081</td>\n",
       "      <td>0.119624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>0.050659</td>\n",
       "      <td>0.048557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019021</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033505</td>\n",
       "      <td>0.032679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057081</td>\n",
       "      <td>0.050659</td>\n",
       "      <td>0.033505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.119624</td>\n",
       "      <td>0.048557</td>\n",
       "      <td>0.032679</td>\n",
       "      <td>0.034654</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  1.000000  0.055508  0.019021  0.057081  0.119624\n",
       "1  0.055508  1.000000  0.028461  0.050659  0.048557\n",
       "2  0.019021  0.028461  1.000000  0.033505  0.032679\n",
       "3  0.057081  0.050659  0.033505  1.000000  0.034654\n",
       "4  0.119624  0.048557  0.032679  0.034654  1.000000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1=df_data_3.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['raw_context', 'row_num', 'title', 'tokenized_context'], dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp=df_data_3.loc[0].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0], dtype='int64')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe loc to Series to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1=df_data_3.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_context</th>\n",
       "      <th>row_num</th>\n",
       "      <th>title</th>\n",
       "      <th>tokenized_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anarchism is a political philosophy that advoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>anarchism political philosophy advocate societ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anarchism is a political philosophy that advoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>anarchism political philosophy advocate societ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_context row_num      title  \\\n",
       "0  Anarchism is a political philosophy that advoc...       0  Anarchism   \n",
       "0  Anarchism is a political philosophy that advoc...       0  Anarchism   \n",
       "\n",
       "                                   tokenized_context  \n",
       "0  anarchism political philosophy advocate societ...  \n",
       "0  anarchism political philosophy advocate societ...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2=var1.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2=var2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'raw_context', 'row_num', 'title', 'tokenized_context'], dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['raw_context', 'row_num', 'title', 'tokenized_context'], dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_context</th>\n",
       "      <th>row_num</th>\n",
       "      <th>title</th>\n",
       "      <th>tokenized_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anarchism is a political philosophy that advoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>anarchism political philosophy advocate societ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_context row_num      title  \\\n",
       "0  Anarchism is a political philosophy that advoc...       0  Anarchism   \n",
       "\n",
       "                                   tokenized_context  \n",
       "0  anarchism political philosophy advocate societ...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3=df_data_3.append(var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_context</th>\n",
       "      <th>row_num</th>\n",
       "      <th>title</th>\n",
       "      <th>tokenized_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anarchism is a political philosophy that advoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>anarchism political philosophy advocate societ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autism is a developmental disorder characteriz...</td>\n",
       "      <td>1</td>\n",
       "      <td>Autism</td>\n",
       "      <td>autism developmental disorder characterized di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albedo () (, meaning 'whiteness') is the measu...</td>\n",
       "      <td>2</td>\n",
       "      <td>Albedo</td>\n",
       "      <td>albedo meaning measure diffuse reflection sola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A (named , plural \"As\", \"A's\", \"a\"s, \"a's\" or ...</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>named plural aes first letter first vowel mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama is a state in the southeastern region ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>alabama state southeastern region united state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anarchism is a political philosophy that advoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>anarchism political philosophy advocate societ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_context row_num      title  \\\n",
       "0  Anarchism is a political philosophy that advoc...       0  Anarchism   \n",
       "1  Autism is a developmental disorder characteriz...       1     Autism   \n",
       "2  Albedo () (, meaning 'whiteness') is the measu...       2     Albedo   \n",
       "3  A (named , plural \"As\", \"A's\", \"a\"s, \"a's\" or ...       3          A   \n",
       "4  Alabama is a state in the southeastern region ...       4    Alabama   \n",
       "0  Anarchism is a political philosophy that advoc...       0  Anarchism   \n",
       "\n",
       "                                   tokenized_context  \n",
       "0  anarchism political philosophy advocate societ...  \n",
       "1  autism developmental disorder characterized di...  \n",
       "2  albedo meaning measure diffuse reflection sola...  \n",
       "3  named plural aes first letter first vowel mode...  \n",
       "4  alabama state southeastern region united state...  \n",
       "0  anarchism political philosophy advocate societ...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformed = tfidf.fit_transform(df_data_3['tokenized_context'])\n",
    "pairwise_similarity = text_transformed * text_transformed.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(pairwise_similarity.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>0.018739</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.117219</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.045646</td>\n",
       "      <td>0.043454</td>\n",
       "      <td>0.054158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018739</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.031129</td>\n",
       "      <td>0.018739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.045646</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031933</td>\n",
       "      <td>0.057473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117219</td>\n",
       "      <td>0.043454</td>\n",
       "      <td>0.031129</td>\n",
       "      <td>0.031933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>0.018739</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.117219</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0  1.000000  0.054158  0.018739  0.057473  0.117219  1.000000\n",
       "1  0.054158  1.000000  0.026240  0.045646  0.043454  0.054158\n",
       "2  0.018739  0.026240  1.000000  0.032594  0.031129  0.018739\n",
       "3  0.057473  0.045646  0.032594  1.000000  0.031933  0.057473\n",
       "4  0.117219  0.043454  0.031129  0.031933  1.000000  0.117219\n",
       "5  1.000000  0.054158  0.018739  0.057473  0.117219  1.000000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.117219</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.117219</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2         3         4         5\n",
       "0  1.000000  0.054158  NaN  0.057473  0.117219  1.000000\n",
       "1  0.054158  1.000000  NaN       NaN       NaN  0.054158\n",
       "2       NaN       NaN  1.0       NaN       NaN       NaN\n",
       "3  0.057473       NaN  NaN  1.000000       NaN  0.057473\n",
       "4  0.117219       NaN  NaN       NaN  1.000000  0.117219\n",
       "5  1.000000  0.054158  NaN  0.057473  0.117219  1.000000"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1=set()\n",
    "set1.update([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1.update([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_titles(in_row_idx: int, in_title_idx: list):\n",
    "    print(\"Root title:\",df_data_4.loc[in_row_idx]['title'])\n",
    "    print(\"Similar titles are:\")\n",
    "    for ele in in_title_idx:\n",
    "        print(df_data_4.loc[ele]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MATCH_THRESHOLD=0.05\n",
    "MATCH_THRESHOLD=0.1\n",
    "def f_get_threshold_val_index(in_values):\n",
    "    tmp_arr=np.array(in_values)[:-1]\n",
    "    ret_value=np.nonzero(tmp_arr>=MATCH_THRESHOLD)[0].tolist()\n",
    "    \n",
    "    return ret_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seencols=set()\n",
    "\n",
    "def f_get_sim_titles(in_column_idx: list):\n",
    "    \n",
    "    global set_seencols\n",
    "\n",
    "    list_titles=[]\n",
    "    for ele in in_column_idx:\n",
    "        if ele in set_seencols:\n",
    "            continue\n",
    "        else:\n",
    "            list_titles.append(df_data_4.loc[ele]['title'])\n",
    "\n",
    "    #Updating seen columns\n",
    "    set_seencols.update(in_column_idx)\n",
    "    \n",
    "    ret_value=list_titles\n",
    "    \n",
    "    return ret_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seencols_topnwords=set()\n",
    "def get_top_n_words(list_corpus_idx: list, n=3, ):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \n",
    "    get_top_n_words([\"I love Python\", \"Python is a language programming\", \"Hello world\", \"I love the world\"]) -> \n",
    "    [('python', 2),\n",
    "     ('world', 2),\n",
    "     ('love', 2),\n",
    "     ('hello', 1),\n",
    "     ('is', 1),\n",
    "     ('programming', 1),\n",
    "     ('the', 1),\n",
    "     ('language', 1)]\n",
    "    \"\"\"\n",
    "    corpus=[]\n",
    "    list_of_frequent_words=[]\n",
    "    global set_seencols_topnwords\n",
    "    \n",
    "    list_corpus_idx_filtered = set(list_corpus_idx) - set_seencols_topnwords\n",
    "    # for ele in list_corpus_idx:\n",
    "    #     if ele in set_seencols_topnwords:\n",
    "    #         continue\n",
    "    #     else:\n",
    "    #         corpus.append(df_data_4.iloc[ele]['tokenized_context'] )\n",
    "    corpus.append(df_data_4.iloc[list(list_corpus_idx_filtered)]['tokenized_context'] )\n",
    "    \n",
    "    #Reason for corpus[0]\n",
    "    #corpus=[]\n",
    "    # corpus.append(df_data_4.iloc[[0,2,3]]['title'].values)\n",
    "    # corpus\n",
    "    # [array(['Hair', 'Hawker Harrier', 'Hergé'], dtype=object)]\n",
    "    corpus=corpus[0]\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    list_of_frequent_words=[x[0] for x in words_freq]\n",
    "\n",
    "    #Updating seen columns\n",
    "    set_seencols.update(list_corpus_idx_filtered)\n",
    "\n",
    "    #return words_freq[:n]\n",
    "    return list_of_frequent_words[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10301"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_seencols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10302, 3)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For development\n",
    "df_data_4=pd.DataFrame()\n",
    "df_data_4=df_data_2.copy(deep=True)\n",
    "df_data_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing and cleaning context\n",
    "df_data_4['tokenized_context']=df_data_4['raw_context'].apply(f_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(analyzer='word', smooth_idf=False, sublinear_tf=False, norm=None,\n",
    "#                         stop_words='english', ngram_range=(1,1), strip_accents='ascii',use_idf=True) \n",
    "tfidf = TfidfVectorizer() \n",
    "text_transformed = tfidf.fit_transform(df_data_4['tokenized_context'])\n",
    "pairwise_similarity = text_transformed * text_transformed.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding similar columns\n",
    "df_data_simi=pd.DataFrame(pairwise_similarity.toarray())\n",
    "df_data_simi['sim_columns']=df_data_simi.apply(f_get_threshold_val_index,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data_simi['sim_titles']=df_data_simi['sim_columns'].apply(f_get_sim_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data_simi['common_words']=df_data_simi['sim_columns'].apply(get_top_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_data_simi['sim_titles'].to_csv('/home/sdatta/work/sim_titles.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_data_simi['common_words'].to_csv('/home/sdatta/work/common_words.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_simi[['sim_titles','common_words']].to_csv('/home/sdatta/work/sim_titles_words.txt', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdatta/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_data_simi['sim_columns'].to_csv('/home/sdatta/work/sim_columns.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_data_4, open('/home/sdatta/work/df_data_4_1.0_20190416_1418.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_data_simi, open('/home/sdatta/work/df_data_simi_1.0_20190416_1418.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_data, open('/home/sdatta/work/df_data_20190416_0852.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_data_2, open('/home/sdatta/work/df_data_2_20190416_0852.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10302, 4)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
